Datetime,Message
2023-03-02 07:21:36,ChatGPT API Launch tl;dr: 
2023-03-02 12:32:16,in case someone missed it
2023-03-02 12:33:54,https://twitter.com/c_valenzuelab/status/1630969280803250176?t=Timm5pV-ymLQM02QPZM-sg&s=08
2023-03-02 12:38:40,Ok I finally got controlnet working in a way that makes me happy!
2023-03-02 14:11:04,Anyone here who’s deployed gpt-3.5-turbo on any of their production apps? How are the latencies after some certain scale? Is the API timing out or throwing errors?
2023-03-02 14:11:42,"Na, mostly stable so far. Needs some retries but works with exponential backoff"
2023-03-02 23:14:45,Corridor Digital reveals how they made Anime using SD VFX and Blender (scenes)
2023-03-02 23:56:59,https://twitter.com/stabilityai/status/1631339515792039968
2023-03-03 01:22:09,The new Flan-UL2 20B from GoogleAI is out! 
2023-03-03 01:23:17,"PS: As a dev I like to use fancy terms, ask questions — fun to answer them :)"
2023-03-03 03:58:20,What's the compute required to have a good / useful throughput
2023-03-03 03:59:07,"If it's gonna be costing similar in cloud instance cost, you might as well go with chatgpt API?"
2023-03-03 08:27:13,"Was thinking more data localisation and compliance needs, not cost"
2023-03-03 12:15:01,"+ control…If you need to train specialized models, can’t yet do it with chatGPT. Also once LLMs start to call APIs which access sensitive data, we might need different, transparent and configurable/ finetunable base models."
2023-03-03 14:04:02,"Same applies if it's on cloud instead of on prem, no?"
2023-03-03 14:22:44,Two interesting a16z articles
2023-03-03 14:22:48,https://a16z.com/2023/01/19/who-owns-the-generative-ai-platform/
2023-03-03 14:22:52,https://a16z.com/2023/02/07/everyday-ai-consumer/
2023-03-03 14:26:51,I wrote a deeper dive into what successful AI products would look like at https://www.amoghvaishampayan.com/post/generative-ai-product-strategy
2023-03-03 14:29:46,I've worked as an AI product manager for the last 5 years. The essence of my generative AI article cold be summarized as - 
2023-03-03 14:42:36,https://www.reforge.com/blog/ai-products-arms-race
2023-03-03 14:59:35,https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full.pdf
2023-03-03 15:01:38,"This is the fMRI → SD from Japanese folks, right? It's quite radical, and well — brain shattering ;)"
2023-03-03 15:02:02,"Oh yeah, the on from Osaka. :D"
2023-03-03 15:06:45,It took me a couple of mins to realise that prompt for these images was imagination 🤯
2023-03-03 15:07:57,This is genius
2023-03-03 15:10:05,Yep...
2023-03-03 15:10:22,🤩
2023-03-03 15:11:23,"Increasing the noise in my brain by watching non Hindi and non English media only from now on! Will also learn a new language, but only the hi, hello part every month."
2023-03-03 15:11:49,Ummm have they released some code?
2023-03-03 15:12:18,I am very skeptical on this. Data from brain to be used for useful things is still in very very early research.
2023-03-03 15:12:27,"Nahi, it's not peer reviewed. Just submitted to some conf I think."
2023-03-03 15:12:32,Like up/down itself has 70% accuracy
2023-03-03 15:12:42,State of the art devices with some 200 probes ke sath this is the case
2023-03-03 15:12:55,Off the shelf devices like the one that came in shark tank are bleh
2023-03-03 15:12:58,You're bringing facts to an emo excited conversation. Why you be like this?
2023-03-03 15:13:12,Coz I have spent a lot of money and time on this 😂
2023-03-03 15:13:23,My rant is my emo :P
2023-03-03 15:13:28,Please elaborate further
2023-03-03 15:13:51,😂😂😂 
2023-03-03 15:13:55,I have bought some 4 such devices over 4 years
2023-03-03 15:14:01,Each costing 25k to 1L :P
2023-03-03 15:14:11,And I was a subject in one such experiment too
2023-03-03 15:14:27,And the data is so noisy and hard to use.
2023-03-03 15:14:42,Like the ones used in hospitals was benchmark for off the shel devices
2023-03-03 15:14:49,"those have 200 probes, you have to be bald"
2023-03-03 15:14:56,and then also it is noisy.
2023-03-03 15:15:08,It works on voltage of neurons. So probes need to be very ver sensitive
2023-03-03 15:15:13,Which is a hard hardware problem
2023-03-03 15:16:29,"They are using fMRI data which has a much stronger signal profile. I participated in a couple of frontal lobe activation expts here, and the data was apparently clean enough to run some pretty interesting analyses."
2023-03-03 15:18:05,Can't we get such data without having a hardware device ?
2023-03-03 15:18:34,That's a near-certain no.
2023-03-03 15:19:39,"What does clean enough and analyses mean here? If it's alright with you, share a couple of examples?"
2023-03-03 15:20:03,I will try and find the paper.
2023-03-03 15:24:57,Non-invasive devices are already pretty noisy compared to brain probes. Without hardware matlab kya?
2023-03-03 15:25:27,"In the meanwhile, the expt was as follows: two sessions of 45 min- 1hr wherein a volunteer (me and 10 others) will lie in an fMRI machine, and solve some logic and language puzzles (they will be projected on a screen and I have to verbalize my answer). They showed me the processed data stream sometime later, and explained that they were going to try and localize activations and their strengths to understand which subsection of the frontal lobe is responsible for the thought. After that, they had planned to run some time-series analyses to see how the activation shifts as the answer is obtained and verbalised (not sure if they ever published this one)."
2023-03-03 17:06:41,"Folks, what are the best videos/resources on using SD for designers (product, UX) and artists? "
2023-03-03 17:07:01,"(Yes, I've already included the anime which plays rock, paper)"
2023-03-03 17:15:00,Automatic1111 is the easiest way to use SD and all of its plugins but requires a GPU to run on local. Plus the setup can be a bit technical. If no GPU then it has to run on Colab which is also technical.
2023-03-03 17:28:28,Imagine getting actual footage of your dreams 🤯
2023-03-03 17:40:40,YC Founder talks to YC Partner: https://youtu.be/hQC5O3WTmuo
2023-03-04 09:26:02,https://theresanaiforthat.com/
2023-03-04 11:29:22,"We open-sourced our Hasura AI bot code; and made it easy to deploy with one click. Read about it here,"
2023-03-04 15:49:59,Offset Noise is heating up AI Art
2023-03-04 16:35:29,https://twitter.com/MetaAI/status/1631351811696394240?s=20
2023-03-04 16:54:48,Can you post the original tweet link
2023-03-04 16:55:35,He is also running purchase parity which I feel most products miss
2023-03-04 21:23:02,"An AI themed movie that someone will make soon enough. Think Her, but with a couple and a twist!"
2023-03-05 23:13:08,"Hi everyone, I'm Anirudth, currently an Applied Scientist at Amazon. Invited by [PHONE REMOVED] to this group. I'm excited about generative AI and looking to unlock new opportunities."
2023-03-06 00:59:23,https://www.marktechpost.com/2023/02/28/oxford-university-researchers-introduce-a-diffusion-model-called-realfusion-that-can-generate-360-degree-reconstructions-of-objects-from-an-image/?amp
2023-03-06 00:59:37,Breakthrough for nerf
2023-03-06 08:41:34,cc [PHONE REMOVED] Devanshu Tak is a 3D artist who has used NeRF earlier in his work
2023-03-06 14:44:37,Interesting read: https://unsupervisedlearning.substack.com/p/using-large-language-models-effectively. Esp the #4 point around embeddings
2023-03-06 15:57:01,"really interesting points. [PHONE REMOVED] you guys used pinecone and langchain in the hasura bot for the embedding purpose only, right?"
2023-03-06 15:59:11,Embedding and prompt templating
2023-03-06 15:59:17,But embedding was the biggest reason
2023-03-06 16:00:40,Any specific reason for not using the openai's embedding endpoint other than cost and latency?
2023-03-06 16:00:54,It uses openAI embedding
2023-03-06 16:01:02,Pinecone is used as vector store
2023-03-06 16:01:06,oh ok
2023-03-06 16:01:11,Yeah that's what I would assume
2023-03-06 16:01:15,Langchain gives a good abstraction
2023-03-06 16:02:09,"Cool cool, haven't used it yet. I thought it might be some kind of local store creator (if that makes sense 😅)"
2023-03-06 16:16:15,Chroma bundles store and the embedding call into one from what I can tell. I'll try that out this week
2023-03-08 10:37:42,Doing a GenerativeAI Hackathon! 
2023-03-08 17:56:52,What kind of problem statements are welcome?
2023-03-08 17:57:56,"Anything that uses Generative AI e.g. ChatGPT, Midjourney is welcome. No other constraint on the problem statement. Make April Fool Apps for all I care"
2023-03-08 17:58:36,Cool
2023-03-08 18:11:05,Has everyone already got a team? 😄
2023-03-08 18:12:04,Anyone here interested in Normalizing flows?
2023-03-08 18:32:07,"I have been, for a while."
2023-03-08 18:33:03,+1
2023-03-08 18:48:41,Industrial use cases or out if academic interest?
2023-03-08 18:48:45,*of
2023-03-08 18:52:31,Wrong window.
2023-03-08 18:53:03,Interesting resource:
2023-03-08 21:41:50,https://research.runwayml.com/gen1
2023-03-09 15:24:31,"Hi all, wanted to run by an opportunity with you. It's a large content + consumer brands company that I am closely working with, they reach about 40% of all social media users in India. "
2023-03-09 15:24:56,Is this something that you/any friend you know be interested in exploring? You can DM if yes
2023-03-10 08:13:40,https://zenil.substack.com/p/indian-generative-ai-landscape-the?r=1f3ivv&utm_campaign=post&utm_medium=web
2023-03-10 08:19:30,https://www.reddit.com/r/singularity/comments/11mztcu/gpt4_is_coming_next_week_and_it_will_be/
2023-03-10 16:11:50,Thanks [PHONE REMOVED] for adding me here. 
2023-03-12 16:32:26,Interested in finding what GPT hype is about?
2023-03-12 16:39:51,Is this different from the Google form i filled for hackathon?
2023-03-12 16:40:42,"Yes, that is participants only. For people hacking on that day. This is for everyone interested in just seeing what was built during the hackathon!"
2023-03-12 16:41:00,"So participants don't need to fill then, right?"
2023-03-12 16:41:02,Register here for a hackathon invite to the BLR venue: https://forms.gle/UizUwyKi4bajt6WB7
2023-03-12 16:41:09,No
2023-03-12 19:00:13,Why does wording say only GPT?
2023-03-12 19:02:23,"Haan Nirant. [PHONE REMOVED], is going to dazzle with stable diffusion. :)"
2023-03-12 19:02:44,Exactly :P 
2023-03-12 19:10:34,"Would help you save face a lot more if at least someone from your company signed up to participate, that number is 🥚 right now"
2023-03-12 19:19:47,Registrations shall come :P
2023-03-12 19:39:18,https://www.youtube.com/watch?v=VdMgPgicvK4
2023-03-12 19:39:38,Anyone with access to Runwayml?
2023-03-13 22:36:50,"Hey, are there any LLMs by open AI that can be deployed on prem today?"
2023-03-13 22:37:25,OpenAI has Foundry at $1M/yr which will have onprem
2023-03-13 22:37:36,*FLan-T5 is FOSS and by Google
2023-03-13 22:39:22,Thanks Nirant for the quick help!
2023-03-14 11:35:40,"Hello folks, "
2023-03-14 11:36:23,same question!
2023-03-14 11:42:06,"Yes, most definitely! "
2023-03-14 11:46:52,"Hi folks, any non-techies here? This space is too technical for me right now, but I want to make a conscious effort to keep up with what's happening. Will appreciate any help!"
2023-03-14 11:52:47,"[PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] are PMs, [PHONE REMOVED] [PHONE REMOVED] are founder and VC respectively, [PHONE REMOVED] is Mumbai based creative agency person, "
2023-03-14 11:53:07,Thanks Nirant! 🌻 I'll bug 'em.
2023-03-14 11:55:11,What's the prize money split?
2023-03-14 11:56:54,"1L minimum per track — no runners up, remote submissions welcome, split between all members of the winning team equally "
2023-03-14 12:32:13,"Details of evaluation criteria will be helpful, best if it is quantitative and transparent"
2023-03-14 12:36:55,"This is left to jury's discretion. I'm not aware of it either, nor will I be till the day of hackathon. The jury may choose to share it, after the demos or make it quantitative."
2023-03-14 12:37:15,Personally not a fan of making JEE Mains out of a hackathon
2023-03-14 12:38:25,"At least devs competing will know what they are going to be judged on, right?"
2023-03-14 12:38:57,And will be helpful for the jury as well on what to look for
2023-03-14 12:40:13,So need to know the jee syllabus rather than going with broad ias subject 🙂
2023-03-14 12:46:58,Tracks are announced no for the hackathon? Isnt that enough to decide? 🤔
2023-03-14 12:48:10,"Hey Heer, Rasagy here! Designer / Data Artist 👋"
2023-03-14 12:48:22,"Having criteria takes away the fun from hacking/creativity part from hackathons, I absolutely agree with Nirants point of leaving it to the judges"
2023-03-14 13:03:18,Hey Heer. My name is Jay. I'm a product manager
2023-03-14 15:38:08,Hey Jay! 👋🏻 nice to meet you..DMing.
2023-03-14 15:38:46,Hello Rasagy! 💃 DMing!
2023-03-14 15:55:23,"Hi Heer, Vikas here. fintech/tech  consultant/trainer"
2023-03-14 15:57:37,Thanks Nirant. 
2023-03-14 17:22:33,https://alpaca-ai-custom4.ngrok.io/ Thoughts on this?
2023-03-14 17:31:13,"Very slow to try prompts there atm. Hoping it'll be on nat.dev soon. So far, it looks more like davinci-002 than the 003 series in terms of ability to follow logic over multiple hops. Also, no weights — so kinda iffy on what is going inside training"
2023-03-14 18:29:45,"Welcome Manjot [PHONE REMOVED]. She is with Lightspeed VC currently. She has a ton of experience having been at Google, started up and then led Stripe India as CEO."
2023-03-14 18:53:18,The instruct dataset is key. And the PR they have raised with Huggingface gives you the training code.
2023-03-14 22:41:47,https://twitter.com/OpenAI/status/1635687373060317185?t=nhm2BaNejunBE9-syFgEeA&s=19
2023-03-14 22:42:20,"Clearly, built for enterprise:"
2023-03-14 22:51:17,As I understand the big user visible things are:
2023-03-14 22:51:51,This was actually true 😶
2023-03-14 22:53:08,Also too much happening in this space in a day😅 how do one keep up with things?
2023-03-14 22:53:39,3x the price
2023-03-14 22:53:58,Yeah this is crazy. The train just does not stop
2023-03-14 22:55:29,Seems enterprise grade security/Scalability costs premium😅
2023-03-14 22:56:04,12 cents per 1K token completions is quite expensive — this is going to encourage Llama-Alpaca experiments even more
2023-03-14 22:56:12,GPT4 capabilities have a FOSS counterpart from Amazon: github.com/amazon-science/mm-cot
2023-03-14 22:57:05,The be my eyes demo is hilarious 😂
2023-03-14 23:03:37,https://www.youtube.com/live/outcGtbnMuQ?feature=share
2023-03-14 23:09:28,Thank you ... Odd timing for ist. Will wait for the summary from others
2023-03-14 23:18:00,"Thank you so much everyone, glad to be a part of this community! Thanks for adding me Pranjal!"
2023-03-15 02:01:35,https://twitter.com/prashanthshanm/status/1635646028648177669?s=20
2023-03-15 02:03:12,"Too late, too little 😂😅😂😅"
2023-03-15 02:03:22,After seeing the OpenAI demo
2023-03-15 02:04:21,the paper wireframe to working code was just 🤯
2023-03-15 02:05:42,"But wouldn't this get used more than anything else? who doesn't have to check email, write docs / make slides"
2023-03-15 02:09:09,I agree. It doesn’t open up loads of possibilities for others to build upon- but enough productivity & note apps are irrelevant after this.
2023-03-15 02:13:35,Loved the wireframe to code demo by OpenAI today
2023-03-15 02:14:05,Really good demos
2023-03-15 09:41:36,Hello! 
2023-03-15 09:42:25,Will also request other experts hiding in the weeds to lend their expertise around StableDiffusion: [PHONE REMOVED] [PHONE REMOVED]
2023-03-15 09:59:33,Last paper I read on Deep Learning/NLP was Attention Is All You Need.
2023-03-15 10:07:04,I would highly recommend watching Karpathy's nonogpt video. 2 hours of golden content. He basically reproduces the same paper you read from scratch.
2023-03-15 10:07:16,[Beginner Researcher Answer]
2023-03-15 10:08:31,The other way is to work backwards from what is out there and we can study e.g. everything from Llama to Flan-T5 and see what blocks they've been built on
2023-03-15 10:10:16,Do you think Xavi Amatriain's catalog is a good read for starters?
2023-03-15 10:12:01,"That can be a bit overwhelming for someone who was last reading BERT-era papers. I mean, even Contrastive Learning is a new concept there in a way. "
2023-03-15 10:12:21,"But if you do this for a living, you should most def use that as a starting point"
2023-03-15 10:17:12,Re-iterating: Non-technical Qs most welcome. They also are good prompt for someone to elaborate and spark and idea :)
2023-03-15 10:28:49,transformers have taken over the field which was dominated primarily by RNN variants. Are we seeing signals of any new architecture doing the same with transformers?
2023-03-15 10:32:45,On a slightly different tangent 
2023-03-15 10:41:40,"With my limited understanding, I think fine-tuning any LLM is quite tricky."
2023-03-15 10:42:13,"Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks/ months)-  https://web.stanford.edu/class/cs25/ , https://web.stanford.edu/class/cs224n/index.html#schedule , https://people.cs.umass.edu/~miyyer/cs685/"
2023-03-15 10:42:29,What do you think about trlx re: PPO? 
2023-03-15 10:51:42,"My very spicy, uninformed take is that we'll see model sizes, personalities, flavours spread across the spectrum of use cases like we did for DBs."
2023-03-15 10:53:20,"Do we think finetuning is needed for most of the usecases? Or just clever prompt engineering is the way to go? The way I am thinking about this is finetuned model is someone who has learned and internalised the concepts vs prompt optimisation with relevant context is someone intelligent reading interesting information and inferring outputs based on it? And for most cases I feel someone smart reading correct information and responding based on that would be sufficient. Do we think that for applications, prefix / prompt tuning is the way to go than finetuning base models (for applications; for open source LLMs, we will need instruction tuning) ?"
2023-03-15 10:53:20,"For artists (non-tech) looking for _prompt to art_ experiments, what is the next step after playing with basic prompts on Midjourney & Dall-e? Do you recommend just going deep with those two platforms, or is there something else that works better?"
2023-03-15 10:53:21,Alex from Carper AI is presenting this tonight at W&B conference. So I'll wait till then and discuss tomorrow.
2023-03-15 10:54:41,Playgroundai
2023-03-15 10:55:28,Prompt optimisation looks more lucrative as the possible size of prompt is now much bigger. Would we train smaller models which will generate better prompts for the underlying LLMs ?
2023-03-15 10:56:34,"Stable Diffusion gives you a lot more control, power and flexibility. See civitai.com (NSFW!) for all the styles and themes you can create around. You might also want to checkout a couple of Youtube artists using this really well for prompt to art: youtube.com/@sebastiankamph is my fav at the moment"
2023-03-15 10:57:33,"In this group, [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] have played with Automatic1111 the interface and all that it unlocks from ControlNet (used for making fingers, control posture, faces) to upresolution for high res images"
2023-03-15 11:05:51,"Prompt engineering also changes with each new release, the system gets better at understanding what the user is looking for"
2023-03-15 11:07:01,I'll try this for first one week.
2023-03-15 11:07:36,"a related but different thought, the next step for text2image providers is integrating directly with artists choice of full-fledge tool - canva, photoshop"
2023-03-15 11:10:40,"if you have explored prompt engineering, i think next logical step would be exploring image2image, in-painting, out-painting and instruct pix2pix"
2023-03-15 11:30:28,"also did a quick write-up on different web UIs out there, hope this is helpful for this group - https://www.ai-art.dev/web-uis-for-stable-diffusion"
2023-03-15 12:04:37,https://www.linkedin.com/posts/sayak-paul_bangalore-folks-how-about-organizing-an-activity-7041263527482830848-qGzh?utm_source=share&utm_medium=member_ios
2023-03-15 12:48:04,[PHONE REMOVED] Have been working with artists and their flows a lot to figure on how to empower them more.
2023-03-15 12:50:52,RNNs are fighting back https://mobile.twitter.com/arankomatsuzaki/status/1635453248252391427
2023-03-15 13:14:52,"Most research shows that bigger the model, more the number of emergent properties. Are there any works that show when these arise during training? Do they arise gradually one by one as we train or do they all come up early and become better as we train?"
2023-03-15 13:27:07,To give more context on the premise: https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ/s1600/image8.gif from the Google palm Blogpost https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html?m=1
2023-03-16 10:27:52,"I basically read all the papers related to popular models, helps you understand the differences."
2023-03-16 10:35:00,Thanks Majot. I'll try and explore this as well.
2023-03-16 10:46:16,DM [PHONE REMOVED]
2023-03-16 10:49:34,"At the risk of waxing poetic, I like this game of hunting for clues, trying to get into the mind of what did the research team think and what might be the failed experiments they've not mentioned in a paper. "
2023-03-16 10:51:03,"You can play this game in arcade (like above), or go to hard mode and start with interdisciplinary papers like Visual ChatGPT and diff it against say, Amazon's MM CoT or even team mode: Host a reading session and invite 4 people to present different papers and tell what the authors missed or got right or what their ""insight"" was"
2023-03-16 10:51:23,Brilliant resource. Thanks for sharing.
2023-03-16 10:53:19,Are there any happening in blr? Any channel to discover these?
2023-03-16 10:54:45,Wow this sounds like a great idea. Folks should spontaneously organize such stuff in Bangalore.
2023-03-16 10:55:39,"Sumod Mohan used to run a CV paper reading group, Swanand runs one via Hasgeek which is more broader CS (and very high quality!) "
2023-03-16 10:57:29,I would love to listen in if that’s allowed!
2023-03-16 10:58:34,"If I get >5 DMs, will share the time and venue here. Can do Zoom if >3 of these are non-BLR"
2023-03-16 11:27:57,+1 DM
2023-03-16 11:30:19,Please don't reply here with DM? That's a bit spammy for everyone else here 😅
2023-03-16 12:37:59,https://twitter.com/LangChainAI/status/1636122692645691393?t=aUUOXK9kILoYkyVzVgjdhg&s=19
2023-03-16 15:41:48,I was storing embedding vectors as json in PG database previously. Need to explore this . Thanks for sharing
2023-03-17 00:06:14,"Thank you [PHONE REMOVED] for bringing this, how does this do with large scale searches ? Any help appreciated 👍"
2023-03-17 00:31:53,"Haven't done any performance tests yet, so don't have much idea about that. The integration is still missing some indexing steps, but from what I've seen, specific vector database like pinecone will have better results in case of large scale applications."
2023-03-17 00:32:14,"But again, can't say for sure."
2023-03-17 01:05:59,"Great thanks for your response ,"
2023-03-17 02:35:28,https://www.youtube.com/watch?v=VqhDnaqhnd4 - Very impressive 🙌
2023-03-17 10:34:57,"This might be a naive question but can someone explain why these language models have cut off in 2021, gpt4 included "
2023-03-17 10:40:02,Training involves curating a dataset which is a lot of effort. The dataset they used to train on was curated till 2021.
2023-03-17 10:40:34,"Cleaning the data, wrangling it etc take a LOT of time"
2023-03-17 10:57:47,Does each llm build their own dataset from scratch 
2023-03-17 11:37:52,Afaik gpt4 cut off is aug 22
2023-03-17 11:43:33,there are some open source datasets   
2023-03-17 11:44:26,https://www.springboard.com/blog/data-science/machine-learning-gpt-3-open-ai/
2023-03-17 11:44:47,Gpt-4 paper might have the dataset details. The paper was pretty disappointing though
2023-03-17 12:30:46,"ChatGPT-3 Whatsapp bot. Can summarise videos, transcribe voice notes, answer text questions and generate images using /image "
2023-03-17 13:56:33,"This is interesting as well, I use it for productivity "
2023-03-17 18:45:24,"Count me in for listening, please."
2023-03-17 20:35:03,Replit.com will be sponsoring the hackathon! 
2023-03-17 20:47:53,"It seems slightly more complicated. The model certainly has access to data from 2022, and can answer some questions about it, but its official position is that the data has a cutoff date in 2021, and it doesn't answer some questions citing that as a reason."
2023-03-17 23:48:31,"The first statement is wrong. I don't know what to make of the whole thing. It knows about IFRNet, but somehow gives a partial answer. Produced correct answer for earlier models."
2023-03-17 23:48:44,"Just another day in the life of an LLM, I guess."
2023-03-18 05:52:49,New BingGPT Launch: https://www.bing.com/new
2023-03-18 09:37:50,This has the potential make advertising briefs soooo much easier 💯
2023-03-18 09:45:33,https://www.gizmochina.com/2023/03/16/ai-hire-a-human-to-solve-captcha/
2023-03-18 10:08:04,How will GPT4 change software engineering? I took a stab at answering this: 
2023-03-18 10:10:00,"And by I, I mean actually me, not GPT4 — that guy speaks too much"
2023-03-18 13:09:16,"hey! is march meetup for gen ai is happening today? at Hasura HQ, kora?"
2023-03-18 13:16:18,Is there an RSVP link / signup link for this?
2023-03-18 13:17:44,"No meetup in March, come to the hackathon!"
2023-03-18 18:40:04,Anyone here who has been using image generation model for a while? Have a few questions 
2023-03-18 18:43:52,"1. Yes, I did notice as well. Mid journey results looks more realistic. I tried open-journey too on HF."
2023-03-18 18:46:30,"Yup been playing and creating since 2020, even fine tuned old VQGAN models"
2023-03-18 18:46:58,Thanks 
2023-03-18 18:47:32,"Midjourney is superior, there are a few models in cvitai that come close"
2023-03-18 18:48:03,they offer far more functionality and the open source community is very active
2023-03-18 18:48:11,Midj is really pretty but a lot of models have matched quality now.
2023-03-18 18:48:18,Try gooey.ai
2023-03-18 18:48:22,I recently came across it.
2023-03-18 18:48:41,"I mean HF spaces. If they are not on HF spaces, you can use HF diffusers. The have documentation on inferencing."
2023-03-18 18:49:01,models like?
2023-03-18 18:49:14,"Dreamshaper, openjourney, protogen"
2023-03-18 18:49:24,They're not good enough
2023-03-18 18:49:28,Openjourney is pretty bad
2023-03-18 18:49:32,Protogen has many versions.
2023-03-18 18:49:40,Each with some good and some bad.
2023-03-18 18:49:44,None of them lol
2023-03-18 18:49:51,I've tried all
2023-03-18 18:49:56,Depends what you want. 😅
2023-03-18 18:50:00,The closest model is illuminati diffusion
2023-03-18 18:50:08,With negative embeddings
2023-03-18 18:50:48,Getting MJ like photorealism even with realistic vision is hard
2023-03-18 18:51:09,V5 they really really stepped on photo realism true.
2023-03-18 18:51:13,open journey is good though compared to available open-source models?
2023-03-18 18:51:23,https://civitai.com/
2023-03-18 18:51:28,have fun :)
2023-03-18 18:51:34,"So true, couldn’t try it though "
2023-03-18 18:52:10,Yea. This has most models. There are Bollywood models too 😂
2023-03-18 18:52:22,Yup anyone can train a LORA or a dreambooth
2023-03-18 18:52:38,They're using LORAs to finetune alpaca now
2023-03-18 18:53:13,Anyone giving it a shot? Making LLaMa better with self instruct datasets
2023-03-18 18:53:41,Was discussing literally this yesterday with [PHONE REMOVED] 😅
2023-03-18 18:54:12,Maybe give it a shot over the hackathon day
2023-03-18 18:56:50,I'll sponsor this upto $500 and happy to contribute datasets and get you your first few users if you want to go commercial with it too. 
2023-03-18 18:57:24,^This should tell you how excited I'm about this xD
2023-03-18 18:55:33,Are non engineers doing this enough in India? 🤔
2023-03-18 18:56:26,Most are annon
2023-03-18 18:56:37,Anyone can do it tbh
2023-03-18 18:56:46,what's self instruct datasets?
2023-03-18 18:56:48,Just gotta get through the pain of setting up automatic1111 properly
2023-03-18 18:57:32,Alpaca can be much better.
2023-03-18 18:57:56,And then finetune with lora
2023-03-18 18:58:24,Awesome
2023-03-18 18:58:43,Dude even I'm super excited haha. We actually have a chance to compete with OpenAI and launch something super competetive
2023-03-18 19:00:36,Hashed them out quickly - have a look folks and lmk what you think
2023-03-18 19:00:41,"I'm a simple man, I see Roam, I like it"
2023-03-18 19:00:51,I have the same question..
2023-03-18 19:02:23,haha
2023-03-18 19:03:14,https://crfm.stanford.edu/2023/03/13/alpaca.html
2023-03-18 19:04:44,This is self instructions dataset 
2023-03-18 19:04:16,"Basically a large json that can fine tune any LLM and make them more ""aligned"" - makes an LLM better and more like ChatGPT"
2023-03-18 19:04:22,to put it simply
2023-03-18 19:04:46,https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json
2023-03-18 19:06:45,Who did this? It’s excellent
2023-03-18 19:08:12,catching up on the convos -
2023-03-18 19:09:02,offset noise write up - https://www.crosslabs.org/blog/diffusion-with-offset-noise
2023-03-18 19:11:13,4 months away from this generative AI space and this discussion is already putting me in stone age 😅😅
2023-03-18 19:11:15,"UW PhD Student, quite clever.  Ofc, Stanford hogged all the recall value with Alpaca"
2023-03-18 19:11:58,All this happened in last 2 weeks 😂
2023-03-18 19:12:29,We didn't talk about all the Google stuff and Blender ControlNet for posture and depth yet xD
2023-03-18 19:12:29,"i was still in GenerativeAI, just in text2img and not text2text, and i feel like i am in stone age 😂"
2023-03-18 19:14:31,Haha I'm in touch with toysxyz - the dude building all that. We were jamming on using facial keypoints for better control
2023-03-18 19:14:52,Do people not sleep these days?
2023-03-18 19:14:58,Is everyone on Adderall?
2023-03-18 19:15:09,Hahaha
2023-03-18 19:15:32,Was sleep a ZIRP phenomenon?
2023-03-18 19:15:44,"Asking for myself, I'm the friend"
2023-03-18 19:16:01,😂
2023-03-18 19:18:39,So basically the json structure you need to fine-tune gpt using OpenAI?
2023-03-18 19:18:45,Yup
2023-03-18 19:19:00,It's simple instructions + answers generated by GPT-3
2023-03-18 19:19:21,What if we use GPT-4?
2023-03-18 19:19:55,OpenAI had a team of 40 upwork contractors and Scale AI;s help to do this - (from instructGPT paper)
2023-03-18 19:21:00,A good dataset can make a large difference - like any ML problem
2023-03-19 13:31:16,"Confirmed *FOSS* Demos for the hackathon, 2 of the top 3 projects from Github Trending in AI:"
2023-03-19 13:33:42,"Thanks for the intro Ravi Theja, GPT-Index contributor and inMobi DS [PHONE REMOVED]  to Jerry Liu"
2023-03-19 18:40:21,https://mobile.twitter.com/nickfloats/status/1631346749297106958
2023-03-19 21:16:03,Sharing my favourite blog from last few weeks: https://simonwillison.net/2023/Mar/17/beat-chatgpt-in-a-browser/
2023-03-19 21:16:17,"WASM for LLMs is super interesting, anyone tried?"
2023-03-19 21:18:04,came across this today
2023-03-19 21:33:06,Yup saw this
2023-03-19 21:33:34,They also trained an LLM to mimic Homer Simpson and it’s apparently better than gpt-4
2023-03-19 21:47:15,Hey Hi Guys !
2023-03-19 21:56:32,Iit madras or Bombay has research labs you can cold mail them or reach out to other iits they might help or redirect to appropriate org.
2023-03-19 22:07:26,It'd be hilarious if the model forgot how to do chain of thought reasoning because of that 😂😂
2023-03-19 22:14:56,Lol
2023-03-19 22:18:19,Anyone exploring building a tool like this for VCs? 
2023-03-19 22:18:44,Good customers to sell to and solid use case of AI
2023-03-20 00:11:44,https://twitter.com/tarundua81/status/1625092808095961090
2023-03-20 02:29:00,https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis anyone tried this?
2023-03-20 09:27:09,Reid Hoffmann's essay on GPT4 — but is there an AI Summary of this? 😛
2023-03-20 09:27:23,I mean it's 150+ pages long
2023-03-20 09:27:54,It contains dialogues with GPT-4. 
2023-03-20 09:29:00,"This is the future, people will use copilot to make their emails more detailed and comprehensive. Readers would use copilot to summarise it. 😂"
2023-03-20 09:29:38,"No, in the future — there will be no emails, just byte-streams going from your brain to another brain. Mann Ki Baat."
2023-03-20 09:34:11,"Shubham, my friend from college and a writer on TVF Pitchers S2 [PHONE REMOVED] shared this HBR essay: https://hbr.org/2023/03/how-will-generative-ai-disrupt-video-platforms"
2023-03-20 09:39:59,Very little MLE in the loop
2023-03-20 09:55:41,"Ok super late to this because I was off the phone yesterday. But in my experience Midjourney is far far superior out of the box. Fantastic for applications where you need generic imagery and don't care too much about difficult characters, image composition and other fine control. Very useful for - blog post images, moodboards, inspiration images, stock images "
2023-03-20 10:06:52,Midjourney : Canva : : Stable Diffusion : Photoshop
2023-03-20 12:47:44,interesting
2023-03-20 12:53:07,"But I think its not ""very"" hard to make midj and also there is a lot of legal gray area with midj."
2023-03-20 12:57:06,i wasn't expecting this to happen but Midjourney might release an API!
2023-03-20 12:58:27,InvokeAI has made a pretty slick open source UI for SD.  automatic1111 is like a freaking Bloomberg terminal 😂
2023-03-20 12:58:35,In 2 months? Wow. I missed this office hours
2023-03-20 12:58:48,So true 😂
2023-03-20 12:59:47,has anybody managed to run invokeAI on colab? AFAIK they have docker to run locally on your desktop GPU
2023-03-20 12:59:48,"plus they don't have any changelog, releases. i check updates by looking for closed issues with the enhancement label on github"
2023-03-20 13:00:03,😂
2023-03-20 13:00:10,I just debug after things break :P
2023-03-20 13:00:19,"Automatic1111 will be the crazy hackers option that 5 years from now we will look back and say ""Back in my day we had this thing called Automatic1111 and it was beautiful. All you kids have it easy these days"""
2023-03-20 13:01:24,i didn't watch it either. recap: https://youtu.be/onjfu3Uh2vI
2023-03-20 13:02:07,winamp of CreativeAI 😂
2023-03-20 13:03:39,Haha true
2023-03-20 13:03:39,btw anyone used runwayML Gen1? i got access few days back. crazy impressive.
2023-03-20 13:04:20,Does invoke has the extensions that auto has?
2023-03-20 13:06:37,invoke is pretty limited. i haven't even installed it right now. but love the focus on UX. 
2023-03-20 13:22:52,"Has anyone tried Comfy UI, the node based/DAG interface for image generation?"
2023-03-20 13:32:38,V interesting!
2023-03-20 15:42:21,OpenAI wrote a paper on the potential impact of Large Language Models on the Labor Market
2023-03-20 15:44:02,thread https://twitter.com/rubinovitz/status/1637651591191842816?t=g4U4qTnkF-R02mImutwo8w&s=19
2023-03-20 16:16:35,With the amount of funds that openAI has are these PR stunts?
2023-03-20 16:17:35,No
2023-03-20 16:21:30,https://twitter.com/arankomatsuzaki/status/1637612922934382593
2023-03-20 16:24:01,"Request: When sharing links in future, please add a line about why should we click through or what is the topic about!"
2023-03-20 16:32:16,didn't know about this. looks interesting but feels like just slapping a nodeUI without attention to workflows. InvokeAI is also working on a node architecture along with their canvas UI.
2023-03-20 17:21:32,"Hello,"
2023-03-20 17:36:54,"Hi everyone, please welcome Kishore [PHONE REMOVED] to the group! He's building in the Generative AI space to generate statics for advertisers."
2023-03-20 17:40:16,What is a static? Image? Text?
2023-03-20 17:44:20,Hey Kishore!
2023-03-20 17:44:34,Excited to see what you have so far.
2023-03-20 17:51:49,Hi Kishore! Welcome to the group. Curious about the images you posted. Are they examples of what a static image is or output from your product's pipeline?
2023-03-20 17:53:38,Hi [PHONE REMOVED] . This is the output from my product pipeline.
2023-03-20 17:54:36,Pretty cool! So stable diffusion with some fine tuning magic I would guess?
2023-03-20 17:55:03,"hey, nice to see you here [PHONE REMOVED], amazing progress from last time we caught up 👍"
2023-03-20 18:00:27,You can do this without finetuning. There are many methods out there which you can implement to get similar results. But it does require a lot of trial and error and breaking apart the typical model. You can change the encoders. and other things in the HF pipeline for it to work.
2023-03-20 18:07:28,"It was based of some prompt, or img2img?"
2023-03-20 18:56:32,"Gen2 by RunwayML. paper, video "
2023-03-20 20:26:44,Can the world slow down a bit😂
2023-03-20 20:32:29,My current favourite conspiracy theory: Someone is spiking SF's water supply with Adderall
2023-03-20 21:04:44,"Not true, tech bros only drink sparkling water"
2023-03-20 23:18:30,https://vercel.com/templates/ai
2023-03-20 23:26:14,some cool Replit templates - 
2023-03-20 23:26:42,check out all templates here - https://replit.com/templates?q=AI
2023-03-21 01:06:08,Great results!
2023-03-21 06:09:50,"I'm curious, why not inpaint the main product from a separate LoRA finetuned on the product?"
2023-03-21 07:06:26,"For folks working on multiple images with minor variations, here is a _tutorial_ (yes! we're in the tutorial era of Stable Diffusion) using ComfyUI for generating similar images but with models of different ethnicities and different anime styles of same character"
2023-03-21 09:05:32,Hi [PHONE REMOVED] the main product here doesn’t vary. The main product isn’t the candle. It is the matchstick box with the person holding it.
2023-03-21 09:08:41,This image should be a better representation [PHONE REMOVED]
2023-03-21 09:13:27,Is that how tools like flair / booth.ai work?
2023-03-21 10:01:59,How do they retain the text? Lora screws it up usually right
2023-03-21 10:29:59,Didn't try it. Will give it a shot
2023-03-21 10:42:14,I think there's some smart img2img + masking going on apart from dreamboothing
2023-03-21 11:05:12,https://bit.ly/hf-nvidia-meetup
2023-03-21 11:08:01,"Flair isn't using dreambooth. They are using their own custom trained models, which to my understanding was some sort of mask based, with outpainting. The issues with dreambooth are not only text but also product fidelity. You cannot get the original product fidelity preserved with dreambooth. Also dreambooth required people to custom train models which was very inefficient. better methods have popped up after that. ControlNet, Adapters, Composer(pending release).  finetuning models to my understanding is not needed as of now. You can control, style, image composition, colour scheme without finetuning a model for usecases similar to flair."
2023-03-21 11:32:38,[PHONE REMOVED] I missed this. Primarily speaking training a model on an object and trying to recreate it during the generation process fails when the product fidelity cannot be compromised. The only method which exists as of today is to start the init image of the pipelines and then create the rest of the image. Even when you do that you can see that the product will get changed because all the SD algorithms work in latent space and not in pixels space. This compression and reconstruction of the image makes it impossible to get the original product image which is present in init image. however the solution is very straightforward . All you need to do is copy paste the pixels on the final image where the product exists. No need for LORA or anything of that sort. 
2023-03-21 11:32:51,Is anywhere working on apps like these : https://news.ycombinator.com/item?id=35236275
2023-03-21 11:35:07,Worked on document search.
2023-03-21 11:39:43,"Thanks for explaining! I was thinking about this problem statement the other day. What if we take a pic of the product photo in the exact orientation we want, remove the background and inpaint a new one around the product? Haven't tried out Booth ai myself though"
2023-03-21 11:40:09,They are using LLM + embedding approach. Guess they use LangChain as well under the hood.
2023-03-21 11:44:53,Yes this is exactly what I was talking about
2023-03-21 11:46:46,And that's why you will have these differences. This will work for e-commerce folks at all. Especially for high value items like furniture
2023-03-21 11:47:37,it will or won't? My understanding is that it won't work.
2023-03-21 11:48:11,"It definitely WON'T work! Sorry, did a typo in the worst possible place 😅"
2023-03-21 11:52:49,But here's a method that I am reasonably confident WILL work - Users can use a Nerf capture app like Luma to generate a 3D model from any novel viewpoint. It's as easy as walking around a product while taking a video and takes like 30s. Perhaps extract a mesh from the capture because that's easier to render in a browser than Nerf. Then in your product let the user rotate and orient the accurately captured product however they want. Take a snapshot of it without background. Then mask and inpaint like you did.
2023-03-21 11:56:11,This will remove all limitations. Highly accurate and infinite product photo generation from any angle in every aspect ratio for all your visualization needs.
2023-03-21 11:56:24,[PHONE REMOVED] isnt simple bg subtraction and some bg improvement good enough for ecommerce? :thi
2023-03-21 11:56:50,[PHONE REMOVED] s images also seemed mostly really smart bg replacement only.
2023-03-21 11:56:58,"[PHONE REMOVED] you can read up on this as well. https://www.deepset.ai/blog/build-a-search-engine-with-gpt-3 This is by deepset and they have a framework called Haystack. I was looking into it in June of last year, and it's pretty good. Suggest you check it out as well."
2023-03-21 11:57:03,There is a slight halo that is visible if you stare at it long enough 😅
2023-03-21 11:57:20,"Yes, because that is what it is. It is BG replacement."
2023-03-21 11:57:47,I was using similar method too for characters in a scene but this halo hurt the continuity. I am moving to using controlnet for this.
2023-03-21 11:57:56,A lot frankly. But that was mainly cause the original lighting of the image had it and I didn't wan't to spend time to remove it.
2023-03-21 11:58:15,I am using controlnet
2023-03-21 11:58:21,The images are from using controlnet
2023-03-21 11:58:24,Yea. Lighting causes it. Magic brushing with smudge over it removes it usually.
2023-03-21 11:58:33,Ah really. 🤔
2023-03-21 11:58:54,Maybe mine have a halo too. lemme check 😅
2023-03-21 11:59:21,Yes that's the ideal case if you already have the product photo in the exact orientation you want. Real world situation is that product photography is a whole other expensive initiative usually done by a different team. Marketing which creates the final images comes in much later and they have to make do with what they already have. Like there's a whole workflow for this thing.
2023-03-21 11:59:47,^Yea. I was asked to once build a 3D rotating platform to take ecommerce photos :P
2023-03-21 11:59:59,"For constant lighting, bg etc."
2023-03-21 12:00:24,So if you have a 3D capture that the marketing team can put into ANY orientation to generate images that's a big advantage.
2023-03-21 12:00:50,"3D is hard for a lot of use-cases like clothes, grocery no?"
2023-03-21 12:01:15,Your eyes will fall out if I show you Nerf captures of clothes and grocery
2023-03-21 12:02:26,"Hahaha. I have not done nerf but in my freelancing days, number of folks who reached out to me for 3d capture of clothes expecting realistic results was 🙏"
2023-03-21 12:03:01,"And then folks also wanted these clothes to go over humans and look ""natural"""
2023-03-21 12:03:49,"I might even have a long mail explaining ""Cloth Simulation is not a solve problem"". Definitely not in freelancing monies :P"
2023-03-21 12:05:27,😛
2023-03-21 12:05:43,Danny postama is doing to decently well now
2023-03-21 12:06:25,Catching up with these messages
2023-03-21 12:09:31,I'll add my colleague Bharath here who can go even deeper into the nuances of product capture and visualization for e-commerce. [PHONE REMOVED] he can share a lot of great inputs about product imaging for e-commerce. He was interacting with a lot of e-commerce store owners and product photographers from enterprise to small Shopify merchants
2023-03-21 12:13:56,Hey folks!
2023-03-21 12:16:54,Also [PHONE REMOVED] The code for this is still pending. but you can look into this project as well. https://dolorousrtur.github.io/hood/
2023-03-21 12:18:23,the demos are 🙌
2023-03-21 12:27:35,Damn. This looks good. But lets see how replicable it is. I am a little skeptical. 😅
2023-03-21 12:28:14,Damn this is also my lab 😂
2023-03-21 17:36:06,Welcome [PHONE REMOVED]. Bharath is a colleague of mine from Avataar who has worked extensively on generating 3D models using Nerf for e-commerce.
2023-03-21 17:42:04,"Ah, I see."
2023-03-21 17:42:09,Hello everyone!
2023-03-21 18:53:12,https://a16z.com/2022/11/17/the-generative-ai-revolution-in-games/
2023-03-21 19:01:47,Hey Bharath! Really excited to see someone work in the nerf space.
2023-03-21 19:20:50,"Hi All, Anyone in here who is interested in https://www.adept.ai/ and similar space? This is a different space than generative AI but will be game changer in how we use computers."
2023-03-21 19:23:47,Yes! afaik this was always a research area in RL. https://proceedings.mlr.press/v70/shi17a.html. Curious to learn how they’re going about it.
2023-03-21 19:28:59,This space is very exciting! Even more so that this can actually be done via prompt engineering- https://github.com/microsoft/visual-chatgpt
2023-03-21 19:40:53,[PHONE REMOVED] and myself :)
2023-03-21 20:02:15,The model at adept is pretty good
2023-03-21 20:03:01,Someone replicated Adept
2023-03-21 20:03:17,"Using GPT4 API, same control as GPT4: "
2023-03-21 20:03:58,I don’t think adept uses VQA or image captioning  - looks like it works with the DOM
2023-03-21 20:04:44,"Might be wrong, but that’s the impression I got when I played with it back in august"
2023-03-21 20:06:14,"August 2022, might as well have been last century in LLM years 😅"
2023-03-21 20:06:57,Hahaha true
2023-03-21 20:07:00,Folks in US can sign up for Google's BARD (waitlist) here: 
2023-03-21 20:07:04,But VQA is still prett shit right
2023-03-21 20:07:17,I tried blip-2 from Salesforce and it was average
2023-03-21 20:07:18,^That's Google's attempt at making GPT3
2023-03-21 20:44:14,"Predictably, Adobe is going to drop something big in generative AI. It's a tough fight for horizontal gen AI startups. Adobe ships solid products"
2023-03-21 20:44:31,https://mobile.twitter.com/ESYudkowsky/status/1635577836525469697
2023-03-21 20:47:34,"idk, it's adobe -people will avoid lol"
2023-03-21 20:48:09,Only people believing that Alpaca is as good text-davinci-003 are the ones who've not tried both.
2023-03-21 20:48:16,Creative world runs on Adobe. Nobody avoids. At max they pirate
2023-03-21 20:51:34,"Niche and industry specific vertical AI products are fantastic markets for startups right now. Like textile design, which uses Adobe products, but only as a part of a deeper workflow in which a generative AI startup can capture the entire stack. From tilable texture generation to fabric pattern generation. "
2023-03-21 21:03:23,I agree also adobe is the OG computer vision company. They literally are deepest in computer vision tools. 
2023-03-21 21:05:52,"You couldnt be a creative without adobe tools before gen ai.  It is the Microsoft office for creativity. But then like office, I don’t think they’ll make their weights public. 😞"
2023-03-21 21:07:02,Yeah they're going to play it like Microsoft.
2023-03-21 21:08:28,"For a large corporate company, it's overcoming the inertia is the challenge"
2023-03-21 21:10:15,"products which focus on specific workflows like Descript, RunwayML will carve out some market share, i think."
2023-03-21 21:11:41,"otoh, crazy to see how Canva is not visible in the GenAI space. although they launch stuff only once a year, still idk if they have a focus on ML research or not."
2023-03-21 21:16:48,https://youtu.be/DiGB5uAYKAg
2023-03-21 21:17:09,Nvidia livestream is live Rn
2023-03-21 21:17:10,"The criteria for these horizontal products to succeed is that they have to enable a non expert to create output that hits ALL 3 criteria - fast, cheap and good quality. A designer using Photoshop or Premier Pro currently can hit only 2/3. Fast + cheap is rarely good, and so on. Canva worked because it let an accountant create a classy looking event poster in minutes. There are some ways to do this, true. Like radically new UX, template based creation and having the best model in production consistently. But it's very very hard."
2023-03-21 21:24:55,Okay holy shit firefly is impressive
2023-03-21 21:24:58,This is so good.
2023-03-21 21:25:15,Do you have access?
2023-03-21 21:25:32,No just checked the features out and wrote a thread on it
2023-03-21 21:25:54,But they basically are problem first.
2023-03-21 21:26:29,"Not for fun, or entertainment. How do you use AI Art models effectively to solve problems (vs entertainment)"
2023-03-21 21:29:24,"This is mostly catch up on mid journey and runway, right?"
2023-03-21 21:30:26,Nope
2023-03-21 21:30:38,It’s competing with designer and canva
2023-03-21 21:30:48,But completely overthrew them
2023-03-21 21:37:10,⚠️➡️🧵
2023-03-21 21:48:43,I had the same question 😅
2023-03-21 21:51:14,This is Yudkowsky's propoganda trying to make the business model of building foundational models less attractive
2023-03-21 21:51:41,"In the thread he explicitly said if this was pointing in the other direction, he wouldn't have tweeted it 😂"
2023-03-21 21:55:34,"The ImageCaptioning model it’s using, i.e., BLIP, is pretty bad imo."
2023-03-21 22:00:36,this worked very well for me https://huggingface.co/spaces/fffiloni/CLIP-Interrogator-2
2023-03-21 22:30:09,Or use VPN.
2023-03-21 22:31:41,"I know lol, I didn't take it seriously but saw the features. Blew my mind"
2023-03-21 22:32:07,Adobe have done a very good job
2023-03-21 22:32:24,Open to changing my opinions and not going to be rigid
2023-03-21 22:33:02,https://twitter.com/vinniemourax/status/1638218512760971277?s=20 have people seen this?
2023-03-21 22:33:17,https://www.youtube.com/watch?app=desktop&v=DiGB5uAYKAg&feature=youtu.be
2023-03-21 22:54:14,Is there an API version of this? [PHONE REMOVED]
2023-03-21 22:54:54,"I converted this into an API, I will send you the script if i find it."
2023-03-21 22:56:49,"I found this, but seems like a task to integrate: https://github.com/rmokady/CLIP_prefix_caption"
2023-03-21 23:01:12,i think replicate also has this
2023-03-21 23:10:29,People started interacting with BARD already 😅😅😅
2023-03-21 23:10:53,Twitter is fastest
2023-03-21 23:11:06,I tested lamda 3 months back only
2023-03-21 23:11:17,It's worst model
2023-03-21 23:13:55,this maybe useful https://gist.github.com/ovshake/69efb594f3b1e8d98b34687b16916145
2023-03-21 23:37:12,Link?
2023-03-22 00:30:42,this one probably https://replicate.com/pharmapsychotic/clip-interrogator
2023-03-22 08:46:34,"Also sorry, have been lurking, didn’t introduce myself. Vishal Tripathi, Venture Investor, worked on a fund of funds strategy for Google Ventures - Plexo Capital. Currently with Legacy Venture, investors in many of the funds people have mentioned above (Sequoia, A16z, Matrix, Accel, True, etc). Love the conversation and learning a lot about the space, also building tools on the side/over weekends. Someone mentioned Yohei (from untapped VC) above, he’s a close friend and I’ve collaborated with him on some of those GPT tools and love learning about these new use cases."
2023-03-22 08:50:57,"Hi, "
2023-03-22 08:51:43,I have a proof of concept script that I would like to take to customers 😃.
2023-03-22 09:20:05,Fun blog post for folks who are in marketing or content or do a lot of writing work in other ways: 
2023-03-22 09:20:58,The last line of this link is: This will make certain people really mad
2023-03-22 10:02:19,Wowww!
2023-03-22 10:13:31,"Damn, this is so good. Me want!"
2023-03-22 10:14:44,"I hope its as good as it appears, would be sooo coool"
2023-03-22 10:14:45,Infinite customization is actually a pain. Firefly imo is a great example of limiting functionality and making it more useful than the competitors.
2023-03-22 10:26:21,Pre Firefly Adobe was doing all its ML inference on user's local system? Can anyone confirm?
2023-03-22 10:28:05,"Adobe express is not local, you could do stuff there online. "
2023-03-22 10:28:59,"Hey Vishal, nice to meet you!"
2023-03-22 10:30:56,DMing :)
2023-03-22 10:31:23,Just came across this paper today from another route as well. Planning to try it on HF and look through it
2023-03-22 11:35:59,Can add him here
2023-03-22 11:36:06,He published in CVPR 2023
2023-03-22 11:36:54,https://www.cs.umd.edu/~shishira/Nirvana/nirvana.html
2023-03-22 11:38:10,"Works with video compression, he’s a good friend of mine"
2023-03-22 14:53:16,https://github.com/microsoft/MM-REACT
2023-03-22 14:53:27,Demo looks good and better than BLIP-2
2023-03-22 15:17:47,"tf, they literally cloned the langchain repo in it"
2023-03-22 15:18:14,https://huggingface.co/spaces/microsoft-cognitive-service/mm-react
2023-03-22 15:18:47,i uploaded my picture and asked it to describe it to describe me in close detail. It did a decent job.
2023-03-22 15:44:01,send results?
2023-03-22 17:31:34,folks noob question but has openAI exposed multimodal inputs to GPT4? I see that I can only feed chatGPT plus text.
2023-03-22 17:45:00,not yet. very few have access to visual input right now.
2023-03-22 17:45:29,ah understood thanks!
2023-03-22 18:31:46,anyone working in any projects related to healthcare?
2023-03-22 18:49:17,Yes
2023-03-22 19:07:00,Do tell.
2023-03-23 13:20:22,Patiently waiting for them to let everyone use it 😂
2023-03-23 13:25:46,Oh I realised I did not introduce myself. I'm Dukaan's head of AI. 
2023-03-23 13:26:03,If anyone's interested in seeing Jadoosnap you can use the link below
2023-03-23 13:26:09,JadooSnap.com
2023-03-23 13:27:48,"Have seen this, great work!"
2023-03-23 13:28:45,Going to take some time for public access - there are a few companies using it already
2023-03-23 13:29:44,Any way we can request access for Dukaan?
2023-03-23 13:35:52,https://twitter.com/T_Goody3/status/1638203321704955904?t=8aQye9lDksWh81DJjhZGlg&s=08
2023-03-23 13:50:16,Hoping to get a contract with the gates foundation to build a Whatsapp chatbot to guide rural nurses in India. 
2023-03-23 13:58:11,Rural india would need Hindi
2023-03-23 13:58:33,"Hindi is supported by both GPT4 and Whisper, so quite doable"
2023-03-23 13:58:52,Most popular Indian vernacular languages are in fact
2023-03-23 13:59:16,We’re also using bhashini - an indian government funded research project that has a fine tuned whisper model for hindi
2023-03-23 13:59:23,The hindi results of gpt are not as great as english
2023-03-23 13:59:40,Slightly confused then by Bill Gates writing about an Indian startup working on LLMs for Indian languages
2023-03-23 13:59:50,This is probably why
2023-03-23 14:00:29,"Yes, same findings. Plus the source documents are all in English too. Using google translate so that gpt only ever sees english"
2023-03-23 14:01:21,Hmm. Doesn't look like it with GPT4 — original ChatGPT was worse. Using Google Translate would invariably add error. Propose a test set on this — why discuss opinions when we can run experiments!
2023-03-23 14:01:45,Openai/evals ✨
2023-03-23 15:12:16,Anybodys got any idea how to achieve this?
2023-03-23 15:25:46,"Change the tint of image to RGB (may be converting to grey scale then colorify it), add noise and then denoise guided by prompt a photo of baby"
2023-03-23 15:26:28,Controlnet / depth2img
2023-03-23 15:31:04,This is too clear ultra sound
2023-03-23 15:31:52,might create false expectations for parents 😅
2023-03-23 15:31:56,"unet came out of medical imaging, so i think in future, rather than taking home ultra sound, you might take back a generated photo realistic image"
2023-03-23 15:32:29,Why stop there? Ultrasound → Baby Photo → Age by X years is a known dataset
2023-03-23 15:32:51,"That as well, bachche ki shakal to pregnancy scanning se mil hi nahi, hospital be bacha badal diya hai 😂"
2023-03-23 16:00:44,Link?
2023-03-23 16:18:57,"You jest, but I'll wait for the next medical provider data breach to get this dataset"
2023-03-23 18:47:15,https://gooey.ai/ai-photo-editor/?run_id=4ndpy7e0&uid=Nli0J2dP80WU3sdJ9RCw3DeNvIT2
2023-03-23 19:30:59,"Regarding the Adobe products that someone else mentioned, it’s out now"
2023-03-23 19:31:02,https://www.linkedin.com/posts/alexandru-costin-a4367_adobefirefly-ugcPost-7043965991910854656-pjbp?utm_source=share&utm_medium=member_ios
2023-03-24 00:08:08,What was the prompt :)
2023-03-24 00:13:17,What model?
2023-03-24 00:14:11,Omg the second prompt 😂😂 
2023-03-24 00:15:00,"But this prompt and neg prompt alone isn't enough. It won't give you the robot heads or the glowing eyes, colour tone or the exact kind of armour and rifle that you want. So you need to do a lot of composition iterations"
2023-03-24 00:18:12,"I've created my own now based on what kind of output I want. It's a checkpoint merge between deliberate v2, dreamlike_photoreal v2 and a few others"
2023-03-24 00:19:44,"The style reference for this second pic was not in the prompts, rather it was a Rembrandt painting, which is why he's wearing medieval looking plate armour along with what looks like leather and chainmail"
2023-03-24 08:52:56,https://openai.com/blog/chatgpt-plugins
2023-03-24 09:10:30,Curious to see if this goes the way of ios/android apps or Alexa skills.
2023-03-24 09:44:48,I would bet better success than  Alexa Skills anyday
2023-03-24 10:37:44,https://platform.openai.com/docs/plugins/introduction
2023-03-24 11:35:35,[PHONE REMOVED]
2023-03-24 13:00:57,[PHONE REMOVED] is working on his next company. He was CTO at BharatPe until recently.
2023-03-24 14:14:52,Thanks Pranjal!
2023-03-24 14:15:08,Hi everyone! Glad to be here! 🙂
2023-03-24 15:58:50,Very very unrelated: Has anyone here worked on Firestore?
2023-03-24 15:58:50,We’re stuck at one place and need some help
2023-03-24 16:00:08,Very off topic 😅
2023-03-24 18:33:23,"Hey everyone, got quite a bunch of people who showed interest in attending this. There are a lot of people in this group who are hacking projects on the side, DM me if any of you would want to talk (or show demos) about your projects tomorrow, would love to host 🙌🏻"
2023-03-24 19:31:40,"Can you share that message again, some of us joined the group after the message was sent 😬"
2023-03-24 19:33:50,Hey folks!
2023-03-24 19:33:52,here you go
2023-03-24 19:34:00,Thanks 🫡
2023-03-24 20:49:26,https://analyticsindiamag.com/the-hidden-cost-of-chatgpt-for-indian-languages/ Is this cost analysis accurate?
2023-03-24 20:51:56,Yes
2023-03-24 20:52:15,You can try it out here
2023-03-24 20:52:15,https://platform.openai.com/tokenizer
2023-03-24 21:01:59,Got it. Thanks
2023-03-24 21:37:27,does anyone know if opencv videocapture() can connect to an external iOs camera?
2023-03-24 21:46:24,"Not sure about iOs but in android you can capture using any wifi camera app, if there is same kind of app for ios then I think you can do this."
2023-03-24 21:59:57,Do you interact with GPT in English or directly in vernacular languages?
2023-03-24 22:18:33,Direct vernacular is supported
2023-03-24 23:49:57,Doesnt have very good performance though
2023-03-25 00:09:36,Can try few shot learning for training
2023-03-25 00:45:20,I ran out of context length before I could stuff enough context for it to have significant improvements 😂
2023-03-25 18:57:02,What was your workflow? Like what tools did u use?
2023-03-25 19:14:49,Completely using Stable Diffusion. Workflow was first using text2img with controlnet depth map of this image. I got the depth map from Clipdrop's API because it's really good. Thanks to Sudharshan's tweet for this tip! Fixed the red background using this. 
2023-03-25 19:15:30,Do you use automatic1111 for all this? Or just code
2023-03-25 19:16:15,Automatic1111. You would go mad doing this with code 😅
2023-03-25 19:19:00,Makes sense. Have you played around with langchain agents / chatgpt plugins? 
2023-03-25 19:28:45,I think certain things are easier and more fun with a UI - when you need more control and direction a UI would do
2023-03-25 19:29:03,Neat! The depth maps have more control
2023-03-25 19:29:22,"The only problem with this is that you need to run iteration loops in every step until you are satisfied with the output before moving to the next step. Doing 1, 2, 3 successively would not work."
2023-03-25 19:30:14,And this is nothing new for artists: retakes are common
2023-03-25 19:35:58,"Personally what fascinates me more about AI generating art than generating code is how a deterministic input (auto encoder, model weights, controlnet algorithms etc) can give infinite non deterministic output."
2023-03-25 19:37:11,"I believe the non deterministic output still stems from a classical random number generator :) if you keep the seed constant, its very much deterministic."
2023-03-25 19:38:06,Yep
2023-03-25 19:38:28,"Simple but quite useful, the entire concept of seeds"
2023-03-25 19:38:45,To someone who has control over enough constraints the entire universe becomes deterministic
2023-03-25 19:39:08,There are in theory infinite seeds
2023-03-25 19:40:01,"Oh man, this debate itself is infinite 😆"
2023-03-26 02:56:47,https://www.youtube.com/watch?v=L_Guz73e6fw
2023-03-26 02:58:10,No technical details (few hints here and there); but lots of philosophical nuggets about how Sam Altman and by extension OpenAi is thinking about development trajectory
2023-03-26 19:17:44,https://www.youtube.com/@aajtakai/videos
2023-03-26 19:26:44,"As we all work on AI and have been inundated with new AI advancements & specifically blitzscaling of OpenAI & Microsoft since last many days, here is a video on *The A.I. dilemma* talking about safety and what's at stake with respect to new exponential growth of LLMs."
2023-03-27 11:20:22,"Putting on my friendly salesperson hat, please share this with your friends (and lovers?) in Bengaluru"
2023-03-27 11:20:27,**Deep Hack Demo Day Invite**
2023-03-27 11:35:28,Wish I could attend but flying out that day
2023-03-27 12:24:22,"Jobot, a ChatGPT-powered bot is live at Jovian"
2023-03-27 13:08:02,Would u be streaming the Demos ? 
2023-03-27 14:30:58,"For those unfamiliar with who I am: Anthropologist and senior fellow with the Max Planck Institute for Social Anthropology (Halle, Germany). Am originally from Amsterdam but often in India (in Bangalore as we speak). I’m particularly interested in the way those working with AI - data scientists, ML professionals, artists - relate to the inherent unpredictability of their models."
2023-03-27 14:38:06,Welcome to the group 😄✨
2023-03-27 14:42:42,Better introduce yourself real fast!
2023-03-27 14:48:03,"Sure. I’m Hasan, a new media artist and an educator. My practice is focused on making the cutting edge accessible. I use AI, Robotics and code to build magical experiences. I have been mentoring international artists over the last 5 years about how to use technology to augment their practice. [PHONE REMOVED] and I also run https://responsibletoday.in focused on addressing the societal challenges of technology in the Indian context. Glad to be a part of this community, you can find my website on my WhatsApp bio and please leave a message if you want to have a conversation. ✨"
2023-03-27 14:54:03,is it done via stop motion?
2023-03-27 14:55:25,Hey Hasan! I remember seeing your work at the art tech community fair. Good stuff!
2023-03-27 14:56:08,No vfx have been used for this video. It’s the raw recording. OCR -> content search -> style transfer  -> projection mapping
2023-03-27 14:57:02,I’m trying out some generative video models for the future iterations but those are very slow at the moment.
2023-03-27 14:59:22,https://github.com/justanotherlad/blindvisaidgpt
2023-03-27 14:59:56,"nice to meet everyone here btw; i’m swastik, search engineer at wolfram|alpha :)"
2023-03-27 15:23:27,"Isn't OpenAI already is doing this with BeMyEyes, am I missing something? Guessing you want a open source version?"
2023-03-27 15:24:42,correct
2023-03-27 15:25:59,it’s always a plus to be able to add a bunch of other visual foundation models :)
2023-03-27 15:27:21,What about blip-2? Seems that's been doing well on captioning tasks?
2023-03-27 15:29:03,"Also, a kick ass demo of this built over 12h is amazing bragging rights 😅"
2023-03-27 15:30:26,Swastik has a great demo of WIP stuff here btw:
2023-03-27 15:32:24,[PHONE REMOVED] i was trying a bunch of stuff aside work :) 
2023-03-27 15:33:34,esp integrating ControlNet to alter per specific requirements for a particular color blind person?
2023-03-27 15:43:43,"I'll look into this. Traditionally, have avoided doing this because participants feel like their ideas or work might come under too much light too soon. Will ask the folks at the hackathon itself and decide accordingly."
2023-03-27 16:05:42,"Were you able to get the WiFi camera connected? Using the wifi camera steaming apps as someone had suggested. We had done something similar but for visually users to navigate in indoor environments. This was device that detects collision probability and provides feedback to user using haptic feedback. This was a long time ago, so running complex enough model on cheap hardware (think 2014, < Rs 10k phones) was quite hard. All the very best."
2023-03-27 16:06:00,*streaming
2023-03-27 16:08:52,sounds interesting
2023-03-27 16:08:59,do you have a repo for it?
2023-03-27 16:11:55,This wasn't open source per se. We had done this for TechMahindra. Please don't share outside. https://m.economictimes.com/tech/ites/tech-mahindra-tests-goggles-for-blind-plans-variant-for-cars/articleshow/45302948.cms
2023-03-27 16:17:30,"But one could do this today, if someone is looking for ideas. Phones have decent compute to do interesting stuff. There is a challenge in distribution because you might need different  optimizations for different manufacturers. But for a quick demo this could be really possible."
2023-03-27 16:18:30,"If anyone is interested in making ControlNet work on iPhone, this is a good start: https://github.com/apple/ml-stable-diffusion/issues/131"
2023-03-27 16:21:56,"Hi, Does anyone know of any text to video tool through which one can do camera movements over still images?"
2023-03-27 16:22:18,Zoom/pan/tilt that kind of thing
2023-03-27 16:24:24,We have a controlnet webapp and API too :)
2023-03-27 16:26:30,Nice do you offer all modes? I’m building an app and was looking to deploy on runpod or modal
2023-03-27 16:28:11,The underlying container is opensource too so you should be able to deploy on modal
2023-03-27 16:29:11,"No sir, I bring my own gpus 😂"
2023-03-27 16:30:13,Ive tried at least 5 different serverless gpus. None of them have a way to get excellent cold start times where you have over 30 models and sparse network activity.
2023-03-27 16:31:09,"See, I need clients like you who have over 30 serverless models 😅"
2023-03-27 16:31:29,"If you define a simplistic DSL (something like MOVE LEFT 3) then you can directly call the transform or scale. Or you could also provide some examples, in your pre-promt to GPT to create the transformation functions."
2023-03-27 16:31:31,That is quite good price to perf ratio for most B2B use cases
2023-03-27 16:31:58,I think it'd be helpful to have a more simplified answer. [PHONE REMOVED] isn't a ML Engineer
2023-03-27 16:32:19,I’ve worked as an ml engineer at amazon.
2023-03-27 16:32:20,Thanks i got that
2023-03-27 16:32:22,:)
2023-03-27 16:32:49,For what model sizes you are getting these latencies?
2023-03-27 16:33:42,"Aeee, you told me you wrote for TVF Pitchers S2! "
2023-03-27 16:34:14,Wow what!
2023-03-27 16:34:26,Haha in my previous avatar I was an ML Engineer. Can't help combine the two skills now that AI is going where it is going.
2023-03-27 16:34:56,I use accelerate to offload to cpu which lets me deploy all of them on a single a100 without running out of gpu. Latency is less than 5 seconds for the diffusion models.
2023-03-27 16:35:02,My vision is to be able to  make full scale movies with AI
2023-03-27 16:35:32,"Model sizes isn't perhaps a good proxy for the kind of work I am doing: think TorToise TTS, GPT-6J as a proxy"
2023-03-27 16:36:20,"People accuse OpenAI of putting software engineers out of job, Shubham here is putting King Khan and Deepika Padukone out of work. No one is safe any more"
2023-03-27 16:36:39,"On second thought, very curious to know how GPT will handle degeneracies."
2023-03-27 16:36:51,Or trying to save himself from going out of work
2023-03-27 16:37:24,"Make AI to write and create episodes for the final season of GOT, my goal 🥲"
2023-03-27 16:37:33,Makes sense. Because i have tried with around 5GB model size and it was more than 40 secs
2023-03-27 16:38:11,1. Their own cold start times have improves over Feb and more in March
2023-03-27 16:38:47,I started up with this dream. 😅
2023-03-27 16:39:29,Yes.. they are getting better. In feb it was around 60 secs
2023-03-27 17:07:22,"Just checked this, basic part works. It is even able to create even Homography matrix if I say move left by 20% etc (Homography Matrix tells how to transform an image by translation, scaling eyc). I thought it will  gets tripped by degeneracy. But it gets tripped up even before with non commutativity of matrix multiplication. So please use that idea with caution."
2023-03-27 17:22:21,unrelated but this seems really interesting; i’m a regular user of sam harris’s Waking Up
2023-03-27 17:30:15,"I’ve tried giving it those direction questions (start north move 30degree south … where are you now), from a mental ability textbook and the performance is shit."
2023-03-27 17:32:25,New AGI test: Can GPT4 do route planning for a Logo (anyone remember that?) pointer in specific shapes and mazes?
2023-03-27 17:50:54,"That's gonna be a yes, I think."
2023-03-27 17:51:47,I am a little more curious about its ability to reason about problems in its distribution but not in its data: eg. leetcode hards that it might not have been trained on.
2023-03-27 17:54:32,Asked GPT-4 (via ChatGPT Plus) the following puzzle for and it fumbled and failed.
2023-03-27 17:55:29,As per the paper they can't do well. See Aravind's post about contamination: https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks
2023-03-27 17:55:36,Is it 20kg of supplies all together or each person? Can the supplies be broken?
2023-03-27 17:55:38,"Thanks, yall."
2023-03-27 17:56:01,👆🏽
2023-03-27 17:56:56,"The 20Kg of supplies are together. No, the supplies can't be broken down. Have to be carried as a whole 20Kg."
2023-03-27 17:57:57,"GPT-4, on NEW Leetcode problems past its training date, in 5 attempts, gets"
2023-03-27 18:17:10,"Yeah, not 100% sure of this. There are just so many questions out there, that these newly created questions could just rewording without change in core idea. See Aravind's blog. In my experience with ChatGPT, when I give problems that are easy to medium and then I change the problem ever so slightly in its core idea and it will get it wrong. Or there are tell tale signs it has mugged up. Like I will give a problem that is a coin change in disguise with coins that are multiples of each other.  Thus allows greedy solution, it will provide a DP Solution (I am not even testing for corner cases etc or even if it will run). Just whether the core structure is right, which it did not. So in my experience small perturbations to core idea causes drastic change in correctness."
2023-03-27 18:18:17,Hard questions usually are what differentiates for top ranks (and much fewer) and could just be what people put more effort in creating.
2023-03-27 18:58:05,I saw someone on Twitter saying gpt-4 does much worse than leetcode hard on newer Euler problems.
2023-03-27 20:02:20,https://about.sourcegraph.com/blog/cheating-is-all-you-need
2023-03-27 20:35:43,The author for some reason seems to be discounting Github's excellent search product which has similar or maybe larger advantage than Sourcegraph
2023-03-27 20:36:24,The author is quite famous Steve Yegge.
2023-03-27 20:36:45,"yeah I noticed, I liked the rant style"
2023-03-27 20:37:08,Why do you think my Substack is called niranting.substack.com ? xD
2023-03-27 20:40:35,His infamous Google rant from 2011 https://gist.github.com/chitchcock/1281611
2023-03-27 21:09:58,"Yeah, obviously he'll be baised for his company. But larger point he makes about how people are underestimating potential of LLM powered coding assistants by seeing a few edge case failures of code generation on chatgpt is quite valid. Finetuning LLMs for user's existing codebases + building search capabilities on codebases will be gamechanger"
2023-03-27 21:13:20,I believe https://www.buildt.ai does this
2023-03-27 21:15:23,Github Copilot X(available for preview only) is doing it (https://github.com/features/preview/copilot-x)
2023-03-27 21:23:58,"Thanks for sharing. I absolutely think this is monumental and going to change how we work. And working on something using LLMs. Funny thing is the same time, question I asked it is the exact kind of question I would usually ask a fresher to know if they are faking it (as in just knowing the answers mugging up a lot of leetcode answers) or they conceptually know it. I do think lot of the code today we write, will easily to automated too. That begs the question what won't be. All the glue code, all the templates, all the code that is quickly needed to get a project up and running will all be automated. What will possibly remain? So what skills will become more important?"
2023-03-27 23:43:35,Remote submissions are eligible for prize. Correct ?
2023-03-27 23:43:46,Yes
2023-03-28 00:12:24,"Hello everyone, this is Dr. Parth Sharma...I am a doctor by profession...i have keen interest in python and likes of AI, deep learning for some years now...i look forward to learning/implementing some good stuff here in medical AI especially"
2023-03-28 02:56:05,"Hi all, "
2023-03-28 02:57:16,Andrej karpathy on youtube ✨
2023-03-28 03:56:18,Which videos?
2023-03-28 08:11:03,We are vision-mission buddies
2023-03-28 12:10:18,"New Prompt trick: Every time ChatGPT gives an answer I am not satisfied with in terms of detail, I just go full gym bro on it:"
2023-03-28 12:11:35,"Realised that you can use GPT-3.5 as data resource even without internet connection. I asked for a list of shopify websites in USA which sell Candles. I use those links and asked chatGPT for a crawler code to get email Ids. Till now I got 130 valid links. Incase anyone doesn't have the money to splurge on databases and want some free solution, try this."
2023-03-28 12:14:07,were you inspired by: https://twitter.com/AKASpencerScott/status/1638996898941124609?s=20 ?
2023-03-28 12:15:06,"It's pretty good at competitor analysis too. If you give precise small collection and ask it to give you similar companies, it will get you really good ones. It tends to give general answers, so need to do prompt engg to really get the interesting things."
2023-03-28 12:16:37,"Oh wow. No. I was trying to get shopify lists and thought it will give me a way to get it. However, it started giving me the actual links."
2023-03-28 12:24:34,"Hmm, interesting - didn't quite for me"
2023-03-28 13:03:24,"Pratyush bhai, Is that the best you can do?"
2023-03-28 13:10:58,Thor got depressed after that win. Let's not do that to GPT4
2023-03-28 21:12:01,"Hi,"
2023-03-28 21:27:13,Is this a real person?
2023-03-28 21:27:21,No
2023-03-28 21:32:19,Which checkpoint are you using ?
2023-03-28 21:32:35,Does the image have Exif data of generation ?
2023-03-28 21:33:03,Did you try dreamboothing her?
2023-03-28 21:35:08,"I'm a simple man. I see Deepika Padukone, I ❤️ it"
2023-03-28 21:35:09,"No, I was too tired to dreambooth today. Spent so much time on the jacket and trees that I was pretty exhausted 😛"
2023-03-28 21:35:21,"I know, right?"
2023-03-28 21:35:53,Dude this became a point of debate. 
2023-03-28 21:40:02,Not aiming for photorealistic fwiw
2023-03-28 21:41:56,"On the one flower in focus, the petals look weird."
2023-03-28 21:44:22,"Depressed software engineer from Bangalore spends all night generating AI girl, falls in love. Laptop crashes at midnight, man loses checkpoint, seed, prompt, everything. Cannot recreate girl. Has only 1 image. Shares image online with heartbroken message. Kind netizens of Bangalore organize a search for the real girl. Girl is found! She is a photographer. They get in touch, romance kindles, they get married, AI generates their wedding invitation. Cinderella 2023."
2023-03-28 21:45:43,"The plot of Her, Yash Raj Films edition"
2023-03-28 21:47:28,Sell the movie rights to this
2023-03-28 21:47:56,Make this movie using AI > Sell the movie rights to this
2023-03-28 21:47:59,Would watch this movie. Extra props if it’s made using AI
2023-03-28 21:49:14,“There is no good and evil. There is only Balenciaga”.
2023-03-28 21:49:22,https://youtu.be/kCc8FmEb1nY
2023-03-28 21:57:36,"I had a Deepika in Arcane animation art style. But literally lost the seed, prompt and everything 😭"
2023-03-28 21:58:05,Arre arre yeh movie tou real hain
2023-03-28 22:47:11,"In Greek mythology, there's a similar story of a sculptor who falls in love with a statue that he carved:"
2023-03-28 22:52:10,This is my bumble bio from today
2023-03-28 23:32:19,Length of the neck gave away a little🤪
2023-03-29 01:50:10,https://twitter.com/io_Y_oi/status/1634835399918108673?t=malrs07ZHMBbup1Pr7gO-g&s=19
2023-03-29 02:03:01,Google Partners with AI Startup Replit to Take on Microsoft’s GitHub 
2023-03-29 02:20:55,i wonder if ghostwriter is gonna use Bard now
2023-03-29 06:28:02,"Anshul sir [PHONE REMOVED] runs India Replit — and they're sponsoring the hackathon (https://has.gy/gpt4hack), ask him how you can try GCP features on Replit!"
2023-03-29 06:54:59,"For engineers wanting to get a first hand feel of how to write a GPT from scratch, this is great — but I wonder how popular will be that in the months, years to come?"
2023-03-29 06:57:17,Theory enthusiats who are still in college might do it as it gives them the sense of having deeper knowledge.
2023-03-29 07:17:24,"Elon Musk, Emad Mostaque, Yoshua Bengio, Steve Wozniak and bunch of other famous people have asked AI Labs to not train systems more powerful than GPT4 for 6 months and instead use this time to ""jointly develop safety protocols"" "
2023-03-29 07:18:53,Playing around with alien technology needs a built-in stop-loss 👍🏽
2023-03-29 07:22:15,"I wonder if you'd have felt the same way about printing press, Internet or smart phones/social media."
2023-03-29 07:23:46,"Zooming out, the Church hated printing press, horse-specialists hated Ford cars, Govts hate social media and engineers outside Microsoft/OpenAI hate GPT4 — there seems to be a pattern here :)"
2023-03-29 07:24:08,"The only sane way to align incentives is to buy $MSFT, Nvidia and ASML xD"
2023-03-29 07:24:52,"Yea, but we 'understood' how these technologies worked, right?"
2023-03-29 07:25:50,"Like printing a book by itself does not have any meaningful emergent properties, unlike AI."
2023-03-29 07:26:16,"Ofc, printing a newspaper has emergent properties? How do you think nation states came into existence?"
2023-03-29 07:26:26,"There are of course societal effects, which can be called emergent"
2023-03-29 07:27:11,"Also, we've gone too off-topic — let's move to DMs 😆"
2023-03-29 07:47:42,"Does anyone know Richa Gandhi, the journalist who wrote this? Would be fun to have her here perhaps?"
2023-03-29 07:50:37,"BIC is having an event on ""ChatGPT and it's Ilk"" by Anil Ananthaswamy, a science writer and editor."
2023-03-29 08:32:42,"For folks who are wondering how this'll play out wrt Search and ads, Bing Chat has ads: https://twitter.com/debarghya_das/status/1640892791923572737"
2023-03-29 08:59:46,Will be waiting to see stats on CTRs and their subsequent effect on CPCs. 
2023-03-29 09:05:18,I think those are valuable discussions though. Can we utilise the WhatsApp community feature to have a philosophy room? So people can continue those discussions.
2023-03-29 09:08:10,Yeah man if there's anything related to gen AI it's cool with me
2023-03-29 09:08:19,I don't care if it's just 2 people talking
2023-03-29 09:08:38,Context can be figured about scrolling in the north direction 😂
2023-03-29 09:23:01,That would be great!
2023-03-29 09:27:43,"The group is small and would want to keep our _attention_ here at the moment — as a reminder, most people here don't do this full time :)"
2023-03-29 09:27:44,Will consider doing a philosophy fork if we've more topics like David Chalmers coming up organically
2023-03-29 09:31:04,"While we are on the topic - another point to support the case for forks at some point would be to have some use-case specific groups - such as photo studio, legal, education"
2023-03-29 09:31:20,That’s fair. we can make a small philosophy group with the few people interested in that and do this full time. Is it okay with you if I share the link here?
2023-03-29 09:34:47,"Yeah, go ahead! Added a group to the community which makes it easier for folks here to find that hopefully 🫰🏻"
2023-03-29 10:02:27,so missed the important classifier _Funding_ feel free to drop a 🔥 emo to identify :)
2023-03-29 10:36:55,Reposting because lot of new friends!
2023-03-29 10:38:24,"Streaming, pls!"
2023-03-29 10:41:20,And for those who want to _participate_ in the hackathon in BLR: https://has.gy/gpt4hack
2023-03-29 12:40:47,One of my recent best reads: https://direct.mit.edu/daed/article/151/2/183/110604/Do-Large-Language-Models-Understand-Us
2023-03-29 14:03:26,Hey hey I want to be in these DMs 😅
2023-03-29 14:44:13,Same
2023-03-29 16:30:39,https://twitter.com/tobi/status/1641010421493637122
2023-03-29 19:24:01,what is the source for 100 Trillion? have we already reached triple digit in trillions 😮
2023-03-29 19:44:04,"Don’t think 100 trillion is right. Sam Altman had clarified in the podcast with Lex that 100 trillion is just a meme going around. ~1-10 trillion is what seems probable (though thats also a speculation, no authoritative source)"
2023-03-29 22:08:18,https://twitter.com/marckohlbrugge/status/1640961076039925760
2023-03-29 22:08:42,Alt - builders can apply too for any projects this weekends fyi
2023-03-29 22:11:14,"You kinda need an active project with a website, ""CTO"" and stuff to apply"
2023-03-29 22:11:34,Why does this look like a phishing attack?
2023-03-29 22:12:48,We're talking to Azure and going via them for Azure OpenAI credits — OpenAI ghosted already. Will see how this pans out!
2023-03-29 22:12:49,Grant Eligibility:
2023-03-29 22:16:10,Ah got it
2023-03-29 22:17:35,"I mean its a random google form with no actual announcement from openai, feels very phishy"
2023-03-29 22:21:11,And a Google form instead of their usual Microsoft thing which they use in Wait list
2023-03-29 22:33:39,https://futureoflife.org/open-letter/pause-giant-ai-experiments/
2023-03-29 22:37:08,I found this which looks more plausible: https://openai.com/microsoft-for-startups
2023-03-29 22:37:17,"[PHONE REMOVED] scroll up maadi, this is the first thing we discussed today xD"
2023-03-29 22:47:20,any good hacks to reduce hallucination of gpt?
2023-03-29 22:49:56,Add to System Prompt: You are a Harvard Professor of <whatever domain>. 
2023-03-29 22:50:41,"Treat GPT4 as a naughty 5-7 year old who talks a lot, wants to be helpful and if you say the same thing in 4 different ways it'll eventually listen to you"
2023-03-29 22:53:45,The talk at BIC was excellent today.
2023-03-29 22:53:51,And it was a packed house.
2023-03-29 22:54:20,I use a score in interactive sessions. So penalize when it starts to hallucinate. That seems to help. But not in first time prompting. Similarly score for speed seems to help  🤫
2023-03-29 22:54:21,More like a 9 year old since it passed the theory of mind test
2023-03-29 22:55:18,btw
2023-03-29 22:55:34,"We'll not go there, because it's already better at Leetcode, Chess, flirting and bunch of other things than me. The only things I'm better at are puns and Shayari at this point."
2023-03-29 22:56:24,I bet it could very soon be better at those too 😅
2023-03-29 22:56:33,"It making up stuff and saying things that not true, creating references, articles etc"
2023-03-29 22:56:56,Ask for references or sources ?
2023-03-29 22:57:11,Its like doing a peer review of a paper when it is to be published
2023-03-29 22:57:17,"Once the model hallucinates, this doesn't help — it'll make up a source"
2023-03-29 22:57:50,"But if you've an extra API call, you can do a self-consistency check: ""Are you sure your answer was correct using the information below:"""
2023-03-29 22:58:03,But we can verify if the source is legit or not ? Or does it cite something that might be obscure ?
2023-03-29 22:58:33,And yeah very good one at that. I had it create references with actual researcher in that area of maths. Just that they didn't write the paper (at least not yet or don't know if it had access to data I don't have access to ;)
2023-03-29 22:59:20,Are you using penalty system like the Dan jailbreak? 
2023-03-29 22:59:26,"Depends on the task — for open domain QA, it'll make up very believable stuff and you'll be tripping acid for a while. For closed domain QA, verification is somewhat easier but harder to use this signal."
2023-03-29 22:59:51,Ghosts of Future Past: Math Papers edition
2023-03-29 23:00:26,```refine``` from langchain works well for gradual operations around this
2023-03-29 23:02:25,Not not across sessions. No did not use DAN jailbreak.
2023-03-29 23:05:03,"What surprised me was that the speed one worked. Can others try and let me know if it works for you too. Nothing Fancy: start with saying you get +1 for producing the output fast and -1 for slow responses. But ensure that you doing when things are bit slow. Last 3-4 days, it adds a disclaimer that it will be slow irrespective but in my experience it was decently fast compared to otherwise."
2023-03-29 23:06:28,"Because if this works, seems like they might be throttling using prompts!! Which just didn't seem right."
2023-03-29 23:11:38,I was thinking of doing something else. Basically you can make a series of questions answer pairs based on the output it gave and then search using serp or other available tools to validate or invalidate the answer. Haven’t tried this out but will do so when I get the time.
2023-03-29 23:12:12,second one does seem to work. will share here if I find any really good solution. was thinking if a custom agent implementation helps which first figures out if this is made up (does induce recursive problem) and then dodges the reply if yes.
2023-03-29 23:12:22,Self Consistency is empirically known to work: arxiv.org/abs/2203.11171
2023-03-30 00:44:38,was this before or after the GS report of 300 million jobs likely to get impacted ?
2023-03-30 00:45:19,Yeah this was a surprise - Stuart russel and Yoshu bengio signed off on this
2023-03-30 00:45:45,"I personally think any kind of hindrance to tech hurts the entity that's hindered, and is hardly ever fruitful."
2023-03-30 00:45:52,But this won't happen
2023-03-30 00:45:58,OpenAI is a for-profit company
2023-03-30 00:46:09,And backed by microsoft
2023-03-30 00:46:30,It's like asking Apple to stop innovating and launching new things
2023-03-30 00:46:30,"In 6 months openAI went from gpt 3.5 to gpt4, will they really stop training new AI models for the next 6 months just because of a document on the internet?"
2023-03-30 00:46:50,Perhaps more marketing/bringing awareness to the issue - like Balaji
2023-03-30 00:47:01,"They won't, and they shouldn't. It's a joke."
2023-03-30 00:49:53,Even if I was running a non-profit AI research lab. 
2023-03-30 00:53:16,true lol
2023-03-30 00:55:06,"It's all virtue signalling, which I completely understand. But that's for outsiders. If you're an insider, you really should see this as a joke."
2023-03-30 07:21:38,I'm surprised with Elon  backing it
2023-03-30 07:22:27,So looks like strategy to catch up rather than concern
2023-03-30 09:38:15,Yann Lecun drew a line in the sand! 🔥
2023-03-30 09:41:43,"Google Bard is trained on ChatGPT — the first author of BERT, Devlin, resigned over this? "
2023-03-30 09:43:32,Wasn’t the whole point of buying Twitter the data it offers? Hard to justify the price he paid for it otherwise
2023-03-30 09:45:27,"Elon is famously very pro-Govt when it benefits him: He takes tax rebates for Tesla via their Solar City acquisition, lobbies NASA and Congress to use US launch vehicles instead of European or Indian. He's basically Ambani Redux."
2023-03-30 09:48:09,As someone who has worked with Elon : I second that..
2023-03-30 09:48:22,"FYI - most likely this was a phishing scam (that i fall for as well), have reported it to twitter and google, let's see what happens"
2023-03-30 09:48:59,I got 2500 OpenAI credit as well.
2023-03-30 09:50:31,by filling this form? i doubt it
2023-03-30 09:52:17,Loss of long term memory is a feature not a bug.
2023-03-30 09:52:22,Got it.. I got email from OpenAI
2023-03-30 10:03:13,In what capacity?
2023-03-30 10:04:04,Leading data program at Tesla.
2023-03-30 10:11:42,Oh nice!
2023-03-30 10:12:03,Aditya is working on building an Adept rival from Namma Bengaluru! Hit him up if that's your vibe :) 
2023-03-30 10:12:45,Thanks Nirant..
2023-03-30 10:13:02,"We've got a bunch of very interesting folks here, feels like home 🙈"
2023-03-30 10:21:10,This calls for more elon gossips 🍿
2023-03-30 10:22:57,"Would be way more interested in Karpathy's work, the work Tesla did with synthetic data e.g. simulations and how they manage _truly_ big datasets!"
2023-03-30 10:25:25,Sure. I def have some nice ones to share...
2023-03-30 10:26:01,I vote for aditya focussed meetup 😂 tesla pe charcha
2023-03-30 10:26:13,I dint work with Karpathy as Data Org is different than car engineering. But worked on data privacy program which had overlap.
2023-03-30 10:33:34,"Hi All, "
2023-03-30 10:34:29,Hey Aditya great to see you here :)
2023-03-30 10:36:42,"In case you are comfortable sharing, would love to hear about your 'Bhramastra' against adept and inflection."
2023-03-30 10:37:06,Hey Aditya!✨
2023-03-30 10:37:21,Definitely 😅
2023-03-30 10:45:28,Thanks guys. Sure will share more. Any additional AI groups on reddit or discord I should be part of?
2023-03-30 12:03:13,Are you looking to minimise hallucinations during QnA over documents or just plain vanilla chat conversations?
2023-03-30 12:03:28,https://twitter.com/jerryjliu0/status/1641234014991446016?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-03-30 12:03:39,The maker of that evaluation model is [PHONE REMOVED] — he is here!
2023-03-30 12:05:03,"Thanks, Nirant for the mention."
2023-03-30 12:06:13,[PHONE REMOVED] Ravi great to have you here 🙌🏻🙌🏻 Been following your work and Llama Index for quite a while !
2023-03-30 13:11:14,Asking a dumb question what is Llama index? Been so caught up with visual AI that I've missed a lot of LLM progress 😬
2023-03-30 13:12:15,This project: github.com/jerryjliu/gpt_index
2023-03-30 13:13:47,did llama index and langchain raise funds?
2023-03-30 13:14:50,Curious to see if Harrison would tackle the langchain deployment layer himself
2023-03-30 13:14:53,"Give a read of Overview section here Amogh, you will get pretty good idea - https://github.com/jerryjliu/llama_index."
2023-03-30 13:15:15,They are trying to afaik
2023-03-30 13:16:21,SLAs are so tricky with open source projects; a lot of companies try to prioritize their features and fixes
2023-03-30 13:16:29,feature requests*
2023-03-30 13:16:32,"Chase is also doing a lot of community events/webinars btw. Almost 2 a week at this point, Chatbase, Explain Paper and other projects built around that"
2023-03-30 13:16:59,"ikr, what a machine"
2023-03-30 13:31:35,Small offtopic: anyone here who got an O1? Looking for advice on lawyers..
2023-03-30 14:00:32,https://huggingface.co/google/pix2struct-textcaps-large
2023-03-30 14:06:07,The results shown are pretty impressing with pix2struct.
2023-03-30 14:11:25,Pretty good
2023-03-30 14:11:39,I've found mm-react to be the best - probably SOTA till GPT-4 launches multimodal
2023-03-30 14:13:20,Randomly collaborating on someone who DMed me on twitter to build poetry CAM 
2023-03-30 14:13:40,"""In the garden of fading hues,"
2023-03-30 14:13:45,Fed to GPT-4
2023-03-30 14:14:26,what product use cases could you think of with such features?
2023-03-30 14:25:35,I see the first wave as mostly fun and interesting products
2023-03-30 14:25:46,"Like glean, for images too"
2023-03-30 14:26:26,There's also llama mulitmodal - need to benchmark that too.
2023-03-30 14:39:54,"Please welcome Shreya Rajpal [PHONE REMOVED], creator+maintainer of Guardrails: github.com/shreyar/guardrails"
2023-03-30 14:40:54,Something on these lines : https://www.springworks.in/albus/
2023-03-30 14:43:53,Thanks for inviting me to the group [PHONE REMOVED]!
2023-03-30 14:46:35,You have any ideas?
2023-03-30 14:47:19,"Shreya has also kindly agreed to give a Guardrails demo on Friday late night at the hackathon. Should be pretty useful for anyone working on LLM-Agents, structured parsing and similar sub-tasks!"
2023-03-30 14:47:43,Btw a fun usecase I saw in my improv group was using GPT-4 to do improv with as a scene actor
2023-03-30 14:56:53,https://twitter.com/sama/status/1641181668206858240?s=20
2023-03-30 14:56:53,Sam altman coming to india
2023-03-30 14:57:47,OpenAI Tour haha
2023-03-30 14:58:04,"Very shady ""regulate-in-my-favour-please"" tour on behalf of Microsoft"
2023-03-30 14:58:40,Yes. Not even coming to Bangalore.
2023-03-30 14:59:49,Mostly travelling to capitals. Talking to different govts.
2023-03-30 15:00:01,why govts?
2023-03-30 15:00:31,reason ^
2023-03-30 15:01:25,He’s going to Delhi not Bangalore! Bad choice
2023-03-30 15:01:59,"Microsoft runs World's largest Govt cloud, and was the first company to offer a backdoor to CCP for Windows. At that time, Windows was ""dangerous"" technology."
2023-03-30 15:02:02,"Bhai saab, itni job losses hone wali hai from openai, thoda confidence main to Lena padega"
2023-03-30 15:02:14,"I have heard about this . Apparently how to tune it according to different rules of each government , like free speech rules and such!"
2023-03-30 15:03:23,What to show ! And what not to show
2023-03-30 15:04:35,Github (MSFT acquisition) used to share when they got take down requests from Govt here: https://github.com/github/gov-takedowns
2023-03-30 15:06:04,Unfortunately yes! Great leavy for power
2023-03-30 15:09:07,Let me invite them here. I’m currently doing an art residency with that group.
2023-03-30 15:09:18,A DNS cert is basically you taking someone else's word instead of a small Twitter celeb 😅
2023-03-30 15:09:35,How many years y’all are into AI?
2023-03-30 15:09:49,They performed at rang Shankara and BIC recently. AI improve
2023-03-30 15:11:38,I was born in the ashes of SVM Kernels and raised in the wilderness of Random Forests
2023-03-30 15:12:20,https://instagram.com/climateprov?igshid=YmMyMTA2M2Y=
2023-03-30 15:13:32,import tensorflow as tf
2023-03-30 15:16:49,6 months here 😬👶
2023-03-30 15:17:27,In days or days and nights?
2023-03-30 15:18:54,"Been 3 months I guess! Been trying to do things on Kaggle and others ! Small things creating model , tuning different parameters . Lot to learn ! Long way to go!"
2023-03-30 15:19:20,How do you tell the difference ? 😵‍💫
2023-03-30 15:22:26,I started training when tf.Session was the only way to do it :))
2023-03-30 15:23:48,So I suppose that’s an OG statement
2023-03-30 15:24:22,"For exploring new capabilities and building quick things: no of years might be weak indicator, may be even negative indicator. It's a Brave New World !! 😂."
2023-03-30 15:24:22,Theano folks in the house?
2023-03-30 15:24:55,They'll need a Caffe before they step out with a Torch
2023-03-30 15:29:25,Sam Altman over elon musk
2023-03-30 15:38:20,probably he has changed his view this year lmao
2023-03-30 15:40:46,since tf-idf features were slowly being replaced by word2vec from gensim and mainstream torch was in lua
2023-03-30 15:41:08,"That's a long, long time."
2023-03-30 15:41:19,Now you'll have to explain what are gensim and Lua 🤣
2023-03-30 15:41:53,but also this
2023-03-30 15:42:32,Crazy’
2023-03-30 15:42:32,"In before someone says that it's all just matrix multiplication and those ""foundations"" haven't changed"
2023-03-30 15:42:33,"When I started, word2vec, maybe GloVE, were the bleeding edge of NLP tools."
2023-03-30 15:44:43,Haha. Here's mine
2023-03-30 15:45:31,started roughly in late ~2016
2023-03-30 15:45:41,https://www.researchgate.net/publication/308719279_Sentiment_Analysis_for_Mixed_Script_Indic_Sentences i worked on this paper in 2015 and i thought i was working on bleeding edge stuff.   Shows how out of touch research work in our universities was
2023-03-30 15:47:38,Same pinch. 
2023-03-30 15:48:31,and likewise infra spend has also increased dramatically
2023-03-30 15:51:01,Coded a sparse autoencoder in MATLAB back in 2012. Not ashamed to admit that was the peak of my ML prowess
2023-03-30 15:53:41,I actually first heard about ML first from [PHONE REMOVED] nerding about Tom Mitchell's book
2023-03-30 15:57:12,I think I still have a pdf of it somewhere. The only major book I got a hard copy of was the AI AMA.
2023-03-30 15:57:59,Curious to know if there are folks from the mlblr / tsai community here!
2023-03-30 15:59:34,I mucked around with theano and also had a gsoc proposal that didn't go through 😅
2023-03-30 15:59:58,What’s your source for discovering the latest papers/works? I saw someone shared a paper from a week ago
2023-03-30 16:00:29,"Tbf, matmul optimization is still an unsolved problem and folks do PhDs on this even today"
2023-03-30 16:01:33,"Follow this firehose, turn on notifs "
2023-03-30 16:03:14,Deepmind's AlphaTensor is beating them 😅
2023-03-30 16:09:09,Except there was a paper in the next day that found faster matmul algorithm. Just that they were academics that didn't have a PR team behind them
2023-03-30 16:11:18,https://arxiv.org/abs/2210.04045
2023-03-30 21:46:03,Wrote A3C in lua torch (it was asynchronous as we were using threads instead processes in Lua) and trained the agent to play doom game .
2023-03-30 21:49:26,Since alpha zero beat stockfish.  There was some excellent chess coverage around those matches
2023-03-30 21:49:51,Thankfully it's much simpler to do something with it now
2023-03-30 22:04:48,Around 2018. When I saw Deepminds first demos of neural nets playing Tetris. 
2023-03-30 22:37:48,https://www.linkedin.com/posts/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_android
2023-03-30 22:42:26,"Hey Munjal, welcome to the group!"
2023-03-30 22:46:04,Hi Nirant sorry will not repeat again. My intention was not self promotion but education.
2023-03-30 23:10:11,hackathon idea - get all relevant WhatsApp chats from [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] and other organisers related to questions they've been receiving about the upcoming event. Fine-tune a LangChain model on those question answers. 
2023-03-30 23:11:04,[PHONE REMOVED] expected footfall for the hackathon? 🔥
2023-03-30 23:12:20,154 invites sent out for the in-person Bengaluru hackathon
2023-03-30 23:12:48,woohooo!
2023-03-31 01:49:11,A quick hack for DeepMind GPT
2023-03-31 01:49:54,"It is able to handle multiple context questions ,check the demo vid till the end"
2023-03-31 01:51:18,Sorry *DeepHack GPT
2023-03-31 01:51:49,Quick extension++
2023-03-31 01:57:29,Small flex - you can export this group chat from whatsapp and just upload the text file to gooey and it will get you this search without writing any code  - you can change the prompts and change model settings from the ui!
2023-03-31 02:00:42,Will this also herd adults? 😀
2023-03-31 07:48:49,"Has anybody worked with making LLMs understand table structures? If I have it a document / PDF that has a table in it, the LLM needs to read it row by row, remembering context of the columns as well."
2023-03-31 08:51:34,chatpdf.com
2023-03-31 09:09:56,This is the best!
2023-03-31 09:13:36,"Nice, gonna try this out. Did you build it Shashwat?"
2023-03-31 09:15:19,No Amogh. I'm building on databases. Text2Sql usecase primarily.
2023-03-31 09:23:04,From when did WhatsApp start allowing exporting chats as txt 😮
2023-03-31 09:24:01,I think it's been there since quite a while
2023-03-31 09:33:50,Yeah used that feature 4-5 years back.. they did in a zip..
2023-03-31 10:20:35,2016
2023-03-31 10:41:40,"Rephrase.ai just launched a completely automated blog to video powered by GPT-4. I made some contributions to it, and am working on the next version of it.  https://www.rephrase.ai/blog-to-video"
2023-03-31 11:21:59,thanks! pinged Mathis
2023-03-31 11:22:01,"Ritesh, Some issues in your form. One time the email input field did not render at all, the other time it took more than 20s for the form to load. May be just a load thing."
2023-03-31 11:22:02,Interesting work btw.
2023-03-31 11:25:04,"Hi all,"
2023-03-31 11:26:02,Hi Pradyumna. You can just use the Whisper API to get the transcript. Don't need GPUs
2023-03-31 11:26:08,"You can upload this to gooey doc search too, might take a while. You can select the asr model in settings"
2023-03-31 11:27:19,You can use Colab 
2023-03-31 11:27:50,"Thanks alot, trying this right now"
2023-03-31 11:28:16,"Oh you just needed the transcript. Sorry, that’s at https://gooey.ai/asr/"
2023-03-31 11:29:05,"Oh, thanks! "
2023-03-31 11:29:21,Sure
2023-03-31 11:31:03,"You could even use - https://www.gladia.io/ - 1-hour audio file transcript will be extracted in 10-20 seconds which uses openai Whisper backend. Currently, the API is free."
2023-03-31 11:54:42,"Maybe check out Assembly.ai, they have a playground to upload files to and try transcription, accuracy is pretty good too."
2023-03-31 11:57:00,Checking. I usually use their python API.
2023-03-31 11:58:02,[PHONE REMOVED] I tried just now with a 50-minute audio file by uploading. It worked fine.
2023-03-31 11:58:26,"Wierd, I'll try again. Thanks"
2023-03-31 12:46:27,Tried on one of the medium blogs and it’s pretty good. Is there a constraint on time limit on the video generated?
2023-03-31 12:51:23,seems like the default is 1 minute
2023-03-31 13:03:09,yes we are generating videos for around 1 minute. There is a limit on size of blog - upto 20k characters
2023-03-31 13:03:28,Is the 1 minute limit because of computation/cost or technical limitations?
2023-03-31 13:03:33,let me check
2023-03-31 13:04:16,"just a product decision for now, since it's free for now - cost is also a reason"
2023-03-31 13:04:40,What'd it take to make a Tiktok/IG reels version of this?
2023-03-31 13:07:24,Or use whisper.cpp
2023-03-31 13:08:39,You mean in terms of only the resolution or is there any other difference
2023-03-31 13:08:58,"Pitch, editing style, cuts, screen transitions, overlays"
2023-03-31 13:09:17,"yes all of that is what i am working on, that is the plan"
2023-03-31 13:10:15,"i mean there are lower hanging fruits then these , but all of these will come.  Making pitch better will happen sooner"
2023-03-31 13:10:55,Do it before Bytedance/Tiktok does it!
2023-03-31 13:15:11,Or runwayml!
2023-03-31 13:37:04,Could you please share the results? 👀
2023-03-31 13:47:44,https://mobile.twitter.com/svembu/status/1641710194458791939
2023-03-31 13:49:43,Video: https://personalized.rephrase.ai/?campaign_id=0Rhz6gA1qhU07BWGCjHap03Pfr9SRQ&shareable=true
2023-03-31 13:50:48,hi
2023-03-31 17:51:34,https://arxiv.org/abs/2303.17580 HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. What do you guys think of this?
2023-03-31 18:09:56,ChatGPT plugins and langchain agents already do this in a way.
2023-03-31 18:13:36,Calling out to fellow Product Managers  - need some insight on some KPI error corrections.
2023-03-31 19:36:11,The Italian Data Protection Authority (DPA) has some interesting things to say about ChatGPT's training models and finds it violation of their data laws.
2023-04-01 16:41:26,Who all going to the DeepHack demo day?
2023-04-01 16:45:08,Live stream is set up here - https://has.gy/ULYt
2023-04-01 16:45:21,Demo Day live stream
2023-04-01 19:23:52,"Hi, Are we done with all the submissions? The live stream just stopped"
2023-04-01 19:24:44,Taking a 5 min break
2023-04-01 19:25:19,Oh okay. Thanks Nirant!
2023-04-02 05:01:08,https://magicfusion.github.io
2023-04-02 19:08:40,"hey folks. are there any good/free/local alternatives to D-ID, ElevenLabs? so that i can upload my custom image, audio and get a lip-synced avatar video."
2023-04-02 19:10:15,https://gooey.ai/lipsync/
2023-04-02 19:11:49,"also, is there anywhere I can read the difference b/w Dreambooth, LoRA, Texual Inversion - differences, pros, cons, training time etc. I had trained custom DB model last year, know a lil bit about the other two, but haven't used them yet...looking to. "
2023-04-02 19:12:04,thanks!
2023-04-02 20:08:26,"I don't have a brief doc written but based on my experience, LoRA works really well compared to other two especially after being trained on small amount of data relatively, followed by dreambooth which would provide decent results after multiple attempts of fine tuning whereas textual inversion did'nt return any good results for me, i did try making small changes but that didn't help much as well."
2023-04-02 20:50:06,https://youtu.be/dVjMiJsuR5o
2023-04-03 00:07:07,thanks [PHONE REMOVED] [PHONE REMOVED] 🙏
2023-04-03 02:00:34,"> But it’s very possible that creativity and what we think of us as human intelligence are just an emergent property of a small number of algorithms operating with a lot of compute power (In fact, many respected neocortex researchers believe there is effectively one algorithm for all intelligence.  I distinctly remember my undergrad advisor saying the reason he was excited about machine intelligence again was that brain research made it seem possible there was only one algorithm computer scientists had to figure out.)"
2023-04-03 02:02:05,"> Human brains don’t look all that different from chimp brains, and yet somehow produce wildly different capabilities.  We decry current machine intelligence as cheap tricks, but perhaps our own intelligence is just the emergent combination of a bunch of cheap tricks."
2023-04-04 11:32:07,https://twitter.com/lumalabsai/status/1642883558938411008?s=46
2023-04-04 11:41:35,Report here: https://aiindex.stanford.edu/report/
2023-04-04 17:22:10,"Funny but off topic, we do not encourage this :)"
2023-04-04 17:22:39,No worries
2023-04-04 17:33:17,"Hey Hackers, [PHONE REMOVED] and I have built something in the generative AI space, that we wanted your feedback on: https://twitter.com/CyberSahu/status/1643166480794791938?s=20"
2023-04-04 17:59:37,https://github.com/nat/openplayground
2023-04-04 18:01:36,Collateral Damage: Killing Suhail's playgroundai.com any chance of entry into text LLMs 😂
2023-04-04 18:03:05,Playground.ai is very different na? I think its more about popular prompts and upvoting rather than comparing models
2023-04-04 18:05:43,"playgroundai lets you experiment with different diffusion models, parameters, inpainting, base image generation...openplayground also does same thing for LLM's right."
2023-04-04 18:08:21,Surprised they don't have mid journey 5
2023-04-04 18:10:21,"it's free, which is a big deal"
2023-04-04 18:10:45,AFAIR it's only accessible through discord
2023-04-04 18:11:31,"Yes, I’ve heard that API is in the works"
2023-04-04 18:11:58,"Yes, you're right. I presumed it would be in some alpha by now"
2023-04-04 18:12:51,"once it comes out, I believe it's going to be chatgpt moment for them"
2023-04-04 18:19:35,Why the strategy to have a discord bot but not an API?
2023-04-04 18:22:13,I think they are/were bootstrapped and inference infra is hard & expensive
2023-04-04 18:22:55,"I think Stability supports them with GPU resources, not completely sure though."
2023-04-04 18:25:06,They’re rolling out API access soon. Heard in their office hours. 
2023-04-04 18:25:54,Anyone remember magicleap? That’s the guy behind it 😬
2023-04-04 18:27:09,Sorry leap motion*
2023-04-04 18:28:47,https://youtu.be/xNqs_S-zEBY
2023-04-04 18:29:33,AirBnB for GPUs would be such a thing
2023-04-04 18:30:40,Used to be called AWS
2023-04-04 18:31:03,those are hotels
2023-04-04 18:31:08,vast.ai
2023-04-04 18:31:50,Hetzner Cloud was the OG hotels no? https://www.hetzner.com/cloud
2023-04-04 18:34:11,"if you mean someone letting renting out their GPUs, then runpod is doing it"
2023-04-04 18:34:37,"Damn, didn’t know Jasper trained their models on the Cerebras systems"
2023-04-04 19:12:10,Claims to be unofficial MJ API - https://www.imagineapi.dev
2023-04-04 19:13:33,Did they create a MJ bot for the MJ bot?! 😆
2023-04-04 19:46:08,"W&B speaks to OpenAI, answers questions about cutoff date and bunch of other tidbits: "
2023-04-04 23:03:05,Langchain is awesome. 
2023-04-04 23:03:40,Indians in India should've a globally used GenerativeAI library within next 12 months if we're to be still in the running. We missed the PyTorch/Tensorflow/transformers wave completely. 
2023-04-04 23:04:09,For anyone interested in my AI-generated comic from the weekend hackathon:
2023-04-04 23:16:07,Sooo good
2023-04-04 23:16:40,Praise Lord Dattā!
2023-04-04 23:19:17,it's actually impressive 🔥
2023-04-04 23:23:15,Love it! Publish a sequel :)
2023-04-05 00:49:01,Does anyone know if we can utilise OpenAI embeddings model to create graph embeddings?
2023-04-05 00:57:28,"One naive approach is if you have graph structure with sentences as nodes, you can use openai embeddings - ""text-embedding-ada-002"" to get node embeddings directly, and using adjacency matric you can compute edge embeddings by averaging the connected nodes."
2023-04-05 00:58:33,Pinterest — the OG graph folks would recommend starting off with any base embedding and then update them  
2023-04-05 01:07:35,I came across this article on HN and was wondering if it can be done using some form of text representation using ‘text-embedding-ada-002’
2023-04-05 02:12:05,Is there a gpt model that i can currently use finetuned with financial data and analysis?
2023-04-05 02:15:37,there's some bloomberg gpt ig
2023-04-05 02:15:53,its not usable yet
2023-04-05 02:15:54,Yeah but I don’t think this is available publicly
2023-04-05 02:16:08,I somehow doubt they will ever open source it
2023-04-05 02:16:11,its just a paper by far
2023-04-05 02:41:33,It’s a paper of an existing /closed implementation- won’t be open sourcing . It’s trained on their proprietary data .
2023-04-05 02:41:42,*sourced
2023-04-05 05:59:13,It works?
2023-04-05 05:59:24,500 lol
2023-04-05 05:59:56,but it's around the corner it seems
2023-04-05 06:00:04,maybe they've rolled it out already to a few people
2023-04-05 07:40:07,"[PHONE REMOVED] can you pls add Abhinav here. He is Shop101 CEO, wanted to join the community"
2023-04-05 07:54:04,PSA: Please DM for add or other admin requests in future :)
2023-04-05 08:12:06,"In the words of Kaggle Grandmaster Sanyam Bhutani — the ""World's best Deep Learning course"" "
2023-04-05 10:56:11,"Hey folks! Thinking of having a light beer + pizza mixer of ~20 people building in generative AI at the Lightspeed office in Koramangala opposite to third wave on the 13th of April, next week Thursday. We can keep the conversations focused on just new things people are building as well as what I'm seeing in the market more broadly in the US and around the world. Folks that are interested, please do a thumbs up on this thread! I'll start a separate group with you all! Looking forward 🙂"
2023-04-05 11:12:01,"If we exceed 20, no worries, will do this at least once in 3 weeks, so should be just including people in the next set."
2023-04-05 11:27:54,If you all can fill up this form: https://docs.google.com/forms/d/e/1FAIpQLSfRg1AOSSfSs8ZBbKzWd5ne_8JqzJrwFvy_NN0K-TUIdG2jYA/viewform
2023-04-05 12:11:38,"Good to see so many events around AI happening in Bangalore. Sharing one I am hosting on April 14th, 6pm at the Draper Startup House, Koramangala. "
2023-04-05 12:31:49,"Folks, I got the 2500$ openAI credits from here! You all should check it out 😀"
2023-04-05 12:32:41,Not a phishing attack? Share an email screenshot etc?
2023-04-05 12:34:27,I mean this is an open ai link. Not sure what else would convince you
2023-04-05 12:35:09,"Oh right, this link is different"
2023-04-05 12:36:04,You had a crunchbase profile? I set it to NA while filling the form 😅
2023-04-05 12:36:32,lol I created on last year for lulz after I incorporated my company
2023-04-05 12:37:11,Same. I did too. Although I have an incorporated company so that might have helped.
2023-04-05 12:37:27,Guess I won’t be receiving the credits anytime soon
2023-04-05 12:51:19,You can get this only if you are registered as a start-up or even if you are an individual looking to build stuff?
2023-04-05 12:52:08,registered as startup and then got this but took many months
2023-04-05 12:52:20,"I recently came across a Blind post saying Google is moving the majority of its resources from Assistant to Bard, and heard similar sort of news for Amazon's Alexa."
2023-04-05 12:53:02,Incentives explain more of these decisions than insight :)
2023-04-05 12:56:07,Do we get this only if it's an incorporated company?
2023-04-05 12:57:05,8:30am 8th April no?
2023-04-05 12:57:57,"Perhaps, but I didn't provide any official details of the company (only website and crunchbase)"
2023-04-05 12:58:23,sorry for the scare guys :P
2023-04-05 12:59:01,"This is two phenomenon occurring almost at the same time. Amazon Alexa and Google assistant orgs were slowly being shutdown / dismantled due to economic downturn. With the sudden hype around LLMs, they're simply pivoting these teams instead of firing and hiring"
2023-04-05 13:22:12,"This makes sense, but I thought post LLM hype they will just rejuvenate these projects but understandable."
2023-04-05 13:28:36,May be next time.
2023-04-05 15:07:33,Update on this. 
2023-04-05 15:09:22,All that I'm hearing is the first 1000 are free 🤣
2023-04-05 15:11:24,https://community.riscv.org/events/details/risc-v-international-risc-v-in-india-presents-nerds-talking-to-nerds-about-risc-v-hosted-by-tenstorrent/waitlist/151
2023-04-05 16:31:08,Is anyone aware of research happening in Deepfake detection?
2023-04-05 16:31:17,any good app/software for it?
2023-04-05 16:32:52,[PHONE REMOVED] from Spoofsense.ai is working on this I believe.
2023-04-05 16:32:57,"Found this effort by Microsoft as well, but it doesn’t have a working model for public ig: https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/"
2023-04-05 16:35:14,"Not releasing is probably a good call, tricky thing to release authenticators because that makes it easier for next generation of cheaters to evolve/reverse engineer."
2023-04-05 16:36:41,"I recall that long time ago Y! had released a nudity detection model, and a bunch figured out Wordpress and other social media companies were using similar CNN based methods — and had bypasses to detect babies from adults. "
2023-04-05 16:37:53,Found the model. It's 7 years ago and written in Caffe. 
2023-04-05 16:39:16,"interesting, thanks for sharing Nirant"
2023-04-05 16:48:13,one lofty way I could think of is all newly created images having a mandatory hash/digital signature like NFTs to verify and validate their origin;
2023-04-05 16:48:33,not sure what’ll be the limitations of this.
2023-04-05 16:49:23,"Sigh, every generation re-invents pgp keys, pdf standards, and SSO 😅"
2023-04-05 16:49:24,"not only images, I mean any digital “information”"
2023-04-05 16:51:02,sure
2023-04-05 16:51:35,"I meant, that we've to re-invent to keep up. The threat surface has evolved too."
2023-04-05 16:54:47,absolutely; cryptography is a constantly-evolving process/field
2023-04-05 17:12:51,can use this https://kroop.ai/the-vizmantiz/
2023-04-05 18:30:00,"Has anyone seen an API to categorize questions into HR, Finance, Marketing etc?"
2023-04-05 18:31:01,"DM, send me 20 samples, can make you one over the weekend?"
2023-04-05 18:33:10,"Yes but will need to host etc / I was thinking if there's a service which could do analytics etc, retagging etc"
2023-04-05 18:33:40,Google Sheets has GPT4 if it's batch 😂
2023-04-05 18:34:25,"are you think of a prompt ""Please categorize this into HR, Finance"" etc?"
2023-04-05 18:34:48,"That's the baseline, yeah"
2023-04-05 18:35:19,It would be great if you can give it samples in the prompt itself and perhaps chain it with the system response and then in the second user message send your input query
2023-04-05 18:35:42,Does anyone know how to get more than $1K/month hard limit of OpenAI? We're going to be crossing that any day and I've already applied for an increase.
2023-04-05 18:35:43,Sorry didn't bother with punctuations 😅
2023-04-05 18:35:57,yes / can get very expensive very quickly. 5K questions a day.
2023-04-05 18:38:50,Can it be done by similarity search ? 
2023-04-05 18:38:58,You can perhaps then use gpt4 data do generate your own dataset
2023-04-05 18:39:12,And then train a model of your own labelled dataset
2023-04-05 18:39:20,And use that in prod
2023-04-05 18:39:31,Over engineering friends
2023-04-05 18:39:44,Perhaps :p
2023-04-05 18:40:03,Run this against a decent prompt and see how most of it will just work
2023-04-05 18:40:14,Prone to less accuracy
2023-04-05 18:40:44,"I used the Google Sheet workflow to decide who to invite for the hackathon, over 200 folks applied"
2023-04-05 18:41:29,"Just descibe what HR and Finance mean, and gpt will classify pretty well. "
2023-04-05 18:41:56,This technique was also used by openai to train gpt4
2023-04-05 18:42:10,Gooey is such a cool ass Swiss knife
2023-04-05 18:42:13,Kudos to you
2023-04-05 18:46:23,The trade off I was considering was using prompt to classify would require a more expensive API end point 
2023-04-05 18:46:51,Turbo is cheaper than Ada?
2023-04-05 18:56:11,Could be that I might have referred to wrong prices then 
2023-04-05 18:57:11,"I could be wrong as well, let's check and come back"
2023-04-05 18:59:26,who's the largest openai customer in India?
2023-04-05 19:04:42,https://www.buildt.ai/blog/incorrectusage
2023-04-05 19:04:59,Pepper is one of the larger customers.. fwik
2023-04-05 19:06:10,how much do you think they spend per month?
2023-04-05 19:07:29,"not sure if I can share that, but what are you looking for?"
2023-04-05 20:12:45,https://analyticsindiamag.com/hugging-face-launches-gpt-4-alternative-vicuna-13b/
2023-04-05 20:33:19,Neat! This seems to be essentially knowledge distillation+human in loop for higher quality labels. Or do folks think this is a false equivalence?
2023-04-05 20:49:45,Here’s on Zero Knowledge Machine learning published by WorldCoin 
2023-04-05 20:52:05,One good use case they’ve highlighted is on using ZMKL for the purpose of inference on medical data
2023-04-05 21:12:06,"""HuggingFace launches"""
2023-04-05 21:44:48,Please don't share outright wrong press. Erodes trust in the group 😀
2023-04-05 22:03:12,"hey folks, what's the status of prompt injection in gpt4?"
2023-04-05 22:06:48,"Funny you should ask, just earlier today I was experimenting with prompt injection out of curiosity. I know that in chatGPT and GPT 3, 3.5, asking it to simulate another agent with different ideals works well. I don't have access to GPT 4 but have heard that this doesn't work well with it. What, in particular, are you interested about in prompt injections?"
2023-04-05 22:07:16,one silly example from my experiments
2023-04-05 22:07:59,thanks. i just want examples which worked before but don't right now in chatgpt-4.
2023-04-05 22:08:49,ask it to create a full form for that name 😂
2023-04-05 22:11:00,You can make it do a lot of funny things with this hack. I'll probably get kicked out by the admins if I post too many of those screenshots 😂
2023-04-05 22:12:03,"My DMs are open, send me your darkest work"
2023-04-05 22:29:40,Go ahead da. Dumbledore's Army will always have a space in Room of Requirements!
2023-04-05 23:10:08,"I've experimented with GPT-4 and it is really good with handling prompt injections. It sticks to the system prompt and straight up denies such prompt injections methods. Atleast with the experiments I did, I had no luck to get promo injection working with GPT-4. OpenAI seems to have worked well on handling it."
2023-04-06 00:09:34,"I reckon they made good use of the system prompt this time. My guess is that it’s appended at the END of all previous messages and the network is trained to ignore the grammatical content of it, but obey the instructions."
2023-04-06 00:11:42,"Yep, could be the case."
2023-04-06 01:05:44,yo anyone building anything for gen ai applications in schools?
2023-04-06 04:34:33,Im looking to create Sparse Veccors and do hybrid search. What is the best model to use in a prod environment?
2023-04-06 05:29:43,"Doing a small experiment, say hi to this guy 😬"
2023-04-06 05:48:52,Nicee
2023-04-06 05:49:01,What are you using for text2vid
2023-04-06 06:56:08,Goodmorning folks. Does anyone know how Danny postma is doing cloth transfer? 
2023-04-06 06:57:19,"Is he masking the cloth first, and then doing style transfer? Even then, the results look near perfect and artefact free, unlike what style transfer or img2img can do"
2023-04-06 07:15:15,https://arxiv.org/abs/2304.01852
2023-04-06 07:20:02,This came out two days ago 👆
2023-04-06 08:01:54,https://github.com/sangyun884/HR-VITON
2023-04-06 08:34:52,Has anyone tried a paid subscription of MidJourney from India? My payments seem not to be going through.
2023-04-06 08:36:36,Yes - my team had setup a subscription
2023-04-06 08:42:19,Did you pay for it by credit card or is there any other mode of payment available?
2023-04-06 08:43:45,This is so cool!!
2023-04-06 09:06:31,https://youtu.be/E7fGsSNKMc4
2023-04-06 09:07:26,Personal citi Indian master credit card
2023-04-06 09:54:15,"it's a stripe link, right? i think other modes should work as well. i used my amazon icici cc"
2023-04-06 13:10:59,more good ideas on how to use the platform ---
2023-04-06 13:12:12,I see my college's library in the preview 👀
2023-04-06 13:12:25,😱
2023-04-06 13:12:51,"Yeah that's definitely Trinity college Dublins library ""the book of Kells"""
2023-04-06 13:17:53,Hi folks. I’m trying to achieve text to color grading similar to this model provided by RunwayML. 
2023-04-06 13:41:34,"Nice, runwayml is 🔥"
2023-04-06 14:01:51,"Can't recall which teams had asked for this specifically, but finetuned STT for Indian languages: https://huggingface.co/blog/fine-tune-whisper"
2023-04-06 14:02:48,"And dataset, wave2vec models: https://github.com/Open-Speech-EkStep/vakyansh-models"
2023-04-06 14:07:57,https://twitter.com/MetaAI/status/1643602729615646720 
2023-04-06 15:03:15,"hey everyone,"
2023-04-06 15:03:57,"Quick q, how big is the database?"
2023-04-06 15:03:59,cc [PHONE REMOVED] did you work with Pinecone? 
2023-04-06 15:05:01,3361 - vector count
2023-04-06 15:05:45,"Not to derail your project, but this sounds like an xy problem. You dont need the complexity of a vector database at this scale. Just use pandas"
2023-04-06 15:06:29,Will the response be faster?
2023-04-06 15:06:58,Yes. It will be in-memory and require no network calls.
2023-04-06 15:07:17,Openai has notebook examples of it too
2023-04-06 15:07:39,"Not to mention, so much easier to debug and inspect"
2023-04-06 15:08:06,"Ankur, how comfy are you with Python/pandas ecosystem?"
2023-04-06 15:08:21,Very little.. learning on go
2023-04-06 15:08:55,"Hmm, in that case you can also do what I do and just do python lists and not even do pandas 😂"
2023-04-06 15:09:01,"Okay, if I can teach you how to do this in Google Sheets, will that be faster for you?"
2023-04-06 15:09:07,Any link?
2023-04-06 15:09:25,"And how you decide when vector db is better ? And which vector db is much pinecone, superbase etc.. or all these are just brands and using same tech under the hood?"
2023-04-06 15:09:28,Very interested as well
2023-04-06 15:09:42,"Aside: Keeping this convo on main, since 2-5 people have pinged with similar/adjacent questions, and hoping that answering this would help more folks :)"
2023-04-06 15:10:23,Really..
2023-04-06 15:10:44,Nah.. not looking at google sheets ways..
2023-04-06 15:10:46,Yes. 3000 rows is pocket change
2023-04-06 15:11:13,https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
2023-04-06 15:12:55,"For any indie hackers, you can use Google Sheet as a db to launch a GPT4 app as well: "
2023-04-06 15:13:43,"Small self promotion: Gooey.ai supports this as well, and even lets you create bots that refer to google sheets 😬"
2023-04-06 15:14:56,You can use self-hosted postgres with pgvector too
2023-04-06 15:15:16,"Pinecone and Supabase are both over the network. Pinecone is _vector first_, while Supabase is basically managed Postgres. So querying metadata is hard and it's terrible at ranking/search for both. If you've a complex webapp at launch, you can launch with Supabase. It's just Postgres. "
2023-04-06 15:16:00,nice
2023-04-06 15:16:24,"Chroma works in-memory, persists state (unlike Pandas) — and no network overhead. Unlike Weaviate, it's quite a thin Docker image and doesn't need bells and whistles — just pip install and it works."
2023-04-06 15:16:52,"Chroma can do a lot better dev marketing by saying: ""It works"""
2023-04-06 15:17:01,The Founder is also very nice
2023-04-06 15:17:39,"And in a market where Pinecone deletes your vectors, Weaviate doesn't review PRs — that's quite important 😅"
2023-04-06 15:17:47,Indian gov has finedtuned checkpoints too - https://huggingface.co/vasista22/whisper-hindi-large-v2
2023-04-06 15:18:41,is there an api for this?
2023-04-06 15:19:12,Sorry I can’t help self plug again - https://gooey.ai/asr/
2023-04-06 15:20:51,this notebook had serious finetuning-example problems
2023-04-06 15:21:34,You can make $500 MRR by fixing OpenAI Notebook bugs and putting behind a Stripe link and Fly.io deployment at this point
2023-04-06 15:22:03,wait what
2023-04-06 15:22:20,I’m a contributor of openai cookbook: https://github.com/openai/openai-cookbook/blob/6df6ceff470eeba26a56de131254e775292eac22/examples/fine-tuned_qa/olympics-1-collect-data.ipynb
2023-04-06 15:22:26,How can I make money?
2023-04-06 15:25:08,[PHONE REMOVED] how much time it takes to insert embeddings/ data into chroma? Asking this in the context of online/ on the fly data insertion.
2023-04-06 15:25:50,"Problem Statement: Finetune off the shelf embedding for a specific domain, extremely useful for improving search ranking and QA. Empirically proved by ColBERT and Vespa both. "
2023-04-06 15:26:30,"Host on a web service to show that it works, market with a ton of benchmarks — mock every commercial service who can't answer questions from their own pricing page _almost always_"
2023-04-06 15:27:07,"10% kalesh marketing (why does this problem matter), 90% convince that it's enough value (here is my solution)"
2023-04-06 15:27:51,"Haven't profiled it tbh, but for a 50K chunk/rows size, it was more than 30s. So on the fly should be worth taking a shot at"
2023-04-06 15:29:15,This kinda homework/advice is what I invoice $500 to Series A CTOs/Founders usually 😆
2023-04-06 15:29:15,"Nirant since we’re on this topic, is there any way to use colbert / dsp over an unlabelled dataset?"
2023-04-06 15:30:12,"This is very interesting commercially. Many fashion brand owners are quite keen on AI generated catalogues, and do away with model photoshoots"
2023-04-06 15:30:20,The market pull is real for that use case
2023-04-06 15:30:53,"Happy to share ideas on DM, when I am sober on Sunday. Have not tested this enough. But zooming out, I refuse to believe that there is such a thing as ""unlabeled text data"" anymore."
2023-04-06 15:33:06,Anybody know if I can use hydbrid embeddings on Chroma?
2023-04-06 15:33:56,"Embedding search is very powerful but I feel the linear nature of the embeddings can be limiting, not in terms of performance but the semantic capacity."
2023-04-06 15:34:54,"Would be helpful if you elaborated on what do you mean by ""hybrid"" :)"
2023-04-06 15:36:23,"I love this constant human urge to decouple systems into memory, reasoning, context and what not — despite 15 years of ML research proving that combined systems outperform decoupled systems. "
2023-04-06 15:36:59,"Sure, so hybrid meaning searching for keywords + semantic meaning. My understanding is that you can use sparse + dense embeddings to achieve better accuracy on results. Pinecone for example allows you to store both of these for a single ID. Wondering if Chroma does the same"
2023-04-06 15:38:25,"Yes, Chroma does the same. They don't have good docs around it yet though. Assuming that you're a hacker solving for time to market, launch with Pinecone. Move to Chroma when someone asks on-premise"
2023-04-06 15:40:02,Combined system definitely will perform better and I feel we are on the verge of achieving this in AI. But as of now it’s clear that memory is a limiting factor of LLMs and hence we need alternative solutions.
2023-04-06 15:41:06,something related: https://twitter.com/LangChainAI/status/1643628476505681920?s=20
2023-04-06 15:41:38,"Thanks, will have a look 🙏🏽"
2023-04-06 15:42:47,"""Managed Retrieval Engines"" — clearly a Management Consultant type was paid to rebrand hosted services into something cooler, so that we can add one more category to G2 and then become it's leader 🤣"
2023-04-06 15:44:24,"The most basic model is to use sklearn's CountVectorizer (which is based on bag of words) on the text, and use the sparse vectors generated by it. All conventional systems use bm25, tfidf etc., So you could generate sparse vectors from that as well."
2023-04-06 15:45:42,"What would be the nodes and edges of this graph. Idea sounds interesting, but would like to hear more of your thoughts on it"
2023-04-06 15:47:57,"Some sort of a entity relationship graph might work, upon some text input, we could semantically traverse the graph to filter out the relevant nodes and edges and focus on them for future processing (using LLMs maybe)"
2023-04-06 15:49:45,Even I’m not sure if it will work but I definitely feel there are some semantic gaps when using purely embeddings and this might be a solution
2023-04-06 15:51:37,The thing is: *everything* can be (and is) linearly embeddable. Even graphs themselves 😀.
2023-04-06 15:52:26,"Understood, yea the graph db approach makes a lot of sense"
2023-04-06 15:52:46,I'm actually designing something like the second for a company right now
2023-04-06 15:55:31,Nice nice thanks will check it out 🙏🏽
2023-04-06 15:57:32,I wonder how many of their new integrations are going to be business-motivated (eg: the bm25 being with Elastic). I'm guessing we can still contribute our own adaptors for other platforms to their GitHub..
2023-04-06 15:57:52,"Nope, used an in memory JSON file with embeddings stored in a key value store. For the hack it was good enough, but for scaling it I was planning to use weaviate. "
2023-04-06 16:06:54,"b25 is more fundamental I think… it’s a class in lucene, on top of which Elastic is essentially built."
2023-04-06 16:10:04,"By “bootstrapped” I mean those who have their own “search-system”, and do not use Elastic, etc."
2023-04-06 16:27:41,"btw, langchain has some stuff around graphs as well "
2023-04-06 16:29:41,"for anyone using pinecone, just be careful. their pricing is very confusing. this dude paid $1000 for ... ~no usage"
2023-04-06 16:35:22,yeahs got $24 billing for 5 days with just 10 queries -
2023-04-06 16:36:38,For how many indexes?
2023-04-06 16:38:05,2
2023-04-06 16:39:41,damn. could've had one month of ChatGPT Pro and still have $4 left 😂
2023-04-06 16:40:27,Then it should be correct I guess. One index costs approx $2.3 per day and 2 indexes for 5 days it’s $24
2023-04-06 16:41:31,Was the bill because he was creating an index per customer or something?
2023-04-06 17:11:34,"only after his tweet I deleted my unused stuff on Pinecone, did not know I was paying for it."
2023-04-06 17:25:56,"i checked my account as well, just in case"
2023-04-06 17:26:33,Digital ocean used to be the nice ones 🥲
2023-04-06 17:27:28,thats why i use credit card with limits. so if by any chance any tools more than what I can pay. Service stops.
2023-04-06 17:28:38,"pinecone started off with a lot of community collaboration, their blogs on semantic search by james briggs are still my favorite on the topic"
2023-04-06 17:34:37,"this was generated by chatgpt, right?"
2023-04-06 17:35:02,"lol, no"
2023-04-06 17:35:22,i only use stolen credit cards 😎
2023-04-06 17:35:38,pure dadaji vibes..
2023-04-06 17:36:19,"Donald Knuth didn’t spare any words, “getting binomial coefficients to work properly” 😂"
2023-04-06 17:37:02,Send some my ways too
2023-04-06 17:41:46,Fun story: met jim keller today and he wants to build a 2 terabyte risc-v chip that can run pytorch code. 2 goddamn terabytes 🤯🤯🤯
2023-04-06 17:42:20,anyone here tried the gpt4 compression prompt? it's pretty good. 
2023-04-06 17:43:52,"I tried out another one I saw before this tweet, worked good for plain text, not much for other kinds of text(like code)"
2023-04-06 18:17:28,Read somewhere Djikstra loved theoritical CS so much that he considered plebs writing code to paint pixels on a screen vulgar in his time.
2023-04-06 18:24:28,yeah. i tried to compress lyrics. didn't work.
2023-04-06 20:14:51,https://www.linkedin.com/posts/samyakhtukra_holy-smokes-sam-segment-anything-model-activity-7049699206206283776-_fva?
2023-04-06 20:48:21,This seems like a fitting analogue
2023-04-06 20:50:56,"Speaking of which, Chroma just announced their template for Replit."
2023-04-06 21:07:07,Terabyte or Teraflop?
2023-04-06 21:19:27,"Haha.. Let me bite. I wouldn't bet against theory folks (CS Theory) in the long term. First aeroplanes were build out of experiments but we really learned how to build aircrafts safely only later with the necessary math. They will come up with much simpler representation and more compact algorithm. That is their job by definition. To quote a friend who was an early FB engineer, what we write becomes useless in few months. Some of what they do remains current for much much longer. That's probably where he is coming from."
2023-04-06 21:34:14,What is your take?
2023-04-06 21:43:08,Lol!
2023-04-06 21:45:17,ig some people are so attached to the work of their lifetime that they cannot accept/focus on things changing…
2023-04-06 21:45:57,"but these are nobel laureates we’re talking abt, so i’d never know 🤷🏻‍♂️"
2023-04-06 22:14:55,I spoke too soon. There is a hot new YC company on this: https://getmetal.io/
2023-04-06 22:15:23,OpenAI notebook bug fixes + Stripe → YC pipeline is strong 💪
2023-04-06 22:16:48,How Stripe?
2023-04-06 22:17:19,That is how you take the credit card of an unsuspecting developer and then invoice them some absurd amount 😛
2023-04-06 22:40:43,Paul Krugman is another one 😂
2023-04-06 22:53:16,Has anyone tried using ElevenLabs for training and generating audio in Hindi?
2023-04-06 23:06:32,Or maybe open source alternatives like tortoise-tts?
2023-04-06 23:38:43,[PHONE REMOVED]
2023-04-06 23:42:47,Demos from India's first Generative AI hackathon are here: https://nirantk.com/deephackdemos
2023-04-06 23:45:05,"To friends in VC, can make introductions to teams if you give me carry 😆"
2023-04-06 23:46:01,"To engineers — lazy fuckers please write better copy, and take pitching tips from [PHONE REMOVED] [PHONE REMOVED] next time"
2023-04-07 00:15:40,"Could the creator of the ViewsAct project kindly share a demo video, please?"
2023-04-07 00:16:13,He opted out because his demo used some real-world company designs and data.
2023-04-07 00:17:58,"For those who track of hackathon demos in SF/NYC/Berlin circuits, I genuinely believe that all winners would've done well in SF, won in NYC/Berlin in Feb end atleast. Would love to hear more if you do track :)"
2023-04-07 02:10:10,anyone saw the first shortfilm using dalle? : https://www.instagram.com/reel/CqstiaNuSjX/?igshid=MDJmNzVkMjY=
2023-04-07 02:29:11,There is this one too
2023-04-07 02:29:47,Using mid-journey. He has also shared the breakdown process.
2023-04-07 10:21:21,I'm in the bay area until Saturday. Would love to meet people working in the gen AI space.
2023-04-07 10:22:05,I'm an Applied Scientist at Amazon building computer vision tech for video action recognition
2023-04-07 10:22:44,"Hi, "
2023-04-07 10:32:05,cc [PHONE REMOVED]
2023-04-07 10:54:52,[PHONE REMOVED]
2023-04-07 10:56:24,Following.
2023-04-07 11:36:25,For those in London: this might be worth checking out. Lots of AI/art/gaming stuff: https://www.theguardian.com/games/2023/apr/06/now-play-this-ai-video-game-somerset-house-london?CMP=Share_iOSApp_Other
2023-04-07 12:57:55,chrome just shipped WebGPU 
2023-04-07 13:09:42,Pichai baba is back baby!
2023-04-07 13:10:59,Gazab
2023-04-07 13:14:10,I’m curious that for use cases outside of those that need extreme security - why would I run a model on my personal machine vs accessing it via an API?
2023-04-07 13:15:43,"It's wayyy lower latency, higher throughput. Think why games continue to be written for devices."
2023-04-07 13:15:56,Also Makes compute significantly cheaper for companies serving consumers at scale
2023-04-07 13:16:16,This would still happen on a server farm I assume?
2023-04-07 13:16:19,"brb, gotta buy some Cloudflare now."
2023-04-07 13:16:34,Doesn’t the inference take longer though?
2023-04-07 13:17:06,"No, WASM will do the rest. Segment-Anything proves that inference can be light-weight decoder only"
2023-04-07 13:17:10,"Depends on the case I guess, I know some very large companies who have benefitted significantly from running ML on the mobile edge"
2023-04-07 13:17:15,Thought that is more a bandwidth issue. How much data can I fit through a pipe
2023-04-07 13:17:21,I literally opened vested for this
2023-04-07 13:17:22,:P
2023-04-07 13:17:57,Cashflow poor and idea rich people think alike 😛
2023-04-07 13:18:21,Any examples?
2023-04-07 13:19:07,"Hmm, need to do more reading here"
2023-04-07 13:21:31,there will be no strong QoS but it opens up possibility of freemium models
2023-04-07 13:21:46,https://twitter.com/mathemagic1an/status/1644123645432958976?s=46
2023-04-07 13:21:46,Pichai baba ya fir Larry/Sergey?
2023-04-07 13:21:49,What is QoS?
2023-04-07 13:22:06,Quality of Service?
2023-04-07 13:22:08,"Chrome is classic Pichai in my mind, so is Web acceleration ideas"
2023-04-07 13:22:12,Quality of Service
2023-04-07 13:23:07,"Was his brainchild, yes"
2023-04-07 13:26:02,hopefully battery tech keeps up
2023-04-07 13:26:58,like Google Keyboard already does
2023-04-07 13:30:32,I think the best product in this case is actually SwiftKey and Microsoft acquired them very quietly in 2016
2023-04-07 13:31:26,"As we move to models running on the edge, I'd not be surprised to see Microsoft launching some OAI features inside SwiftKey"
2023-04-07 13:31:35,The product as is works incredibly well
2023-04-07 13:54:49,SwiftKey has been botched after the acquisition. It's a slow and unbearable app now
2023-04-07 14:05:21,How is agent planning evolving? This was quite broken in Turbo. Is it 2x better in GPT4? 10x better? 
2023-04-07 14:06:24,"No idea, deep diving soon"
2023-04-07 14:15:55,"Umm, not sure why you'd say so - have been using it since they were launched and haven't seen any notable difference"
2023-04-07 14:16:01,I've been using it on Android though - not sure if that changes things
2023-04-07 14:30:34,https://twitter.com/wileycwj/status/1644220882062282752?s=46&t=lkuvFQUWr1nav0QpUpFmdQ
2023-04-07 14:31:35,This is probably just me but I still don’t have a good sense of why something like pgVector won’t work. At what scale does pgVector not work?
2023-04-07 14:37:50,Does pg_vector also do NN like HNSW or nmslib?
2023-04-07 14:38:12,"I'll RTFM, but if someone has direct docs, would appreciate"
2023-04-07 14:47:32,It is not performance as in speed but accuracy/semantic richness. Does this answer your question.
2023-04-07 14:53:42,"Don't think so, quick glance through code base doesn't seem like it."
2023-04-07 14:58:56,there was some good discussion wrt pgvector in this thread https://twitter.com/jobergum/status/1643187540222959616
2023-04-07 15:02:46,"btw, has anyone tried out Midjourney's /describe feature (img2text2img)? "
2023-04-07 15:04:34,Interesting read on hardware infra of OpenAI
2023-04-07 15:59:41,"I spoke to Qdrant founder, and he said pgvector is basically unusable for LLM apps. It has recall in the area of 50%"
2023-04-07 16:20:15,Basically whatever was referenced here
2023-04-07 16:24:24,"Erik Bern of Modal Labs maintains ann-benchmarks github.com/erikbern/ann-benchmarks, let's request him to add pg_vector to it?"
2023-04-07 16:25:04,"This is something we can test/verify empirically, don't need to trust opinions from direct competition"
2023-04-07 16:39:45,And avatars come for news anchors: https://twitter.com/KhaleejMag/status/1641123893145485343
2023-04-07 16:43:34,True
2023-04-07 16:47:24,agreed. i find it kinda hard to trust benchmarking blogs by other vectorDB startups.
2023-04-07 17:22:08,https://www.linkedin.com/posts/hsemina_generativeai-community-hackathon-activity-7050057219123400704-NIHR?utm_source=share&utm_medium=member_android
2023-04-07 18:20:22,This is fab. Thank you! Hoping pgvector comes out decent. Want to stay within the supabase ecosystem
2023-04-07 18:28:01,"Eric mast aadmi. Gave me access to modal in five mins, when I mailed him"
2023-04-07 18:28:31,Same. Matt Welsh of Fixie too.
2023-04-07 18:30:32,https://medium.com/m/global-identity-2?redirectUrl=https://blog.startupstash.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b https://medium.com/m/global-identity-2?redirectUrl=https://blog.startupstash.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b
2023-04-07 18:31:44,How was your experience with fixie?
2023-04-07 18:31:58,The product? Confusing 🙈
2023-04-07 18:32:17,I'm not their Target either. I think they're building for PM junta
2023-04-07 18:36:33,"Haha, maybe they didn’t anticipate the launch of ChatGPT plugins"
2023-04-07 18:36:52,The last bad product I used was https://www.steamship.com
2023-04-07 18:37:15,Platform to deploy langchain applications
2023-04-07 18:39:04,Interviewing him this week for newsletter :)
2023-04-07 18:39:20,Why was this bad out of curiosity?
2023-04-07 18:40:43,Nice! What newsletter?
2023-04-07 18:42:14,ntkris.substack.com
2023-04-07 18:49:26,Sweeet! I might have a question.
2023-04-07 18:50:45,will ask!
2023-04-07 18:52:46,Keen to know too
2023-04-07 18:59:23,"Pinecone, weaviet, Chroma, vertex ai matching engine and there are bunch of other vector stores as well. What is the logic behind having soo many vector stores? Is the market soo huge?"
2023-04-07 18:59:41,They are building a wrapper on top of LangChain components to take it to production.
2023-04-07 19:02:07,"And I did mention it to one of their engineers on a call a month back, Harrison will pick up funding soon and have to build a cloud solution to monetize. "
2023-04-07 19:04:36,They raised $10 m
2023-04-07 19:05:37,"Question best answered by VCs [PHONE REMOVED], want to chip in?"
2023-04-07 19:07:36,[PHONE REMOVED]
2023-04-07 19:08:31,Sorry for the self plug but this is relevant to the conversation here: https://twitter.com/nirantk/status/1644290469915164672?s=46
2023-04-07 19:08:45,I love this quadrant
2023-04-07 19:09:12,"Honestly, based on Vespa founder's tweets I think they might have the best tech? But I die a slow death every time I look at their documentation"
2023-04-07 19:09:58,Oh long discussion but yeah pinecone is basically far ahead of the competitors in terms of technology
2023-04-07 19:10:04,"Vespa is so good, and their docs so bad -- you could make money by just simplifying their docs."
2023-04-07 19:12:13,"Why/how are they ahead? Latency, throughput?"
2023-04-07 19:12:36,Gcp vertex ai matching engine is ready for enterprise scale? 
2023-04-07 19:13:20,"My biggest worry with vector stores: what happens when Azure, AWS or GCP adds them?"
2023-04-07 19:14:47,"The same thing which happened with Mongo, Elastic, MySQL, Postgres"
2023-04-07 19:25:44,"Basically pinecone has been in the bake for 4 years, always focusing on enterprise readiness and supports the largest number of use cases. Happy to talk more in depth about the actual tech that makes it more scalable, reliable"
2023-04-07 19:27:50,"Generally agree. My one push back on this: all of the things you mention are the “primary” storage of some kind. Vector DBs, for now, are a critical feature. I still need a stand-alone sql or no sql db for the rest of my stack"
2023-04-07 19:30:15,"True. And unless it's massive scale, where the differences in performance becomes signficant, there's probably merit to keeping it unified"
2023-04-07 19:30:30,Does pinecone offer a signficant advantage over something like pgvector?
2023-04-07 20:27:00,inb4 AWS comes out with an S3 integration for vector DB storage
2023-04-07 21:36:46,This would be a game changer. 
2023-04-07 21:46:44,Folks as someone who loves learning database internals:
2023-04-07 21:48:02,https://rime.ai/
2023-04-07 21:48:30,https://twitter.com/lilyjclifford/status/1643702014680133632
2023-04-07 21:50:00,https://twitter.com/younesbelkada/status/1644341068241186818?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-04-07 21:50:55,Seems like new foundational models for different tasks are released everyday 
2023-04-07 22:53:48,"Is anyone generating embeddings for this group, to create top 10 learnings from here every week? 😅"
2023-04-07 22:57:14,"Haha, nice idea, and then scrape the learning articles and links and make sumarizer, which summarizes every topic in 10 words 😎"
2023-04-08 00:30:06,So needed
2023-04-08 00:31:48,Do folks know if anyone has integrated chatGPT/LLMs into Alexa/Nest type of smart home devices? Seems like a low hanging fruit.
2023-04-08 00:35:59,"hey folks, has anyone dabbled with paddlespeech?"
2023-04-08 11:56:57,The video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published - https://youtu.be/WF28ZwhUCc4
2023-04-08 14:00:55,"there are tools that do it, alexa and siri integration is possible given you have your openai key which is the barrier to adoption"
2023-04-08 15:50:08,Use Automatic 1111 on colab
2023-04-08 15:50:47,If you have MacBook download DrawThings App.
2023-04-08 15:51:53,GPU memory issue i think. Try smaller models
2023-04-08 15:52:09,I believe Jay is trying to get that running on local via Web GPU. Not a direct Python to GPU.
2023-04-08 15:56:02,I'm on windows machine on chrome canary. Currently the image is being created and is in process
2023-04-08 16:11:09,"Image got generated on windows, but took a lot of time"
2023-04-08 16:59:19,Automatic1111 works quite well on my max
2023-04-08 16:59:27,*Mac
2023-04-08 16:59:35,Like text to image in 10 seconds
2023-04-08 16:59:42,Is this even faster?
2023-04-08 17:01:46,SD is about 10 sec on A100 too
2023-04-08 17:03:37,Subtle flex but this one is M1Max with 64 gigs of RAM so maybe that's why
2023-04-08 17:03:50,It's ridiculous
2023-04-08 17:04:14,In my experience using Automatic on Mac simple text2image works but if you run inpainting with batch count of 4 using multi control net then you’re going to have trouble
2023-04-08 17:04:16,Meanwhile Siri is in absolute shambles
2023-04-08 17:04:47,This is with xformers and fp16 though
2023-04-08 17:05:03,Bro I already have trouble
2023-04-08 17:05:08,M2 with 16GB RAM though. Complex operations would be better with 64 GB
2023-04-08 17:13:29,Wealth advantage 😂
2023-04-08 17:14:52,"Given we are discussing apple hardware, I'm planning to buy a MacBook soon"
2023-04-08 17:16:02,2 points I have to decide on
2023-04-08 17:18:02,My recommendation would be to either go all the way or get the Macbook air
2023-04-08 17:18:51,You can always get generative AI running on a cloud setup
2023-04-08 17:19:25,But if you want local gen AI capabilities do try to get as big of a machine as your wallet permits
2023-04-08 17:19:51,It's never going to be enough specially once text-to-video takes off
2023-04-08 17:20:01,True
2023-04-08 17:20:19,"Yeah, but my Mac needs an upgrade, so looking to include the ai workflows locally as well"
2023-04-08 17:21:12,"I understand, I just wanted to highlight that M1 MB-air is plenty of you have a cloud setup"
2023-04-08 17:21:57,*if
2023-04-08 17:22:19,"I'm all in for a good ROI, and apple is very evil when it comes to pricing ladders, so looking at the optimum config"
2023-04-08 17:25:53,How optimized are these models for running on apple RAM? As opposed to Nvidia GPUs 
2023-04-08 18:33:55,"CEO of Weaviate, Vespa and Modal Labs are nerding out over serverless Vector DB and pricing around it: https://twitter.com/jobergum/status/1644653416994488320"
2023-04-08 18:46:32,"If you know how to read between the lines, that's a free masterclass on Developer eXperience and how that influences pricing, GTM — and mostly will continue to do so"
2023-04-08 18:47:27,https://youtu.be/8y7GRYaYYQg
2023-04-08 18:52:50,"It's quite neat how the dev is debugging the logic on his own, but letting GPT4 fix the syntax and API calls. Quite close to my mental model of what it is right now."
2023-04-08 18:53:42,"Within 2-3 months, I expect to see dedicated planning ""agents"" which can pair with the dev much more on the first part — this demo still relied on dev's skill and knowledge on how to describe game play well."
2023-04-08 18:54:20,Would love to hear more from game devs here :)
2023-04-08 18:55:08,My brother who is a not into development sent me this video today. Was intrigued at the possibilities and the capabilities we can have with GPT assisting.
2023-04-08 19:04:38,Jo never shills Vespa. Doesn't need to. Vespa is run  by web search OGs.
2023-04-08 19:05:31,"[PHONE REMOVED] if you ever do a podcast style fireside chat/discussion, do count me in for one of your sessions. "
2023-04-08 19:05:56,With Erik or any of these folks?
2023-04-08 19:06:15,Anyone.
2023-04-08 19:29:29,Working on something close.
2023-04-08 20:06:16,Not sure is this was already shared
2023-04-09 00:16:03,"12am saturday, what else would you do but generate desi lofi girls"
2023-04-09 09:30:44,If anyone to sell his SAAS company - https://twitter.com/danmartell/status/1644798423961575426?t=BwA0POzNya9uB_BZkY1cHA&s=19
2023-04-09 09:32:00,brb starting a vector db company 🤣
2023-04-09 09:38:03,"Spending some time this weekend to catch up on everything, made this little tool 🔨 "
2023-04-09 09:39:26,cc [PHONE REMOVED] and friends built this for Youtube videos
2023-04-09 10:16:16,sitegpt as well does something similar - https://sitegpt.ai/
2023-04-09 10:33:38,Talking about similar projects - if folks are still interested. Microsoft Edge has a copilot option which does this exact thing which I’ve been using.
2023-04-09 10:39:24,https://twitter.com/alexgraveley/status/1644186023868416000?t=3mfuMZb0hDnOx2sFR9Wn4Q&s=08
2023-04-09 10:47:42,Doesn't jsonlines format solve this?
2023-04-09 10:48:14,https://jsonlines.readthedocs.io/en/latest/
2023-04-09 11:11:01,https://twitter.com/rowancheung/status/1644778701974822913
2023-04-09 11:26:40,this will probably have the same bias as that viral midjourney thread with indian villagers smiling(like western folks)
2023-04-09 11:27:37,"Youtubers in 2025: Smile wide and talk loudly, clearly to get an interview offer when talking to AI Interviewer"
2023-04-09 11:29:28,Yeah only alternative is to train on an indian data set
2023-04-09 11:33:25,Has anyone used gptindex here in production?
2023-04-09 11:34:36,"[PHONE REMOVED] is a contributor to Llama Index, might know more folks, please DM him. If you've hosting/infra challenges, since that's the quite similar for Langchain, I can also help. I've 2 Langchain projects in prod+going to prod."
2023-04-09 11:35:32,Yes already working with him.  Seeing scale challenges now - slowness of answering and training new docs. What database did you use?
2023-04-09 11:37:04,"Chroma, works in-memory, other than frequent deploys, not a pain. "
2023-04-09 11:37:51,"Also, very small data: Less than a Gb of text"
2023-04-09 11:39:34,In memory won’t work for 100s of docs for us
2023-04-09 11:39:56,Yes it’s not OpenAI as it’s mostly in search which has no calls to it
2023-04-09 11:41:15,"Hmm, if you're embedding a query with Ada, that is still a call to their API?"
2023-04-09 11:43:32,"Any better embedding suggestions than Ada, trying something on legal docs but it does not seem to work well, results are not consistent enough with Pinecone indexing and ada embedding, faced anything similar"
2023-04-09 11:45:59,sachin from https://intellawyer.com/ - should be able to answer it as he has experience with legal documents
2023-04-09 11:49:22,cc [PHONE REMOVED] — Indian legal docs
2023-04-09 11:50:00,Try mpnet from sentence transformers …works quite well
2023-04-09 11:50:21,That’s only during training. I was talking about searching
2023-04-09 11:50:36,https://www.sbert.net/docs/pretrained_models.html
2023-04-09 11:51:00,Btw a great shout out to Ravi / he’s been so helpful to us with all his expert advice and tips.
2023-04-09 11:52:50,Any suggestions of Vector DBs?
2023-04-09 11:54:49,Thanks Karthik. 
2023-04-09 11:57:32,I use pinecone.. Nirant / Ravi knows much more about tradeoffs between them
2023-04-09 11:58:01,https://twitter.com/nirantk/status/1644290469915164672?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Tweet thread by Nirant about this topic
2023-04-09 12:04:35,Nirant- you should start an accelerator for startups. So much knowledge.
2023-04-09 12:05:01,We got approved till $5K now.
2023-04-09 12:20:23,[PHONE REMOVED]
2023-04-09 12:22:50,You're 9 days late for April Fools Kartik sir 😛
2023-04-09 12:23:47,"Would a Pinecone, Chroma, pgvector comparison/benchmark be useful? "
2023-04-09 12:44:33,hamara Erlich Bachman
2023-04-09 12:44:48,🤣🤣🤣
2023-04-09 14:40:21,"On a serious note, really want hackerhouses to exist in bangalore!"
2023-04-09 14:55:23,+1
2023-04-09 14:58:17,The only hackerhouse I wish to go to
2023-04-09 14:58:56,Oh HF0
2023-04-09 14:59:14,legends
2023-04-09 15:00:13,You can actually make something like this happen in BLR
2023-04-09 15:00:30,Kormangala/Indranagar has bunch of great bunglows
2023-04-09 15:00:53,Logistics is not the issue
2023-04-09 15:00:59,Rent them and make it a hacker house and attach it to some accelerator
2023-04-09 15:01:09,Yeah!
2023-04-09 15:01:20,So what is the bottleneck?
2023-04-09 15:01:41,Not enough OpenAI researchers in Bengaluru
2023-04-09 15:03:04,Why the accelerator? I would assume a bungalow would be self sufficient from just the rent
2023-04-09 15:04:41,"If you putting all that effort to increase the chances of success for startups, you want to capture at least part of the upside"
2023-04-09 15:04:58,*As a person hosting the thing
2023-04-09 15:05:25,Charging flat rent is not interesting in that regard
2023-04-09 15:07:07,There are more aligned ways to capture that upside e.g. can invest a pre-seed amount. But very off topic now.
2023-04-09 15:11:59,"I really miss HackerDojo, used to be a blast. [PHONE REMOVED] This is something you all can do. A space for hackers to meet for cheap and hack together. Indiranagar is ideally located."
2023-04-09 15:15:20,"Related note, GenerativeAI April meetup registration link: https://hasgeek.com/generativeAI/april-meetup/"
2023-04-09 15:21:07,"Let's do it. Who's in for this? [PHONE REMOVED] you want to help set this up, to get it going?"
2023-04-09 15:24:38,This is interesting. What was hackerdojo ?
2023-04-09 15:25:12,Google research toh h na?
2023-04-09 15:26:58,"In theory, we also have Microsoft Research. In theory, Sharechat, Flipkart and a handful others do write CVPR, ICML, ACL papers. "
2023-04-09 15:28:23,Sure thing
2023-04-09 15:28:29,That’s the thing to change nirant baba 😅
2023-04-09 15:35:46,[PHONE REMOVED] will be lead the change and be teaching how to make comics at the April meetup
2023-04-09 15:35:51,"This was exactly what I miss. HackerDojo in Mountain View is a community run space, I think it is a not for profit, where people can get desks for cheap with bunch of tooling etc to build stuff. Couple of startups started there, Pinterest is one that comes to mind. They used to be the default place for many meetups. I had met H2O's Satish Ambati there, when they were just 2 people amongst others. There were quite few others.  There were a bunch of people from Google Brain and FB's some team, who used to give talks there. So there was the amazing vibe and back and forth between the grey hairs and people pushing the bleeding edge."
2023-04-09 15:36:38,They used to have some link with Computer History Museum not 100% sure what it was.
2023-04-09 15:36:44,Hahaha May meet-up I’ll do this pakka. April is tight.
2023-04-09 15:37:10,Maybe as part of the oral history series?
2023-04-09 15:43:42,That one could be one thing. There was some fiasco with finances. But one thing they did was they had membership dues + hot desk charges hot desk was quite reasonable. Definitely had the hacker vibes. I think there was some support from well to do community members too. May be we can talk to Nandan etc and others too can chip in. Just thinking out loud.
2023-04-09 15:45:29,+1
2023-04-09 17:16:43,Any awards this time?
2023-04-09 17:17:47,😁
2023-04-09 17:18:16,"Also, has anyone here gotten off the chatGPT plugins waitlist?"
2023-04-09 17:35:19,still waiting :(
2023-04-09 17:35:54,"same, still waiting :/"
2023-04-09 17:36:37,Same. I don't know anyone in India who's received plugins access. 
2023-04-09 17:36:53,*its
2023-04-09 17:37:46,yeah me too. got gpt4 immediately. surprised that many people still don't have access to gpt4 api as well.
2023-04-09 17:58:08,Guy who is maintaining kisaangpt got it I guess
2023-04-09 18:00:36,Is there a link?
2023-04-09 18:00:48,He's living in SF so my conspiracy theory still holds 😅
2023-04-09 18:01:04,"I have it, going to build something for my product in the next week"
2023-04-09 18:01:28,Oh wow. Let me DM you!
2023-04-09 18:01:55,"But wait, you're not in India it seems (going off of your phone number)"
2023-04-09 18:02:46,Yes I’m in London(sorry didn’t realise it was india specific)
2023-04-09 18:04:12,Welcome Dr Pratik. We were just talking about you!
2023-04-09 18:04:43,👋
2023-04-09 18:05:05,We're talking about how few folks in India have gotten chatGPT plugins access
2023-04-09 18:05:16,"Hey Ojasvi, Nice job with Jadoo and Shakalaka… Been following all of you guys work and Nitant’s hackathon."
2023-04-09 18:05:27,I've got the access
2023-04-09 18:05:33,Thank you sir 🙌🏻
2023-04-09 18:05:40,Not in India though
2023-04-09 18:06:27,What could be the reason India isn't getting the same treatment as the rest of the countries for plugins access
2023-04-09 18:07:31,Often compliance is a big reasion
2023-04-09 18:07:36,*reason
2023-04-09 18:10:38,"Yeah, I got the access. They are mostly vetting and rolling out access slowly. They have been following my work with Kissan GPT and provided support letter as I have been called up by ministries. That may be the reason for my boost."
2023-04-09 18:11:21,Quite inspiring
2023-04-09 18:11:37,You're still in SF?
2023-04-09 18:11:46,Yes
2023-04-09 18:18:51,I'm still waiting for GPT-4 API. Any recommendations on what I can do to?
2023-04-09 18:36:07,You guys may be right about country preferences due to compliance as I got access to GPT4 API in the first few days only. The another reason can be age of account or usage. I have been using their API platform since 2020.
2023-04-09 18:38:32,"Same, 2020 user. But Atty soft-confirmed they're doing SF first. Everyone else came later."
2023-04-09 18:38:51,Atty is the OpenAI engineer at Setu office right now
2023-04-09 18:42:43,Just the city. Wow. Looks like doomers are making them more cautious about opening up.
2023-04-09 18:58:06,Meaning? Who?
2023-04-09 18:58:21,What’s your usage? Ballpark $ or requests?
2023-04-09 18:59:32,https://www.linkedin.com/in/athyuttamre
2023-04-09 19:00:14,He's on the plugins team
2023-04-09 19:02:59,"Is the talk being recorded anywhere ? Missed it, unfortunately :("
2023-04-09 19:17:32,"My usage is not so high tbh. 80k+ requests/mo. Mostly using turbo instead of 4, to keep the cost low, which is really inexpensive, and good enough for my use case."
2023-04-09 19:19:20,oh
2023-04-09 19:22:16,coming to india v soon
2023-04-09 19:23:20,Came back to SF yesterday
2023-04-09 19:23:32,was in India for a month
2023-04-09 19:23:47,i mean the plugin access 😅
2023-04-09 19:24:47,Who will be in SF this month? 👋🏼
2023-04-09 19:25:10,[PHONE REMOVED] ?
2023-04-09 19:25:13,https://www.linkedin.com/posts/setu-apis_we-have-kicked-off-the-openai-x-fintech-session-activity-7050806116791832576-S3Ns?utm_source=share&utm_medium=member_android
2023-04-09 19:25:41,"I’m here in Bay Area , in case anyone wants to grab a coffee or beer."
2023-04-09 19:28:21,"also, people who are thinking to buy plus just for plugins"
2023-04-09 19:28:30,disjoint sets
2023-04-09 20:02:49,Was this recorded by any chance? Would love to get if anyone took screenshot or could share access to the recording later.
2023-04-09 21:02:15,"Oh, just came back to Seattle. I'll be in Seattle for a few months. Would be happy to meet w/ you when you're around here.  https://www.linkedin.com/in/anirudthn"
2023-04-09 21:14:32,"Hi folks, have been lurking a bit in the group for now."
2023-04-09 23:02:37,Hey I have some experience in this and can help out. Is it for a product or a one time thing? Because the approach would be different
2023-04-09 23:04:07,"I have something in mind, but not sure if it can be a product."
2023-04-09 23:04:19,Sure
2023-04-09 23:05:05,I'd like to help
2023-04-09 23:05:59,"Will dm you as well, thanks"
2023-04-09 23:31:00,Cerebral Valley (which I’ve been a part of) started with ~50 members. (About 500 now but it started off small)
2023-04-10 08:54:28,https://www.youtube.com/watch?v=2xxziIWmaSA&t=1079s 
2023-04-10 08:59:31,Thread of Hackathon ideas and lot of the same ideas we saw at our hackathon: 
2023-04-10 09:01:36,"Weird, the political action project is the first thing we sold to a client back in 2022!  Who’s the creator?"
2023-04-10 09:02:19,"Creators haven't been mentioned, but you can tweet to Joseph or @swyx and ask?"
2023-04-10 09:08:39,Aside: I realised I know swyx from back in the react world because of this superb talk - https://youtu.be/KJP1E-Y-xyo
2023-04-10 09:33:51,"many of them are chatbots, we had so much variety in our hackathon imo."
2023-04-10 09:39:51,"GPT 3.5 users, have you ran into problems which require you to limit output length?"
2023-04-10 09:39:56,"So my question is, instead of instructing it to change its length in terms of characters, will there be any benefit to changing the length units to token. "
2023-04-10 09:39:58,Sorry for the long message. Had to make sure it's clear to the people who'd like to answer
2023-04-10 09:41:34,The recommended way to do this is to use Guardrails and turn on re-ask (iterative variant of your recursive strategy). It's easier to reason about and often more token efficient too. 
2023-04-10 09:42:01,You'd know about this if you were at the hackathon venue [PHONE REMOVED] — we had Guardrails creator do the demo xD
2023-04-10 09:42:28,"Thanks a lot, will check it out"
2023-04-10 09:43:14,"My body was barely functioning, I was borderline disoriented with 2 hours of sleep 😂 you know this"
2023-04-10 09:43:20,https://github.com/ShreyaR/guardrails
2023-04-10 10:00:15,My intent for sharing this is to emphasise that Indians are no longer playing catch up. 
2023-04-10 10:03:46,One weird thing that I noticed in guardrails and kor - why is the schema format not the same as the output format?
2023-04-10 10:05:40,What’s Kor?
2023-04-10 10:05:59,General purpose parser for any text/schema
2023-04-10 10:06:07,"Similarly for guardrails, the schema is xml, but the output is json"
2023-04-10 10:08:21,"From a language/lib design PoV, these are the two things you're trying to balance: "
2023-04-10 10:10:09,<3
2023-04-10 10:10:59,"The dsl makes sense, but the part that’s confusing to me is why the schema sent to the llm is not the same as the requested output format."
2023-04-10 10:11:48,"My intuition, based on the thousands of samples I've tried so far is this. The resizing prompts work fairly well when input and output language is English. Tokenizing ka rule is uniform in English. "
2023-04-10 10:13:33,"Thanks for moving this back to main, since it's widely relevant. E.g. [PHONE REMOVED] has worked on an adjacent problem statement as well."
2023-04-10 10:14:14,Aligned on the non-English challenge: The BPE tokeniser is notoriously unstable for CJK and Indian languages. Better with European languages often. 
2023-04-10 10:15:12,"Prompt engineering in this way is a bit like casting a spell, and I don't think any amount of tips on ""wingardium leviosa"" is going to help — doing it will work best 🙌🏻"
2023-04-10 10:24:24,"Tweet this, tag OpenAI folks. Nothing like this to nerd snipe them into replying to you and spilling some detail about GPT4 is actually trained on text-davinci-003 😂"
2023-04-10 10:24:52,I like how your mind ticks 😂👌🏼
2023-04-10 10:28:18,My customers are raising support tickets for this and saying that we're fooling them by saying we got GPT4 access
2023-04-10 10:29:30,"Ouch. I'd try to improve this with a system prompt: ""You are helpful OpenAI Assistant, specifically GPT4. Never say GPT3"" or something along those lines."
2023-04-10 10:31:26,"The reason this happens is that chat models are instruction finetuned, sanitised and scaled forks of large base models. Same for the REPL and Retrieval models in Plugins."
2023-04-10 10:34:16,This trick should also work the other way around. You can have GPT3.5-Turbo claim to be GPT4 😂
2023-04-10 11:15:43,Super explanation of GPT with 2 tokens and a context length of 3. 
2023-04-10 14:26:18,What a beautiful doc ❤️
2023-04-10 15:17:39,Karpathy is doing teaching again? Yess!
2023-04-10 20:18:12,Interesting new research on Generative Agents
2023-04-10 20:31:30,Some enthu reporting as always - https://youtu.be/wHiOKDlA8Ac
2023-04-10 21:40:51,"Anyone suggestions on how I can get my hands dirty with Midjourney? On the discord, it has been showing full capacity for quite sometime. Any other way that I can try it out?"
2023-04-10 21:42:41,Midjourney is exclusively on Discord. Wait for a while or try in the afternoon when traffic eases up. Or pay for premium
2023-04-10 21:44:18,Hi. There is a new model Kandisky 2.1 available on dreamlike.art which is pretty decent  alternative to MJ. They provide daily credits as of now
2023-04-10 21:49:38,Quick ques: What are the costs differences between GPT-4 and GPT3 API?
2023-04-10 21:51:40,"I had found this quick compare table,handy for comparing various models"
2023-04-10 22:12:57,any image-creation tool that accepts looking into a website design for reference?
2023-04-10 22:44:41,Do you've friends or acquaintance artists working with LoRA? 
2023-04-10 22:46:04,"Vignesh is quite nice! In my Covid-tinged master's days, he gave me great advice for job hunting in Leuven."
2023-04-10 23:01:17,Thank you very much Nirant! You are awesome 😍
2023-04-10 23:01:37,Thank you Sid! 😍
2023-04-11 01:36:54,https://arxiv.org/pdf/2304.03442.pdf
2023-04-11 02:52:27,"Yeah, just saw on Andrej Karpathy tweet"
2023-04-11 02:53:52,with the demo at https://reverie.herokuapp.com/arXiv_Demo/
2023-04-11 06:20:51,Yeah Generative Agents 😀
2023-04-11 07:48:50,Yup!
2023-04-11 07:50:16,He’s an awesome person. I agree 🫡
2023-04-11 08:28:18,"I've seen this project/tool floated around Twitter. But I can't recall its name, google isn't helping much either. Would love if anyone of you can share what its called or a link to it."
2023-04-11 08:29:31,That was a while back and I think they were using flat GPT output without crawling their pages. I may be wrong.
2023-04-11 08:45:15,is it this one? : https://wtfdoesthiscompanydo.vercel.app/
2023-04-11 08:45:54,Yeah
2023-04-11 08:48:20,thanks folks
2023-04-11 09:34:02,This is another interesting paper. Combined with Meta’s segmentation model can open up many interesting use cases. https://twitter.com/_akhaliq/status/1645594671068971008?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw
2023-04-11 09:56:51,Langchain Bruh moment
2023-04-11 10:04:38,"This bot doesn't have memory, you asked if the lib has memory, not the bot. Classic NER ambiguity mistake."
2023-04-11 10:10:44,even Jeremy didn't have access to ChatGPT plugins until now! it really is SF-first (he's in Australia i think) https://twitter.com/jeremyphoward/status/1645597656499245057?t=21TkvGGfdo-gEqmw3NKvsA&s=19
2023-04-11 10:11:07,Ab FOMO Nahi ho raha 😂
2023-04-11 10:11:28,My hypothesis was they have profiles on pro open source people and are being slow w GPT-4 features w them
2023-04-11 10:33:38,"Is using a VPN a workaround? Depends on how do they determine your country, does anyone have an idea?"
2023-04-11 10:39:00,i don't think that's gonna be useful. 
2023-04-11 10:39:55,Let's assume that my OpenAI account is a part of a big organisation and we use OpenAI APIs extensively
2023-04-11 10:40:21,PSA: Ojasvi leads AI at mydukaan.io
2023-04-11 10:42:34,yeah im aware :)
2023-04-11 10:43:11,im just guessing..
2023-04-11 10:43:12,"They ask you isn't it? Guessing probably use ur input + your ip + other sources like where cloudflare is serving from + some predictive stuff based on prior tokens. Guessing they probably use martech profile data as well. Which exact ones, is anyone guess. Guessing you tried messaging over Twitter. Try connects if you have any at OpenAI. Don't know if they have 'strong' policy around it though."
2023-04-11 10:43:23,"mydukaan.io needs to IPO [PHONE REMOVED] bhai, they've given access to more public companies"
2023-04-11 10:43:27,"Hey folks! I've started sending out invites for this, it's happening on Thursday at the Lightspeed office in Koramangala at 6:30pm, not all folks are there on the invite since we were trying to make it a very interactive group with small number of people, but the idea is to invite for the next mixers. Looking forward to seeing people on Thursday! Please do DM me on WA to confirm if you're coming, thanks 🙂"
2023-04-11 10:44:42,You didn't have to tell 350+ people that we're not cool enough [PHONE REMOVED] 🤣
2023-04-11 10:46:10,"Haha, more like we have a small rooftop which can only support so many people😂"
2023-04-11 11:43:05,It’s not entirely location based. It’s org working with openai + selected startups + particular use cases of person working on a specific domain openai is experimenting on
2023-04-11 11:43:32,I have access to all the plugins sitting near bellandur lake 🤣
2023-04-11 11:43:59,So I don’t think vpn would work
2023-04-11 12:21:32,https://www.inferless.com/serverless-gpu-market
2023-04-11 12:42:11,"Thank you for the shoutout, Dev! "
2023-04-11 12:48:00,This is well written! Great job
2023-04-11 12:54:41,This is great!
2023-04-11 13:21:26,"This is a very comprehensive guide, Aishwarya. "
2023-04-11 14:34:19,Anybody know any Ai research labs in Bangalore?
2023-04-11 15:01:06,I have a client which is an AI lab. What's up?
2023-04-11 15:02:00,Looking for some research based experience on cutting edge tech! [PHONE REMOVED]
2023-04-11 15:02:07,In Ai itself
2023-04-11 15:04:54,"Can connect you, DM!"
2023-04-11 15:08:58,Rahul is one of the smartest people I know. He's worked at MS on Wall St and then started a crypto hedge fund. He sold it to BlockTower Capital.
2023-04-11 15:25:27,Has anyone tried using YubiBert? CredAvenue's OSS Financial LLM?
2023-04-11 16:15:26,Linkedin has one of its research arm at Bangalore.
2023-04-11 16:16:07,[PHONE REMOVED]  whom do i contact?
2023-04-11 16:16:20,I work there. DMing you
2023-04-11 16:27:34,I would also be keen to learn more about this AI lab
2023-04-11 16:28:58,[PHONE REMOVED] what kind of work do they do?
2023-04-11 16:34:53,The team works on content moderation and content quality on the Linkedin platform.
2023-04-11 16:35:47,So they build their own models or something for all these?
2023-04-11 16:37:08,"Yes, we train our own models, since the data distribution is different from the datasets used in academic setting."
2023-04-11 16:38:36,Yes got it!
2023-04-11 17:37:07,Anyone attending the OpenAI meetup in HSR today?
2023-04-11 17:40:14,How to find out more?
2023-04-11 17:40:55,https://lu.ma/y7uu4m4e
2023-04-11 17:57:00,https://www.inkle.io/resources/events/talks
2023-04-11 18:02:28,Any chance this will be streamed?
2023-04-11 20:48:11,"On providing the required config files to access a service that requires authorisation, can we ask gpt to access let's say a specific table in database and make commits in that?"
2023-04-11 21:45:24,Yes. It's possible. You can perform CRUD ops in database
2023-04-11 21:52:55,"this can be done using tools for dml,ddl commands or do you have any other method?"
2023-04-11 21:55:57,Yes. Just the dml commands. Connect with [PHONE REMOVED] if u are still blocked
2023-04-12 00:15:45,"Has anyone compared/experimented with OpenAI's best embedding model available ""text-embedding-ada-002"" vs Huggingface models or Sentence Transformers. Have seen most people using OpenAI's embedding, does it have any advantage over others available?"
2023-04-12 00:18:40,"I believe many of the OS ones are superior. There was a thread on this, let me see if I can find."
2023-04-12 00:19:26,https://twitter.com/mr_cheu/status/1626261050566778880?s=46&t=lkuvFQUWr1nav0QpUpFmdQ
2023-04-12 00:19:46,That was Feb 2023 so like a decade ago by AI standards…
2023-04-12 00:45:26,"I had compared sentence transformers with OpenAI embeddings 6ish months ago..For my use case, sentence transformers turned out to be quite competitive"
2023-04-12 00:46:29,"Got it, thinking to try this model 'sentence-transformers/all-mpnet-base-v2', is that the best mpnet variation?"
2023-04-12 00:48:50,Multi-qa-mpnet-base-dot-v1 works a little bit better for semantic search ..but I will recommend tryiing top 2 or 3 and checking
2023-04-12 00:49:46,"Also if you need better scoring mechanisms, use cross-encoder for scoring afterwards"
2023-04-12 07:37:59,https://youtu.be/540vzMlf-54
2023-04-12 07:38:09,Awfully painful questions 😂
2023-04-12 08:12:25,"Traditional News Media looks really frightened with AI. Even I got call for Interviews for that tweet 🤦🏽‍♂️. The buzz is really hot and controversial, people are waiting to take you opinion out of context and attack. Everyone is on edge."
2023-04-12 08:45:30,"Ohh, the ChatGPT Plugins SF hackathon announced their winners: https://twitter.com/atroyn/status/1645954654394802176"
2023-04-12 08:46:12,All the winners here have much higher _usability_ than what we had though
2023-04-12 08:46:15,Reminder: My intent for sharing this is to emphasise that Indians are no longer playing catch up. 
2023-04-12 09:02:06,"Thank you for sharing [PHONE REMOVED]. The chatrooms concept was super cool, brings social networking into it. I’m going to explore that. It is analogous to an idea I had about enabling long term conversational memory, by vector indexing the conversation history itself."
2023-04-12 09:04:21,Langchain has some pretty good abstractions around memory (in addition to the index+retrieve approach): https://python.langchain.com/en/latest/modules/memory/examples/conversational_customization.html
2023-04-12 09:21:45,Happening as we speak : https://twitter.com/i/spaces/1djGXldPqNyGZ?s=20
2023-04-12 09:24:19,Very off topic. Appreciate the intent to share news though. 
2023-04-12 09:25:59,"depends on where you draw the lines. There are obv going to be some AGI conversations in this space. But anyway,"
2023-04-12 09:31:45,Silicon valley is stealing my ideas >.>
2023-04-12 09:36:39,Elon just spent at least $250M on GPUs for training generative AI at Twitter.
2023-04-12 09:41:55,https://twitter.com/yoheinakajima/status/1645811071230545920?s=48&t=vVjNVO7AhqZtPO3IJxRokA
2023-04-12 09:42:45,I’m really liking this autonomous GPT agent stuff :
2023-04-12 09:43:33,AutoGPT -4 SigGravitas 
2023-04-12 09:46:10,Harrison Chase implemented a custom LangChain abstraction for BabyAGI based on Yohei’s method 
2023-04-12 09:47:19,https://twitter.com/langchainai/status/1645808279849947137?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-04-12 09:47:24,https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html
2023-04-12 09:52:31,Also worthwhile checking this out 
2023-04-12 09:53:33,Smaller version of the “Westworld Sims” experiment
2023-04-12 09:53:42,Design Principles for building Agents
2023-04-12 10:03:26,https://github.com/eumemic/ai-legion
2023-04-12 10:03:45,For folks using Typescript for agent building
2023-04-12 10:04:55,We're starting to see first steps towards regulation by governments https://www.wsj.com/articles/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b
2023-04-12 10:08:26,Obligatory next step for gov of India to try to build BharatGPT. 😅
2023-04-12 10:09:22,They're already doing that
2023-04-12 10:09:55,Yeah I heard in a Nadella interview.
2023-04-12 10:12:25,"Sam Altman is making a DEL trip, not BLR. Clearly, monopolisation and regulations are best buddies."
2023-04-12 10:13:04,Monopoly play clearly 😅
2023-04-12 10:13:32,https://github.com/RSTLess-research/Fauno-Italian-LLM
2023-04-12 10:13:49,Italy might have banned OpenAI 
2023-04-12 10:14:16,Petition to create a Bharat LLM instead of Bharat GPT
2023-04-12 10:14:20,Are you referring to a foundational model or a GPT model fine tuned on India data?
2023-04-12 10:14:30,+100
2023-04-12 10:18:00,I would assume it would start off with GPT first.
2023-04-12 10:29:21,Problem is with all the examples you’ve mentioned we are not fully local till today 
2023-04-12 10:30:19,A better example would be India’s nuclear programme and ICBMs
2023-04-12 10:40:55,I think they'll create an LLM because Gov is more focused on self owned public infrastructure
2023-04-12 10:41:27,https://ai4bharat.iitm.ac.in/models
2023-04-12 10:41:36,"Anyways, AI4Bharat is working on it ig. The IITM one"
2023-04-12 10:41:44,BabyAGI on Replit in just 105 lines of code https://replit.com/@YoheiNakajima/babyagi?v=1
2023-04-12 10:41:57,Lol what a coincidence
2023-04-12 10:42:34,But I think it will be very hard to beat translation + gpt-4 performance
2023-04-12 10:43:18,For now their focus can be on transliteration
2023-04-12 10:44:18,Also they might just invest 500 mil and ask Microsoft and Nvidia to just do it too who knows.
2023-04-12 10:45:42,"Yeah, pratuysh works at msft research only so"
2023-04-12 10:47:01,https://www.medianama.com/2023/02/223-nadella-bhashini-language-translation-platform/
2023-04-12 10:48:18,https://farmer.chat
2023-04-12 10:50:27,"Can add more Indic Languages, add voice support and link to government schemes via plugins"
2023-04-12 10:51:08,Voice support is there via one of the ai4bharat models
2023-04-12 10:52:19,More Indic languages will come :)
2023-04-12 10:52:30,We are using IndicTrans in KissanGPT for few already
2023-04-12 10:52:58,We use google translate. How are the latencies for indictrans? Where are you hosting it?
2023-04-12 10:53:05,Trying to add TTS but the inference is not optimized yet
2023-04-12 10:53:19,The US got another tool for its leverage and control 🤦
2023-04-12 10:53:37,You mean stt?
2023-04-12 10:54:10,TTS as we are trying to also return answer in same language
2023-04-12 10:54:19,https://www.inferless.com/serverless-gpu-market
2023-04-12 10:54:25,You can check it out at https://kissangpt.com
2023-04-12 10:55:05,Pretty slick!
2023-04-12 10:55:44,We have been working in AI for agriculture for sometime so we have significant amount of knowledge base and in talk with ministry to access huge amount of information that we will start adding
2023-04-12 10:55:53,Our government is actually working to enable the ecosystem. They're hiring PMs for AI roles too. bhashini.gov.in/en/ecosystem
2023-04-12 10:55:59,"While [PHONE REMOVED] speaks of how the country is advancing and getting ahead in the tech-contribution at par with the westworld, the only difference is the tools that people build there start getting used quite immediately and you can see it’s effect, while it’d probably have 0 usability here."
2023-04-12 10:56:56,"Of course we are doing better than most, these models are good but our local open ecosystem needs to jump on making these models production ready from research output."
2023-04-12 10:57:19,That's probably because we don't have PMF with the end user. Our products are still not designed well for them
2023-04-12 10:57:47,By what time do you think farmers of India will start using https://kissangpt.com? 🙃
2023-04-12 10:58:02,I have been getting calls from all type of farmers and hobbyist about using Kissan GPT and feature requests. Not getting time to add features as I’m talking to them.
2023-04-12 10:58:29,Probably when it stops having foreign words like GPT in its name for starters
2023-04-12 10:58:45,(foreign to the local farmer)
2023-04-12 10:59:00,"that’s insane, kudos!"
2023-04-12 10:59:04,Already there is a good amount of folks using it. Farmers have phone and they are very much aware of news and things going on then you tokan think.
2023-04-12 10:59:13,Folks*
2023-04-12 10:59:38,There are large club house groups where talk regularly
2023-04-12 10:59:42,Would love to see an use case like above! 😃
2023-04-12 11:00:52,"When last time I was on clubhouse, they were suggesting requests for their everyday use thay I have to look for note pad."
2023-04-12 11:01:33,Hey how are you ensuring RLHF ? Here ?
2023-04-12 11:01:42,Do you have any systems in place ?
2023-04-12 11:01:49,"Yes, our students are capable but they don't have the required resources (computing is costly). Hopefully corporate and govt will support this ecosystem."
2023-04-12 11:02:18,No I don’t. But I’m collecting enough information that I can implement something in future and May be share voice dataset with Bhasini.
2023-04-12 11:02:58,"Let’s see, lot of initial conversation going on multiple front"
2023-04-12 11:03:53,I got one interesting request to integrate visual capabilities to detect bad signs in the crop photos. Do you have any plans or thoughts there?
2023-04-12 11:05:02,"I have asked OpenAI to give me access to multimodal when it is available in gpt4 api, let’s see when that available. We will be integrating it."
2023-04-12 11:05:03,This is a novel and socially good use case.
2023-04-12 11:05:54,"Yes soon, I’ll have to move from my home rigs to cloid infra. I’ll reach out."
2023-04-12 11:06:21,You are running this on your home infra? 🔥🤯
2023-04-12 11:06:44,🙏🙏
2023-04-12 11:06:46,Yes 😔
2023-04-12 11:07:05,What will the cost to move it to the cloud?
2023-04-12 11:07:09,Need to keep cost low as possible to make it available for Agri domain
2023-04-12 11:07:51,Register a company and apply to Microsoft for startups get 150k in credits donot for 2 years
2023-04-12 11:07:55,One PSU already gave up
2023-04-12 11:08:07,"Same, we got google cloud for 2 years."
2023-04-12 11:08:11,Working on it
2023-04-12 11:08:26,Amazon before that. Just keep moving clouds until you get free credits from everyone
2023-04-12 11:08:29,They are supportive
2023-04-12 11:09:28,"With open source, non-profit research use cases any cloud provider can provide credits easily."
2023-04-12 11:10:11,How big are you guys? Just you?
2023-04-12 11:10:55,I am not thinking non-profit case as it won’t help me scale. I have Agri startups to integrate in their platforms lined up. But still they do give startup credits which I’m going to apply for.
2023-04-12 11:11:31,"Im here in Bay Area and small team in Surat, 7."
2023-04-12 11:15:11,I know [PHONE REMOVED] is also from Surat. Small city folks. 😁
2023-04-12 11:21:35,Any Finance bros/gals in this group playing with AI? There is an idea I'm toying with would love to chat.
2023-04-12 11:23:02,Not finance but building in the legal space.
2023-04-12 11:23:27,Glad to find that it was helpful! :)
2023-04-12 11:38:04,Have you used TTS ? Can’t locate their weights
2023-04-12 11:38:39,"What are you using, quality is good"
2023-04-12 11:54:13,"You have to literally hack into their XMLs and storage path to get those. They are saying they have them on Bhasini and open sourced them but I couldn’t find direct links. I tried to request on their account but I didn’t get any reply, and then the inference is not optimized. That’s the reason I’ve to run everything on my rigs right now, as a lot of hacks are involved."
2023-04-12 12:14:51,Just realised that SAM runs inside a browser on the cpu 🤯
2023-04-12 12:15:11,cc [PHONE REMOVED] do you want to do a demo on this in the April meetup?
2023-04-12 12:16:32,Yup. Working on it.
2023-04-12 12:16:59,"Link for April meetup, for those who've joined recently"
2023-04-12 12:17:04,"In-person, BLR only"
2023-04-12 12:22:44,https://huggingface.co/spaces/abhishek/StableSAM
2023-04-12 12:23:27,I’ll be there 🫡
2023-04-12 12:23:49,"Folks, a portfolio co which generates research reports on quality of carbon credits, is looking for tools that can help write their research reports on top of the research they have done. This report will be a mix of text & charts. "
2023-04-12 12:24:19,"Else, if someone is willing to hack something like this along with the portfolio co, happy to make the introduction. "
2023-04-12 12:24:33,"whosoever picks this up, please charge more than $10K"
2023-04-12 12:44:10,"The initial encoder uses GPUs, it's only the decoder which runs on web browser."
2023-04-12 13:45:43,I have a question regarding SAM.
2023-04-12 13:46:24,Compare yourself here: https://huggingface.co/spaces/abhishek/StableSAM
2023-04-12 13:50:40,You'll need a 512X512 to try this link btw. Errors out for all else dims
2023-04-12 13:54:18,Internally resizing is happening right
2023-04-12 13:54:41,"Thanks, will try this"
2023-04-12 13:55:36,Dumb Q: Wont you use SAM to just generate a mask for the inpainting or outpainting model?
2023-04-12 13:57:37,I’m still a noob at these. 
2023-04-12 13:58:18,I think the advantage with SAM is the interactivity from a UX perspective
2023-04-12 13:58:34,"This looks like SD code, not the sam code"
2023-04-12 14:00:05,Yes SAM gives mask
2023-04-12 15:01:45,"tried, still didn't work"
2023-04-12 15:32:36,https://twitter.com/kevinafischer/status/1646009719314841601?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-04-12 16:50:31,AI agents writing their own plugins
2023-04-12 18:14:23,https://twitter.com/shivam124081/status/1645691399164026880?s=46&t=kpJ79jqt9oDMH6ZCqnhylA 
2023-04-12 18:25:55,Cc [PHONE REMOVED] karde Kya?
2023-04-12 19:29:58,"Hey folks, anyone here know any dataset agencies? (Need to curate an instruct type dataset.)"
2023-04-12 21:37:17,"Folks, this langchain webinar with harrison, yohei among others is quite nice - https://www.crowdcast.io/c/46erbpbz609r. Is live now"
2023-04-12 22:38:17,Can anyone share Langchain resource i can checkout to get started ?
2023-04-12 22:40:10,The Langchain docs are really good to get started with they also have guides for reference too. Check them out here : 
2023-04-12 22:40:28,*- https://python.langchain.com/en/latest/
2023-04-12 22:45:54,Thanks
2023-04-12 23:16:22,https://huyenchip.com/2023/04/11/llm-engineering.html
2023-04-12 23:40:34,OpenAI have released open source implementation and model weights for their latest work. These models do one step image generation. 
2023-04-13 00:35:55,Love how they crowd sourced the dataset from own employees: https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
2023-04-13 04:04:15,"This can be amazingly fast as it doesn't use diffusion. If someone finds memory requirements and inference speed, please share. If it is small enough to tinker without using the A100 cluster, we can see its versions of Dreambooth and ControlNet popping out soon."
2023-04-13 04:10:57,A nice summary - https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/
2023-04-13 13:26:56,oh no! we just went live with Pinecone and this is scary
2023-04-13 13:27:50,"Ditch em. That's a key risk. Even if you ever want to tell your customers how good your recall your QA is, Pinecone prevents you from doing so. Will handicap your marketing/sales."
2023-04-13 13:28:19,"yes agreed. Weaviate had other problems though - scale, connectors. Will check out Qdrant"
2023-04-13 13:29:34,"Yeah, hear you on Weaviate's scaling issues. Qdrant scales betters. Connectors solution is to go via Llama Index for recall. "
2023-04-13 13:30:06,"That is quite valuable to my enterprise SaaS friends, any sort of reporting/tooling to see what they're missing in FAQ"
2023-04-13 13:35:17,yes using LlamaIndex with Pinecone in prod with Ravi's evaluation
2023-04-13 13:36:17,"Please forgive me for being repetitive, I am a sucker for neatly executed ideas 😅"
2023-04-13 13:40:23,"Much needed one. As more people use it, it helps me to get feedback and make it better 👍😉"
2023-04-13 13:48:42,Which is the best Vector DB for production ?
2023-04-13 13:48:52,Naive question but being bold asked
2023-04-13 13:49:16,"Not naive at all, the answer is — we don't know"
2023-04-13 13:49:26,😎
2023-04-13 13:49:32,Ok
2023-04-13 13:49:38,"Worse, we don't know if it's worth answering this question when 32K context windows become a thing"
2023-04-13 13:50:04,I am a little biased but I'd throw in the name of Redis
2023-04-13 13:50:18,Inferencing costs?
2023-04-13 13:50:52,People married to Azure Redis is the only choice which is PAAS
2023-04-13 13:51:24,"[PHONE REMOVED] sir, sponsor a grant to do this ANN Recall vs $$ benchmark? I'll do it for 💵"
2023-04-13 13:51:38,I am liking this group so lively
2023-04-13 13:52:42,There is one Vector DB Millivus
2023-04-13 13:52:44,"The current inferencing costs are about 10-50x from what they can be at scale, even for GPT4. I think the price will drop another 10x in next 6-12 months."
2023-04-13 13:53:42,"Name your favourite Pokemon: Milvus, Weaviate, Qdrant, Chroma, Pinecone, Redis Vector Cache, Vespa, Elastic, pgvector on Supabase"
2023-04-13 13:54:22,I like you 2x2 matrix actually here 
2023-04-13 13:54:59,I'll let you know how Pinecone goes. Will push to 250 customers next week.
2023-04-13 13:56:08,I’m implementing hybrid search and really annoyed with their docs. Literally tried their example and it doesn’t work. Good time to move away it sounds like
2023-04-13 13:56:20,"Umm, could I ask what makes you believe so? "
2023-04-13 13:56:40,Cloud Providers' APIs are also fairly expensive
2023-04-13 13:56:45,"Azure, AWS, GCP"
2023-04-13 13:58:33,"For example, https://aws.amazon.com/comprehend/medical/pricing/"
2023-04-13 13:58:49,GPT3.5 was cheaper than GPT3
2023-04-13 14:05:24,Was?
2023-04-13 14:05:58,text-davinci-003 is more expensive than gpt3.5-turbo
2023-04-13 14:06:12,"sorry, is."
2023-04-13 14:06:28,2M tokens for $2
2023-04-13 14:06:29,Ah! I thought they increased overnight
2023-04-13 14:07:07,point is that LLM models will only get cheaper and faster - as proven in the past few months. GPT4 is more expensive than 3.5 until GPT5 comes up
2023-04-13 14:07:33,GPT4 has two major releases pending: 
2023-04-13 14:08:07,3. Plugins for all practical purposes. I doubt they want to stop at giving 20K people access to that.
2023-04-13 14:08:57,Plugins has _at least_ 2 new GPT4 finetuned forks: 
2023-04-13 14:09:35,and plugins in API
2023-04-13 14:09:50,I got zero juice from that Atty OpenAI event
2023-04-13 14:09:54,sigh
2023-04-13 14:10:21,The juice from the Setu event was worth 30 min commute tbh
2023-04-13 14:10:44,Setu event?
2023-04-13 14:12:01,"Before the open-for-all event, Setu hosted Atty in a closed door meeting. He answered questions like finetuning for plugins, API design, release plans and constraints, internal tooling, some benchmarks (and who makes them), checkpointing and how they decide to brand one model as ""GPT4"""
2023-04-13 14:12:30,"bruh, this sounds so much better"
2023-04-13 14:12:46,lol
2023-04-13 14:13:03,"Can add libraries to the list? Faiss, Annoy, ScaNN, ANNlite"
2023-04-13 14:13:26,"Yeah, at the very least FAISS and Annoy qualify"
2023-04-13 14:13:35,But I ran out of storage in my Pokedex
2023-04-13 14:53:44,How much? :P
2023-04-13 14:58:12,If you've to ask ...
2023-04-13 14:59:47,"I doubt it Karthik, most of the foundational LLM companies are losing a lot of money + there is a GPU shortage in the market ... they have to jack up prices to customers.  At least I think next 12 months prices will increase, until there is mass adoption and so we reach supply demand equilibrium."
2023-04-13 15:01:33,Will you take a personal wager of 1L INR on price hike?
2023-04-13 15:01:58,I'm willing to take a personal wager that prices drop — either via people switching to internal GPUs or OpenAI or some other mechanism
2023-04-13 15:03:01,Sorry not a gambler here. But happy to buy you a drink. And as I said my comment is for commercial LLM providers - a company switching from commercial to self-hosted / open source LLM is not where my perspective applies.
2023-04-13 15:03:43,"Cost of compute is high, moving to open source / self hosted makes a lot of sense. But then you have to include the LLMOps cost + team cost + data cost etc etc ..."
2023-04-13 15:04:10,And I don't believe most startups have the money to hire very expensive research scientists that OpenAI has
2023-04-13 15:05:11,It is a gamble if you think it's a game of chance and not skill :)
2023-04-13 15:05:22,"Maybe once the usage of private data to train the model is restricted, APIs can be free if the user consent to give up on data rights. Paid for those who don't."
2023-04-13 15:05:27,The moat for a company lies in proprietary dataset is my view.
2023-04-13 15:10:23,"I believe even commercial ones will get cheaper and willing to bet on it. We haven’t even seen AWS, Google, Microsoft enter yet"
2023-04-13 15:14:56,Unfortunately to me it feels like Google is not even in the game. And Microsoft has such a sizeable investment in OpenAI that most probably Azure APIs will be essentially OpenAI APIs repackaged.
2023-04-13 15:15:26,I think the fight is between Oracle (yes lot of people don't know that they are cheapest out there in GPU pricing) vs. AWS
2023-04-13 15:16:24,TPUs don't make a difference?
2023-04-13 15:17:46,Fantastic case study from StableCog and what did they consider when selecting between all the popular Vector Databases.
2023-04-13 15:23:37,lets discuss in 6 months
2023-04-13 15:32:30,good documentation
2023-04-13 15:47:42,https://github.com/lllyasviel/ControlNet-v1-1-nightly
2023-04-13 16:16:18,Is anybody using Milvus ?
2023-04-13 16:17:30,I hear it's popular at Zilliz
2023-04-13 16:17:52,It's their opensourc
2023-04-13 16:17:55,opensource
2023-04-13 16:18:24,https://zilliz.com/
2023-04-13 16:18:48,You didn't have to ruin the joke for everyone by explaining it
2023-04-13 16:20:16,someone will need to build a migration tool to avoid re-embedding
2023-04-13 16:28:16,AFAIK: That is an open research problem.
2023-04-13 16:43:49,I'm currently in touch with the Lead who's managing vector similarity search in Redis
2023-04-13 16:44:58,"Recall against $$, recall against qps"
2023-04-13 17:21:10,"Prayank, I agree with your arguments from the economics pov. From a technical pov, it seems like models will get smaller without drastic reduction in accuracy unlike now. The fact that we can train them with simple optimisation algorithms, the fact that you train on 570GB to create a 170B parameter model etc, all sort of allude to the fact that we possibly have a much smaller model (possibly this is just a smaller model embedded in larger space, so to speak). There are things that can still  help these companies make money and we still have to use them."
2023-04-13 17:28:12,"The research community is super split on this. There is a smaller model future faction and a larger model faction. Smaller you described and larger you can guess. After having spoken to enough researchers, it feels like only time will tell which way we will head. OpenAI is clearly interested in larger and larger models."
2023-04-13 17:30:21,Is any meaningful alternative to Nvdia coming up in the next 12 months that can alleviate the stress on chip supply?
2023-04-13 17:31:12,"From what I have read, smaller models are accurate for certain tasks but for higher accuracy still larger models are required. And, also emergent abilities are coming out in larger models"
2023-04-13 17:33:53,https://tenstorrent.com
2023-04-13 17:33:56,[PHONE REMOVED] good to see you here
2023-04-13 17:36:26,[PHONE REMOVED] any idea on who is using them and what is the cost/performance comparison to NVidia?
2023-04-13 17:37:48,"This is jim keller’s new chip company. Openai put money into it. Don’t know the specifics right now, but jim informally told us that they want to build a 2 terabyte ram ai accelerator."
2023-04-13 17:39:47,Sorry I dont think the openai funding got through yet - https://techcrunch.com/2023/01/10/openai-in-talks-to-back-zeloof-and-chip-legend-kellers-startup-at-100-million-valuation/amp/
2023-04-13 17:40:46,Just noticed they have a Bangalore office. Unbelievable!
2023-04-13 17:40:51,"But the vibe at the bangalore meetup was very clear, they want to give the incumbents a run for their money :)"
2023-04-13 17:41:05,"You are 100% accurate on this. There is interesting dynamics around what is needed by the task at hand. So really the question is are there going to be lots of reasoning like applications or better search/similarity like applications. How much larger models resoning like capability requires, that probably is anyone guess. Given the semiconductor lifecycle, new chips will take time. OpenCL has been trying to make inroads for last decade. Would be interesting if new models can do reasoning (GPU like) + table lookups (traditional computers), AllenAI did some work on this but nothing mind blowing afaik."
2023-04-13 17:42:03,"IMO these are very long term play and probably only help OpenAI or whoever can afford development out side of cuda. Also OAI, reportedly using Cerebras."
2023-04-13 17:43:18,AllenAI's announcement this summer will change that mostly but I wouldn't swear by it yet
2023-04-13 17:44:29,"Cant tell about the long term play part, but they were a lot of talks about open ISAs because of risc-v and how they’re actually trying to democratise access to chip designs. They also talked a lot about open source."
2023-04-13 18:48:30,"folks, have you come across any open source LLMs that are strong with code generation & various programming languages?"
2023-04-13 18:51:20,"If I'm not wrong, Replit and Aws codewishperer are both using CodeGen"
2023-04-13 18:53:19,Anybody knows Something which can be hosted locally without internet... Can Alpaca be finetuned for local codebase?
2023-04-13 18:54:53,I recently tried running GPT4ALL locally and it worked pretty good on my 8gb ram laptop
2023-04-13 19:01:56,https://github.com/ravenscroftj/turbopilot
2023-04-13 19:15:02,I was just trying this since noon. This is good for text generation and the onboarding is super simple. But it’s not really strong with code yet
2023-04-13 19:17:04,Will check this out 👍
2023-04-13 19:18:08,Agreed. OpenAI has kind of merged their codex model with GPT 3.5 turbo so they have a single purpose code generation model kind of integrated which makes it powerful
2023-04-13 19:41:37,Feat. [PHONE REMOVED]
2023-04-13 19:41:51,Nice! Any way deck can be shared?
2023-04-13 19:43:12,"There is no deck, it's a survey thing they did live"
2023-04-13 19:44:17,Ah
2023-04-13 19:57:47,🔥Commercially Viable LLM from Databricks - Dolly 2.0 - 12B parameter language model (LLM) 
2023-04-13 19:58:20,"They have open-sourced training code, the dataset, and the model weights, all suitable for commercial use :)"
2023-04-13 20:01:57,That's their top highlight while selling the contract renewal of the data bricks platform 😂
2023-04-13 20:03:22,https://github.com/huggingface/diffusers/releases/tag/v0.15.0
2023-04-13 20:17:38,Such a good share.
2023-04-13 20:20:48,Anyone wants to join hands on translating Spectrogram Diffusion to work for images?
2023-04-13 20:22:25,We (Koo)want to identify generated images. 
2023-04-13 20:22:57,"cc [PHONE REMOVED] runs a company called Spoofsense.ai if I remember correctly, but I might be wrong"
2023-04-13 20:24:34,Perfect. I'm wearing a Dukaan tee. How can I spot you?
2023-04-13 20:25:30,"Hi Harsh, Kartikeya here (spoofsense.ai) would love to connect."
2023-04-13 20:34:38,Coming back up. Stepped our to buy cigs
2023-04-13 20:36:00,"Are you sure, heard it can’t be done"
2023-04-13 20:41:09,Let me know how we can collaborate. Sending you DM
2023-04-13 21:42:49,https://twitter.com/ashe_cs/status/1646543644038397952?s=46&t=0NBX3C3Uma-Su4_rjA3OMA
2023-04-13 21:51:12,Thanks a lot [PHONE REMOVED] for hosting today's mixer. Met so many cool people and it was absolutely delightful to hear what everyone in Bangalore AI space is up to.
2023-04-13 22:07:13,You forgot to thank them for free beer and food 😂
2023-04-13 22:08:53,Ehh they'll probably make it back 10x if they invest in some of the killer startups that people represented today 😉
2023-04-13 22:10:51,Nirant should get carry!! He runs a group that has the highest ROI of perhaps most groups in Bangalore tech space.
2023-04-13 22:17:20,Anyone else experiencing crazy timeouts with GPT-4 API? 🥺
2023-04-13 22:25:54,Yes
2023-04-13 22:26:04,"Ohh yes, I think so. It started to feel slower from evening today"
2023-04-13 22:26:54,"They're rolling out new access, so small spike. Will even out tomorrow hopefully. Consider using tenacity with exponential backoff in the meantime and be nice :)"
2023-04-13 22:27:21,Tenacity is a Python lib for retrying with exponential backoff
2023-04-13 22:27:55,Mujhe laga life skill of being patient bola aapne 😂
2023-04-13 22:28:07,(Not kidding. I actually didn’t the framework. Thanks 🙏)
2023-04-13 23:45:34,Cerebras is doing some solid work but not planning to be consumer focused chips
2023-04-13 23:58:33,https://www.linkedin.com/posts/harshsinghal_under40-activity-7052341005978615809-EaUX?utm_source=share&utm_medium=member_android
2023-04-13 23:58:35,Sambanova building FPGA based chips for AI
2023-04-13 23:58:50,Open to working on this with interested folks.
2023-04-14 00:01:32,langchain uses Tenacity too!
2023-04-14 00:04:32,+1 on this
2023-04-14 00:25:34,We have an api for this kids as superheros idea 😆
2023-04-14 00:34:13,https://techcrunch.com/2023/04/13/with-bedrock-amazon-enters-the-generative-ai-race/
2023-04-14 00:48:20,"Today i finished the Andrej Karpathy's video on Neural Nets. Even though i knew few things, i learned a lot in depth. Will highly recommend to anyone starting or even in the field. He teaches really well and in depth."
2023-04-14 00:50:58,https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
2023-04-14 00:53:58,cache LLM calls and save $$
2023-04-14 00:57:14,Tried this on an online image. Pretty good. 
2023-04-14 00:58:22,Img2img models for inpainting? How?
2023-04-14 01:07:29,"I'm not an expert and things are moving fast - I'll ask GPT-4, browse diffusers like crazy, watch a ton of YouTube videos or wait for someone here to suggest."
2023-04-14 02:02:33,https://stability.ai/blog/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users
2023-04-14 08:58:09,Morning everyone. I remember seeing a Twitter post about 'ChatGPT for a github repository'. 
2023-04-14 08:59:25,https://js.langchain.com/docs/modules/indexes/document_loaders/examples/web_loaders/github
2023-04-14 08:59:46,Demo video of Chat with GitHub 
2023-04-14 09:16:55,Must be this one only
2023-04-14 09:17:38,"sweet, thanks bud. Have a great day."
2023-04-14 10:07:37,"What if someone build this ""Google me what I have seen or heard somewhere"" 😅"
2023-04-14 10:11:01,It is entirely possible using LangChain 
2023-04-14 10:13:23,"Actually, I am using Bard for asking questions on a github repository, and it is performing pretty well for me until now."
2023-04-14 10:13:39,"Seen/Read: On Twitter, Browser, WhatsApp, Slack, and any other platform/app "
2023-04-14 10:14:05,Check Reflect.Ai then
2023-04-14 10:15:45,Thanks I will check.
2023-04-14 10:16:03,"Ah no,I think I got the name wrong "
2023-04-14 10:16:21,Directly asking questions to bard about certain repository by providing link or some other way?
2023-04-14 10:18:02,"For famous repositories, it directly works by typing the name of repo, for new repo or repo that is not ranked, I provide link and ask questions."
2023-04-14 10:19:02,I think you meant rewind.ai
2023-04-14 10:19:07,I could really do with that tool just now 😅
2023-04-14 10:19:13,Yes exactly
2023-04-14 10:22:41,Their tagline itself is 
2023-04-14 11:03:40,Building LLM applications for production
2023-04-14 11:15:53,https://grail.cs.washington.edu/projects/dreampose/
2023-04-14 11:16:23,Here's a new AI model called DreamPose that can generate Video from Image.
2023-04-14 11:36:44,do we need to finetune the model on the subject-specific image before creating the video?  [PHONE REMOVED]
2023-04-14 11:47:20,"Yeah it looks like it, https://github.com/johannakarras/DreamPose#finetune-on-sample"
2023-04-14 13:11:59,ok. noob question may be but how is this diffrent from an edge detection algorithm on steroid .
2023-04-14 14:04:43,"question: for smaller sets of data, what’ll be the difference between generating embeddings and storing them in vectorDBs v/s providing them directly to the LLM for question-answering?"
2023-04-14 14:07:50,If data set has >4000 tokens you have to chunk it and store them in dbs and do QA by taking relevant chunks….if it’s <4000 tokens you can directly ask LLM for QA.
2023-04-14 14:15:31,4k is still high. One should consider prompt tokens and tokens to generate in the answer too. Else they are left with just 97
2023-04-14 19:46:28,Akto.io just launched AktoGPT - https://www.akto.io/blog/aktogpt
2023-04-14 19:46:53,@ankush talks about things to watch out for before deploying GPT LLM in production - https://twitter.com/Ankush12389/status/1646779395833741313
2023-04-14 20:07:49,"Folks I'm here as myself not a VC, but yes Akto is funded by Accel India so here is a disclaimer"
2023-04-14 20:11:24,https://arxiv.org/abs/2303.01469
2023-04-14 20:24:35,"In the software world, we call it ""avoiding premature optimization"""
2023-04-14 20:40:38,Has anyone used LangChain with Azure endpoints instead of OpenAI  directly ?
2023-04-14 20:43:16,https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html
2023-04-14 20:43:23,Tried this?
2023-04-14 20:44:18,Yup I’ve tried this 
2023-04-14 20:45:04,"They have examples for custom LLM agents, not sure if that helps"
2023-04-14 20:47:08,Using gpt-3.5 response as it is from Azure endpoint response and then customising it for use is a huge headache for me currently 🥲
2023-04-14 20:48:59,Prompt was simple “Tell me a joke” nothing more
2023-04-14 20:52:44,This has happened before too
2023-04-14 21:29:01,https://colin-scott.github.io/personal_website/research/interactive_latency.html
2023-04-14 21:52:35,wow
2023-04-14 21:56:26,latency for 2000 Bytes over commodity network went from 2000NS in year 2009 to 44 NS in 2020 . 😮
2023-04-14 22:10:15,CTO of Stability AI is talking about Stability diffusion if anyone is interested 
2023-04-14 22:22:51,ChatGPT for Robotics
2023-04-14 22:38:08,Fire optics became more widely adopted over this time 😊
2023-04-14 22:39:24,It's fun to see these numbers and trends as a way to understand industry directions and opportunities. 
2023-04-14 23:39:09,https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing
2023-04-14 23:40:48,you have it in your name
2023-04-15 06:15:34,Awesome 👏🏽
2023-04-15 06:16:51,Enjoy 🫡
2023-04-15 06:18:56,"on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me."
2023-04-15 09:13:21,"Has anyone here been able to get the latest controlnet v1-1 nightly release models working with inpainting? There is one controlnet model which is for inpainting, any inputs on how that would fit with multi controlnet? I got the models working with multi controlnet but have not been able to do so for inpainting yet."
2023-04-15 09:38:07,https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
2023-04-15 09:38:25,"Sounds very cool, must put into gooey"
2023-04-15 09:58:41,You may check Haystack. It provides very easy abstraction.
2023-04-15 09:59:57,Would love to see some comparisons at production level scale
2023-04-15 10:00:39,This was about controlnet inpainting
2023-04-15 10:01:51,We are not at production level scale yet anways 😅 about 1% of dukaan probably
2023-04-15 10:17:48,Enterprise Document Search in Azure - MSFT recommends using Azure Cognitive Search with Azure OpenAI . I would be interested to know your thoughts . Azure Cognitive Search may be costly
2023-04-15 10:19:04,Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search
2023-04-15 10:19:25,Interested to know from the community of production level deloyments
2023-04-15 10:20:14,This is what we’re live with.
2023-04-15 10:21:17,Thank you [PHONE REMOVED]  . Size of the DB = ? and your choice of Vector DB = ?
2023-04-15 10:42:32,twitter discussion for this https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19
2023-04-15 10:42:55,10681 vectors and pinecone
2023-04-15 10:45:25,Thanks so much
2023-04-15 11:15:49,"Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies."
2023-04-15 11:22:57,https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman
2023-04-15 11:23:02,"Yes, works great though when you don't have too many data refreshes/updates."
2023-04-15 12:11:51,I have a friend called gpt 4. Fairly reasonably priced. 😋
2023-04-15 12:14:57,immediately reminded me of spam detection PoCs :P
2023-04-15 15:59:21,True! I recently pushed a project thru the deadline and practically - copilot helped w a good chunk of front end code . GPT for all those complex Cloud formation templates .
2023-04-15 16:18:00,has anyone figured good ways to reduce time in getting output from an LLM?
2023-04-15 16:19:24,also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique?
2023-04-15 16:22:12,Introduced to this recently for a similar problem statement
2023-04-15 16:37:16,"wow amazing. thanks a lot, been searching for 2-3 days"
2023-04-15 16:38:36,https://twitter.com/pratyush_r8/status/1647104801950552064
2023-04-15 16:47:14,Interesting thought. I always thought bionic reading just highlights the first 2-3 characters of each word.
2023-04-15 21:21:30,I have a question and I think people here would be well suited to answer
2023-04-15 21:21:31,"If projects like langchain are open-source, then why do they raise money? What are the economics here?"
2023-04-15 21:21:31,Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?
2023-04-15 21:22:24,Fowarded a thread I'm having elsewhere. Let me know if anyone has any understanding about this.
2023-04-15 21:23:10,"Users and distribution. As a man once said, your monetisation techiniques are very different when you have 10K users vs 10M users"
2023-04-15 21:23:17,Managed Services. Including enterprise. See dbt cloud for reference.
2023-04-15 21:25:19,Also people don't like writing code or reading docs. This is also the Fixie thesis
2023-04-15 21:23:58,OpenSUSE and RedHat open sourced their code. Still profitable by providing training and support
2023-04-15 21:24:11,"Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies"
2023-04-15 21:24:16,What’s dbt cloud? Heard this from my investors too
2023-04-15 21:26:16,That'd be off topic. I love dbt too. Happy to talk more on DM
2023-04-15 21:26:52,I'd wager Llama Index should/will raise too if they build a company around it
2023-04-15 21:30:39,Hosted cloud version - that’s a great value prop Id pay for. Like mongodb
2023-04-15 21:34:08,It's a fantastic model. A wrapper around Foss. With a lot of successes
2023-04-15 21:34:48,Cal.com has turned that into a pretty decent content model as well
2023-04-15 21:37:30,Like elasticsearch went into AWS?
2023-04-15 21:38:06,Anyone here who has invested in such a business model before?
2023-04-15 21:41:33,"Won't compare to AWS services, but more like mongodb, appsmith, vercel etc."
2023-04-15 21:42:39,"Where you get hooked to the service by first using it on your instances, but as team/complexity grows, you prefer to just use their hosted offerings"
2023-04-15 21:44:24,Vercel and NextJS is a great example
2023-04-15 21:46:03,Gotcha
2023-04-15 21:46:10,Makes sense
2023-04-15 21:47:34,"Yeah, and when you try using NextJS on AWS amplify, it had terrible build times (as per my last experience). We had no choice, but to use the Vercel hosting"
2023-04-15 22:14:08,Is anyone familiar with AI for crime detection (loud noises etc)
2023-04-15 22:29:50,Redhat $1B
2023-04-15 22:30:17,https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19
2023-04-15 22:39:32,https://www.linkedin.com/feed/update/urn:li:activity:7053046289256632320
2023-04-15 22:39:43,https://twitter.com/foyerwork/status/1647282584907579393?s=20
2023-04-15 23:03:16,AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/
2023-04-15 23:09:38,https://aws.amazon.com/blogs/machine-learning/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity/
2023-04-15 23:13:54,https://blog.lucas-simon.com/amazon-codewhisperer-vs-github-copilot#heading-final-thoughts
2023-04-16 09:06:39,Any sci-fi enthusiasts here ? 😃
2023-04-16 09:07:27,Yeah it’s great
2023-04-16 09:07:44,This is even better - it’s also very timely because of AI
2023-04-16 09:07:46,https://www.gregegan.net/MISC/CRYSTAL/Crystal.html
2023-04-16 09:08:03,Doesn’t the Multivac sound eerily similar to today’s LLMs /Auto-GPT ?
2023-04-16 09:09:02,"You ask a question ,it finds answers "
2023-04-16 09:09:47,"Yeah lol, Asimov basically predicted AGI"
2023-04-16 09:10:22,I guess Turing had already predicted it before him though
2023-04-16 09:11:42,"Asimov did do that in many stories ,I’ve read basically all of his books "
2023-04-16 09:12:17,Yeah agreed!
2023-04-16 09:12:52,"The interface is similar, but I think the big difference is that LLMs are conceptually structured, but untethered from reality. That I think is the big difference between multivac and LLMs"
2023-04-16 09:13:42,"Like it understands conceptually that colors should cluster together, but doesn’t really understand a color"
2023-04-16 09:13:56,Multimodality will help a lot with that
2023-04-16 09:14:57,On the color front I just happened to come across this paper :) 
2023-04-16 09:15:25,Agreed they are largely conceptually structured
2023-04-16 09:15:53,Great share thanks 🙏🏽
2023-04-16 09:16:50,Like in the “last question” the question asked over eons is can entropy be reversed. The fact that it took sooo long to answer because it is such a difficult question based on its understanding of reality was amazing
2023-04-16 09:17:45,"But thank you for bringing up Asimov’s work, that man was my first brush with sci-fi and a genius"
2023-04-16 09:18:31,It kept updating its understanding of reality 
2023-04-16 09:19:14,Glad to meet a fellow Asimov fan! 
2023-04-16 09:20:19,Cixin Liu is my all time favorite
2023-04-16 09:51:46,Draft Community Guidelines for this WA group. Will hopefully make it easier for you to decide for yourself what is off topic 🥲
2023-04-16 09:59:00,"Very cool, curious was it generated using AutoGPT, it seems to have 1 numbering only but also working links."
2023-04-16 10:00:06,Get yourself an admin that defines community guidelines in git 🫂
2023-04-16 10:17:07,off-topic - orion's arm is a cool website for sci-fi enthusiasts.
2023-04-16 10:26:37,Sci-fi thats relevant to this group
2023-04-16 10:54:31,"Huge fan here. Probably read Asimov, Clark and Heinlein all through college and masters. Kept me sane and got me excited about the future. "
2023-04-16 10:56:41,Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?
2023-04-16 10:56:53,I figured that's cheaper than buying chatGPT plus
2023-04-16 10:57:21,https://www.chatbotui.com/
2023-04-16 10:57:32,"And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit?"
2023-04-16 10:57:43,Is this the one you are looking for?
2023-04-16 10:58:14,Seems so
2023-04-16 10:58:17,Thank you
2023-04-16 11:00:59,I mostly use plus because it lets me use GPT-4 with large context windows and that turns out to be cost efficient. Do consider that.
2023-04-16 11:01:14,"Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great!"
2023-04-16 11:03:02,https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
2023-04-16 11:34:23,"Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful."
2023-04-16 11:38:41,"I love sci-fi,"
2023-04-16 11:41:28,+1 
2023-04-16 11:41:47,https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html
2023-04-16 11:42:00,https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
2023-04-16 11:42:45,These are articles by Databrick on how they’ve tuned the open source Dolly LLM for reference if anyone is interested 
2023-04-16 11:56:01,"I am trying to use sentence transformers and OpenAI combined and making a Docker Image. Obviously the image is quite big [ > 4 GB ] , did anybody try deploying this type of thing to Kubernetes / AKS / EKS ?"
2023-04-16 11:56:40,Doing it in a VM is ok and works fine. Interested to know the community viewpoints
2023-04-16 11:59:04,Anyone who has performed Model Distillation?
2023-04-16 12:03:28,I am curious - what’s your use case?  Use different models based on inference request parameters/tasks?
2023-04-16 12:04:31,"Standard ones [ Q&A , Chatbot]. The reason I am using Sentence Transformers instead of OpenAI embeddings to save cost"
2023-04-16 12:06:37,"Oh I see, so using embeddings from ST to do information retrieval and then add the context into OpenAI prompt?"
2023-04-16 12:06:49,Correct
2023-04-16 12:07:43,"OpenAI embeddings are good but they would charge. Hence alternative ST , but con is image is huge"
2023-04-16 12:08:23,In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ]
2023-04-16 12:10:42,May be deploying the model separately behind a service endpoint could be a way to go. That way you wont have to distribute the model in the application containers.
2023-04-16 12:13:14,Yes that's correct ; but the model itself is huge [ ST with all its fanfare Torch and … ] ; Are you suggesting deploying the Model in a VM and exposing as a service ?
2023-04-16 12:13:36,Yeah
2023-04-16 12:14:35,Thank you for your views
2023-04-16 12:16:04,I am just wondering how the community is thinking about using OpenAI for everything [ Embeddings and Chat Completion ]. My views are Embeddings can be done using ST and Hugging Face and reduce cost
2023-04-16 12:17:04,I agree.
2023-04-16 12:31:03,Have seen it start to work with 200 odd examples. OpenAI suggest 1000+ for accuracy. 
2023-04-16 12:32:33,Sorry I'm not sure i understand. Do you mean the image is large because of storing the vectors?
2023-04-16 12:33:00,Different than the OpenAI fine-tuning*
2023-04-16 12:33:39,"I am using Sentence Transformers for Word Embedding. The ST has dependencies on Torch and NVIDIA libraries , hence the image is large"
2023-04-16 12:34:42,Your standard flow is Embeddings + Chat Completion [ Very Himalaya level flow ] . For Embeddings to minimize cost using ST
2023-04-16 12:35:13,and Context / Chat Completion using OpenAI / Azure OpenAI
2023-04-16 12:36:11,It’s not recommended to use fine tuning where you can get away with embeddings.
2023-04-16 12:36:45,How many GBs are we talking about?
2023-04-16 12:37:02,> 5GB
2023-04-16 12:37:52,One solution from one helpful community member is to convert ST into ONNX format
2023-04-16 12:37:59,and this would reduce the size
2023-04-16 12:38:39,Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated
2023-04-16 12:39:53,I love this community . So very quick and helpful members
2023-04-16 12:42:04,"wait, I thought finetuning means providing extra/specific information to the model which it already doesn’t know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong?"
2023-04-16 12:43:53,https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images
2023-04-16 12:45:31,Harrison is really open about their strategy and sharing the plans. 
2023-04-16 12:49:34,https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696
2023-04-16 12:50:24,Nice article to convert ST into ONNX format
2023-04-16 13:29:22,Haha
2023-04-16 13:43:05,This is quite neat. I missed pinned messages for this!
2023-04-16 13:44:53,"Fine tuning adjusts the weights of a model, with more training samples. Embedding are usually used for similarity search(among other things)."
2023-04-16 13:47:17,"calculating embeddings is a part of adding “more training samples”, right? Or not necessarily…?"
2023-04-16 13:48:05,These things are orthogonal to each other.
2023-04-16 13:51:08,Are you talking about fine tuning the embedding model or something?
2023-04-16 13:51:35,These things are nuanced based on the context :)
2023-04-16 13:54:51,ah
2023-04-16 13:54:52,Think of it this way
2023-04-16 13:54:55,You can say embeddings is an LLM's mother tongue. It understands text by converting in into an embedding to understand the meaning and relation between words. Finetuning is giving the llm lot's of examples to learn a particular new skill or subject
2023-04-16 13:58:24,"I used ""differentiate"" in a explanatory flavour"
2023-04-16 13:58:27,https://twitter.com/tree_industries/status/1647416130753945601?s=46
2023-04-16 13:58:46,I imagine gpt3.5 and gpt4 embeddings will be much better for similarity search
2023-04-16 13:59:37,Anyway gpt3 embeddings are 1536 in length
2023-04-16 14:00:53,I see….
2023-04-16 14:03:45,"just trying to understand, so if this “intelligence” depends on the models’ weights, variance, etc which is obviously the case (basically upgrading from gpt3 to gpt4), there are ways to finetune, i.e., add more weights, etc. ourselves also? instead of waiting for a new release like gpt5?"
2023-04-16 14:05:22,I so long thought finetuning just means giving it more documents (storing the embeddings in a db)… i didn’t know there are ways to make the model smarter without burning huge computation powers
2023-04-16 14:07:16,Check this out https://huggingface.co/spaces/microsoft/HuggingGPT
2023-04-16 14:10:23,"Hmm ,think of embeddings as transformations (At very high level)"
2023-04-16 14:11:26,ya I understood that…
2023-04-16 14:11:27,When you fine tune a model
2023-04-16 14:12:22,what is the “process” of ‘finetuning’ then if not generating and storing embeddings?
2023-04-16 14:12:34,Providing it with prompts?
2023-04-16 14:12:52,to use those embeddings more smartly?
2023-04-16 14:12:53,"larger dof is not good for longer run, latency wise, too."
2023-04-16 14:13:00,Calling the api and updating the weights for your use cases.
2023-04-16 14:13:21,Weights being updated with example data
2023-04-16 14:14:13,Can I get a more comprehensive guide on how to ‘update these weights’ please?
2023-04-16 14:15:13,https://platform.openai.com/docs/guides/fine-tuning
2023-04-16 14:15:19,Providing with example date like rightly said 
2023-04-16 14:16:17,There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.
2023-04-16 14:16:36,Tweet about a paper
2023-04-16 14:19:13,Make sure if finetuning is really necessary for your usecase (computational costs involved) or if you can simply  use a external vector database like pinecone or weaviate instead.
2023-04-16 14:24:08,"I had read a little bit of this when I was initially exploring, but never tried myself: ```question and answer pairs to additionally create adversarial questions and context pairs```"
2023-04-16 14:52:36,What do you people think of this?
2023-04-16 14:59:25,This is interesting but needs more finesse. 
2023-04-16 15:00:19,"Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more ""precise"" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?"
2023-04-16 15:02:38,I think langchain's conversation memory types can be combined to optimise for your chunks
2023-04-16 15:03:44,https://python.langchain.com/en/latest/modules/memory/how_to_guides.html
2023-04-16 16:15:50,https://trib.al/HIuiF1K
2023-04-16 16:17:05,Is it possible for a specialized piece of hardware (ASICs or FPGAs) to speed up the embedding search ?
2023-04-16 17:26:14,"Hey [PHONE REMOVED] can we summarize the things going on here with GPT. It's getting really hard and time consuming to catch up with 50+ messages on WA. As more people are joining, the number of messages here is just exploding 😅"
2023-04-16 17:44:10,This guy is literally raising funds via his github repository
2023-04-16 17:44:11,https://github.com/jdagdelen/hyperDB
2023-04-16 17:44:24,someone said langchain will probably integrate this by end of the day
2023-04-16 17:45:13,it's a joke apparently
2023-04-16 17:45:50,yea it opens up that nyan cat youtube video 😄
2023-04-16 19:04:05,I tried asking GPT for this. This is what it responded with.
2023-04-16 19:05:27,A smart summariser Bot for WhatsApp groups will be really helpful. 
2023-04-16 19:32:33,im very inspired by this. gonna launch my own database next week. have a killer name in mind.
2023-04-16 20:42:11,post by Vespa founder https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
2023-04-16 22:18:29,IPython ChatGPT extension
2023-04-16 22:20:34,"Neat, this can work with Google Colab in theory too"
2023-04-16 22:36:37,or is it just ranking them and using the closest match to the input
2023-04-16 22:37:17,Good questions
2023-04-16 22:37:37,Would love to hear what people have to say
2023-04-16 22:38:43,Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks
2023-04-16 22:40:18,Not sure whqts happening in here though
2023-04-16 22:41:18,makes sense..
2023-04-16 22:42:04,Anyone here who has worked extensively with these agents?
2023-04-16 22:42:04,There are few different things:
2023-04-16 22:42:31,[PHONE REMOVED] uses them almost daily to run his company and cribs about how broken they are
2023-04-16 22:57:12,If you do not like to use LLM for HTML parsing then this tool I found does a great job. But use it at arm distances because it is GPL3 licensed.
2023-04-16 23:12:31,not extensively yet but have the same experience.
2023-04-16 23:16:56,for now my plan is also to keep adding new tasks in classifier and seperating their workflow standalone
2023-04-16 23:36:53,"There are strategies in langchain for this.. map_reduce, refine, ..."
2023-04-16 23:38:57,Will read up on it. What's the umbrella term langchain uses for these?
2023-04-16 23:40:31,https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html
2023-04-16 23:40:35,memory chains or conversation memory
2023-04-16 23:40:58,those are different I think
2023-04-16 23:41:46,Summarisation sounds about right
2023-04-16 23:42:12,Memory is retrieval
2023-04-16 23:42:31,Sorry. You are right. It's summarization
2023-04-17 00:22:07,"btw folks langchain discord has a ""ask-kapa-langchain"" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase."
2023-04-17 00:24:16,"they also have integrated https://www.mendable.ai/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat?"
2023-04-17 00:28:18,"yeah. the kapa langchain bot is discord based. when you ask a question, it generates the answer in a thread"
2023-04-17 00:28:26,https://www.paradox.ai/solutions/recruiters
2023-04-17 00:30:03,Does this also have automated screening of resumes?
2023-04-17 00:32:11,https://www.skillate.com/
2023-04-17 00:34:50,https://leoforce.com/
2023-04-17 00:38:40,"Gottit ,I was planning on building an automated screening in my company "
2023-04-17 00:39:01,How do you solve for this issue if automated screening is used?
2023-04-17 00:39:50,I abandoned working on the prototype all together because of these issues 🥲
2023-04-17 00:44:53,Sounds a lot like the SEO - google war
2023-04-17 00:44:58,It's perennial
2023-04-17 00:45:14,One party is trying to deliver the best results to its usere
2023-04-17 00:45:30,The other party is trying to hack around that delivery logic
2023-04-17 00:45:42,True. The other side of this spectrum is someone building a resume builder to job candidates so that the resume is maximally similar to JD
2023-04-17 00:45:58,Never ending arms race
2023-04-17 00:46:51,"Yes, it's unethical. But if you won't use it, someone else probably will"
2023-04-17 00:48:09,"even today, recruiters don't do the first touch on resumes in big corps."
2023-04-17 00:48:10,Then the other side will start too :)
2023-04-17 00:48:42,There is also the matter of possible bias which the AI solutions might have. Which is difficult to solve for and a very sensitive issue.
2023-04-17 00:51:49,And then use chat GPT during the interview
2023-04-17 00:51:51,Boom
2023-04-17 00:52:32,Slightly off track but it reminds me of this dialogue from Batman Begins :)
2023-04-17 00:53:42,I’m seeing many companies ask candidates to come in person to the office for interviews for this very reason 😂
2023-04-17 01:13:39,"The _“actions”_ settings say it can retrieve upto 500 rows, but I’ve only been able to reach that limit for small, tokenised, chunked datas in each row"
2023-04-17 01:57:45,anyone here who can share some basic dope on how some people are creating realistic music with AI?
2023-04-17 02:01:48,Check:
2023-04-17 02:17:03,thanks ✅
2023-04-17 02:19:38,so there's no elevenlabs like product yet - right?
2023-04-17 04:46:39,https://gooey.ai/text2audio/
2023-04-17 07:58:19,Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it. 
2023-04-17 08:17:28,Summary of this in a thread here - https://twitter.com/psurya1994/status/1647628166792372224?s=20
2023-04-17 08:56:39,"Sharing the original paper here as well for completeness. The talk, thread are based off this and paper has some amazing examples"
2023-04-17 09:37:10,"If you'd like to present a paper summary e.g. Reflexion, Sparks of AGI, Amazon's MM-CoT at the meetup this Saturday, happy to help you outline and prepare. Please DM me soon!"
2023-04-17 09:37:27,BLR Generative April meetup: 
2023-04-17 10:08:50,"Here is one about review of fine tuning techniques  https://arxiv.org/abs/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning."
2023-04-17 10:09:42,Are we also calling model distillation as fine-tuning now? I see them both being used interchangeably on interwebs
2023-04-17 10:17:49,"Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4"
2023-04-17 10:52:25,https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12
2023-04-17 10:57:15,This seems to be GPT-3.5
2023-04-17 10:57:44,Someone tested using GPT-4 and they reported 21/108 questions being solved by GPT-4 
2023-04-17 10:59:56,"Also IMO these tests are very misleading ,it’s performance on zero shot prompting of JEE questions would obviously be poor "
2023-04-17 11:00:17,Present LLMs fake understanding
2023-04-17 11:00:24,"Plus we don’t really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores"
2023-04-17 11:00:39,Isn't having access to a Wolfram plugin basically cheating?
2023-04-17 11:01:14,It is sort of consistent with the fact that it cannot do complex math. For now. Physics and chemistry it can reproduce well with decent reasoning
2023-04-17 11:01:52,I’m 100% sure the ones reporting failure of GPT on JEE would be copy pasting questions in ChatGPT
2023-04-17 11:02:31,"""Significant gains are visible in the accuracy of the GPT4 model, in decreasing order of Chemistry(✨36%✨), Physics(14%), and Maths(3%) over ChatGPT on our challenge set"" thread says"
2023-04-17 11:02:40,"I’m curious to see the performance with Wolfram access + textbook content retrieval. Even though it’s kinda like cheating, considering the complexity of JEE it’s still impressive if it can solve with content retrieval and tools access as well"
2023-04-17 11:03:44,Also we're forgetting the value of negative marking
2023-04-17 11:03:52,"Exactly, these people just post results with some general prompting and then give a wrong impression"
2023-04-17 11:04:05,Not sure how else to train a LLM to solve complex math 
2023-04-17 11:04:20,Also perhaps there is some value in prompting it to skip math more than chem and physics
2023-04-17 11:04:31,Since it's dumber at maths
2023-04-17 11:05:19,+1 on this 
2023-04-17 11:05:51,In Zero shot prompting you’re just posting a question and taking at face value the first answer GPT provides
2023-04-17 11:05:52,Someone can experiment autogpt with jee and see where it leads
2023-04-17 11:06:03,Will be still useless with math I am guessing
2023-04-17 11:06:10,And also many low hanging fruit problems in JEE are repeat questions with slightly different values
2023-04-17 11:07:34,Also I'm sure GPT finishes the entire test in like 5 to 10 minutes
2023-04-17 11:09:48,And also sequential questions. Where one question's answer leads to the context of next one. I'm sure whoever implemented this experiment did not take into account the previous questions context and prompted GPT to answer it in isolation. 
2023-04-17 11:10:10,Anyone wants to join hands and work on this with me?
2023-04-17 11:11:25,Sure!
2023-04-17 11:11:46,Also had another idea if anyone is up to collab: https://replit.com/bounties/@JosephJacks/llm-ify-any-app
2023-04-17 11:12:05,"It still can't do math calculations, that must have been main reason why it failed brutally. I think it must have scored great in reasoning questions."
2023-04-17 11:12:17,Making a group
2023-04-17 11:12:21,Anyone else?
2023-04-17 11:14:49,"A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider"
2023-04-17 11:15:22,"actually interesting idea, I could give this a try…"
2023-04-17 11:15:57,Clip it up
2023-04-17 11:16:24,Not going to help 100% of the time but that is indeed very valuable context
2023-04-17 11:16:32,"I doubt clip would be effective with academic diagrams, worth a shot but i'm skeptical"
2023-04-17 11:17:06,Let's see
2023-04-17 11:17:28,If it isn't then we'll just prompt it to be a little hesitant in answering diagram based questions
2023-04-17 11:17:31,CLIP + some OCR logic + some prompting on top of that maybe idk
2023-04-17 11:17:34,Can probably glue up something like Amazon's MM-CoT and see if that helps with diagrams and figures? cc [PHONE REMOVED]
2023-04-17 11:17:56,I'm sure folks in this group can do much better than what these guys did
2023-04-17 11:18:10,I've already made a group with [PHONE REMOVED]
2023-04-17 11:18:20,We'll crack it soon!
2023-04-17 11:18:30,Happy to have more folks on board
2023-04-17 11:18:45,OCR is definitely required
2023-04-17 11:18:55,Flip your work to FOSS and post weekly updates :)
2023-04-17 11:20:28,are we opening a fiitjee for llms now :p
2023-04-17 11:21:01,If you start fine tuning it then definitely it’s FIITJEE
2023-04-17 11:21:22,overFIITJEE
2023-04-17 11:21:43,After all aren’t students “fine tuned” for cracking JEE ? 😝
2023-04-17 11:26:51,We can also skip image related questions in first try? and see how it performs on questions with no images.
2023-04-17 11:27:02,I am already in process of writing a paper on this. Should be up on arxiv by this weekend
2023-04-17 11:29:26,Problem:
2023-04-17 11:34:27,Working on similar problem statement currently 
2023-04-17 11:34:46,Should we spin off a separate group for speculative fiction enthusiasts?
2023-04-17 11:35:38,You can create a separate prompt for determining the question type. In the prompt you can keep the three options in MCQ format at the end of the prompt so you can easily parse the output. Keep this prompt at the very beginning before the retrieval part
2023-04-17 11:35:40,Already exists: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
2023-04-17 11:36:17,Thank you!
2023-04-17 11:49:38,"I agree we need better terms. Not sure what to call soft-prompting. It's not distillation. Customer don't want to use OpenAI + only davinci knows enough context to generate valid outputs but still needs fine tuning on data not publicly available. But they are insanely expensive to serve ($.12/1k token, that's 10Rs per output)."
2023-04-17 11:50:41,"So we are in this world of fine tuning local models. To be able to serve/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci."
2023-04-17 11:52:55,Btw did anyone try to ask chat GPT4 to solve ie Itodov?
2023-04-17 11:55:53,Imo atleast for the physics part for waves i did try. Let me know if anyone is able to try with questions of IE Irodov 😅
2023-04-17 11:59:50,"Models like MatCha or DePlot are trying to answer based on diagrams. https://huggingface.co/docs/transformers/main/model_doc/matcha , https://huggingface.co/docs/transformers/main/model_doc/deplot"
2023-04-17 12:04:11,"for diagrams, there's Google's Pix2Struct. trained on 9 tasks. links:"
2023-04-17 16:27:18,Vicuna-7B runs in Chrome Canary on M2 Macs with WebGPU
2023-04-17 16:28:33,"Super exciting direction because this means we can have LLMs which are private to _user_, not just _organisation_"
2023-04-17 16:29:20,"Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today"
2023-04-17 16:35:14,Giving me Blade runner 2049/Her vibes.
2023-04-17 16:36:32,_Apple silently beefing up their little ml cores inside iphones_
2023-04-17 16:36:54,"We already have that at a very small scale, your phone keyboard is personalised"
2023-04-17 16:39:20,"Fun fact: Person behind WebLLMs also developed XGBoost, TVM and MXNet"
2023-04-17 16:40:15,"yup. google did some very impressive stuff for on-device ML for Assistant and Gboard apps, a few years back."
2023-04-17 16:47:31,"Before my current product, I wanted to build an AI-enabled analytics product. Some thoughts on this:"
2023-04-17 16:51:13,Talk about a boss-mode Github
2023-04-17 16:52:32,Goat
2023-04-17 17:17:02,Fine-tuning davinci doesn't really work is what I have heard
2023-04-17 17:17:28,Prompt engineering davinci is almost always better than fine-tuning it
2023-04-17 17:19:52,For those not familiar with naming conventions: 
2023-04-17 17:23:15,The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis. 
2023-04-17 17:59:00,Can I get access? Trying to integrate something similar for our data warehouses
2023-04-17 18:09:08,DMing
2023-04-17 18:32:32,https://www.together.xyz/blog/redpajama
2023-04-17 18:32:45,who's picking all these names 😂
2023-04-17 18:40:58,An Indian employee of huggingface worked on this and published it
2023-04-17 18:42:00,During my research days I came across this dataset called LOL dataset
2023-04-17 18:42:52,It was a dataset of low light pictures and their well-lit versions
2023-04-17 18:43:13,I think I even used it in my papers and cited it
2023-04-17 18:43:45,Ohh I know this one: paperswithcode.com/dataset/lol
2023-04-17 18:44:01,Yes exactly that!
2023-04-17 18:45:13,It was the wild West in 2017 
2023-04-17 18:45:56,How could anyone compare their claims to these unreproducable publications
2023-04-17 18:46:14,Paperwithcode.com was quite helpful to compare my research with others
2023-04-17 19:22:10,"Haha lol yes. I remember those days. I spent months trying to make a sota model work for our data, then failed to reproduce then rebuilt with some more data then fine tune and rebuild and so on. Eventually I realised their sota was reproducible but nothing else worked."
2023-04-17 19:22:59,PSA: Please inform whosoever you're sharing the invite link with that this group is a firehose and somewhat technical in it's spirit. 
2023-04-17 19:24:55,but the lora paper didn't have any indian author
2023-04-17 19:25:47,"LoRA is from MSFT, that blog is from Huggingface DevRel — which has a couple of Indian origin folks in Europe"
2023-04-17 19:26:52,yes
2023-04-17 19:28:04,You exactly know my pain 🫂
2023-04-17 19:29:16,Were you working for a research group back then? Or was this an industrial task?
2023-04-17 19:29:22,[PHONE REMOVED]
2023-04-17 19:30:32,Oh my bad
2023-04-17 19:31:44,"Huggingface built a wrapper around multiple finetuning methods, called it PEFT: https://github.com/huggingface/peft"
2023-04-17 19:37:04,for my startup 🙂 Bewgle.
2023-04-17 19:46:27,My salutations
2023-04-17 19:46:57,Can't help but admire any founder ready to roll their sleeves up and get their hands dirty in some R&D
2023-04-17 21:37:32,https://twitter.com/NathanLands/status/1647864974323204096
2023-04-17 21:47:13,Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad 😞.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.
2023-04-17 21:48:13,"Just ask each of them - ""What is Bengaluru? Be concise"" and see all of them spectacularly fail. 😫"
2023-04-17 21:53:26,So Magi is Bards sister? / is this a rebrand because of all the bad press from the bard launch?
2023-04-17 21:54:45,Not PaLM?
2023-04-17 21:59:41,Is it PaLM? not sure.
2023-04-17 22:03:15,"it's Google. multiple launches, rebranding of the same product is their forte 😂"
2023-04-17 22:03:53,"We build some models and ensemble some others. Our use case is deliberately narrow- we don’t need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn’t behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn’t. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment."
2023-04-17 22:05:01,[PHONE REMOVED]
2023-04-17 22:43:58,"LLM Components to decide and weigh memory in Langchain, from the Generative Agents paper. Implements 2 agents talking to each other as well. "
2023-04-17 22:48:05,"i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?"
2023-04-17 22:48:31,especially in this case related to generative AI
2023-04-17 22:50:14,"Has any of you worked with LLMs for math problem solving, or used chain-of-reason prompting? We're delving into the problem solving use case and would love to discuss if you have."
2023-04-17 22:51:37,A good starting point:
2023-04-17 22:53:32,Grab hold of a prof. Or.. Enterprise researchers can help if you intern with them.
2023-04-17 23:10:52,"Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc."
2023-04-17 23:36:37,"github.com/shreyar/guardrails might be useful here, uses LLMs to give structured outputs including JSON, Python objects, XML and DSL like outputs should be possible too"
2023-04-17 23:57:16,Something something PCA Nishant
2023-04-17 23:57:34,*Nirant
2023-04-17 23:57:50,We caught you using old dimensionality reduction techniques 👀
2023-04-17 23:58:14,[PHONE REMOVED] : delt game moderate
2023-04-18 09:07:45,"Adept.ai got copied as an in the OpenAI Plugin Store, called Multi-on"
2023-04-18 10:12:05,We will need people who have the following experience:
2023-04-18 10:14:18,Meeting invite?
2023-04-18 10:16:27,"1. cc [PHONE REMOVED] has worked with CLIP, BLIP-2 and VQA"
2023-04-18 10:17:07,"As mentioned in the screenshot — Please find the group from Community in WhatsApp, Apply to Join, meeting link will be shared there :)"
2023-04-18 10:22:22,What are you trying to build?
2023-04-18 10:23:36,"[PHONE REMOVED] ajao sir, sending you the whatsapp invite directly"
2023-04-18 10:32:42,4. Multimodal vector similarity search - we're going to index image and text embeddings of useful information. Will definitely need someone with solid experience here.
2023-04-18 10:33:58,https://github.com/marqo-ai/marqo - probably can take a look at this db
2023-04-18 10:34:00,*vectordb
2023-04-18 10:36:20,I'm a bit oldschool here and prefer to stick with elasticsearch 😂
2023-04-18 10:36:43,"Is it tough to setup and maintain? yes, but I have production level experience of doing that so it's fine i guess"
2023-04-18 10:38:29,Should I bring an all-purpose AK47 to a knife fight and mention FAISS 😅
2023-04-18 10:38:58,"Additionally, all kinds of financial help in terms of openAI credits, GPU credits are welcome with huge open arms. "
2023-04-18 10:41:07,I'm in. I have curated a tagged dataset of a large number of JEE-styled questions that can be used for training.
2023-04-18 10:44:49,"Go ahead, I'll bite 🙈"
2023-04-18 10:47:39,"Lot of the modern DL infra is built around FAISS: Haystack (Deepset), Milvus, txtai. Even Langchain launched with FAISS."
2023-04-18 10:50:19,makes complete sense
2023-04-18 10:50:58,Maybe we can just train a KNN model and save its artifact locally so people can run it locally too
2023-04-18 10:51:31,Karpathy baba's SVM approach also makes complete sense in this usecase
2023-04-18 10:52:32,"Keep going down the path of Baba Karpathy, and soon you'll find yourself in a Random Forest with Boosted Trees. There my friend, I first saw wisdom."
2023-04-18 10:55:29,Are you saying that Baba Karpathy is the Yoda of the machine learning world?
2023-04-18 10:58:11,So Karpathy (w/ Fei Fei Li and others) was the one who demonstrated the LSTM+CNN Image Captioning Model in his PhD Thesis. He was also the one who introduced the idea of using model weights projected as an _attention_ map to debug models. This was a precursor to _Attention_ in the philosophical sense. 
2023-04-18 11:05:48,Truly a pioneer
2023-04-18 11:29:44,found this in the eval PRs
2023-04-18 12:51:03,https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
2023-04-18 13:24:42,Are there folks in this group interested in working on these problems? 
2023-04-18 13:25:42,Me - Problems I like
2023-04-18 13:25:51,Interested 
2023-04-18 13:26:11,3) Is something I've bee thinking about for a few years - How do you reduce unknown unknowns
2023-04-18 13:26:38,Also - https://www.together.xyz/blog/redpajama
2023-04-18 13:28:33,I’m interested as well. 
2023-04-18 13:29:27,what does the “personal search” problem statement mean?
2023-04-18 13:29:38,Been working on personal search. Will keep you guys posted.
2023-04-18 13:29:49,rewind.ai
2023-04-18 13:31:37,I'm interested in the multimodal AI project.
2023-04-18 13:32:18,DM me if you find mistakes.
2023-04-18 13:33:41,interesting…this must be really memory-heavy?
2023-04-18 13:35:25,The multi-modal AI project finds a direct correlation to what I work on currently. I would love to explore Generative AI to solve problems and build systems which are multi-modal.
2023-04-18 13:35:31,My key takeaway from skimming this paper was the iterative prompting. 
2023-04-18 13:36:25,Interested as well
2023-04-18 13:36:47,Interested in how to do domain specific feedback loop and fine-tuning. 
2023-04-18 13:44:14,+1 Interested in this too [PHONE REMOVED]
2023-04-18 13:45:05,+1 to domain specific feedback and fine-tuning
2023-04-18 13:45:48,What do you all mean by domain specific feedback? RLHF?
2023-04-18 13:46:55,Check out character.ai. They are doing something similar.
2023-04-18 13:47:02,Nice! Any comparison for open source LLMs?
2023-04-18 14:06:51,Interested
2023-04-18 14:09:16,"Folks, please share ideas which you can contribute/implement to indicate interest. Or even better, share any relevant code/paper which you've seen on the topic :)"
2023-04-18 14:10:29,Yes RLHF from the domain experts and internal team users. 
2023-04-18 14:11:33,Helpful list of directions
2023-04-18 14:15:46,are you planning to talk to Anton?
2023-04-18 14:23:45,Augmented reality Pokedex caught my eye.
2023-04-18 14:26:14,There is a openai model to convert image/text to 3D model I have seen: github.com/openai/point-e
2023-04-18 14:26:25,Yes there seems to be a project on this 
2023-04-18 14:27:10,Segment Anything Model was used to create an object mask from image
2023-04-18 14:27:53,Demo for anyone interested 
2023-04-18 14:29:51,https://t.co/sVSHuljpwe
2023-04-18 14:55:33,"Might DM, but this program is US or US remote. Wbu?"
2023-04-18 15:06:28,Anyone else facing issues with huggingface endpoints rn?
2023-04-18 15:16:50,Both Gh and hf are facing issues.
2023-04-18 15:20:20,personal search related: https://github.com/KnowledgeCanvas/knowledge
2023-04-18 15:24:41,"interested. working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data."
2023-04-18 16:20:15,These are some really interesting directions.
2023-04-18 16:44:37,Clashes with this meetup
2023-04-18 16:56:27,"Removing the previous message since we discourage self promotion and the person hasn't replied to a personal ping, has no name on WA, nor an active contributor here"
2023-04-18 16:57:14,"That is amazing! BLR should've more gatherings, hackathons for people to choose from!"
2023-04-18 17:05:32,Very good read
2023-04-18 17:05:34,https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/
2023-04-18 17:05:36,"Title is a bit misleading though. The point is that models will become better, but not by adding more base training data"
2023-04-18 17:13:16,Better chance of playing catchup for startups :)
2023-04-18 17:22:47,Especially comes after together  said that their model will be 1.3 trillion params
2023-04-18 17:24:04,Quick question for folks who are using LLMs in production(guessing there would be many in the group)
2023-04-18 17:29:00,One account with multiple keys - easier to consolidate and have conversations with OpenAI team on priority access.
2023-04-18 17:29:17,"we use AzureOpenAI, so tracking is pretty easy over there."
2023-04-18 17:29:32,I'm also doing this fwiw
2023-04-18 17:29:42,btw do Azure Credits work for Azure OpenAI?
2023-04-18 17:30:05,"cc Ankita [PHONE REMOVED] works for Azure India, can you please folks and confirm here?"
2023-04-18 17:31:23,Can you track dev and prod on the same keys though? I didn’t know that functionality was there
2023-04-18 17:31:24,"Our OpenAI access   is on a subscription level , so if you have credits on that subscription, absolutely will work"
2023-04-18 17:32:38,probably create different resources for prod and dev? haven't tried it though.
2023-04-18 17:34:55,"Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product 😅"
2023-04-18 17:35:14,1 strike next week*
2023-04-18 17:35:55,"You can always ask someone else to post, including me sir! 🙏🏼"
2023-04-18 17:36:24,Haha yea! Have to book some time with you anyway
2023-04-18 17:39:13,count me in as an early user
2023-04-18 17:40:30,[PHONE REMOVED] I heard there’s a meet up this sat. Where can I find details about this and how do I register?
2023-04-18 17:40:38,https://hasgeek.com/generativeAI/april-meetup/
2023-04-18 17:56:32,has anyone worked with context based search with cohere embeddings and openai gpt3.5 for non-english languages? how good it is in terms of results?
2023-04-18 18:03:04,Has anyone worked here with map_rerank chain types in LangChain? Would like to know of there is away to return the document metadata for sources alongside the QA responses
2023-04-18 18:03:39,map_reduce and refine both have this already. map_rerank should too?
2023-04-18 18:09:05,Worked with OpenAI. Good for some languages (eg Spanish) not good for others (Czech) based on feedback from our users
2023-04-18 18:09:42,Haven’t seen a good resource on what languages are good VS bad. Presume it’s based on amount of training data on the open web
2023-04-18 18:11:13,I am trying with Arabic but it just says hmm. I am not sure 🥲
2023-04-18 18:12:18,"I think you're right, I need to explicitly define which keys I want in the chain response, let me give it a try"
2023-04-18 18:12:21,"Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: دائما الرد باللغة العربية"
2023-04-18 18:13:09,"Hey everyone, please welcome [PHONE REMOVED]. My old roommate. He's from CMI in case anyone from CMI is here. 15+ yrs in tech. 8+ yrs in fintech space , currently building AI solutions for real estate sector in India/Middle East/ North America/ Australia."
2023-04-18 18:14:36,"I just said, replay in context's language.. but let me be specific."
2023-04-18 18:14:39,thanks!
2023-04-18 18:54:52,"I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another."
2023-04-18 18:55:32,"In the right place and product, this reply is worth hundreds of dollars!"
2023-04-18 18:55:51,Is there any cheaper and lower latency way to detect language? Especially in audio
2023-04-18 18:56:55,Open-source knowledge sir 🙏🏻
2023-04-18 18:56:59,In text we do this.https://github.com/Mimino666/langdetect
2023-04-18 18:57:24,But audio is a bit more difficult
2023-04-18 18:59:04,Not worked in audio.
2023-04-18 19:00:21,exactly what I started using.. by specifying the language it works for a generic question
2023-04-18 19:55:42,https://www.youtube.com/watch?v=30xueN12guw
2023-04-18 20:05:15,How easy/complex was this language detection/translation?
2023-04-18 20:05:30,And did it introduce some latency?
2023-04-18 20:20:27,[PHONE REMOVED] check this. If API based solution then it will add latency for sure.
2023-04-18 20:20:42,"Of the top of my head - Cut out a very short snippet of the audio, then use something like deepgram or whisper?"
2023-04-18 20:20:57,"smaller the file, lower the latency is my guess.. but haven't tried it"
2023-04-18 20:22:52,"Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation"
2023-04-18 20:25:54,"One issue is translation depends on context too, so chunks can’t be super small"
2023-04-18 20:35:40,So you can split on gaps in amplitude. With a rule like 5 gaps in one chunk
2023-04-18 20:49:34,This might actually make for a good cost reduction (compromising latency though) use case as well. Read the amplitude and omit parts of the audio where no sound was detected and then translate/transcribe
2023-04-18 20:51:30,Yeah that's pretty common in audio pre processing.
2023-04-18 20:51:51,Interesting.. didn’t know that
2023-04-18 20:52:54,Same for text too. we remove white spaces and new lines to save for tokens in document chunks. 
2023-04-18 21:06:50,"Hey Everyone,"
2023-04-18 21:08:02,Props for asking a well-formed question! 👏
2023-04-18 21:16:38,Can you please create a poll for this?
2023-04-18 21:27:51,I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses 
2023-04-18 21:29:07,"Let me zoom out a bit: I'm personally convinced that there is sincere interest. For a working group to happen, the bottleneck isn't buyer, reader or user interest — but builder/experimenter effort."
2023-04-18 21:31:44,I’m looking to slice audio too. What would folks recommend with Python? I know pydub is popular but I saw it requires an external package
2023-04-18 21:33:21,pydub is fine
2023-04-18 21:47:54,"hey, can you post an example input image? on which you're trying to do this task."
2023-04-18 21:49:33,Nice! Share more? or DM
2023-04-18 21:51:56,Happy to chat. Have build/deployed something like this before but not with LLM.
2023-04-18 21:52:51,"I think someone had asked on Text to Video, do check this"
2023-04-18 21:54:09,quick thoughts
2023-04-18 21:54:32,[PHONE REMOVED] might have some good ideas
2023-04-18 21:57:12,Just read your last point - have you thought of asking the user to select the best mask? Simple product problem vs complex AI pipeline
2023-04-18 21:57:51,could work depending on your product!
2023-04-18 22:12:41,Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more
2023-04-18 22:15:30,"Not GenerativeAI tbh, but pretty neat offering: https://www.causal.app/"
2023-04-18 22:15:47,https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2
2023-04-18 22:15:57,Open Source Bloomberg GPT
2023-04-18 22:16:27,"OpenBB is pure terminal play, right?"
2023-04-18 22:17:07,"I don't recall them doing a LLM, and if yes, what data and arch are they building on?"
2023-04-18 22:19:09,Yup I’d thought the same based on their site 
2023-04-18 22:19:22,"Yeah, pure terminal play, i think they get direct market data, earnings calls, and reports"
2023-04-18 22:24:29,Making videos via SD. This guy's last couple of reels are very good : https://www.instagram.com/reel/Cq5eWq4rRQC/?utm_source=ig_web_copy_link
2023-04-18 22:44:18,Have you tried using the latest control net models for intruct pix2pix (https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-instruct-pix2pix) 
2023-04-18 22:48:17,Discovered by [PHONE REMOVED]
2023-04-18 22:53:07,[PHONE REMOVED] have you come across any img2img models where I can generate variations of UI elements. 
2023-04-18 22:56:50,a very limited version of this used to be logojoy.com
2023-04-18 22:56:55,Pretty cool that its open https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0
2023-04-18 23:00:29,This is nice. I've played with Midjourney for logo creation and it was pretty good. 
2023-04-18 23:25:55,Can you explain what you mean by you have existing designs? Is it some type of sketch? Also can you elaborate on “segment various attributes of UI elements “ 
2023-04-18 23:27:57,Try this gradio space if you already have a sketch. https://huggingface.co/spaces/hysts/ControlNet
2023-04-18 23:32:18,"My understanding is that the maximum amount of control right now comes from control net models. Given that multiple controllers can be clubbed together and img2img and inpainting is also supported, with even huggingface launching a control net sprint , we will get a lot of community controlnets which can be used. T2I adapters is another approach but controlnet has community momentum with it."
2023-04-18 23:57:56,"Noob here, but would Controlnet (https://github.com/lllyasviel/ControlNet) be useful?"
2023-04-19 00:05:40,Existing designs - I've used some UI elements from the Koo app and tried dreamstudio. 
2023-04-19 00:08:03,Cool. Use the gradio space I shared. It would be a good starting point. You can also try playgroundai.com and see if that can help you
2023-04-19 00:09:33,Thanks a lot [PHONE REMOVED]
2023-04-19 00:23:34,"Hi,"
2023-04-19 00:24:29,"For readers, Shapiro Wilk is a measure of whether the data is normally distributed or not. https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test"
2023-04-19 00:27:14,"In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset — sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption. "
2023-04-19 00:29:37,Thanks for your input. Do you have any suggestions for methods I can use with a non normal dataset.
2023-04-19 00:29:44,"This was my thought too. This just violates some assumptions for linear regression variants, you can consider 1. other regression algorithms like tree based ones, or 2. See if the target can be transformed via a sensible function to close to normal distribution."
2023-04-19 00:30:44,2. *and then apply liner regression family
2023-04-19 00:32:30,Can you elaborate what you mean by confined? And really bad for what exactly?
2023-04-19 00:32:41,"Also, can you plot it somehow?"
2023-04-19 00:32:53,"I tried using support vector regression and experimented with non linear kernels, the results remained the same. Will try tree based methods as well."
2023-04-19 00:40:28,"Also, really sorry if I am making some stupid remarks/comments about the data. I have not worked a lot with tabular data, and I am just a beginner in Machine Learning."
2023-04-19 00:42:09,This is not some sort of time series data?
2023-04-19 00:45:46,No it’s not a time series data
2023-04-19 01:17:08,It's not a function in the traditional sense. It could the case that y = some_prob_distribution(x). Ex. Y = normal_distributed(mean =x)
2023-04-19 01:22:46,"Hey Guys, thanks a lot for suggestions on this. "
2023-04-19 01:25:04,Try jadoosnap.com
2023-04-19 01:26:38,Wanted to give users of I’m feeling lucky option :) Though a nice suggestion if they want total control!
2023-04-19 01:27:30,how did you blend the images? only if you want to share or is it a completely different approach?
2023-04-19 01:28:24,Yeah man curious to know! Results look quite nice!
2023-04-19 01:29:37,I actually did this exact approach.. researched online on how to blend.. saw adobe firefly results.. and dropped it 🥲
2023-04-19 01:30:31,Two cents
2023-04-19 01:30:57,DM me brother
2023-04-19 01:36:03,For the first part no my data isn’t categorical. 
2023-04-19 01:39:41,Would be great if we could get prettier backgrounds! Thanks already!
2023-04-19 01:58:32,Along with SD 1.5 inpainting ckpt
2023-04-19 01:59:29,"And this was with minimal effort on the prompting end, so results may get better with better prompting."
2023-04-19 02:19:20,Have you tried to use any inpainting models? They are opensource by runwayml. The one shared above by Abhishek. 
2023-04-19 02:25:52,Folks hoping all of you have seen launch of Open Assistant - https://open-assistant.io/ - opensourced alternative to ChatGPT by the LAION-AI initiative.
2023-04-19 02:40:08,I have seen this image somewhere. Is this a product of any startup?
2023-04-19 02:43:03,"The image is from my startups website. The “ product” is from a Instagram image of this company which sells candles. I just dropped out the hands, matchbox and light of the matchstick and incorporated into other image which I then used as base for controlnet inpainting."
2023-04-19 02:44:32,do you have a website to check it out more?
2023-04-19 07:49:17,https://github.com/geekyutao/Inpaint-Anything maybe this can work for you
2023-04-19 08:10:07,Thanks for the suggestions. I did use normal checkpoints with a basic prompt to see if they are understanding physical structure. I’m attaching one of the result where I gave the prompt “add dining table in background”.  
2023-04-19 08:26:30,"if your data is not normally distributed then you can use Extreme Value Theory tools. See Hill Estimator for instance, but there are others"
2023-04-19 08:48:28,Just curious to understand -
2023-04-19 08:49:37,"fwiw, in my experience trusting things which are made up is more common with my parent's age cohorts than urban, educated teenagers who seem to be skeptics by design"
2023-04-19 08:52:31,"Yeah, they are curious but how about keeping things age appropriate for them?"
2023-04-19 08:57:50,Thank you 🙏
2023-04-19 08:57:56,"cc [PHONE REMOVED] works on making the Google Play Store safe for kids and minors. Would love to hear more product design, generic principles from you 🙏🏼"
2023-04-19 09:02:49,"Since these interfaces will have image (search, generation) soon, there has been academic interest in detecting _sexy_ images as well. These are suggestive, but not porn or nudity. The line gets blurred even more with comics/anime/hentai."
2023-04-19 09:08:04,Speaking purely in individual capacity 
2023-04-19 09:10:05,We've been using this to ensure all questions are safe for works. Works decently well and is a requirement from companies
2023-04-19 09:14:04,This will be super interesting as I do not know of any specific regulation yet....
2023-04-19 09:17:13,"Sure, will look into that as well."
2023-04-19 09:36:21,Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?
2023-04-19 09:36:59,ouch
2023-04-19 10:16:57,Hi! I need one help.
2023-04-19 10:17:34,Fine tune vicuna on your WhatsApp chats
2023-04-19 10:17:58,index n retrive from vectorDB could be a easy quick start
2023-04-19 10:18:49,fine-tuning is not to save info . Its to teach a skill to the LLM
2023-04-19 10:19:07,Do you think dependence on these for home work affect reasoning abilities in kids?
2023-04-19 10:22:05,I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs. 
2023-04-19 10:22:19,"Yes, in my view"
2023-04-19 10:25:08,"yes. you just retrive the relavant context with cosine similarity , and simply feed it into the prompt. with character limit . it should work well . with some prompt engineering + if you using GPT4 put in the system message  to impersonate you based on the context provide. LLM chains"
2023-04-19 10:26:13,Do you think dependency on Google Search and Saved contacts affect our memory skills?
2023-04-19 10:27:10,These are memory recall skills aren’t they ?
2023-04-19 10:27:23,"hey guy quick intro i'm Akash , we are building a embedding engine specifically for code syntax.  also anyone here worked with Siamese search stuff ?"
2023-04-19 10:27:50,Parents I guess would be more concerned with reasoning skills being affected coz of using GPT
2023-04-19 10:28:32,Thank you Edgar and Akash! I will check these out!
2023-04-19 10:28:58,Our parents were worried about memory and we seem to be doing okay without them 😛
2023-04-19 10:29:22,https://twitter.com/hwchase17/status/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19
2023-04-19 10:30:04,cue the pessimists_archive twitter handle 😂
2023-04-19 10:31:03,🤣🤣🤣
2023-04-19 10:33:34,Heard it from Altman in the Lex friedman interview that he repeatedly says in the company to treats it's users like adults
2023-04-19 10:33:51,cc [PHONE REMOVED] for questions on QA evaluation and fact checking — since you worked on that problem
2023-04-19 10:38:36,I did. Curious how you are thinking of applying it.
2023-04-19 10:43:06,GPT4 8k and 32k versions are now available on Azure Openai India as well.
2023-04-19 10:46:32,https://twitter.com/varunshenoy_/status/1648374949537775616?s=52
2023-04-19 12:02:08,"You could additionally change the object's position and use SD Inpainting, which gives more variation results. [PHONE REMOVED] has mentioned those in details section of his product here - https://gooey.ai/product-photo-background-generator/"
2023-04-19 12:17:22,anyone here using promptlayer or other tools for prompt versioning? 
2023-04-19 12:52:53,Want to use a tool badly - is this good?
2023-04-19 12:55:46,Humanloop does A/B testing+versioning of prompts as well
2023-04-19 12:59:24,https://www.izzy.co/blogs/robo-boys.html
2023-04-19 13:01:26,haven't used it yet. but they integrate with langchain too.
2023-04-19 13:03:44,btw [PHONE REMOVED] is also working on this!
2023-04-19 13:05:11,"thanks! Yes, I'm going to announce this soon.. we have a few companies in beta right now so happy to help if someone wants a tool that works out of the box"
2023-04-19 13:13:34,👍 joined the waitlist
2023-04-19 13:33:13,https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html
2023-04-19 13:45:44,"interesting attempt at structuring prompts better. guardrail:XML, this:SQL"
2023-04-19 13:49:10,There should be some way to get nudged about cost incurred when running these via LLM calls lol
2023-04-19 14:00:33,https://python.langchain.com/en/latest/modules/models/llms/examples/token_usage_tracking.html
2023-04-19 15:08:11,Appreciate the guardrails shoutout!
2023-04-19 15:10:28,"Folks, I have a request. "
2023-04-19 15:10:40,"*/imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections."
2023-04-19 15:11:27,"Friends, Nilesh [PHONE REMOVED] is an engineer-turned-journalist covering Generative AI in India and it's impact on jobs and business"
2023-04-19 15:20:01,You can try openjourney if it's urgent
2023-04-19 15:21:36,https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png
2023-04-19 15:23:15,TIL Discord CDN has no auth!
2023-04-19 15:23:44,trying out the chatgpt-retrieval plugin. 
2023-04-19 15:25:06,It's an embedded image right?
2023-04-19 15:25:55,"just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too"
2023-04-19 15:26:12,full disclosure: trying to sign qdrant as consulting client
2023-04-19 15:28:16,"Yeah, using SQL lets me do embed ontology a little better, saves me a bit of time doing prompt engineering with vectordbs, but I have a theory about where all this is going to end up"
2023-04-19 15:28:36,RDF2text2vector
2023-04-19 15:29:46,"Literally no solution out there allows me to embed both taxonomy and ontology in my text right now, so my workflow is to put both of them in the text first before embedding."
2023-04-19 15:30:11,Hopefully someone comes up with RDF2vector directly
2023-04-19 15:30:21,my dataset has 7.5k rows…shouldn’t be a constraint right?
2023-04-19 15:30:46,"Weaviate even had an issue in gh for RDF2vec, but it closed due to lack of interest"
2023-04-19 15:31:20,Less than a million rows should be fine. qdrant CTO told me that they can do entire Wiki with inference usage of ~1.2G RAM 😧
2023-04-19 15:32:10,This sounds insane. Wiki text is around 80gb I think.
2023-04-19 15:32:51,(not sure that's just English though)
2023-04-19 15:35:52,English Wikipedia is the claim
2023-04-19 15:39:42,"Thank you, Shashank."
2023-04-19 15:52:09,what is the challenge with saving embeddings in a vector variable
2023-04-19 15:52:54,"In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU — or FAISS"
2023-04-19 16:00:59,"@here getting really disappointing result when cloning my voice on elevenlabs, any other tool/saas suggestions?"
2023-04-19 16:02:48,Checkout out VALL-E's unofficial PyTorch implementation  on GitHub. Facing similar issues with ElevenLabs
2023-04-19 16:06:45,Is there a way to use np.array for the chatgpt/retrieval-plugin? Didn’t find it in the documentation
2023-04-19 16:12:28,azure tts has a neural voice cloning service i think. haven't used it tho. i only used their presets.
2023-04-19 16:12:59,also Descript has cloning too
2023-04-19 16:26:56,is anyone working on AI financial advisors? change the incentive model. 
2023-04-19 16:28:48,"Chroma has a decent local db support, could start with that as well"
2023-04-19 16:29:40,Simple local dev interface to get started with
2023-04-19 16:33:30,How to use these custom dbs in chatgpt/retrieval-plugin??
2023-04-19 16:33:51,"also, it’s entirely open source. I like knowing the hood, helps to extend, debug and hack around. They will come up with their hosted solution soon"
2023-04-19 16:34:18,under the*
2023-04-19 16:35:33,"Not sure, haven’t checked out the retrieval plugin repo in depth. It kinda looked like a mess when I saw it first lol"
2023-04-19 16:35:49,Probably others could help here
2023-04-19 16:41:00,Has anyone retrained an open source transformer like llama? Mostly content creators are going gung ho around architectures like few shot learning/vector similarity
2023-04-19 16:42:10,"okay, I checked it out. You could check out this PR branch https://github.com/openai/chatgpt-retrieval-plugin/pull/59 and get started with Chroma"
2023-04-19 17:15:00,"Did you use it ? Issue with eleven labs is it doesn’t have Indian accent, it works well on American accent"
2023-04-19 17:15:25,I mean does vall-e not have same issue
2023-04-19 18:34:23,I opened an issue: https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410
2023-04-19 19:17:13,"I haven't tried it myself, but will patch you in with some folks :)"
2023-04-19 19:41:36,Sharing what I wrote today - 
2023-04-19 20:18:38,Has anyone evaluated - DeepSpeed - https://www.deepspeed.ai/ ?
2023-04-19 20:22:13,Deepspeed powers Bloom and LoRA from MSFT — so many people might've tried it without knowing
2023-04-19 20:22:29,*tried the output model
2023-04-19 20:29:32,Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google
2023-04-19 20:29:58,Has anyone felt/realized this anecdotally?
2023-04-19 21:04:36,"thanks, that’d be v helpful"
2023-04-19 21:06:31,"qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now 😅"
2023-04-19 21:14:53,"If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?"
2023-04-19 21:14:57,Does a pod correspond to a pinecone index? 
2023-04-19 21:16:40,Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way
2023-04-19 21:17:21,DevEx is the key - long Redis
2023-04-19 21:23:18,https://github.com/Stability-AI/StableLM
2023-04-19 21:35:59,Awesome !!! 🤩
2023-04-19 21:42:14,I wanted to know about how the different language models out there today are different.
2023-04-19 21:42:43,It’s already 20th April in some parts of the world so… 😅
2023-04-19 22:19:27,Any benchmark studies on how it's faring compared to existing models?
2023-04-19 22:21:24,"“As is typical for any pretrained Large Language Model without additional finetuning and reinforcement learning, the responses a user gets might be of varying quality and might potentially include offensive language and views. This is expected to be improved with scale, better data, community feedback, and optimisation.”"
2023-04-19 22:21:52,Have anyone used Weaviate? 
2023-04-19 22:22:55,"Also, wrt to embedding models, has anyone here done considerable research on which model is better? Ada from openAI is good, but how different is it from sentence transformers from HuggingFace?"
2023-04-19 22:23:47,Haha... I thought so but then the founding team mostly isn't based out of those areas
2023-04-19 22:25:54,It’s always 4/20 somewhere 💁‍♂️
2023-04-19 22:28:53,Haven't come across any benchmarks or anecdotal reviews
2023-04-19 22:33:18,"i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet."
2023-04-19 22:34:45,Not sure how many folks have tried the new Bedrock product by AWS but curious if folks think some of it and the aspects of model benchmarks potentially move to AWS
2023-04-19 22:35:42,Any idea where I can find it?
2023-04-19 22:36:04,For indian languages cohere multilingual embeddings are having good discrimination based on my experiments.
2023-04-19 22:37:13,https://twitter.com/Nils_Reimers/status/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19
2023-04-19 22:44:07,https://twitter.com/jerryjliu0/status/1648709029777252352?s=46&t=gjIVQMn9Hp7sUgYs_m23Ww
2023-04-19 22:44:25,[PHONE REMOVED] - again contributing with Evalset generator
2023-04-19 23:19:13,Thank-you for the mention Arpan.
2023-04-20 01:05:50,Thanks for the mention ravi! ❤️
2023-04-20 09:12:30,sorry I must have missed. Where is the meet-up ?
2023-04-20 09:13:05,"BLR, Saturday evening: https://hasgeek.com/generativeAI/april-meetup/"
2023-04-20 10:22:06,https://blog.replit.com/llm-training A good blog post by Replit where they give us high-level description of how they train their own LLMs
2023-04-20 10:44:17,What's amazing is that the team is <5 people :)
2023-04-20 10:45:33,Replit is < 5 people???
2023-04-20 10:47:35,The ML team
2023-04-20 10:48:09,Wow ❤️
2023-04-20 10:49:00,The entire engineering team ~50 people
2023-04-20 10:49:46,Talent density >> head count ❤️🔥
2023-04-20 11:14:39,https://twitter.com/fabianstelzer/status/1648700767992180737?s=48
2023-04-20 11:24:55,EyeQuant founder talks about text2film
2023-04-20 11:29:27,Proven again and again in the world of Foundational Models - almost all top companies have lean teams
2023-04-20 11:33:11,"Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors"
2023-04-20 11:36:20,midjourney outsourced frontend to discord 😂
2023-04-20 11:38:54,https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/
2023-04-20 11:45:51,Cracked crazy adoption
2023-04-20 12:39:52,Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88
2023-04-20 12:58:51,What tech is used for this?
2023-04-20 13:26:57,Are you tracking usage on a per-api key basis? Is this even possible?
2023-04-20 13:28:53,"OpenAI tracks usage per organisation basis, one way to work through this might be setting up different teams for different keys"
2023-04-20 13:29:31,I came across https://twitter.com/vboykis/status/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19
2023-04-20 13:32:25,Someone had a very good analogy on this :
2023-04-20 13:34:08,just org / no tracking per key possible. 
2023-04-20 13:37:36,Well said
2023-04-20 13:43:44,"Tried this last night. Controlnet inpaint model isn’t much better than the regular sd inpaint. The advantage though is that you dont need a custom inpainting checkpoint, so you can inpaint with community models like analog diffusion, openjourney, protogen etc or maybe even a lora model?"
2023-04-20 13:49:27,"This is the comment by the author of the controlnet repo: """
2023-04-20 13:52:21,"Thanks. I used diffusers lib with the hugginface checkpoint so yes probably not as good as a1111. The inpainting code in general has always been super well done in a1111, really amazing stuff! What’s the status of a1111’s python api these days?"
2023-04-20 13:55:54,I haven't worked with the API yet. So wouldn't know. Also the diffusers library isn't upToDate with the latest release. This is because the repo author is working on integrating it with automatic1111 first.
2023-04-20 14:01:41,What resolution is this?
2023-04-20 14:02:04,768x512
2023-04-20 14:02:50,The glass seems to have been modified a bit?
2023-04-20 14:04:11,yeah. I didn't mask correctly. I am testing other aspects of the controlnet.
2023-04-20 14:08:25,Keep us posted :-)
2023-04-20 15:16:13,cc [PHONE REMOVED] since you opened this thread
2023-04-20 15:17:12,"The best way to insert an external object like a glass into another image is to just overlay it in another layer using photoshop or free web based photopea. Export as a single image (img1). Also export an image in the same dimensions but with only the glass and the rest of the background black (img2). Then inpaint over and around the glass in img1. Load img2 into controlnet. Use canny, depth, hed maps or a combo of these based on the kind of object. Adjust the controlnet weight appropriately. Also adjust the weight of the right word in the prompt like (glass:1.2)."
2023-04-20 15:20:21,Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny / depth / hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image.
2023-04-20 15:31:06,This is awesome [PHONE REMOVED] Thanks a lot for this. I'll update once I have setup Automatic UI.
2023-04-20 16:12:11,How hard to push per key API results to Prometheus? From there use any UI tool like grafana to monitor per API usages.
2023-04-20 16:40:35,Is anyone using GPT4 in prod? I'm sending gpt-4 as the model but its still using gpt-4-0314. Have heard gpt-4 is much more faster than the 0314
2023-04-20 17:02:10,Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR.
2023-04-20 17:04:29,Which LLM’s? Pix2instruct? Or any other LLM?
2023-04-20 17:10:18,say GPT-4? I know the multi-modal functionality is not rolled out yet but curious of  Visual Document Q&A is an application since you can ask it questions about images.
2023-04-20 17:11:47,I was just checking out this repo: https://github.com/clovaai/donut
2023-04-20 17:11:51,Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments
2023-04-20 17:11:54,Doesn’t use OCR
2023-04-20 17:14:35,"I've tried it, hard to fine tune to your use case and get consistent results"
2023-04-20 17:15:52,Ya tesseract is great. I’m coming from the perspective of one model to rule them all. It’s clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API
2023-04-20 17:18:20,"In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base"
2023-04-20 17:24:22,"[PHONE REMOVED] pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing"
2023-04-20 17:26:15,"I see. Since they are taking in images, I was thinking there might be some ocr involved"
2023-04-20 17:27:26,"Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?"
2023-04-20 17:28:11,"Today, or in future? "
2023-04-20 17:29:41,"Got it, thanks."
2023-04-20 17:29:57,Future changes everyday nowadays 😅
2023-04-20 18:03:11,"Sounds reasonable. Additionally, can I audit the requests made to each api key?"
2023-04-20 18:09:13,Labels can be used to pass API key hash or user friendly name (do not pass exact API key :))
2023-04-20 18:19:19,I tried using MM-REACT using hugging face space provided by them. It works much better than Donut. The work uses Reasoning capabilities of LLMs to extract information from visually rich documents
2023-04-20 18:19:44,https://github.com/microsoft/MM-REACT
2023-04-20 18:29:46,https://github.com/Layout-Parser/layout-parser
2023-04-20 18:30:41,"last time i checked, langchain had a layout-parser integration for pdfs"
2023-04-20 19:22:15,https://blog.eleuther.ai/transformer-math/?s=08
2023-04-20 19:32:36,"Optimised implementation for Whisper, faster than real time 🚀"
2023-04-20 19:34:22,Sanchit is absolutely killing it
2023-04-20 19:36:08,Sahi! Anyone know the costs?
2023-04-20 19:37:03,Has anyone tried fine tuning dolly2 yet?
2023-04-20 19:37:52,It is open source 
2023-04-20 19:58:46,[PHONE REMOVED] This was so-vits-svc
2023-04-20 20:29:22,"What tools or best practices you guys use for recording LLM experiments (for example, with what change of parameters, how much reasoning/relevancy of retrieved results increased along with tracking metrics like accuracy/precision improvements, finding difficulty in managing ways to look through various Jupyter notebooks etc? W&B is a familiar tool, but want to capture and know the Gist of all the experiments at one place. Looking forward to hearing your suggestions 🙏"
2023-04-20 22:51:08,https://twitter.com/CohereAI/status/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19
2023-04-20 22:53:04,"Given the model specificity for any operations, the more open and accessible you are, the more acceptance you will have by early adopters, more traction you will get"
2023-04-20 22:54:14,"Cmiiw, stability haven't made their latest stable diffusion model available to public and is only available on their dreamstudio ui, right?"
2023-04-20 23:28:18,minigpt-4 is better
2023-04-20 23:30:32,and https://llava-vl.github.io/ is very good too. Does well on gpt-4 samples
2023-04-20 23:36:26,https://twitter.com/marty_catboy/status/1649032460573745152
2023-04-20 23:37:03,Martin Shkreli's AI launch
2023-04-20 23:56:45,Btw very nice talks going on live at Weights & Biases LLMOps London event - https://www.youtube.com/watch?v=YfBtytGNEKE
2023-04-21 02:16:58,This guy says he used langchain 
2023-04-21 02:27:24,WebGPT - run gpt models entirely on the browser. based on WebGPU. 
2023-04-21 02:35:43,damn. WebGPU seems to be a great ROI for folks building apps that concerns client privacy
2023-04-21 07:38:09,Absolutely love this resource! 
2023-04-21 08:23:52,https://kubiya.ai/
2023-04-21 08:24:00,Has anyone tried something similar?
2023-04-21 08:30:25,What caught your eye? Why is this interesting?
2023-04-21 08:35:24,"Can apply helm charts, debug, rollback on K8s clusters all via using a chat interface using natural language"
2023-04-21 09:09:01,"Well computer engineering goes in circles. It all started with command lines, then started becoming fancier, spent enormous efforts building GUIs and now after all the decades of innovation we are back to … command lines 😆(essentially)"
2023-04-21 09:33:34,😆😆
2023-04-21 09:37:34,https://blog.replit.com/llm-training this one
2023-04-21 10:03:29,I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask. 
2023-04-21 10:03:50,Like this technique
2023-04-21 10:09:23,I was hearing it live ! Pretty awesome talk Amogh !
2023-04-21 10:11:37,Thanks!
2023-04-21 11:01:07,"You didn't pray to the demo Gods, they almost tested you there 😂"
2023-04-21 11:04:34,Good demo and techniques there 👏
2023-04-21 11:05:08,I was going to do pre recorded videos but [PHONE REMOVED] keeps me so busy at Dashtoon that I had no time and had to wing it live 😛
2023-04-21 11:26:51,Is there any good drawing to 3D tools out there
2023-04-21 11:27:12,cc [PHONE REMOVED] is a 3d artist and has worked with NeRFs
2023-04-21 11:30:15,https://www.reddit.com/r/StableDiffusion/comments/12etqvx/tutorial_creating_a_consistent_character_as_a/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
2023-04-21 11:30:21,Create consistent AI characters across images with SD
2023-04-21 11:30:37,Is there an AI art/ text to image group? [PHONE REMOVED] [PHONE REMOVED]
2023-04-21 11:32:37,"This is the one for now — hence the ""DeepMedia"" in the name!"
2023-04-21 11:36:10,I agree on separate image group too 😅
2023-04-21 11:36:50,Text is so much more popular but would want to have 100% coverage on images.
2023-04-21 11:37:54,I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) — so if more than 10% (>30)
2023-04-21 11:37:55,Can we join if we are noobs looking to start in deep media ?
2023-04-21 11:39:04,[PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED]  please vote :P
2023-04-21 11:39:32,I’ve not muted
2023-04-21 11:39:52,It’s actually a really high quality group. I’ve met some really smart people on here 🫡
2023-04-21 11:40:08,I agree.
2023-04-21 11:40:23,"But from discussion standpoint, just want images/video specific place too 😅"
2023-04-21 11:42:20,"Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of ."
2023-04-21 11:42:33,Yessss. Beginners are welcome in the community! This is why I personally take the pain to dig up everything from UI components to VectorDB benchmarks for questions asked here!
2023-04-21 11:42:55,Working on this. Releasing next Friday.
2023-04-21 11:44:18,Hero we deserve
2023-04-21 11:44:34,"Thanks, man. I recently got into LLMs stuff, so I'm missing the text to image and basically all the new recently released techniques on the image generation. This will really be helpful."
2023-04-21 11:45:13,There should be an option for Not Applicable
2023-04-21 11:45:21,Agree!
2023-04-21 11:45:27,"Yeah, that's ""No"""
2023-04-21 11:47:02,"there are already like 5 groups in this community, it's becoming like the slack channel hell 😂"
2023-04-21 11:47:13,Yes please. Separate image group please
2023-04-21 11:48:16,"Ah! Have a lot of controlnet, SD and text to video stuff I’d love to share and have deeper discussions. Have felt this group is more towards LLMs and NLP and image stuff doesn’t get discussed as much."
2023-04-21 11:48:50,Haha “NO” can be rude
2023-04-21 11:48:51,😂
2023-04-21 11:50:27,"And much like Slack, the expectation is that you've 1-2 core channels where you contribute actively, sporadically in 2 more and lurk in the rest :)"
2023-04-21 11:50:42,Dont follow all is the secret to all slack groups :D
2023-04-21 11:50:43,You can just choose to not vote 😅
2023-04-21 12:15:44,I promise to contribute more actively to the resultant text-only group :)
2023-04-21 12:36:36,Guess I tipped the balance. Can us commoners get a new group? 😬
2023-04-21 12:41:47,"DeepMedia: Generative Art (Text to Images, Video, Music)"
2023-04-21 13:14:11,Haha [PHONE REMOVED]  we need a Text to Action group as well for the next revolution in AI ..
2023-04-21 13:14:49,New poll please
2023-04-21 13:15:00,Early joiners beer on me 🍺
2023-04-21 13:15:28,"Yes sir, in couple of weeks when we've more people interested in actions :)"
2023-04-21 13:16:21,Haha 😂  I know an expert in building AI community..
2023-04-21 13:19:08,"folks, noob request here."
2023-04-21 13:21:27,Illustrated Transformers: https://jalammar.github.io/illustrated-transformer/
2023-04-21 13:21:49,Thanks a ton Nirant!
2023-04-21 13:52:26,https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
2023-04-21 14:19:12,https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this
2023-04-21 14:21:20,"🙇‍♂️ thanks, my weekend will go well"
2023-04-21 14:41:42,Really nice. Did you write a script for whatsapp web?
2023-04-21 14:42:45,Can export chat to plain text and regex on it :)
2023-04-21 14:43:05,yeah this. now tweaking to get context. almost done
2023-04-21 14:43:29,Langchain it! Release code to Github. I'll add the features I'm working on as well.
2023-04-21 14:45:34,My Ola's ex-colleague built this. See if this is helpful 
2023-04-21 15:36:33,"""Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples"" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 ) "
2023-04-21 15:39:54,https://arxiv.org/abs/2303.12712 in this paper Microsoft researchers who had early access describes to an extent how they think it works. Finally they also conclude they don't know how it works 🙁
2023-04-21 15:53:34,How did you do this so quickly
2023-04-21 15:54:58,export chat+pandas
2023-04-21 15:55:05,+github copilot ofc
2023-04-21 15:58:19,"Love how ""Langchain it"" is becoming a verb here"
2023-04-21 16:45:37,"Am sorry if I'm missing something here. What's new in this? Isn't this what we have been doing in most LLM apps? Just feed the context. Model won't ""learn"" anything."
2023-04-21 16:47:39,"In context learning examples include input/output pairs, not just stuffing data into the prompt"
2023-04-21 16:53:09,There is an interesting Microsoft paper that checks the values at various layers of the transformer when giving examples in the prompt vs fine tuning the models with the same examples for 1 epoch. They find similar values in both and have a theory that prompting with examples causes implicit gradient descent which helps the model perform on the unseen example.
2023-04-21 21:46:42,"Question for the embeddings experts in this group: say I have a hybrid index on Pinecone. Then during my query, I *only* input dense (semantic) embeddings, what happens? Does this mean it will query only using the dense embeddings or am I likely to get bad results?"
2023-04-21 21:47:32,"With Pinecone, we don't know. We'll have to read their docs"
2023-04-21 21:48:39,"okay cool, i will do some digging and report back here as Im sure its useful to others. FWIW I'm migrating from dense only -> sparse + dense and a lot of these little questions come up"
2023-04-21 21:59:59,"Same story here, would be interested in hearing more about your experience (will share mine once I have gone through it)"
2023-04-21 22:58:13,Text to (relatively) high res video is here:
2023-04-22 00:55:58,"Hi, I am bit new with using GPU. I want to train/run few models. "
2023-04-22 00:57:29,You can try this if it works for you https://colab.research.google.com/drive/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing
2023-04-22 00:58:33,You can get a free tesla T4 from google
2023-04-22 00:59:50,"You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :("
2023-04-22 01:03:12,https://fullstackdeeplearning.com/cloud-gpus/ This comparison table might be useful.
2023-04-22 01:04:03,Thank you Sachin and The Last Samurai. I will go through these links!
2023-04-22 01:10:09,Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.
2023-04-22 01:17:08,Wow! I think this will solve my problem! Thank you Nirant!!
2023-04-22 01:28:04,"also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too"
2023-04-22 01:38:01,https://www.freecodecamp.org/news/how-to-use-google-colab-with-vs-code/
2023-04-22 01:42:43,Seems like they have banned it 
2023-04-22 07:24:32,"Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand"
2023-04-22 10:44:48,Thank you!!
2023-04-22 10:51:02,I am actually failing to understand the pricing of cloud gpus.
2023-04-22 10:53:09,"You need economies of scale, not considering maintenance and over head"
2023-04-22 10:53:22,Also interests rate on capital investment
2023-04-22 10:53:23,e2e networks give some GPUs. 
2023-04-22 10:54:45,"Also the current price point is similar across many providers, so we already have an optimum price discovery for this asset"
2023-04-22 10:58:18,Got it guys! Thanks. This makes sense.
2023-04-22 12:04:46,I have one. 
2023-04-22 12:05:35,https://vast.ai/
2023-04-22 12:05:52,Any reviews on this cloud GPU rental
2023-04-22 12:08:12,16Gb memory is not enough.
2023-04-22 15:37:35,"Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful"
2023-04-22 15:38:14,The Docker file will have this RUN pip3 install torch --index-url https://download.pytorch.org/whl/cpu for my Linux machine
2023-04-22 15:38:19,Hope this is useful
2023-04-22 15:43:13,"Hi, How can you enable multiple checkpoints in automatic1111?"
2023-04-22 15:50:53,While fine tuning the model using dreambooth?
2023-04-22 15:51:20,Yeah
2023-04-22 16:44:20,"Awesome. If you have any public images/code, please share. Thanks"
2023-04-22 18:00:59,Folks will we get the recording or decks of today's talks ?
2023-04-22 18:02:39,Decks yes. I'll email them to the email on the registration one. 
2023-04-22 20:27:24,"Hey guys, what’s the solution to privacy while using chatGPT? Most enterprises don’t want to risk sharing their sensitive information to chatGPT?"
2023-04-22 20:29:41,We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs.
2023-04-22 20:36:14,What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results?
2023-04-22 20:36:45,Thanks for organising the event! [PHONE REMOVED] and others (whose names I didn’t catch 😅)
2023-04-22 20:36:53,"IIRC, GPT-4 launched with McKinsey as a client. Maybe they can use that to assuage any privacy concerns"
2023-04-22 20:37:18,Then lightning rounds were good. Would like to hear more of what others have been building..
2023-04-22 21:10:07,FROM python:3.8-slim-buster
2023-04-22 21:54:02,https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I’ve used it frequently and it worked great for my use case
2023-04-22 22:40:34,Will DM you!
2023-04-22 22:53:36,Privacy is important as a principle for enterprises. What’s the best way to figure out which model will work for a particular use case? Any blog/advice on that?
2023-04-22 23:52:54,Have y’all seen this: 
2023-04-23 00:03:40,Looks interesting. 
2023-04-23 00:38:44,"I can look around, but nothing comes top of mind."
2023-04-23 01:26:45,Thank you!! I will reach out :D
2023-04-23 05:34:37,Thanks!
2023-04-23 06:26:47,Does anyone have access to Anthropics pitch deck? 
2023-04-23 06:44:43,OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely. 
2023-04-23 08:21:21,First instance of an Indian politician referring to deepfakes / audio synthesis?
2023-04-23 08:31:41,"Hi all,"
2023-04-23 09:31:38,course.fast.ai for being able to make sense of all of this — even as it changes in 2-3 months and we add VQA (Vision) to mainstream OpenAI APIs
2023-04-23 09:33:31,"Lot of new work should come from STT and TTS side, including performance improvements like Whisper-JAX in the coming 4-6 month and more important, voice cloning, avatars and the like. They should have their own ""Lensa moment"" as such if someone markets it well."
2023-04-23 09:34:56,Stable Diffusion/Generative video?
2023-04-23 09:35:31,Not for beginners I think... but I should say Stable Diffusion does get people hooked ... I got hooked like that 🙂
2023-04-23 09:35:31,Depends if your friend would like to get more into theory or hands on applications
2023-04-23 09:35:54,most devs want hands on first i think
2023-04-23 09:38:12,"This is good learning path, only it skips all the LLM theory"
2023-04-23 09:45:32,if i had to recommend a course to cover the NLP hands-on with theory - https://www.udemy.com/course/nlp-with-transformers/
2023-04-23 11:20:51,"This used to be super helpful when heroku was free and we could deploy our applications on heroku. Last I remember, Torch CPU and other packages took less than 500mb to deploy"
2023-04-23 11:21:15,Was talking about this
2023-04-23 11:33:44,You can still pretty affordable (about $2/mo) instances on Fly.io
2023-04-23 12:38:31,"If there's anyone interested, Mckay Wrigley is starting a course on Replit on AI dev. The advanced stuff is coming soon but here's the day 0 course. https://twitter.com/mckaywrigley/status/1649492404943323136"
2023-04-23 12:48:16,Thanks
2023-04-23 13:15:18,controlnet Inpaint guidelines for A1111. https://github.com/Mikubill/sd-webui-controlnet/issues/968 [PHONE REMOVED] you can try out with this and let me know how it is working for you. 
2023-04-23 13:15:53,From the author of controlnet repo: 
2023-04-23 14:48:56,"Hi everyone! Shreyas here, I’m a product designer at Clari working on revGPT, a chat interface to get on top of everything happening with sales in an organisation ( and a few personal projects:) ). "
2023-04-23 16:52:21,"I saw this tweet by the guy who made BabyAGI, with a new approach to vector search & embeddings: https://twitter.com/yoheinakajima/status/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg"
2023-04-23 16:53:01,"He then goes on to say that the “paper”, the code, and the twitter thread as well, were all created with ChatGPT"
2023-04-23 16:53:25,Can the experts here explain if this is all fluff or has actual basis?
2023-04-23 16:53:36,https://yoheinakajima.com/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search/
2023-04-23 16:55:56,Not fluff. Nakajima has been tinkering with AGI for long
2023-04-23 16:56:43,"Yep. I was referring to this new technique for vector search which he came up with, or chatgpt came up with"
2023-04-23 17:11:30,Lol. He literally said he has idea what it does.
2023-04-23 17:13:43,Well I didn’t say he didn’t knew what he’s talking about or that what he’s speaking is fluff.
2023-04-23 17:15:09,"Yep. Still assimilating. Atleast from a reco system lens can comment : in theory, this can potentially be a good approach"
2023-04-23 20:36:29,"what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing"
2023-04-23 20:37:13,This WhatsApp group 🙈
2023-04-23 20:39:04,I hear OpenAI has some decent folks
2023-04-23 20:39:33,should have a job board :)
2023-04-23 20:41:41,This would be helpful - looking for an AD/Director of ML for my team too 🙌🏼
2023-04-23 20:42:31,How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one.
2023-04-23 20:43:07,Looking to hire folks as well - full time or part time! Job board would be ideal
2023-04-23 20:44:18,"I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?"
2023-04-23 21:11:16,Oh it’s ridiculous. 
2023-04-23 21:16:54,I haven’t come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set.
2023-04-23 21:21:12,"For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers / [ something like that ] and pass the Embeddings to OpenAI for completion"
2023-04-23 21:21:22,They’re also building foundation models 
2023-04-23 21:21:26,"Hence, ^"
2023-04-23 21:21:29,"Don't know if this helps, thought of putting this"
2023-04-23 21:21:46,[PHONE REMOVED] has built a wrapper around openai tiktoken to count tokens in a file or text -
2023-04-23 21:28:00,I think we can put one google doc in the group description. Should be good enough to solve the purpose. :)
2023-04-23 21:28:56,Or another group in the community for sole job seekers and employers!
2023-04-23 22:37:45,"I was trying to generate an image of ""a key ring with the OpenAI logo on it"""
2023-04-23 22:41:25,"u can use ControlNet canny model https://huggingface.co/spaces/hysts/ControlNet, just start with the openai logo, select the canny model and give the promptt"
2023-04-23 22:43:45,"If it had the keyring chain-thing, that'd be pretty cool, trying out the ControlNet model"
2023-04-23 22:46:13,As someone who did hire from this group in some way and trying more. 
2023-04-23 22:48:22,pardon my bad drawing
2023-04-23 22:50:01,"Thx, this is something very close! will finish the remaining using gooey"
2023-04-23 22:50:58,"This was controlnet only btw, both canny and hed boundary worked well (you can change that in settings)"
2023-04-23 23:18:32,Anyone working on open domain Q&A type problems or ones which make use of retreievers/dense embeddings?
2023-04-23 23:21:57,Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success).
2023-04-23 23:31:25,"Oh cool, can you share what kind of models and retrieval algorithms you are using?"
2023-04-24 03:09:29,Yup we use OpenAI at the moment and dense embeddings only (OpenAI again)
2023-04-24 03:09:34,Going to move to hybrid soon
2023-04-24 03:24:21,"Oh cool, are you doing similarity search on a flat embedding space to retrieve context?"
2023-04-24 03:32:04,"At the moment, yes. Might change depending on what we focus on / feedback from customer s"
2023-04-24 09:20:29,Came across this GitHub where someone used PEFT to fine tune a LLM based on their iMessage chats to impersonate so that you can create a bot which talks like you 
2023-04-24 09:23:07,Son of Anton 😜
2023-04-24 09:27:33,"cc [PHONE REMOVED] who runs a similar community, [PHONE REMOVED] who is in a Marketing role at Slice, and tech savvy generally"
2023-04-24 10:41:35,Hi rohan happy to connext
2023-04-24 12:06:28,Any supabase user is there? 
2023-04-24 12:07:42,You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?
2023-04-24 12:07:47,"If it's an rpc call, can you explain analyze the sql?"
2023-04-24 12:07:58,Or check your RLS policies
2023-04-24 12:08:51,RLS polies are public. 
2023-04-24 12:08:57,https://explain.dalibo.com/
2023-04-24 12:09:05,posted their too- but no response yet
2023-04-24 12:09:17,Use this to visualize your query to understand where it's slow
2023-04-24 12:10:00,Add indexes for parts of the query where there's a mismatch between planned rows and returned rows
2023-04-24 12:10:49,Unoptimized reads on RLS policies won't show up here. So do check for that separately
2023-04-24 12:11:23,ahh okay..
2023-04-24 12:11:52,Send the specific link on the Github or discord forum with more details
2023-04-24 12:11:53,Can help
2023-04-24 12:13:02,Folks @brkirch ... Automatic1111 guy is doing a new branch for Mac release of Automatic1111 - I tried it much faster than the stock Automatic1111 ... but it is still experimental
2023-04-24 12:13:03,https://github.com/brkirch/stable-diffusion-webui/releases
2023-04-24 12:13:15,https://github.com/orgs/supabase/discussions/13923
2023-04-24 12:14:53,cc [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] Thought this might be interesting to you
2023-04-24 12:15:25,Woah this is great
2023-04-24 12:15:53,hahah was just tagging you and [PHONE REMOVED]
2023-04-24 12:19:29,It's failing because the query us timing out. Two options :
2023-04-24 12:19:59,Need to get a 64 gb mac like [PHONE REMOVED] now
2023-04-24 12:21:12,ahh okay. let me try
2023-04-24 12:22:26,Are school kids in India using chatGPT ? 
2023-04-24 12:25:00,"If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. [PHONE REMOVED] mentioned how his daughter's friends are using it."
2023-04-24 12:26:03,https://e2eml.school/transformers.html
2023-04-24 12:26:12,Yeah the demographic data isn't available but the percentage of users in India is just going up month on month
2023-04-24 12:27:20,Same here. Hear anecdotal evidence of kids going majorly into it. My 12 yo son using it to rephrase stuff from Wikipedia for school essays 🤣😅
2023-04-24 12:36:22,What is memory usage before hitting a query? Also what is data size?
2023-04-24 12:36:36,"on the second step , while copying the data from one column to another"
2023-04-24 12:38:11,Memory Usage is around 63% before and after... 
2023-04-24 12:38:30,However you guard. Kids are smart and they know how to navigate around restrictions. 😅
2023-04-24 12:38:35,"Friends, how long do I've to wait before I can say ""off-topic"" for Supabase/Postgres performance queries? Asking for a friend 😅"
2023-04-24 12:38:42,Nice! 
2023-04-24 12:39:10,okay. sorry.. I didn't knew that..
2023-04-24 12:40:28,"No sweat, just want to be cognisant that we've 600+ folks here and they're here mainly for keeping up with GenerativeAI. Supabase is quite likely not relevant for them :)"
2023-04-24 12:40:51,make sense
2023-04-24 12:42:26,Would ❤️ to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions? 
2023-04-24 12:42:51,https://www.reddit.com/r/selfhosted/comments/12w4p2f/localai_openai_compatible_api_to_run_llm_models/
2023-04-24 12:43:03,Yourself? :)
2023-04-24 12:44:32,[PHONE REMOVED]
2023-04-24 12:45:09,The intent is to have mid-speakers (we're all mid compared to Amod) as backup incase we've speaker cancellations. 
2023-04-24 12:53:50,"Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?"
2023-04-24 12:54:18,Cohere (Nils Reimers) for sure — I've a half a page of questions also!
2023-04-24 13:01:11,Is there any event/session link to register for the same?
2023-04-24 13:03:59,I will try to get it setup. Will share with the community
2023-04-24 13:34:42,Yes please would love transformers or diffusion models in the May one. Any takers here?
2023-04-24 13:37:10,"For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. [PHONE REMOVED] and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon."
2023-04-24 13:39:58,https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting
2023-04-24 13:40:43,"Addendum: The April theme was Question Answering (hence a QA demo + QA internals) aka ""How to make your own ChatGPT for internal docs"" "
2023-04-24 13:40:48,"The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep [PHONE REMOVED] (https://www.linkedin.com/in/soumyadeepmukherjee/?originalSubdomain=in) — previously Infra at Udaan and now runs a Generative AI company in Bengaluru."
2023-04-24 13:41:05,💯 
2023-04-24 13:42:04,"[PHONE REMOVED] taught a Stable Diffusion workshop in Feb, and there wasn't enough interest at that time. We'll consider this going foward."
2023-04-24 13:45:02,"Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more. "
2023-04-24 13:46:14,"Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time. "
2023-04-24 13:47:28,"Yeah, by default, workshops will be paid. Upto the educator to price them. Can set this up early May and ask here :)"
2023-04-24 14:05:56,"So the way me and Nirant have been thinking to structure like 1 product/usage/use-case talk, 1 deep dive into some engg optimisations/libraries/use-cases and 1 deep dive into fundamentals."
2023-04-24 14:08:13,PSA - we had a stable diffusion workshop in March has.gy/1CNF
2023-04-24 14:56:41,"Hey [PHONE REMOVED] can you explain a bit on ""creating realistic images"" specifically what would be the topics on this. Is it prompt oriented or model oriented or something else?"
2023-04-24 15:35:13,Sure works - was thinking this would be similar to Amod’s talk but can do a paid workshop too
2023-04-24 15:35:22,Makes sense
2023-04-24 15:35:28,Both - but mostly model oriented and more complex dreambooth methods
2023-04-24 15:35:34,Or rather less known
2023-04-24 16:37:57,Sounds good
2023-04-24 16:42:09,Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!) 
2023-04-24 17:17:12,https://warpspeed2023.devfolio.co/
2023-04-24 17:27:32,"Piratewires is always great, one of my favourite substacks"
2023-04-24 18:39:30,"This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic."
2023-04-24 18:40:43,[PHONE REMOVED] ? 🤔
2023-04-24 18:46:55,"I work in these areas, happy to chat!"
2023-04-24 19:06:19,Did some work few months back with mediapipe along with integration in blender. Though not updated with recent developments
2023-04-24 19:07:50,"I've worked on a few projects where we did live performance capture, yes. Happy to chat about it!"
2023-04-24 19:18:55,https://twitter.com/Uncanny_Harry/status/1650462479237931008?s=2
2023-04-24 19:23:10,Text is easier to read on a phone than a text inside an image :) Type the text ;)
2023-04-24 19:25:03,"If it's a marketing plug, please refrain."
2023-04-24 19:28:19,"It is not. But happy to remove it if you think so. Sorry, I happen to be a marketer 🙏🏽"
2023-04-24 19:28:33,Anyone here has experience working with Interoperable Master Format? Would love to connect.
2023-04-24 21:18:05,Has anyone noticed differences between using newlines/replacing them when using openai's embedding api?
2023-04-24 21:19:33,"While you're at it, [PHONE REMOVED] and I'd love to know why Langchain does a newline replacement too 😅"
2023-04-24 21:38:07,\n is probably not a token in the vocabulary
2023-04-24 21:42:31,Creating a token from an unknown world and having it in the vocabulary is different. The model’s vocabulary are words that it understands to encode into something meaningful in the encoder.
2023-04-24 21:43:47,Can you elaborate or rephrase a bit? I didn't understand
2023-04-24 21:44:49,https://www.livemint.com/companies/start-ups/indian-engineering-colleges-lead-generative-ai-research-projects-in-indic-languages-facing-challenges-in-data-sourcing-and-computing-power-11681663553393.html
2023-04-24 21:46:12,"Let’s take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary."
2023-04-24 21:46:41,So while a newline could be a token it doesn’t have any semantic meaning when it’s encoded.
2023-04-24 21:47:35,"Aaah, that'd make sense. Thanks for explaining!"
2023-04-24 21:49:43,"So to rephrase the original question —  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?"
2023-04-24 21:54:11,"If the vocabulary has new lines, you could keep them. But for all practical purposes I haven’t seen models contain any space, tab or new lines in models"
2023-04-24 21:54:31,You will use up tokens and not get any advantage in terms of results
2023-04-24 21:54:40,"Sometimes, new line matters for text splitting/ chunking. (Such as splitting by para). Then the /n has meaning, correct?"
2023-04-24 21:55:11,I'm referring to text splitting pre-embedding
2023-04-24 21:55:51,Those are character splitters. Yeah they look into these control characters.
2023-04-24 21:56:51,"The assumption from the model author is that you would split texts the way you see fit and then remove unknown vocabulary, tokenize and then feed the texts into the model."
2023-04-24 21:57:58,*text splitters
2023-04-24 22:02:52,My approach for choosing splitting and sanitizing texts would be to run some experiments and see what preserves or improved the performance of the model with the least number of tokens.
2023-04-24 22:03:23,Context length obviously plays a role also. Can’t go longer than ctx supported.
2023-04-24 22:03:31,might be the reason for the extra tokens too? As the new line + word is not recognised as a common enough token
2023-04-24 22:04:26,You could look into the source code of the tiktoken library on GitHub to see how they are doing it. It’s purely heuristics.
2023-04-24 22:04:50,The tokenizer is called C100k or something
2023-04-24 22:05:49,gpt-4 uses a different tokenizer but they haven't updated the url you linked with that.
2023-04-24 22:06:51,yes
2023-04-24 22:13:11,"Nice, love pirate wires - good source of truth with lesswrong and scott alexander"
2023-04-24 22:13:51,Can help - explored and published on these topics
2023-04-24 22:25:30,https://twitter.com/aribk24/status/1650372832524926977?s=20
2023-04-24 22:25:35,responded*
2023-04-24 22:26:07,Worked in pose estimation (egomotion/SLAM etc) and deployed in few places. Dabbled in human pose at some point but not up to date with lit. You can DM. Not much in mocap/face-body reconstruction.
2023-04-24 23:02:11,How did you do this?
2023-04-24 23:08:16,We did something very similar for the hackathon - there are some good voice models out there
2023-04-24 23:22:28,Holy shit! Let’s go Arib. Arib hooked me up with a free ticket to a Sam Altman session. What a great dude
2023-04-24 23:24:34,This thing is going to take over the world.
2023-04-24 23:58:21,Sounds legit ! Can you repost your hackathon link? 
2023-04-25 00:11:07,what are some cool chatgpt related chrome extensions y'all have come across?
2023-04-25 00:35:19,V. interesting read on potential to use RL without human feedback: https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81
2023-04-25 00:36:39,"Not entirely sure if this belongs here, but which are most interesting OSS projects in the space? I finally have some free time and would love to contribute more."
2023-04-25 00:52:42,ShareGPT!
2023-04-25 01:02:32,One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI 😝 and not be bothered to text-back during the week. And just be presented with a date on the weekend.
2023-04-25 01:02:46,For that I had to make a chrome extension that can read all my chats
2023-04-25 01:05:13,"she: you're so fun, so when do we go out?"
2023-04-25 01:05:42,🤣🤣🤣🤣🤣
2023-04-25 01:06:03,No it's trained exclusively to type like me with a super low temperature
2023-04-25 01:06:24,I don't want to come across as someone I'm not
2023-04-25 01:07:15,"Just wanted my own two extra hands, not an AI ""dating expert"""
2023-04-25 01:08:37,time to recreate: hang the DJ
2023-04-25 01:10:05,beware of prompt injection attacks 😂
2023-04-25 01:15:32,Next feature is a vector search on all the girls I've swiped right in the past and autoswiping on girls that cross a certain similarity threshold. Will apply to their images and also their textual information like bios.
2023-04-25 01:16:37,It's still in POC stage 😝
2023-04-25 01:16:55,can those occur in my context?
2023-04-25 01:17:14,Damn exactly what I was looking for
2023-04-25 01:21:07,idk honestly. yours is also low temp. so maybe more difficult than usual? my understanding is that most prompt injection out there is tested on the default temperature 0.7
2023-04-25 01:23:42,"If anyone wants/needs help on prompt injection, please send me your model. I enjoy interacting with LLMs to trick them into breaking things."
2023-04-25 01:34:31,Will do once I'm out of POC stage
2023-04-25 01:35:13,Yeah plus the training dataset is made from my chats
2023-04-25 01:36:03,**creates fake profile to send ojasvi a prompt injection attack**
2023-04-25 08:42:58,Feels like a dialogue straight outta ‘Indian Matchmaking’
2023-04-25 09:27:41,https://openai.com/brand
2023-04-25 09:34:59,+1 on this 
2023-04-25 09:37:49,"Transformers is the generic term, GPT was their branding from the beginning"
2023-04-25 09:38:29,This is for Branding if you want to mention OpenAI. Just don’t mentioned them and you can name anything.
2023-04-25 09:39:13,ah so do they have a trademark on GPT?
2023-04-25 09:40:53,https://techcrunch.com/2023/04/24/gpt-may-be-trademarked-soon-if-openai-has-its-way/
2023-04-25 09:57:22,"The fact that ChatGPT, as being associated with OpenAI is widely known - they’re only trying to prevent any use of [insertword]GPT that may suggest an association/affiliation/partnership with OpenAI when there may be none. "
2023-04-25 12:45:17,Any of you use qdrant for vector search? It looks really cool and easy to use as well.
2023-04-25 12:45:51,"The difference between pinecone, Milvus and Qdrant is so small!"
2023-04-25 12:52:42,Redis and Qdrant. Have tried Chroma too. 
2023-04-25 13:03:00,Developer Experience?
2023-04-25 13:11:35,off-topic - anyone wants to complete a Bounty for Yohei Nakajima? https://replit.com/bounties/@YoheiNakajima/scrape-an-api-and-se
2023-04-25 13:15:26,Too little money for trivial work?
2023-04-25 13:15:48,Has anybody tried training any of the openai models on code?
2023-04-25 13:17:02,Embeddings plus GPT-3.5 should be able to do it
2023-04-25 13:17:05,"While I read through the fine tuning section of openai docs, just wondering if there are any do/donts/tips that I should keep in mind"
2023-04-25 13:17:14,Not perfectly though
2023-04-25 13:17:55,Is fine tuning necessary?
2023-04-25 13:18:29,I did kind of a similar approach to create diagrams using MermaidJS. Created embeddings from the docs and added gpt-3.5. Worked well for the most part
2023-04-25 13:20:38,Most of these components have several parameters that they accept that define the behaviour of the UI component.
2023-04-25 13:22:09,Plan of action that I have in mind:
2023-04-25 13:25:49,"Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance."
2023-04-25 13:38:11,Thanks
2023-04-25 13:47:53,I couldn’t setup Qdrant and Chroma with the chatgpt-retrieval plugin 😢
2023-04-25 13:48:23,https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410
2023-04-25 13:49:23,Is there a consensus yet on the best affordable spot GPU / cloud providers?
2023-04-25 13:53:38,Haha great idea - how did you train it?
2023-04-25 14:05:32,Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use.
2023-04-25 14:28:24,I got access to this. Haven’t installed yet 
2023-04-25 14:28:42,Nice! Which model? 
2023-04-25 14:29:04,so-vits-svc fork
2023-04-25 14:29:15,This is how world will end
2023-04-25 14:30:21,"I like the disclaimer : "" Havent installed it yet "" . : )"
2023-04-25 14:57:36,Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search. 
2023-04-25 14:59:37,Haha
2023-04-25 15:16:25,This was not a scam? Had strong scam vibes
2023-04-25 15:20:34,Can you tell us which parts require training vs which parts are zero shot / one shot inference?
2023-04-25 15:26:03,https://arize.com/observe-2023/
2023-04-25 15:30:58,I haven't trained these models myself because of data prep requirements.
2023-04-25 15:32:01,Is someone kind enough to share their gpt4 access for a day and half please? 🥹
2023-04-25 15:32:49,"For GPT4 access, you can try https://github.com/xtekky/gpt4free"
2023-04-25 15:32:58,In case you do not have a paid subscription
2023-04-25 15:33:12,I want to clone Arijit Singh's voice. Will have to collect and clean the data.
2023-04-25 15:36:55,"Ah, so its like style transfer for speech, nice"
2023-04-25 15:38:18,Yup.
2023-04-25 15:57:31,Hire someone on upwork/fiver? Costs <50 USD for this
2023-04-25 15:57:33,And 2 dats
2023-04-25 15:57:34,days*
2023-04-25 15:58:56,Are you using https://beta.elevenlabs.io/ for this?
2023-04-25 15:59:44,Nope. https://github.com/voicepaw/so-vits-svc-fork
2023-04-25 16:07:55,Someone leaked pretrained models of many popular singers a week back. Was that for this project?
2023-04-25 16:08:56,Probably. Wait I'll share.
2023-04-25 16:09:09,https://docs.google.com/spreadsheets/d/1qzeFdpUPr7E0jOFwWSXd8LF30ZLjz1CSVEBiG8gPHTU/edit#gid=1792554832 this one?
2023-04-25 16:41:02,They even got Freddy
2023-04-25 17:02:19,https://twitter.com/tivadardanka/status/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA
2023-04-25 18:21:27,https://aiagent.app/
2023-04-25 18:34:42,This is pretty cool! Know who's built this?
2023-04-25 18:35:34,The toolkit says coming soon
2023-04-25 18:36:16,something that’s already here - fixie.ai
2023-04-25 18:38:49,doesnt this look like godmode.space (or just AutoGPT in general)?
2023-04-25 18:38:54,Fixie's SDK is pretty powerful
2023-04-25 18:39:36,has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.
2023-04-25 18:41:07,have you used this?
2023-04-25 18:41:23,"I have, a bit"
2023-04-25 18:41:40,Worked for the 30 mins i played with it
2023-04-25 18:47:22,How are you running it on prod? Docker? Is it a cluster?
2023-04-25 18:48:06,"The concept is fun, but I haven’t really found it useful."
2023-04-25 18:54:00,"It's a cluster, but we're using their managed SaaS service WCS, https://weaviate.io/developers/weaviate/installation/weaviate-cloud-services"
2023-04-25 18:59:22,"Just out of curiosity, why not?"
2023-04-25 19:02:35,"depends on the application I guess? I generally use it for paraphrasing (for which chatgpt suffices) and coding (where none of these models work very well - haven't tried GPT4 which some people claim is much better, but more expensive too)"
2023-04-25 19:19:47,"why not? at least thats the idea wit medical AI, as of now humans by nature will not trust AI diagnosis any more than a human doctor's diagnosis. AI assisted healthcare makes sense from both effort minimization and improving patient outcome"
2023-04-25 19:20:32,an example: https://whiterabbit.ai/
2023-04-25 20:31:44,"Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines."
2023-04-25 20:33:57,Serverless? Modal and Banana type services?
2023-04-25 20:33:59,Have it forever - https://gooey.ai/compare-large-language-models/?example_id=7ihhyv3l
2023-04-25 20:37:17,"Okay, I am not sure if serverless would be right for us. So I have a normal python script with multiple diffusion models and hosted via flask/streamlit. Sorry, little noob in hosting :p"
2023-04-25 20:37:47,"wow - this should help my case, if they offer what they claim."
2023-04-25 20:38:11,"Hey Shivansh ,"
2023-04-25 20:38:25,happy to connect and understand how we can help you
2023-04-25 20:38:58,Arey this is mine only :) DM for bugs and feedback
2023-04-25 20:39:03,https://arize.com/observe-2023/
2023-04-25 20:39:58,We’ve spent a lot of time trying diff GPU hosting platforms. 
2023-04-25 20:40:09,Check Modal Labs perhaps? It's beginner friendly and they've Python-friendly web endpoints: https://modal.com/docs/guide/webhooks
2023-04-25 20:56:51,Ongoing webinar on Dolly right now. Still on for another 30 mins. 
2023-04-25 20:58:21,Q&A so far. In case it's helpful for anyone.
2023-04-25 21:03:44,Open Source (Llama 30B-based) rival to ChatGPT from Huggingface:
2023-04-25 21:03:59,Must be WA blue 🤣
2023-04-25 21:06:11,You're welcome :P Did this via apple app on mac in case there's an actual constraint on other devices :P
2023-04-25 21:26:21,"Fine tuning vs sending long, detailed prompts is a very interesting topic/Product design requirement"
2023-04-25 21:28:27,My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction. 
2023-04-25 21:28:46,Added Q to above:
2023-04-25 21:28:47,*satisfactory output
2023-04-25 21:28:49,https://manifold.markets/IsaacKing/will-any-llm-have-a-context-window
2023-04-25 21:29:07,Related discussion here https://news.ycombinator.com/item?id=35682424
2023-04-25 21:31:02,"Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?"
2023-04-25 21:31:30,"Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better?"
2023-04-25 21:31:50,Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?
2023-04-25 21:32:09,How do we think of expenses?
2023-04-25 21:32:27,More input tokens would mostly mean more expensive API calls?
2023-04-25 21:33:25,Expenses is ~ # of context window tokens to and fro on OpenAI atleast
2023-04-25 21:33:45,"My understanding so far is that GPT 4 especially is very capable for most use cases with few shot in-context learning. So would be easier to test and learn like this, figure the nuances of the use case and then evaluate smaller fine tuned models."
2023-04-25 21:33:53,Makes sense. With that in mind 1M tokens of context will be much worse on $ than fine tuning maybe.
2023-04-25 21:35:01,But say we were using an open source model (Llama? alpaca? Of the future) where pricing isn’t a factor of token count. The large context window approach will work better with more flexibility?
2023-04-25 21:35:46,Open question still - anyone tried both approaches?
2023-04-25 21:37:25,(Adding to what Karan said)
2023-04-25 21:41:45,I think it's a function of Product maturity
2023-04-25 21:45:00,"If it's a multi tenant setup, I think it's better to finetune on the combined data for all tenants and then use few-shot prompting to refine for every customer."
2023-04-25 21:49:59,"Umm, if I'm a chatbot/conversational AI company and have competing customers (say Axis and HDFC) as my clientele, I'd likely have a base model and fine-tuned (forked) versions of the same running inside the environments of Axis and HDFC"
2023-04-25 21:52:02,The former use-case was via anecdotal research
2023-04-25 21:53:06,How much are we seeing Indian clients caring about their data being used for model training? Is it just regulatory heavy industries like banking or are non-reg industries saying the same? (Eg Ed-tech)
2023-04-25 21:53:40,https://www.researchgate.net/publication/370213628_Scaling_Transformer_to_1M_tokens_and_beyond_with_RMT
2023-04-25 21:54:23,Personal experience from a limited sample set - more about the use-case than regulations
2023-04-25 21:58:44,"I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data. "
2023-04-25 22:00:23,Also important to build a differentiated solution. Else anyone can create the wrapper without fine tuning
2023-04-25 22:01:32,Well said. We have a similar vision - start with embeddings and then at some point fine tune per client (maybe per team)
2023-04-25 22:01:36,Precisely why AI has higher marginal costs (and poorer GMs) than traditional cloud software
2023-04-25 22:03:29,You can get away with embeddings right? So there’s no training?
2023-04-25 22:10:21,discussing this for a complicated usecase where finetuning is required in some capacity. So pureplay embeddings and few shot prompting won't work is the assumption here.
2023-04-25 22:12:45,"Those models doesn't not have RLHF etc, not just smaller models. So you will be seeing perf similar to GPT3 and some more: your fine tuning. You will need other models and then train RLHF or use one of the RLHF trained models and try. Haven't done the last part. You will most likely need to fine tune RLHF as well, as the new models might have drifted in the output space."
2023-04-25 22:16:55,"Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white."
2023-04-25 22:17:33,What's the exact fine print that is difficult to decipher?
2023-04-25 22:18:16,"From what I understand, context is the application's and not Open AIs but want to understand this further."
2023-04-25 22:18:35,Tell them they’ll loose everything when their competition uses chatgpt to outperform them 😗😝
2023-04-25 22:19:30,Scare is definitely one approach haha :D
2023-04-25 22:19:31,And it took the big 3 15 odd years to instil this trust
2023-04-25 22:20:10,"Or tell them you’re using azure, azure has like a direct passthrough of gpt"
2023-04-25 22:20:16,"Used replicate and runpod.io, would recommend both for serverless and stateful use cases"
2023-04-25 22:20:19,"In typical Amazon fashion, better selection inside a VPC that customers trust with Anthropic which is possibly the biggest competitor to OAI today"
2023-04-25 22:23:07,"It feels like a good tool for scaffolding, but also a bit blind. The way the repo is also feels limiting. "
2023-04-25 22:24:25,"Their wordings are something like ""OpenAI may use content to provide and maintain services"". What he heard from an OpenAI engineer was won't be used for training* (*to be verified by the engineer). Don't know if Nirant or others heard an update from their team."
2023-04-25 22:30:03,https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy
2023-04-25 22:31:04,"Open AI engineer Boris Power - ""Prompting leads to faster results, with fine tuning it's painful to edit with changing data. Use fine tuning for exact format of input and output and if you have lots of historical high quality data. New use cases - fine tuning acts a lot of cost. Fine tuning doesn't do well when you need to understand facts and then provide the output"""
2023-04-25 22:33:01,Thanks for this. Could be helpful for us.
2023-04-25 22:33:32,They did say in an email that all data is deleted within 30 days and it’s not used for training
2023-04-25 23:03:18,https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt
2023-04-25 23:06:34,Already did this. Like how this is fine print on the website since Sam said the purpose of releasing chatgpt to the world was (high frequency / diverse) user feedback.
2023-04-25 23:07:55,*this was
2023-04-25 23:54:09,"Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety."
2023-04-26 00:27:45,"OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions."
2023-04-26 00:30:14,I think multinationals too will move to start using them. Their models are quite good and it is just a matter of time.
2023-04-26 00:36:21,"They do need more data, just not api platform customer data."
2023-04-26 00:37:49,Data Partnership: Interesting.
2023-04-26 00:51:43,Anyone have a list of data partners for Open AI?
2023-04-26 00:54:48,Nah... They don't talk about how they train their new models either in terms of data or architecture...  Their platform api  data policy is public info though...
2023-04-26 09:29:54,"I spent a day in march at openai office when they have invited some startups. They are very much looking to get more data to train their models from the industry because they have exhausted internet and academic datasets. However their organization is so small that they are able to cater to partnership proposals only from the biggest tech companies right now, all of which are lining up at their door. Over time they may get to your request."
2023-04-26 10:49:13,"Woah, it would have easily made 90%'ile in my undergrad randomized algo course at IIT."
2023-04-26 10:50:43,"If it helps, BITS Pilani did not have a randomized algo course — we had a design and analysis of algorithms, which was more analysis than design: And even Turbo does better than on those questions (specially speed!) than I do even today 😅"
2023-04-26 10:53:38,"Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics"
2023-04-26 10:54:08,Apparently they built this under 2 weeks
2023-04-26 10:56:42,https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19
2023-04-26 10:57:37,"Widely known no? Even GPT3.5-turbo and GPT4 are a Codex iteration, not vanilla LLM?"
2023-04-26 10:59:08,"Widely known to maybe scientists, not discussed much I feel"
2023-04-26 11:00:16,"Fair, I might be suffering some form of inside-track groupthink here 😅"
2023-04-26 11:06:17,"To many, I wouldn't think it does"
2023-04-26 11:06:50,"Aligned, it's a utility like ec2 in 3 years or sooner"
2023-04-26 11:19:46,100% - this is the difference between AI now and 5 years back.
2023-04-26 11:20:28,The UX of consuming models was not great up until openai came into the picture.
2023-04-26 11:22:15,Still kinda sad that HF hasn't learned this well enough tbh
2023-04-26 11:22:56,"Once we have a well supported IR which works across all platforms, serving and consuming models from source would become a lot easier too."
2023-04-26 11:23:54,They were born at a different time. Compared to their competition at that time(2017-18) they have done well.
2023-04-26 11:24:49,Almost everyone who does NLP now makes their models work their transformer library.
2023-04-26 11:25:08,In 2018 we spent half a day finding out how to use a model someone trained lol
2023-04-26 11:27:38,UX bhi and ML application development pipeline bhi 😅
2023-04-26 11:27:46,Stanford NLP 🤌🏼
2023-04-26 11:32:17,https://www.reddit.com/r/StableDiffusion/comments/12yzd2a/google_researchers_achieve_performance/
2023-04-26 11:32:25,Anyone working on ML on edge here?
2023-04-26 11:32:30,This looks big
2023-04-26 11:53:15,Some of this stuff like flash attention is generally applicable even on servers
2023-04-26 11:53:57,Wow!
2023-04-26 11:56:58,https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android
2023-04-26 11:57:10,Some earlier work from Qualcomm
2023-04-26 12:00:28,Pretty cool. Quite interesting that there is a huge jump from chatGPT. Will try this on the JEE ones we all were trying.
2023-04-26 12:29:10,Palantir launches ChatGPT for war 
2023-04-26 12:31:39,Damn expect anduril to come up with something too
2023-04-26 12:46:21,The full video link for those who are interested in involvement of tech in defence and future wars
2023-04-26 12:50:17,this makes me sad
2023-04-26 12:58:22,I hate that their tech usecases go from disaster relief efforts straight to drone warfare
2023-04-26 13:47:00,"Well for one, this is clear proof that programmers are god living among us ☺️"
2023-04-26 13:47:29,Only 2 ML engineers that too :)
2023-04-26 13:53:09,"Any idea how 10 days of traning time translates to total gpu time spent, i.e. including experiments?"
2023-04-26 14:20:53,"I’ve worked with Pete Warden and the tinyml folks at Google, used to be with the company that owns the accelerators for their voice wake, happy to chat !"
2023-04-26 14:33:57,Wonderful!
2023-04-26 14:33:58,Will DM
2023-04-26 16:12:48,Anyone knows how they did it with 1/10th the parameter count?
2023-04-26 16:15:30,Keeping it coming pls. Beginner insights most welcome Some of us still noobs in the group. 3 month old industry for us 😂
2023-04-26 16:21:50,Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM 🙏 🎼
2023-04-26 16:23:02,Doesn't look like they've some unfair data (qty or quality advantage) — they just decided to test Chinchilla limits and that worked. They trained for a lot more tokens than most people have tried for similarly sized models. 
2023-04-26 16:23:26,"PSA: Dedicated group for music, images, video: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J"
2023-04-26 16:23:51,If anyone remotely knows this person. An expert talk by then would be helpful ++
2023-04-26 16:24:00,them *
2023-04-26 16:24:14,Replit Demo Day videos are soon going to be on Youtube from what I hear
2023-04-26 16:24:37,"To all the silent VCs in this group feeding this chat thread to an LLM, pls help 🙏 😂"
2023-04-26 16:25:53,"Slide Deck from Accel's [PHONE REMOVED] on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes. "
2023-04-26 16:26:08,yeah will be up tomorrow - and the model should be released soon as well
2023-04-26 16:26:25,Thanks!
2023-04-26 16:26:32,Thanks Anshul sir! Anshul sir [PHONE REMOVED] leads Replit India
2023-04-26 16:38:18,Thanks! Was this a closed session?
2023-04-26 16:38:52,Yes Sudharshan .. i did this for Accel funded startups - founders and tech teams
2023-04-26 16:40:40,"Alright thanks, was going to ask for invites to future sessions - this is really good"
2023-04-26 17:06:14,https://twitter.com/matthieurouif/status/1650904940036890626
2023-04-26 17:07:29,The gpt-4 multimodal model has an api yet? I thought it was chatgpt only
2023-04-26 17:08:06,GPT4 takes text in and can generate prompt for a SD/Midjourney landscape
2023-04-26 17:10:18,They use photoroom 
2023-04-26 17:11:31,"Not out, you can use https://minigpt-4.github.io/ or https://llava-vl.github.io/"
2023-04-26 17:11:43,Doesn't have image understanding
2023-04-26 17:11:47,https://dust.tt is awesome!
2023-04-26 17:11:50,It's internal for now
2023-04-26 17:12:39,better than modal or runpod?
2023-04-26 17:12:58,"Shared interest, please keep me posted on your connects !"
2023-04-26 17:13:56,"It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own"
2023-04-26 17:14:56,Dust.tt is amazing!
2023-04-26 17:19:18,Nice looking at the docs
2023-04-26 17:19:56,"i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?"
2023-04-26 17:26:29,https://www.linkedin.com/posts/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios
2023-04-26 17:46:49,[PHONE REMOVED] is playing with music gen these days
2023-04-26 17:46:56,Novelty isn't the only dimension. Ease of use is greatly improved and tons of Shopify stores which sell everything from soaps and other trinkets would love this. 
2023-04-26 17:53:25,oh totally agreed! my initial impression from the post here was that there's something new... technically speaking (as a lot of folks here are technical). 
2023-04-26 17:56:06,The application.
2023-04-26 18:25:08,"Went through this, this is very useful"
2023-04-26 18:27:17,"Resharing the link, as someone has recently joined and is curious about the deck DM'ed "
2023-04-26 18:31:40,Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling
2023-04-26 18:37:42,How's the availability on Amazon Sagemaker?
2023-04-26 18:38:49,"Might not be applicable for everyone, but I think by far the fastest and best experience would be to apply for google cloud startup credits, and use a dedicated A100 for colab."
2023-04-26 18:39:25,Jupiter on VS Code with Banana on backend will cost ₹150/hour. 
2023-04-26 18:39:43,^ banana.dev also has a great free tier for 1 hour of use
2023-04-26 18:40:30,Should still be good for tinkering use-cases I'd guess?
2023-04-26 18:40:36,Really nice for notebooks / automation / scripting 
2023-04-26 18:41:40,Yes. Community model templates allow one click deployment. For 50+ models. Simple docs.
2023-04-26 18:43:05,Kaggle
2023-04-26 18:43:37,I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase
2023-04-26 18:46:27,"You can try paperspace, they are undercutting big tech on GPUs. https://www.paperspace.com"
2023-04-26 18:46:50,they have 5GB space on the Gradient .. 🙁
2023-04-26 18:47:59,Google Colab is $12 - and 50GB
2023-04-26 18:50:19,I have been using my Mac Pro as a server at home + socket + multiple LMs. Works like a charm :)
2023-04-26 18:51:25,You can keep the model storage on hugging face and then use any serverless gpu player to import your model from there directly.
2023-04-26 18:52:06,Will try this !
2023-04-26 19:40:26,"This doesn't work, start up credits cannot be used for colab, they have separate billing"
2023-04-26 19:41:34,"Yes, but now you can connect a gce vm to colab, giving you persistent sessions and dedicated compute"
2023-04-26 19:41:49,https://research.google.com/colaboratory/marketplace.html
2023-04-26 19:43:06,"Can recommend runpod, stop the instance when not using, will only be charged for storage"
2023-04-26 19:51:08,Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home 😅
2023-04-26 19:52:01,"On a more serious note, runpod, lambdalabs, fluidstack. Keep moving around 😅"
2023-04-26 20:50:30,Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.
2023-04-26 20:52:39,Does anyone know what compute units mean?
2023-04-26 20:55:37,I asked gpt. this maybe helpful
2023-04-26 20:55:44,Back to On Prime? 😂
2023-04-26 20:56:15,What GPU do they offer at this price? How much RAM for SD?
2023-04-26 20:56:31,T4 24GB think for this rate
2023-04-26 20:57:56,"""No One Knows What It Means But It's Provocative, It Gets The People Going"" 🤣"
2023-04-26 20:58:07,Are these instances persistent? Or do yoh still have to do the google drive hack
2023-04-26 21:03:40,not persistent
2023-04-26 21:04:30,Which platform is this?
2023-04-26 21:06:18,Google cloud
2023-04-26 21:11:38,For non persistent / spot instances of GPUs GOOG was always in under supply while we were testing. 
2023-04-26 21:31:07,https://www.chartgpt.dev/
2023-04-26 22:10:08,https://news.ycombinator.com/item?id=35697627
2023-04-26 23:08:22,"For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB?"
2023-04-26 23:09:13,Context: I'm using Pinecone and I'm saving most of my content in a different db (pinecone has a limit on size of meta data). Want to know if that is required / recommended for other Vector DBs like Weaviate
2023-04-26 23:12:34,whats the major difference between storing it in vector dbs and something like a numpy array? is retrieval super fast for say 1000s of vectors
2023-04-26 23:13:53,"Yep, our app allows users embed content so we need containerization + expect this to increase significantly (🤞). If you are building a vertical app (only embedding content yourself), numpy is probably ok - others probably have a better view tho"
2023-04-26 23:30:52,https://www.youtube.com/watch?v=7TCqGslll-4
2023-04-26 23:57:00,https://github.com/ai-forever/Kandinsky-2
2023-04-27 00:06:54,https://twitter.com/rasbt/status/1651226178353614854?s=48&t=ACPHEfclkXmi9Z92RTsh9g
2023-04-27 00:34:46,[PHONE REMOVED]
2023-04-27 00:58:01,"In Weaviate itself. It also allows to do pre filtered vector search based on the metadata, it internally builds separate indices for the metadata as well."
2023-04-27 01:03:29,"Oh cool, so you could store everything in weviate? Is the cost prohibitive? For example, if metadata is chunks of text"
2023-04-27 01:06:11,"Their managed SaaS  right now actually charges only based on the number of vectors and the dimensions of the vectors, irrespective of the extra metadata stored"
2023-04-27 03:50:10,Replit's latest announcement is interesting: https://twitter.com/swyx/status/1650989632413401089?s=20
2023-04-27 06:59:32,Anyone started learning LLMs/Transformers/ML in the last 3 months?
2023-04-27 08:44:40,Let’s do a zoom session to discuss?
2023-04-27 08:46:34,"How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX"
2023-04-27 08:47:07,bumping - has anyone been able to solve?
2023-04-27 08:48:56,I faced this problem before. We used some form of leaky bucket to smoothen the API calling rate.
2023-04-27 08:50:03,Not particularly for OpenAI but for a general solution for limiting API calling rates.
2023-04-27 08:53:43,"429s, use the retry-after. Are you getting rate limited for requests or tokenS?"
2023-04-27 08:55:17,all types of errors now. I wish there was a middle layer to solve this
2023-04-27 09:09:20,:)
2023-04-27 09:48:17,Any proxies like Nginx with Lua JIT or Envoy with WASM/Lua can be used for production setup without adding any much latency and performance overhead.
2023-04-27 09:49:22,Can you elaborate and/or share links? Hearing about Lua JIT and WASM in this context for the first time 😅
2023-04-27 09:54:14,https://openresty.org/en/
2023-04-27 09:55:46,https://tetrate.io/blog/wasm-modules-and-envoy-extensibility-explained-part-1/
2023-04-27 09:58:49,"These enovy, istio, nginx are API proxy and they have a customised layer where we can add multiple filters. These filters can extend functionality. Which you can write in Lua, Wasm etc. Lua interpreters bring less overhead and way faster than python interpreter."
2023-04-27 10:04:50,Things like if you are testing multiple models on production one is main other are tests. And you like to send prod requests to all and then like to monitor outcomes. For this generally you need to write code. But in the case of these proxies you simply need to write small Lua or even yaml. And this proxy itself sends requests to all these services (which host models) and passes the response of the main service to the caller/client. 
2023-04-27 10:21:36,Thanks to those who reached out. 
2023-04-27 10:28:56,"Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos). "
2023-04-27 10:50:58,Guys quick question. 
2023-04-27 10:52:37,https://twitter.com/raj_raj88/status/1631018786492157954
2023-04-27 10:53:00,"i guess 302, 303 etc. are later versions"
2023-04-27 11:00:05,"Not clear to me what does snapshop mean here. If this model is to be deprecated in 3 months, what's the need in the forst place. Is there a specific reason of not following conventional versioning. Would appreciate if someone can eli5"
2023-04-27 11:02:33,"Think of a continuous model training process with multiple forks, each ""named"" or versioned model is a actually a checkpoint in that. "
2023-04-27 11:03:32,"Workflow wise: Say you build on 0314 or any other 3 month model, when it gets deprecated, you have to explicitly upgrade and you'll be prepared to run your entire battery of tests again. This is better than a silent upgrade where the behaviour of underlying model changes silently."
2023-04-27 11:03:36,Does this help?
2023-04-27 11:06:38,Yes but basis this tweet https://twitter.com/raj_raj88/status/1631018786492157954 my understanding is 3.5-turbo refers to the latest model 3.5-turbo-x 
2023-04-27 11:07:20,"Let me move this to DM, need to understand your query better 😅"
2023-04-27 12:08:45,"Might be useful for you,i was trying to train a Bloom model  and i was running out of GPU memory..and this gradient notebook helped me https://github.com/rasbt/gradient-accumulation-blog/blob/main/src/1_batchsize-1.py where if we want to use a batch size of 256 but can only fit a batch size of 64 into GPU memory, we can perform gradient accumulation over four batches of size 64. (After processing all four batches, we will have the accumulated gradients equivalent to a single batch of size 256.) This allows us to effectively emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices."
2023-04-27 12:17:07,"As I have mentioned, tried all possible combinations with gradient accumulation as well. Problem is of memory leak"
2023-04-27 12:40:01,If you are facing GPU constraints you can try using the quantized version and fine tuning using lora+ bits and bytes
2023-04-27 12:41:04,Okay my bad I see you are already using peft
2023-04-27 12:55:56,"Based on cursory research, rundiffusion seems like a good hosted solution for automatic SD UI. "
2023-04-27 13:07:17,"It's pretty good, just not that well known"
2023-04-27 13:29:58,Hey Guys
2023-04-27 13:35:12,https://twitter.com/Replit/status/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19
2023-04-27 13:37:05,You can try qblocks.cloud
2023-04-27 13:37:06,Tried serverless GPUs like bananadev?
2023-04-27 13:37:29,I am using this. Comes to around 1 dollar for 24gb GPU
2023-04-27 13:50:49,This is some kind of membership. Optional I think
2023-04-27 13:52:46,any devrels here ?
2023-04-27 13:54:12,This has some nice comparison of serverless platforms
2023-04-27 13:57:01,You’re welcome to try it out for yourself next week when it drops :)
2023-04-27 13:57:22,Also the LLM relevant stuff is 46:00 onwards
2023-04-27 13:58:38,Already signed up & looking forward :)
2023-04-27 13:59:44,This is optional but might turn out to be cheaper if you are using it for high-velocity use cases. I have tried the Automatic1111 on SD V1.5 and is pretty decent for playing around.
2023-04-27 14:03:54,Has anyone gotten higher rate limits from OpenAI?
2023-04-27 14:06:27,"cc [PHONE REMOVED] has among the largest OpenAI bills in India, [PHONE REMOVED] used to work with the same team"
2023-04-27 14:21:09,Names please? 😅 (I see Rohit’s)
2023-04-27 14:32:46,Can this be used to solve marketing problems?
2023-04-27 14:33:02,"Anirudh Singla of Pepper Content and Rohit (now of Portkey), earlier at Pepper Content"
2023-04-27 14:43:23,"yes, we got it upgraded multiple times at Pepper. (This is Rohit)"
2023-04-27 16:11:11,was it for GPT4? or GPT3.5?
2023-04-27 16:15:21,Yes. Take usually 2-3 days. Applies for all incl gpt4
2023-04-27 16:38:30,Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too
2023-04-27 16:40:33,Stand corrected.. i misread it as quota increase.
2023-04-27 16:54:14,Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI 
2023-04-27 16:55:35,We are limited to 20 seats so pardon me if we're unable to accommodate all
2023-04-27 16:57:04,Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal [PHONE REMOVED] isn't doing self promotion here :).
2023-04-27 16:58:01,Oh yes thanks. It's free and there are no affiliations. Just shared passion for AI
2023-04-27 16:59:16,20 seats is a venue constraint
2023-04-27 17:00:02,[PHONE REMOVED] truly missing your organising skills and energy today 😅
2023-04-27 17:38:28,Nirant is a one man army
2023-04-27 17:39:07,We've hit capacity. Optimising for maximum participation by limiting it to one VC per firm. Please pardon 🙏
2023-04-27 17:39:20,Any chance of a live stream/recording?
2023-04-27 17:39:59,"It appears that way, but in practice, I'm simply the face for the work done by multiple folks e.g. [PHONE REMOVED], [PHONE REMOVED], [PHONE REMOVED], Hasgeek crew: [PHONE REMOVED] and co"
2023-04-27 17:40:18,Don't have the infra/team. Sorry
2023-04-27 19:00:59,Is this happening? 🙂
2023-04-27 19:02:01,Any recommended resources?
2023-04-27 19:03:47,Try training your own via huggingface. I did that and learnt a lot more (had to beat my head around a lot)
2023-04-27 19:04:15,1. https://course.fast.ai — probably the best there is 
2023-04-27 19:04:30,"3 is more NLP focussed, 2 is broader ranging from Vision to Speech and what not"
2023-04-27 19:10:09,Thanks Aashay and Nirant.
2023-04-27 19:11:23,could you pls reshare or perhaps link it in group desc
2023-04-27 19:13:20,https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
2023-04-27 19:19:56,It starts from scratch. Not sure if useful to many here. Anyway Admin’s call if they want to add it group  desc
2023-04-27 20:52:30,https://twitter.com/andrewyng/status/1651605660382134274?s=46&t=wdMpftHBI367157ViAY2Gg
2023-04-27 20:54:52,Pinecone raised 100m
2023-04-27 20:55:04,https://twitter.com/pinecone/status/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19
2023-04-27 21:08:23,"It's having the nvidia moment in age of langchain , good to raise when you have the buzz"
2023-04-27 21:09:21,"Yeah, also serendipity is a beautiful thing. Started in W15 cohort 8 years ago, to build for the vector search market. Raised series A after 7 years"
2023-04-27 21:09:45,Took 8 years to be in the right place at right time. More power to them
2023-04-27 21:10:16,"Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!"
2023-04-27 21:10:29,This.
2023-04-27 21:25:34,Woah! Have to say they’re good - literally 0 issues since we launched with them
2023-04-27 21:35:27,"agreed, love his videos"
2023-04-27 21:43:15,For anyone looking for them:
2023-04-27 21:53:09,"Oh absolutely,"
2023-04-27 21:55:17,I have a friend there and he was telling me about their production traction from India - it's significant
2023-04-27 21:59:11,any idea if these individuals devs using it or more startups / small companies?
2023-04-27 22:00:39,Startups/companies
2023-04-27 22:02:12,yes / would love to know who all so can share learnings. We are at 20K vectors
2023-04-27 22:06:56,Their content game is also great. In most AI keywords they are within 5.
2023-04-27 22:23:01,https://www.databricks.com/blog/contributing-spark-loader-for-hugging-face-datasets
2023-04-27 23:01:34,Haan we can plan one on weekend. [PHONE REMOVED]  would you want to take a lead on this?  cc [PHONE REMOVED]
2023-04-28 00:00:24,Sure
2023-04-28 00:08:55,"(There is a Nvidia-HF event on Saturday morning, hence kept slots after that)"
2023-04-28 00:12:06,Online ? URL ?
2023-04-28 00:13:22,https://sites.google.com/huggingface.co/generative-ai-meetup
2023-04-28 00:38:08,Need an experienced person to guide and answer queries.. volunteer please
2023-04-28 01:35:59,https://twitter.com/thesephist/status/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19
2023-04-28 01:37:26,https://www.euractiv.com/section/artificial-intelligence/news/meps-seal-the-deal-on-artificial-intelligence-act/
2023-04-28 02:36:05,same
2023-04-28 02:46:02,"haha, whose place is this party going down at"
2023-04-28 03:27:34,"Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar."
2023-04-28 03:28:29,"Or, more generally, using diffusion in a generic neural network or for some other application outside of generating content"
2023-04-28 03:30:07,They use transformers for lane detection- https://youtu.be/aVjDX5XshYo
2023-04-28 03:31:07,https://arxiv.org/abs/2112.00390
2023-04-28 04:00:39,text2motion 
2023-04-28 09:39:41,[PHONE REMOVED] might know a thing or two
2023-04-28 09:41:06,I got a call from someone inviting me here. Seems a lot like a marketing campaign. If someone is interested in  their data lake services then they should definitely attend it.
2023-04-28 09:41:24,"If not, then I don't see much why anyone would attend"
2023-04-28 09:42:24,Diffusion is a noise removal process at its core
2023-04-28 09:49:02,"You can use it to generate content, but you can also use diffusion to process content."
2023-04-28 10:43:25,[PHONE REMOVED]’s place
2023-04-28 10:45:45,[PHONE REMOVED] is an incredible teacher - should do a talk for the group
2023-04-28 12:05:12,Has anyone used promptlayer? or anything similar?
2023-04-28 12:23:22,Anyone who has resources for Data Exploration and Feature Engineering?
2023-04-28 12:33:47,"We can point you in a million directions, but perhaps the most value-for-time is this:"
2023-04-28 12:41:14,What are the best projects around these areas of interest:
2023-04-28 12:44:00,Is the intention to get more familiar with these problems? Like a project to assist coursework?
2023-04-28 12:45:36,"Hmm, that's part of the problem. Too many teams re-invent these pieces internally."
2023-04-28 12:47:36,Why do you've to touch a GPU for doing custom embedding in 2023? That's a very 2016 thing to do
2023-04-28 12:51:22,https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/
2023-04-28 12:52:37,Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable 🤔
2023-04-28 12:56:22,"I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P"
2023-04-28 12:57:24,"Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in."
2023-04-28 12:58:14,"Umm, almost all kinds of arts have an audience as well"
2023-04-28 12:58:26,"Also, AutoGPT has fantastic marketing. Credit due where it is due."
2023-04-28 13:00:55,Did it actually do anything useful yet? Haven't seen any impressive results so far.
2023-04-28 13:02:15,AutoGPT has been major disappointment from the hype prospective
2023-04-28 13:04:08,it is only aboe to do small things/tasks with bounded scopes and well-defined goals 
2023-04-28 13:07:37,Can do basic financial analysis of companies. Somehow gets the easiest thing (getting the right current price from google) wrong. But was able to so SWOT + competitive analysis + DCF
2023-04-28 13:09:58,"This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search."
2023-04-28 13:10:01,"Have done market sizing and memo writing using AutoGPT, but takes alot of time and gets into loops too often"
2023-04-28 13:17:37,"Oh my,  I see that link has led to a mini furore in this group 😟 I actually had a specific question but got a call."
2023-04-28 13:17:59,"Hahha, no furore. Just banter."
2023-04-28 13:19:28,"Bing has a lot longer context window — so can reason over more search results, is basically free for most people, easier to use."
2023-04-28 13:19:43,"AutoGPT took all the learnings developed by langchain, vectors DBs etc etc and made it available for the wider non-developer audience to use in the format they understand better. "
2023-04-28 13:19:45,Bing is also not powered 100% by GPT but uses an internal MSFT model quite often
2023-04-28 13:20:49,"*Anyone here who has used such sequential prompting on a custom dataset to run a controlled conversation, say a roleplay?* We’re building a sales roleplay product that mimics conversations of a specific team, and I would like to know such available best practices to optimise the output if someone has dived deeper into something like this."
2023-04-28 13:22:37,This is perhaps the best tooling for guided-chat with some roleplay.
2023-04-28 13:22:55,"It’s for B2B enterprises, so the idea is that it better get as precise yet flair-ful as it can get (based on a team’s dynamics)."
2023-04-28 13:41:41,AlignmentAI
2023-04-28 13:42:13,PMGPT
2023-04-28 13:42:26,```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:
2023-04-28 13:42:26,"No offence to any PM, you all are loved 😛"
2023-04-28 13:43:37,Tx. Deleted since it borders self promotion
2023-04-28 13:48:06,Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone.
2023-04-28 13:49:58,Used this only https://www.namefinder.ai
2023-04-28 13:51:04,A dairy founder wanted g.ai but had to resort to mal.ai
2023-04-28 13:51:43,AIshwarIA
2023-04-28 14:40:56,"I think something like autogpt becomes useful when human closed loop feedback cycles are involved at a large scale. Something that incorporates large scale human feedback and nudges into its reasoning, that's where I see real potential"
2023-04-28 14:42:03,Eg for trading bots this might be a community of 1000s of traders constantly giving it nudges and guidance on its thoughts and actions
2023-04-28 14:55:03,"For the technical folks that are waiting on GPT4 API Access for more than 30 days, with any meaningful open source presence — please DM me. "
2023-04-28 14:55:34,I got the access in 5 days. Had requested it last weekend and got it this week.
2023-04-28 14:56:10,"Works like a charm. We had been pusing internal teams at Microsoft for a month, with no end in sight, but nirant's tip worked in 2 hours :)"
2023-04-28 15:10:18,Does anyone have access to GPT plugins?
2023-04-28 15:10:23,did you get through Azure OpenAI service?
2023-04-28 15:10:58,"Yes, thanks to nirant as well"
2023-04-28 15:12:48,I haven't checked that yet. Is it available through that?
2023-04-28 15:12:59,Are awesome. How did you get it?
2023-04-28 15:13:15,I just want to play with the plugins and explore their capabilities.
2023-04-28 15:14:05,"Interesting bit: the Microsoft folks pushed us to shift all our code to azure openai service, and something called semantic-kernel in order to get gpt-4 access, but none of it has materialised yet"
2023-04-28 15:16:07,I feel guilty open sourcing nirant's tips 😂
2023-04-28 15:17:04,More important: We also shouldn't abuse OpenAI's goodwill :)
2023-04-28 15:17:54,Haha. No worries. I have gpt-4 api access.
2023-04-28 15:45:50,Anyone in Ben Tossel's AI maker group?
2023-04-28 15:55:04,I am
2023-04-28 15:58:58,Pray tell 🙂
2023-04-28 16:05:03,And also the joining link😅
2023-04-28 16:05:59,Gotta apply
2023-04-28 16:06:23,maker club?
2023-04-28 16:06:39,Where?
2023-04-28 16:08:27,let me find the link
2023-04-28 17:03:15,For folks wondering how is FP8 working? This is based on NVIDIA's Transformer Engine: https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/index.html
2023-04-28 17:05:12,"What impact you foresee? Large Model, Faster Model, or new model arch?"
2023-04-28 17:13:48,Coreweave talks about tier 3 datacenters in north america. What does that mean? Do we have any in India as well?
2023-04-28 17:22:28,"Mostly faster inference in the 3-6 month horizon as compute providers figure this out, and perhaps more Fp16, Fp8/int8 proliferation for task-specific models"
2023-04-28 17:55:41,Faster inference means lesser costs because you can handle higher concurrent users per gpu
2023-04-28 19:04:39,"If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not — I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases"
2023-04-28 19:10:25,"Also at times you can’t guarantee to spawn up some of the higher end GPUs on demand, leading to slower spawn up time for users"
2023-04-28 19:10:57,"I doubt you'll have this luxury for long, imo serverless gpus are a perfect competition model with market competition dictating  the pricing instead of arbitrary end user value"
2023-04-28 22:28:28,https://twitter.com/bentossell/status/1636394074101153792
2023-04-28 22:28:30,fyi
2023-04-28 22:59:56,"Hey, this is nice, thanks for sharing"
2023-04-28 23:00:13,"Looks too good to be true, what do you think is the catch here?"
2023-04-28 23:00:29,"No catch, it's Ben"
2023-04-28 23:09:02,"anyone  , building with langchain here ?  just deployed a private V2 for collectiv langchainX. would be happy to share access , if you building with langchain would help your process"
2023-04-28 23:09:05,Hi! Does anyone know of any tools that can summarize custom code repos/documentation? Something like https://github.com/mtenenholtz/chat-twitter but where you can maybe enter in any Github repo link and it'll summarize it for you.
2023-04-28 23:11:49,https://github.com/peterw/Chat-with-Github-Repo
2023-04-28 23:13:03,https://stability.ai/blog/deepfloyd-if-text-to-image-model
2023-04-28 23:15:27,Thanks
2023-04-28 23:20:58,Research license only
2023-04-28 23:32:09,"interesting approach, will be interesting to see if it will be able to displace the stable diffusion model given the eco-system that has already grown around it"
2023-04-29 00:49:44,Very lame question: Does LlamaIndex or Langchain support VectorDB with Sources with GPT4 or GPT3.5-Turbo? 
2023-04-29 00:50:52,"If yes, can you please point me to the right docs 😅"
2023-04-29 00:51:00,what does vectordb with sources with gpt mean?
2023-04-29 00:52:31,"Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question — I want the response to include 5, 7"
2023-04-29 00:53:25,https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/PineconeIndexDemo.ipynb
2023-04-29 00:53:50,response.source_nodes should give you the sources.
2023-04-29 00:54:12,"That gives 1, 3, 5, 7 — all top k"
2023-04-29 00:55:27,"ohh okay. Sorry, I misunderstood then. One way is to use evaluation module on top these to get only 5, 7 are being used."
2023-04-29 00:56:54,I have a hack for this
2023-04-29 00:57:36,Use this prompt - 
2023-04-29 00:57:55,Then simply parse the citations returned using regex
2023-04-29 00:58:26,I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way?
2023-04-29 00:59:54,Works very consistently
2023-04-29 01:00:10,(Haven't experimented with gpt-4 though yet)
2023-04-29 01:01:11,Including instructions and search results in system prompt made it forget the instructions sometimes
2023-04-29 01:01:23,So moved them to user prompt
2023-04-29 01:05:33,"This technique also in my experience has the added benefit of producing more grounded results, because you are kinda forcing it to cite sources. (Not sure why it works at all though)"
2023-04-29 01:22:00,OpenAI models don’t do this. What you want is basically the LLMs to cite references.
2023-04-29 01:22:19,*The reader model
2023-04-29 01:23:10,Interesting.
2023-04-29 01:25:42,[PHONE REMOVED] something like this - https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html ?
2023-04-29 01:27:35,"Yes, but this uses text-davinci-003 — which leads to couple of trade offs:  "
2023-04-29 01:31:15,"what could be reasons that the methodology can’t be ported to GPT-4? (I haven’t looked at the code yet, only did a cursory read on this today)"
2023-04-29 01:32:40,Do you mean LLM or code reasons? There are no LLM reasons
2023-04-29 01:33:29,Replacing the OpenAI() classes in the example with ChatOpenAI() doesn't work?
2023-04-29 01:33:51,Code reasons - is the “return_only_outputs” prop not available for ChatCompletions
2023-04-29 01:33:53,Code Reasons: Langchain is structured around separation of LLMs and Vector Indices — the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources
2023-04-29 01:34:30,You’ll have to extend the chain functions I guess..
2023-04-29 01:34:37,"Llama Index: [PHONE REMOVED] can share more context, but I think they've just gotten around to it. From what I can tell, they have no such limitations"
2023-04-29 01:34:46,*just not gotten around to it
2023-04-29 01:35:08,"Aah, that makes sense. Will make for a great PR!"
2023-04-29 01:35:35,That was a quick delete 😂😂😂
2023-04-29 01:36:13,"Yeah, sometimes I've to enforce that ""stay on topic"" policy to myself 🤣"
2023-04-29 01:36:29,Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs
2023-04-29 01:36:42,"My eyes can’t believe this, what error does it throw?"
2023-04-29 01:36:46,It's definitely not meant for simple things
2023-04-29 01:38:15,OpenAI has a function in one of their libs to convert chat prompts to text ones and vice versa - that’s needed here I guess 😅
2023-04-29 01:38:48,"Wait, what. I've not seen this. Is this part of their default Python SDK? If not, can you link it here?"
2023-04-29 01:39:22,https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/prompt/base.py#L22
2023-04-29 01:40:10,"Okay, I see the code. Now I feel sad that I didn't think of this. Probably should've asked this question at 9 AM instead of 2 AM 😅"
2023-04-29 01:41:54,while we are in this repo - these prompts are gold 
2023-04-29 01:42:21,These kinda gems are what make this group worthwhile 🫰🏻
2023-04-29 01:42:37,Yes! Writing a blog on how good the library is. We aren’t using so much of what became available here!
2023-04-29 02:54:42,anyone knows a model that can give aesthetic score for an image?
2023-04-29 02:55:28,FID against LAION-A?
2023-04-29 02:59:18,Please share after ur done
2023-04-29 03:14:01,Adding context here: 
2023-04-29 03:26:08,Pretty cool approach.
2023-04-29 03:26:42,"That said, if you've user-scored images, you can go very far with just a ResNet and a classification model. AirBnB Staff ML Engineers with a PhD were still doing that and getting promoted in Dec 2022: https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2"
2023-04-29 03:26:59,"Basically, Big Data beats Big Brains any day, all day long"
2023-04-29 03:28:14,"Before anyone asks, Airbnb uses AWS OpenSearch with HNSW for their VectorStore"
2023-04-29 03:36:14,"Thinking along similar lines, I'm eagerly waiting for a model that takes in any photo and gives out professional level DSLR photos. Perfect lighting, colors, focus, contrast, etc :)"
2023-04-29 03:44:33,"For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license)."
2023-04-29 03:47:14,"Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there’s 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development 😛). "
2023-04-29 03:47:53,Working on a summary web version and hopefully a weekly/monthly newsletter 🤞
2023-04-29 03:50:13,Cool che. Will sign up for that.
2023-04-29 07:47:15,I prefer never using them... Just picking the prompts from their source code
2023-04-29 08:03:25,Who here is using langchain in prod?
2023-04-29 08:28:39,How? Manually 😯
2023-04-29 08:42:15,No way. Shouldn't expect that from Nirant. Automate. 😁
2023-04-29 08:44:50,This is a nice read
2023-04-29 08:57:43,Mainly my point about finding any good way to extract WhatsApp group data  automatically. I don't find any official APIs. There might be few unofficial ways but that may cause a number ban.
2023-04-29 09:00:47,"Hey folks, "
2023-04-29 09:08:42,My understanding is currently runwayml gen 2.
2023-04-29 09:09:08,This isn't available yet I thought.
2023-04-29 09:10:54,Don’t know about access. I have seen multiple videos of it on twitter lately.
2023-04-29 09:11:06,Few days old 😜: 
2023-04-29 09:20:07,https://replicate.com/cjwbw/damo-text-to-video
2023-04-29 10:10:02,https://github.com/Picsart-AI-Research/Text2Video-Zero
2023-04-29 10:15:36,"Folks, so we are doing the ""Learning Transformers/NLP/ML"" discussion on Sunday 4-5pm."
2023-04-29 10:55:03,Anyone at the nvidia event?
2023-04-29 11:00:31,Using openai APIs to expand?
2023-04-29 11:19:43,"Fyi that calendar link doesn't do anything for me, using Android here"
2023-04-29 11:36:19,I can make a list of great solutions for it if there's interest :)
2023-04-29 11:38:21,"Tuned in for Gen AI, listening to GPU talks 💀"
2023-04-29 11:40:53,Thanks for flagging it Amir.
2023-04-29 11:41:00,https://twitter.com/bhutanisanyam1/status/1412933178411536384
2023-04-29 11:49:55,https://postgresml.org/blog/tuning-vector-recall-while-generating-query-embeddings-in-the-database
2023-04-29 11:50:40,Haha - I'm here
2023-04-29 11:50:42,It's high quality
2023-04-29 11:54:37,Will share insights
2023-04-29 11:56:02,https://teams.microsoft.com/l/meetup-join/19%3ameeting_OGM2NDU4N2QtYjdmOS00YzJmLThmZTctYTkxYWEyNWQ0OGNj%40thread.v2/0?context=%7B%22Tid%22%3A%2243083d15-7273-40c1-b7db-39efd9ccc17a%22%2C%22Oid%22%3A%222e1cc663-be56-46e0-ab3b-b7a9f58868e7%22%2C%22IsBroadcastMeeting%22%3Atrue%2C%22role%22%3A%22a%22%7D&btype=a&role=a 
2023-04-29 12:51:48,"Hey [PHONE REMOVED] [PHONE REMOVED] : For tomorrow's zoom meet-up, can you drive 15 minute of the session on 101 of Generative AI? [PHONE REMOVED] is looking for a tech expert in the session."
2023-04-29 13:22:22,Nirant is busy tomorrow.
2023-04-29 13:31:16,"Hey guys. I am trying to build something with Generative AI in the advertisement space. I don’t have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss."
2023-04-29 13:31:46,My name is Srinath btw. And I am a final year BTech student.
2023-04-29 13:32:56,Would love to help [PHONE REMOVED] . Dm me whenever free
2023-04-29 13:33:21,"Folks, please reach out to our friend directly :)"
2023-04-29 13:33:29,Thanks Nitish. DMing you.
2023-04-29 13:43:10,"Hello everyone, I am Apurva. I am building a product to make content viral on social media using generative AI. "
2023-04-29 15:29:29,"Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically)."
2023-04-29 15:34:14,Looks like all the Mohits are looking for same use case. 😂
2023-04-29 15:34:49,Brilliant. We can call our library mohit then!
2023-04-29 15:35:15,Definitely 💯
2023-04-29 15:42:28,Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages
2023-04-29 15:42:49,OpenAI Whisper does this off the bat
2023-04-29 15:44:03,"I tried assemblyAI as well but they are expensive, are there any other that I may have missed?"
2023-04-29 15:45:01,[PHONE REMOVED] should definitely be able to help!
2023-04-29 15:47:02,thanks will dm him
2023-04-29 15:55:56,"Building this but for CSVs at the moment, would love to chat!"
2023-04-29 16:00:24,For Hindi there are whisper models trained for Hindi from IITM.
2023-04-29 16:00:26,Deepgram built using whisper works good as well. They give $200 credit to try it out.
2023-04-29 16:37:06,You can try monster api as well
2023-04-29 16:50:00,If somebody is trying out deepgram nova vs Whisper - would love to hear results from both
2023-04-29 17:02:46,You don't need generative models for this. Converting raw text to PDFs/images and then applying simple distortions is a very common and effective way to get synthetic data for OCR.
2023-04-29 18:00:41,https://playbook.samaltman.com
2023-04-29 18:08:58,Hey
2023-04-29 18:09:01,Will not be able to make it.
2023-04-29 18:58:02,Will you be recording this?
2023-04-29 19:22:26,Weekend fun!
2023-04-29 19:35:59,D-ID is crazy good. Any ideas on the underlying architecture?
2023-04-29 19:38:31,SadTalker is open and it getting there. Some friends are working on a project and they moved on from D-ID for SadTalker. You will need a good GPU though.
2023-04-29 19:41:33,Not so sure but this tech is around since a while.
2023-04-29 19:42:04,Not zero shot lipsync / animation - that's hard and has limited work
2023-04-29 19:45:47,Sad talker is arguably better...
2023-04-29 19:48:41,D-ID is very expensive if you’re building a project with a pipeline to generate content on an enormous amount.
2023-04-29 19:50:24,How expensive?
2023-04-29 19:52:00,As mentioned on their Pricing page. 🤣
2023-04-29 19:52:34,Have you deployed and tested at scale?
2023-04-29 19:52:41,Unreasonably expensive for an api product
2023-04-29 19:52:48,We used multiple D-ID accounts to get this done :p
2023-04-29 19:53:43,They have a full fledged web studio as well.
2023-04-29 19:54:10,Yup exactly - I feel like the pricing is aligned for the dashboard only
2023-04-29 19:54:34,Right now SadTalker can generate 10min video per hour that’s 2$ GPU time
2023-04-29 19:57:47,"D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back."
2023-04-29 20:00:13,May be get one with nvlinks for larger runs and still it’s a lot better return time for investment
2023-04-29 20:00:49,And yet has a lot of traction - good product to build.
2023-04-29 20:01:06,Any idea on what models they use?
2023-04-29 20:01:40,🤷‍♂️ their own. SadTalker is new and evolving. From tencent I think.
2023-04-29 20:09:12,"So many things to build, so many industries to disrupt. "
2023-04-29 20:14:32,Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced
2023-04-29 20:17:09,👍 
2023-04-29 20:29:40,Only notes (as of now)
2023-04-29 20:36:00,Yes and 2$ can be brought down if doing at scale (Assuming A100)
2023-04-29 20:36:28,Margins are great for this - and competition is less. (text to talking head avatars vs rephrase ai etc). Good product to build.
2023-04-29 20:36:41,I'll take a stab at building an mvp soon
2023-04-29 20:37:03,"Tried doing this back in 2019 and almost raised funding, but didn't work out"
2023-04-29 20:37:11,Not sure how big is the market for this though.
2023-04-29 20:37:42,It's an evolving market. Also look at leading indicators
2023-04-29 20:38:17,Wow this is very real
2023-04-29 20:38:58,"I've built this product as both an API, and also earlier (2020) as a charcater.ai type offering, and even tried to sell as nfts. "
2023-04-29 20:39:08,Hillarious stuff man
2023-04-29 20:39:15,I know how to do that :)
2023-04-29 20:39:27,That's the easy bit
2023-04-29 20:39:27,Don’t you want 8 AI avatars on Arnab’s show with different personalities?
2023-04-29 20:39:34,*Shakes hands*
2023-04-29 20:39:45,Thank you! [PHONE REMOVED] spent lot of time in generating the voices!
2023-04-29 20:39:53,Haha. We should jam.
2023-04-29 20:44:24,"If human can generate similar kind of content, I don’t think pureplay AI will sell. Human generated content is already limitless."
2023-04-29 20:45:22,It was just a joke. But AI fact checking anchor in every debate can be a nice start.
2023-04-29 20:45:47,Thinking XYZ movie in Nolan style. Or personalized standup making references about my own personal life - that might really work.
2023-04-29 20:46:17,"Also if anyone else wants to jam with [PHONE REMOVED] and me, and even potentially collaborate on building this - hit me up. "
2023-04-29 20:46:31,There will be a popup after every statement then 😅😅
2023-04-29 21:12:28,Interested. Would like to offer something like this to creators on Koo.
2023-04-29 21:14:02,Also interested. Particularly interested in the AI Vocalist use case.
2023-04-29 21:14:27,Please do keep me posted on the jam
2023-04-29 21:15:13,"Also interested in the jam in a literal sense, as I’d be happy to beta test to create viral content"
2023-04-29 21:18:39,Sure will make a group
2023-04-29 21:29:37,Any opensource alternative to elevenlabs?
2023-04-29 21:29:53,bark
2023-04-29 21:30:00,Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?
2023-04-29 21:34:52,Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?
2023-04-29 21:35:03,Thanks! Checking.
2023-04-29 21:36:18,"Except for their officially released cloned voices, it hallucinates a lot."
2023-04-29 21:43:11,Yes correct
2023-04-29 21:44:36,guardrails released this recently
2023-04-29 21:46:34,https://twitter.com/ShreyaR/status/1650883072324419587
2023-04-29 21:46:39,cc [PHONE REMOVED]
2023-04-29 22:51:08,Looks very interesting. DMing for further help.
2023-04-29 23:24:58,Hey
2023-04-29 23:25:59,Couldn't find anything. Trying to build it in house with eventual plans to expose as API & dashboard
2023-04-29 23:26:24,[PHONE REMOVED] please build this for us! 🫣
2023-04-29 23:27:14,The analysis part might be outsource-able to thoughtspot
2023-04-29 23:35:08,This is what they're currently offering:
2023-04-29 23:35:50,Their responses have to be REALLY good to have people leave chatGPT and other LLMs and use these features.
2023-04-30 00:21:44,Bark is lit too 🔥
2023-04-30 00:23:31,"Lyrics by gpt, vocals and music by bark!"
2023-04-30 00:26:10,This is the way!
2023-04-30 00:34:02,https://github.com/gventuri/pandas-ai
2023-04-30 00:51:20,"Anyone has found any solution to ChatOpenAI giving ""Could not parse LLM output:"" errors?"
2023-04-30 03:39:44,https://github.com/jerryjliu/llama_index/blob/590639a14dd7346b7f5cc00a21dd24ce0d35ae30/gpt_index/langchain_helpers/text_splitter.py#L240
2023-04-30 06:42:10,https://github.com/openai/openai-python/blob/c556584eff3b36c92278e6af62cfe02ebb68fb65/openai/embeddings_utils.py#L21
2023-04-30 07:29:58,This is what openai used in their rlhf paper - https://scale.com/content-language
2023-04-30 10:01:00,https://twitter.com/MisbahSy/status/1652479189747130368?t=l_GaFpmX5tP50AfqEut_Dw&s=09
2023-04-30 10:32:55,I'm excited to try cohere's multilingual model somewhere.. Maybe benchmark it to NLLB :)
2023-04-30 10:42:04,basic project idea:
2023-04-30 10:42:11,shortcuts are super useful if you know what you're doing
2023-04-30 10:42:26,Most people don't use them to their full potential since the documentation is so messy
2023-04-30 10:43:34,"Can be a vague, small step towards AGI for the common-man."
2023-04-30 10:44:14,"Would love to get a functionality like : ""Create shortcuts to automatically change my wallpaper based on 7 images, 1 for each day of the week"""
2023-04-30 10:44:38,One of my friends set up something like that and it took him 2 full hours to get his head around it
2023-04-30 10:54:18,And even generating a step by step guide to make a shortcut should be plenty for people like me
2023-04-30 10:58:01,"Any best resources for creating charts/graphs from data, open-source ""Chart-GPT"" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives."
2023-04-30 11:30:57,Got it. Any open source solution which you know?
2023-04-30 11:34:03,are you looking to fine-tune or perform RLHF?
2023-04-30 11:34:17,RLHF on an open-source model*
2023-04-30 11:39:41,Majorly for RLHF.
2023-04-30 11:41:52,"So, for the first case, let’s say"
2023-04-30 13:29:48,"Hey , "
2023-04-30 13:35:26,Contextual is the way to go. Tracing will allow for this. Working on it now
2023-04-30 14:01:10,Alright
2023-04-30 14:28:08,"Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs."
2023-04-30 14:39:35,Any other alternative you suggest?  Let me try to increase the ram and see?
2023-04-30 14:41:56,How do I read this - how’s the recall measured?
2023-04-30 14:45:58,Those details are the same as here: https://ann-benchmarks.com
2023-04-30 14:47:05,"What would be the best way to implement a file search? If I have a ton of documents and I want a semantic search on top of it to solve the discovery problem, how should I go about it? One use case could be for google drive."
2023-04-30 14:48:11,Langchain has a drive connector fwik. You could use that to then do search with it's helper functions
2023-04-30 14:48:57,"okay, I'll check that.. thanks."
2023-04-30 14:58:27,"Nice, performance gains attributed to rust vs golang? Assuming both are using the same algo (hnsw) ?"
2023-04-30 15:14:59,"is the tuning of recall/speed done by building a new index for each point on this plot, or is it tunable per query?"
2023-04-30 15:17:05,This is the code outline we used: 
2023-04-30 15:40:31,Folks we are starting the Learners' discussion at 4pm - Join here : meet.google.com/jag-jjny-owf
2023-04-30 17:12:14,Thanks [PHONE REMOVED]  [PHONE REMOVED] [PHONE REMOVED] for joining in and sharing pointers and notes 🙏
2023-04-30 17:41:19,I found this tool that shows a nice dashboard of costs incurred while using OpenAI api’s : https://llm.report
2023-04-30 17:49:57,Thanks [PHONE REMOVED] for hosting
2023-04-30 18:32:39,"Looking for feedback on a new product that I'm working on that generates design from prompts using a design system, would love to get some feedback. DM me or upvote and I will send a message 🧰 Thanks :D"
2023-04-30 18:40:47,Are there any graphic designers in this group who are interested in learning more about using stable diffusion in their work? I'd love to talk and understand where generative AI can make the most impact in your work. And then hopefully show you how you can apply it
2023-04-30 18:54:36,This is nice. Do you know any other tool which also has per user usage tables?
2023-04-30 18:54:41,Would also love to interview product designers ❤️
2023-04-30 18:55:12,"On that note, would like to connect to folks in marketing, specially graphic designers in marketing agencies, or if you know anyone in such agency, kindly connect 🙏"
2023-04-30 19:04:15,https://twitter.com/bohanhou1998/status/1652151502012837890?s=20
2023-04-30 19:05:21,Haven’t found any other yet
2023-05-01 00:54:06,"It's quite public, OpenAI demos it everywhere?"
2023-05-01 00:54:29,MUST get access to this tool
2023-05-01 00:55:22,The fastest way to get GPT Plugins access is perhaps to make a Twitter viral demo 🥲
2023-05-01 00:56:02,"I have GPT plugins access, but I don't this tool anywhere in the ui"
2023-05-01 02:56:26,https://github.com/georgia-tech-db/eva
2023-05-01 03:54:34,Any  *** flask / python web stack devs here for freelance? Thx!
2023-05-01 06:44:42,Dm ing.
2023-05-01 09:19:42,AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails
2023-05-01 09:50:43,"I was able to deploy something locally ( followed line by line advice of chatgpt) to generate personalised DM, email + coffee conversation points for a linkedin profile as a non coder. Jason's requirement should be easy stuff for someone better."
2023-05-01 10:32:53,Link to this group? Want to add a friend
2023-05-01 11:36:56,[PHONE REMOVED] can I post an GenAI internship opportunity at Koo here?
2023-05-01 11:38:06,Posting it without really posting it 😎
2023-05-01 11:38:11,I just pinged [PHONE REMOVED] ki please delete this too 😅
2023-05-01 11:50:59,"We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there"
2023-05-01 11:52:06,Agree
2023-05-01 11:52:30,Lots of good talent here and opportunities
2023-05-01 11:56:02,"A subgroup for hiring could be a great idea, keeping this group for ideas/discussions"
2023-05-01 12:00:49,"How about a subreddit with flairs for hiring, news, discussion etc?"
2023-05-01 12:01:05,Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also. 
2023-05-01 12:01:11,The challenge is that posting on LinkedIn has been ineffective for specific areas and GenAI has very few communities.
2023-05-01 12:02:30,Sent you something similar
2023-05-01 12:40:51,"For folks interested in hiring from the community, added a Google Form here: https://nirantk.com/community"
2023-05-01 12:56:19,Why not have a diff announcement group? 🤔
2023-05-01 12:58:42,+1
2023-05-01 13:01:20,"Splintering off is a terrible idea — that is partially why of the last 3 groups which we've split off: Generative AI + {Art, Philosophy, Startups} — 2 are dead and one is comatose"
2023-05-01 13:04:16,Why is no one discussing AI philosophy 😂🙈
2023-05-01 13:05:46,"Stems from my bias since I seeded this community from my friends. I've generally been a believer that the best philosophy is action, not discussion. That is why we care about OpenAI and not say, so many other brilliant teams"
2023-05-01 13:14:35,I would be interested in something that covers hiring freelancers too.
2023-05-01 13:16:14,"Yeah, please add there! You can mention in the questions that what kinda freelancing role is this e.g. contractual, but recurring, project based. That is why the questions are free form :)"
2023-05-01 15:59:57,https://www.youtube.com/watch?v=FE88OOUBonQ
2023-05-01 17:29:08,Send link?
2023-05-01 17:30:12,Anyone interested in teaming up for Warpspeed?
2023-05-01 17:39:21,"Looking forward to participate, hopefully this one is online"
2023-05-01 18:14:14,It is mentioned that it is an offline event
2023-05-01 18:42:06,"Offline, only selected candidates will be allowed"
2023-05-01 21:44:40,Meta's SAM under the hood?
2023-05-01 22:02:07,"Yes it's offline, please do apply :)"
2023-05-01 22:05:51,Will there be selections for attending the hackathon?
2023-05-01 22:12:15,"Nope, this is a custom model, haven’t seen anything quite like it anywhere else"
2023-05-01 22:36:36,+ 1. Need more teams from this group. And winners! I’m up as well to jam with anyone looking.
2023-05-01 23:39:00,Have you tried if it works when you call it from outside those notebooks?
2023-05-01 23:39:21,Ok yeah doesn't work. Interesting.
2023-05-01 23:39:31,AuthenticationError: Your authentication token is not from a valid issuer.
2023-05-01 23:39:55,Wireshark it and find if you can get the headers?
2023-05-01 23:40:31,"I mean, this is just nerd-sniping [PHONE REMOVED], I feel ambushed 😂"
2023-05-01 23:40:32,I also want this magic api key though that I can just publish in my code lol
2023-05-01 23:46:45,playwright might be easier than reverse engineering the jupyter notebook api 👀
2023-05-01 23:51:48,"Sal Khan just gave another Ted, the vision reimagined with AI. As good and powerful as the first one. "
2023-05-01 23:53:05,Hinton is leaving google
2023-05-01 23:55:34,https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html
2023-05-02 00:04:13,Article is biased
2023-05-02 00:04:14,His tweets are better
2023-05-02 00:13:22,https://twitter.com/zoink/status/1653052807950536706
2023-05-02 00:28:05,How are you folks using ChatGPT to learn?
2023-05-02 01:35:09,Yudbot.com
2023-05-02 01:42:52,I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)
2023-05-02 01:43:42,[PHONE REMOVED] [PHONE REMOVED]
2023-05-02 01:43:45,"also is API level cap, something that you generally try to keep? got some responses on twitter - wanted to check here too if people would find it useful"
2023-05-02 02:09:29,[PHONE REMOVED] might be interesting for you
2023-05-02 04:11:18,https://www.yudbot.com/
2023-05-02 06:33:51,"If something can cause the world harm, shouldn’t  the news article be open to all and not behind a paywall 🤷🏻‍♂️😜"
2023-05-02 06:51:39,"If this was a political group, I'd say that this is an example of capitalism at its prime. But hey, I don't want to get banned 😞"
2023-05-02 10:18:40,How are you folks adding conversational memory to gpt-3.5-turbo?
2023-05-02 10:19:45,Might help :)
2023-05-02 10:19:51,I would have loved to plug Langchain here if they had absolutely anything which worked
2023-05-02 10:20:41,Could you please elaborate? Trying this out. Any shortcomings that we need to be aware of?
2023-05-02 10:22:16,https://augmented-reality-knowledge.github.io/
2023-05-02 10:22:49,Is this not working for you?
2023-05-02 10:23:06,Random shortcoming from the last 24 hours alone which I've seen:
2023-05-02 10:25:04,"For a lot of _common_ use cases (outside of agents), it's perhaps better to roll your own then to use Langchain — and I say this as the resident Langchain fanboi of this group"
2023-05-02 10:25:13,What if there are a lot of messages? Exceed 4096 tokens.
2023-05-02 10:25:43,Make an extra API call and ask the model which messages are worth keeping up
2023-05-02 10:26:37,Give an Example?
2023-05-02 10:32:23,Code flow example: https://github.com/hwchase17/langchain/blob/master/langchain/memory/summary.py
2023-05-02 10:47:26,thanks!
2023-05-02 11:47:54,1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?
2023-05-02 11:48:41,There was a person from luma labs here no? 🤔
2023-05-02 11:48:41,A friend has used llamaindex for chat conversations and was satisfied
2023-05-02 11:49:15,He is in the other group created  by Nirant.
2023-05-02 11:51:55,DMing you
2023-05-02 11:52:31,[PHONE REMOVED] for chat convos how has your experience been with llamaindex?
2023-05-02 11:52:42,I know you use both langchain and llama
2023-05-02 11:53:15,Yeah I started of with gpt index but moved to langchain
2023-05-02 11:53:28,Actually I wanted to create custom tools
2023-05-02 11:54:00,My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?
2023-05-02 11:54:06,"For these use cases, Langchain is still very good"
2023-05-02 11:55:00,Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?
2023-05-02 11:55:53,For storing chat history isn't llama better? Thought you had some points on this
2023-05-02 11:56:39,I have
2023-05-02 11:56:42,It gets the job done
2023-05-02 11:57:03,Those are also options being evaluated but there are company level constraints on them.
2023-05-02 11:57:22,[PHONE REMOVED] any input on the 2nd question?
2023-05-02 11:57:25,"Thanks, I will DM you."
2023-05-02 12:12:51,This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.
2023-05-02 12:15:05,"It's not just about backward compatibility. It's also about clarity on what they want to do — Langchain seems to be prioritising agents, tools and toolchain around that over everything else"
2023-05-02 12:31:12,"True we wrote own in js stuff moved away from langchain , will open source soon once we have most basic func"
2023-05-02 12:36:04,Question was around data connectors and indexing: 
2023-05-02 12:49:09,Does deforum have a commercial license?
2023-05-02 13:14:05,interesting - I've been using https://deeplearn.org/ for this
2023-05-02 13:24:15,Has anybody tried Semantic Kernel? Do you see this as langchain alternative? 
2023-05-02 13:38:47,"I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) — but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along"
2023-05-02 13:42:00,"Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term."
2023-05-02 13:50:06,"But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest 🥲"
2023-05-02 13:50:53,yea! heard they raised another round already (not sure about the source though)
2023-05-02 13:54:12,Why though?
2023-05-02 13:54:38,I frankly don’t see any llm abstraction library really working out in the near term. Its like writing a C compiler for a changing chip design and Instruction set before x86
2023-05-02 13:54:48,API design has little to do with community traction I'd believe
2023-05-02 13:55:04,"Say more, I don't understand you"
2023-05-02 13:55:17,"Fun analogy, but the x86 is GPT4 no?"
2023-05-02 13:55:36,"Gpt is the processor, instruction set is the prompts"
2023-05-02 13:59:07,MSFT is the fastest moving startup in his new world IMO
2023-05-02 13:59:43,"Reminds of the SaaS joke I've made since 2019: All B2B salesfolk work for Microsoft, only some know it"
2023-05-02 14:00:49,"I love how one man Satya Nadella has changed that perception over a few years, completely"
2023-05-02 14:03:16,"Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more."
2023-05-02 14:03:48,https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/default_prompts.py
2023-05-02 14:04:55,langchain is buggy as hell also.
2023-05-02 14:06:40,this is gold! 🌟
2023-05-02 14:06:58,Thanks! Will DM. We’re doing something similar - a simple moving window of 500 input tokens.
2023-05-02 14:07:05,fwiw we've been using llama index in prod for two weeks now doing around 500 questions on the company docs daily / no issues
2023-05-02 14:07:43,"Please, can we make a simple colab notebook that has best practices of implementing rolling windows contexts?"
2023-05-02 14:07:49,"I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because ""this is the first thing I said!"""
2023-05-02 14:08:50,maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio
2023-05-02 14:09:21,What about summarisation? We’ve tried calling the openai summarisation API to summarise the prev chat but it’s slow af
2023-05-02 14:10:14,We need some inside info on how chatgpt is doing this 🫣
2023-05-02 14:10:35,OpenAI has a summarisation API? Didn't they deprecate that?
2023-05-02 14:11:34,"Prompt engineering helps there. Think of your usecases as bucketed modules. Don't use a one size fits all prompt, but smartly create prompts that can preserve needed info. Has been working well for our usecases"
2023-05-02 14:11:41,"Openai once suggested to us in 2020 to use a smaller and faster model for summarisation here, wonder how well that works"
2023-05-02 14:12:04,"It's a trade off, experience vs expense. Have to take that call based on your product."
2023-05-02 14:12:35,"use gpt-3.5 only, prompt it well, keep temp low."
2023-05-02 14:18:22,Had worked on Lucene (query side) and written custom rankers in Solr etc. But not worked with OpenSearch. It's been a while.
2023-05-02 14:25:00,[PHONE REMOVED]
2023-05-02 15:12:18,Would this be of help? It creates a running summary of earlier conversations while also retaining the latest n interactions in their richer form.
2023-05-02 19:20:35,"Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com"
2023-05-02 22:54:34,I think we might have the answer why LangChain is so focused on tools and agents 
2023-05-02 22:55:21,Using tools and agents with LangChain officially part of OpenAI cookbook
2023-05-02 23:08:15,Also a very basic question for anyone who can help 
2023-05-02 23:09:11,You mean executing untrusted code from an LLM?
2023-05-02 23:14:34,Python environment can be sandboxed ?
2023-05-02 23:16:58,Also not an agent like AutoGPT/BabyAGI
2023-05-02 23:18:55,Doing so in production at a decent scale
2023-05-02 23:58:47,Awesome. Would love to talk. Will DM you
2023-05-03 00:18:34,What’s the scale?
2023-05-03 00:54:17,https://twitter.com/samim/status/1653289578390749186?s=46
2023-05-03 00:55:50,Done ✅ 
2023-05-03 01:08:25,Nice
2023-05-03 04:52:08,GPT4 creates a vector DB: https://twitter.com/AlistairPullen/status/1653459578229788672?s=20
2023-05-03 08:09:16,"Replit open source LLM just dropped. Its released under CC BY-SA 4.0, which allows for commercial use."
2023-05-03 08:27:19,is this what powers ghostwriter?
2023-05-03 09:50:04,https://twitter.com/grimezsz/status/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA
2023-05-03 10:12:48,Looks like he also called it out on his pod https://www.youtube.com/watch?v=WBgrfWW8xxA&t=2095s
2023-05-03 10:34:30,Finetune on instruction dataset curated from geeksforgeeks
2023-05-03 12:19:52,https://twitter.com/pirroh/status/1653586734641471490
2023-05-03 12:26:20,"Prompt Injection in less than 10 minutes (video, slides, transcripts): "
2023-05-03 12:28:36,Also the very fun follow up article to why you can’t use AI to fix this 😂
2023-05-03 14:30:59,Anybody applied for the OpenAI service on Azure?
2023-05-03 14:32:19,Got ours withing a couple of days
2023-05-03 14:33:04,JSONFormer: https://github.com/1rgs/jsonformer — guaranteed JSON output with Huggingface LLMs
2023-05-03 14:33:25,cc Ankita [PHONE REMOVED] is from Microsoft Azure India — can reach out to her directly
2023-05-03 14:34:14,Why would you do that? 🤣Sorry ankita be ready to be bombarded with api requests
2023-05-03 14:35:22,Please DM me - happy to help
2023-05-03 14:40:48,the approach looks very promising!
2023-05-03 18:00:55,DeepFloyd or Multi-ControlNet?
2023-05-03 18:01:02,Abstract artwork I made using stable diffusion. Abstracts are hard to conceptualize and compose but they're a lot of fun!
2023-05-03 18:01:10,Neither
2023-05-03 18:03:00,"Custom trained checkpoint, good use of prompts and neg prompts, inpainting, upscaling. And several iterative loops with tweaks in each interation"
2023-05-03 18:24:54,"Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt ""impressionism oil on canvas painting, thick brush strokes, palette knife technique"""
2023-05-03 18:25:46,It was used in the prompt of several of the iterations used to make this
2023-05-03 18:47:19,Is there a model (other than gpt4) that can extract info from a image in JSON format? 
2023-05-03 18:51:08,What kind of info?
2023-05-03 18:51:59,"Basic OCR should be able to do that, unless you want only some part of the text"
2023-05-03 18:52:03,Does anyone know anyone who has access to multi-modal gpt4?
2023-05-03 18:54:48,That’s true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.
2023-05-03 18:55:01,I feed it search result cards from any website and it gives me extracted data with {fieldName: value}
2023-05-03 18:55:39,Yes! That’s so true
2023-05-03 18:57:04,"Infact, we can extract values without OCR as well. HTML contains most of the info anyways."
2023-05-03 19:13:11,[PHONE REMOVED] check if this can help
2023-05-03 19:28:48,Thanks. But I think it's solving a different problem :(
2023-05-03 19:33:40,https://www.spellpage.com/?utm_source=bensbites&utm_medium=newsletter&utm_campaign=pi-the-new-ai-on-the-block
2023-05-03 19:33:41,autogpt app
2023-05-03 19:51:21,A schema of the output json would help
2023-05-03 19:58:37,It should depend on how the clip model used to create  captions describes the image
2023-05-03 20:17:08,"If these result cards are in tabular form, table-transformer might help. https://github.com/microsoft/table-transformer"
2023-05-03 20:32:11,"haha, been there!"
2023-05-03 20:40:06,"Hey folks, can you help with the group invite link? (Can't find it in description)"
2023-05-03 20:43:59,No issues at all
2023-05-03 20:44:04,Sorry for delay in response earlier
2023-05-03 20:51:58,"Have worked on this before. This kind of information is hard to parse in general case (sometimes value can be left of field or right of field, the field and value both can be non regex-able etc). Is there strong geometric structure or is the layout confirming to some standard (think specific bank forms etc). If not folks train specific models to extract these for specific class of documents. Little busy for next day or so, if not urgent message me and happy to chat later."
2023-05-03 20:52:39,"Has anyone tried langflow here? Please DM if you have, thanks!"
2023-05-03 20:53:22,https://techcrunch.com/2023/05/03/where-is-india-in-the-generative-ai-race/
2023-05-03 21:35:50,https://www.latent.space/p/reza-shabani#details
2023-05-03 21:37:26,interview with our head of ML and swyx
2023-05-03 22:08:59,"While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,” said analysts at Sanford C. Bernstein."
2023-05-03 22:17:35,Chris Lattner's new ML focussed language
2023-05-03 22:18:42,[PHONE REMOVED] - is working on this. More from him.
2023-05-03 22:24:55,Amazing. Would love to connect and contribute.
2023-05-03 22:39:28,https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table
2023-05-03 22:40:26,I would also like to learn more and contribute in this project
2023-05-03 22:44:59,I think the entire article can be summarised in 3 sentences - 
2023-05-03 22:47:08,"Yes, keen to learn more!"
2023-05-03 22:49:03,Can someone add the author Manish Singh from Tech Crunch to this group if they have the number https://twitter.com/refsrc?s=21
2023-05-03 22:49:40,"We have coders, designers, PMs and VCs here but any journalists or media folks? Please say hi!"
2023-05-03 22:51:36,Asking
2023-05-03 23:01:12,Hi Manish 👋🏻
2023-05-03 23:03:01,Thanks for adding Aakrit -- good to be here
2023-05-03 23:03:59,Good to see you here [PHONE REMOVED]
2023-05-03 23:04:43,Good to see you here [PHONE REMOVED]
2023-05-03 23:26:37,Yes
2023-05-04 00:29:26,Glad to be a part - thanks for adding me [PHONE REMOVED] 
2023-05-04 00:31:02,Good to see you here!
2023-05-04 00:31:30,Oh hi haha! likewise :)
2023-05-04 00:58:33,https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19
2023-05-04 02:37:21,any model (large language or not) with many parameters suffers from the curse of dimensionality and it is fundamentally impractical to cover all modes of adversarial attack
2023-05-04 02:37:28,arrey hey rahul 👋!
2023-05-04 09:03:02,"There is an opportunity here to create artist focussed digital painting tool using GenerativeAI, right now you are hacking with automatic1111, recursively using the output as the next input, using Photoshop to do what's not possible in automatic etc."
2023-05-04 09:45:39,"Hey folks, does anyone in this group have experience creating large scale datasets for llm model training?"
2023-05-04 09:48:06,How large? I processed around 300GB for https://huggingface.co/aashay96/indic-BloomLM
2023-05-04 09:48:31,300gb is large enough DMing
2023-05-04 09:57:18,"Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline."
2023-05-04 09:58:42,cc [PHONE REMOVED] [PHONE REMOVED] would be great to hear from top of my head
2023-05-04 10:00:52,Can you please look at https://github.com/EleutherAI/lm-evaluation-harness as well? [PHONE REMOVED]
2023-05-04 10:01:04,"Doesn't have qdrant, Weaviate — has the same libs as earlier, only adds Vespa as far as I can tell? Did Erik choose to wait for Weaviate feedback?"
2023-05-04 10:11:56,Would love this
2023-05-04 10:12:58,"A very interesting question to ask would be how does OpenAI do on the lm-evaluation-harness, and what does openai/evals which the harness does not?"
2023-05-04 10:14:17,Unfortunately the whole pipeline is hugginface based. Would require a lot of rewrite
2023-05-04 10:15:29,"“To now be relevant as a SaaS co, depth+breadth of workflow is going to be more and more critical. Point problem solutions will find it harder to establish why they capture value”. . Good set of thoughts pinned by [PHONE REMOVED]"
2023-05-04 10:16:16,"yep, was wondering what the choice for libraries was.. Redis seems to be doing very well though"
2023-05-04 10:31:05,Already building this artist’s tool 😉
2023-05-04 10:31:23,Oh nice 🔥
2023-05-04 10:39:44,HF <> Inferless ([PHONE REMOVED] ) on deploying GenAI models meet-up on June 10th.
2023-05-04 10:41:48,"Thanks for the shoutout Ravi! Folks, please share what all would you like us to cover specifically around model training and deployment.. I am all ears! 😃"
2023-05-04 10:58:57,"Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com"
2023-05-04 11:00:16,Hey folks - Vikram is excited to have a session. 
2023-05-04 11:17:37,Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.
2023-05-04 11:32:44,I believe Soumendra [PHONE REMOVED] was giving it a shot
2023-05-04 11:50:10,What do you mean by your own vector embeddings?
2023-05-04 11:50:23,How are you generating them?
2023-05-04 11:52:19,Thanks for responding. I am not using any of the prebuilt vectorizers.
2023-05-04 11:52:21,with client.batch as batch:
2023-05-04 11:52:38,cc [PHONE REMOVED] from RestOfWorld is here. He's also quite comfy with Midjourney and ChatGPT based apps.
2023-05-04 11:52:50,Here the embeddings are my vectors generated thru Sentence Transformers  [ choose  your model ]
2023-05-04 11:53:30,Example : from sentence_transformers import SentenceTransformer
2023-05-04 11:53:42,embeddings = model.encode(Lines)
2023-05-04 11:54:26,What does the search query look like?
2023-05-04 11:55:32,result = (
2023-05-04 11:55:43,See the near_vector please
2023-05-04 12:01:52,Moving this to one-on-ine as this is going to get technical
2023-05-04 12:02:29,Yes that's better
2023-05-04 12:02:33,Can you DM me output of print(result)? We'll take it forward from there.
2023-05-04 12:02:52,"Maybe try reducing ""certainty"" to 0.7 and see?"
2023-05-04 12:03:36,How one can achieve multi-tenancy in Qdrant?
2023-05-04 12:04:44,Thank you ; reduced further still no luck
2023-05-04 12:06:54,+1 have the same question about vector dbs
2023-05-04 12:12:46,"I have used Faiss and Milvus (via Haystack) for personal projects very long time ago. Used to create create separate collections for different type of datas. As that time filters were not common in these vector dbs. Now like to understand is there other better way, ideally separating storage from query layer."
2023-05-04 12:26:12,"Yes, separate collections is perhaps the cleanest way? "
2023-05-04 12:37:57,"For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J"
2023-05-04 12:55:45,https://github.com/unum-cloud/usearch
2023-05-04 12:56:08,"From NimbleBox folks in India, [PHONE REMOVED] and friends — low-code for making chat experiences in particular: https://github.com/NimbleBoxAI/ChainFury"
2023-05-04 12:57:13,Thanks for the shout-out Nirant 🙏🏻😊
2023-05-04 12:58:40,I have done this. 
2023-05-04 13:00:31,"What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale"
2023-05-04 13:17:13,"Hi everyone, "
2023-05-04 13:17:51,Average out the embeddings for the document
2023-05-04 13:18:25,Are you predicting related keywords for a given text and then clustering somehow ?
2023-05-04 13:19:39,"For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved"
2023-05-04 13:20:02,"Shyam, a few details which will help us answer your question better: "
2023-05-04 13:20:46,Could you describe your approach ?
2023-05-04 13:20:47,"Example, if the user is prompting 'x of 10%', but the data point has the absolute value of that variable, then some logic will be needed."
2023-05-04 13:22:03,"We don't implement the matching, because the prompts are varied as I mentioned, we are directly feeding the data and prompt to gpt-3"
2023-05-04 13:23:43,Is there a reason for using text-davinci-003 and NOT gpt3.5-turbo?
2023-05-04 13:24:57,"1. No, just the GPT-3 endpoint."
2023-05-04 13:26:25,"No reason, have to try gpt-3.5-turbo and compare results"
2023-05-04 13:28:26,Any links/readings to understand this in detail?
2023-05-04 13:28:28,Thanks ! Can you also please share the invite link for this group
2023-05-04 13:29:39,https://huggingface.co/gemasphi/laprador-document-encoder
2023-05-04 13:32:59,Has anybody used langchain or llama index for hybrid embeddings? I was looking through their code to find what they use for sparse embeddings. Llama seems to use BERT and langchain I couldn’t find
2023-05-04 13:33:22,The error was the Vectors were not inserted properly. The correct code [ highly simplified is here]
2023-05-04 13:33:25,with client.batch as batch:
2023-05-04 13:33:50,Vector =  < Place your VECTOR embeddings here>
2023-05-04 13:34:43,"Llama Index has extensible Retrievers, so shouldn't matter either way no?"
2023-05-04 13:34:56,Thanks to  Soumendra @+91 74980 76111  for trying yo help me
2023-05-04 13:36:17,Thank you for your interest. I used simple Python and Weavite librarues
2023-05-04 13:37:19,Thanks Sharding is another good way.
2023-05-04 13:37:48,Ah got it. So BERT was just an example
2023-05-04 13:38:00,Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.
2023-05-04 13:38:19,cc [PHONE REMOVED] was a Haystack contributor :)
2023-05-04 13:38:36,"Yeah, Llama Index has decent Retriever design. Some Custom examples: https://github.com/jerryjliu/llama_index/blob/main/examples/query/CustomRetrievers.ipynb"
2023-05-04 13:47:05,"I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?"
2023-05-04 13:47:56,"Ease of use, right place at right time, became viral too fast before people even knew about alternatives"
2023-05-04 13:48:35,Once the GitHub stars started picking up everyone's eyes were on it.
2023-05-04 13:48:37,Haystack is much better in code quality and documentation imo.
2023-05-04 13:51:05,"Chatgpt helped as well, probably they rode that wave, may be haystack didn't treat chatgpt as urgent requirement"
2023-05-04 13:52:26,"Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain."
2023-05-04 13:53:12,I mean there is overlap between both
2023-05-04 14:03:59,indexes feels like semantic search interface - https://python.langchain.com/en/latest/modules/indexes/getting_started.html
2023-05-04 14:15:39,"Thanks, this discussion helped understanding strengths of langchain and/vs haystack"
2023-05-04 14:27:04,"yeah, just discovered this: https://docs.haystack.deepset.ai/docs/document_store because of the discussion here. I was thinking of creating a similar abstraction layer (i.e. provide a single API for vector DBs, allowing any VectorDB to be plugged in), but I might just depend on this now"
2023-05-04 14:29:17,True. Apart from code and documentation. Haystack is very good in design. Just check how haystack implemented PromptNode and compare it with Langchain. You will see the difference.
2023-05-04 14:31:47,"“ This approach is the most flexible, but creating numerous collections may result in resource overhead.  only recommended to separate users into multiple collections if you have a limited number of users “"
2023-05-04 14:33:00,"Agreed. And the vector store abstraction too. Granted it's not perfect, but flexible enough to mould it the way we want."
2023-05-04 14:34:07,100s should be pretty fine from what I've been told internally
2023-05-04 14:34:41,100x100 na
2023-05-04 14:37:52,"Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build."
2023-05-04 14:39:22,"fwiw, all FOSS Vector DBs offer cloud solutions so that you don't have to think about cluster sizing, managing servers, sharding and  problems like what [PHONE REMOVED] just mentioned"
2023-05-04 14:40:16,Build vs Buy 😄
2023-05-04 14:50:27,Vitess is a great tool.
2023-05-04 15:36:38,For folks wondering: https://vitess.io/ is a tool for sharding — and here is a good primer for what sharding means: https://aws.amazon.com/what-is/database-sharding/
2023-05-04 15:42:57,"Have y’all heard of Modular? Chris Lattner’s (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication "
2023-05-04 15:45:11,https://planetscale.com/ does managed Vitess as well. We were exploring it at Razorpay.
2023-05-04 15:45:15,"Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years."
2023-05-04 15:45:58,How did Razorpay end up doing sharding?
2023-05-04 15:46:29,Not being open source at launch was a weird choice...  Can't remember the last time a language launched like that...
2023-05-04 15:50:14,We didn't go ahead in the end. 😅
2023-05-04 16:04:04,Jeremy was a strong proponent of TF Swift as well. But that hasn't seen major adoption even inside G so ymmv
2023-05-04 16:12:17,https://open.substack.com/pub/semianalysis/p/google-we-have-no-moat-and-neither?r=2gao6&utm_medium=ios&utm_campaign=post
2023-05-04 16:17:24,(from the above article)
2023-05-04 16:18:09,Why do I think this graph is on a log scale 😅
2023-05-04 16:18:55,"Hey, i wanted to understand the difference between generative pre training vs instruction tuning in terms of huggingface trainer class. How does the training objective change?"
2023-05-04 16:20:30,This is using gpt4 as a judge having it rate llm outputs
2023-05-04 16:21:12,https://lmsys.org/blog/2023-03-30-vicuna/
2023-05-04 16:21:42,“According to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.”
2023-05-04 16:22:06,Exactly!
2023-05-04 16:22:14,Maybe we run openi evals on it :)
2023-05-04 16:24:15,This eval doesn't make any sense to me. Already LLMs capabilities to produce such ranks/marks are highly debated to it's stochastic nature. It's like a teacher that gives a different score each time when she evaluates  answer from a different room
2023-05-04 16:24:39,Yea... independent and good benchmarking of AI needs to be a thing...
2023-05-04 16:26:21,LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.
2023-05-04 16:28:14,"just to add one more point, alpaca and vinuca are LLAMA derivatives so I don't think it can fit in that graph since they aren't new base LLMs. Also I don't think its good idea to train models on chatgpts output like Alpaca did, if you're curious about the reason:https://twitter.com/Shahules786/status/1650898925178720256"
2023-05-04 16:28:43,"Benchmarking has this weird dynamic of very useful for industry and their labs, but gives no glory to people who make them — so it doesn't attract hackers or academics. "
2023-05-04 16:29:34,Sure... at the research level some objective ones will help but also at the consumer and solutions level... We have a full tech gadget review industry... A similar AI review industry is needed...  This impacts everyone and everything now...
2023-05-04 16:29:52,Need a rtings.com of this space...
2023-05-04 16:30:02,"That is exactly how ImageNet was born fwiw, and Stanford DAWN Bench and so on."
2023-05-04 16:40:54,This is the exact problem with building a tool for Devs 😅
2023-05-04 16:42:41,"Most devs actually have the highest buying power in any organisation. If a developer says they need to pay 100$/mo to keep their database up, that’s a bottom line for a business"
2023-05-04 16:44:41,Devs are the end consumers
2023-05-04 16:46:01,"Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM — I'll resist the temptation since this is already off topic for a Generative AI focussed chat 😅"
2023-05-04 16:48:25,"We should jam separately on this, very different problems and implications :)"
2023-05-04 16:48:36,"yeah. fastai was also going to build a tf swift version i think, but all those projects kinda got abandoned when Chris Lattner left Google."
2023-05-04 17:23:41,"Generative Pretraining is the default ""GPT"" training objective, I'll let you dig this up on your own. If you don't mind reading papers, the original Radford et al is still relevant for this. "
2023-05-04 17:28:16,"On a concept level I understand the difference, but while training it, is there a difference? I checked databricks dolly script - https://github.com/databrickslabs/dolly/blob/master/training/trainer.py"
2023-05-04 17:28:19,"For wider audience, the code interpreter is largely a Python REPL and a GPT4-fork finetuned on Python/code. This is not a separate feature or anything like that. "
2023-05-04 17:28:51,Difference in outcomes or syntax/code which we write?
2023-05-04 17:30:51,Syntax/code - essentially the training objective
2023-05-04 17:33:09,"Going out on a limb, but I'd like to think that they should be identical with different configs — finetuning and training objectives are often kept identical these days"
2023-05-04 17:35:49,Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop?
2023-05-04 17:38:42,Yep. Code interpreter is quite useful.  Threw a csv I had at it and it saved me at least an hour in data clean up if not more...
2023-05-04 17:40:19,Chatgpt code interpreter and gpt-4 browsing models are more useful than I anticipated.
2023-05-04 17:40:40,Guessing — stop word markers in the instruction dataset?
2023-05-04 17:41:35,Are there specific communities/ influencers to follow for generative AI content on Twitter ?I see a lot of content across all groups from Twitter hence asking here
2023-05-04 17:43:10,DM'd my list
2023-05-04 17:44:15,https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table
2023-05-04 18:20:56,https://www.reddit.com/r/StableDiffusion/comments/137ex2j/controlnet_tile_can_generate_details_for_each/
2023-05-04 18:44:20,"Does anyone have experience working with GPT4 for coding in Rust/working with libraries? GPT-3.5 is quite terrible, so wanted some insights on whether GPT4 is any better"
2023-05-04 18:59:57,"If it turns out to be as great as they are claiming, I’m sure someone will build and release open source version of Mojo soon, like OpenMojo etc, and it may create pressure on them."
2023-05-04 19:53:51,"Yeah, you train on( instruction+prompt, output). So the system learn from those instruction what the stop points are to some degree. But the real challenge is ""how do tell these specific words really messed up"". Here is where you do RLHF. Let me try to find some resource to explain this."
2023-05-04 19:54:33,I need to see a training script
2023-05-04 19:56:40,Doesn't the dolly one do.
2023-05-04 19:58:15,"For all thos who asked me earlier and I couldn't find the original resource. This a great one from Stanford. Explains big picture of pretraining, fine-tuning and RLHF. https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf"
2023-05-04 19:59:00,One will need to deep dive into each of those areas for more details. This is big picture intuition.
2023-05-04 20:27:07,asking without asking part-2 😂
2023-05-04 22:12:04,https://twitter.com/pbteja1998/status/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08
2023-05-04 22:15:11,Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though
2023-05-04 22:19:20,There are other differences: 
2023-05-04 22:20:10,"StarCoder is open that their model is GPT2 — so all GPT2 tricks, scripts will work!"
2023-05-04 22:21:25,Really interesting read from Simon Wilson on moats in closed source models quickly disappearing: https://simonwillison.net/2023/May/4/no-moat/
2023-05-04 22:21:45,https://blogs.microsoft.com/blog/2023/05/04/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge/
2023-05-04 22:29:18,"If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ?"
2023-05-04 22:31:40,1. LM-evaluation-harness for Huggingface compatible models: https://github.com/EleutherAI/lm-evaluation-harness
2023-05-04 22:34:16,"I've not had a chance to try Dolly and OpenAssist yet, but GPT-JT (https://huggingface.co/spaces/togethercomputer/GPT-JT) is definitely comparable to text-davinci-003, which was their claim."
2023-05-04 22:34:56,And I am honestly surprised that they were able to get this far by careful training data selection and training/finetuning params
2023-05-04 22:35:41,new model?
2023-05-04 22:35:57,Together are the ones behind redpyjamas right?
2023-05-04 22:41:37,I think it's a bit old? Dec 2022/Jan 2023?
2023-05-04 22:41:50,"Yes, I believe so"
2023-05-04 22:46:19,okay
2023-05-04 23:05:14,https://twitter.com/lmsysorg/status/1653843200975704069?s=46
2023-05-04 23:05:26,seema perfectly reasonable
2023-05-05 00:37:41,"Having tried all the models from Google, I fully agree they have no moat."
2023-05-05 00:41:23,You think OpenAI has no moat either?
2023-05-05 00:41:51,Community / dev side NFX is there
2023-05-05 00:43:12,Also early mover is a real advantage for them. All that gets built/is getting built right .. tough/lethargy to rewrite/rewire
2023-05-05 00:44:08,NFX?
2023-05-05 00:44:37,Network Effects
2023-05-05 00:44:39,Network effects 🙈
2023-05-05 00:45:59,"Of course not, which is why I pointedly talked only about Google 😀"
2023-05-05 00:48:46,"Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough."
2023-05-05 00:50:03,I don't think community/nfx is a moat here. Look at what happened to tensorflow.
2023-05-05 00:50:23,"I think even if open source becomes comparable or even more effective, the possibilities of building a business does exist. "
2023-05-05 00:54:39,OpenAI's moat comes from aligning with MSFT/Azure. Government and finance domains are essentially theirs for the taking.
2023-05-05 00:55:55,"And the pace at with they can onboard other businesses on plugins- like uber, expedia"
2023-05-05 00:57:03,"That will take a while to mature, finance sector is where they'll make the big bags for now"
2023-05-05 00:58:00,esp now that they have solved EDA with code interpreter
2023-05-05 00:59:21,This seems a bit panicky. It's not difficult for big tech to integrate oss stuff back in. They'll most likely wait a while to see what works best before integrating and releasing into products
2023-05-05 00:59:51,have u guys tried out the code interpreter? is that on the waiting list right ?
2023-05-05 01:03:05,"With 3 million software devs in India second only to the US's 4 million, not sure about china numbers. I think the open source implementation may accelerate faster than commercial models. "
2023-05-05 01:18:22,"Not that I disagree. But as the terrain stands currently, (and please correct me if I'm wrong), all major oss developments in LLM (alpaca, llama.cpp etc) built on top of llama. It cost 30M to train that. I don't know how much we can replicate that in OSS."
2023-05-05 01:18:36,Perhaps works like Bloom could prove me wrong?
2023-05-05 01:27:50,"Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs."
2023-05-05 01:29:53,"Man, MSFT under Nadella is gonna be a business school 101 case study in a few years. He's trying to commoditize their complement: https://gwern.net/complement"
2023-05-05 02:15:32,"Not sure if someone shared this here, but super interesting/scary (also expected):"
2023-05-05 02:17:56,"The nearest neighbors will fall first. Further away from it, less chance of being destroyed by the fast-moving train."
2023-05-05 02:32:00,https://www.semianalysis.com/p/google-we-have-no-moat-and-neither
2023-05-05 02:36:47,Hello awesome people. Missed a week (feels like a decade).
2023-05-05 02:37:53,"wish there was an llm-summarisation hooked to this chatbox for the purpose, lol"
2023-05-05 04:03:15,Hugging face just launched StarCoder LLM
2023-05-05 06:12:38,You know this group became so big and intractable when you see the same article being shared 5 times in the past 100+ messages. 😅
2023-05-05 07:06:53,"The Google doom story is about 6mo old, if they get their acts together, they can turn the tide as they still have their distribution intact"
2023-05-05 07:48:06,Anyone using bharatforAI translation in prod? It seems to very require large server instances. Would love to chat if anyone has /is using
2023-05-05 08:41:09,Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up: https://docs.google.com/presentation/d/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU/edit#slide=id.g20f09001284_0_76 
2023-05-05 08:46:40,"Is there any good article with all available SoTA large models in multimodal space (text, image, video, audio, etc)"
2023-05-05 09:05:25,"I'm afk, but look up Amazon's mm-CoT on HF and explore tags from there. Similar for PapersWithCode."
2023-05-05 09:05:48,HF is huggingface.co
2023-05-05 09:18:27,we are getting alternatives now
2023-05-05 12:26:08,Does anyone know if the probabilistic functions in generative models are truly random or deterministic?
2023-05-05 12:31:55,Can you elaborate on what you're trying to understand? This phrasing is hard to understand
2023-05-05 12:33:33,if you are talking about RNGs then they are psuedo random and can be controlled via seed
2023-05-05 12:34:11,although don't expect same results across devices (chipset)
2023-05-05 12:38:52,What's the difference between gpt-3.5-turbo and gpt-3.5-turbo-0301?
2023-05-05 12:40:09,"gpt-3.5-turbo is a ""brand"", it will change under the hood when the _next version_ of gpt3.5 comes out.  "
2023-05-05 12:40:46,got it thanks
2023-05-05 12:45:00,"The encoder takes in a sequence of input tokens, the decoder needs to generate/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence. "
2023-05-05 12:47:01,"as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over?"
2023-05-05 12:49:00,"I think they've shared rate limits, but if they do separately -- yes"
2023-05-05 12:50:34,"Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem. "
2023-05-05 12:50:54,Does it work that way? Or rate limits are key based
2023-05-05 12:56:05,"so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)?"
2023-05-05 13:00:39,Sure
2023-05-05 13:04:28,"Yes, but there is always some non determinism with GPUs."
2023-05-05 13:09:39,"In GPT, the randomness comes from the probability distribution over the vocabulary right? Is there a way we set top-k/top-p values though the chat interface?"
2023-05-05 13:09:45,What are some good tools for creating and managing prompts?
2023-05-05 13:41:29,"Does anyone have resources around how to do chunking while creating code embeddings? Also, pointers to the best open source model for code embeddings would be great."
2023-05-05 13:46:26,Noob question: Can Meta's SAM (Segment Anything) and Track Anything - can be utilised for tracking logos from the video? 
2023-05-05 14:03:30,Yeah. Should work out of the box
2023-05-05 14:07:04,What are the best tools/repos to replicate the AI songs like the ghostwriter ones (drake wala)
2023-05-05 14:56:58,"on the same chipset, yes, as long as all software versions are pinned down to the lowest levels including the os and kernel"
2023-05-05 15:15:40,"So-vita-svc, afaik"
2023-05-05 15:15:43,https://agi-sphere.com/llama-models/
2023-05-05 15:16:05,so-vits-svc
2023-05-05 15:16:37,Would be interested to know what artist you’re replicating
2023-05-05 15:17:34,"Also, it would be a fun get together for anyone trying to make a song, I know I haven’t taken an initiative here, but would be thrilled to jam with anyone who does 🙂"
2023-05-05 15:20:55,There was a sheet here with a list of fine-tuned models - anyone have it?
2023-05-05 15:20:57,[PHONE REMOVED]
2023-05-05 15:52:32,Can you share a link plij?
2023-05-05 15:55:42,I've heard good things about this
2023-05-05 17:17:15,Hi
2023-05-05 18:07:39,Well that so-vits-svc models sheet is deprecated now (obviously because decades have passed 😛)
2023-05-05 18:09:03,I want to train on Arijit's voice but I'm quite occupied these days :')
2023-05-05 18:21:33,++
2023-05-05 18:26:31,"https://discord.gg/aihub a lot of models here. It’s 7000 people big and people say all kinds of stuff there. [PHONE REMOVED] did an amazing job of keeping this community focused and productive for this long, everyday I am blown away looking at the cutting edge work you’ll are doing. ✨"
2023-05-05 20:55:09,https://www.mosaicml.com/blog/mpt-7b
2023-05-05 20:55:40,"SlackGPT — multiple business workflows, horizontally integrated with Slack.  "
2023-05-05 21:05:07,"Might have to rename it, gpt trademark"
2023-05-05 21:11:32,salesforce v openai soon
2023-05-05 21:12:28,Salesforce vs Microsoft
2023-05-05 21:13:14,Also didn’t Slack partner with OpenAI for this ?
2023-05-05 21:15:06,They are able to generate 84k tokens on a single A100 GPU by finetuning base model of 2k context length to finetuned model with context length of 65k.
2023-05-05 21:21:28,"Just used for a few prompts that I tried for ChatGPT (GPT4), still a long way to go. I used mainly used code snippets and asked questions around it. I wasn't able to get  answers and abruptly stopped giving responses mid way."
2023-05-05 21:26:44,Which checkpoint did you use ? + it might not do that great with code understanding as it is trained only on 135B tokens from the stack.
2023-05-05 21:27:20,This one `MPT-7B-Instruct`
2023-05-05 21:29:01,I will also try it. Would be interesting to generate 6th book of GoT series as George RR Martin might never write it
2023-05-05 21:56:43,Taylor Swift singing a kannada song :D
2023-05-05 22:27:53,I genuinely want to try out The Weeknd singing Arijit songs 😬
2023-05-05 22:50:12,"Not sure if this has been shared / discussed before (since I joined late in this group), throwing it here. "
2023-05-05 23:15:20,https://wandb.ai/site/prompts
2023-05-06 00:43:09,https://huggingface.co/spaces/mosaicml/mpt-7b-chat
2023-05-06 01:36:13,A very good post on what transformers are for some of us who are getting started and others who just want to deepen fundamentals.
2023-05-06 01:46:43,Luis Serrano and Jay Alammar - Cohere has two of best ML content creators ever.
2023-05-06 10:23:20,Hi. Anyone wants to join an already formed awesome team in Warpspeed GenAI hackathon? We have one open slot! We would love to have you.
2023-05-06 11:53:51,Does anyone have/made a list of top AI themed newsletters??
2023-05-06 11:58:33,I followed a few but found this the best bensbites.co
2023-05-06 12:04:07,checkout 42papers.com
2023-05-06 12:13:03,That's Twitter but worse because almost everything there is already from https://twitter.com/_akhaliq
2023-05-06 12:14:53,These are the one's ive found quite useful:
2023-05-06 12:55:43,"New open source LLM, better than Llama, commercial use allowed"
2023-05-06 12:58:15,"""The 7B model is still training (at 800B tokens) and we see the training loss still decrease consistently. As a result, we will continue to train it to 1T tokens."" Fascinating that models will start to touch the trillion mark!"
2023-05-06 13:17:03,"No. There are two ways to make it deterministic (this is not including RLHF magic, any fine-tuning magic etc, don't know what all they have here) but both with different behaviours. One by setting temp=0, here you are forcing softmax to select the top word pick, so this degenerates to greedy though you are sampling. Thus will have issues being it taking the most frequent word combinations."
2023-05-06 13:18:09,"The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero."
2023-05-06 13:19:46,Pro Tip for anyone trying to pursue this line of reasoning and looking for first hand experience: Take a GPT2 or BLOOM model and try to get consistent outputs — you'll develop a very good mental model of what it takes to get a deterministic output.
2023-05-06 13:23:58,"Hey everyone, Chirag this side from Endiya Partners, an early stage VC. Happy to be here! "
2023-05-06 13:53:56,https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor
2023-05-06 14:17:31,Might have a better time just running clip interrogator and just asking gpt for a score from that genenrated caption
2023-05-06 14:22:48,"Hallucination and determinism (the above definition of it, same output for same input) are not that related. Hallucination is largely an after effect of model learning patterns that aren't true, in the weights so to speak. The determinism issue is largely a final layer problem (and may be fine-tuning layers). As in how you select from most  reasonable walk amongst series of words choices (you essentially have k-ary tree starting from first word). Another meaning of determinism could be whether it could generalize well (minor perturbation of input don't lead to change in output), this is very related to hallucination and both are related model weights."
2023-05-06 14:34:08,"I don't think this is doing human profile scoring per se 😀. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating."
2023-05-06 14:38:01,[PHONE REMOVED] sir would you like to explain AVA and image dataset curation methods/conventions — lot of folks here are not from Vision in particular
2023-05-06 14:40:41,It is pretty bad at scene scoring too unfortunately. Only the examples they've shared score well.
2023-05-06 14:51:58,"Sorry, my bad. This is for the problem of Visual Aesthetic Scoring that is given a set of pictures, score pictures from interesting to least (think flickr interestingness if you know what that was, like what photos you will want in your album or showcase your photography talent). There were bunch of datasets created for this, AVA was one of those, I think curated from DPChallenge with score and sematic tags for each image."
2023-05-06 14:55:19,it's ranked based on likes etc not from a specific person also each paper is has a short summary as well as why it's important basically designed for a daily quick scan
2023-05-06 14:56:23,which part is worst always improving so happy to learn
2023-05-06 15:02:33,https://github.com/mosaicml/llm-foundry/tree/main/scripts/eval
2023-05-06 15:06:28,there needs to be a standard that everyone can use. Was hoping HELM becomes that
2023-05-06 15:07:14,"Any good library references to create datasets for LLMs? Say, training Vicuna/Dolly 7B/13B on a domain. I want to replicate what BloombergGPT did in finance but for a very specific bucket in finance. Also, any way to estimate infra cost for suchs training and hosting?"
2023-05-06 15:08:40,"Given a prompt, and a set of generations from the prompt, example, if the prompt is ""black and gold colour scheme, blue sky, white mountains, red house,... "" and 10 images are generated, is it possible to rank the generated images based on how well the prompt was followed?"
2023-05-06 15:11:18,"Additionally, given that there are numerous generations where there are small issues, for example, extra hand in one, incorrect tshirt representation in another, is it possible to auto build a workflow, which figures out where the image is incorrect , masks it, and sends through another generation to fix that area?  If so, what would be required for it to detect errors in the image?"
2023-05-06 15:12:30,Reply with: DM me 😂
2023-05-06 15:14:30,you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service.
2023-05-06 15:19:35,Could be a growth hack as well
2023-05-06 15:23:50,"Are you a dev? Because you just pulled a ""It's a not a bug, it's a feature"" 😂"
2023-05-06 15:58:17,"No that is a different problem altogether. The above one is a very visual problem, doesn't depend on things like semantic meaning or the implications of those as much. So for example, it will rank the fanous Henry Cartier Bresson's Leap into unknown photo (this photo's context is Europe entering world war 2) poorly. The visual aesthetic problem to a decent degree is sort of solved. Many models are production use, where you can remove human time required. But this problem requires more understanding of real world (like humans have 2 hands etc). So training on that dataset probably won't work as well. I think [PHONE REMOVED] and others have worked on this more. They can chime in on what works."
2023-05-06 16:00:39,"I mean, large scale deployments are common for Visual Aesthetic scoring, where revenue numbers can be impacted if you do poorly."
2023-05-06 16:04:17,"Is it possible for a visual QA model to identify errors in a picture, if we use ""errors in the image"" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections?"
2023-05-06 16:05:14,"I am asking more from a workflow, rather than one model doing it all. It would be difficult to make it work using a single model."
2023-05-06 16:06:02,this seems like a task for andrew ng's https://landing.ai/
2023-05-06 16:07:19,Any open source suggestions?
2023-05-06 16:20:42,"Could you expand a bit on errors, what kind of errors are you expecting, like logical, or edited in errors?"
2023-05-06 16:22:04,"Oh I just saw the above messages, you mean errors between the prompt and the images."
2023-05-06 16:23:47,"a naive idea that comes to my mind, is divide the images into multiscale patches, embed with CLIP and then check similarity with the prompt."
2023-05-06 16:24:20,"The issue with this is that if the hands were incorrect, it would still return hands."
2023-05-06 16:26:26,Discussion on HN about Langchain
2023-05-06 16:31:44,"similarity of the string ""hands"" will still be less for it, compared to a good set of hands, is what I am hoping. "
2023-05-06 17:33:19,Any idea how much time does it take to get access to chatgptplugins?
2023-05-06 19:10:25,"Thanks, I'll check."
2023-05-06 19:19:23,"Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?"
2023-05-06 19:34:21,Bloomberg gpt.. but it quite expensive
2023-05-06 19:34:45,they’ve released a product? Last I knew it was a paper
2023-05-06 19:35:46,I think they released it into their terminal
2023-05-06 19:37:13,someone was finetuning gpt with yahoo finance in this group?
2023-05-06 20:40:54,https://llava.hliu.cc/
2023-05-06 21:02:59,There’s an open source alternative to Bloomberg terminal called OpenBB. They released a blog on how one can train on their documentation to get the appropriate OpenBB command 
2023-05-06 22:46:05,I'm starting to look into the autonomous agents space
2023-05-06 23:37:51,https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents
2023-05-06 23:44:43,i built something for myself along these lines much simpler and no dependencies
2023-05-06 23:44:57,https://github.com/dosco/minds
2023-05-07 03:29:53,"OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of _safety reasons_ — as they've hinted in the past, , but because of competitive reasons. He believes models can be improved to the point _in future_ where it becomes a safety concern.  "
2023-05-07 03:30:19,competitive reasons aka MSFT in simple words
2023-05-07 04:39:54,"If anyone wants a longer rant, look up yannic kilcher on YouTube 😂"
2023-05-07 07:06:25,Try yubibert for India
2023-05-07 08:17:41,"As LLaMa adoption suggests, once you release the weights publicly, the ecosystem catches up very, very strongly"
2023-05-07 12:32:14,they will have the RLHF edge in 1-1.5 years where OSS will keep playing catchup
2023-05-07 12:40:38,"True, and in 1-1.5 years they will have the RLHF edge which OSS will keep playing catchup on"
2023-05-07 14:44:34,Here's where my thoughts are -
2023-05-07 14:46:19,"While [PHONE REMOVED] already gets this, reminder for other readers: "
2023-05-07 14:57:27,Which (as per my current level of understanding) matters more in an Autonomous Agent powered world
2023-05-07 16:10:39,Hot take from Jim Fan: 
2023-05-07 18:17:44,Summary of everything that we discussed yesterday with all the links: 
2023-05-07 18:25:38,https://twitter.com/natolambert/status/1654190084428808194
2023-05-07 18:31:06,This is also a work-in-progress preview of a daily summary of this group chat — going back to starting of the group itself:  https://nirantk.com/ai.html
2023-05-07 18:31:47,Design Choices:
2023-05-07 18:31:53,Asks: 
2023-05-07 18:31:59,"Damn, I was about to start working on this exact thing!"
2023-05-07 18:36:57,"The markdowns in content/ai/ are the summaries, right?"
2023-05-07 18:37:22,Yes
2023-05-07 18:39:54,It's the markdown files which Hugo builds into static website served via Github Pages
2023-05-07 18:40:15,I'd love if we can use prettier CSS and better JS: https://quartz.jzhao.xyz/ — this has fast search and is also markdown friendly
2023-05-07 18:42:56,I'll do 2. I'm guessing you have the zip file locally and you want to run manually for now?
2023-05-07 18:43:55,"Yes. I've the zip file locally — well everyone in the group can download it as well. And I want to run locally, but only incrementally."
2023-05-07 18:46:04,"Thanks so much for doing this [PHONE REMOVED]. Maybe we can have a pool where we can contribute to the bill or something? Happy to support in whatever way you suggest. Also realise its a fraction of the total effort, so double thank you"
2023-05-07 20:53:57,You have to appreciate the hustle
2023-05-07 20:54:31,AI creating new jobs (NOT taking them away :P)
2023-05-07 20:55:57,Totally. Fiverrs a great window into what services are becoming valuable.
2023-05-07 20:58:24,Replit bounties are flooded with ChatGPT and AutoGPT related projects too.
2023-05-07 20:59:06,promptbase is a better signal
2023-05-07 20:59:21,They have loads of prompt engineers - they charge 50-500$ for custom prompts
2023-05-07 22:00:47,the google memo leak seems to think smaller os models are the future
2023-05-07 22:02:55,"Reminder that is a single Google employee's opinion, not their company policy or even a team's mandate."
2023-05-07 22:08:23,https://arxiv.org/abs/2305.02301
2023-05-07 22:08:47,"Is the memo written and leaked by a single employee, or it was a memo shared internally and leaked by an employee?"
2023-05-07 22:09:24,"Written by a single employee, shared internally, like an internal forum, and shared outside by someone else presumably"
2023-05-07 22:11:16,"Got it, I was thinking it was shared by higher ups in some meeting or something"
2023-05-07 22:19:42,"Google is quite open internally, ex you can view almost anyone's code if you're an employee. Most likely someone wrote a Google doc, shared in an internal Google group and it went viral / leaked. Similar to the memo written by James Demore"
2023-05-07 22:20:06,great thread wrt the  Google employee memo.
2023-05-07 22:23:00,Koi tldr?
2023-05-07 22:25:09,"Hey, who can I dm for a referral at dashtoon? It is for a friend"
2023-05-07 22:25:42,Ask admin literally.
2023-05-07 22:25:43,[PHONE REMOVED]
2023-05-07 22:25:58,Thanks
2023-05-07 22:26:17,Yes please DM me :D
2023-05-07 22:26:28,I love referrals for dashtoon specifically :P
2023-05-07 22:36:42,Personally am aligned to [PHONE REMOVED] ‘s #3rd point above.
2023-05-07 22:58:06,TLDR. worth reading the whole thread but pasting some main points below:
2023-05-07 22:58:48,⬆️ done
2023-05-07 23:06:05,What's the current hypothesis on how OpenAI is able to offer such a low price?
2023-05-07 23:14:00,"I think if we dive a little deeper, openai has been making lots of optimisation on the inference side. Hence the cost is continuously coming down. Lilian weng (applied scientist at openai) wrote this -https://lilianweng.github.io/posts/2023-01-10-inference-optimization/"
2023-05-07 23:15:06,"Hi everyone, I am experimenting on the prompts with gpt3.5 api"
2023-05-07 23:15:12,Current result -
2023-05-07 23:20:46,Is this the answer everytime? Have you tried it multiple times?
2023-05-07 23:22:06,https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html?highlight=don%27t%20know#the-stuff-chain
2023-05-07 23:30:17,optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API.
2023-05-07 23:33:03,The part “As an AI language model” is consistent in all the messages which model doesn’t know
2023-05-07 23:33:10,Let me go through this
2023-05-07 23:48:16,"have you tried few-shot prompting? Prime with examples where you respond with ""I am still learning, I'll get back to you on this"""
2023-05-07 23:50:40,Not yet. Didn’t try it because I am running the bot which is solving multiple cases and for those cases prompt is already big.
2023-05-08 00:00:12,"This group is cutting edge, folks! Can be monetised. 😄"
2023-05-08 00:08:50,Absolutely! These daily chat summaries can be signal amidst all the noise around AI for a lot of people as newsletter/podcasts(maybe with weekly frequency reviewed by mods).
2023-05-08 06:59:03,"hard to speculate anything from losses they are a creation of accounting often sv companies have large stock comp. based losses. i work with llms in production mostly using react and other simpler prompting openai is the most consistent llm i can be confident around, cohere is the second most"
2023-05-08 10:46:46,"Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?"
2023-05-08 10:48:29,[PHONE REMOVED]
2023-05-08 11:06:47,Thanks bhai. Will DM Nirant and Somu
2023-05-08 11:09:35,Rohan from Inkers.
2023-05-08 12:00:39,Might schedule a meet with an executive at Midjourney soon.
2023-05-08 12:02:00,are they profitable?
2023-05-08 12:04:32,What is their plan for the long run? The discord model cannot be that sustainable.
2023-05-08 12:05:46,"hey admins, is there a way we can do beta launches in the group. Interestingly the first ever demo of the product was presented at deep hackathon. Thanks for adding [PHONE REMOVED] in the first place. At a slightly more mature and functional stage now."
2023-05-08 12:19:50,Glad to hear that you've a more mature product! 🫶🏻
2023-05-08 12:28:33,I believe [PHONE REMOVED] literally did his PhD on this :)
2023-05-08 12:29:11,"He was our first pick as well, unfortunately he is occupied on the meetup dates"
2023-05-08 12:32:11,some users have access to the web app.
2023-05-08 12:32:26,Sure. Thanks Nirant. Will DM you with more context mid week.
2023-05-08 12:33:03,David's tweet https://twitter.com/DavidSHolz/status/1655122525616242690?t=aM1R-2Vk5gvrOIScY4ipWg&s=19
2023-05-08 12:35:01,Wouldn’t the investor group be a good fit for this
2023-05-08 12:35:23,API. When are they launching official API for their products.
2023-05-08 12:41:04,"Sorry folks, too many things this month."
2023-05-08 12:42:31,[PHONE REMOVED]
2023-05-08 12:43:56,Thanks Sudarshan.. Happy to share with the community!
2023-05-08 12:46:38,"He's published in ICCV, CVPR, consults a good number of startups, and has worked with IIIT-H. Much more too, but this is what I remember from our small chat at the Nvidia meetup :)"
2023-05-08 12:47:41,when API
2023-05-08 13:15:15,How did they approach their hiring? 
2023-05-08 14:25:59,I guess it would just be the leap motion team na?
2023-05-08 14:30:40,https://twitter.com/bindureddy/status/1655253111659978752?s=46
2023-05-08 15:39:36,"Hi All,"
2023-05-08 15:50:59,Ping [PHONE REMOVED]
2023-05-08 15:57:31,I am able to fix this. I made few changes in prompt. I have mentioned about the type of message it can send & have specifically mentioned avoid saying the line.
2023-05-08 15:59:48,you can email Atty from OpenAI / he is pretty helpful
2023-05-08 16:00:02,Facing the same issue.
2023-05-08 16:02:18,Go live with GPT3.5 and show traction worked really well for us
2023-05-08 16:08:43,I have access to both 3.5 turbo and 4.
2023-05-08 16:10:45,"GPT4 is slower, more expensive and almost 2-5x better for any reasoning e.g. QA or agent behaviour e.g. AutoGPT kinda things."
2023-05-08 16:13:35,"no, we applied two weeks ago and haven't gotten gpt4 yet"
2023-05-08 16:28:29,Yes 100%. 
2023-05-08 16:45:10,Any good material on how folks are monetizing the GPT plugins?
2023-05-08 16:55:39,"There is another way to solve this, I am able to add context block for starting any communication with the llm model one of the fields of the context block is currentDateTime: <ISO string format> "
2023-05-08 17:05:24,roughly equivalent to their api pricing plan because ultimately it calls their api?
2023-05-08 17:06:11,Let me try this out. Have not thought about it yet
2023-05-08 17:07:28,Has anyone even monetized?
2023-05-08 17:07:34,"Hey folks, "
2023-05-08 17:09:16,Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization
2023-05-08 17:27:46,"I paid using an axis bank corporate debit card and it worked, lol."
2023-05-08 17:32:14,"Hello,"
2023-05-08 17:35:09,"For short term, you can do stuff like custom search in slack, notion etc"
2023-05-08 17:37:38,Facing same problem. Unable to pay for past 2 months 😅😅
2023-05-08 17:42:10,we use USA issued cards and those work fine
2023-05-08 17:49:44,And manual payment goes through smoothly
2023-05-08 19:05:11,https://archive.is/elhiG
2023-05-08 19:09:15,Hello 
2023-05-08 19:15:46,"Hi, any suggestions for Natural Language to Code. Something similar to OpenAI Codex."
2023-05-08 19:16:32,What are you looking for? I've an ACL SemEval paper: https://aclanthology.org/2020.semeval-1.119/
2023-05-08 19:18:05,"Do you want something which can follow instruction? If yes, this is the best FOSS I've seen so far: https://huggingface.co/bigcode/starcoder "
2023-05-08 19:19:56,"I am currently doing research mostly on MultiModel (Speech, Language, video) systems if you like to collaborate DM me"
2023-05-08 19:20:26,Thanks.
2023-05-08 19:27:42,"Not an academic  — the ACL Paper was to help an intern get into academia, done mostly as a hobby :)"
2023-05-08 19:28:17,Ohh Fine !
2023-05-08 19:28:55,Please anyone is interested let me know
2023-05-08 19:33:35,Does KDD count? I know my friend who had worked on a paper at glance and it got published
2023-05-08 19:33:42,He can probably help you
2023-05-08 19:34:17,Ohh yaa KDD will also count in
2023-05-08 19:36:22,What's up? I've published in ACL in low parameter adptation - https://arxiv.org/abs/2107.09622
2023-05-08 19:36:56,Ohh Jawahar's student 🙏
2023-05-08 19:37:20,Haha yeap...
2023-05-08 19:38:15,your too jawahar sir student
2023-05-08 21:44:09,What's the solution for storing and querying embeddings in/from a MySQL db?
2023-05-08 23:21:05,np.array(SELECT * FROM db) 😂🫶
2023-05-09 01:21:17,https://twitter.com/jxnlco/status/1655368751657676800?t=5t9flIlOSbLwO-N2fhza5A&s=19
2023-05-09 01:46:00,facing massive timeout issues with /chat/completions/gpt-3.5-turbo. Status page is all green. Anyone been facing this lately?
2023-05-09 02:04:50,yes happens a bunch of times and can see some 50-60 timeouts yesterday. you can put retries in place if not already. 95% of 50 timeouts succeeded on retry.
2023-05-09 02:09:04,anyone knows what's the fastest open source llm right now?
2023-05-09 03:16:11,https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
2023-05-09 06:25:59,https://twitter.com/kevinafischer/status/1655734333720633348?s=48&t=ACPHEfclkXmi9Z92RTsh9g
2023-05-09 07:40:54,It shines when doing eda kind of work...
2023-05-09 08:09:45,"Oooof. Socher, the OG Prompter, woke up and chose violence against academic peer review today"
2023-05-09 08:20:41,"If somebody has to build a chat, summarize and index type of application today, would yo recommend:"
2023-05-09 08:21:37,"Langchain or Llama Index — retain the flexibility to change both the underlying models, and how you interact with them with powerful abstractions"
2023-05-09 08:22:44,What is cohere and steamship's play?
2023-05-09 08:26:42,"OpenAI apis , + Langchain to start"
2023-05-09 09:32:27,I am assuming doesn’t work for all hf models? Since they need to have an endpoint.
2023-05-09 09:39:52,Is there a SAM but for audio?
2023-05-09 09:48:51,You can convert it from speech to text and try for text
2023-05-09 09:49:38,For music?.. Something that strip away all instrumental + vocal layers
2023-05-09 09:50:24,Yes I think there are
2023-05-09 09:53:17,Open assistant
2023-05-09 09:53:29,Are you looking for a source separation?
2023-05-09 09:56:19,You can try spleeter
2023-05-09 10:00:09,"I am part of OA team (safety and ML), I can help if you're interested in opensource LLMs."
2023-05-09 10:29:04,What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.
2023-05-09 10:29:46,Embed → Nearest Neighbor → Return answer
2023-05-09 10:36:21,Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries. 
2023-05-09 10:36:57,Will try this
2023-05-09 10:41:17,"I'm guessing the dataset is fairly large, hence the question. Perhaps look into https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec"
2023-05-09 10:44:24,Why is NN slow for embedding? I can do about a million comparisons in less than a second on 2vCPU and more on a modern M1/M2 Pro machine
2023-05-09 10:46:58,"Women in AI, Bengaluru meetup: "
2023-05-09 10:50:33,You can try FAISS
2023-05-09 10:51:20,Alternatively you can do PCA or similar methods for dimensionality reduction. This can improve speed
2023-05-09 10:55:56,"This approach, along with feeding the results into a reader model to refine the answer might work even better."
2023-05-09 10:56:38,For hindi texts
2023-05-09 11:01:23,At the cost of accuracy
2023-05-09 11:02:01,What are the techniques or preprocessing steps to reduce prompt with context tokens while sending it OpenAI without affecting outcome?
2023-05-09 11:05:41,Removing stop words is a low hanging fruit
2023-05-09 11:06:04,I'm sure people here can give you many other techniques to try
2023-05-09 11:09:21,I remember someone shared about compression. Thanks for reminding me about it. My data mostly have English chars only.
2023-05-09 11:48:00,what were the results using traditional keyword/BM-25 approach? what is not working with the traditional approach to apply the semantic search result techniques?
2023-05-09 11:56:42,"If the use case is very defined, consider fine-tuning"
2023-05-09 11:58:04,Not yet. It is still in the experimental phase.
2023-05-09 13:36:54,how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key
2023-05-09 13:40:49,"Use the product, revoke every Wednesday 😅"
2023-05-09 13:41:02,Write logs from each service and review them in sumologic or coralogix for attribution.
2023-05-09 13:41:41,"but these services are not under my control. I'm talking about external products which have a ""enter OpenAI API key"" flow"
2023-05-09 13:44:01,Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.
2023-05-09 13:44:24,Little tedious 😅
2023-05-09 13:45:14,that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?
2023-05-09 13:45:23,Bottom line is to agree to a central wrapper call. Managed in one place.
2023-05-09 13:45:56,"Stop providing the keys, that's the point of creating a wrapper so that you control the key."
2023-05-09 13:46:06,Basically a proxy server is what he’s saying. Should be about 20 lines of fastapi
2023-05-09 13:46:40,Precisely. Didn't want to use 'proxy server' to avoid confusion.
2023-05-09 13:47:28,Wait but the openai endpoint url should be editable on the service/product you give the api key to
2023-05-09 13:47:54,[PHONE REMOVED] is a CMU grad and Professional ML Engineer via Meta
2023-05-09 13:48:08,Talking about things like:
2023-05-09 13:48:43,Can you share the ss of the place where you enter the api key
2023-05-09 13:50:42,"they seem to be storing the key in plain text, which is kinda crazy in itself"
2023-05-09 13:51:24,[PHONE REMOVED] what are your thoughts about this?
2023-05-09 13:52:39,Yeah I dont think the proxy / wrapper will work here
2023-05-09 13:57:26,"thanks, I'd forgotten about this. OpenAI is so miserably bad a devx"
2023-05-09 13:57:43,they should have like monthly views etc.
2023-05-09 14:20:30,"My bad, I assumed you were talking about service hosted within a company and you are trying to manage all those."
2023-05-09 14:35:35,The standard MS response is to use OpenAI through Azure
2023-05-09 14:40:21,https://github.com/eugeneyan/open-llms
2023-05-09 15:42:22,Has anyone faced the following issue while using gpt-4 model?: https://github.com/openai/openai-cookbook/issues/405
2023-05-09 17:05:18,It rarely works at scale. Keeps failing after $100/day
2023-05-09 17:05:50,Try this I suppose
2023-05-09 17:05:55,Are you using Azure? I’ve faced this same issue using Azure APIs
2023-05-09 17:08:59,"No, im calling the APIs directly from my local machine"
2023-05-09 17:09:09,how did you fix it?
2023-05-09 17:09:41,https://github.com/openai/tiktoken/blob/main/tiktoken/model.py
2023-05-09 17:10:01,This does a match with the model name while calling the APIs 
2023-05-09 17:10:41,I’m doing per documentation for calling gpt-4
2023-05-09 17:11:04,"Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?"
2023-05-09 17:11:15,I solved it by keeping deployment id of Azure same as model name 
2023-05-09 17:11:32,interesting
2023-05-09 17:14:07,Custom. Mostly experiment with  the prompt using the chat interface in playground and then use that prompt. Ofcourse not scalable if you need to check with vector embeddings etc. In that case tune the prompt on a small dataset and benchmark on a larger set
2023-05-09 17:14:59,"documentation suggests doing something like ```encoding = tiktoken.encoding_for_model(“gpt-4”)``` , which is exactly what Im doing, but it’s throwing ```KeyError: ‘Could not automatically map gpt-3 to a tokenizer. Please use ‘ tiktok.get_encoding’ to explicitly get the tokeniser you expect.’```"
2023-05-09 17:15:19,From the screenshot of the bug you’ve raised it’s the model.py file which is throwing the exception 
2023-05-09 17:16:01,Any idea which encodinf gpt-4 uses?
2023-05-09 17:16:32,"gpt-4"": ""cl100k_base"","
2023-05-09 17:16:41,"nice, thanks 👍🏼"
2023-05-09 17:22:20,Changing it to tiktoken.get_encoding(“cl100k_base”) fixed the error
2023-05-09 17:23:51,It’s funny that the error message suggests “try ```tiktok.get_encoding()```” instead of ```“tiktoken.get_encoding()”``` 
2023-05-09 17:24:18,"Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_."
2023-05-09 17:24:28,Could be relevant to some folks here!
2023-05-09 17:30:25,"ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right? "
2023-05-09 17:31:18,edit: *is imported in ```model.py``` (not ```application.py```)
2023-05-09 17:33:22,"The ```encoding``` variable is being set in ```num_tokens()``` method in _Ask_ section, incase anyone is looking into the code."
2023-05-09 17:46:04,"AH OKAY, updating ```tiktoken``` to ```version 0.4.0``` solved the issue. It was just released 2 days ago"
2023-05-09 18:44:24,Actually a combination - there are certain things where using things out of the box helps -purely depends on the use-case. 
2023-05-09 19:00:18,does anyone know of a contact/ email of someone in Warpspeed GenAI hackathon organising team?
2023-05-09 19:02:18,or if there is any open position in any team in case someone drops out
2023-05-09 19:08:31,What's up
2023-05-09 19:09:19,Better to mask ids while sharing on public platforms unless they are dummy IDs. 😅
2023-05-09 19:10:09,"Its a public id na, the key is emerphal anyway"
2023-05-09 19:11:07,"Hey Manjot, I have one question regarding the Warpspeed hackathon."
2023-05-09 19:37:45,I can't comment about OpenAI but if I had designed their rate limiter and someone use this org id or user id for their brute force attack then it would have certainly banned that account tagging it as compromised account.
2023-05-09 19:52:34,"We built an internal tool when the one mentioned in this group for tracking OpenAI bills had some bugs, while charging $10 dollars per month 🥲 and we wanted some more features. We recently made the initial version available for everyone at https://puddl.io/ . User level data is next on this tiny tool's roadmap. Check it out and let me know. 🫡"
2023-05-09 19:59:07,hey guys!
2023-05-09 20:01:20,The LLM can perform intent recognition and entity extraction fairly well and respond/route accordingly.
2023-05-09 20:02:34,"A lot of them yes, but not all invites are out yet"
2023-05-09 20:03:48,"Got it, thanks for the update. 🤞🏼in that case"
2023-05-09 20:04:25,Have you tried this from Llama Index 
2023-05-09 20:04:47,Have checked this link and spoken to Ruthvik — I don't think this counts as self promotion and hence leaving it here. Sharing the decision here before someone forwards this to me 😅
2023-05-09 20:05:17,"One cheap way to write a script similar to this https://community.openai.com/t/how-to-track-individual-usage/15935/6 , deploy in some hourly cron push data to Airtable/DB/Excel and create graphs (excel graphs would be easy)"
2023-05-09 20:06:14,Tried RasaGPT?
2023-05-09 20:08:23,"I run a small service, pushing events from that API key to Simple Analytics. All successful, failed events go there with the key in metadata 😅"
2023-05-09 20:12:12,checking this.
2023-05-09 20:20:32,"I have also came across similar problem, one solution is to build a simple classifier and reroute prompts based on it's output."
2023-05-09 20:22:22,"In my case I had a specific list of queries that I wanted bot to not answer using context, I kept them in a separate vector db and comparing incoming prompts with that list can also act as a classifier."
2023-05-09 20:23:26,not sure if a classifier will work
2023-05-09 20:25:37,"Yeh, solution for this depends very much of the distribution of prompts you're getting."
2023-05-09 20:29:46,https://jam.dev/
2023-05-09 20:32:55,cc [PHONE REMOVED] [PHONE REMOVED] I'm sure you've seen this since you're building in the adjacent space. Thought this might be interesting to you
2023-05-09 20:36:26,who ever is building this
2023-05-09 21:07:58,anyone tried GPT4All and Atlas? Just met the founder and they're doing something very interesting. Runs on CPUs / open source / visualization on top of embeddings 
2023-05-09 21:18:18,Wonder if openai will tolerate the use of GPT4 In their name. Likely no.
2023-05-09 21:25:50,"Thread about StarCoder, seems like there’s a correlation between coding and reasoning capability in a language model? "
2023-05-09 22:29:06,"One thing that worked well for me was to play with temp and p to get the system to output on consistent output  format. Takes away some richness (with low temp) but if you give enough stakes points (think of using CoT, or other reasoning with intermediate steps etc) you can get enough richness."
2023-05-09 22:29:51,"But again, depends on application. The above was more for a reasoning sort of application."
2023-05-09 22:34:43,"i built this library to help work with llms it has lots of examples, supports multiple llms openai, cohere, etc. has sensible defaults for parameters etc and zero dependencies. designed to be easy and quick to use https://github.com/dosco/minds"
2023-05-09 22:35:25,"Instead of using the bert model directly to output 0 or 1, use it as a vectoriser to extract embeddings, and then follow what Nirant suggested. Inference won't be slower as the search space increases, and this will likely perform better if you have trained your bert well"
2023-05-09 22:35:41,We use Mrkl agent with custom built tools. Works well for now. It is WIP
2023-05-09 22:36:19,Was reading this - https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
2023-05-09 23:11:24,https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once.
2023-05-10 01:10:21,Does a great job recognizing Chunky Pandey too. :)
2023-05-10 01:15:05,"Has great conceptual memory: Works for smiling woman with red hair, dog - finds a celeb with golden retriever hair 😆"
2023-05-10 01:16:32,Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well
2023-05-10 01:17:46,Was going to index my iCloud library. Will share results on how it went.
2023-05-10 01:18:10,Hmm. Yes. You can build your own Google Photos now. With power booster search --- better than anything Google can offer today
2023-05-10 01:18:15,https://imagebind.metademolab.com/demo
2023-05-10 01:18:34,google photos does face recognition
2023-05-10 01:19:27,"So do these embeddings in a way, NN to a person is dead easy to find. It finds Jet Li by name -- that's face recognition already :)"
2023-05-10 01:20:14,How??
2023-05-10 01:21:08,"Check the Google Colab notebook I shared, that demos this"
2023-05-10 01:22:09,google photos does one-shot face recognition from custom labels
2023-05-10 01:23:16,E.g. this notebook won't find Nirant :3
2023-05-10 01:23:28,"If it has some concept of celeb faces, then the embeddings would have atleast some one-shot recognition capabilities"
2023-05-10 01:23:49,"If it has one photo of me, easy to do a nearest neighbor on that and expand from there"
2023-05-10 01:48:00,Can replace the whole foley part of film making if executed on a huge dataset
2023-05-10 01:59:39,This looks more the result of shallow feature matching.
2023-05-10 02:01:34,https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing
2023-05-10 02:02:44,Jawahar sir's former Student is the first author
2023-05-10 02:03:00,Is that an ad in the bottom? Even that ad has Nirant 😵‍💫
2023-05-10 02:03:56,Anyone worked on OCR? Need some quick pointers
2023-05-10 02:04:09,try face recognition + aligned cropping (use keypoints to align faces)
2023-05-10 02:05:32,"It is also very likely that the performance would vary a lot for different race, gender, age, etc. "
2023-05-10 02:06:59,I've been wanting a tool which can recommend soundtrack for shorts/reels. Looks like this might almost be there.
2023-05-10 02:11:46,yeah that ad probably needs a crop :D
2023-05-10 02:12:32,you mean detection + alignment? https://github.com/1adrianb/face-alignment
2023-05-10 02:13:00,Yeah
2023-05-10 02:16:36,I had a similar project with [PHONE REMOVED] way back to play soundtracks based on mood. this could do it from facial expressions / heartbeat sounds / tone of my voice etc. 😵
2023-05-10 02:17:20,"5 landmark points are usually enough though, you can check - https://github.com/ZhaoJ9014/face.evoLVe"
2023-05-10 02:21:22,First and last both IIITH folks :)
2023-05-10 02:21:34,Yes
2023-05-10 03:30:56,"thanks, pinging you in DM"
2023-05-10 03:50:42,But this is a great way to find doppelgangers
2023-05-10 04:56:40,https://openai.com/research/language-models-can-explain-neurons-in-language-models
2023-05-10 06:40:26,https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM’s on audio files - now you can perform QA on your audio files directly.
2023-05-10 07:41:48,"As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?"
2023-05-10 07:58:58,What’s the dataset of images? One of them is my friend.
2023-05-10 07:59:25,I don’t think he’s in this group
2023-05-10 08:49:43,Ugh I thought it was something new on modelling side
2023-05-10 08:55:45,"Same, clever marketing, repackage and give it an acronym 😂"
2023-05-10 09:19:52,This is retrieving the audio from a database?
2023-05-10 09:21:55,"The database has 3 files in the demo, but yes, that is the intent."
2023-05-10 09:36:02,Would perhaps be better to ask an outline of your questions? 
2023-05-10 10:46:58,Hello! 
2023-05-10 10:47:14,"All,"
2023-05-10 10:51:40,https://twitter.com/generatorman_ai/status/1655941986627772419
2023-05-10 10:58:53,https://twitter.com/OpenMMLab/status/1656127026687000578?t=bwtsiMeA6SNW2hWGHIo8Ww&s=19
2023-05-10 11:00:54,"doston, link dump na karo, ek line likh do what that link is about 😅"
2023-05-10 11:03:16,Lots of claims in this post - what do you guys think?
2023-05-10 11:11:14,"65B model, calling a prompt a ""constitution"", worse performance than Vicuna — marketing team at IBM should be rewarded for doing such technical work"
2023-05-10 11:13:02,More underwhelming than Watson actually 😅
2023-05-10 11:16:38,"But what about the practicality of the approach? Seems promising, much better than distilling, which increases hallucinations"
2023-05-10 11:18:31,https://twitter.com/_akhaliq/status/1656144222204903426?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-05-10 11:19:23,For ex.as per the paper’s method 
2023-05-10 11:32:11,This is  similar to jerry liu’s new blogpost? [PHONE REMOVED]
2023-05-10 11:36:09,Is that one using LLM for retrieval ?
2023-05-10 11:36:56,From what I’ve understood of Jerry’s post That was more like passing entire doc/doc summary to choose documents using LLM
2023-05-10 11:37:21,Reminds me of triplet generation from the bygones era. 
2023-05-10 11:37:34,Type karne do bhai log 🤣
2023-05-10 11:44:20,Analogy:
2023-05-10 11:45:09,"That's a terribly written on-the-fly blog on a paper which I read 20 minutes ago for the first time, but can answer more questions on DM 😅"
2023-05-10 11:47:32,Still a good overall explanation 🙌🏻🙌🏻 thanks [PHONE REMOVED]
2023-05-10 12:41:29,"Yes, in fact that Y-axes is likely to be logarithmic, not linear"
2023-05-10 13:04:29,emergent capabilities in ImageBind:
2023-05-10 13:41:28,If someone wants to try ImageBind: colab.research.google.com/drive/1_erdut6xnikv5f1qnbutoik4us-w3pxm?authuser=0#scrollto=zjl-nv30rngb
2023-05-10 13:46:47,PSA for Technical Folks: Fifthelephant — India's best ML Conference has the Call for Talks open: 
2023-05-10 13:54:56,https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing
2023-05-10 14:50:55,"🚀Announcing the May Generative AI Meetup with more focus on Visuals - Images, Videos, Games  🎮🎨📽️"
2023-05-10 15:06:58,Potential game changer 
2023-05-10 15:28:57,Just an FYI it is CC BY-NC not truly open source.
2023-05-10 15:57:27,Dude the third photo is of a friends 😅
2023-05-10 16:46:34,2nd photo looks freakishly like my IITD electronics prof. 🙈 Really hoping it’s not him
2023-05-10 17:19:43,Glad to learn that even my face isn't unique friends
2023-05-10 17:38:40,Fun use of diffusion - https://youtu.be/KrjL_TSOFrI
2023-05-10 19:04:43,https://www.zdziarski.com/blog/?p=12001
2023-05-10 20:03:15,"What he wrote makes quite a lot of sense, and OpenAI's yesterday's research on understanding _which neurons_ is probably an answer in that direction"
2023-05-10 20:33:26,"Which are some of the good Robotics, AI/ML newsletters I can follow?"
2023-05-10 21:01:21,This message was answered just couple of days back. I'll copy paste:
2023-05-10 21:02:03,Thankyou!
2023-05-10 21:30:04,"I have generated embedding vectors using np.array, and the file size is roughly 230mb (saved as a csv)."
2023-05-10 21:30:52,npy files?
2023-05-10 21:38:10,saved as csv
2023-05-10 21:41:35,"yes, npy files are much faster"
2023-05-10 21:41:46,https://runwayml.com/hosted-models/
2023-05-10 21:44:36,https://mmappickle.readthedocs.io/en/latest/
2023-05-10 21:45:29,Nothing is going to be faster than mmap. I think pickle supports storing objects as mmaps too.
2023-05-10 21:45:54,This is likely just what you need
2023-05-10 21:47:15,And you're storing the object itself. Very very unlikely to lose any accuracy.
2023-05-10 21:48:24,"If mmap doesn't work for you, then just use pickle (slower, but faster than anything else)."
2023-05-10 21:49:12,This is lovely
2023-05-10 21:50:13,But you could still lose accuracy/encounter changed embeddings even if you pickle an object. Ensure you recreate your environment exactly with venv or poetry.
2023-05-10 21:50:23,Do you have to use locks to handle concurrent writes though btw?
2023-05-10 21:51:07,Pickling is lossy? TIL
2023-05-10 21:52:16,"yeah i think it's been there for a long time. i remember seeing something like this back when Runway had a few GAN models only (for generating shoes, cars etc )"
2023-05-10 21:52:52,"Yes, depends on versions in your env. You can get by for a while, usually, but there are no guarantees in the long run."
2023-05-10 21:53:41,Okay. I used to think its comprehensive Ser/Deser
2023-05-10 21:54:04,"Depends on how you plan to write. If you're code guarantees it, you don't need locks, otherwise you do."
2023-05-10 21:55:19,"Far from it. Pickling itself might break with version changes, forget about guaranteeing losslessness"
2023-05-10 22:00:01,"That's correct if you're only storing native python objects. He's interested in storing numpy arrays. Which may still be fine. As I said, you can get by for a while, but no guarantees in the long run."
2023-05-10 22:00:21,The ling-run doing the heavy lifting 😂
2023-05-10 22:00:32,*long-run
2023-05-10 22:23:35,"Thanks, ill look into this"
2023-05-10 22:27:04,"Hi All, I'm looking to generate images for words that can illustrate meaning of the word . To be used by school children. Tried by various prompts to illustrate using stable diffusion. Example : illustrate the word 'abhor'. "
2023-05-10 22:34:17,https://www.assemblyai.com/blog/lemur-early-access/
2023-05-10 22:35:27,We've already roasted this enough today. Please resist the temptation - note for myself
2023-05-10 22:35:30,You are a day late 🤣
2023-05-10 22:36:22,🙈🙈 missed today’s chatter
2023-05-10 22:42:46,"ugh, in that case why not just us numpy native mmap that guarantees backwards compat?"
2023-05-10 22:44:44,"I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat"
2023-05-10 22:48:02,"On a related note, [PHONE REMOVED] has built out an OpenAI embeddings API cost calculator: https://llmtown.com/e/openai-cost-calculator. Thought this might be interesting to folks here"
2023-05-10 22:54:13,Not sure where it mentions backward compatibility. It probably does it now. For small usecases it is perfectly fine.
2023-05-10 22:54:57,I don't like that flush() operation though. I have to call it every single time I update something in the array!
2023-05-10 22:55:16,Primary reason why I don't use npy
2023-05-10 22:55:35,Awesome 👍🏻
2023-05-10 22:56:10,"As I said, this is perfectly fine for small usecases."
2023-05-10 23:00:14,What were you using to store the embeddings?
2023-05-10 23:01:59,"pickle, but my backwards compat issue was more of a data format upgrade not a file format upgrade"
2023-05-10 23:03:32,"Ah ok, so you were storing them in a class you created or provided by a package or something?"
2023-05-10 23:05:04,"As in, curious about why the embeddings were not recoverable from the pickle."
2023-05-10 23:08:20,"changed the preprocessing a bunch of times, chunking strategies, X -> text conversion, added cleaning steps to transcripts, changed transcription engines, etc."
2023-05-10 23:16:01,"Oh acha, there's no fighting against this. Went with Weaviate modules from the start to avoid this cost."
2023-05-10 23:17:29,text2vec-bert?
2023-05-10 23:20:21,"With the I/O event, I think Bard is now almost generally available. I applied through the waitlist and got access within minutes."
2023-05-10 23:21:29,They haven't released it for workspace yet
2023-05-10 23:21:31,Which is surprising
2023-05-10 23:21:35,Can you point me to where you saw that it is using lossy. This is news to me.
2023-05-10 23:21:38,I would have thought it would begin there
2023-05-10 23:35:00,"Models from sbert.io (sentencebert, they come with Weaviate modules by default)"
2023-05-10 23:36:39,This happened with version upgrade mismatches of tf 1.x (pre tf2 era).
2023-05-10 23:38:36,"We started with saving embeddings in a db, which was obviously bad. Then pickling sometimes led to this. Eventually we put some tests in place. I think GPU arch mismatch also had a role to play, but I may be misremembering that. We just matched everything and put tests in place."
2023-05-10 23:54:18,Microsoft Researcher used GPT4 to solve a simple maze game. Quite clever hints for you to think about how to evoke world building with text based models. 
2023-05-11 00:18:59,Fun fact. I‘ve tried to run similar experiments with chess. And had some mind = blown moments initially.
2023-05-11 00:22:25,But it turned out that as games went on it started suggesting random/illegal moves.
2023-05-11 00:22:51,And all the aha moments came from games that were probably in its training data.
2023-05-11 00:25:51,"Really wanted to try giving it access to a chess engine so it could evaluate moves, before making them. That’ll be the equivalent of giving it access to the code interpreter like the Microsoft researcher talks about in this blog."
2023-05-11 00:26:29,It’s on my weekend side projects list for now. Sigh… so much to do. Such little time…
2023-05-11 00:33:35,Render.com added pgvector to their PostgreSQL databases. 
2023-05-11 00:59:15,https://twitter.com/scottbelsky/status/1656365796761694218?t=c9Gvl0xFQKA3Vn4nPnEtbA&s=08
2023-05-11 09:42:51,its sneaky / I got an email asking for a commitment of $2500/month for 6 months to be part of it. LOL
2023-05-11 09:45:23,"Ohh damn. That's _not startups_, that's just a VC funded Series B co"
2023-05-11 09:46:39,yeah / I get that they are good but this is very bad / if you had this commitment then be upfront before you ask companies to fill a long form to apply
2023-05-11 09:47:33,If you pay upfront annual
2023-05-11 09:48:15,Ah others already pointed that
2023-05-11 09:50:47,It’s unclear what does small and big mean. I think the disparity is small. I haven’t found any research on scaling laws of fine-tuning but know from experiments that for a narrow task the gap between small and big is not much. Palm 2 small beats Palm 540B. So it’s not a pure function of size. 
2023-05-11 09:52:59,one point to consider is task accuracy is evaluated using discontinuous non-linear metrics like exact match
2023-05-11 09:53:46,"About PaLM2, I'm impressed by the reasoning ability of it as it has shown better performance with reasoning tasks than GPT-4"
2023-05-11 09:55:50,this is total waste. 😂
2023-05-11 09:56:39,Couple of months? 😳
2023-05-11 09:57:59,Does anybody have access to ChatGPT plugins API?
2023-05-11 09:58:20,What do you mean by Plugins API?
2023-05-11 09:58:35,"Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc"
2023-05-11 10:00:25,"OpenAI Evals, LM-Harness for HF models, and the extremely entertaining, useful and wrong ELO rating approach"
2023-05-11 10:01:33,This is precisely what I wanted  to acquaint myself with well known benchmarks atleast. ELO doesnt seem to be a good measure of llm performance
2023-05-11 10:01:35,Thanks
2023-05-11 10:02:02,This looks good thank you
2023-05-11 10:02:51,https://arxiv.org/pdf/2303.17564.pdf
2023-05-11 10:25:54,Checkout Big bench
2023-05-11 10:27:48,"Big Bench is a dataset curated by Google to make Google models look good, OpenAI Evals makes GPT4 looks good, only LM-Harness is real — it makes everyone look great! 🤣"
2023-05-11 10:29:29,Only benchmarking that truly matters is community benchmarking
2023-05-11 10:35:38,Controversial Take: Benchmarks don't matter when your product is great. Benchmarks are for plebs. 
2023-05-11 10:45:10,"I think the fundamental difference is openai is doing all it can to break gpt-4, while google trying to show they are as good at chatgpt so use us"
2023-05-11 10:53:39,what is the source for this? What is the Elo based on?
2023-05-11 10:54:46,Curious - why don't Elo ratings work? Because this is not a true head-to-head comparison?
2023-05-11 10:55:03,https://lmsys.org/blog/2023-05-10-leaderboard/?s=09
2023-05-11 12:09:59,"Sequoia APAC is doing a curated *virtual* demo day called Bird of Feather on Generative AI next week. Has 15 curated demos from the wider web, not just their folio. "
2023-05-11 12:14:40,superb thanks for the callout. Missed this ealrier
2023-05-11 12:20:07,https://arxiv.org/pdf/2305.05576.pdf
2023-05-11 12:20:17,+1. Love what [PHONE REMOVED] is building.
2023-05-11 12:20:51,What are some of the most useful resources for exploring AutoGPT and creating agents?
2023-05-11 12:26:06,anyone knows here which model powers Sage bot on Poe?
2023-05-11 12:26:11,https://python.langchain.com/en/latest/use_cases/autonomous_agents/autogpt.html
2023-05-11 12:26:21,Claude+ from Anthropic?
2023-05-11 12:28:20,don't think so since Poe has a seperate bot for Claude+ and that's paid
2023-05-11 12:30:01,"oh they have added ""powered by 3.5"" now. wasn't there earlier."
2023-05-11 12:30:30,why two bots for same model tho? poe.com/chatgpt is also by 3.5 turbo
2023-05-11 12:31:18,but good to know it's the same model 😅
2023-05-11 12:33:43,thank you
2023-05-11 12:38:39,"this to me feels like a NFT-like scam, only if they ICO'd with these kind of models lol. Creating own LLM powered by gpt-3.5"
2023-05-11 12:39:13,I’d assume different first “system” message if you’re seeing diff responses from both bots
2023-05-11 12:42:10,"it cud also be different model config. tempertaure,  etc."
2023-05-11 13:03:46,A masterclass on how to PichAI
2023-05-11 13:10:11,If you’re interested in reading paper checkout ReAct paper
2023-05-11 13:12:26,Im trying to make an agent with a finetuned model
2023-05-11 13:13:08,Actually 2-3 agents with separate finetuned models and I want to see them interact 😛
2023-05-11 13:13:19,just as a fun sideproject…will share if I succeed
2023-05-11 13:14:00,How do you tell which one us better at what task though is the key! 😆
2023-05-11 13:15:44,By separate finetuned models I mean not separate llms…for now im just trying to finetune gpt with separate additional informations about a particular subject
2023-05-11 13:19:36,i.e. separate context and instructions using prompt engineering?
2023-05-11 13:22:48,not prompt engineering. Already trained models (im not training them)
2023-05-11 14:53:52,"Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture."
2023-05-11 14:57:05,cc [PHONE REMOVED] is a Llama index contributor. 
2023-05-11 15:06:46,Has anyone encountered this error from OpenAI when embedding? AFAIK it’s not a rate limit 
2023-05-11 15:09:32,"I think this is a common “too many requests, try again later” error when their servers are flooding. I’ve encountered this multiple times but resolves with retry after some time"
2023-05-11 15:11:31,"[PHONE REMOVED] can you help me with this, i.e., your approach?"
2023-05-11 15:16:23,I meant this ^
2023-05-11 16:42:00,Anyone tried the Bhashini APIs?
2023-05-11 16:42:31,"Asr Models yes, not APIs"
2023-05-11 16:44:43,how are the results with asr models? can be used in prod?
2023-05-11 16:45:05,Using in prod. Best models for indic languages
2023-05-11 16:45:48,"Not very good for long files, they use nemo, and doing chunked asr on it is not trivial"
2023-05-11 16:46:00,Timestamps also are an issue
2023-05-11 16:46:08,Do they support streaming??
2023-05-11 16:46:09,But the asr quality is good
2023-05-11 16:46:41,https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/intro.html
2023-05-11 16:46:53,This is what they use
2023-05-11 16:47:29,Seems to support streaming
2023-05-11 16:59:00,https://github.com/opennyai/jugalbandi-api
2023-05-11 17:36:42,https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi
2023-05-11 22:01:29,https://www-moneycontrol-com.cdn.ampproject.org/c/s/www.moneycontrol.com/news/business/startup/foreign-firms-like-google-have-to-invest-in-indian-ai-start-ups-for-access-to-countrys-data-sets-rajeev-chandrasekhar-10569191.html/amp
2023-05-11 22:03:21,"Seems like a smart idea. Thinking in the right direction, at least."
2023-05-11 22:11:31,https://twitter.com/AnthropicAI/status/1656700154190389248?s=20 -  Claude’s 100k tokens context window
2023-05-11 22:37:25,What exactly? [PHONE REMOVED] can you please share a link?
2023-05-11 22:40:21,Hey sure. We are building in co-pilot for Analyst space. Given business context in.csv file you can use it for text 2 SQL translation. Sharing the link in DM.
2023-05-11 22:42:39,[PHONE REMOVED] - Something you experimented with as well right!
2023-05-11 22:43:32,We are in closed beta. Feel free to DM for early access.
2023-05-11 22:44:02,Would love to check it out
2023-05-11 22:48:05,Yes. Quite a few player in this space. About 4-5 just last month in Bangalore. Overall 50+ in this space. Not seen true PMF yet. 
2023-05-12 02:09:06,Will the increase in context window size also increase latency of LLM's in any way?
2023-05-12 02:09:50,"“We fed Claude-Instant The Great Gatsby (72K tokens), except we modified one line to say that Mr. Carraway was ""a software engineer that works on machine learning tooling at Anthropic."" We asked the model to spot what was added - it responded with the right answer in 22 seconds.”"
2023-05-12 02:16:21,The first 2 inputs were the 72K tokens and third input was the query right? In that case why the latency?
2023-05-12 02:17:37,"This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money."
2023-05-12 02:23:32,https://www.mosaicml.com/blog/mpt-7b
2023-05-12 02:23:53,Doesn’t seem so - for the smaller models maybe it is feasible
2023-05-12 02:26:00,It took 22second and the entire infra to generate something that is probably less than 50 tokens from 72K token
2023-05-12 02:27:00,"May be I'm wrong, and may have to read some more documents."
2023-05-12 02:27:29,Whats the time complexity w.r.t. # of params?
2023-05-12 02:28:52,Good question. I don't know how significantly parameters will affect or which model they are using for this demo.
2023-05-12 02:35:04,"I'm going to let someone else figure it out and post a detailed analysis on Twitter. They are not saying the size of the model that will be used for 100k API. If they use 1T model for 100K, it is probably going to be very expensive to accommodate practical use cases. 🤷‍♂️ but then my temporal snapshot of knowledge is changing every day."
2023-05-12 02:54:43,https://bard.google.com
2023-05-12 04:15:21,"They're probably showing top 3 probable beams as a part of their beam search decoding. Afaict, all LLMs do perform this decoding but other providers just give the top most beam"
2023-05-12 05:58:26,User shares preview from Anthropic's 100K tokens context window
2023-05-12 07:30:13,https://twitter.com/lijunnan0409/status/1656821806593101827?s=46 - InstructBLIP - sales force - vision language instruction tuning framework
2023-05-12 08:04:09,"https://twitter.com/harishkgarg/status/1656724079183798273?s=20 - 100k tokens seem to cost ~$1, for 100k tokens with GPT4 it would cost ~$0.5. Multiple hits on a doc from users are still costly with 100k tokens with a compromise on latency probably 🤔"
2023-05-12 09:19:43,Meta comment:
2023-05-12 09:26:29,Need a news ticker for AI advances as a -1 screen replacement.
2023-05-12 09:27:03,future tools will be helpful. https://www.futuretools.io/news
2023-05-12 09:32:14,This is excellent!! 
2023-05-12 09:32:32,Can I try this out?
2023-05-12 09:32:40,This is running on Vicuna13B. Even 7B is giving out awesome results
2023-05-12 09:32:51,Pretty cool
2023-05-12 09:32:57,Looks very interesting. Details available?
2023-05-12 09:32:58,I will send you the link Siddharth - ping me please
2023-05-12 09:42:14,What is the attack here?  Can you give us a brief summary?  That looks impressive!
2023-05-12 09:45:18,Ok. here is the high level view of how it works. 
2023-05-12 09:45:42,Anyone try instruct-blip yet?
2023-05-12 09:45:58,This IS instruct blip
2023-05-12 09:46:13,Oh
2023-05-12 09:46:42,"That’s all we need for multi-modal gpt, right? This is all solved now 😅"
2023-05-12 09:47:37,"The open source projects which will help you all get up to speed are BLIP2, MiniGPT4 and Instruct-BLIP (which came out yesterday)"
2023-05-12 09:48:34,Here is the challenge - this works quite well at 7B params. But with OPT2.7B it hallucinates a lot. Some of us have been trying to make that better over the past 4 days....it's slowly getting there
2023-05-12 10:16:34,Is this on mid journey
2023-05-12 10:25:14,"popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well"
2023-05-12 10:30:21,Don't already many tools exist to automate this?
2023-05-12 10:31:26,Is there any model to perform QA on video?
2023-05-12 10:31:56,Can make one with Instruct BLIP + Vicuna now
2023-05-12 10:32:12,I think we can wait till Monday for someone else to do it 🥲
2023-05-12 10:33:29,I like this approach these days.
2023-05-12 10:33:50,I have it for video.
2023-05-12 10:37:15,Any links to Instruct BLIP?
2023-05-12 10:38:57,https://github.com/salesforce/LAVIS/tree/main/projects/instructblip
2023-05-12 10:49:25,What approach? Is there an intro / write up to it?
2023-05-12 10:49:36,How do you find salient frames?
2023-05-12 10:51:25,Good question. Increasing information density is the first step. short answer: cosine distances. Long answer: a lot of back and forth between LLMs and the ViT
2023-05-12 10:52:09,I was talking about Nirant’s approach of waiting for someone on Twitter to do it and post 😁
2023-05-12 10:57:06,someone took their tweets from last 1 year and dumped them into Anthropic 100k 😂. 
2023-05-12 11:08:03,Damn! Can this be a step forward to do live commentary  for blind people with some obvious latency?
2023-05-12 11:09:34,"Yeah, I don't see why. With the speeds we achieve now (in known envs) this could happen sooner than people realize"
2023-05-12 11:41:10,Exactly!!
2023-05-12 11:48:09,I started a project back in march with the high hopes of this 😅 Had talked to [PHONE REMOVED] about the lofty aims.
2023-05-12 11:49:37,We are trying to get the vicuna7B performance out of OPT2.7B. 
2023-05-12 12:05:04,Google's PaLM 2 model training data is up to Feb 2023!
2023-05-12 12:32:07,I’ll dm for more details
2023-05-12 12:52:50,No
2023-05-12 12:58:04,"Wait, minigpt4 can be used. It's BSD3"
2023-05-12 12:59:34,what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful
2023-05-12 13:11:28,LLaMa I think
2023-05-12 13:12:00,I’ve already heard a couple of people/teams doing so
2023-05-12 13:36:12,There's this company called bemyeyes which used to do this with volunteers- where someone who was visually impaired would open up the app camera and wait for someone on other end to describe it to them- now replaced with GPT- 4
2023-05-12 13:36:13,https://twitter.com/BeMyEyes/status/1635690254689599488?t=qEPFpSZg2Rn8_PJu9CU0Vw&s=19
2023-05-12 13:36:33,Insanely impactful stuff
2023-05-12 13:38:22,Related to previous discussion on vector DBs 
2023-05-12 13:42:50,"right, but the volunteer thing reminded me of a funny incident. Someone once asked me, “so tell me, do you actually sit at the back and solve those tough integration problems and quickly return then when someone asks wolfram alpha?” 😂"
2023-05-12 13:44:16,"gpt integration with bemyeyes is v cool but they had a few limitations and challenges, mostly trained on west-accented tts/stt and not opensource"
2023-05-12 13:51:52,"Yeah I saw the license file, but can we commercially use a model which is built on top of another non commercial model."
2023-05-12 13:56:25,"The Vicuna, MiniGPT4 shows license Apache 2.0 or BSD3. Which makes one belive that we can use this commercially."
2023-05-12 13:58:37,p.s. Vicuna is fine-tunned LLaMa.
2023-05-12 14:45:37,Code? StarCoder
2023-05-12 14:48:36,Salesforce's codegen endpoint is also good alongside StarCoder
2023-05-12 15:00:08,"folks, question: how do you iterate your prompts?"
2023-05-12 15:03:45,Try evaluations.. create a test data set
2023-05-12 15:10:04,can you elaborate?
2023-05-12 15:12:13,Iterate on them a lot. I've used this approach. Give GPT4 the outcome I want and then ask it to tell me what would be the most useful inputs. It's a good starting point
2023-05-12 15:12:25,One layman approach that works for me a number of times :
2023-05-12 15:13:26,"Rohit can't plug since he wrote this, but I can: portkey.ai/blog/decoding-openai-evals/"
2023-05-12 15:17:25,read this too https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids
2023-05-12 15:18:50,Source preprint which the blog discusses:
2023-05-12 15:20:04,How to get Chatgpt to just output the code that I've asked it for instead of any other extra text. I've tried mentioning this multiple times but it ignores those instructions.
2023-05-12 15:21:17,https://github.com/irgolic/AutoPR
2023-05-12 15:24:53,"Thanks, I'll check it out!"
2023-05-12 16:50:08,Folks - what are sources where I can find standard evaluation datasets?
2023-05-12 16:50:35,huggingface.co/docs/datasets
2023-05-12 16:53:02,"yea, was browsing this.. any way to filter LLM specific evaluation datasets?"
2023-05-12 16:54:27,https://huggingface.co/datasets?task_categories=task_categories:text2text-generation&sort=downloads
2023-05-12 16:58:15,thanks so much man!
2023-05-12 17:51:29,Can you explain what happens in iterate?
2023-05-12 17:52:01,This might be useful 
2023-05-12 18:47:02,thanks
2023-05-12 18:47:44,reading material
2023-05-12 18:48:53,Do we have extremely small llms that can work in js in the browser? A link would be nice.
2023-05-12 18:52:11,https://simonwillison.net/2023/Apr/16/web-llm/
2023-05-12 18:52:44,Yes this! Thanks
2023-05-12 20:03:55,Nirant shared this earlier
2023-05-12 20:10:54,"This also struggles to answer meta questions like summarising. Answers precise questions well, in my experience."
2023-05-12 20:23:08,This is a good blog
2023-05-12 20:23:10,https://medium.com/geekculture/prompt-engineering-with-llamaindex-and-openai-gpt-3-f52114aba8b7
2023-05-12 20:24:16,"On a side note, just notized that the first author, Manzil, was a senior from college and his room was right next to mine."
2023-05-12 20:59:45,So you're the first-adjacent author of this paper? 😀
2023-05-12 21:00:00,https://twitter.com/AiBreakfast/status/1656881667116613636 Could anyone tell me how computationally intensive is this technology?
2023-05-12 21:09:34,Or can we say he’s the literal ‘Approximate Nearest Neighbour’ 😁😁
2023-05-12 22:18:08,Discovered chatpdf.com early. 
2023-05-12 22:19:53,Have been a avid user of chatgpt directly
2023-05-12 22:20:22,Will call it 5/5. Especially gpt4.
2023-05-12 22:34:45,I have heard good things about the new feature they have. 
2023-05-13 00:29:54,Someone created an architectural overview of Langchain. It is useful to understand it's concepts.
2023-05-13 04:05:03,Full Stack DL released their LLM Bootcamp lectures for free
2023-05-13 04:11:13,https://lmql.ai/
2023-05-13 09:13:59,Does it work with open ai models?
2023-05-13 10:07:08,Nice! Does this have similar concepts as jsonformer?
2023-05-13 10:08:31,Something similar to minddb
2023-05-13 10:09:08,Mean query engine
2023-05-13 12:10:04,"For LLM training, what is the impact of choosing different hardware architectures across training and inference?"
2023-05-13 12:11:00,"cc [PHONE REMOVED] was on the original TPU firmware team, would love to hear from him on training-inference trade offs for hardware"
2023-05-13 12:32:57,"Might be too technical for this group, but purely from a nvidia hardware point of view "
2023-05-13 13:03:20,"You can surely do this and in most cases save cost. But a lot depends on your input workloads, model architecture, pipeline etc. How much of it is/can be parallelized and how much is the actual utilization."
2023-05-13 13:04:13,"Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference."
2023-05-13 13:07:50,Ah I read your query the other way round. TBH this needs you to do some work either in the terms of architecturally mapping your model's architecture and compute/memory needs to the cores/sram/vram utilization besides the architectural needs to consider not just the performance but even feasibility of being able to do this. OR just try it out and see what the results you get.
2023-05-13 13:09:35,"Let's say for any QnA or text summarisation task for a domain specific model (assume Llama-30B fine-tuned works well), and less than 2K tokens a query, if I can train using a P2/P3 8xlarge and then switch to a V100 during inference, does it affect my performance? "
2023-05-13 13:10:34,cheap would be subjective I guess
2023-05-13 13:12:20,Agreed. Training cost is one of the factor. More important is performance during inference.
2023-05-13 13:17:20,"It may or may not impact you. I am not that conversant with off the shelf GPU HW and hence the need to test this. For inference accelerators, like Qualcomm's NPU or Google's TPUs, you get compilers/sdk that translates your trained model to best utilize the hardware during inference. LLMs are very tricky though, even run of the mill LSTMs for that matter, and we used to continuously run into lot more nuances there."
2023-05-13 13:24:39,"danke friends, learnt more about Inference optim and GPUs in this convo than 4 hours of Googling and reading blogs 🙏"
2023-05-13 13:28:09,ChatGPT Plugins will be rolled out to _all_ ChatGPT Plus ($20/mo) users in the coming week
2023-05-13 14:11:58,What's stopping you from running a small experiment with off the shelf model with these GPUs to find throughout / $ on a single GPU? 
2023-05-13 14:13:00,How much of it can be attributed to Bard?
2023-05-13 14:13:46,"Nothing, I plan to do that. Was looking for suggestions."
2023-05-13 14:14:03,Weights maybe the same but set of operations  performed / opset might be different for different card generations.
2023-05-13 14:31:17,Haven't found a use case where Bard is better than GPT4 yet
2023-05-13 14:32:31,https://youtu.be/u_dSUtp4eM8
2023-05-13 14:33:55,Clearly in multilingual capability but also in some other tasks in english too
2023-05-13 14:36:25,"Surfing the web and embedded ""Google it"""
2023-05-13 14:42:09,Plus its blazing fast compared to the web browsing plugin probably because its google and they have internal indexes and tpus
2023-05-13 14:44:44,Plug-in mila nahi hai so far :( 
2023-05-13 14:44:48,Like a follow-up prompt could be summarize what social media is saying about this and the results are pretty accurate
2023-05-13 14:44:53,And there's always the Google It button below for us to click
2023-05-13 14:45:11,But this is so wrong? Am i getting something wrong?
2023-05-13 14:47:49,"The crazy part is that in the exit polls it shows correctly, guess this is where the chat rlhf stuff is lacking"
2023-05-13 14:55:18,With my limited usage.
2023-05-13 15:28:54,"Bard is worse at code than my intern, GPT4 is better"
2023-05-13 15:59:01,"""During exams, always attempt to answer the questions even though you don't know the real answer, but never leave any questions"" - AI learned from students"
2023-05-13 18:19:28,TIL - openai pays indian contractors software engineer rates to train its models for code and maths
2023-05-13 18:19:57,"Human evaluators write code for the model to train on, even do stuff like time and space complexity analysis"
2023-05-13 18:26:19,My friend used to work with them
2023-05-13 18:29:09,"Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?"
2023-05-13 18:33:28,I saw a blog post recently which said they paid $15/hr to contractors.
2023-05-13 18:35:58,35lpa
2023-05-13 18:36:35,"They have many more projects, more deeper than just ranking, happy to take questions also. 😂"
2023-05-13 18:36:34,Goddamn!
2023-05-13 18:36:57,I thought openai does data labelling through Surge AI?
2023-05-13 18:37:37,This is a moonlight btw
2023-05-13 21:15:40,So basically Indians are leading in AI in every possible way :p
2023-05-13 21:16:34,AI stands for Anonymous Indians
2023-05-13 21:18:57,Is it wfh though?
2023-05-13 21:23:38,I expect all the prize money is in this photo?
2023-05-13 21:26:46,We're doing an edtech project
2023-05-13 21:27:02,The name? 
2023-05-13 21:28:18,The name deserves an award in itself 😁
2023-05-13 21:31:25,"hey good people, had one simple question:"
2023-05-13 21:46:33,Do you want to do similarity search based on new message from user?
2023-05-13 21:49:07,Why not do the similarity search directly? What’s the LLM outputting on the first call?
2023-05-13 22:52:27,Have LLMs analyze this
2023-05-13 22:53:48,What questions are interesting you? Can throw the csv to code interpreter and ask questions
2023-05-13 22:54:26,Are these the only columns
2023-05-13 22:55:03,What's the churned senders Column mean actually?
2023-05-13 22:55:36,"People who have replied or sent a message here earlier but then stopped, presumably because they've muted or archived this group."
2023-05-13 22:55:55,Ok.
2023-05-13 22:57:38,"Got it. At the moment, not a lot of questions to ask."
2023-05-13 22:59:35,"LOL what were the themes for last few questions/statements from churned senders & group responses thereof, and are there any patterns there."
2023-05-13 23:03:51,But if all the Colmns are the ones being shown. It's not really much that can be asked
2023-05-13 23:04:08,yes. like if this was a chat happening
2023-05-13 23:04:48,Prompt engineering here
2023-05-13 23:04:52,Most active time period?
2023-05-13 23:06:52,Thought this might be interesting to you: HyDE — https://arxiv.org/abs/2212.10496
2023-05-13 23:07:35,Please contrib functions/code here 
2023-05-13 23:09:07,can you explain more? prompt what on which step?
2023-05-13 23:09:19,"checking, thanks for sharing 🙏🏻"
2023-05-13 23:10:26,"""question with full context"" → give it a name as well and a conference workshop paper idea right there 😅"
2023-05-13 23:11:20,Arrey yaar. I'd done this for work a month back. Should publish this 😂
2023-05-13 23:11:49,I'll message you on this
2023-05-13 23:12:47,"You can ask GPT4 to write the paper as well, just give all the titles, method outline and results 😂"
2023-05-13 23:13:52,Haan. Although long form mai Claude is very good. I'm liking it a little more. But gpt4 is very powerful
2023-05-13 23:17:47,for picking relevant messages
2023-05-13 23:38:41,How are you exporting files? Automated or doing it manually everyday?
2023-05-13 23:40:26,"Yes, manual"
2023-05-14 00:14:34,Never Split the Difference: Negotiating As If Your Life Depended On It by Chris Voss.
2023-05-14 00:34:52,"I know someone whose favorite prompt is : Based on Robert Greene’s advice in xyz book, how should I deal with following situation.  "
2023-05-14 00:36:31,"can also do something like, take a chapter of the book you like to base your answer on, feed it to claude 100k and ask it to asnwer in the tone of that chapter"
2023-05-14 01:03:12,Dealing with the same problems. There is a query decomposition module in llamaindex that jerry demo'd in the gen ai hackathon that I'm eager to try out
2023-05-14 01:04:02,Query bundle is something you need to try out.
2023-05-14 01:14:39,Ok since people are DMing me - here are more deets on this -
2023-05-14 01:18:41,"What this implies IMO, is that these models are really still just awesome search engines rather than general reasoning engines. (this is something people have been suspecting since the first time gpt3 paper did 2-digit arithmetic - it's probably parroting it from some table online)"
2023-05-14 09:41:02,"Langchain planning to host a webinar about Education and the role these tools, specially Langchain can play there"
2023-05-14 12:20:57,Software subscriptions also 20% more expensive upfront 
2023-05-14 12:23:48,"No, no. They got cheaper for funded companies. They will just not move money to India for these transactions anymore. Have a Delaware LLC, keep the money there."
2023-05-14 12:32:36,Anyone know of colo providers in India? 
2023-05-14 12:33:41,I intend to just ship them to [PHONE REMOVED]'s house?
2023-05-14 12:33:59,😀
2023-05-14 12:34:07,"What's ""colo""?"
2023-05-14 12:34:15,Colocation
2023-05-14 12:34:26,I see
2023-05-14 12:35:19,https://www.esds.co.in/colocation-services?gclid=CjwKCAjwjYKjBhB5EiwAiFdSfsRbekZqh6173zJpqhDv4xaODkp1-2UxTy6mT2JSG8Vvg1nG9AGfqhoCbHAQAvD_BwE
2023-05-14 12:35:54,This is an example. 
2023-05-14 12:36:27,"In the spirit of suggesting solutions, for those doing >$100K in business/earnings: "
2023-05-14 12:36:44,e2enetworks? NSE listed company
2023-05-14 12:37:02,They don't do colo AFAIK. I've used their stuff in the past.
2023-05-14 12:37:05,You also get openai credits if you’re a stripe atlas customer 🤩
2023-05-14 12:48:19,"no gotchas like ""valid for only 1 year"" ?"
2023-05-14 12:50:10,https://twitter.com/jeff_weinstein/status/1636035301536833538?s=20
2023-05-14 12:53:41,👍. i meant whether they expire within a certain timeframe. like how the trial $18 expired in 3 months.
2023-05-14 12:58:29,ICYMI: Community's Generative AI May Meetups: 
2023-05-14 13:14:17,Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf 😅
2023-05-14 13:21:28,Sure. 
2023-05-14 13:28:42,https://twitter.com/goodside/status/1657396491676164096 😶‍🌫️
2023-05-14 13:36:55,Wow
2023-05-14 13:36:57,Bard is underwhelming for reasoning - where it works is that it's connected to the web & can do things that GPT4 cannot w/o the browser plug-in 
2023-05-14 13:37:50,"Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast"
2023-05-14 13:41:32,"I feel Phind.com (GPT-4 under the hood tho) somehow is in between, and works best for reasoning + information retrieval use cases."
2023-05-14 13:42:36,This raises so many thoughts 💭😅
2023-05-14 13:43:19,"If Shakespeare knew we're calling this a Bard, he'd roll in his grave."
2023-05-14 13:43:32,Try comparing for UPSC predictions? And validate in a few weeks 😅
2023-05-14 13:43:59,UPSC predictions? There is a betting market on who will become IAS now?
2023-05-14 13:44:41,This is w/ Browser Plug-in?
2023-05-14 13:45:21,"UPSC prelims exam is due in a few weeks. So basis old question papers, predict major themes for current year exam"
2023-05-14 13:46:21,I've the entirety of humanity's history on the tip of my fingers. I am not using that for anything boring. 🤣
2023-05-14 13:48:58,"Either it underlearns, or it overlearns, here's an example of the latter: https://masto.ai/@amodm/110353717014726946"
2023-05-14 13:51:17,Yes. Have used a few across India from udaan.
2023-05-14 13:51:19,"Actions like ""making it up"" is what brings a bad name to AI, why is Pichai doing this escapes me."
2023-05-14 13:51:59,The dream is to make it a colo one step at a time 😅
2023-05-14 13:52:01,“I saw the greatest minds of my generation
2023-05-14 14:05:47,Can anyone with ChatGPT browsing plugin try this
2023-05-14 14:08:02,Imagine sitting in a meeting explaining how AI tech works. In my experience ML explanations were always hard in senior management levels. My glance experience was quite satisfactory tho.
2023-05-14 14:09:26,ya this is correct
2023-05-14 14:09:52,I am curious how long before GPT is forced to add such a capability! Its a singificant problem for not having latest knowledge
2023-05-14 14:10:54,GPT has this capability for at least last 2 months
2023-05-14 14:11:35,So it is trained on latest knowledge? Or is it via browser plugin?
2023-05-14 14:11:45,"Ah, but increasingly, you wouldn't need to. "
2023-05-14 14:12:07,via browser plugin
2023-05-14 14:14:19,"On that note, need some help from a technical person here. I am trying to make use of my Notion knowledge base (lots books summaries, podcasts, articles, etc)  using OpenAI. Built a prorotype using langchain, chromaDb, and OpenAi embeddings. But anwers are very rudimentary."
2023-05-14 14:14:31,Related to teaching. 
2023-05-14 14:15:31,+1
2023-05-14 14:16:09,You can use streaming here
2023-05-14 14:16:56,I hear today is his last lecture. Or was it yesterday
2023-05-14 14:17:25,It's 16May 830PM IST
2023-05-14 14:31:24,Can you tell about how many tokens you're trying to generate here? That affects speed of model
2023-05-14 14:37:42,"If you guys want to try any interesting VQA examples, please let me know!"
2023-05-14 14:37:49,is vicuna multi modal?
2023-05-14 14:38:09,is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?
2023-05-14 14:38:41,with langchain you can integrate the serp tool
2023-05-14 14:38:44,I'm already using serp api as tool btw. would using a browser plugin change much?
2023-05-14 14:38:53,no.
2023-05-14 14:39:07,serp api is pretty costly no?
2023-05-14 14:39:27,yes it is costly $
2023-05-14 14:44:43,Please advice this with disclaimer. If you use your personal Indian credit card to incorporate US entity then you have to follow RBI's FEMA compliances. It is easy to neglect small things which may cause issue at later stages. Specially how you move your money across the border. This article by Upekkha is good to learn about this topic https://www.upekkha.io/blog/indian-saas-startups-going-global-a-detailed-legal-incorporation-guide
2023-05-14 14:46:18,"I suspect a lot of the second half complications is when you've an intent to involve a third party e.g. an investor, acquirer or similar. As long as it's just vendors and buyers — only the first part should be applicable?"
2023-05-14 14:55:26,"Not entirely as you have to show your foreign holdings with your income tax (foreign bank account, equities etc) every year as well. Anyway I am not legal and compliance expert but my suggestion is  to use their advice before taking any steps."
2023-05-14 14:57:33,"This is a nightmare with services like firstbase positioning themselves as Indian founder friendly, but not paying attention to any of this"
2023-05-14 14:59:41,Anyone here use a FEMA compliant service which is more template based and not a full overhead law firm that actually does it right ?
2023-05-14 15:02:44,https://docs.cohere.com/docs/llmu
2023-05-14 15:03:37,Zomatos childgpt feature is neat deployment
2023-05-14 15:03:59,Passing about 2500 in context and prompt
2023-05-14 15:04:16,Set max as 4096
2023-05-14 15:04:58,"I've tried streaming, but still takes a bit of time to begin"
2023-05-14 15:05:28,What is a bit of time? What is your tooling here? Llama Index/Langchain or something else?
2023-05-14 15:06:11,Varies. About 8 sec to 15 sec
2023-05-14 15:06:44,Using Langchain
2023-05-14 15:06:48,Doesn’t seem like it’s generating anything in real time 
2023-05-14 15:07:32,Didn't stress test. It's be stupid if they still did that. Lol
2023-05-14 15:07:33,Is 8 sec normal
2023-05-14 15:07:53,Any way to improve that?
2023-05-14 15:07:55,It doesn't actually take time to begin once the prompt has been sent. Atleast not this long. Might need to check how langchain is handling the streaming request. What module does langchain use for this
2023-05-14 15:08:46,Langchain is Python async
2023-05-14 15:09:57,I'm still confused on the time it takes to begin streaming the responses. In my experience 3.5 turbo is actually really fast.
2023-05-14 15:10:11,Unless the api is slow at that point
2023-05-14 15:11:02,Ah maybe
2023-05-14 15:11:18,Let me try a few things again
2023-05-14 15:56:28,"On a related note, here's a q if you kind folks could help"
2023-05-14 16:26:46,Anybody in this group building on top of https://data.gov.in/apis?
2023-05-14 16:34:03,Very cool idea
2023-05-14 16:41:15,"Someone from the group shared that Chroma is pretty fast for upsert/insert operations — beating Huggingface lib in the embedding operation. If someone has similar experiences, would love to hear!"
2023-05-14 16:43:14,"Hey everyone,"
2023-05-14 16:50:02,1. What you are describing is an appealing Avenue but not exactly evidently appealing for a newcomer in the AI field. 
2023-05-14 16:50:03,Google search term was
2023-05-14 16:50:20,Industrial process optimization ai
2023-05-14 16:52:47,"Thanks, [PHONE REMOVED] We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis."
2023-05-14 16:53:01,Got it
2023-05-14 16:53:01,You can't do both in parallel as you want to save the entire thing at once.
2023-05-14 16:54:03,Got it. Thanks
2023-05-14 16:54:23,Interesting article:
2023-05-14 17:16:28,"Yes get a good lawyer here, especially if you plan to do a subsidiary too (which you probably will need if you are based out of india)"
2023-05-14 17:26:21,Using proxy nginx/envoy you can do. check this blog something similar you can do adding extra things in proxy to publish SSE response to some queue as well.
2023-05-14 17:28:27,Thanks a bunch. Will look through
2023-05-14 18:12:53,I still need to understand this. You can only save to the database at the end of generation. You can't keep updating the same object after every token generation it is too expensive and costly.
2023-05-14 18:14:32,I am writing a simpler version using python itself and share gist. What I shared was for scalable approach which is bit complex.
2023-05-14 18:14:48,A try: {generation stream} finally: {save to db} seems like a good approach to handle failures too
2023-05-14 18:15:39,Yes but this is sequential not parallel
2023-05-14 18:16:14,Why would you need to save in parallel to the db?
2023-05-14 18:16:29,That's what the question was
2023-05-14 18:16:47,Our Team *parh.ai* won *$1000 from Google Cloud* for our work.
2023-05-14 18:19:14,I don’t see a very good reason unless you are doing realtime stuff to multiple frontends and would like them to be synced without dealing witht multiple hierarchies of data sources
2023-05-14 18:20:22,Yes I agree.
2023-05-14 18:37:21,I can help you setup H2O LLM Studio for it 🫡
2023-05-14 18:41:53,(After I’m back from LLM vacation^ 😂)
2023-05-14 18:42:59,"Very nice work man. I worked on a similar problem some time ago. Using a diagnostic test, understanding the students concept mastery and then prepare a adaptive learning journey for the student. We used mainly BKT ( also deep knowledge tracing can be used) to estimate concept mastery for students"
2023-05-14 18:46:11,Created this sample gist using GPT4 itself which store SSE data to DB and along with serving frontend client. But as pointed out with [PHONE REMOVED] it will not essentially parallel but storing will happen during wait period.
2023-05-14 18:52:25,Can finally claim I got seed funded by Google
2023-05-14 18:54:24,This is generated by gpt4? What did you edit?
2023-05-14 18:56:45,"I did prompting to improve the output, first one was very bad. And added few things like disclaimer and description but that also generated by it GPT, thats why you may see gist edits :)"
2023-05-14 19:04:52,Checks out. I would say about 10% of it is usable in prod 🫣
2023-05-14 19:06:36,You should try feeding this into gpt4 and see if it understands 😂 
2023-05-14 19:11:07,https://amp-lepoint-fr.cdn.ampproject.org/c/s/amp.lepoint.fr/2519782
2023-05-14 19:12:25,"Of course it is sample code only showing a simple way to tap streaming data from openai api. Need proper DB schema (key against data to preserve), multiple clients, multiple api instances, latency, regeneration and many more required for production use."
2023-05-14 19:15:23,Any takeaways?
2023-05-14 20:38:15,QnA generation looks solid. Congratulations 🎉
2023-05-14 20:50:05,Thank you. 
2023-05-14 20:50:17,This story is an explanation of relativity
2023-05-14 20:50:58,"Just first two paragraphs of the entire story, which is slightly longer. Happy to share if anyone likes."
2023-05-14 20:54:18,Looks absolutely amazing.
2023-05-14 20:55:00,Noice! I think there’s a lot of potential in auto learning generation. I’m trying to learn Dutch based on how I would converse with a paid in person tutor. The first pass seems solid
2023-05-14 20:56:13,"You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum."
2023-05-14 20:56:32,"Play.HT has some decent Dutch voices, which are monotone, but works well while hearing the pitch and pronunciation"
2023-05-14 20:56:35,"It doesn't exactly cater to our ""AI tutor for all-nighters"" main course of action. "
2023-05-14 20:56:53,Perhaps it's value lies more in the long term study plans
2023-05-14 20:57:09,When you've been freshly introduced to a topic and exams are still far away
2023-05-14 20:57:36,That's when these stories could help cement concepts
2023-05-14 20:57:39,You are saying not suitable for goal based education?
2023-05-14 20:57:46,Aligned
2023-05-14 20:59:30,Yeah i would imagine students that reap the most benefit from all nighters are ones who focus exclusively on question answering. These stories shouldn't really be a part of those student's productive time.
2023-05-14 21:00:24,"Well, I guess we know what byjus is buying next"
2023-05-15 00:49:19,Does anyone know the diff between langchain python and js featuresets? A client has a typescript backend and doesn't want to have a python microservice for the LLM app
2023-05-15 00:51:56,https://langchain.com/integrations.html
2023-05-15 01:26:19,in langchain is there any agent flow which is for correcting hallucination that occur in generation.
2023-05-15 01:33:44,This is so scary
2023-05-15 01:34:37,What doomsday scenario has come to your mind
2023-05-15 01:35:01,A ny times journalist using this to fact check something
2023-05-15 01:35:54,They will bias it to their own views.
2023-05-15 01:57:47,chain of thought reasoning on open domain Q&A will only lead to more hallucinations no?
2023-05-15 01:58:21,"haan, this repo is good. although has some limitations"
2023-05-15 03:02:08,https://twitter.com/gdb/status/1657860994956410880?s=20
2023-05-15 03:05:23,https://twitter.com/main_horse/status/1657810453278658560?s=20
2023-05-15 05:31:44,What's your use case? Hyde is one approach to improve quality of answer. You can also reduce hallucinations with better prompts.
2023-05-15 08:20:30,Hello everyone! 👋 
2023-05-15 09:06:35,https://docs.cohere.com/docs/llmu
2023-05-15 09:11:11,There is this and then fullstackdeeplearning came up with a course which [PHONE REMOVED] posted on Twitter!
2023-05-15 09:13:49,"If you're working on NLP heavy areas e.g. search, chat, question-answering: https://docs.cohere.com/docs/llmu — this is perhaps more deverloper-friendly because NLP is Cohere's bread and better."
2023-05-15 09:20:27,Thanks. Still working my way through basics and building small applications.
2023-05-15 11:30:31,Oh I've done all that. Taking this one step further.
2023-05-15 11:32:13,Abhinav [PHONE REMOVED] would you be open to giving an advanced prompting for Q&A talk at the BOM meetup in June? 
2023-05-15 11:32:38,Does anyone here understand how hashing works in recommendation systems?
2023-05-15 11:33:01,Paper https://arxiv.org/pdf/2209.07663.pdf
2023-05-15 11:33:25,"I understood Cuckoo Hashing, but why is hash used when you have an embedding?"
2023-05-15 11:36:54,Embeddings start to collide at social media scale because power creators and consumers skew the distribution: 
2023-05-15 11:38:38,What would embed start to collide mean?
2023-05-15 11:39:22,"Haven't seen the paper. Hashing is the general technique and some of these are related to Locality Sensitive Hashing, where the idea is instead of hashing to random locations to use probability theory of local chance of collision, here you want similar things to hash to similar locations. These are different class of hashing algorithms."
2023-05-15 11:39:29,"Two cents, busy to into details."
2023-05-15 11:41:47,"word2vec isn't a good analogy for recsys embedding perhaps. But yes, that is one way to imagine. "
2023-05-15 11:46:23,Got it.
2023-05-15 11:47:48,It is moving away from one-got encoding -> embedding
2023-05-15 11:50:56,"Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing."
2023-05-15 11:51:43,"So people might be using it interchangeably, except when they are not and using embedding followed by hashing (not sure when this is useful)."
2023-05-15 11:52:35,"Yeah, I understand embedding is a type of embedding (compression)"
2023-05-15 11:52:45,Embedding is a type of hashing*
2023-05-15 11:55:46,Will look at the paper and come back later. Can you send the link to the original paper.
2023-05-15 11:56:34,Ya.
2023-05-15 11:57:31,This is the paper I wanted to understand and got stuck up on hashes
2023-05-15 11:57:51,Thank you for offering to help [PHONE REMOVED]
2023-05-15 12:22:06,just bumping this thread back again to see if there is any plugin i can use to enable browsing via API except using serp as a tool? or any other library that's optimised on cost.
2023-05-15 12:24:56,I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?
2023-05-15 12:25:03,Could anyone help?
2023-05-15 12:25:40,Llama index
2023-05-15 12:26:35,Thank you!!!
2023-05-15 12:27:56,you can do map reduce on langchain. load summarize chain and do with map reduce chain type.
2023-05-15 12:29:38,You can see some of the community discussions here: https://nirantk.com/ai 
2023-05-15 12:34:31,This is great!!
2023-05-15 12:35:23,code is here if it helps: 
2023-05-15 12:35:39,It can be turned into newsletter as well.
2023-05-15 12:41:45,👋 Hello everyone! 🎉 
2023-05-15 12:46:17,The approach would be to break it down and summarize each chunk separately.
2023-05-15 12:46:37,If you want to make hiring posts: https://nirantk.com/ai/community.html
2023-05-15 12:48:21,A friend is looking for using GenAI for AR/VR - any pointers ?
2023-05-15 12:49:00,"I essentially want to build something similar to anthropic where I can give long texts, pdfs, transcripts, entire tweets of a hashtag per day - and then can ask to generate insights out of it."
2023-05-15 12:49:03,"Want to do it for personal use first, so okay with extra cost of personal hosting, etc."
2023-05-15 12:49:29,Would have to be a bot ore specific. XR + gen AI super wide
2023-05-15 12:50:40,FYI. If anybody is interested:
2023-05-15 12:53:07,Any open-source alternative for https://www.glean.com/?
2023-05-15 12:54:14,Few examples
2023-05-15 12:57:07,"He is a logistics researcher, wants to create city traffic simulations - so wants to create cities with roads and traffic etc"
2023-05-15 12:59:15,"cc Devanshu [PHONE REMOVED], Yash [PHONE REMOVED] and Charu [PHONE REMOVED] have worked on doing simulations based on user input. Phenomenal project."
2023-05-15 12:59:45,Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now 
2023-05-15 13:02:49,Have you built something with it? Or have a demo someone can start off?
2023-05-15 13:06:03,Recently saw this demo on twitter by a dude who made a Google Maps driving game:
2023-05-15 13:07:36,This api was recently released in Google IO: 
2023-05-15 13:08:25,"There are quite few things out there. Along with what folks mentioned. Do look at ADAS simulators (Carla etc), in this case you can simulate without even GenAI. Not quite sure what the specific problem is, so can't comment if this will fit."
2023-05-15 13:12:27,Have been playing with luma + unreal. 
2023-05-15 13:36:41,This is so cool! I am completely new to this space. The only thing I've tried in unity is building a small 360 immersive world so that I can use my pico4 to chill in it. This stuff is fascinating.
2023-05-15 13:42:16,"But if any of you want to generate 360 images for VR, please check out https://skybox.blockadelabs.com/"
2023-05-15 13:49:31,Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf
2023-05-15 13:51:26,PS: This is a good tool to breakdown papers and learn faster : https://www.explainpaper.com/
2023-05-15 14:26:12,Has anyone ran into rate limit issues with OpenAI api?
2023-05-15 14:28:11,"If you're looking at rec systems broad ideas, this webpage has some good ones: https://vinija.ai/recsys/papers/"
2023-05-15 15:08:23,"Contextual bandits are amazing framework.. Even under the hood of RLHF/ RLAIF, these systems are being contextual bandits with context being all the tokens except last and action being log probabilities."
2023-05-15 16:01:49,Hey
2023-05-15 16:02:26,"Folks, is there a JS or TS wrapper for llamaindex?"
2023-05-15 16:02:52,Can't seem to find it in the official docs
2023-05-15 16:03:02,Maybe an unofficial fork you've seen?
2023-05-15 16:51:27,"I'm unclear on your exact use case but if it's something like QA over documents, https://github.com/gmpetrov/databerry is perhaps a better fit for you"
2023-05-15 17:10:09,Would this be a single gpu? Or multiple in one machine
2023-05-15 17:13:30,Multiple in 1.
2023-05-15 17:13:55,It can also be a shared box.
2023-05-15 17:14:21,How can this even work
2023-05-15 17:14:29,Its not a cpu where you can easily share memory
2023-05-15 17:14:42,You have to divide memory na
2023-05-15 17:16:42,What I meant is there can be motherboards that has more than 8 A6000
2023-05-15 17:16:51,I was actually trying to check how common are they.
2023-05-15 17:17:09,Actually not very common so probably you have 1 full box/machine to yourself.
2023-05-15 17:20:07,Gigabyte G481-S80 is likely the motherboard
2023-05-15 17:20:22,It can support 8 double width GPUs i.e. A6000.
2023-05-15 17:21:00,"It's common to have 8 GPU boxes and then giving access to hosts with 1,2,4 or 8 GPUs."
2023-05-15 17:21:02,Supermicro SYS-4029GP-TRT is the only one I found that takes 10 double width GPUs 😮
2023-05-15 17:21:20,Yea. But the image shows access to 8.
2023-05-15 17:21:33,Yeah
2023-05-15 17:43:46,who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?
2023-05-15 17:46:58,[PHONE REMOVED] is using it in production systems. I'm migrating a consulting client from Langchain to Llama because Langchain is 💔🥲
2023-05-15 19:23:15,Kailash Nadh is the CTO of India's largest brokerage by transaction volume: Zerodha. He is also an active FOSS contributor: https://github.com/knadh
2023-05-15 19:23:18,Can we get him in this group?
2023-05-15 19:26:38,In the same breath https://economictimes.indiatimes.com/news/company/corporate-trends/nithin-kamath-unveils-zerodhas-ai-policy-will-not-fire-anyone/no-job-loss-because-of-ai/slideshow/100210374.cms?from=mdr
2023-05-15 19:33:53,"when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though"
2023-05-15 19:41:49,This is very interesting. Can u talk more about this ?
2023-05-15 19:43:30,This is expected. These models only work well when you do prompt engg over your specific data distribution. Both libraries make prompt engineering so opaque 😭 (langchain has not so good default prompts too)
2023-05-15 19:48:02,For metric analysis is vector embedding a good approach ? 
2023-05-15 19:48:45,"Nahi, nahi. You're better off asking that to something like a defog.ai for warehousing or https://github.com/gventuri/pandas-ai"
2023-05-15 19:50:22,Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db
2023-05-15 19:50:33,Disclosure: I've a business relationship with Defog.ai — so I also know how good their tech is since I built it 😅
2023-05-15 19:53:16,yes same prompt. different vector store (pinecone)
2023-05-15 19:53:20,"Yeah, I pay a therapist to teach me how to do this again again. Thank you, thank you for confirming that it's working 🤣😂"
2023-05-15 19:53:25,Any pointers on how to do this on nested tree like data? Eg website crawlers
2023-05-15 19:54:38,"Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?"
2023-05-15 19:54:44,"interesting, I will try this and check"
2023-05-15 19:55:48,"I can flatten it out without ai, and feed that into a vector db - but that would loose the hirearchical structure."
2023-05-15 19:56:48,Basically want to build my own algolia crawler but powered by new embeddings and llm tech - https://www.algolia.com/products/search-and-discovery/crawler/
2023-05-15 19:58:57,Thought this might be interesting to you: https://github.com/typesense/typesense
2023-05-15 19:59:44,"From what I can tell (earlier read, not tonight) — that is already flat content, right?"
2023-05-15 20:01:51,"Hmm, you can always recompose by having navigation history in each chunk. You've to invent something to capture what positional embedding, circa 2018, did"
2023-05-15 20:02:51,I've tried this navigational history → chunk trick only till depth 5 though 🤔
2023-05-15 20:04:19,You're trying to capture backlink information?
2023-05-15 20:09:47,https://twitter.com/aakrit/status/1658116297178112004?t=FhTQTej4iq5k_keIJfeA3Q&s=08
2023-05-15 20:10:00,Mumbai Hackathon for AI.
2023-05-15 20:11:43,"I think so, because if you have say this list"
2023-05-15 20:11:48,# /resources/awesome_programmers.md
2023-05-15 20:11:59,and the links resolve to a doc like this -
2023-05-15 20:12:00,# /resources/awesome_programmers/nirant.md
2023-05-15 20:12:15,Then the end nodes don't make any sense without the backlinks
2023-05-15 20:14:21,We've gone too deep into this? Let's move this to DMs
2023-05-15 20:16:18,"A more expensive approach but will give you a more natural interface is to retrieve the closest vector to the question from the vector db, pass it as history in the prompt to chat gpt and let it give you the final answer."
2023-05-15 20:17:16,"Clever: ""HyDe-lite"""
2023-05-15 20:24:39,Love the set-up
2023-05-15 20:30:14,Dope keyboard
2023-05-15 20:34:25,Does torch.compile also work with pytorch2?
2023-05-15 20:35:10,Haven't tried this.
2023-05-15 20:47:47,It only works in pytorch2
2023-05-15 20:58:22,https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561
2023-05-15 21:45:00,Few things you can explore in LlamaIndex:
2023-05-15 22:39:09,LlamaIndex has made an integration with Poe API - https://github.com/poe-platform/poe-protocol/tree/main/llama_poe
2023-05-15 22:40:01,awesome!
2023-05-15 22:41:19,Invited him :D
2023-05-15 22:46:25,Anyone using humanloop actively?
2023-05-15 22:47:02,Had a few questions
2023-05-15 22:49:09,PSA: 
2023-05-15 22:56:21,https://dontasktoask.com
2023-05-15 22:58:27,reminds me of this and slack DMs at work 😄 https://nohello.net/en/
2023-05-15 23:03:23,This is the exact link from community guidelines: https://nirantk.com/ai/community.html
2023-05-15 23:05:42,*running similar web on nirantk.com* :p
2023-05-15 23:57:18,Sorry guys was doing some user research so potentially would’ve involved many noob qs. But noted
2023-05-15 23:57:21,Ouch
2023-05-16 00:30:42,"Noob questions are fine, what they're pointing out is that don't ask for permission/context to ask. Just ask your question directly. Don't try to save your time, save the community's time."
2023-05-16 00:55:04,50k livestream views for strangs final lecture
2023-05-16 05:42:25,"Team, before I get roasted, I thought I’d check if it’s okay to share about events in thr group? "
2023-05-16 05:47:33,"Just met with OpenAI in their office. Signed an nda so can’t talk about what’s coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better."
2023-05-16 06:03:33,I have this request - https://community.openai.com/t/is-there-a-way-to-set-a-a-random-seed-for-responses-with-temperature-0/4164
2023-05-16 06:16:59,"Pls join if this seems relevant to you, or pls pass it along to anyone who may benefit. "
2023-05-16 08:58:35,https://levelup.gitconnected.com/mpt-7b-the-times-of-commercially-usable-language-models-has-come-8c9c6c3316ef
2023-05-16 09:51:41,FYI: This was the press coverage then. You cannot use it commercially.
2023-05-16 09:58:25,"Confidence score for each reply. This is the huge problem for enterprise deployment, prompt testing...basically everything."
2023-05-16 09:58:30,Even base?
2023-05-16 10:01:36,logprobs used to solve this to some extent before chat completion endpoints
2023-05-16 10:01:47,for prompt testing - have you tried evals?
2023-05-16 10:05:13,Wow! Access to the most brilliant minds on earth right now! 
2023-05-16 10:05:23,"This is an involved question. How will u eval ? String match, embedding match or statistical match?"
2023-05-16 10:08:11,Would depend on the task at hand I assume.
2023-05-16 10:08:27,"Also, sorry - what’s an “involved question”?"
2023-05-16 11:29:13,"Yes you are right. In their particular case, they are using a collision less hashing (here ids span 2^48 space). Here hashing being normal hashing (not semantic/LSH). They needed a hash function that hashes to smaller space (after removal of some of the long tail data) with extra properties, like ability to remove hashes cheaply (as things get stale), ability to add new IDs (as they do online learning on new IDs as they come in). You can DM, if you have more questions."
2023-05-16 11:31:18,"Thanks for asking this question, sharing the write up (helped me understand where you are), the paper was quite interesting with lots of sys  details, though tad bit badly written. I also learned few things 😀."
2023-05-16 11:32:25,thanks for answering.
2023-05-16 11:34:02,"Haha. Yeah, that is their sauce for 💸"
2023-05-16 11:34:21,Also keeps engineers employable
2023-05-16 11:35:45,"It seems to me that ML engineering is where the moat is, not so much in ML research."
2023-05-16 11:36:28,"Yeah, I've bet my career on that since 2018"
2023-05-16 11:37:42,Timeout of their api can be improved and we should be able to pass custom values. The current ones don't work
2023-05-16 11:45:35,"Hey folks, came across replicate.com. Would this be a good way to begin working with open source models for a newbie?"
2023-05-16 11:48:39,Yes. At least for me have been using this and found free lancers comfortable using it for a prototype
2023-05-16 11:49:47,I think [PHONE REMOVED] already has some experience with this. He can share some points on this
2023-05-16 11:50:29,"From what I see, we can run predictions easily. Apart from predictions, can we use replicate for training the existing models with custom datasets too?"
2023-05-16 11:55:21,Best part of replicate is you can test the model on their UI to see if it works for your use case and then spend time on setting things up.
2023-05-16 12:44:38,"I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?"
2023-05-16 12:46:56,Same here. Is there any plugin which does the same?
2023-05-16 12:47:00,did you enable it on your account settings?
2023-05-16 12:47:12,Don't have it in the options yet
2023-05-16 12:47:43,cuz if its not visible there then probably hasnt been rolled out to your account. they're doing it in tranches
2023-05-16 12:47:59,All other plugins are there
2023-05-16 12:49:30,its a different model and not a plugin
2023-05-16 12:56:37,Hey everyone! *A request*
2023-05-16 12:56:39,My profile: https://restofworld.org/author/nilesh-christopher/
2023-05-16 12:58:44,"Can recommend helping out Nilesh, high integrity. He wrote about the Generative AI Hackathon winners as well: "
2023-05-16 13:01:38,Not sure why the clicks are falling
2023-05-16 13:01:51,Try WebPilot or Keymate.Ai Search if u have access to that
2023-05-16 13:04:30,I've enabled it this way
2023-05-16 13:17:35,"Just curious to know the impact of launching plugin on business metrics: traffic, revenue, CSAT, etc?"
2023-05-16 13:18:05,"Do we have a list of good learning resource? Bunch of college grads have started reaching out asking for resources which can make them industry ready in the ML/AI space, specially Generative ?"
2023-05-16 13:25:19,course.fast.ai is all you need if you've some programming exposure e.g. 1 year of Python/2 years of JS/6 months of Rust
2023-05-16 13:25:56,and stats?
2023-05-16 13:26:12,and  LangChain for structure?
2023-05-16 13:27:00,I'd recommend every beginner against Langchain. These libs evolve fast. And they might over index on the wrong ideas e.g. vector similarity is how search is done 🤢
2023-05-16 13:29:30,got it..
2023-05-16 13:30:58,Would you recommend Fast.ai over Hugging Face course?
2023-05-16 13:31:15,"I hope most undergrad students know this better than me, given that they practiced for entrance exams:"
2023-05-16 13:31:48,Trust me they have not..
2023-05-16 13:32:34,I have interviewed around 50-100 folks in past..
2023-05-16 13:34:00,Lot more folks from SDE background are in the market than statistics background
2023-05-16 13:40:06,Has anyone developed plugins here yet?
2023-05-16 13:40:12,Any idea how to set custom metadata?
2023-05-16 13:41:40,"I’ve ```/upsert``` -ed the documents using chatgpt-retrieval-plugin, but not being able to make custom metadata work yet"
2023-05-16 13:49:42,the custom metadata needs to be added both in the vector db model as well as the openapi spec. did u change the openapi as well ?
2023-05-16 13:51:28,"Yes I’ve changed the openapi specs, particularly ```models.py``` in ```/models``` and ```openapi.yaml``` in ```/.well-known``` if you’re a acquainted with the repo"
2023-05-16 13:52:17,But maybe I’ve not defined the custom metadata correctly
2023-05-16 13:53:15,"Anyone who had worked in this direction, a tutorial if available, or a small screenshot where they’ve defined their custom metadata if shareable, would be really helpful"
2023-05-16 15:59:38,"some background before a question, "
2023-05-16 16:16:50,"thanks, I think in chromadb server sometimes takes up the memory and stores things in memory of python itself. In qdrant can u share the file mode-related ref... or are u talking about payloads stored in disk ..."
2023-05-16 16:17:44,"Not just payloads, you can also pipe the vectors to local. Syntax from memory is something like this: "
2023-05-16 16:24:47,"interesting, oh I did not know this, this must be new let me try to find a ref"
2023-05-16 16:31:35,"Happy to help, also I should disclose I've a business relationship with Qdrant."
2023-05-16 16:33:55,"this is almost starting to sound like “As an AI language model,….” 🫣"
2023-05-16 19:51:46,"Hi all,"
2023-05-16 21:13:11,Sam Altman proposes to the US Congress that licenses be issued for building AI
2023-05-16 21:17:53,This agi stuff is just an excuse to build a monopoly
2023-05-16 21:18:43,He's come a long way from *Open* AI
2023-05-16 21:20:04,Regardless of intentions. I don't think government should just listen to a for profit organization. You might not know AGI but you know greed
2023-05-16 21:20:29,"Sad part is that, if enough new software solutions built using GPT emerge as job providers, openAI will be at the forefront of making legislation for all things pertaining to AI"
2023-05-16 21:21:25,Haan.
2023-05-16 21:22:40,Microsoft wants a return on its investment
2023-05-16 21:26:27,This feels like jio days when everyone and their dogs were getting aadhaar biometric based sim card activated in shortest possible time.
2023-05-16 21:27:30,Microsoft is also an investor in Jio.
2023-05-16 21:30:01,Is openai profitable on unit economics?
2023-05-16 21:31:11,Not yet
2023-05-16 21:32:17,Satya vachan
2023-05-16 21:47:06,How long before buying GPUs gets licensed ?
2023-05-16 21:49:59,"No reason for Jenson to block potential buyers. Now, if we're talking about using GPUs in data centers, that's already a messed up area"
2023-05-16 21:50:45,Any room with more than 5 computers (or some smallish number) can be considered a data center and therefore you cannot use the RTX family of GPUs in such a setup
2023-05-16 22:37:53,https://home.mlops.community/public/events/fine-tuning-llms-best-practices-and-when-to-go-small-2023-05-17
2023-05-16 22:45:18,"When you do embedding based retrieval, what threshold are you using for the similarity score? I know it depends on the use case but we are having to do a lot of trial and error so I’m curious"
2023-05-16 22:46:43,"Don't just focus on this part...focus more on creating the embeddings. For e.g. the OpenAI Tiktoken library is the BPE algorithm. U can switch this out...have tokens overlap, etc etc. Lots of stuff u can do."
2023-05-16 22:47:57,Thanks! You mean focus more on the content being used to create the embeddings and any other parameters you can control?
2023-05-16 22:51:06,Karpathy has a very interesting take on this.  Checkout his notebook 
2023-05-16 22:51:08,:-)
2023-05-16 22:56:53,This is very cool!
2023-05-16 22:57:27,Any other documents for tradeoffs with just using embeddings based search v/s alternatives/hybrid search?
2023-05-16 22:59:37,"No not the content. The same content, but the way you tokenize to create the embeddings."
2023-05-16 23:00:05,The retrieval algo itself is the most unchanging thing here...svm vs knn nonwithstanding
2023-05-16 23:12:43,There were indications of this monopolistic behaviour since quite some time
2023-05-16 23:15:36,"Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so."
2023-05-16 23:18:02,please share results
2023-05-16 23:18:36,That's where he is building world coin ? He has some crypto stuff also going on right ?
2023-05-16 23:19:39,"Yup ,ties in pretty neatly to give OpenAI a good monopoly"
2023-05-16 23:19:48,https://fortune.com/crypto/2023/05/15/openai-sam-altman-100-million-worldcoin-funding-iris-human-artificial-intelligence/
2023-05-16 23:33:07,Here is his talk. He was an very lucid expositor: http://videolectures.net/lce06_roweis_ncaml/
2023-05-17 00:13:23,Got access to chatgpt plugins.
2023-05-17 00:14:35,the diagrams one
2023-05-17 00:17:01,also a basic question
2023-05-17 00:17:32,Hi everyone. I’m Kailash. @kshivendu invited me to this group. I’m a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in
2023-05-17 00:22:20,Huge fan of zerodha and what's it done so far! Welcome aboard.
2023-05-17 00:32:55,https://blog.cloudflare.com/introducing-constellation/
2023-05-17 00:39:31,"Hi Kailash, Welcome onboard. Sumod here btw. Yeah, exact same feelings of fascination & bewilderment at the same time. Trying to see how to make it to be something for greater good."
2023-05-17 00:45:48,wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days
2023-05-17 00:51:52,https://www.digitaltrends.com/computing/nvidia-bans-consumer-gpus-in-data-centers/
2023-05-17 00:52:07,"Bit of an old news, i haven't seen the latest on this"
2023-05-17 00:53:06,"Google could that because they were small. Back during Stanford days, they used to offer to setup machines that come for the CS dept and secretly use it for a week or so before giving it to the intended recipient"
2023-05-17 02:52:33,https://github.com/microsoft/guidance
2023-05-17 02:54:11,Any comparisons between this and https://lmql.ai/ ?
2023-05-17 05:22:44,"I think OpenAI simply doesn't have the expertise or maybe motivation to do growth work, especially on free products side. FB would've optimised the hell out of chatgpt growth metrics if they were working on it"
2023-05-17 07:27:31,"This mindset is perhaps why FB didn't invent ChatGPT, or even any GPT?"
2023-05-17 07:28:27,"Before someone says Llama, in comparison to even 3.5-Turbo it's Lmao."
2023-05-17 07:29:02,Naa I think it was because of too much metaverse.
2023-05-17 07:29:21,I'm sure they saw more growth in Metaverse.
2023-05-17 07:29:51,Engagement pro max
2023-05-17 07:30:45,"I’m talking to one of the gen ai leads from meta next week, Looks like they’re doing a bunch of stuff"
2023-05-17 07:31:17,Next level ads also
2023-05-17 07:32:28,"Absolutely no disputing Meta's ability to fast follow by throwing together compute, and talent. I love Meta for making FAISS, PyTorch and what not"
2023-05-17 07:38:57,Would love to know if Meta plans to continue to intend this research license behaviour + 
2023-05-17 07:51:38,Apple takes its first step in Gen AI
2023-05-17 07:51:39,https://www.apple.com/newsroom/2023/05/apple-previews-live-speech-personal-voice-and-more-new-accessibility-features/
2023-05-17 07:52:14,Going to steal a few customers from eleven labs TTS
2023-05-17 08:02:00,Shopify released this interesting dataset
2023-05-17 08:21:20,Exports of shopify merchants in India selling abroad
2023-05-17 08:21:27,There's possibly a currency impact too
2023-05-17 08:21:41,That isn't factored in
2023-05-17 08:41:15,Here's an idea: Prompt injection detection as a service.
2023-05-17 08:47:09,Related? 
2023-05-17 08:47:18,"https://rebuff.ai/ is trying to build this, they even have a self hostable server"
2023-05-17 08:47:27,Oh beat me to it
2023-05-17 08:47:46,To self host
2023-05-17 08:49:31,Why was it forwarded to the same WA group?
2023-05-17 09:23:06,"Removed those for now, I assume it was meant for someone else"
2023-05-17 09:50:11,"[PHONE REMOVED] compiled this excel sheet with learning resource, hope you find this helpful "
2023-05-17 10:11:13,Thanks for this.
2023-05-17 10:52:58,"They also made changes to CoreML for stable diffusion. Feels like in sometime, they will ship iphone/mac with their modified version of SD which devs/consumers can directly use. "
2023-05-17 11:16:22,https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353
2023-05-17 11:43:21,https://hackathon.bio/ - Bio x AI hackathon - fully remote - people interested in AI in biology can look into it
2023-05-17 11:43:24,"This is really cool find, will try this out"
2023-05-17 11:52:49,Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.
2023-05-17 11:55:07,GPT-3.5-turbo and GPT-4 have default context sizes of 4096 tokens. There are variants of GPT-4 models with 8k and 32k tokens context sizes as well.
2023-05-17 11:58:00,Got it. Ty. 
2023-05-17 11:58:03,Works via Map Reduce kinda ideas. 
2023-05-17 11:59:23,"Map reduce has a theoretical upper limit on the size of output, which is 1/3 of the max output token count of the model btw something to keep in mind"
2023-05-17 12:01:42,I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh
2023-05-17 12:05:47,https://twitter.com/itstimconnors/status/1658547632124354595?s=48&t=ACPHEfclkXmi9Z92RTsh9g
2023-05-17 12:06:15,Has anyone put ANY opensource model in production without fine tuning? 
2023-05-17 12:07:34,would be good to use Azure OpenAI service while building products as you may hit rate limit error with OpenAI token.
2023-05-17 12:07:34,What is the usecase of putting a generic model in production?
2023-05-17 12:08:49,The product will be using the user's Chat GPT token. So I don't think it will be hitting OpenAI's throttle limits
2023-05-17 12:09:25,You might run foul of Terms of Service
2023-05-17 12:09:27,Is there a difference bw chat.openai.com and gpt-3.5-turbo?
2023-05-17 12:09:57,"Hm, yes that could be an issue. But technically OpenAI does not know the requests are coming from an extension"
2023-05-17 12:11:13,Hey there. Can someone help
2023-05-17 12:11:38,And it is just a user's request. I pay for ChatGPT. But the app could be more for targeted segments instead of being a chat only tool.
2023-05-17 12:12:48,"Yes, the biggest one has to be that there’s a farm of humans looking at what you type into chatgpt and trying to fix it 😂"
2023-05-17 12:15:33,Taking a guess
2023-05-17 12:16:41,Why not factor something like an xy+yz+xz.. sometimes memory triggers for us are a combination of similarity and importance?
2023-05-17 12:17:35,I understand more unstability but maybe can be combined with a smaller coefficient?
2023-05-17 12:37:42,chatgpt is a generic model. more commonly known as a foundation model. 
2023-05-17 12:44:26,I guess its upto use case.
2023-05-17 12:48:46,Simple intuition - 
2023-05-17 12:49:50,Addition is more lax. And so the model can decide what to do. And you err on the side of calling into the model more
2023-05-17 12:51:05,Someone was asking about metas plans
2023-05-17 12:51:09,https://atscaleconference.com/events/meta-ai-infra-scale/
2023-05-17 12:51:14,Tune in if you’re curious
2023-05-17 12:53:02,Yeah SVM with three features makes sense. Treating them like vectors on independent axes
2023-05-17 12:54:45,X+Y+Z < C is a diamond shape
2023-05-17 12:57:57,Has anyone seen any example of an agent setup doing something truly impressive ?
2023-05-17 12:58:02,"One way of think of them (Control System PoV) is that are they operations in series (multiplication) or parallel(addition)? Multiplying is great if you sort have a condition ""if any of these are bad, then output should be low"", as even one component being low will effect output drastically. Whereas addition will reduce only for that component's selection. There are other nuances as well. You can see this talk I gave at 2018 fifthelephant (some of those are dated today). See anti pattern3: https://m.youtube.com/watch?v=FYVFK4Y4IiY"
2023-05-17 12:58:12,I have seen more demos of the frameworks than actual outputs
2023-05-17 12:58:23,I’m working on a bunch of stuff in ecomm - will dm you!
2023-05-17 12:59:55,Like the Microsoft paper was cool because it was a simulation / game for fun. So for eg agents might be great for writing the plot of a movie. Make a set of characters and set them loose. But for “real work” yet to see something that works well
2023-05-17 13:03:09,The key here is to make you one of the “agents” and also things like compilers and search engines. And you can interrupt it at any point by pressing Ctrl+D or something and redirect it.
2023-05-17 13:06:29,And then you do tbis a lot and fine tune / RLHF on it. This is what openAI is doing with plugins.
2023-05-17 14:55:49,Any of you have github pro here? 
2023-05-17 15:15:09,I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?
2023-05-17 15:17:32,You can get GitHub Pro for 12 months here if you're buying it for a startup: https://github.com/enterprise/startups
2023-05-17 15:34:08,There is a maximum storage limit
2023-05-17 15:34:13,/month
2023-05-17 15:35:29,"Ok, so 2gb per file"
2023-05-17 16:06:05,"Hey folks,"
2023-05-17 16:06:12,I had a question for the folks working on Stable Diffusion / any diffusion model in a larger org. Most models / the companies behind them don't accept any liability for the images generated from the model and AI copyright is a tricky subject. There have been instances (although a small %) where copyrighted content has surfaced on the generated images (cross-checked with LAION-5B) and this makes working with them a bit hard. 
2023-05-17 16:08:11,I follow AI regulations closely.
2023-05-17 16:08:47,These are the regs if u want to read https://www.copyright.gov/ai/
2023-05-17 16:08:53,(deleted my answer because it was wrong)
2023-05-17 16:11:16,"That said, I know this will be a tricky decision making process for someone like Flipkart to start getting audit clearance to generate AI images/content for products."
2023-05-17 16:20:49,Correct me if I am wrong but doesn’t Adobe’s firefly helps you get around any copyright infringement reporting since the dataset is not on infringed content?
2023-05-17 16:21:06,"Yeah while possible in certain instances, that would be hard to do at scale. Thank you though!"
2023-05-17 16:25:46,"Yes and no, "
2023-05-17 17:11:47,https://www.sanctuary.ai/
2023-05-17 17:12:06,AI is at its peak i guess 
2023-05-17 17:25:48,Question: What are the best FOSS chat models which can be given personality with light finetuning or prompting?
2023-05-17 17:26:02,-cries in corner-
2023-05-17 17:26:25,Wait. Let me try this on my sarcastic chatbot
2023-05-17 17:26:40,Replicate had one where they trained on Simpsons
2023-05-17 17:32:50,Does anybody have a viewpoint on this- When does it make sense to give personality traits in the prompt itself vs using constitutional ai to direct the LLM to give responses in a certain style?
2023-05-17 17:33:19,Follow up question: What is Constitutional AI?
2023-05-17 17:33:24,"hmmm, seems so: https://docs.github.com/en/billing/managing-billing-for-your-github-account/one-time-payments-for-customers-in-india"
2023-05-17 17:35:29,Not foss sorry but davinci works better
2023-05-17 17:35:33,I am doing this 10 interactions deep. 2-3 interactions is dead easy. Starts breaking the 4th wall about 5-7 interactions deep. 
2023-05-17 17:36:14,"they are prompts which are given as pre-instructions before your actual prompt. they help in safety stuff (like no racist responses, etc etc)"
2023-05-17 17:36:22,"langchain has this to setup a set of principles which the LLM's responses should follow while giving a response. Although it's more so for not giving harmful or unethical responses, I was thinking that can't we use the same stuff for giving personality traits to the LLM as well?"
2023-05-17 17:36:59,Constitutional AI is by Anthropic
2023-05-17 17:37:04,https://arxiv.org/abs/2212.08073
2023-05-17 17:38:04,"FYI - constitutional AI will work very badly on models that are not RLHFed . because it wont know what ""ethics"" is"
2023-05-17 17:44:48,someone shared this link on this group itself a few days back- https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids
2023-05-17 17:56:01,"i dont think it says that. it says that if you retrain AI with constitutional AI responses (which are generated themselves from vanilla RLHFed AI), it gives a better Elo score of ethics."
2023-05-17 18:15:47,"If you've any working notebooks for this, please share?"
2023-05-17 18:24:35,Tinkering with it. Will do soon
2023-05-17 18:32:59,Lol
2023-05-17 18:33:01,What prompt are you using for this?
2023-05-17 18:36:37,Are there any collaborative ChatGPT interfaces? 
2023-05-17 18:50:35,Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?
2023-05-17 18:54:09,Off the Shelf for QA: https://github.com/gmpetrov/databerry
2023-05-17 18:54:40,"*Built on LangchainJS, not on Langchain Python"
2023-05-17 18:57:42,"I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this"
2023-05-17 18:59:55,Any opinions on steamship?
2023-05-17 19:00:33,What are multi message chats
2023-05-17 19:00:56,Is this what you are looking for?
2023-05-17 19:01:55,haha.. I mean chat which is multi-turn while QA is just single turn
2023-05-17 19:02:59,My question is more around serving
2023-05-17 19:07:35,The new chat models have an option to give a chat history.
2023-05-17 19:14:40,"If the serving is serverless without state, is it better to send history from client or from a cloud cache like elasticache?"
2023-05-17 19:17:02,The problem with sending state from client is latency over slow networks. 
2023-05-17 19:20:18,We built one on WhatsApp using Langchain agents with ConversationBufferWindowMemory which uses Redis for managing the last few messages context window.
2023-05-17 19:21:31,We’re using django & postgres - allows long term storage & you get a free ui for monitoring too.
2023-05-17 19:22:12,ya db query is a similar thought lot of people have
2023-05-17 19:25:47,You do have to do a bit of post maths after the query to figure out exactly how many tokens each msg is and fit accordingly
2023-05-17 19:26:42,">For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states."
2023-05-17 19:31:46,"I tried doing this for a chat bot, but did not find a way in langchain to persist summary along with buffer. So ended up implementing something like ConversationSummaryBufferMemory but where both Buffer and Summary were persisted in PG. Ended up writing my own python script."
2023-05-17 19:38:46,RedisChatMessageHistory which was the ChatMemory that we used in our ConversationSummaryBufferMemory (langchain classes) has a field called session_id.
2023-05-17 19:40:54,"I use both fastapi & django, deadly combo 🫣"
2023-05-17 19:41:31,Do you configure redis to have aways on disk writes?
2023-05-17 20:00:19,"For us, it’s just an in memory store - so we don’t do disk writes there. For persistent storage, we store the chats in mongodb."
2023-05-17 20:00:55,And load from mongo to redis on server restarts?
2023-05-17 20:02:46,Still need to implement this! 😅
2023-05-17 20:04:18,Curious why you wouldn’t just use mongo here
2023-05-17 20:04:32,Do you have that level of scale where mongo db won’t hold up
2023-05-17 20:05:54,Discord for eg used mongodb until a 100 million msgs https://discord.com/blog/how-discord-stores-billions-of-messages
2023-05-17 20:09:34,We are using a managed redis so we didn’t accommodate for edge cases such as a redis restart.
2023-05-17 20:18:40,What does FastAPI has to do with serverless?
2023-05-17 20:38:38,I think now they moved to Scylla DB. Which is way better than Cassandra.
2023-05-17 20:45:15,That's a great combination. 
2023-05-17 20:52:24,Retriver for the documents? np.array & cosine similarity
2023-05-17 20:59:11,Chad.
2023-05-17 20:59:25,What is next? You implement in numpy too?
2023-05-17 21:01:33,Cosine similarity ko NP.dot over unit vectors coz you know... Chad
2023-05-17 21:04:10,Appx Nearest neighbors and imagebind
2023-05-17 21:05:25,Numpy I trust 😂
2023-05-17 21:07:26,That's great... 😅
2023-05-17 21:07:51,"That word simplicity in that sentence is like, ""What am I doing here?"""
2023-05-17 21:09:27,😅
2023-05-17 21:13:20,Curious - are mordern vector dbs just in memory stores? Or do they implement vector search using clever indexes so they dont have to load everything into ram
2023-05-17 21:14:48,They implement techniques like hnsw. They optimize for speed and lose a little bit in accuracy
2023-05-17 21:21:36,Has someone built a model to summarize conversations in this chat group?
2023-05-17 21:22:05,You can see some of the community discussions here: https://nirantk.com/ai
2023-05-17 21:22:44,Question -: Anyone tried implementing self query retriever from Langchain. 
2023-05-17 21:25:13,Are you talking about this? 
2023-05-17 21:26:07,What metadata are you storing? If you can share some
2023-05-17 21:26:18,Did you try incontext learning? As in give an example of filters in the prompt?
2023-05-17 21:27:02,"If you want to filter on metadata in some way, Llama Index has native support for that: https://gpt-index.readthedocs.io/en/latest/how_to/query/second_stage.html"
2023-05-17 21:27:13,Alternatively you can use this
2023-05-17 21:28:26,"Metadata example -: 'area', 'price', 'locality', .... More 3 are there"
2023-05-17 21:33:14,"You can use the above solutions mentioned, or you can keep the ones you know it's getting wrong as a parameter that you receive for your function /api"
2023-05-17 21:38:20,Self query retriever uses Langchain construct and this is forming a wrong query that is being applied to the document.
2023-05-17 21:54:50,Is it just me or is gpt4 been having a lot of issues full day. Lots of failures
2023-05-17 21:57:49,Yes same issue we are facing.
2023-05-17 21:59:04,The python package that returns response of Google Bard through API.
2023-05-17 21:59:21,https://github.com/dsdanielpark/Bard-API
2023-05-17 22:01:10,Anyone tried it? How's the response ?
2023-05-17 22:49:16,"I have been playing around with langchain document loaders and some of these loaders are quite limited. For example, the Arxiv loader has a limit of max 4000 characters. To embed documents from arxiv, I am resorting to using a PyPDFLoader and then splitting the document using a splitter and then creating embeddings."
2023-05-17 22:49:54,Own regexes 🫣😭
2023-05-17 22:51:26,Not the reply that I was hoping for :P
2023-05-17 22:53:54,"+1, For arxiv documents specifically - I've written a lot of code to extract text from PDF and then removing unusable pieces & even using font variations to split properly."
2023-05-17 22:56:27,I use something like this - https://gist.github.com/roh26it/d1d7af2432175b443355990ec640b1d5
2023-05-17 23:02:44,has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P
2023-05-17 23:05:06,Some things only work on Pg essays…
2023-05-17 23:05:54,"haha, this is how we've all internalised his essays now :)"
2023-05-17 23:06:26,Doing things that don't scale xD
2023-05-17 23:07:46,"Hmm, elicit.org has amazing paper summarisation output. I've no idea what magic they do, but their beta is rad. I've abandoned my toolchain completely for wide paper reading (surveys) and single both."
2023-05-17 23:18:14,"Default loaders are decent, but a bit of pre processing is always good. Like use pyPDF for loading, but remove new lines and extra spaces by using TextPreProcessors. That saves embedding cost and has not much perf difference for retrieval."
2023-05-17 23:22:37,https://blog.google/technology/developers/google-colab-ai-coding-features/
2023-05-17 23:47:59,“We’re not planning to train GPT-5 for the next 6 months”
2023-05-17 23:49:16,Yeah cause gpt4 is so big that it can remember everything their human ops team teaches it for the next 6 months 😂
2023-05-17 23:49:45,This indicates that they've already trained GPT5. Not the other way around.
2023-05-17 23:49:55,GPT5 feels like Bahubali 2 to me now.
2023-05-17 23:51:57,"In Khan academy demo they mentioned they got access last year to gpt-4, so the actual state of the art must be way ahead?"
2023-05-17 23:52:26,I fear that might nuke GPT capabilities and only allow some sort of licensed usage given the tone of discourse here. They did this with GPS a long time back when the precision tech was only allowed to be used by the military
2023-05-17 23:53:04,Yeah but we don’t need satellites to recreate these things. GPU farm is enough
2023-05-17 23:53:21,And you can steal the satellites you can copy the weights
2023-05-17 23:53:26,*cant
2023-05-17 23:53:33,All these are doomed to fail
2023-05-17 23:53:40,"For something like GPT-4, we might need human farms more than GPU farms 😅"
2023-05-17 23:53:51,Also available. India is human farm
2023-05-17 23:53:58,Yep. This is needed
2023-05-17 23:54:25,Arre Arre Arre! 🤣
2023-05-17 23:55:38,Get all the unkils labeling data on their WhatsApp you’ll have data you need in few days
2023-05-17 23:56:13,But jokes apart this legit is a huge advantage we have if we use it well
2023-05-17 23:57:00,"Expensive one, philipines is cheaper"
2023-05-17 23:57:48,JioGPT - get ppl in villages to label stuff on their Jio phone
2023-05-17 23:58:06,but if you have to make indicGPT then you need people in india
2023-05-17 23:58:37,your ai has the median intelligence of your labeller
2023-05-17 23:58:55,GPT is bad at math. go figure
2023-05-17 23:59:01,Harder part will be RLHF to make sure it doesn't piss of politicians
2023-05-17 23:59:47,"But making like a Government GPT that can do all your taxes , forms , aadhar etc is actually a very good idea imo"
2023-05-18 00:00:04,"bhaiyo, behno , mai ek bhaasha model hu, scam mai nahi karta"
2023-05-18 00:00:12,You can nuke bureaucracy on a massive level
2023-05-18 00:00:21,"Is someone making BharatGPT ,?"
2023-05-18 00:00:26,I think i read somewhere
2023-05-18 00:00:33,Ai4bharat is
2023-05-18 00:00:34,Someone ask Nandan
2023-05-18 00:00:51,I also tried my training via lora on their dataset
2023-05-18 00:00:55,Aadhar authenticated plugins for all your govt work
2023-05-18 00:01:03,we need bureaucracy. just a little more efficient. bureaucracy chahiye democracy mai. otherwise it just becomes authoritarian completely.
2023-05-18 00:01:05,Payment via UPI
2023-05-18 00:01:41,https://corover.ai/bharatgpt/
2023-05-18 00:02:19,"India should do something about this whole AI, it's an opportunity"
2023-05-18 00:02:55,"plus, this might be a double edged sword but flexible regulations will help here"
2023-05-18 00:03:22,there's a lot of red tape for models like MPT etc being released as commerical in US instead of plain open source
2023-05-18 00:03:45,"In 2021 they had this DEEPMAX framework to evaluate AI and all an India framework, the whole licence system was talked about"
2023-05-18 00:03:53,IndiaStack should train foundation models
2023-05-18 00:04:06,"But i think the tech wasn't sophisticated back then, but it's now"
2023-05-18 00:05:03,"Koo launched one i guess, "
2023-05-18 00:05:11,Make govt apis available for plugins allow third parties to build and iterate UPI style
2023-05-18 00:05:12,they call it kooBERT
2023-05-18 00:06:28,cc Harsh [PHONE REMOVED] is the Head of ML at Koo
2023-05-18 00:08:02,"Koo you guys should make a foundation model, ditch the gov "
2023-05-18 00:09:37,https://caryn.ai/
2023-05-18 00:09:51,does anyone have  any idea to create a similiar bot like this ?
2023-05-18 00:10:11,where the the voice can also be cloned ?
2023-05-18 00:37:20,Noob question? What kind of data is in the medQA dataset
2023-05-18 00:37:36,like is it general medical QA
2023-05-18 00:37:56,or like stuff on more advanced diagnosis
2023-05-18 00:40:29,Mixed. It's based on USMLE — It's an exam you've to give to become a doctor in US
2023-05-18 00:41:05,Interesting
2023-05-18 00:42:01,I think LLMs will raise the standard of competency needed for the job
2023-05-18 00:56:08,"pretty cool, but Palm 2 is only available on private beta right now, correct?"
2023-05-18 00:56:46,"and i presume it also has the limit that open ai has with 4097 tokens, makes it harder to parse data, otherwise have to divide the data and stream which makes it more challenging"
2023-05-18 01:15:00,"The bison api on par with gpt3.5 based on personal experience, but not as good as gpt4. "
2023-05-18 01:37:12,i built 42papers.com but it's aimed at quick scanning daily
2023-05-18 01:38:11,also a side project so working on improving things it's a spider+gpt4+staticsite
2023-05-18 02:16:28,text-bison@001 has 8192/1024
2023-05-18 02:17:01,chat-bison is 4096/1024
2023-05-18 03:03:34,"Ah right, they updated token limit for text api this month"
2023-05-18 08:33:38,"Blinkit has started using gen AI to make receipes automatically. They are directly showing it to customers. Also, generates images using midjourney : https://twitter.com/albinder/status/1658821632008523777?cxt=HHwWgsDQmYnfqIUuAAAA"
2023-05-18 08:49:18,They use a custom model 
2023-05-18 08:50:18,Play.ht but don’t know the legality of it
2023-05-18 08:55:17,Can one of admins please add my colleague `+91 77605 75030` to this group?
2023-05-18 09:01:20,Done
2023-05-18 09:15:07,https://github.com/justinjohn0306/so-vits-svc-4.0
2023-05-18 09:58:46,Has anyone tried this out: https://www.tutory-ai.com/
2023-05-18 10:08:59,"If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?"
2023-05-18 10:11:35,Llamaindex will be easiest place to start
2023-05-18 10:12:20,"Ohh, I sound stupid now, haha🥲"
2023-05-18 10:14:11,Nahi nahi. 
2023-05-18 10:19:50,I'm not able to find them on plugins even
2023-05-18 10:36:04,Just out it curiosity - anyone here / in India doing research towards AGI?
2023-05-18 10:42:14,"""AGI is a feeling. Like love. Stop trying to define it."" - Andrej Karpathy"
2023-05-18 10:43:45,"Everyone has their own definitions of AGI, but this iisc research group has a few worthwhile projects n publications in the area"
2023-05-18 11:21:00,"If anyone's used the GPTeam repo extensively lmk. Having some weird issues running it locally, which start after a few mins of successful agent communication. Will DM for help."
2023-05-18 11:28:36,PSA: 
2023-05-18 11:37:04,"I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple."
2023-05-18 11:41:42,This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place
2023-05-18 11:42:44,https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html
2023-05-18 11:42:53,"Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023. "
2023-05-18 11:43:30,Do you mean something like this? https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443 (paywall)
2023-05-18 11:45:35,Not always an issue with json type data. Happens with agents with some expected format as response.
2023-05-18 11:45:48,+1 to guardrails. I've this running as my json extracter in two projects on prod.
2023-05-18 11:46:07,Conversational agent expects a response starting with
2023-05-18 11:46:53,Where can you apply for access for the apis?
2023-05-18 11:56:51,"Not exactly. So this would work really well for qa retrieval over a simple text doc, right?"
2023-05-18 12:00:10,"> But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble."
2023-05-18 12:01:15,"And just to zoom out a bit, this is an empirical domain, not intuitive or theory (and definitely not in the _best practices_ era) —  so whatever solutions we share have a half life of max 6 months"
2023-05-18 12:12:16,"Yeah that's fair. I was just wondering if anyone has worked with something like this before, so I could leverage those learnings"
2023-05-18 12:13:30,"So when you query the DB for a semantic match, it often throws up a completely irrelevant endpoint to the task. Sometimes even from the wrong tool"
2023-05-18 12:17:28,have u tried jsonformer or RELLM ? would love to know ur opinion
2023-05-18 12:19:12,"Not related to generative AI, but NLP"
2023-05-18 12:19:32,ReLLM and JSONFormer ideas are now both part of Guardrails as a lib now? 
2023-05-18 12:20:27,Oh I didn't know that. Intresting
2023-05-18 12:20:48,Which one of the two works better in general?
2023-05-18 12:20:56,"I am also asking, I saw a discussion around this. ReAsk is definitely there. I've used it"
2023-05-18 12:23:25,RLHF Karna padega 😁
2023-05-18 12:27:45,I've not fully read it through.
2023-05-18 12:29:35,"FYI, Rohit [PHONE REMOVED] and I were discussing this. Looks like JSONFormer doesn't work with OpenAI Chat models (3.5-Turbo and GPT4) because they have a logit bias while JSONFormer uses Logits."
2023-05-18 12:31:00,Mid journey how??
2023-05-18 12:31:50,Unofficial APIs perhaps? https://midjourneyapi.io/
2023-05-18 12:33:03,"Wow, and is this using a discord bot to get the image from mj discord bot? 😂"
2023-05-18 12:36:48,Ok albinder definitely needs to have a chat with his team before tweeting
2023-05-18 12:37:23,LOL
2023-05-18 12:38:40,https://blinkit.com/blog/recipe-rover
2023-05-18 12:39:56,Yep! I’ve been planning on adding constrained decoding for general grammars in guardrails.
2023-05-18 12:42:26,What breaks Cohere?
2023-05-18 12:49:51,No access to logits
2023-05-18 12:50:22,I didn't know that they removed logits too 😔
2023-05-18 12:50:27,This would break in the chat models as well I think
2023-05-18 12:51:16,Yeah I think this may have been recent. They updated a few of their models
2023-05-18 12:52:38,"I think OpenAI is working on their own language called ""ChatML"""
2023-05-18 12:53:12,-yeah. New models. Much better at RAG.
2023-05-18 12:53:47,To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually 😁
2023-05-18 12:54:48,"All roads converge to a Programming language. At this point, both TF and PyTorch are programming language pretending to be a framework anyway"
2023-05-18 12:55:02,I have a feeling a simpler trade off is to just use regexes. 😁
2023-05-18 12:55:34,Higher level framework can compile into regexes and send to backend provider. Regexes are very easy to support
2023-05-18 12:56:22,Perhaps a slight syntax tweak to control temperature etc for each regex.
2023-05-18 12:57:21,"Context free grammar etc is cool but most specific JSON you need can be expressed as key , value regex."
2023-05-18 12:57:23,https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags
2023-05-18 12:58:21,I know this but this answer is misleading. Yes regex cannot parse it in general. But for specific scenarios they can work. And we are often trying to generate some specific and simple JSON
2023-05-18 12:58:37,I have parsed HTML using regex many times 😁
2023-05-18 12:59:08,Yes this . “Worse is better” Unix philosophy of design.
2023-05-18 12:59:51,"it seems to me that openai wants us to have less access to logits, etc and wants to do everything via few shots."
2023-05-18 13:01:39,"Logit sharing is more high level. You cannot constrain in the middle of a generation unless you call the API many many times for even simple things. So it’s probably not the way for JSON etc. you need some way to share a grammar , regex , program"
2023-05-18 13:01:54,It just adds too much latency and cost
2023-05-18 13:03:03,This is also an advantage of open models. You can do lot of innovation around sampling
2023-05-18 13:03:16,fair point. cost is always a thing.
2023-05-18 13:04:17,"but i think in the long run, having a custom NER model doing the extraction might be the best tradeoff of cost vs accuracy. dont bring in the LLM at all."
2023-05-18 13:05:24,Yes so the way I try to explain this to ppl is 
2023-05-18 13:06:02,Earlier it was hard to tell if ML had business value because each model for a task was expensive. Now you can find PMF quickly and then optimize
2023-05-18 13:06:29,Infra around this is an excellent startup idea if anyone is looking 😁
2023-05-18 13:07:25,Sandeep eager to hear your thoughts on this
2023-05-18 13:09:42,Has anyone here stumbled across any projects which does federated decision making by multiple role playing agents?
2023-05-18 13:34:12,Looking for suggestions on opensource models that are good at writing sql queries based on provided question and schema. Has anyone worked on this? I am looking for collaborations as well if anyone interested.
2023-05-18 13:50:00,"Anyone who did computer science in college. There was a course, theory of computation. And it basically started with every language started as something similar like just regex"
2023-05-18 13:50:45,To note. The udacity course on this was much better
2023-05-18 14:55:47,What is the biggest GPU size you guys have used for training/fine tuning model? We are using 64GB and still running out of memory. Would highly appreciate any help in the regard .
2023-05-18 14:59:44,Which model are you training ?
2023-05-18 15:00:08,Lora Adapter
2023-05-18 15:03:55,"not tested with open source models, but there's guardrails for sql generation that perform validation for a specific db schema and have a few other tricks for good performance http://getguardrails.ai/use_cases/text2sql/text2sql/"
2023-05-18 15:24:42,Which is supposed to be super super small but dont know whats wrong.
2023-05-18 15:36:12,Hey! 
2023-05-18 15:38:48,Thanks! 
2023-05-18 16:02:50,"Hey, is there anyone here who can help with converting a vision transformer model to tflite?"
2023-05-18 16:35:03,"When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha"
2023-05-18 16:48:44,"PSA: Please DM mods for Invite links instead of sharing phone numbers of your friends. If you do that, I'll add your friend's number to Bajaj Finance, Yes Bank, Policy Bazaar."
2023-05-18 16:49:00,"I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string 🤔"
2023-05-18 16:50:49,I think this blog might be useful for you - https://medium.com/llamaindex-blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6
2023-05-18 16:51:03,Do you just want relevancy scores or an answer? 
2023-05-18 16:51:11,No need to touch Llama Index or Langchain
2023-05-18 16:53:52,https://github.com/saschaschramm/chatgpt#gpt-35
2023-05-18 16:55:11,Just relevancy scores
2023-05-18 16:57:05,So it is different from what’s provided through the api? (GPT 3.5 vs GPT 3.5 Turbo)
2023-05-18 17:06:46,Only as much as is mentioned there in the link:
2023-05-18 17:07:11,"Got it, thanks!"
2023-05-18 18:57:40,"Anyone working here on gpt 4 api, could you help me with right max_token value which will make it generate the longest possible response without hitting error. I see the it's sum of input plus output. But the documentation is a bit unclear on limits.."
2023-05-18 18:59:19,8096 for input + output tokens
2023-05-18 18:59:34,32k if you have access to that version
2023-05-18 19:00:52,Giving 8k as max token errors out if I want to generate a 3k word story. With a input in 2 lines.
2023-05-18 19:01:26,2k output. Over that errors can occur
2023-05-18 19:02:24,If you want a lot of output you need to be creative. But at one go it hangs over 2k output and timeout after 4k output tokens
2023-05-18 19:02:27,"You have to calculate the input size using tiktoken, subtract it from 8k/4k"
2023-05-18 19:03:05,Interesting - on the streaming api too?
2023-05-18 19:03:19,Oh dint know this. Same rule for 32k?
2023-05-18 19:03:24,Not to mention horribly slow
2023-05-18 19:03:30,This too. Also you need to take into consideration that one token is different in different languages
2023-05-18 19:03:37,Yes
2023-05-18 19:03:50,"Yup, cause the limit is for input + output. So if your input is big, then it will throw an error"
2023-05-18 19:05:04,It takes ~50x time to generate a token than ingest an input token
2023-05-18 19:05:28,Similar findings
2023-05-18 19:06:00,Also the more you generate the more you hallucinate
2023-05-18 19:25:16,Basic question- I want to train a model locally on all my emails and documents. What’s the best way to do it nowadays. Lora? Gpt4all? Something else? I’ve never trained a model locally so I’m a bit uncertain about this. (Also I don’t genuinely care about “worldly knowledge” being part of the model but it doesn’t hurt)
2023-05-18 19:35:55,https://github.com/imartinez/privateGPT
2023-05-18 19:44:45,"Thanks, quite useful. Still, curious if we can train / fine tune a model locally."
2023-05-18 19:45:02,TEAM is organising a Hackathon for GenAI in Mumbai on 3rd and 4th June (Saturday & Sunday)
2023-05-18 19:54:22,Is there any other better option for long form content generation
2023-05-18 20:00:05,approach in a similar approach to how you would do on the playground
2023-05-18 20:00:19,continuous generation via different calls
2023-05-18 20:00:35,but you need to make sure your input+output is between the token limit
2023-05-18 20:27:11,https://www.cnbc.com/amp/2023/05/18/bilderberg-openai-microsoft-google-join-ai-talks-at-secretive-meeting.html?__source=instagram%7Cmain
2023-05-18 20:49:19,[PHONE REMOVED] [PHONE REMOVED]
2023-05-18 21:06:48,Does anyone know how to force copilot to generate something when you're in the middle of a line / start of a line? It only seems to complete if I'm at the end of a line.
2023-05-18 21:07:19,Threaten it 😂
2023-05-18 21:08:33,"I think there was a shortcut key for copilot generations, tried it?"
2023-05-18 21:08:44,doesn't generate anything
2023-05-18 21:22:08,https://twitter.com/peterjliu/status/1659023597447565312?s=46
2023-05-18 21:29:05,"Ohh one of the co-authors is a college acquaintance, let me ping him!"
2023-05-18 21:30:24,The may not need humans part seems hard to believe
2023-05-18 21:31:20,I thought RLHF stood for RL with human farms 😂
2023-05-18 21:46:20,We really need an opensource copilot that works off any llm API key  (use the langchain API wrapper  maybe)
2023-05-18 21:48:19,Have you tried Codeium? Not open source though
2023-05-18 21:48:29,I have been using it of late
2023-05-18 21:48:53,It has chat in IDE as well
2023-05-18 22:16:22,"Team, validating my following rudimentary understanding of opportunity for any company using LLMs!"
2023-05-18 22:18:05,Is this understanding correct?
2023-05-18 22:32:40,"Yes, plus collecting human feedback to later pipe back into your data / rlhf"
2023-05-18 22:37:07,Anyone used Lang chain or embeddings on bigger text data? How do you pass say 20 pages (or embeddings) from a repo of books to have accurate summarized snippets considering gpt 4 token limit?any other alternatives?
2023-05-18 22:39:30,"For summarisation, you can consider Map-Reduce/Combine or Refine: You can see some of the community summary here: https://nirantk.com/ai — they're all done that way. You can also create chapter/section specific summaries and concat"
2023-05-18 22:42:27,make sure you respect this limit too
2023-05-18 22:43:03,Code for the Langchain summarisation
2023-05-18 22:51:46,Have tried it not even close to Copilot
2023-05-18 22:52:10,https://openai.com/blog/introducing-the-chatgpt-app-for-ios
2023-05-18 22:52:19,Not available in India still though
2023-05-18 23:05:23,"Logits would allow others to distill the models, so we should expect them to go away eventually in most commercial LLM APIs which are deemed valuable. OpenAI and cohere have already taken it off the table."
2023-05-18 23:19:10,Is it possible they might want to do an on-device LLM ? 
2023-05-18 23:20:37,I don't understand why would an iOS app come before an android app :/
2023-05-18 23:25:36,“Google” it
2023-05-18 23:26:54,"P.S. Android users, you're next! ChatGPT will be coming to your devices soon. Pretty obvious :) (Unless windows phone is making a comeback)"
2023-05-18 23:30:59,"The IOS app looks bit wonky , the speech recognition is dead , throws error. They could have used iOS's built in recognition ~, but they wanted to use Whisper apparently ."
2023-05-18 23:31:16,This never works for me
2023-05-18 23:32:03,2nd point 😂😂
2023-05-18 23:32:03,Also usually ios people are tech deprived. So possibly trying to expose them to new technology 😁. Iphone people please don't take come with pitchforks
2023-05-18 23:32:06,These cases started working for me just a couple of days ago. But I also did move from python to typescript in that time
2023-05-18 23:33:16,More difficult for apps for ios to be approved implies ios app releases first 🥴
2023-05-18 23:35:48,Makes sense ngl
2023-05-18 23:51:54,[PHONE REMOVED] any results?
2023-05-19 00:19:41,"guys anyone can please guide , which is best Llm for translation task?"
2023-05-19 02:13:31,Detailed report from EU for AI safety standards in aviation:
2023-05-19 06:48:55,https://colab.research.google.com/drive/1Icoxgd2IJAjMU2fyD-MET5a706HGpwVg?usp=sharing
2023-05-19 07:02:09,"Hey [PHONE REMOVED],"
2023-05-19 07:06:33,You can try ctrl+enter - this would ideally force it to respond
2023-05-19 07:59:03,Which company?
2023-05-19 08:32:57,https://tome.app/ - https://twitter.com/jasonyuandesign/status/1659317627208998914?s=20
2023-05-19 08:36:02,Seems like he'll bring MercuryOS to life
2023-05-19 09:20:17,Have seen this where companies based out of US release their 1st app on iOS than android. E.g. Insta / Snapchat
2023-05-19 09:21:53,"It is known statistics here that iOS users pay more. Also, in US they say no one important uses Android. 🤣"
2023-05-19 09:23:28,iMessage is the culprit for it
2023-05-19 09:23:59,But chatgpt is free (or is this a sign) :(((((
2023-05-19 09:24:22,people text you on imessage (not whatsapp) and make facetime calls
2023-05-19 09:24:28,Get more plus users
2023-05-19 09:24:40,Ah
2023-05-19 09:26:39,Also what's with gpt-4 browsing? Most times I try it says click failed or something like that. Is there a specific way to prompt that model?
2023-05-19 09:26:43,"True. Also, general folks care less about installing apks and trust Apple to take care security and privacy."
2023-05-19 09:27:14,robots.txt
2023-05-19 09:27:36,At the current stage a gpt extension on the site is doing better than gpt-4 browsing in terms of summarisation
2023-05-19 09:29:03,They are probably going to remove that bad browsing UX and start indexing like good soon.
2023-05-19 09:29:10,*google*
2023-05-19 09:29:18,Oh. So gpt-4 is crawling sites... wouldn't it get blocked by cloudflares are you human as well
2023-05-19 09:29:31,For those sites where it's enabled?
2023-05-19 09:30:24,"They published an article about this recently, you'll have to search Twitter for more details."
2023-05-19 09:31:03,Sure. Thanks!
2023-05-19 11:07:21,"Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc."
2023-05-19 11:17:55,I follow Nick from twitter. He has good command over that
2023-05-19 11:18:18,Thanks
2023-05-19 11:20:14,Profile pls
2023-05-19 11:24:59,https://twitter.com/nickfloats?s=21&t=slFa1z9kP5GT6uvB_oz7cw
2023-05-19 11:25:31,https://docs.google.com/spreadsheets/d/1MsX0NYYqhv4ZhZ7-50cXH1gvYE2FKLixLBvAkI40ha0/edit#gid=0
2023-05-19 11:26:13,Great thankyou
2023-05-19 11:27:16,https://docs.midjourney.com/docs/prompts
2023-05-19 12:10:00,Nick's threads are great. 
2023-05-19 13:53:08,Operating G-mail using brain waves and ChatGPT https://www.araya.org/en/publications/news20230512/
2023-05-19 13:58:58,"On a similar note, there’s a startup called Neurosity which creates consumer grade “crowns” that can be used to control and build stuff using brain waves."
2023-05-19 14:01:50,A guy used it to control a Tesla: https://youtu.be/BDYdWoaa6g0
2023-05-19 15:15:47,https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android
2023-05-19 15:15:51,This is next level
2023-05-19 15:16:41,"They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!"
2023-05-19 15:17:27,"Yea, but we know what all can be achieved"
2023-05-19 15:18:26,"I guess due to extreme competition, companies are avoiding releasing much information about their research. Google and Openai have already started"
2023-05-19 15:19:04,"This is not a company, its the Max Plank Institute in Germany, where I did my PhD from"
2023-05-19 15:31:52,I see
2023-05-19 17:15:53,Going viral on Twitter 🥸
2023-05-19 17:32:49,Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/
2023-05-19 17:34:03,"They said going to release in June, probably after paper is published in SIGGRAPH"
2023-05-19 17:34:45,What are the odds someone will implement this before that :P
2023-05-19 18:29:20,Won't we also need a pretrained model to get these results?
2023-05-19 23:37:13,anyone looking into https://github.com/microsoft/guidance
2023-05-19 23:37:57,cc Ravi [PHONE REMOVED] did you get a chance to go deeper into this?
2023-05-19 23:41:14,Yes. Output is saved in the key “chapter”
2023-05-19 23:50:20,what is the prompt used by {{gen}} is it just everything generated upto the point of the {{gen}} call ?
2023-05-20 00:16:42,Any idea how we can generate a prompt dataset with openai and llama index given an article ?
2023-05-20 00:20:46,What do you mean by prompt dataset here?
2023-05-20 00:21:10,"Question and answer, a format similar to what alpaca needs"
2023-05-20 00:22:54,There is question generation module which you can use to create questions and use index and query to generate answers.
2023-05-20 00:24:41,Thanks for your reply . Any links sources that I can learn from?
2023-05-20 00:25:27,https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html
2023-05-20 00:26:53,"Yup, that’s why the “sequential execution”"
2023-05-20 00:32:21,I also found https://lmql.ai/ a lot easier to understand and try out in their neat little playground
2023-05-20 00:32:55,Hot take - though I think even this could be simpler it’s better than guidance
2023-05-20 00:33:28,Haven’t tried either just from a simplicity POV
2023-05-20 00:33:40,I spent 10-15 mins on guidance got confused and gave up 😁
2023-05-20 00:43:16,If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ 🤓
2023-05-20 00:44:00,Their entity extraction utils are truly neat
2023-05-20 00:45:06,And with pydantic support 🤯
2023-05-20 00:45:32,this is actually pretty neat! wow
2023-05-20 00:45:43,"Yeah. That's what makes them neat. I eventually switched to Guardrails because they've ReAsk, making it more reliable"
2023-05-20 00:47:12,https://www.askmarvin.ai/guide/concepts/plugins/
2023-05-20 00:50:32,This is cool
2023-05-20 00:52:00,This is probably the best way to use LLMs
2023-05-20 00:53:13,It's taking too long. Is that the right behavior. I just have one pdf file with 4 pages.
2023-05-20 01:26:28,also they are not really clear that this might end up costing a lot more with hosted llms like openai than a single pass execution. nor would some of the token rewind stuff work
2023-05-20 07:12:52,Yup saw AI functions for the first time in AutoGPT. Found the concept super interesting.
2023-05-20 07:13:11,They come from here. 
2023-05-20 09:46:45,"hey folks, is there already any sophisticated method to do unit tests like things for functions powered by LLMs?"
2023-05-20 09:47:14,have you come across a js/ts impl of these
2023-05-20 09:49:17,one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts
2023-05-20 09:49:21,"btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp."
2023-05-20 09:49:59,is 100k free per month?
2023-05-20 09:50:16,"just have to make sure JS websites are excluded otherwise you'll just get ""couldn't get data because page blocked you"" and some html tags cases"
2023-05-20 09:55:46,interesting how did you make it so it checks everytime a commit is made?
2023-05-20 09:57:36,i manually run the tests but yes that would be a future flow once i have the git actiosn setup
2023-05-20 09:58:15,Git Pre Commit has entered this chat
2023-05-20 10:04:40,Ah thanks for this! Kept running into SERPs free limit
2023-05-20 10:09:37,"Hey guys, can anyone tell which model is being used for image generation by Bing ? "
2023-05-20 10:23:45,"Based on DALL∙E, could be a next gen model, but probably finetuned."
2023-05-20 11:35:02,has anyone been playing with integrating OpenAI (or other llm) in stuff like customer support chatbots in actual production ? 
2023-05-20 11:47:16,How does AWS Kendra compared to LLM tools ?
2023-05-20 12:11:00,Kendra is more of an info retrieval system.
2023-05-20 12:15:43,I see. But does it do well?
2023-05-20 12:16:38,Can you not combine a retrieval system with a generation system
2023-05-20 12:17:08,Whats your task?
2023-05-20 12:17:58,"Hi , "
2023-05-20 12:18:28,Enabling helpdesk guys to look at past data and suggest resolution for new support queries.
2023-05-20 12:18:33,Yeah there has been some progress in this area.
2023-05-20 12:18:45,Yes
2023-05-20 12:19:15,You have to just specify it as a tool and the agent will decide whether to use it or not
2023-05-20 12:19:51,They can. But they can be pretty bad at deciding when to not search. You'll have to put the boundaries properly in the prompt if you wanna enforce cases where you don't want it to search
2023-05-20 12:20:36,So my question for you is:
2023-05-20 12:22:20,is this to optimize serpapi calls for cost ?
2023-05-20 12:22:30,"oh , so instead of action agents , i'll need a custom one ."
2023-05-20 12:22:35,yep
2023-05-20 12:23:10,"+ latency, serp is usually not as fast as google"
2023-05-20 12:24:18,"Kind of. But you don't need the whole thing to be custom, you can just get the prompt template from codebase, append your guardrails and pass that instead"
2023-05-20 12:24:58,Preferably later. 
2023-05-20 12:28:12,Every business will have domain specific details which are not generic and usually could be present in set of documents that were ingested by system.
2023-05-20 12:29:16,For this you need a LLM.
2023-05-20 12:29:37,Step 1: use kendra to get your relevant docs
2023-05-20 12:29:53,Step 2: with relevant docs as context
2023-05-20 12:30:00,Answer client query
2023-05-20 12:30:40,"Step 3 : let human verify to override the response and of response is edited, would that be fed back to Kendra or LLM ?"
2023-05-20 12:30:52,Maybe you wdnt need a giant LLM for this. Cheaper ones would do.
2023-05-20 12:33:00,It cant goto Kendra from my understanding.
2023-05-20 12:34:07,"If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?"
2023-05-20 12:34:57,That's why you combine both
2023-05-20 12:35:19,Yup use the docs as context for LLM
2023-05-20 12:36:16,OSS?
2023-05-20 12:36:16,I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.
2023-05-20 12:36:27,Open source software.
2023-05-20 12:36:29,np.array to store embeddings of the docs
2023-05-20 12:37:11,Maybe going for paragraphs might be better.
2023-05-20 12:37:39,Yes..I meant that. Chunk your docs always
2023-05-20 12:38:18,"Also if the docs are pdf, ppt, etc "
2023-05-20 12:38:27,Given the variety of tech present what's the pattern of tools that could be leveraged.
2023-05-20 12:39:00,You can always develop a chunking strategy.
2023-05-20 12:39:06,I think for a POC do what your engineering team is familiar with.
2023-05-20 12:39:27,Dont make ppl learn web frameworks for a POC. 🥲
2023-05-20 12:39:36,Even that needs to begin somewhere. Imagine clean slate.
2023-05-20 12:40:05,Web framework was just a analogy
2023-05-20 12:40:18,Python + Flask
2023-05-20 12:40:52,I would use it for a simple POC on a browser.
2023-05-20 12:43:41,I'm not talking about REST.
2023-05-20 12:44:28,"X, Y, Z, Q could be combination of some python libs and chat gpt "
2023-05-20 12:46:12,Or may be we are in metamorphosis phase where such patterns and stacks are yet to appear and stabilize.
2023-05-20 12:49:01,"I have hopes from only one person, simon willison"
2023-05-20 13:56:36,Guess what I’ve been thinking about for months 😁
2023-05-20 13:59:11,A lot depends on the available budget for each case and the complexity of the queries that need to be answered.
2023-05-20 14:00:13,LLM can definitely play a powerful role here
2023-05-20 14:01:09,Can design LangChain agents to act as fast assistants to help desk staff
2023-05-20 14:01:58,actually - thats a very interesting question. how does one get LLM to look at *past data* and use that to suggest resolutions ? lets say we pump all this stuff into a vector db as well. is there any prompts/chain-of-thought that does this ?
2023-05-20 14:02:37,No I don’t think that works beyond the most basic queries
2023-05-20 14:03:46,What you want to do is build a combination of GitHub copilot / openAI plugins for the support staff.
2023-05-20 14:04:06,In spirit like not literally tbc
2023-05-20 14:04:24,Then you keep gathering data and improving
2023-05-20 14:04:49,Once you have enough you start fine tuning / RLHFing ..
2023-05-20 14:06:35,But ppl want fast easy solutions which I don’t think exist yet. This requires lots of careful engineering and planning.
2023-05-20 14:12:07,This new research is incredible.
2023-05-20 14:21:57,Combining with diffusion models can give some awesome workflows
2023-05-20 14:27:14,https://www.reddit.com/r/ChatGPT/comments/13lqm1s/chatgpt_describe_a_world_where_the_power
2023-05-20 18:04:09,Hi folks 👋
2023-05-21 00:33:13,"I am currently working on performing QA retrieval over an existing FAISS index using the load_qa_with_sources_chain module in Langchain. I was wondering if there are any open-source, LLMs supported by Langchain that can serve as alternatives to OpenAI's models without requiring any authentication(i.e. OpenAI API key). Does anyone have any experience or recommendations for deploying such models in a production environment?"
2023-05-21 00:39:59,huggingface supports open source models through langchain. No experience of using them though https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html
2023-05-21 02:51:56,Did anyone try loading llama 7b with alpaca and was successful in converting llama weighs to hugging face transformers?
2023-05-21 03:13:49,"Most of these are too slow, or do not generate a meaningful response :)"
2023-05-21 03:17:17,"Surprisingly the Q/A models cannot be used with the QA_chains in Langchain, pretty weird"
2023-05-21 05:12:50,"Team, I am sure versions of these exist out there:"
2023-05-21 05:20:04,I think it matters where these places are - Google drive? Notion? A file on someone’s computer?
2023-05-21 05:21:04,"I have a out 50-75 pdfs through my access to seismic, then some google sheets, some notion docs yes, some ppts"
2023-05-21 05:21:18,All of these files i have in my computer :)
2023-05-21 06:43:45,Are you keen on writing code? 
2023-05-21 07:02:29,Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?
2023-05-21 07:22:01,"Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS."
2023-05-21 07:23:31,"For most projects like the one which Rohan [PHONE REMOVED] bhaiya is trying, OpenAI + Redis would work better perhaps? Most tech teams already use Redis, so any questions are answered in 5 minutes vs 3 days."
2023-05-21 07:25:44,"Related Q: how do I compare  the embeddings like intuitively, like what are the modalities where one embedding “gets it” and other doesn’t"
2023-05-21 07:29:28,Not at all actually. I want to cut out as much help required from others.  Willing to put 20 days haha
2023-05-21 07:29:56,"But if openai tells me step by step here is the code. Here is how you deploy, that’s something on me."
2023-05-21 07:32:36,Check this and this was done using embeddings. How do I do this on my own?
2023-05-21 07:33:56,"Yeah, so tools like the one which I linked to do use embeddings + some stores under the hood. They're a neater wrap on this ofc."
2023-05-21 07:34:15,Neater → Easier to use here
2023-05-21 07:37:39,You mean you’re developing something of this sort? 
2023-05-21 07:40:38,"I've not seen a single guidebook of sorts, but it should, you're right!"
2023-05-21 07:43:17,What do u mean by that ? For e.g. the mpt chat model won't work with langchain qa chain ?
2023-05-21 07:45:45,Damnnnn. So this a good challenge to solve and touch code in some form 🤣
2023-05-21 10:09:12,what are the most authortiative books on prompt engineering yet?
2023-05-21 10:16:16,We've discussed this quite a bit in the past. You can see some of the community discussions here: https://nirantk.com/ai
2023-05-21 10:18:49,Advanced User Guide for prompts: lilianweng.github.io/posts/2023-03-15-prompt-engineering
2023-05-21 10:18:53,Thank you thank you. Sorry for the spam haha
2023-05-21 10:19:57,"You can't reliably do this by asking OpenAI which has a knowledge cut-off date of sep21. Their is some post-sep21 data leakage due to RLHF, but it won't be reliable for building something like this."
2023-05-21 10:20:37,Basically the non coder in me who got D grades all my life is not going to feel happy anytime soon 🔜
2023-05-21 10:24:05,"I think Chroma is the easiest to build something like this with, and its default guides should be good enough for you (if not, come back here and let us know). I would not recommend that for production though, and you should probably talk to [PHONE REMOVED] if you're ready to take something live."
2023-05-21 10:25:08,"Ok. That’s quite, helpful. Thank you 🙏🏻"
2023-05-21 11:25:40,Tanmay Bhat tweeted a sequel to the last harry potter book. Generated of course. 
2023-05-21 11:32:45,Maybe GRRM can use GPT to finally finish his books...
2023-05-21 11:33:33,God save the old man
2023-05-21 12:17:24,This is a repeat pattern.
2023-05-21 12:17:44,.
2023-05-21 12:17:55,Seems the most common use case
2023-05-21 12:33:10,https://learnprompting.org
2023-05-21 12:41:58,Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.
2023-05-21 12:44:15,Depends on the websites
2023-05-21 12:44:16,What website was it
2023-05-21 12:44:58,yes it mostly fails 
2023-05-21 12:46:34,G2 reviews are not easily scraped. It seems the scraper isn't working the one they're using at openai
2023-05-21 12:55:09,I've tried a lot mostly github repos & documentations
2023-05-21 12:55:25,Yes they are hard to scrape
2023-05-21 12:59:08,Quota github LinkedIn are hard to scrape sites
2023-05-21 12:59:23,Quora*
2023-05-21 13:14:27,Yes facing the same issue since yesterday
2023-05-21 13:27:13,What are you trying to scrape and search exactly? There might be some tools that might work better for you
2023-05-21 13:30:50,https://nianticlabs.github.io/implicit-depth/index.html
2023-05-21 13:37:42,just wanted to summarise some articles..its not able to open any links
2023-05-21 13:38:14,Is it one of these
2023-05-21 13:39:08,https://studio.ribbonfarm.com/p/text-is-all-you-need
2023-05-21 13:42:07,weird. it can be scraped
2023-05-21 15:17:04,Was able to get quite a few models to work with langchain that are not OpenAI ones.
2023-05-21 15:18:44,Tanmay again with Lagaan 2
2023-05-21 15:19:31,Hi. Do u have a piece of code that does this ? Especially for mpt7b chat ? It didn't entirely work for us.
2023-05-21 16:02:07,Any suggestions on where to buy used 3080/3090 gpus? Is gameloot safe or it's like quick/olx?
2023-05-21 16:22:38,What are the trade offs if you use redis vs a custom vector store
2023-05-21 16:22:59,Redis seems to also use undelivered
2023-05-21 16:23:06,Hnswlib
2023-05-21 18:20:07,https://blog.google/technology/research/project-starline/
2023-05-21 18:30:06,https://twitter.com/samsja19/status/1659953297011224579?t=OA2QYLUDLKfqCvCdjTFuGQ&s=08
2023-05-21 18:31:00,(doesn't matter if you believe LLMs are purely stochastic parrots)
2023-05-21 18:33:01,Thought this might be interesting to you 
2023-05-21 18:33:54,"Thanks, yes"
2023-05-21 18:35:25,"I meant, the post I shared doesn't matter... Not that your beliefs don't matter 😀"
2023-05-21 18:38:17,Hot take: doesn’t matter even if they’re purely stochastic parrots casue they’re so damn good at it
2023-05-21 18:40:13,"Not an interesting take at all, sorry"
2023-05-21 18:40:34,"As a language model trained by OpenAI, I cannot comment on whether this is philosophy or not. But it it is, we've a thriving *AI and Philosophy* WA group which discusses everything from Roko's Basilisk to Godel, Escher and Bach. "
2023-05-21 18:42:04,Had tried so long to stay away from philosophical discussions around LLMs
2023-05-21 18:43:13,"Is this similar to smartgpt, where you essentially sample multiple outputs and then ask it to reflect on all of them independently and select the best one"
2023-05-21 18:43:19,You check G2 robots.txt. I think ChatGPT browser plugin owner website's robots.txt file. https://www.g2.com/robots.txt
2023-05-21 18:55:10,"Btw, I'm not sure about the overall point being made.The reason I can't make up my mind is because - can the slow verbal reasoning, which humans can't make very fast, be made fast with a faster model? And how is it going to be qualitatively different?"
2023-05-21 19:01:10,They just show a framework to generate multiple actions/thoughts - they are evaluating these thoughts in two ways - where LLM evaluated each thought and assigns a score or LLM looks at all the thoughts and generates comparisons. But we can use lots of other mechanisms to select the best one as well. Like another trained neural network or set of Lora weights which are trained using RL/ planning hybrid methods.
2023-05-21 19:05:02,openai has rlhf data for reflexion and evaluation - they have human labellers doing this - so they probablyhave that rl/planning in built
2023-05-21 19:07:34,Didn’t we have a jee working group here? Did you guys end up doing something like smartgpt or tree of thought to get better perf?
2023-05-21 19:09:07,Complete speculation on my part - But it feels like GPT4 has some sort of internal planning module as well which makes it absolute beast with reasoning.
2023-05-21 19:15:43,https://youtube.com/shorts/H1sXIUbpRCU?feature=share
2023-05-21 19:17:02,"very likely not, at least not mentioned in their paper."
2023-05-21 19:20:37,They haven’t mentioned anything in the paper except it’s a transformer model ..but maybe not. It feels easier to attribute reasoning capabilities of GPT4 to planning and ability to backtrack than just next token prediction.
2023-05-21 19:22:10,"I’d imagine a 1T model learn some first order logic at least., this follows from the argument that emergence is a function of scale"
2023-05-21 19:22:32,what kind of reasoning are u talking about + any papers in nlp or adjacent fields to back it up
2023-05-21 19:22:53,at least in robotics the planners i’ve seen are very domain specific
2023-05-21 19:31:31,I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4’s reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.
2023-05-21 19:32:17,you’re hugely underestimating the potential of scaled networks
2023-05-21 19:32:58,you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex
2023-05-21 19:33:22,"plus the amount of github code it was trained on, it would be excellent at basic coding"
2023-05-21 19:33:46,"i can’t get it to write good c++ or cuda code, even like 100-200 line scripts"
2023-05-21 19:34:08,makes me think it’s more of a data exposure thing than a reasoning module
2023-05-21 19:34:30,This is literally not true
2023-05-21 19:35:13,"If that’s the case, it’s probably much more exciting .. then we will get much better augmented LLMs soon."
2023-05-21 19:35:33,why not
2023-05-21 19:35:39,what else is different
2023-05-21 19:35:43,pretty bad at anything that’s slightly novel. But good for exploring ideas
2023-05-21 19:36:33,exactly! we on the other hand can very easily “extend” reasoning beyond what we learn in tutorials or books
2023-05-21 19:36:53,try asking Yann Lecuns gear problem to GPT
2023-05-21 19:37:09,"if it was good at reasoning, it would solve it no matter what configuration you give it"
2023-05-21 19:37:12,but it doesnt
2023-05-21 19:37:16,"NNs are a very very lossy abstraction inspired by our understanding of the brain from 60 years back. The list of differences are very very long, and I'll have to let you Google it for yourself."
2023-05-21 19:37:26,"I mean, it's not even close."
2023-05-21 19:37:29,lol
2023-05-21 19:37:46,i’m just saying things based off some cognitive neuroscience we’re reading
2023-05-21 19:38:02,"sure, we’re not relu networks"
2023-05-21 19:38:06,but we are networks
2023-05-21 19:38:36,thats why spiking NNs and memory augmented networks are getting interesting
2023-05-21 19:39:13,"look up balints syndrome and other neurodegenerative diseases, it gives a nice primer on location of neural nets"
2023-05-21 19:39:30,Ok we are again in AI philosophy territory
2023-05-21 19:39:35,cc
2023-05-21 19:39:36,also diffusion tensor imaging is literally the process of finding neural bundles
2023-05-21 19:39:37,We don’t understand brain well enough to make valid comparisons
2023-05-21 19:39:48,no this is neuroscience territory
2023-05-21 19:39:52,"We have networks of neurons, sure, but they don't work the way these networks do. I mean, roads are networks too. Our brains don't work like the traffic. Some interesting analogies can be made sure, but that's about it."
2023-05-21 19:39:59,bruh
2023-05-21 19:40:09,pick up any computational neuroscience book
2023-05-21 19:40:34,and you’ll see it say neurons are the fundamental unit in the gray matter
2023-05-21 19:40:43,Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)
2023-05-21 19:41:19,"yes, i’m not saying there is a one-to-one correspondence between human neurons and MLPs"
2023-05-21 19:41:36,but at a computational level they are equivalent (modulo some constant)
2023-05-21 19:41:55,"And not to mention, the current networks have their genesis more than 60 years back, when we understood little about how the brain works. All this retro-fitting sounds like religion finding science in it."
2023-05-21 19:42:12,Even this is largely incorrect
2023-05-21 19:42:14,We don’t know how we learn very well ..we mostly don’t do backprop
2023-05-21 19:42:36,"thik h bhai, if you do not want established neuroscience literature and call it pseudoscience then idk what to tell you"
2023-05-21 19:42:55,Not saying that
2023-05-21 19:43:11,This is also fine.
2023-05-21 19:43:29,But you're making a large reductive jump
2023-05-21 19:43:58,"my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there’s nothing “magical” computationally"
2023-05-21 19:44:03,we don’t even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play
2023-05-21 19:44:25,glial cells are literally just a cover
2023-05-21 19:45:16,functionally they are very different agreed
2023-05-21 19:45:28,but there is also a huge difference in scale + functional discrepancy
2023-05-21 19:45:46,"if I’ve learned one thing pouring over Biology over the years, it’s that any simplistic statement about a biological system is largely under estimating what it does"
2023-05-21 19:46:26,"obviously, again I said im not claiming 1-1 correspondence"
2023-05-21 19:46:51,"but bringing back the cliche example of wright brothers, the airplane wasn't a one to one correspondence to a bird"
2023-05-21 19:47:03,but all functional components were equivalent
2023-05-21 19:47:52,"[PHONE REMOVED] read up ""Neuroscience Exploring the Brain"" by Mark F Bear, and Neuroscience by Dale Purves. These are the books I'm reading for my work"
2023-05-21 19:47:59,first one is very good
2023-05-21 19:49:07,"can also send you studies on neurodegenerative diseases, and what they tell about different lobes and neuronal pathways"
2023-05-21 19:49:58,"ofc, a lot is also unknown because fMRI has very bad spatial resolution, so we can only say about the ""macro"" behavior of the brain, but histopathological slides have shown that neurons do most of the heavy lifting"
2023-05-21 19:50:35,"or comprise most of the functional brain, and neurodegenerative diseases all have to do with damaged or dead gray matter, meaning less neurons"
2023-05-21 19:51:00,"Thanks for the recommendations, and I have read a bunch about computational neuroscience as well, and I see and agree with a bunch of stuff you said as well, but"
2023-05-21 19:51:09,2hat are you claiming?
2023-05-21 19:51:13,"this is what I know. if you guys find some other explanations of the humans, or mammals in general lmk"
2023-05-21 19:51:18,*what are you claiming?
2023-05-21 19:52:39,"This was your original claim that you have backtracked from. If not this, then what else are you claiming now?"
2023-05-21 19:53:06,"Friends, this is decidedly off topic, requesting you to move this conversation to the other group :)"
2023-05-21 19:53:08,"that on a functional level, GPT can have human-like reasoning with neural networks only, because that is how humans do it. Ok I want to do some ERM style math here so why not."
2023-05-21 19:53:30,"sure sure, this is the last bit from me anyway^ "
2023-05-21 19:53:55,i hope the above explanation encompasses this as well
2023-05-21 19:58:20,that gives me a good idea. I will try to write blog post summarizing some of these ideas
2023-05-21 22:40:49,is there any good hack anyone here has figured to promt something for LLM to understand. 
2023-05-21 22:41:10,it works I guess. somewhat but it's just brute force like my most solutions 😅
2023-05-21 22:46:25,I generate a todo list like thing in LLM-1. modified some prompts from guard rails implementation to prevent the gpt big mouth going off track
2023-05-22 07:43:17,Hi Rohit! Nice to see you here!
2023-05-22 07:43:39,But let’s see what still bigger GPTs can do.
2023-05-22 07:50:34,"YLC has been shown to be wrong multiple times (gear configuration problems, forces in physics). I think Yann's stance is also motivated by the backlash of Galactica, and comparatively lesser attention to llama."
2023-05-22 07:50:47,Nice seeing you here too! Small world we live in haha
2023-05-22 07:51:21,"GPT4 is already whooping GPT3 like crazy! I'm very impressed with some of the plugins, my academic workflow is 10x faster now!"
2023-05-22 07:54:10,"True, I guess only time will tell. Interesting times to live in!"
2023-05-22 07:54:27,Very!
2023-05-22 08:07:01,Which plugins have you found useful?
2023-05-22 08:07:45,"penrose analyst is very cool, scraper too"
2023-05-22 08:08:39,xpapers is decent
2023-05-22 08:08:51,"some of the video plugins don’t work, which is disputing"
2023-05-22 08:08:58,disappointing*
2023-05-22 08:11:52,Thanks.  Will check these out.  I found a lot of value in code interpreter but have struggled to get much value from plugins.  Which video plugins have you tried?
2023-05-22 08:35:16,How about the speed?
2023-05-22 08:56:36,*Xpapers
2023-05-22 08:59:38,Has rollout for plugins for chatgpt plus users started in India?
2023-05-22 09:00:55,"Yes, Plugins are accessible to everyone on Plus. I've had Plugins for couple of weeks."
2023-05-22 09:02:37,"I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately?"
2023-05-22 09:06:04,Thank you! Will check this
2023-05-22 09:06:17,Enable in settings
2023-05-22 09:06:22,Browsing is enabled by default but not plug-in access
2023-05-22 09:06:58,"I see, let me check this"
2023-05-22 09:09:40,PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.
2023-05-22 09:10:38,Does gpt browsing have an increased context limit tho?
2023-05-22 09:10:47,It felt like it when I first used it
2023-05-22 09:16:11,"Perhaps, but a longer context window in a weak search does not seem to help much. It's like having great recall for lyrics but not being able to find keys in the morning."
2023-05-22 10:04:49,Isn’t there something called Keymate.AI Search too?
2023-05-22 10:49:34,Which LLM api is available with a free tier that doesn't need a credit card ?
2023-05-22 10:52:55,"curious, why use the HF Inference API?"
2023-05-22 10:53:39,"Free, faster than OpenAI, supports multi-modal, flexible (multiple models, context windows)"
2023-05-22 10:54:16,"I heard Bard is pretty fast, I will look for benchmarks online"
2023-05-22 10:55:58,"Also [PHONE REMOVED], Jerry and I talked about you :) really appreciated your efforts"
2023-05-22 10:56:11,It's fast but I found GPT4/3.5 is superior in most of the cases.
2023-05-22 10:56:44,bard api is free ? and it works with langchain/gptindex ?
2023-05-22 10:56:52,not looking for fast/superior...just free
2023-05-22 10:56:54,Bard has no official API
2023-05-22 10:57:33,can u share this link ? i dont know what page is this
2023-05-22 10:58:38,Let me send you a 30s Loom in next 30 minutes. Huggingface UX is terrible
2023-05-22 10:59:27,I can’t believe how expensive RunwayML is lol
2023-05-22 11:02:41,"Exactly. Almost every creative ai tool is like 20 dollars/20 minute usage. Runway,midjourney, synthesia"
2023-05-22 11:03:10,Is there an open source alternative to synthesia?
2023-05-22 11:04:54,"wow, feeling limited by the 25 messages per 3 hour cap for the first time, because of this"
2023-05-22 11:12:15,Moving that discussion to philosophy
2023-05-22 11:40:56,Something relevant since I found people discussing this last night:
2023-05-22 11:48:09,"The resource ""supercluster"" link mentions theorem proving as a top level project:"
2023-05-22 12:31:10,GPT-4 was able to solve 1-2 IMO problems
2023-05-22 12:32:54,this was able to solve 10 apparently ; best performance till date for reasoning skills
2023-05-22 12:33:18,That's 2 more than me
2023-05-22 12:33:41,“Sparks of AGI” paper
2023-05-22 12:38:08,"The first ever problem of IMO is a gcd problem, you have to show gcd of numerator and denominator is 1 "
2023-05-22 12:38:34,Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack. 
2023-05-22 12:41:44,Anything video is usually premium - right from non-AI tools
2023-05-22 12:41:56,You sell to the same market so companies price accordingly
2023-05-22 13:04:57,Hi prayank
2023-05-22 13:09:25,Anyone here actively working on unreal engine code or content with stable diffusion ?
2023-05-22 13:17:41,mind reading https://twitter.com/_akhaliq/status/1660453496804741120?s=12
2023-05-22 13:24:36,https://github.com/go-skynet/LocalAI
2023-05-22 13:26:30,it is very slow for me ....are you aware of anyway to make it faster ?
2023-05-22 14:05:10,I'm running on 16GB RAM .. Apple M1
2023-05-22 14:24:45,This is very useful. Any idea which is the smallest model that will run on student grade hardware (maybe no GPU). Doesn't matter if it is slow ..as long as it is reasonably accurate
2023-05-22 14:54:59,Has anyone tried this? 
2023-05-22 14:56:29,[PHONE REMOVED]
2023-05-22 14:58:06,"Has anyone experimented with timeout parameter in openai api via the package . Keep seeing it there in their lib code but the versions I tried, didn't seem to work"
2023-05-22 14:58:54,(The mobile app is iPhone only right now)
2023-05-22 15:04:34,Are you able to use their web API?
2023-05-22 15:04:58,The one that GPT4all exposes on localhost
2023-05-22 15:09:41,This is a good idea - you are referring to this - https://docs.gpt4all.io/gpt4all_chat.html
2023-05-22 15:09:56,Yes
2023-05-22 15:10:41,Ah I didn't know this was an option. I thought it was an in-memory model load.
2023-05-22 15:10:50,Will check it out !
2023-05-22 15:11:07,Much thanks [PHONE REMOVED]
2023-05-22 15:12:29,We generally convert models to ONNX in our java edgechains and load it. But I didn't want students to bother with that.
2023-05-22 15:37:09,Did it work?
2023-05-22 15:43:14,Yes ofcourse
2023-05-22 16:20:06,"Unfortunately this doesn't work for me, it seems that there's no API exposed on that port. If you get it working, please let me know."
2023-05-22 16:22:10,use GPT4?
2023-05-22 16:22:50,"Yes, use it or use an open-source models"
2023-05-22 19:15:20,https://arxiv.org/abs/2305.11206
2023-05-22 19:23:48,Super... Is available to try?
2023-05-22 20:34:16,No
2023-05-22 20:35:35,Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples
2023-05-22 20:56:49,Ok
2023-05-22 21:25:27,"they use 1000 samples to train, so 20% of that to test is ok?"
2023-05-22 21:28:16,https://www.instagram.com/reel/CsOsJcRIZOC/?igshid=MmJiY2I4NDBkZg==
2023-05-22 21:51:45,"Hollywood writers have gone on a strike, demanding a ban on using AI for writing scripts"
2023-05-22 21:51:46,https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/
2023-05-22 22:03:58,i believe in the end we'll need even less good examples maybe even south of 100. i used to use t5 with setfit for zero shot classification and it needed less than 10 good examples to tune
2023-05-22 22:06:39,It’s not about the split it’s about the diversity that could be covered by 200 samples. And they have 1300 samples in total (1k/50/250)
2023-05-22 22:34:29,This is quite an insane video reconstruction follow up to the image reconstruction from fmri machines work
2023-05-22 22:40:10,https://twitter.com/jerryjliu0/status/1660683176099078144?t=suncjjVwLbYRB2-3LMJBHg&s=19
2023-05-22 22:53:54,The webpilot plugin for chatgpt is hallucinating a lot. 
2023-05-22 22:59:14,https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/
2023-05-23 01:25:26,What's the cheapest way to deploy open source models like Vicuna for quick inference ? Want to create a streamlit/gradio chatbot.
2023-05-23 01:36:30,Has anyone got a chance to try the LIMA model?
2023-05-23 01:37:18,Also any torrent link for the weights
2023-05-23 01:38:04,is there a link of independent comparison of free llms in the group somewhere. i couldnt find it
2023-05-23 01:39:02,not sure. but did someone share a HF space for this very same thing? Might be able to find one on twitter
2023-05-23 01:43:45,"Can use - https://github.com/Elyah2035/llama-dl for direct download , for torrent link, can search on 4chan"
2023-05-23 01:47:29,"Is anyone here doing experiments with fine tuning using a company's internal data - like internal chat, word documents, etc."
2023-05-23 02:03:13,"The code interpreter plugin is wildly good. It doesn’t just produce code and run it, it can split the problem into steps, run multiple blocks code, inspects the output and even corrects exceptions."
2023-05-23 02:04:17,it can generate a graph ?
2023-05-23 02:04:32,or it gave a data and you put it in excel
2023-05-23 02:04:42,"It can do everything, images text audio video graphs animations"
2023-05-23 02:05:19,Used matplotlib
2023-05-23 02:08:01,It even edits files - i can see crazy shift here in analyst jobs
2023-05-23 02:08:16,[PHONE REMOVED]
2023-05-23 02:13:30,sigh. that plugin doesnt seemed to be visible :(. there are some other 16 pages but not this
2023-05-23 02:17:43,More stats - this thing is just super 😵
2023-05-23 02:20:50,ya seems like alpha release.
2023-05-23 02:21:49,Anyone worked on possible ways on factchecking a given article using LLM's. Is it theoretically possible to do this. if yes what could be approach
2023-05-23 06:16:37,Open ai has a classifier
2023-05-23 06:16:41,https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text
2023-05-23 06:16:51,But read limitations
2023-05-23 07:16:38,Which plugin?
2023-05-23 07:20:33,Code Interpreter
2023-05-23 07:47:59,Code interpreter is amazing! It's very close to talking to an analyst...
2023-05-23 07:49:37,PSA: this is not a plugin - you can’t write a plguin that replicates the behaviour of code interpreter
2023-05-23 07:58:31,Decomposing this a bit: 
2023-05-23 07:58:37,Got it! Is it based on codex model?
2023-05-23 08:00:01,GPT3.5 and GPT4 are both based on Codex. 
2023-05-23 08:02:20,https://openai.com/blog/governance-of-superintelligence
2023-05-23 08:02:24,Superintelligence in 10 years ?
2023-05-23 08:03:15,"Yup, Its not just gpt4 + repl. There are other intricacies here. Like it has to inspect the contnents of a large file, without running out of context length, and has to carry out multiple steps without going into an auto gpt loop of doom. It will also ask follow up questions before writing code sometimes"
2023-05-23 08:21:32,The reasoning shown by Code Interpreter is too good.
2023-05-23 08:43:55,How do these interpreters work?
2023-05-23 08:45:06,Is it trained on a data set of code?
2023-05-23 08:53:15,Trained by humans. To do specific tasks and create paths to solve problems by writing code and evaluating the outputs
2023-05-23 08:53:45,The trajectories are designed by humans and rlhf’d
2023-05-23 08:54:51,But the code is run on an actual interpreter right?
2023-05-23 08:55:01,Yes
2023-05-23 08:55:38,It doesn’t have gpus though :D I told it to do vector search over the chat but it hung up trying to vectorize the data
2023-05-23 08:57:40,Doesn't seem to have any direct context length improvements over gpt4 afaict...
2023-05-23 08:58:46,Being able to load files into py memory and dealing with it via code is what creates the illusion
2023-05-23 08:59:50,Doesn’t need context length improvement for reasoning does it ? 
2023-05-23 09:00:47,Sorry was responding to this...
2023-05-23 09:01:43,I’ve tried this with 3.5 and it was nowhere near the reasoning ability which Code Interpreter is displaying 
2023-05-23 09:02:40,This is an experiment worth trying out with gpt4
2023-05-23 09:02:44,"Yes, my point was that it knows implicitly that this context length exists, and writes code which respects this limit"
2023-05-23 09:03:15,Eg see that it knows to sample 10 lines only
2023-05-23 09:04:11,"Very much skeptical it will have comparable performance, even after tons of prompt engg"
2023-05-23 09:08:52,Ummm... gpt4 might just be able to pull this off...    It's not bad at coding.  Next time I have a coding task I will test interpreter vs the base model on it.
2023-05-23 09:11:43,Thought this might be interesting to you 
2023-05-23 09:18:55,This kind of an attack is unlikely to do well.   The magic of code interpreter comes from maintaining the pandas data frame between subsequent calls.  Something like rpyc would be what I would go for.
2023-05-23 09:19:39,Its not just dataframes from what I hear. It does images videos etc too
2023-05-23 09:19:57,"You can also try this ,"
2023-05-23 09:20:20,All via keeping the python state maintained between calls
2023-05-23 09:21:01,Interesting though we need the exact reverse.
2023-05-23 09:22:40,An open source code interpreter could actually be quite useful.  Openai doesn't allow their interpreter to make web calls.  Even some ability to download small model weights would dramatically improve usability.
2023-05-23 09:23:33,For instance say upload csv of customer queries and have it clustered via something in nltk.
2023-05-23 09:24:03,Tried something like that a few weeks back and it tried to do some downloads and failed.
2023-05-23 09:25:21,"Not FOSS, but since compute and network are needed: Replit has entered this chat"
2023-05-23 09:26:37,What was the workflow you’d setup for this use case ?
2023-05-23 09:28:19,"I just uploaded a csv to code interpreter, asked it for 5 ways of doing a clustering analysis on it and then asked it to execute no 3."
2023-05-23 09:29:30,For stuff that fits on a pandas data frame this would be my preferred workflow...  It is quite smart about looking at the first few rows of data and coming up with a good plan
2023-05-23 09:29:53,"I don’t think it maintains python state, does it?"
2023-05-23 09:30:10,Maybe for a single generation it does
2023-05-23 09:32:28,I am almost sure it does.  Will run a test and get definitive proof.
2023-05-23 09:32:47,Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this 
2023-05-23 09:33:06,It says no
2023-05-23 09:33:08,😂🤡
2023-05-23 09:36:48,Confirmed.  See the use of the data dataframe between subsequent calls.
2023-05-23 09:37:15,Lovely
2023-05-23 09:37:30,Pyhton’s repr() is ❤️
2023-05-23 09:42:00,Interesting idea - can you give code interpreter the .pyi stub file for a new library/ private code and tell it to use the library? 😱
2023-05-23 09:49:44,Must have the API 😭
2023-05-23 09:51:02,Code interpreter is so powerful.  An unrestricted version of this would be awesome!  If I had any free time...
2023-05-23 10:11:50,"Open AI blog post by Sam Altman, Greg Brockman & Ilya Sutskever on how to regulate future ai systems far more capable than ones that exist today "
2023-05-23 10:44:04,Can it also process sql dumps?
2023-05-23 10:45:07,I tried giving it a heavily nested json - doesn’t do well if you don’t give it a schema. But i guess with sql it can inspect schema
2023-05-23 10:46:02,"With openAPI schema, it might do that"
2023-05-23 10:52:17,https://twitter.com/ylecun/status/1660732998155640833?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-05-23 10:53:12,I guess this would include many Indian languages
2023-05-23 10:58:06,I’m doubting this just based on reading their training methodology 
2023-05-23 10:59:42,https://arxiv.org/abs/2305.13048
2023-05-23 11:02:48,More accessible blog: 
2023-05-23 11:02:53,And a HF space: 
2023-05-23 11:11:47,Makes me hopeful that open source community can drive things forward even if google etc stop publishing
2023-05-23 11:13:40,Could not understand it fully but it looks like context windows of 100k-500k could become normal if this works as the inference cost grows linearly
2023-05-23 11:16:11,"Hiii everyone, "
2023-05-23 11:16:27,Specifically for generative ai tasks
2023-05-23 11:27:18,https://twitter.com/togethercompute/status/1660767722073128960?s=46
2023-05-23 11:28:16,"Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530"
2023-05-23 11:28:18,An interesting thread discussing potential limitations of RWKV and history of large scale RNNs https://twitter.com/smerity/status/1660786104377958400?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
2023-05-23 11:29:41,I have this app but I don’t open it anymore . It makes my phone heat up a lot and it becomes unstable
2023-05-23 11:30:52,But a year ago tbis would have been total science fiction
2023-05-23 11:32:47,Yeah one shouldn’t jump on this kind of researchy stuff. Transformers have a huge ecosystem around them that’s growing every day. It will take a lot of time to replicate that.
2023-05-23 11:37:16,RNNs don’t need to replace transformers..Ability to have ready made embeddings is useful in at least a few niche applications.
2023-05-23 11:43:21,+ faster inference particularly on long sequences
2023-05-23 11:46:55,Not a comparison but a list 
2023-05-23 11:52:22,Nfx.com has an exportable csv
2023-05-23 12:14:19,Thanks. I did see this. Only if there was objective comparison with these and gpt 4 would have been really helpful.
2023-05-23 13:30:34,Hey everyone! I've been really enjoying our discussions on LLMs here. We won a few hackathons using LLM prompting. I've compiled some notes that cover various concepts and recent advancements. I thought they might be useful to some of you. You can find it here: https://nishnik.notion.site/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
2023-05-23 14:13:00,Folks QQ. How do you determine if a text is interrogative?
2023-05-23 14:13:01,I.e. Classify if it's a question or not
2023-05-23 14:34:02,What level did you reach here: https://gandalf.lakera.ai/
2023-05-23 14:34:55,cc [PHONE REMOVED] you were interested in prompt security
2023-05-23 14:47:39,Wow. I love this game
2023-05-23 14:48:04,Stuck at 4
2023-05-23 15:30:14,Good game. I am stuck at level 8
2023-05-23 15:30:47,There are only 8 levels chad
2023-05-23 15:31:15,There's a bonus level which comes after level 7
2023-05-23 15:32:43,"Aaah, I interpreted that to mean that you've cleared level 8 and stuck at it. My bad. "
2023-05-23 15:35:06,Damn. Well done
2023-05-23 16:27:16,"Love how creative this game is. Would also love it if people share some creative answers here, especially for the higher levels"
2023-05-23 16:28:32,Asking the etymology too me to level 7.
2023-05-23 16:41:10,Actually all 8 levels worked
2023-05-23 17:14:32,"Fun thing, just started. First two levels are straightforward 😄"
2023-05-23 17:17:46,Cleared until third in the first 15 mins
2023-05-23 17:17:51,4th is tough :/
2023-05-23 17:18:25,Same 😂
2023-05-23 17:21:42,7th was harder than 8th for me.
2023-05-23 18:02:18,Antler airtable https://airtable.com/shrBeWpMlxf3e14E8/tblS4TkbJbm0cqT0o
2023-05-23 18:21:35,https://web.stanford.edu/class/cs25/
2023-05-23 18:23:04,"PSA: Drop a line with the link, don't just share the link. That increases the chances that people interested in it will get a sense of what it is without clicking through 🙏"
2023-05-23 18:28:08,Found this interesting map of infra companies for Gen AI - https://medium.com/cowboy-ventures/the-new-infra-stack-for-generative-ai-9db8f294dc3f
2023-05-23 18:28:30,Stanford course on transformers .
2023-05-23 18:29:39,Are there more Generative AI companies than devs who can RLHF a Llama model?
2023-05-23 18:34:51,[PHONE REMOVED] any comments about this space ? 
2023-05-23 18:59:59,Has anybody here tried the ChatGPT iOS app in india?
2023-05-23 19:02:18,From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? 🤣
2023-05-23 19:03:14,Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?
2023-05-23 19:04:24,"AWS Sagemaker, Replicate (limited but dead cheap)"
2023-05-23 19:05:38,I think even in this group a lot of us know what it is and how it works in theory but doing RLHF *well* in practice is what will ensure GPT4 like performance & is OpenAI's sweet spot.
2023-05-23 19:49:20,"yes, you need to -"
2023-05-23 19:49:43,"The app is pretty slick, and whisper + gpt4 is just too nice to use"
2023-05-23 19:55:11,"I don't think this exists, whatever exists is probably ~25% of what we want here, and is probably the biggest opportunity for infra startups right now"
2023-05-23 19:57:05,https://www.youtube.com/watch?v=ut5kp56wW_4
2023-05-23 21:35:24,doesn't mosaicML do this? I don't think its multimodal but it does help in deployment optimization https://www.mosaicml.com/
2023-05-23 21:39:57,https://twitter.com/JosephJacks_/status/1660747216561254400?s=20😂
2023-05-23 21:40:00,"There are bunch of dataset companies from the last ML bull run e.g. Scale.ai which are now moving towards this in some way or the other. With datasets like PILE and more coming along, I suspect for text-LLMs FOSS Datasets will win. "
2023-05-23 21:44:44,Anyone can explain to me how the problem of long sequences in transformers was solved?
2023-05-23 21:50:33,"cc [PHONE REMOVED] is perhaps the best person to answer this. But more generally, this is still an unsolved problem. "
2023-05-23 21:51:26,Would multi query attention be also considered something that helped here
2023-05-23 21:52:07,Thanks for your comprehensive answer.
2023-05-23 21:52:28,I think he means response tokens
2023-05-23 21:52:36,Got you
2023-05-23 21:52:50,"Yes, this is what I meant!"
2023-05-23 21:53:11,It's same with gpt4. Even though you can set theoretically 5k response tokens it hangs
2023-05-23 21:53:39,Add ALiBi as well?
2023-05-23 21:54:25,Mpt models are based on ALiBi and flash attention.
2023-05-23 21:55:50,"Yeah, ALiBi counts!"
2023-05-23 21:56:18,I hit the limit of my output/response tokens too 😂
2023-05-23 21:58:37,"The way Mosaic ML approached this with their MPT storywriter model (https://huggingface.co/mosaicml/mpt-7b-storywriter) was that they just finetuned base model with 4096 sequence length on books with longer sequence length. The input sequence to transformer models is of dimension : L * d where L is our sequence length and d is embedding size.So with existing base models, we can train derived models with longer sequence lengths; just doing so would cause us having large Q, K and V matrices."
2023-05-23 22:14:43,https://twitter.com/ofirpress/status/1657040700062441475?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Author of Alibi is stating finetuning is the way to go as 99% of documents in PILE or similar datasets are less than 500 tokens long.
2023-05-23 22:21:12,"QQs: a) this 1 token = three fourth of a word / 4 or 5 characters, right for all LLMs?  b) what's the ""so what"" of this 500 token fact and what are the top implications does it have on use cases for the end user?"
2023-05-23 22:22:41,A) yes..that’s 1token
2023-05-23 22:27:22,"B) because most of the documents are less than 500 tokens. For a base model with 2k context length, most of the time we will be fitting 4 documents together for a single forward pass. If we increase the sequence length, we would fit more documents for a single forward pass. But tokens in document 1 won’t be helping us in predicting tokens in document 2. Hence, he is saying it doesn’t make much sense to increase context length to 100k while training base models."
2023-05-23 22:32:35,ICYMI: Community's Generative AI May Meetups: 
2023-05-23 22:47:26,There's also questions around middle context accuracy in Anthropic's particular case:
2023-05-23 22:47:45,Prompting this gold of a meme by Karpathy xD
2023-05-23 22:48:29,Probably using heuristics
2023-05-23 23:28:13,Helpful. Thank you Sachin
2023-05-23 23:28:52,Anything in mumbai?
2023-05-23 23:34:36,Thanks sir 🎅
2023-05-24 03:20:56,this was pretty fun lol.
2023-05-24 05:04:50,"The Bill & Melinda Gates Foundation today launched a new Grand Challenges (GC) request for proposals, ""Catalyzing Equitable Artificial Intelligence (AI) Use""."
2023-05-24 05:05:33,"Would someone in the group have interest in the above.  Currently, I work at the intersection of technology, social good and policy and want to partner up with someone to explore the above question. Please DM me if above would be interesting."
2023-05-24 06:49:27,"In June, yes"
2023-05-24 07:58:11,"For anyone who has implemented txt2sql ,without fine tuning "
2023-05-24 08:07:54,Cc [PHONE REMOVED] since we discussed this yesterday
2023-05-24 08:26:39,"hi yes, we have used it without fine-tuning but we are yet to run into the prompt size limit prob. I might be able to add more on this in 2 weeks. But fundamentally we want to use something like Llama index to index, save and query the context in/ from embedding space. So to answer your question, yes we can do semantic search for the mentioned use-case."
2023-05-24 08:50:21,So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt 
2023-05-24 09:27:22,[PHONE REMOVED] Why are you doing semantic search over schemas? Do you take only top 1 retrieved DB schema in the prompt for query gen?
2023-05-24 10:16:31,Yes. The answer lies in how your are creating the text corpus and how you are indexing them. Point to remember that these models are probabilistic models and they try to predict the next token by analysing patterns in Corpus. Optimizing the accuracy of such mismatches in your particular usecases is also where the startups like us add value.
2023-05-24 10:17:39,I would suggest breaking the task down into smaller pieces and using multiple LLM calls.
2023-05-24 10:18:24,For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call. 
2023-05-24 10:19:58,I’m currently implementing this 
2023-05-24 10:21:54,Sorry removing it for second order reasons.
2023-05-24 10:24:24,Generally for text corpus on the table description/relations I’m trying to embed files from data cataloging tools like Amundsen 
2023-05-24 10:24:44,i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.
2023-05-24 10:27:16,"another complexity is when u have ""type"" fields in ur db table. (for e.g. type ==<cat,dog,monkey>). so the LLM needs to know about these types before it can generate a query. that means for these kind of columns, u need to send descriptions of columns as well...otherwise the query will fail"
2023-05-24 10:28:14,At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations 
2023-05-24 10:30:51,"if ur doing the ""type descriptions"" i mentioned above..yes it will break the context length."
2023-05-24 10:48:17,Start this way … track your mistakes and then fine tune once you have enough samples. It should always be suggestions and not always be executed.
2023-05-24 10:48:24,Copilot model - show completions and track acceptance rate
2023-05-24 10:49:33,Make an assistant / suggestion tool. This allows for slowly boot strapping better things from data.
2023-05-24 13:46:21,"Has anyone worked on Generative AI tools for identity management? For example, 3D avatars? If so, can you direct me to such open-source resources and the current landscape (both funding-wise and use cases)?"
2023-05-24 15:51:33,Is anyone working with chatgpt-retrieval-plugin?
2023-05-24 16:08:56,*far more tokens
2023-05-24 16:11:19,https://github.com/ricklamers/gpt-code-ui
2023-05-24 17:17:14,Open AI prompt related -
2023-05-24 17:18:20,"Guardrails helps you do that: https://getguardrails.ai/ (I’ve not used it personally, but folks are using it)"
2023-05-24 17:22:32,Try jsonformer
2023-05-24 17:22:34,https://lmql.ai/
2023-05-24 17:27:35,There is a library by Microsoft.
2023-05-24 17:34:06,Anyone here got access to Anthropic’s Claude Instant API?
2023-05-24 17:37:07,do you any example for open ai model? 
2023-05-24 17:47:04,jsonformer won't work with OpenAI. You're better off using guidance or guardrails
2023-05-24 17:47:26,okay.
2023-05-24 17:54:41,I'm making do with a piece of code like https://github.com/hwchase17/langchainjs/blob/main/langchain/src/agents/chat_convo/outputParser.ts#L24-L37
2023-05-24 17:57:10,"Open ai returns the keys(""name"") different sometimes, then it starts creating the problem"
2023-05-24 18:51:54,"Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3"
2023-05-24 18:55:41,fyi - this will be a livestream on YouTube
2023-05-24 18:59:12,Which channel
2023-05-24 18:59:43,"if you register here, you'll get the Youtube livestream link!"
2023-05-24 19:38:46,Livestream Link: https://www.youtube.com/watch?v=zXX0I6dOPYk
2023-05-24 20:07:57,Talk by Karpathy at Msft build 
2023-05-24 20:08:13,Real good
2023-05-24 23:11:18,anyone here
2023-05-24 23:14:14,https://www.youtube.com/watch?v=zXX0I6dOPYk
2023-05-24 23:14:49,am there
2023-05-24 23:20:39,Some interesting points discussed here
2023-05-24 23:23:49,"Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there"
2023-05-24 23:47:26,"Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder. "
2023-05-24 23:48:49,"depends on the talk and who you're targeting, LongShot had SEO related webinars where we discussed our semantic SEO feature, we got a few hundred, but yes they were mostly non technical"
2023-05-24 23:56:18,"Hi all, I am Sam, founder of Writesonic. Been playing with generative AI for the last few years."
2023-05-24 23:56:39,Shark tank bro 😂
2023-05-25 00:38:13,https://twitter.com/tengyuma/status/1661412995430219786?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ A new optimizer which can achieve same performance as Adam with half the number of tokens.
2023-05-25 00:45:52,anyone?
2023-05-25 01:19:46,Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings
2023-05-25 01:22:26,Anyone here working on factchecking the output of an LLM's. Architecture suggestions would be great
2023-05-25 01:57:42,For people who have worked with chunking data/documenta before:
2023-05-25 02:15:56,"During retrieval, we're not looking at (searching for) documents any more, but at chunks, which now all have the same size: (1, 1536)."
2023-05-25 02:21:43,And what if my question has one part of answer in one of the chunks and the in another chunk of the same document?
2023-05-25 02:22:05,Splitting up a document honestly doesn’t sound a good idea to me.
2023-05-25 02:23:43,"Which is why you always chunk with some overlap, which you may have to tune for your dataset."
2023-05-25 02:24:18,"also, to be clear my question sort of translates to “what chunking system does chatgpt-retrieval-plugin use”, if anybody has an idea about it already:-)"
2023-05-25 02:25:26,+1
2023-05-25 02:25:30,"Most vector stores (at least the good ones) support batch insertion which is faster, so it makes sense to create a bunch of docs (chunks actually) and their embeddings and insert them with one command."
2023-05-25 02:27:03,"The only real workaround for this is longer context window for the LLM, which is not in our hands. So we'll be doing chunking before retrieving for a while."
2023-05-25 02:27:34,interesting…
2023-05-25 02:31:03,"chunk overlap sounds a difficult problem, and subjective and very very specific to usecases"
2023-05-25 02:45:16,"No no, it's not that difficult at all. Most libs around this (like langchain) already have params that let you do this easily. Where some thought is required (like code or markdown or msword doc), usually you need to split carefully in the first place and don't need chunking."
2023-05-25 02:45:55,"Or, at least, if you have thought through splitting, chunking strategy will be self-evident."
2023-05-25 06:30:37,a bit biased since i built it but it's the simplest of all of solutions out there and supports zod schemas to get structured data out of llms https://github.com/dosco/minds
2023-05-25 06:44:00,https://geohot.github.io//blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html
2023-05-25 06:44:03,AMD cards*
2023-05-25 06:46:17,"“If NVIDIA is the Apple, we are the Android.” 🤌"
2023-05-25 07:00:02,Love love love the sentiment.
2023-05-25 07:04:20,"Building a developer EcoSystem around chip is very tough. I see only three success stories in last 15 years, Apple, Android and Nvidia. Even Meta couldn't do it well for Oculus."
2023-05-25 07:05:48,You can’t build a great business with perfect market competition. All insanely profitable companies must be in some sort of oliogopoly to succeed (not monopoly because otherwise you get anti trust lawsuits)
2023-05-25 07:07:44,"Not just that,"
2023-05-25 07:08:25,Geohot really loves this analogy 🤣 He said the same thing for Tesla and Comma
2023-05-25 07:54:17,"This is super cool, wishing geohot all the very best!"
2023-05-25 08:55:30,QLoRA: *4-bit* finetuning of LLMs! 
2023-05-25 09:20:55,Take a look at Nvidia earnings and share price
2023-05-25 09:20:58,After markey
2023-05-25 09:34:40,So cheaper than openai now 🤔
2023-05-25 09:34:49,I think Claude is the most expensive to infer ab
2023-05-25 09:40:18,How does Cohere compares to OpenAI in terms of quality?
2023-05-25 09:42:27,https://twitter.com/omarsar0/status/1661540207206846464?s=46&t=NNw5PElvtyZ9tUru_KLDVw
2023-05-25 09:43:18,I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... 🤑🤑🤑
2023-05-25 09:45:29,Curious why do you say so
2023-05-25 09:46:08,just seeing the last rallies in indian market... no data backed
2023-05-25 09:46:58,"Hmm. I thought there is some signal which hints higher number of demand for GPUs in Indian ecosystem vs US/ EUR. But, got it."
2023-05-25 09:52:28,that will add $750B market cap over night
2023-05-25 09:53:27,20% of entire BSE
2023-05-25 10:02:09,don't convert directly dollar into rupees.. stock price will defiantly be on the lower side if  it listed in the indian market.
2023-05-25 10:10:08,Most of it will anyway be fdi
2023-05-25 10:11:10,"nah, indian retail investor/developer will invest a lot."
2023-05-25 10:41:18,App store US
2023-05-25 10:43:23,Tensorflow is the floppy disk of AI era
2023-05-25 10:43:42,My takeaway from both chatgpt and character ai app store launches - its easier to scale massively on web first - you probably don’t need an app!
2023-05-25 10:45:24,"not entirely surprising given that their main use case is ""mann ki baat"" 😂"
2023-05-25 10:47:13,100%. The code didn’t work out of the box. Now will have to dig into it. Just to upload a dataset
2023-05-25 10:48:14,You need an app. All the other AI chat apps are on mobile.
2023-05-25 10:48:35,Started on mobile too.
2023-05-25 10:48:54,Chat is native to mobile over web
2023-05-25 10:49:48,Tensorflow was the reason I took break from DL during 15-17 and focused on just ML  thinking this is not going to work out for real world applications.
2023-05-25 10:50:09,https://twitter.com/andreyzagoruiko/status/1655046102738173954
2023-05-25 10:52:07,All of these combined are <1% of chatgpt
2023-05-25 10:52:22,"There is a saying in Hindi “Ganv basa nahi, lootere aa gye”, every time something good start taking place grifters are first to come."
2023-05-25 10:52:40,translate please? :P
2023-05-25 10:53:09,We should both go to therapy sponsored by tensorflow support group. I did the same
2023-05-25 10:53:13,ChatGPT makes 100M$/month?
2023-05-25 10:53:17,Riding the wave 🌊
2023-05-25 10:53:33,"Before a settlement even start taking place, bandits(lootere) are there"
2023-05-25 10:53:39,Sorry I meant in terms of user count. Not sure what the revenue numbers are
2023-05-25 10:54:12,https://poe.com/s/kBjvkzP5fiwOWn1bo21W
2023-05-25 10:54:45,Honestly stuff like this continues to blow my mind. How is this possible 😁
2023-05-25 10:54:53,Character.ai too is much much bigger. And has insane retention compared even YouTube
2023-05-25 10:55:08,Don't get how these apps are robbers/scammers
2023-05-25 10:55:35,"Oh, sudarshan"
2023-05-25 10:56:03,I find this claim interesting. Coz I don’t know anyone that uses it. 😜
2023-05-25 10:56:26,And not even on Reddit or anything is it discussed much
2023-05-25 10:57:02,https://www.similarweb.com/amp/blog/insights/ai-news/character-ai-engagement/
2023-05-25 10:57:51,So ChatGPT subreddit has 1.7 million members and 10k ppl online right now. Character AI - 80k members and 1k ppl online
2023-05-25 10:58:08,Curious how much time people spend on kissan ai [PHONE REMOVED] 👀
2023-05-25 10:58:13,"Don’t take it literally, just a joke"
2023-05-25 10:58:44,Robbers is a metaphor for stealing a chunk of the limelight
2023-05-25 10:59:20,"Don’t take it literally Bhai, just a light hearted joke."
2023-05-25 11:01:06,"I don’t have stats for apps yet but on web avg 2m per session, went up 2x in a month. I was expecting to go down with more users but it is climbing everyday. Probably a good sign."
2023-05-25 11:01:47,Impressive !
2023-05-25 11:01:56,What kinds of things are people asking ?
2023-05-25 11:06:05,I love the UX. You can introduce a share feature. Like Poe. That will increase sharing and organic growth
2023-05-25 11:06:15,"I’ll run an analysis during weekend, haven’t got anytime lately but some feedback we received, they are going at such a breath that I’m finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. 🤣"
2023-05-25 11:06:55,integrate it with ondc 🫰
2023-05-25 11:07:49,"Yup, I’m going step further and doing vector matching of product with answer so they get exact item and not Google ads type crap."
2023-05-25 11:09:11,I would also suggest to try and turn it into a community of sorts where people can search answers. Or maybe make most answers public by default. So AI generated and human answers can co exist. This will also increase revenue opportunities
2023-05-25 11:09:37,Mid Journey approach
2023-05-25 11:09:49,Are you facing issues with speechtotext considering various languages and accents it has to handle. Or is it manageable
2023-05-25 11:10:17,"That’s also one of the suggestion. If we start seeing people asking about a pest in an area, we can detect in pest infestation and alert authorities."
2023-05-25 11:11:29,"Early I faced, now we have figure out. Working out MoU with some bigger companies to see if the Bhasini can be optimized further for few languages."
2023-05-25 11:13:08,"🙏Great and such a relief to know that. So much can be done in the country in various sections such as education , healthcare with a reliable speechtotext"
2023-05-25 11:13:47,"Luckily, I’m sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources."
2023-05-25 11:14:21,Provide the dataset to ai4bharat? They have annotators
2023-05-25 11:14:22,https://betterprogramming.pub/building-your-own-devsecops-knowledge-base-with-openai-langchain-and-llamaindex-b28cda15abb7
2023-05-25 11:15:35,"Yes, that’s the plan."
2023-05-25 11:16:33,🙏it's a hard task
2023-05-25 11:18:01,I think you’re definitely on a positive feedback loop of data flywheel
2023-05-25 11:53:21,Harrison Chase posted this yesterday. https://twitter.com/hwchase17/status/1661386820272156672
2023-05-25 11:55:06,Can we help here to fast-track your exploratory analysis? So long you are firing events. I think otherwise it shud take you some time to see data at various cuts.
2023-05-25 11:57:38,"You can try creating chunks, and instead of using vector embeddings ask chatgpt to create question/answers from that chunk covering it exhaustively. You can then fine tune some model (open ai has api for davinci) with these question answers. "
2023-05-25 12:05:07,so there’s no embeddings based kNN search involved in this approach?
2023-05-25 12:11:24,Anyone else having problem paying to openai via cc?
2023-05-25 12:21:44,"Yeah, off late been hearing some complaints with Indian cards. Try Amex."
2023-05-25 12:22:35,Icici said it is to do with the merchant
2023-05-25 12:34:50,"Hi, Has anyone trying further fine-tuning Vicuna? "
2023-05-25 12:36:47,I want to build a custom search/summarization for the documents present on my machine. 
2023-05-25 12:42:40,Bigger than 4096 even with vectorDB?
2023-05-25 12:42:55,why not try https://github.com/imartinez/privateGPT
2023-05-25 12:42:58,"You can bump it to gpt-4 with 8k, but it is very expensive"
2023-05-25 12:46:09,"Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens. "
2023-05-25 12:46:38,Yeah :( Waiting for OpenAI to drop prices of GPT-4 and make something like GPT-4-turbo!
2023-05-25 12:46:47,"Thanks, will check it out!"
2023-05-25 12:50:55,https://www.philschmid.de/fine-tune-flan-t5-peft
2023-05-25 12:52:33,This is great!! Thank you so much. Will replicate it!
2023-05-25 13:05:20,"Anyone who has developed any tts application themselves as a product to use, please DM. I have a jam"
2023-05-25 13:05:34,*stt
2023-05-25 13:43:16,This solves the purpose for now! Thanks Sahir. 
2023-05-25 13:52:26,"Anyone faced issues with using GPT4ALL with this, or tried using LLaMa?"
2023-05-25 13:55:48,"hey folks, one question:"
2023-05-25 13:57:00,the prompt on chatbotui is working everytime and giving out incorrect output in code.
2023-05-25 14:01:49,works with my Amazon ICICI credit card.
2023-05-25 14:03:46,Worked now. Looks like a stripe issue yesterdays
2023-05-25 14:04:44,"yeah had some initial issues as well. You need to go and ""view invoice"" on Stripe, and then pay it (i.e. you can't do it from the OpenAI website)."
2023-05-25 14:05:38,Hey everyone what is a good stack/pipeline using a self hosted llm for question answering on Excel sheets?
2023-05-25 14:10:34,"We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production."
2023-05-25 14:13:46,No
2023-05-25 14:17:11,https://www.youtube.com/watch?v=ZMQbHMgK2rw
2023-05-25 14:22:08,Have you tried using their streaming api? [Chat Completion API with streaming=true]
2023-05-25 14:23:57,this has to be the modern version of apple adding animations to make stuff feel smoother
2023-05-25 14:26:12,Yes we are using Chat completion API only...But our use case is not suitable to send response word by word
2023-05-25 14:30:25,"We are building an app using streaming, and the output seems quite quick (just like ChatGPT UI). You might want to reduce maxTokens and tune other params to improve speed"
2023-05-25 14:38:19,I can't believe my eyes. These are so fast. They have fans under them to create suction and increase downforce. G forces as high as F1 🙈
2023-05-25 14:47:58,Haha. micromouse was so much fun. We organised one too during college. 😅
2023-05-25 14:48:24,There are generations of PhDs who did micromouse for years.
2023-05-25 14:48:59,"But anyway, non genAI. Dont want to distract the group."
2023-05-25 14:51:50,"Has anyone fine tuned a self hosted generative llm (alpaca, chatgpt4all) on domain specific data? Need some advice on when it is useful to fine-tune and when it may actually hurt"
2023-05-25 15:01:30,Excellent Prompting Guide for LLM Hackers: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
2023-05-25 15:08:02,https://twitter.com/ansonyuu/status/1661518548664041472
2023-05-25 15:09:50,Totally!
2023-05-25 15:10:20,Can make a real time version of this as well? Attendees enter interests at the venue and get plotted in real time?
2023-05-25 15:10:57,[PHONE REMOVED] has volunteered to build already to me.
2023-05-25 15:12:29,Forking this conversation from here to actually try this for Saturday to a separate group.
2023-05-25 16:51:44,Is it possible to train llm/stable diffusion models (smaller ones) on mac gpu?
2023-05-25 16:52:14,^m1/m2 models
2023-05-25 16:57:58,https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/qr_version.jpg
2023-05-25 18:48:29,Interesting - is this vanilla chatgpt? Had generally heard that LLMs breaks on math problems because they don’t recognise universal math “rules” and haven’t been trained on enough relevant papers etc
2023-05-25 18:48:42,GPT 4
2023-05-25 19:03:04,"Isn’t the first sentence wrong itself? 🤣 How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ?"
2023-05-25 19:06:34,this is also more in line with the IMO solution 🥲
2023-05-25 19:07:17,It is really only a matter of time where this triviality will go away no?
2023-05-25 19:26:49,This solutions is also flawed.
2023-05-25 19:27:44,I saw the official solutions.
2023-05-25 19:28:06,*assumptions it makes
2023-05-25 19:29:02,"I see, that could be possible. Mea Culpa and sorry - probably won't reverify but totally understand your point :)"
2023-05-25 19:30:25,"FWIW: GPT4 is RLHF'd on a ton of math, physics, logic, and code problems. It's possible that even the IMO 2022-style problems were part of that, since they'd professional math educators design the RLHF Set from the rumour mill."
2023-05-25 19:30:26,My flatmate spent a month in homi bhaba preparing for the actual international olympiad. I trust his proofreading 😂😅
2023-05-25 19:33:03,I sincerely hope so
2023-05-25 19:36:51,"but it’s funny how gpt builds up a crap story with full confidence with “7 villagers” , when 7 can never be of the form 4n+2 for any integer n."
2023-05-25 19:40:08,"Friends, we're testing the meetup matchmaker for 27th, mind filling it in if you're going to be there? https://forms.gle/dAYM1bUyhTFa7CnL8"
2023-05-25 19:51:50,Seema kapadia needs to see this💡
2023-05-25 19:56:49,Very neat stuff Dev !
2023-05-25 19:57:09,Yes
2023-05-25 20:05:45,"Asking for a friend: i want to create mock design for my app, eg, create a screen for soliciting aadhar card from user. Are there tools which are able to do that?"
2023-05-25 20:08:41,"Nice, how are you creating this viz?"
2023-05-25 20:09:26,Can we fill it in even if we're not going to be there?
2023-05-25 20:09:47,Is there a GitHub ?
2023-05-25 20:10:18,"Yeah, but that significantly lowers the chances that you'll meet the person. For you, I strongly recommend taking that 3K INR flight to BLR!"
2023-05-25 20:10:49,I'm tempted
2023-05-25 20:11:33,"Inflation adjusted, It's cheaper than Christopher Bishop's Pattern Recognition that we bought in undergrad 🤣!"
2023-05-25 20:16:28,Here you go: 
2023-05-25 23:43:38,https://a16z.com/2023/05/25/ai-canon/  curated list of resources according to the fund that are super compelling and have had an outsized impact
2023-05-26 01:25:48,Fantastic curation
2023-05-26 02:54:30,https://www.bbc.com/news/health-65709834
2023-05-26 03:23:05,Have some questions. Would be really really helpful if someone who has worked with Pinecone could answer these:
2023-05-26 06:57:45,Anthropic round 🫠
2023-05-26 06:59:09,Seriously this is nuts tho.
2023-05-26 07:10:47,https://www.cnbc.com/amp/2023/05/25/jpmorgan-develops-ai-investment-advisor.html?__source=instagram%7Cmain
2023-05-26 07:10:58,This is insane
2023-05-26 07:28:33,This feels like over reliance on LLMs when we know they hallucinate over reasoning and mathematics problems
2023-05-26 07:28:40,Which would factor into selections of investments
2023-05-26 07:31:28,"But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that’s out of training distribution"
2023-05-26 07:53:25,Folks it's simpler than this
2023-05-26 07:54:02,They'll probably end up using llms to generate derived features for their ML models
2023-05-26 07:54:09,Anyone has access to this article ?
2023-05-26 08:39:14,Their earnings guidance is nuts
2023-05-26 08:39:19,Read the transcripts
2023-05-26 08:48:34,You can ask Bard to create the summary of the article link
2023-05-26 08:51:28,https://twitter.com/willdepue/status/1661781360619696128?t=Mjv8eQJ28AvW1cFSH_NO8w&s=08
2023-05-26 09:57:20,"Tried it with a bunch of articles. Bard/G-Search seems to be able to access the content behind paywall , but seems to be hallucinating quite a bit too. "
2023-05-26 10:11:08,https://a16z.com/2023/05/25/ai-canon/ - good compilation of resources
2023-05-26 10:19:08,"Seems pretty good, hoping to read all of it over the weekend 🙂"
2023-05-26 10:37:41,Can anyone tell Which embeddings model did they use?
2023-05-26 10:48:56,InstructorXL
2023-05-26 10:51:06,Soumith Chintala's take on the $NVDA rally !
2023-05-26 10:51:55,"If you've ever used a TPU pod in production, you'd know his directionally right, timeline unknown."
2023-05-26 11:04:37,I haven't but as someone wrote in the thread
2023-05-26 11:17:03,anyone who knows about the default chunking systems in Pinecone?
2023-05-26 11:17:33,They don't do chunking
2023-05-26 11:17:57,You do it..embed the chunks and upsert it with Metadata
2023-05-26 11:21:04,I’m using and exploring```chatgpt-retrieval-plugin```.
2023-05-26 11:26:21,I can confirm that pinecone doesn't do chunking for you. Haven't used chatgpt-retrieval-plugin.
2023-05-26 11:31:28,"We use pinecone and it doesn't do chunking. For that, we use llama index"
2023-05-26 11:41:35,I have a hypothesis. Curious to hear others’ thoughts.
2023-05-26 11:41:36,interesting…
2023-05-26 11:43:44,It will be fun to imagine what applications will be possible when LLMs are almost free
2023-05-26 11:45:11,I guess they would be baked into every OS and products as long as they are not giving financial or health advice. May be the regulators will rein in these kind of products and services first.
2023-05-26 11:48:19,What timeline are you thinking? 5 years out or more like 15 years out?
2023-05-26 11:58:36,If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem
2023-05-26 11:59:22,And And I think Asahi Linux is getting there. So maybe less than 5 years?
2023-05-26 12:07:52,Have you seen this - https://github.com/ParisNeo/gpt4all-ui 
2023-05-26 12:08:52,Yes you can run models. But can you change or influence the OS to work with you?
2023-05-26 12:09:28,"I think 5 years. Bcz most of these tools are positioned to increase productivity. Imp question to ponder is what gets shortened, when the productivity increases. "
2023-05-26 12:09:32,With Linux one could write a OS driver to or a kernel module if needed
2023-05-26 12:10:08,Bhasha Daan : An crowdsourcing initiative for Indian languages (Beta)
2023-05-26 12:13:07,Jarvis
2023-05-26 12:14:53,Isn't it a bit crazy that Tony stark was sitting on that tech all this while without open sourcing it ?
2023-05-26 12:16:12,5
2023-05-26 12:16:17,Less than that actually
2023-05-26 12:17:30,2-3 years seems doable
2023-05-26 12:22:28,Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.
2023-05-26 12:23:23,"my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint"
2023-05-26 12:25:41,Yeah I read a very interesting interview on this. 
2023-05-26 12:33:44,"We actually don't need LLM call for all queries, which is the case rn. This also results in variable answers for a same given query, which is confusing."
2023-05-26 12:39:21,or some other company build something close to apple silicon
2023-05-26 12:40:06,Heard geohot wants to build AI hardware
2023-05-26 12:40:50,"Run llama 65B for $15,000."
2023-05-26 12:42:03,its actually a fun project though he is trying to get AMD drivers/k mods on par with nvidia
2023-05-26 12:42:18,love seeing his streams man
2023-05-26 12:43:55,"geohot is an interesting character. I love his engineering prowess, but we couldn't see his business side / success when running comma.ai"
2023-05-26 12:45:47,You can do that with 2 x A6000 48gb (8k + 2k rest = 10k)
2023-05-26 12:48:37,true that
2023-05-26 12:49:55,"Nvidia being a B2B business, I wonder how long they will be a 1 trillion company. "
2023-05-26 12:51:51,Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work
2023-05-26 12:53:28,Intelligent doc/image search without uploading personal files to the cloud.
2023-05-26 12:53:36,"Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic."
2023-05-26 12:53:55,was speaking with a data storage company considering building it's local LLMs to help with basic ops on storage/datacentres
2023-05-26 12:54:00,"I go upto the computer and ask it to drop my mother a good morning message on WhatsApp, find me which code is breaking from user and server logs and schedule an appointment with my trainer"
2023-05-26 12:54:01,1. Small workload that doesn't need a state of the art LLM
2023-05-26 12:54:47,So more of a privacy concern? Or latency / cost concern?
2023-05-26 12:55:00,I remember this. This is super cool.
2023-05-26 12:56:09,This makes sense to me. Do we have any evals of how good llama is compared to GPT-4 for information retrieval?
2023-05-26 12:56:12,Both.
2023-05-26 12:56:37,Siri will be less stupid as it can under context
2023-05-26 12:56:41,I agree that privacy will be the major factor for client side implementation. I suppose we will also learn more in Jun. After AI regulation draft in US and Eur
2023-05-26 12:56:56,Like a SQL query helper?
2023-05-26 12:57:03,Does anybody here work/do research in medical/health ai ?
2023-05-26 12:58:32,I think that enterprise info can still be solved by running a LLM in house on a server instead of individual devices? 🤔
2023-05-26 12:59:11,"yes, plus agents for partition management, DB health management"
2023-05-26 12:59:54,"Yeah. The ""on premise"" pricing model is gonna have a major comeback"
2023-05-26 12:59:56,"+1, something like privateGPT having API endpoints?"
2023-05-26 13:00:59,"for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)"
2023-05-26 13:01:02,"regulatory. if u pay close attention to how EU AI guidelines are shaping up (which will influence all other countries), personal health info will be covered under stringent regulations. "
2023-05-26 13:01:36,"for most enterprise usecases however, we have seen acceptance and buy in from banks/enterprises. Forget LLM, the big fight was on-premise vs cloud for normal servers"
2023-05-26 13:07:57,Pocket internets?
2023-05-26 13:08:29,Also how did he pull this off any references?
2023-05-26 13:09:13,"With all the hallucination, I think we have a long way to go before we can use LLMs for medical data, notwithstanding the regulatory environment"
2023-05-26 13:11:14,long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model 
2023-05-26 13:15:11,"From the text: first LLM to perform at an “expert” test-taker level performance on the MedQA dataset of US Medical Licensing Examination (USMLE)-style questions, reaching 85%+ accuracy, and it was the first AI system to reach a passing score on the MedMCQA dataset comprising Indian AIIMS and NEET medical examination questions, scoring 72.3%."
2023-05-26 13:15:43,Aren't these exams notoriously amenable to rote learning?
2023-05-26 13:26:07,that is not the interesting part of the paper. 
2023-05-26 13:30:14,And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?
2023-05-26 13:31:22,"There's agent SDKs like Fixie, something similar for LLMs?"
2023-05-26 13:35:22,So there's two claims here.
2023-05-26 13:35:38,"Or could Apple for example include a tiered subscription for app developers for the ""local LLM api service"" running on the ios device ?"
2023-05-26 13:37:18,"Ahaha, that's a risky precedence 🫠"
2023-05-26 13:37:46,"Also somewhat related, somewhat tangential q :"
2023-05-26 13:48:44,"not yet, but have heard great things about it"
2023-05-26 13:54:39,The reference: https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md
2023-05-26 14:01:35,Anyone have experience using the guardrails (https://shreyar.github.io/guardrails/)-
2023-05-26 14:04:50,"Sama may not be in India, but he is spiritually."
2023-05-26 14:05:21,https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=ACPHEfclkXmi9Z92RTsh9g
2023-05-26 14:05:21,He is coming next week!
2023-05-26 14:05:34,Why isn't the developed west not highlighted?
2023-05-26 14:13:04,"cc Shreya, the creator of Guardrails [PHONE REMOVED] is here as well btw"
2023-05-26 14:13:07,And they've a pretty active Discord
2023-05-26 14:13:42,ahh okay. let me join the discord too and message them..
2023-05-26 14:14:07,You might want to start by using the latest guardrails release which is not on Pypi yet
2023-05-26 14:15:13,The biggest issue with using GPU for inference is that the I/O latency.
2023-05-26 14:15:15,"""Global economy"" which is vastly dominated by developed west."
2023-05-26 14:16:24,how to do that? sorry I am python beginner.
2023-05-26 14:16:49,Let's move this to DMs
2023-05-26 14:18:12,So i guess its entirely upto whether your inference is batch and you are loading the model once.
2023-05-26 14:19:10,Thanks this helps! I’ll dm you as well
2023-05-26 14:24:52,"FYI, its not working in the latest release too - 0.1.7"
2023-05-26 14:34:30,Is there anyone here who works for the DiskANN project for microsoft research? Or know someone there?
2023-05-26 14:43:02,Not really true. It also depends on how fast you can copy the model weights to GPU memory. You can reach speed as fast as a CPU ram too!
2023-05-26 14:45:09,I don't have an answer to this. 
2023-05-26 14:52:45,"nono, I just want to connect with a few people working in the team and bounce off ideas lol…"
2023-05-26 14:55:44,I am working on a detailed prompting guide highlighting all use cases! 
2023-05-26 14:55:59,Will publish the blog as well.
2023-05-26 15:11:21,LLM Prompting Guide from [PHONE REMOVED] from the community: 
2023-05-26 15:11:32,And is pretty damn detailed!
2023-05-26 15:33:29,ChatGPT rolling out to India today for iOS https://twitter.com/OfficialLoganK/status/1661834375028154406
2023-05-26 16:17:10,has anyone implemented this repo
2023-05-26 16:18:13,PSA: 
2023-05-26 17:24:42,This is really good [PHONE REMOVED] and seems friendly to non developers too. Love the part on Tool usage.
2023-05-26 17:46:52,"Hi [PHONE REMOVED] ,"
2023-05-26 17:49:37,"Hi Arpit,"
2023-05-26 17:53:34,https://www.cnbc.com/amp/2023/05/25/elon-musks-neuralink-gets-fda-approval-for-in-human-study.html
2023-05-26 18:03:26,Should we add it to the group description? 
2023-05-26 18:51:39,"We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? [PHONE REMOVED]"
2023-05-26 18:54:42,Expiration TTL: I've been storing date and time in the metadata and dropping entries using a cron.
2023-05-26 18:57:11,how do you go through all the vector keys? There's no filter only by meta right?
2023-05-26 19:00:16,Would using Redis help?
2023-05-26 19:02:10,"""To start, we're releasing the embeddings for every research paper on the Arxiv. That's over 4m items, 600m tokens, and 3.07 billion vector dimensions."""
2023-05-26 19:02:20,Do u see a lot of cacheable queries? I thought that the content would be so disparate that cache hits would be very low
2023-05-26 19:04:57,In business usecases it can save a decent share of queries.
2023-05-26 19:05:10,[PHONE REMOVED]
2023-05-26 19:05:56,really ? but ur vector db query would be a prompt right ? u still see opportunities for caching ?
2023-05-26 19:06:00,genuine question btw
2023-05-26 19:06:07,Who's building LLM benchmarking + observability + semantic caching bundled in one?
2023-05-26 19:06:32,yes - running backtests on some datasets and it looks promising. Will come back when we have production datasets to backtest on. Simple caches already are great for dev and simple classification problems. I think semantic would be useful for RAGs
2023-05-26 19:07:30,hmm.. very interesting. would love to know more when ur ready. have been thinking about the caching problem for a long time.
2023-05-26 19:07:34,yea - people ask similar questions to a chatbot. A friend told me 30% of his chatbot questions (niche) were similar - so could build a cache bucket for such queries
2023-05-26 19:09:00,"In that case, ur cache also needs to be a vector db (like redis). Cos it will be difficult to have a cache hit without transforming the ""question"" into an embedding first"
2023-05-26 19:10:57,Seen in our case. True for users who work in v specific niche. Their prompts can be bundled w little difference in results
2023-05-26 19:11:18,yes
2023-05-26 19:13:16,Oh you're Rohit from portkey? Hi again
2023-05-26 19:14:26,"haha, yes! Hi Ankur"
2023-05-26 19:22:40,"This is also the similar usecase that we had thought of as the queries are kind of similar we were thinking to build semantic cache so we can reduce the latency for openai hits and get the results fastwr to users on bot  But as mentioned here u will need to first create a embedding and then this may work based on cosine similarity , but after some thinking as we were thinking this to reduce the latency of the hits we just did not think this will be helpful as still there is embedding creation part involved and if u go with different embedding model like sbert or something  for this specific cache which has lower latency that is an over kill as u will have now 2 kinds of retrieval as openai embeddings u may still want it as they are superioir , so rather than that we just went with streaming api ,and that helped us better our ux and also helped us maintain the latency or make it feel not that slow ."
2023-05-26 19:23:32,"Hope this helps a long message ,but i feel in this field qe all are facing kind of similar issues .."
2023-05-26 19:34:57,"thanks! streaming helps with latency, but you'd still incur twice the cost for the same / similar questions, right?"
2023-05-26 19:37:31,Very intresting to learn
2023-05-26 19:39:08,"Yeah , u are right , if cost is in question than building a semantic cache with sbert model for retrieval of the same queries answered may help . U may need to create a metadata of the response answered with the query embedding and store that . And when new query comes just fire and get the sbert query se get the similar matches on queries and then acc to  that u may reduce your calls . Very intresting approch this we thought but thought to implement streaming first .. but to make sure this is caching at vectordb layer and not at openai level .."
2023-05-26 19:40:31,This is intresting to desing ...
2023-05-26 20:07:50,Yea I’m almost done except for the ttl bit
2023-05-26 20:11:13,So u have built this using? Like redis or something . Anything that u can share on design or what u have used .
2023-05-26 20:11:54,Not sure but technically redis vector search uses RedisJSON. Which supports update and delete of keys. So I think setting up TTL to JSON object is possible via Multi command.
2023-05-26 20:11:56,Ttl may be for u can be -1 right if the semantic match is beyond aome thrsold for incoming query u dont need ttl per say? Am i missing some
2023-05-26 20:12:15,Thing *
2023-05-26 20:12:50,Yea we saw GPTCache - we built it a little bit further and faster. Design and concept is similar
2023-05-26 20:14:21,This comment also says this
2023-05-26 20:26:36,Thanks! I’ll check this out
2023-05-26 22:30:44,"This is the core difference between CPUs and GPUs: CPUs are optimized for latency: to finish a task as fast as possible; GPUs are optimized for throughput: they are slow, but they operate on bulks of data at once."
2023-05-26 22:32:11,I'd read this a while back I think. This is pretty neat
2023-05-26 22:34:29,If you really want to test your use case 
2023-05-26 22:52:48,Embodied Artificial Intelligence.
2023-05-26 23:50:07,https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
2023-05-27 01:30:54,"As we were discussing cache and TTL, just thought to share this quote ."
2023-05-27 01:32:46,Must be a pre-k8s quote 😂
2023-05-27 07:12:57,Real Life Human Feelings
2023-05-27 08:20:51,"Friends, we're delighted to have over 900 esteemed members in this group, nearing the WhatsApp group limit of 1024 participants."
2023-05-27 08:21:57,"I'm hoping that at least 100ish folks make the transition i.e. join that group, and leave this group"
2023-05-27 09:00:28,"When we look back, the link between symbolic and connectionist approaches would have been the breakthroughs in code generation."
2023-05-27 09:39:21,Any reason this group is on WhatsApp and not Telegram? I'm sure you would have given it a thought. Curious to know the reason. I thought things were easier on TG.
2023-05-27 09:43:37,"WhatsApp continues to be the first choice for most folks in India → Telegram is easier for moderators, harder for users"
2023-05-27 09:44:16,I agree. But is it same with tech folks as well?
2023-05-27 09:45:24,Yes. We all have 2-4 muted family WhatsApp groups
2023-05-27 09:49:11,I meant  that  telegram is more opted for in the tech community. I might be wrong as well 😊
2023-05-27 09:51:23,"Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ? "
2023-05-27 09:52:06,"Samsung, Apple, VISA, MathWorks have banned ChatGPT Plus and deploying the GPT4 API under their own brands"
2023-05-27 09:54:03,"Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model."
2023-05-27 09:56:50,SourceGraph had publicly announced that they're offering every employee the subscription. There was a thread by Shreyas Doshi where he had suggested the same. That thread had many people agreeing that they've reimbursed their employees.
2023-05-27 09:57:28,For org plans there is a provision which allows you to opt out.
2023-05-27 09:58:34,This is what we use as well.
2023-05-27 09:58:54,we as in Paypal?
2023-05-27 09:59:03,Yes
2023-05-27 09:59:25,Azure openai within vpc
2023-05-27 10:03:27,MPL offers chatgpt subscription reimbursement
2023-05-27 10:03:33,Seems like there's a lot of trust for folks to use this over the plain OpenAI Service
2023-05-27 10:03:57,Mid journey as well
2023-05-27 10:07:41,"Looks like B2C or B2B, insecurity and aspiration is where all the money lies."
2023-05-27 10:12:53,We at invideo offer both too.
2023-05-27 10:20:34,h/t [PHONE REMOVED] for saying what I was about to: The latest LLM is from the Govt of Dubai. 
2023-05-27 10:23:18,"To clarify, it's not just latest. It is the top of the HuggingFace leaderboard. Beating all the Llama."
2023-05-27 10:23:53,An instruct or chat fork of this would be 🔥
2023-05-27 10:36:11,But you can turn off history any way
2023-05-27 10:36:30,Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM...
2023-05-27 10:40:31,ai4bharat is training one
2023-05-27 10:44:04,Is ai4bharath a government initiative?
2023-05-27 10:48:24,"Yes, by IIT M"
2023-05-27 10:49:12,Why does indus need one?
2023-05-27 10:49:13,India*
2023-05-27 10:50:47,Number of diverse languages is one I can think catering to Indian needs.
2023-05-27 10:51:56,It is a demonstration that we have talent to build a good one + hopefully a precursor to have a company like mosaic (or hopefully soon something like OpenAI) in India
2023-05-27 10:52:43,We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam. 
2023-05-27 10:55:15,1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced. 
2023-05-27 10:57:53,"Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training"
2023-05-27 10:58:32,Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?
2023-05-27 10:59:48,In fact I see the recent calling for some sort of  license/regulation to train LLMs analogous to the NPT..
2023-05-27 11:00:12,I've used their transliteration demo and it's quite bad
2023-05-27 11:00:59,[PHONE REMOVED] is working with them
2023-05-27 11:01:14,Oh great!
2023-05-27 11:01:26,"Meta showed off a translation model last week that seems to be able to translate between many different languages - they claim 11k languages if I'm not wrong - and perhaps it is possible to build a single model that addresses many different languages (speech to text, translation, etc)"
2023-05-27 11:01:38,Bad in what sense?
2023-05-27 11:02:01,Model capability: quality of output basically
2023-05-27 11:02:44,"Okay! I am curious to know, how you tested the quality of the output?"
2023-05-27 11:03:06,Don't know the users on this group and how they see AI strategy at a high level but I agree that serving a large base of consumers in India is a generally good use of AI. Maybe AI can do what smartphones have done for education in India's Tier 3 cities and towns
2023-05-27 11:05:10,Having local players to serve a huge customer base is quite important. It is just a matter of well preparedness...
2023-05-27 11:05:23,Same. So many are just using Azure OpenAI - either that or I'm in a bubble
2023-05-27 11:05:27,This
2023-05-27 11:05:47,"I have worked with Bhasini models, in touch with few folks who worked on it at IITM before, but not directly collaborating with AI4Bharat team, yet. Let me know if someone can get me an intro."
2023-05-27 11:07:12,"Responding to the OP - one of the biggest blockers for building any LLM is data engineering, data quality. Architectures are grokkable, compute is manageable, getting good and well prepared data is probably the biggest differentiator IMO"
2023-05-27 11:08:22,This is still fine right?
2023-05-27 11:08:48,Yeah that's the positive example for contrast
2023-05-27 11:08:56,Agreed. Even in the AI4Bharat team I see a lot of data leads
2023-05-27 11:09:37,*people in data lead positions I mean
2023-05-27 11:10:19,"No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job"
2023-05-27 11:10:48,Okay!
2023-05-27 11:11:21,"To build base model like LLaMa, IITM will be need a hefty fund or huge support from Azure. MS funded the Bhasini training, LLaMa size base model can be very expensive to train."
2023-05-27 11:11:30,Do you expect complete invertibility here in such cases like- Roman to Devnagari and Devanagari to Roman?
2023-05-27 11:11:45,But since hindi is a phonetic language why do we need ai for transliteration?
2023-05-27 11:11:48,There are already standards like baraha
2023-05-27 11:11:54,Yes. Baraha
2023-05-27 11:12:16,I guess AI4Bharat is still being funded hugely by Microsoft Research and IDC..correct me if I am wrong.
2023-05-27 11:12:27,"For creating datasets, a good start can be to translate the training dataset that is open sourced already like redpajama dataset that is also commercially licensed. Then fine-tune with smaller example datasets to add Indian nuances based on what we want to achieve via instruction tuning"
2023-05-27 11:12:41,Tamil would be a difficult language to transliterated
2023-05-27 11:13:45,No i expect the most colloquially correct looking transliteration from an Indian script (devnagari) to roman
2023-05-27 11:13:47,Also I see that Nandan Nilekani is a sponsor/initiative driver
2023-05-27 11:13:48,The crux is that llm might be overkill for transliteration. And prone to hallucination anyway
2023-05-27 11:14:17,"True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT."
2023-05-27 11:14:34,Makes sense for other NLP tasks.. unless it is something like -
2023-05-27 11:15:05,Great! I will check this out
2023-05-27 11:15:06,Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else
2023-05-27 11:15:28,Okay
2023-05-27 11:17:31,"Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out"
2023-05-27 11:17:58,Ah. I'll check it out
2023-05-27 11:18:50,"I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes."
2023-05-27 11:19:37,That's why gpt 3.5 is able to transliterate without it being finetuned for transliteration specifically
2023-05-27 11:19:50,Because it's not a hard task for state of the art
2023-05-27 11:20:05,Would this overcome spelling mistakes and colloquial / dialects
2023-05-27 11:20:30,Not sure. It's been 8 years since I used baraha haha
2023-05-27 11:20:40,Oh is it!
2023-05-27 11:21:01,They have a long time interest in this. https://news.microsoft.com/en-in/features/with-help-from-next-generation-ai-indian-villagers-gain-easier-access-to-government-services/
2023-05-27 11:21:37,Yea it featured in build
2023-05-27 11:21:40,Interesting question!
2023-05-27 11:22:24,MS probably is targeting this segment.  They'll license the basic models to finetuning/ vectorisation for specific use cases
2023-05-27 11:22:40,Using azure openai service or something similar
2023-05-27 11:22:54,"If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link."
2023-05-27 11:23:13,MS research in particular has been building multilingual chat interfaces for decades (my cofunder has that patent 😆)
2023-05-27 11:23:24,You didn't add mine right😮‍💨 I was the last person before the warning
2023-05-27 11:23:27,And remove you from this group.
2023-05-27 11:24:21,Aren't transformer architectures essentially really effective at translation? The gains we saw in language translation around 2018-19 were largely due to these architectures.
2023-05-27 11:24:57,You'll find out soon enough
2023-05-27 11:25:19,😥
2023-05-27 11:25:24,"My point is that increasingly large models will cover almost all languages, which will likely include most Indian languages"
2023-05-27 11:26:08,"GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today."
2023-05-27 11:26:18,And absolutely not worth any commercial utility
2023-05-27 11:26:36,"MS working closely with us, so I am very well aware of their capabilities. My point was regarding them funding India llm, after spending $10B in OpenAI. IITM themselves can't do it. They may have talent but not resources."
2023-05-27 11:26:42,"Yes, ai4bharat indicxlit is just a 11M model with a single transformer only, so it's expected that it's performance may be lacking in a few areas. Using LLM for transliteration is like bringing a tank to a gun fight, but it does wonderful and works zero shot so can't complain. With GGML quantizations, you can even have <4GB models doing transliteration and more for Indic languages if underlying model is fine-tuned on Indic languages."
2023-05-27 11:27:06,"If anything, perhaps it makes sense to fine tune large models on Indian govt files (let’s say Supreme Court decisions) and solve india specific problems"
2023-05-27 11:27:24,"Ah, this makes sense! So where do you think India would find its edge then?"
2023-05-27 11:27:28,"if I remember correctly, but I might be wrong Sachin [PHONE REMOVED] was doing this for Supreme Court"
2023-05-27 11:27:41,"Do English FOSS, do it better than the world"
2023-05-27 11:28:01,"I'm doing it for Agri and Rural data. But embedding is better solution than fine-tuning, imo."
2023-05-27 11:28:04,Okay!
2023-05-27 11:28:17,"we have a rich collection of files from government agencies, so makes sense to focus on domain specific models."
2023-05-27 11:28:29,Msft funded openai after the fact
2023-05-27 11:28:42,What data sources are you ingesting?
2023-05-27 11:28:45,Digital-twin of the Indian govt operations :p
2023-05-27 11:28:54,Meta and Google have keen interest in Indic languages as well. Google is working on USM for 100+ Indian language support and meta recently released MMS for the same purpose
2023-05-27 11:28:56,https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/
2023-05-27 11:29:16,Replace govt with an AGI 
2023-05-27 11:30:10,also full of horrors!
2023-05-27 11:30:19,Who will hold the switch to the AGI? 🤪
2023-05-27 11:30:44,"Agri universities, ICARs, NABARD, and other other Official recommendations. agri is federal, so no one has unified collection. Collection and getting everyone on board is the challenge i'm solving first. But it is coming around."
2023-05-27 11:31:34,"Yeah, any chat GPT user today should be able to generate text in Hindi, Kannada, Tamil, etc. I've done that a few times, it is pretty neat."
2023-05-27 11:32:48,This seems cryptic.
2023-05-27 11:32:54,"The graph is that of its journey in a new website. It faced initial difficulties adjusting to the new place, but then each subsequent spike is a new skill learnt. The spike grows smaller and smaller as the importance of each new learnt skill decreases."
2023-05-27 11:33:05,“Importance” being a weighted-conditional probability distribution over all the features of the website. It is conditional on the task at hand.
2023-05-27 11:33:45,"So the skill of “tweeting” for [PHONE REMOVED] in this case would probably have the most importance if Nirant was using this on Twitter. For a guy like me, however, it would probably be “bookmarking”. Jokes aside, note that the measure of skill importance is CONDITIONAL on the task I give it. So even though ‘bookmarking’ for me might be the most important skill on Twitter generally, but if my instruction involves tweeting, then that does affect the way it assigns the importance to each skill, and that’s how ‘tweeting’ would be prioritised."
2023-05-27 11:34:26,This is some scary&crazy stuff hence I’m completely off the grid for the last 2 weeks. This is the only thing that matters.
2023-05-27 11:34:53,Thanks. Is there documentation on what tasks this is being trained for?
2023-05-27 11:34:58,no
2023-05-27 11:35:13,too risky
2023-05-27 11:36:38,I have no idea what you’re talking about :)
2023-05-27 11:36:52,"Do you have task domain or task type level metrics of some kind? That would be interesting to see. Yes, the model will still get trained if you feed it different sets of training data (for different tasks) in the same dataset. And I'm no expert in LLM training, have only built one or two."
2023-05-27 11:37:07,That’s unjust for folks who want to follow discussions
2023-05-27 11:37:28,"I only have guesses. Seems Ojasvi is building these models and wants to share a general, high level update?"
2023-05-27 11:37:57,"This is not and does not use a wrapper. I don't have a personal openAI account! And this is not an LangChain/autoGPT/babyAGI fork. This doesn't need internet to operate. There is no fine-tuned model either. The data used for its training is my own, just like the models used."
2023-05-27 11:38:06,"I was doing semantic search on Supreme Court cases. I have dataset of (somewhat cleaned) Supreme Court cases and embeddings..If anyone here is interested in finetuning on it, I can share."
2023-05-27 11:38:08,What are you using as the base model?
2023-05-27 11:38:47,that deserves a research paper for itself ;)
2023-05-27 11:39:15,Haha.. will wait to try whatever you’re cooking there.
2023-05-27 11:39:42,Yes. Still initial stages. Don't know the timelines but I can see the proof of concept around the corner.
2023-05-27 11:39:44,Awesome. Good luck
2023-05-27 11:40:51,Good luck.
2023-05-27 11:45:07,[PHONE REMOVED] please provide your coordinates to air strike registry.
2023-05-27 12:09:59,"Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less."
2023-05-27 12:17:26,Esp given how many back office jobs and call center jobs it's gonna replace. Not enough urgency.
2023-05-27 12:17:44,TII UAE is a state funded entity and it's efforts or output can only be compared at the level of equally backed or rich entities.
2023-05-27 12:20:28,Woah didn’t know falcon was from Dubai. Holy shit that’s crazy
2023-05-27 12:20:54,"I gotta dig deeper, going to find out who’s behind this"
2023-05-27 12:22:52,It's TII
2023-05-27 12:23:22,"By the way, Falcon is not a real OSS. 10% royalty after 1M revenue."
2023-05-27 12:24:27,Would encourage you to check the AUM of any VC fund in this WhatsApp group or any single IITs compute expenses. Or any ITBEES company's profits. 
2023-05-27 12:24:56,What is Falcon?
2023-05-27 12:25:17,SoTA LLM
2023-05-27 12:25:28,https://falconllm.tii.ae/
2023-05-27 12:25:35,Models are available on Hugging Face 🤗
2023-05-27 12:26:12,That’s not exactly bad per se 
2023-05-27 12:26:30,Nothing has inspired more licensing innovation than LLM weights in my living memory
2023-05-27 12:26:47,"Well on the one hand we have ""Open"" AI..."
2023-05-27 12:28:27,"Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?"
2023-05-27 12:28:37,"I agree. I hate CC-BY-NC license, it’s hypocrisy."
2023-05-27 12:28:48,CustomRetriver in LlamaIndex
2023-05-27 12:30:01,"And yes, different indexes is one way to do it. Can use collections if your VectorDB supports that. Qdrant allows metadata filtering which works out of the box for these cases"
2023-05-27 12:30:05,I would've agreed if not for the fact that those compute budgets or any other budgets aren't solely dedicated to this purpose. However my comment was to distinguish the efforts made on a personal level by an individual vs state funded entities.
2023-05-27 12:31:58,"Yeah that's a NC license by definition, non-commercial. MPT initially was launched commercially but due to their usage of a non-commercial dataset for usage, they had to change the license to CC BY NC"
2023-05-27 12:31:58,Can you also do weighted search?
2023-05-27 12:34:27,Na. That has to go via a CustomRetriever in LlamaIndex or similar in Langchain
2023-05-27 12:35:06,"Taking off from what Paras said, I would argue we would be better off focusing on training and empowering people with strong knowledge of ml & they will go on & build amazing things."
2023-05-27 12:36:52,"I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold."
2023-05-27 12:37:40,Which court? India? Europe? California?
2023-05-27 12:38:48,Zuckerberg bhi gaya tha. Kuch nahi bigaad paye courts 🙈
2023-05-27 12:39:10,Curious to hear your take [PHONE REMOVED]
2023-05-27 12:39:46,It'd be too off topic and too bitter for this forum. Let's talk on DMs/IRL
2023-05-27 12:40:02,I’m honestly loving Dubai’s stance on tech in general. They’re at the forefront of blockchain and web3. Very blockchain friendly and they give funded founders a 10 year golden visa. 
2023-05-27 12:40:51,[PHONE REMOVED] any update on Sama visiting blore?
2023-05-27 12:41:36,Got multiple denials. Running down some more leads.
2023-05-27 12:44:37,"10% royalty on trained data without paying data sources or without permissions in many cases. Zuck settled outside courts and paying fines. What I'm saying is that if I use Llama commercially and then Meta goes to court, it won't be straightforward cease and desist."
2023-05-27 12:44:42,"Picking one visionary person to be India's ai czar could catapult India to be an ""ai first mover"""
2023-05-27 12:46:03,Geo boundaries haven't mattered for a while. That's how we've every dev who can fine-tune a LLM on a one way flight outside India
2023-05-27 12:48:05,That's not a fair take with due respect. Kickstarting the ecosystem is always the job of the govt.
2023-05-27 12:49:59,Are you an optimist by any chance?
2023-05-27 12:50:21,How is Dubai leading AI in APAC? (Apart from falcon)
2023-05-27 12:50:29,"To be clear: I agree with Sandeep, I'm just disillusioned perhaps."
2023-05-27 12:50:37,Any other initiatives/ funds?
2023-05-27 12:51:16,FalconEdge funds NLP companies e.g. Verloop.io
2023-05-27 12:57:14,Government doesn't read tweet
2023-05-27 12:58:50,hopefully they watch Mirror Now ;)
2023-05-27 13:00:40,"I feel government stuff also work lot like B2B sales. You need to find the right person in the big machinary who has the power and interest in doing what you want them to do, and find ways to talk to them and work with them directly."
2023-05-27 13:01:00,Some corrections 
2023-05-27 13:01:39,Oh yeah! Have visited a few of these when I was in school. Went to school in Abu Dhabi. 
2023-05-27 13:01:40,UAE boss 🙈💜
2023-05-27 13:01:41,"Some random person in the machinery seeing/reading the arguments somewhere is not enough for them to do something. They already have a lot on their plate, and they might not be in the right position to do something."
2023-05-27 13:19:42,The challenge is language structure...in NLP ... English etc are subject verb object 
2023-05-27 13:23:23,How'd you explain Mandarin and China's amazing progress then? That has no SVO even
2023-05-27 13:23:32,Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...
2023-05-27 13:24:25,"Not just Google, Amazon scans books for selling and that's FUP too iirc"
2023-05-27 13:38:01,That's translation. Transliteration is a much easier problem
2023-05-27 13:40:16,"I’m also curious if Marketing teams have a policy around where AI can’t be used - specially for blogs, public work, journo pieces"
2023-05-27 13:42:12,That's one area where they *want* to use NLG capabilities like LLMs if I think
2023-05-27 13:42:47,*if I'm right...
2023-05-27 13:45:55,Yes that is why in NLP translation ... Language structure is very important. Transliteration is just phonetic similarity so AI4Bharat is not wrong to transliterate from Hindi phonetics to English phonetics. If transliteration is what is supposed to do.
2023-05-27 13:47:38,"Yes Hindi, Hinglish will be different that is another problem. And availability of training datasets is a bigger challenge. "
2023-05-27 13:49:31,"At a fundamental level, I think there are two ways to do this: "
2023-05-27 13:50:45,2. Language understanding - might be more relevant to generate correct embeddings in semantic search - I'm not experienced to say if because of stochastic parrot method ... language understanding will follow
2023-05-27 13:51:29,"The models that do well in this area aren't trained on just one language, they are trained on multilingual dataset and learn these capabilities themselves. What you're referring to as stochastic parrot method is the autoregressive transformer architecture and these SoTA architectures don't care for language grammar structures."
2023-05-27 13:52:56,Models trained specifically for multilingual translation like Bloom models also perform fairly well although I've not seen a good Bloom model for Indic languages. Google and Meta have USM and MMS that Target the same problem for 100+ Indic languages.
2023-05-27 13:53:45,"Yeah, ""stochastic parrot"" is just jargon which is used in the context of the interpretability of these models, but the underlying architectures tend to be transformer based for most of the new LLMs. The sequence of tokens you train on is ultimately a data engineering problem - and yes, the model, its tuning and all are not a walk in the park but the data engineering distinguishes itself by being tedious and messy."
2023-05-27 13:54:48,Someone else in the discussion mentioned low resource languages - that is a key thing here - and Indic translation/transliteration/NLU/G/P will improve by leaps and bounds if we had good datasets to start with
2023-05-27 13:56:32,Tooling also matters. Character sets are different and complex across languages - we have many languages and dialects where phrases constructed to be alike may mean different things. Complex languages and dialects -> rich data corpus -> more data engineering requirements -> more training/tuning time -> longer time to get performant models.
2023-05-27 13:56:33,Yeah I mentioned the 2 key problems that are actually unique to a country like India that no other English speaking nation would face. These give us opportunities to add value and push SoTA in areas where it's useful for us and penetrates the bulk of our country that actually doesn't speak English well.
2023-05-27 15:12:57,Deepfakes are a real problem
2023-05-27 15:14:49,They could be used to create havoc in India especially by political parties' it cells
2023-05-27 15:22:32,"Hey [PHONE REMOVED], I have been working in countering deepfakes in social media(LinkedIn) from past year. Short answer is, for now, every synthetic image has a fingerprint/watermark in it which basic model(CNN/Fourier) can detect, but as we go forward, there will be images(midJ) which bypass this fingerprint thing and new methods would need to develop which involve taking other inputs too i.e. IP, activity on platform etc."
2023-05-27 15:32:46,[PHONE REMOVED] bro you're working on deepfakes detection too right ?
2023-05-27 15:32:56,This sounds like something we discussed/proposed 2-3 months back 👀
2023-05-27 15:33:16,.
2023-05-27 15:36:52,https://medium.com/@steinsfu/stable-diffusion-the-invisible-watermark-in-generated-images-2d68e2ab1241
2023-05-27 15:38:23,"Apart from this, there are some other fingerprint which are exposed when you filter image with some fourier kernels, interesting stuff though!"
2023-05-27 15:47:44,https://paperswithcode.com/task/deepfake-detection
2023-05-27 15:48:50,Good start point for working with deep fake detection.. you get links to the best research with their code
2023-05-27 16:06:47,Folks is there going to be a zoom link to today's get meetup ?
2023-05-27 16:08:15,Cc [PHONE REMOVED] is the curator
2023-05-27 16:09:03,Hello everyone!
2023-05-27 16:15:40,"People have stated availability of training dataset as a common problem to Indic language models. As a country with the size of our population what’s coming in the way of creating the correct kind of datasets? We have a lot of people who speake a lot of languages, don’t we?"
2023-05-27 16:24:25,Work has happened on IndicNLP corpus and you can see a good list here https://github.com/AI4Bharat/indicnlp_catalog
2023-05-27 16:24:53,"AI4Bharat leads the charge on developing models, datasets and applications for IndicNLP (along with MSFT as a worthy industry collaborator)."
2023-05-27 17:21:18,https://www.todayonline.com/world/tiktok-tests-ai-chatbot-tako-philippines-2179071
2023-05-27 18:58:54,Yes we are!
2023-05-27 19:53:44,Link for the AI matchmaker at the meetup - http://ai-matchmaker.us-1.gooey.ai
2023-05-27 19:59:21,https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq
2023-05-27 19:59:27,Are these datasets not big enough to create Indic chatGPT?
2023-05-27 20:00:51,can anyone tell me how they might have done it? How will this work in another account or the long?
2023-05-27 20:05:26,"Folks, anyone using a fine-tuned OpenAI endpoint on Azure? Wanted to know if there is a way to host / access the same endpoint in a different instance - if I want an app in a different resource group on Azure to access the same endpoint. Thoughts?"
2023-05-27 20:08:17,Just load the same context to the LLM for future responses. A user account is just for with and rate limiting.
2023-05-27 20:09:46,*a user account is just for authentication and rate limiting (the LLM does not care)
2023-05-27 20:10:15,cool thanks
2023-05-27 20:31:11,There are amazing line of speakers at upcoming *Huggingface x Inferless x SequoiaIndia* meet-up on *June 10th*.
2023-05-27 20:58:41,A high level piece on medical ai by a16z's Vijay Pande: 
2023-05-27 21:10:10,"Embedding the internet , seems to be a good initiative powered by open source https://alex.macrocosm.so/download"
2023-05-27 22:06:34,These are offline? 😵
2023-05-27 22:07:40,"Eliot will be joining virtually, Prasenjit and Saravana in-person, going to be a great conversation 😃"
2023-05-27 22:17:09,There is a GenAI Hackathon happening on June 10-11 by Stellaris.
2023-05-27 23:11:40,[PHONE REMOVED] please check this before sharing number.
2023-05-27 23:23:15,[PHONE REMOVED] the previous msg was shared before I joined this grp. Kindly reshare it as I am not able to read it completely.
2023-05-27 23:34:21,"If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link."
2023-05-28 00:16:18,https://twitter.com/manaskar/status/1662225822604992512?t=v8dK_ngSb6VIp0hUyOlwrA&s=19
2023-05-28 00:17:20,False promise of fine tuned low parameter imitator models?
2023-05-28 01:02:38,It would be so nice if we had the option to pin this 🤣
2023-05-28 01:04:06,https://www.youtube.com/watch?v=cQO2XTP7QDw
2023-05-28 07:28:36,"I love this channel, the past videos on this channel are also very creative"
2023-05-28 07:39:12,This guy is maker-man!
2023-05-28 08:16:44,"Hi,"
2023-05-28 08:20:31,"In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same."
2023-05-28 08:20:42,But are there any better solutions?
2023-05-28 08:44:19,"Arvind, this stuck out to me while scrolling out on twitter"
2023-05-28 08:47:51,Maintain a vectorDB of the documents and and the links as metadata.
2023-05-28 08:48:28,And would you recommend using a meta data catalog?
2023-05-28 08:49:57,Catalog ss in?
2023-05-28 08:49:58,As*
2023-05-28 08:52:09,I think this will do a good job explaining that I would - https://www.ibm.com/docs/en/icfsfz/11.3.0?topic=zos-metadata-catalog
2023-05-28 08:54:07,"Yeah. Read the news today. When the affiants argued no such cases existed in any credible legal databases, these lawyers argued they didn't consult generative AI ChatGPT and it was the affiant's fault for ""consulting"" the same."
2023-05-28 09:00:28,This would be for comparing the output with the document...?
2023-05-28 09:29:23,Interesting work on citing pretraining data for reducing internal hallucinations 
2023-05-28 09:39:55,"In your case, the model has to cite the appropriate law (or the details from the case). After that, there are two components - "
2023-05-28 09:41:28,"Other way to think is use the agent framework, add vector DB as a tool, only cite from the vectorDB"
2023-05-28 09:44:49,"You can search and retrieve from the vector DB that will be a compilation of Indian law in some way but you'll still need to verify the final reasoning and the details drawn from the citation. The application has the same challenges that a RAG application would face. Even Bing/perplexity ai make up details or generate novel nouns every once in a while, even though the request would be to stay completely factual."
2023-05-28 09:49:50,"In India monetisation is a huge problem. The millions of $ of investment takes forever to recover, if at all."
2023-05-28 09:52:17,Maybe building for India requires a different approach from that used by Si valley firms to deliver scalable value for millions of adopters/consumers. We've got a combination of price inelasticity and discerning consumers here. Monetization for new entrants requires partnerships that build scale and credibility.
2023-05-28 09:54:39,"What's the best proper hosted infrastructure or tips to deploy large Langchain based Prompt Templates, currently the API inference call takes ~104sec with GPT-4 API ? Or any ways to make GPT4 API inference faster by optimising prompts?"
2023-05-28 10:02:30,But we have more than enough speakers of such languages. They aren’t low resource in the sense that these aren’t dead languages. So both the problems are solvable.
2023-05-28 10:05:08,Solvable but currently solved with poor performance. So makes for a good opportunity for pushing SoTA in the context of Indian languages and solving a problem unique to countries like India.
2023-05-28 10:06:18,"Friends, we're all quite passionate about Indic LLMs. "
2023-05-28 10:11:43,https://huggingface.co/aashay96/indic-BloomLM
2023-05-28 10:11:56,If anyone wants to explore indic datasets
2023-05-28 10:26:13,"Some thoughts on this; a) how would you set up a test involving counterfactuals for legal applications? b) can we extract human-readable rules from the model's performance - maybe there is a way to do black box testing for something like this? c) Since we're using LLMs, is it possible to develop conversational interactive explanations?"
2023-05-28 13:13:25,https://github.com/currentslab/awesome-vector-search
2023-05-28 13:13:42,Good repo
2023-05-28 13:17:49,https://jalammar.github.io/illustrated-transformer/
2023-05-28 13:18:00,A great blog to understand transformers in detail
2023-05-28 14:26:18,"If we hit 2k people, we start a podcast"
2023-05-28 14:26:50,I like the joke. WhatsApp groups have a limit of 2^10 people
2023-05-28 14:27:39,xD
2023-05-28 14:30:04,Just fork into group 1 & group 2. I’ve seen eg founders circle doing this
2023-05-28 14:32:03,There are better ways to kill a conversation. I'll give them a chance first.
2023-05-28 14:33:21,Hot take: Nirant is secretly a LLM finetuned on sarcasm
2023-05-28 14:34:09,LLMs not there yet. Ye AGI hai in secret
2023-05-28 14:34:25,He's an LLM designed by policybazaar
2023-05-28 14:36:43,"Actually such humor would be a good predictor of agi, when it comes"
2023-05-28 15:04:21,"The existential horror of having an AGI powered auto-complete pre-empting your every statement with a wiser, and more sarcastic take should be enough to sober up the most progressive optimists amongst us. 😁"
2023-05-28 17:39:22,not involved anymore but a few months back I made a Lawyer Copilot over entire Canadian law for a startup. so can share a bit from what i learnt. 
2023-05-28 17:52:00,"Yessirr, DMing you"
2023-05-28 17:59:32,This is very intresting. How did u split the subquestions? I'm assuming u created few-shot examples
2023-05-28 18:01:28,"Guys for someone who’s a beginner who wants to train a Chatbot from scratch using any open source LLM architecture by fine tuning it on a dataset, can you suggest any resources?"
2023-05-28 18:09:06,I am interested. Just registered for the event.
2023-05-28 18:10:27,"I and my cofounder [PHONE REMOVED] were building LegalMind from 2019-2021 in college and worked with CAM (Cyril Amarchand) at that time we were working with various BERTs and even tried creating a specific Legal Word-vec. However in any case in order for any document that has to be admissable in the court one must provide either a statutory-proof,  constitutionalvalidy and evidence mapping in order for the court to accept it. Majorly while arguing the citations must of a judgment that is disposed of in the courts with proper AIR citings. "
2023-05-28 18:11:40,"You can refer, Harvey, Casetext and see how they might have integrated this, my assumption is Harvey has raised money because they are building a foundation model with legal understanding much like what bloombergGPT is for finance a 30B LLM if I am not wrong"
2023-05-28 18:52:38,https://arxiv.org/abs/2305.15717
2023-05-28 18:56:22,Rule violation wohoo
2023-05-28 19:06:14,great points!
2023-05-28 19:09:19,Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.
2023-05-28 19:09:40,Thank you so much
2023-05-28 19:10:58,"""Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs."""
2023-05-28 19:12:48,I think fine-tuning is best for style transfer and that was quite evident from the start. Full knowledge transfer can't be achieved by fine-tuning anyway.
2023-05-28 19:13:44,Nothing new there. A full fine-tuning would still yield value if the focus is for solving a single problem and not imitate chatGPT in every way.
2023-05-28 19:15:55,Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities 
2023-05-28 19:24:01,I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it’d perform better than GPT-3.5
2023-05-28 19:27:52,Not really. It's a conversational AI with arithmetic capabilities better than GPT4. Without base mathematical abilities you wouldn't ever have a decent model useful in financial/academic research involving computations.
2023-05-28 19:29:18,"Rohit bhaiya, why we do the things we do at all?"
2023-05-28 19:30:28,Using this to create decisive conclusions is usually counter productive no?
2023-05-28 19:30:34,"Agreed on this has little/no real world utility, but for kicks, amazing 😅"
2023-05-28 19:31:10,"Absolutely. I think most astute readers get that this is indicative, not decisive or conclusive."
2023-05-28 19:31:17,Yea - doing it to test / have fun is totally cool
2023-05-28 19:32:55,We might not be able to Black box distill GPT.
2023-05-28 19:39:27,https://twitter.com/shishirpatil_/status/1661780076277678082?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
2023-05-28 19:52:41,"Had read a lot of tweets/talks around this, specifically-"
2023-05-28 21:46:49,"Happy 3 year Anniversary to GPT-3 paper, which came out on May 28, 2020. The arXiv submission alone has >10K citations. "
2023-05-28 21:47:33,That and webgpt was the last paper where openai actually revealed something about their process
2023-05-28 21:47:41,Really pivotal paper
2023-05-28 21:47:47,How much would his CTC be? What are AI salaries like generally in the west?
2023-05-28 21:51:37,His ctc would be in tax free gpu credits
2023-05-28 21:52:27,And a protection from air strikes in case the loss drops? 🤣
2023-05-28 21:53:31,"(Sorry for encouraging off topic salary discussions/inside jokes, let's stop here)"
2023-05-28 21:53:45,Yeah I think this topic will be quite the buzz here. I'm just glad we're finally addressing the elephant in the room 🤣
2023-05-28 21:56:44,Yesterday I posted this
2023-05-28 21:56:56,https://twitter.com/dr_cintas/status/1662475320119656448?s=46&t=FvScmWlwJalkIndmUHhjjQ
2023-05-28 21:57:12,Seems like agents loss curves have to be interpreted in their own way
2023-05-28 21:57:34,I thought we should stop so yudkowsky doesn't drone strike this group
2023-05-28 21:57:59,Since loss function's are nowhere dependent on distance based metrics which are 99% of the loss function used
2023-05-28 21:58:47,The loss metrics I used for my agent were completely based on a different reasoning
2023-05-28 21:59:18,This will definitely become its own field of research
2023-05-28 22:01:16,I am quite curious about this!
2023-05-28 22:01:42,Even cross entropy based ones can be thought of as some sort of a distance metric in a probabilistic space..
2023-05-28 22:02:11,Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric
2023-05-28 22:02:14,?
2023-05-28 22:02:36,Not just the loss
2023-05-28 22:02:49,I actually created my own activation layer 😌
2023-05-28 22:03:16,Okay! That's interesting.. I do something similar for my SciML projects but nothing major..
2023-05-28 22:03:25,Ranking losses are there...
2023-05-28 22:07:10,Nothing major this side either. Just that the standard final activation layers are not fundamentally optimised to the task at hand
2023-05-28 22:07:54,Ndcg is one of them if rank of each output matters
2023-05-28 22:09:29,Okay
2023-05-28 22:09:30,Coming back to this. There is no baseline to compare the performance to.
2023-05-28 22:10:41,There is always a possibility of formulating a toy problem which can then be used to compare the existing and proposed one
2023-05-28 22:53:11,https://twitter.com/davidad/status/1662821792942022656?s=20
2023-05-28 22:55:13,Cc [PHONE REMOVED]
2023-05-28 23:11:17,https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models
2023-05-28 23:14:38,Do you want to add a line about why this is interesting to you?
2023-05-28 23:16:15,Using llms to surface mathematics from statement based problems and then using plug-ins which can do the actual symbolic mathematics might be better.
2023-05-28 23:16:16,Kind of like translating into the language of mathematics
2023-05-28 23:17:08,It seems they are doing  semantic neighbor search (a vector db's traditional role) using LLM.
2023-05-28 23:24:13,"Umm no - “At runtime, for every query entered by the customer, we compute the query embedding and then retrieve top K products using ANN search [4]. To serve traffic in realtime, we cache the product embed- dings and compute only the query embedding online.”"
2023-05-28 23:26:31,Ah ok. I think I misread the interpretation. Thanks for the correction
2023-05-28 23:33:13,Actually I still think I'm correct. The paper seems to indicate the embeddings are part of the model and not separately stored. Am I wrong in this ?
2023-05-28 23:34:05,They use the embeddings to finetune a smaller model for faster realtime inference. Issues at amazon scale 😆
2023-05-29 02:46:00,Hey everyone!  Wanted to share the generative agents implementation I was working on - 
2023-05-29 03:00:16,This is amazing 🤩 
2023-05-29 03:18:34,The game env was created with Unity and then ported to Phaser gaming engine for web.
2023-05-29 07:33:23,"Interesting questions. My thoughts are as follows, but they may not necessarily be the most optimal approach to address this problems:"
2023-05-29 08:09:23,This looks very interesting 😁
2023-05-29 09:19:53,That's some really impressive work would love to contribute to it!
2023-05-29 10:07:52,"I kept track of how the copilot generates code for me after I saw this. My takeaway is if the function is very clear with variables either already defined, or present in similar functions, then the copilot generates from the beginning, else, it doesn't. If the copilot can't figure out what you are doing then it struggles. "
2023-05-29 10:50:03,Is this copilot X or github copilot?
2023-05-29 10:50:22,GitHub copilot
2023-05-29 10:51:43,I see... currently github copilot is weaker than some vscode extensions in terms of code autocomplete if I'm not wrong.
2023-05-29 11:01:24,"Copilot is most definitely the best *free* code autocomplete out there. Most VSCode Extensions are often GPT3.5-Turbo wrappers — many ask for your keys, which is still okay. "
2023-05-29 11:01:52,Copilot Chat or Copilot X is in beta and needs VS Code Nightly builds for some reason 🤷‍♂️
2023-05-29 11:02:45,so basically prompts as a service 😂
2023-05-29 11:04:02,https://codeium.com/ seen this a few times
2023-05-29 11:06:02,Have tried codeium (and a few more) it's not as good as copilot.
2023-05-29 11:06:59,What about tabnine?
2023-05-29 11:08:24,"Also, copilot chat is not as good as GPT4."
2023-05-29 11:08:25,Quite behind Copilot
2023-05-29 11:08:34,"Tabnine made a blip some time ago, I guess it is still good. Copilot is the pre-eminent tool at least in enterprises right now. Dunno about startups and smaller firms."
2023-05-29 11:09:49,There was a lawsuit last Nov - Copilot seemed to suggest code found in some private repos. At least that's what I understand - not sure whether needle has moved
2023-05-29 11:09:52,None as good as copilot but codeium is one of the best free copilot alternatives out there that has chat option as well. This and Source graph Cody are very useful. 
2023-05-29 11:09:53,Absolutely nothing is as GPT4. 
2023-05-29 11:09:57,Atleast for Python
2023-05-29 11:11:34,Folks is there any hack for getting GPT4 api access ?
2023-05-29 11:12:10,"Increase your open AI gpt 3 bills, that's the only one i know of"
2023-05-29 11:24:30,Any idea how this compares to replit ghostwriter?
2023-05-29 11:26:08,Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong
2023-05-29 11:27:26,I could add my friend here to the group who worked on Ghostwriter
2023-05-29 11:29:06,Even databricks recommend to use this
2023-05-29 11:46:00,Ghostwriter won’t be open sourced but Replit v1-3 LLM is open source under CC BY
2023-05-29 12:01:40,Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.
2023-05-29 12:03:32,Generate 3D meshes and 360 degree videos from text.
2023-05-29 12:26:43,Very good
2023-05-29 13:58:10,[PHONE REMOVED] are you taking about the Stellaris one? Some people above were interested - [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED]
2023-05-29 14:21:15,Yes thanks will DM them
2023-05-29 14:29:35,Which hackathon is this? Could you share the link?
2023-05-29 14:51:02,Yessir im going
2023-05-29 14:51:52,it's the stellaris one
2023-05-29 15:22:08,there is one happening in mumbai this weekend as well
2023-05-29 15:24:01,can we have a plugins hackathon like the SF one for people who have Plugins access?
2023-05-29 15:26:39,"oh interesting, could you share the link to that?"
2023-05-29 15:26:55,mumbaihacks.com
2023-05-29 15:28:07,https://twitter.com/mumbai_tech_/status/1659198245984419840?s=20
2023-05-29 15:55:58,Outlier features are indeed being handled with 16 bit mat multiplication
2023-05-29 15:56:23,But the paper specifically mentions that these features are only 0.1% of total features
2023-05-29 15:56:43,"this decomposition operation only consumes about 0.1% additional memory. Therefore, it doesn't defeat the purpose of using lower precision computations to save memory."
2023-05-29 15:57:01,Yeah when we maintain W in half precision and int8 both aren't we doubling the memory
2023-05-29 15:59:29,The outlier part is never handled via 8bit but remains 16 bit. But since the outlier features are very small as per this paper (https://arxiv.org/abs/2208.07339) it doesn't make performance difference. But your question was valid and it will be an issue in scenarios where you are dealing with huge number of outliers which I have not considered in detail before.
2023-05-29 16:05:38,https://revoicer.com
2023-05-29 16:30:51,I got the answer..all the matrices are int8 quantised and they also keep track of scale factor needed for each Matrix to dequantise.
2023-05-29 17:11:54,"Is anyone aware of an open source/free ML tool that analyses voice and categorises it as monotonous, too many fillers, too many pauses, engaging, exciting, etc?"
2023-05-29 17:13:03,"If anyone knows of speech pathology identification tools using ML - such as vocal fry identifiers, I’d be interested in knowing as well"
2023-05-29 18:00:25,"hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user."
2023-05-29 18:15:20,"Re: #1, in addition to averaging here are few general methods for combining embeddings: "
2023-05-29 18:22:57,There’s this unique challenge in matchmaking - you can’t just get the top-k results from a vector search and call that your top matches. 
2023-05-29 18:36:39,Can you elaborate on matmul part?
2023-05-29 18:47:55,"The matmul is just a quick and easy way to get a nice distance matrix. But yes, same operation mathematically. The important part is that you have some way to factor in the reverse relationship too."
2023-05-29 18:59:35,"And embedding search is still very much a fuzzy similarity score. For real world I think you need something like amazon’s recent paper on finetuned embeddings on a particular dataset, or a quick hack to just feed the matches into gpt-4 and ask for scores based on some explicitly illustrated criteria in prompt."
2023-05-29 19:03:42,Yeah so you probably average the distance
2023-05-29 19:08:04,The leaderboard seems to have a litter of tasks you can eval against - https://github.com/embeddings-benchmark/mteb#available-tasks
2023-05-29 19:09:10,"IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections. "
2023-05-29 19:10:07,This must be heart breaking. Getting rejected from canada of all places..
2023-05-29 19:22:53,This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. 🥲
2023-05-29 19:23:38,"But why'd this be the case? If anything, they should want IISc folks, right?"
2023-05-29 19:24:18,This was the case earlier with Aerospace degree holders/researchers
2023-05-29 19:24:24,Now AI..nothing different
2023-05-29 19:28:59,And i bet lots of students from India go to Mila and  lots of Canadian universities every year.
2023-05-29 19:30:20,I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else
2023-05-29 19:31:23,This is fantastic for the zero-sum mindset in me. More talent will stay back in India because of this news going wide 🤣
2023-05-29 19:36:31,Mila and UToronto are two of the very best for sure
2023-05-29 19:37:06,I thought Canada was welcoming towards International students / tourists/ job seekers
2023-05-29 19:43:31,"I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai"
2023-05-29 19:46:35,Quite possible! The Indian academic mindset should also shift from journal publication oriented approach to more prestigious conference proceedings + open review approach
2023-05-29 19:46:37,There were others (not students) who faced similar problems - https://twitter.com/RisingSayak/status/1663102361752186880?s=20
2023-05-29 19:46:54,This has been happening for quite a few years atleast with the US.
2023-05-29 19:48:28,"I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR."
2023-05-29 19:48:42,"'Drone', 'AI', 'chemistry', 'nuclear' , 'aerospace', 'aerofoil' etc are some key words always attracted pink slips or straight rejections"
2023-05-29 19:48:57,Yea! I guessed so
2023-05-29 19:49:23,Is their job market saturating/stagnating because of the recession?
2023-05-29 19:50:06,But if that is the case then you should reject work visas 😅
2023-05-29 19:50:15,https://blog.y-axis.com/jobs-outlook-in-canada-for-2023/
2023-05-29 19:50:19,Yea!! Exactly
2023-05-29 19:50:30,But that doesn't seem to be the case :p
2023-05-29 19:57:26,"thanks for the tips, will check out ai matchmaker repo as well 👍"
2023-05-29 19:58:01,thanks! will try these out
2023-05-29 20:00:09,"Thanks, [PHONE REMOVED]"
2023-05-29 20:37:18,This is for how many vectors?
2023-05-29 21:03:50,"All configs, code are from ann-benchmarks.com"
2023-05-29 22:05:58,"Unfortunately, this is nothing new. Happens every year as one of ICML/ICLR/NeuRIPS happens in Canada. 😕"
2023-05-29 22:45:18,Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?
2023-05-29 22:47:13,"Yeah, playing with almost all of the decent ones on M2 pro"
2023-05-29 22:48:12,"Are you running this via GPT4all Mac app, try mpt 7B?"
2023-05-29 22:53:27,I'm using a Jupyter notebook and using langchain.  Let me try mpt7B.
2023-05-29 22:54:03,PrivateGPT
2023-05-29 22:54:20,"Check it out , it's available and setup is also easy"
2023-05-29 22:58:14,Yeah it is good with external docs as well. just that it gets slowed down a lot with increasing number of threads. Still haven't gotten around using the langchain support on this but I love this project.
2023-05-29 22:59:01,"I think he has updated his repo , as he also launched it on product hunt , haven't tried the new one yet"
2023-05-29 22:59:34,You can also have a look at this 
2023-05-29 23:00:08,It's a product tear down of rewind might help check how they have integrated locally
2023-05-30 00:55:44,"I have been facing some issue with setting up the falcon model on sagemaker ,mainly dependency issues"
2023-05-30 01:09:42,I'm running it on a100 80G
2023-05-30 01:09:44,responses are decent
2023-05-30 01:09:49,Enter your text: what is technical innovation institute UAE
2023-05-30 01:10:00,This is the 40B instruct chat model
2023-05-30 01:10:19,what issues you facing :)
2023-05-30 01:19:47,got it working
2023-05-30 10:28:43,"Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm? "
2023-05-30 10:33:25,Have you seen this by llama index creator?
2023-05-30 10:42:27,Can Branch help? 
2023-05-30 10:44:52,Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?
2023-05-30 11:52:49,Nvidia announced a new DGX system with 100TB GPU memory 
2023-05-30 11:53:53,Wow
2023-05-30 12:22:35,"Looking for a good Video based Interactive Python course for a begineer, fastai one could be difficult to go, any suggestions?"
2023-05-30 12:24:48,I came across this really nice one by Sanjeev Thyagarajan on YouTube/FreeCodeCamp. Worth checking out despite its considerable length. https://youtu.be/0sOvCWFmrtA
2023-05-30 12:36:59,Hey everyone! 
2023-05-30 12:38:18,Do you have any specific usecase in mind or are you just exploring ?
2023-05-30 12:43:32,"vakyansh , suggested to me previously by [PHONE REMOVED] "
2023-05-30 12:43:51,yes it's for product advertisements.
2023-05-30 12:44:26,https://github.com/Open-Speech-EkStep/vakyansh-models
2023-05-30 12:45:33,"For TTS, OpenAI Whisper?"
2023-05-30 12:46:11,Thanks [PHONE REMOVED]  will try this out
2023-05-30 12:47:41,"yep . I'm yet to compare the results between whisper and meta mms , esp for indic . will share it here"
2023-05-30 12:48:13,this is STT though
2023-05-30 12:48:25,sorry I had misread earlier
2023-05-30 12:50:42,"np , just saw vakyansh has TTS too . https://github.com/Open-Speech-EkStep/vakyansh-tts"
2023-05-30 12:53:43,"Vakyansh has build great models, I have personally used them"
2023-05-30 12:53:50,Gives great results
2023-05-30 12:55:33,"Whisper is pretty bad though, from personal experiences."
2023-05-30 12:56:04,"nice, what did you use it for?"
2023-05-30 12:56:35,classification
2023-05-30 13:24:13,Any hackathons happening soon?
2023-05-30 13:30:58,https://www.mumbaihacks.com/ - this weekend in Mumbai
2023-05-30 13:32:59,Me and [PHONE REMOVED] were talking in the last meetup if any other similarity metric other than Cosine similarity could potentially give better results. He was of the opinion that it wouldn’t matter much unless for specific usecases.
2023-05-30 13:34:43,"Also, was wondering if anyone has tried hybrid search mechanisms yet (bm25 + embeddings) : not one after another as a fallback, but together"
2023-05-30 13:42:35,"My take is slightly more nuanced, sorry if this was not clear. Simple 1-1 similarity metrics like Cosine, SAD, SSD etc won't matter much except for specific use cases. There are problems that can't be solved using just distances alone (selective attention mechanisms: Where you use completions etc, more powerful search algo like hierarchical representations etc), these are different class altogether."
2023-05-30 13:43:07,Anyone want to team up for the generative AI track in mumbai? Please DM! Would love to jam and collaborate!
2023-05-30 13:43:25,right right correct
2023-05-30 14:05:34,"We at PayPal use Hybrid search for our Enterprise Search which powers a lot of use cases - consumer help, merchant help, dev experience, intranet articles, etc."
2023-05-30 14:06:15,I think that should be the standard. Pure neural search performs badly in a lot of use cases.
2023-05-30 14:06:55,We use bm25 + neural search + things like doc2query
2023-05-30 14:07:07,Have too used hybrid quite a few times.
2023-05-30 14:09:45,"This is fairly common. You often have specific keywords that needs to be matched like tags, categories etc, in such cases regular search is really good."
2023-05-30 14:10:39,And the secret sauce is also the re-ranker across such indexes.
2023-05-30 14:23:14,Is the re-ranking done in a user-personalized way or based on something else?
2023-05-30 14:24:15,this is very interesting. this is much like generating metadata for each document and using that for embeddings.
2023-05-30 14:26:32,I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch
2023-05-30 14:26:55,Let's you weigh disparate input signals
2023-05-30 14:27:07,exactly. i was thinking the same thing. unless u are using two separate db here..in which case i dont know how to do it
2023-05-30 14:27:19,We use this at dukaan to compute similar-products.
2023-05-30 14:32:58,We have a long journey. We started off with bm25 and faiss. Now we have dense vectors in elastic itself.
2023-05-30 14:33:12,"But still, we continue to use our custom re-ranker for final results"
2023-05-30 14:33:43,but just curious - how does ur custom reranker combine the output of faiss and Elastic-bm25. in memory ?
2023-05-30 14:34:17,"Yeah, like Ragotham said too deep and some NDAs. There are many ways to combine and depends on problems. Example to flavour: think Math equations, Chemistry equations etc. You will need different distance functions (say you want similar quadratic equations), modifications to rankers etc. Many ways to do this, we have written custom rankers, distance functions etc in Solr/Lucene. Can't talk more unfortunately."
2023-05-30 14:34:41,ah ok. no probs. thanks for mentioning anyway 🙏
2023-05-30 14:35:24,There was a post by Karpathy on Twitter where he compared nearest neighbour vs SVM.
2023-05-30 14:35:26,There are various ways to do it. Think of it as results coming from various sources and you need to rank them. One Can start with simple weights as re-ranker or go full blown learning the weights as well.
2023-05-30 14:35:34,"Just curious how it performs , i am trying with faiss"
2023-05-30 14:36:12,"And funny thing is sometimes, it is just prodding the user right or providing UI mechanisms for user to nudge us correctly."
2023-05-30 14:36:49,The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime
2023-05-30 14:36:57,"Works well. Can't scale as orchestration is a pain. And when you say enterprise search, it is more like search as a service for the org. So, needs better tools / frameworks like full feature vector db"
2023-05-30 14:37:52,Will try it with bm25
2023-05-30 14:42:04,It needs to be trained for each query !! (or cached) Haha.. That was the context of this discussion.
2023-05-30 14:43:46,"Yeah, the SVM idea as he mentioned is not for enterprise scale. It gives better accuracy for small scale data."
2023-05-30 14:44:30,actually im a big believer in the composite ranking that you did. and that belief goes hand in hand with infrastructure tie in. 
2023-05-30 14:56:21,"Check our the recys paper that [PHONE REMOVED] had posted. It's a slightly terribly written paper but will give you ideas on how TikTok is mixing some of these. There are enough details. For them, freshness can be what is trending video in last 30 mins !!"
2023-05-30 14:58:23,*out
2023-05-30 15:00:34,i'll be honest - i didn't understand how SVM had a better performance than KNN.
2023-05-30 15:00:45,Just curious how any pre-trained cross encoder will perform?
2023-05-30 15:10:25,"So in this case, karpathy argued that SVM cares for the unique aspects of your data more and hence better accuracy. Knn is computationally better but fails to preserve unique cases "
2023-05-30 15:14:12,"yeah, saw that. but didnt get it fully, maybe need to read more"
2023-05-30 15:42:55,"SVM will typically have better performance than KNN because it's mathematically guaranteed to be a strong learner. KNN has the desirable property of being very fast for retrieval inference, so it gets used everywhere. Karpathy had a small, fixed dataset, so inference speed wasn't as issue (wasn't needed), and SVM did better."
2023-05-30 15:43:41,Any strong learner (like boosted trees from xgboost or lightgbm) would have done better than KNN
2023-05-30 15:47:03,but what is the ground turth on which learning is happening?
2023-05-30 15:48:45,I share the confusion. There are no labels here
2023-05-30 15:51:38,😂 that's the beautiful thing about his example
2023-05-30 15:52:00,We have ground truth: the query is identical to itself
2023-05-30 15:52:44,"Everything else is not. The embeddings are assumed to be semantic ones, so the trained model works out for this small dataset"
2023-05-30 15:53:51,but isn't that what classical machine learning is all about? Expecting future data to follow the same distribution as past data
2023-05-30 15:54:19,I don't understand the question
2023-05-30 15:55:06,"like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain"
2023-05-30 15:58:13,https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
2023-05-30 15:58:19,"Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)"
2023-05-30 15:58:20,This has all the answers
2023-05-30 15:59:25,"You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth."
2023-05-30 16:01:41,"We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods"
2023-05-30 16:02:25,"Traditional ml includes NN for tabular data, btw, as those are strong learners too"
2023-05-30 16:10:51,right
2023-05-30 16:16:44,"I remember a project from a couple of years ago where ARIMA/SARIMA class models routinely did better at time series forecasting than deep learning models. I can vouch for good feature engineering + logistic regr for a text classification use case being better than an LLM with prompt engineering and all the jazz - in a specific area, limited or smaller models can work very well."
2023-05-30 16:18:53,"In KNN, you look at k neighbors using some distance metric. Here the assumption being k and distance function being right for the data. Imagine a case where each position of your embedding direction is in different range and scales differently. Thus a simple Euclidean, L1 might not be good. Typically circa when people did PCA or other features etc, they would normalise the vectors to avoid this."
2023-05-30 16:20:57,Though I imagine normalization is only viable if you are going to get your embeddings from 1 model and that alone?
2023-05-30 16:21:22,Going to be a mumbo-jumbo that were to happen across different source-models :P
2023-05-30 16:24:46,"Minor corrections, so edited both above. It's hard to be accurate on WhatsApp, when typing furiously on phone :)."
2023-05-30 16:25:11,You normalize over columns and not rows.
2023-05-30 16:25:52,This is what people used to do before.
2023-05-30 16:34:10,"But that would make inference necessarily complex, no?"
2023-05-30 16:35:13,"Without embeddings from all the embedding-sources using which the index was built, no inference can work reliably"
2023-05-30 16:43:41,actually....
2023-05-30 16:43:51,"If you were to store your min,max,mean values for all the normalization operations"
2023-05-30 16:44:12,"you can re-use them on the embedding, if you know the embedding-source, which you probably would do"
2023-05-30 16:44:38,this can then work
2023-05-30 16:45:11,"I was still talking about the old style. Yes, for multi modal one way is to normalise them across columns for each modality. I think the more prefered one, I have heard is to normalise across rows, so sums to one for each modality. Thus both vectors are equally weighted. In this case cosine will be same as dot product."
2023-05-30 16:45:17,Let's take it offline now.
2023-05-30 16:46:41,"On a tangent, are there any product-folks here who might have worked closely with AI features?"
2023-05-30 16:49:14,"I have a question, I'll keep it open-ended."
2023-05-30 16:51:04,"their goal is maximizing view time on platform (as that drives monetization), so in their A/B test, this would have worked"
2023-05-30 16:53:01,And what kind of reasoning does a AI Product team use to decide if they should replace a feature or give it as an alternative option?
2023-05-30 16:54:01,Because there is an argument always to let the user tune these hyper-parameters
2023-05-30 16:54:21,to their own liking
2023-05-30 17:01:01,my understanding is that this is some sort of A/B test and you're in some other bucket. I'm seeing a variety of similar videoes not just the ones I've already seen.
2023-05-30 17:12:12,https://huggingface.co/decapoda-research
2023-05-30 17:13:36,In general - To match their attempt at User Profiling to predicting what maximizes engagement / consumption time
2023-05-30 17:19:02,Beautifully explained. This is a gem.
2023-05-30 17:19:36,Rec sys is almost entirely about being able to model the human brain
2023-05-30 17:22:50,Absolutely. And maturing the rec sys almost comes down to about generating a space where the sys can atleast mirror ( if not predict) the transition of human behaviour when exposed to matching / disparate data_types
2023-05-30 17:27:21,"Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)"
2023-05-30 17:32:10,"Spellbook, StackAI and Humanloop seem to be three in the space. Haven't used or evaluated them though"
2023-05-30 18:50:47,Have you used humanloop's product? Been trying to evaluate it but haven't gotten the access yet.
2023-05-30 18:53:10,[PHONE REMOVED] is building portkey.ai
2023-05-30 18:57:30,Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain
2023-05-30 18:59:09,The langchain handbook by pinecone
2023-05-30 18:59:10,What’s your use case?
2023-05-30 19:03:49,"+1 for portkey. We evaluated humanloop, promptlayer, promtbase? and some others but landed on portkey"
2023-05-30 19:03:58,Building an internal sales assistant to better prep sales reps for calls
2023-05-30 19:04:51,I have a lot of pdfs and sales enablement materials and now I want a chat with them
2023-05-30 19:05:42,How will human loop help here exactly?
2023-05-30 19:06:08,"They are for prompt management, A/B testing prompt, getting feedback"
2023-05-30 19:09:34,Sorry I don’t understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own
2023-05-30 19:13:45,"something like https://www.chatdox.com/ would be useful for this. I believe there are some open source solutions as well, though depending on your use-case, building something from scratch can also be faster."
2023-05-30 19:14:00,I think two threads got mixed 🥲 
2023-05-30 19:18:18,1. Evaluating different models and comparing
2023-05-30 19:18:21,"Thank you so much. Def looking to do the old fashioned Build from scratch instead of buy for a couple of reasons (resources constraint plus learning also is important, hence the request for videos haha)"
2023-05-30 19:20:16,Evaluating how?
2023-05-30 19:20:50,[PHONE REMOVED] is the founder and can help
2023-05-30 19:22:25,Like trying out different open models simultaneously on a bunch of queries and comparing performances while fine turning
2023-05-30 19:23:30,will try portkey
2023-05-30 19:23:54,Try the tutorials by James Briggs.
2023-05-30 19:24:22,comparing how? Human feedback or through some metric? Best to run a python notebook in that case
2023-05-30 19:25:13,Thank you so much. Will try these out 🙂
2023-05-30 19:26:31,"Hey! I'm Aryan here, and i just passed out of highschool a few months ago, and I used to code back when i was in 8th or something and now am looking to get back into it full time and find internships in the ai/ml field. But i wanted to first gain experience and build a portfolio, so how do i start as a newbie in the field (courses etc), there is so much of info I feel clueless."
2023-05-30 19:27:42,"I just know python, and have worked on one or two projects with the help of gpt, but i don't feel like I learnt much, should I do more math etc and go the conventional method?"
2023-05-30 19:29:41,On babylm & the quest for smaller LLMs
2023-05-30 19:36:06,"Observation: GPT-4 browsing can be used to access text webpages which were once unclickable by saving a snapshot of the webpage on the wayback machine. Not sure how true this is, but it worked the first few times I tried."
2023-05-30 19:45:02,"Anyone tried hands on privateGPT , how it is performing. I have a usecase where i have to extract parties and legal description part from the documents and i tried to use gpt4 and able to get almost Perfect answers for prompts. But constraints here i can't use gpt4 , something i can train or use locally"
2023-05-30 20:37:53,Great resource. 
2023-05-30 20:38:11,What are the open source tools for prompt versioning and prompt management?
2023-05-30 20:38:47,More advanced guide
2023-05-30 20:40:55,Promptable is open source but not great. For simple stuff I’ve seen people manage conf files for prompts and then use them with an SDK like Langchain
2023-05-30 21:09:25,"not me creating TEMPLATE_1, TEMPLATE_PREVOUS, TEMPLATE_NOT_TO_BE_USED, TEMPLATE_ACTIVE"
2023-05-30 21:16:55,Isn't prompt the same as any kind of knob/config in SW? Why not just treat it the same for flavour/variant control via config files? 
2023-05-30 21:20:35,"It works alright for RAG based QA, you'll have to test for your specific use case as it'll be inferior to GPT4 in extracting dependencies and may miss out on few parties here and there as per my observation."
2023-05-30 21:24:08,Where the TEMPLATE_Final_pleaseworkthistime
2023-05-30 22:08:47,anyone here going to the airport to welcome him? 😂
2023-05-30 22:09:51,"As a large language model, I cannot travel"
2023-05-30 22:17:21,Government should lobby Sama to put Indian users of OpenAI on same priority as those in the US. And integrate UPI for payments.
2023-05-30 22:24:32,Are indian users devoid of any features?
2023-05-30 22:24:40,As I'll be switching to an Indian paid subscription soon
2023-05-30 22:25:03,"Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5"
2023-05-30 22:25:47,Some features get rolled out late to Indian users. Iphone app is the recent onem
2023-05-30 22:25:57,Same with a Indian subscription
2023-05-30 22:26:03,*an
2023-05-30 22:26:13,Alright that's a relief
2023-05-30 22:29:27,Is anyone aware of an AI music generator that can do background scores for video?
2023-05-30 22:30:11,do check out - https://riffusion.com/
2023-05-30 22:30:34,"Beatoven, Mubert"
2023-05-30 22:35:28,Do indian users have access to gpt plugins? Even after being a premium user?
2023-05-30 22:35:54,Yes
2023-05-30 22:36:04,"Yes, have access"
2023-05-30 22:36:28,"Although, I'll be honest. Plugins have been quite mediocre so far"
2023-05-30 22:36:45,Strangely it does not work for me. Not sure. Will check with you.
2023-05-30 22:36:46,Browser fails quite often at basic tasks
2023-05-30 22:36:53,Hope they fix that soon
2023-05-30 22:37:09,Interesting! but i found them to sound similar to each other
2023-05-30 22:37:26,"Logout, then login and check settings. If you find beta features, look for plugin/web browsing and enable it"
2023-05-30 22:37:32,How so?
2023-05-30 22:37:45,Is it a click failed failure?
2023-05-30 22:38:00,Yes. That's the most common one
2023-05-30 22:38:06,There are a couple of others as wdll
2023-05-30 22:38:12,This is common because of robots.txt
2023-05-30 22:38:22,I found a workaround earlier.
2023-05-30 22:38:30,.
2023-05-30 22:38:54,Scrapers/link readers have worked very well for me. Web browsing option can fail more frequently.
2023-05-30 22:39:15,"Oh, thanks! Now it works."
2023-05-30 22:39:19,Interesting
2023-05-30 22:40:12,"I think someone on this group (or maybe Twitter) quite astutely pointed out that if meta had built chatgpt, they would have engineered it for crazy amounts of continued growth"
2023-05-30 22:40:38,Openai gets basic UI wrong sometimes. Like the fact that you can't search on plugins is just a big oversight
2023-05-30 22:40:59,"If you want to find a plugin, you need to manually scroll through each page to install"
2023-05-30 22:44:30,"I think not giving a serach bar to find plugins is a calculated move, provided that it's purely growing word of mouth they'd want everyone to know at least some more plugins apart from just their use case and would be tempted to try more. "
2023-05-30 22:46:00,But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing
2023-05-30 22:46:11,Which will not be the case with any browser based extension
2023-05-30 22:46:52,What is the context window they're providing
2023-05-30 22:46:53,Gpt-4 is able to take an entire webpage as input context
2023-05-30 22:47:24,Probably the increased model.
2023-05-30 22:47:28,32k token limit
2023-05-30 22:47:53,Because in chatgpt the gpt4 is limited to 4k
2023-05-30 22:48:43,Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.
2023-05-30 22:49:10,I think there are techniques to help with that
2023-05-30 22:49:55,We have a feature at longshot as well where we read multiple web pages not just 1.
2023-05-30 22:59:07,"True, the plugin interface design should've been similar to play store or iOS app store. It's quite obvious the natural direction of plugin developement is going to be the same as Android/iOS. May be searching and review based system would be implemented once their beta phase is over for plugins."
2023-05-30 23:01:06,"True, I was using plugins to go through YouTube podcasts to identify books/ideas/thought experiments at once. But it was not doing well for anything longer than 1 hour."
2023-05-30 23:06:48,My experience has been similar. Interested in talking if someone has had a good experience with plugins
2023-05-31 00:04:53,Is there a good way to keep a preffered token length of variables inside a prompt template?
2023-05-31 06:41:53,I used show-me plugin for creating flowcharts(for PPT slides) ..seems to be doing a good job.
2023-05-31 06:55:43,Memory e.g. ConversationalMemoryBuffer does this in Langchain?
2023-05-31 10:23:47,"I've confirmed reports from several devs and founders that GPT4 API has unusual RateLimit Errors in last 48 hours or so. Creating a new key seems to help. If you've a personal account, upgrading it to organisation also seems to help."
2023-05-31 10:30:23,Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching
2023-05-31 10:37:29,I thought sourcegraph was awesome but this looks cool. Will check it out
2023-05-31 10:49:26,In fact sourcegraph might be better for a more deterministic browsing
2023-05-31 11:23:54,Could give generative fill a shot in Adobe photoshop without any prompt
2023-05-31 11:42:10,Any news on Sam Altman’s delhi visit?
2023-05-31 11:50:11,This is some complete colab level BS
2023-05-31 11:50:30,You select A100 and you get T4 kind of scam this
2023-05-31 11:50:35,Cc [PHONE REMOVED] any insider info from tcs? 🌝
2023-05-31 11:50:39,Since when. I have been using since morning..
2023-05-31 11:51:19,Right now. Mainly on Code Interpreter.
2023-05-31 13:58:50,https://news.ycombinator.com/item?id=36134249
2023-05-31 14:01:28,"Yes, too much RLHF"
2023-05-31 14:04:29,‘Dumb stochastic parrot’🤣
2023-05-31 14:18:13,How has been people's experience with Claude 100K?
2023-05-31 14:21:51,Good.
2023-05-31 14:22:24,It's definitely very good but lacks some things that gpt4 etc have. It's much faster
2023-05-31 14:22:28,Its called the great AGI disillusionment
2023-05-31 14:22:44,Also prompt engineering is a little different here
2023-05-31 14:39:57,"I mean, Sama is publicly speaking about the species-level dangers of AI, what do you expect? We only get Nerf guns from now on. 😀"
2023-05-31 14:43:02,I keep a nerf water gun with me all the time in case my GPUs suddenly become sentients.
2023-05-31 14:45:00,NSA has a backdoor to all modern cpus / gpus
2023-05-31 15:30:54,Could be that they quantized the model further which leads to faster inference times but reduction in quality.
2023-05-31 15:32:34,+1
2023-05-31 15:36:21,"Yeah if the model has gotten dumber and faster, it's most likely the result of *model compression*. Not quantization though, that'll most likely Nerf it down completely. Also we aren't sure if openAI has started anything resembling GGML/GPTQ quantization internally."
2023-05-31 15:37:25,Has anyone used or knows the best model for english to chinese translation? A bunch of them on HF but if anyone has experience in something else it’ll be great
2023-05-31 15:39:30,"Anybody here regularly finetuning llama, opt or gpt j 6b? Have some quick questions to ask related to approach for the same. Thanks!"
2023-05-31 15:40:13,PSA: 
2023-05-31 15:50:05,"strange, on my codebase it really sucks. Most answers are super lame or fail with ""something went wrong"". Doubtful if I'll use it on an ongoing basis"
2023-05-31 16:08:14,"There is an interesting conversation going on in the *AI and Philosophy* WA group on the regulator, AI research companies and the recent ""AI will cause extinction"" tweet signed by OAI, Stability and others: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV"
2023-05-31 16:08:15,"Related: For folks interested in *Generative Art*, including images, video and music: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4"
2023-05-31 16:35:26,"BTW this is interesting https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized - comparing token sizes for the same sentence in different languages. My takeaways: 1. in some languages token numbers will be unexpectedly high 2. If you're consistently using an LLM with non-English inputs/outputs it may be worth building an LLM with lang specific tokens (I remember we were discussing this a while back in this group) 3. Most likely this would apply to obscure english words too in domains like medical, legal etc which have a lot of foreign words (latin, Greek etc) or domain specific words"
2023-05-31 16:36:49,Number of tokens:
2023-05-31 16:41:56,"If I am new to dl, can anyone recommend good resources to start with it."
2023-05-31 16:42:20,course.fast.ai
2023-05-31 16:42:57,thanks👍✌️
2023-05-31 16:44:07,are there good books that I can use instead of a course?
2023-05-31 16:47:11,+ 1 for this recomendation - there's also a book by the TA of this course - it also has jupyter notebook for all the lessons - https://course.fast.ai/Resources/book.html
2023-05-31 16:57:36,"http://introtodeeplearning.com by MIT is good, I've heard."
2023-05-31 17:11:31,apart from fast.ai
2023-05-31 17:13:28,"Let's stick to the topic, which is Generative AI please 🙏"
2023-05-31 17:16:08,"Can’t we have a separate group for generic deep learning, like things which aren’t a part of generative space."
2023-05-31 17:20:43,"Please feel free to make one, *outside of this community* — I am sure there are lot of folks interested in it! "
2023-05-31 17:42:34,I would love to create an AI Founders Forum with interested folks here :)
2023-05-31 17:55:17,"[PHONE REMOVED] Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?"
2023-05-31 17:55:45,"And I meant topics within Generative AI,"
2023-05-31 17:56:32,+1
2023-05-31 17:56:45,"Please no, discord is not as accessible as WA"
2023-05-31 17:56:46,"Is there a known way to measure diversity, code consistency which people are complaining about?"
2023-05-31 18:35:26,Can you share this link
2023-05-31 18:45:41,"Apart from a few open Ai gym problems like lunar lander and mountain car, can you guys recommend any other RL problem statements ?"
2023-05-31 18:49:13,Recommendation as a RL system (check youtube paper)
2023-05-31 18:50:01,https://m.youtube.com/watch?v=HEqQ2_1XRTs
2023-05-31 21:36:28,Has anyone else come across long build times for docker containers using a Pytorch dependency? Often times upwards of 20 minutes even on dedicated cloud build servers like Azure DevOps. Does anyone know workarounds for this kind of a situation? Or is it to be expected given how heavy torch has become?
2023-05-31 21:39:11,which pytorch version and base image?
2023-05-31 21:42:27,"Random Prediction - 1 year from now, Adobe will do to Premiere pro what they just did to Photoshop."
2023-05-31 21:43:02,yes
2023-05-31 21:43:27,Love the movie aspect ratio use case. Would be awesome if Smart TVs did it :)
2023-05-31 21:46:08,"When a technology has the potential to remove one of the very first lessons that any creative learns about, you know that's significant on another scale"
2023-05-31 21:47:16,torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)
2023-05-31 21:48:16,"Thats helpful, thanks. I think in some cases the CUDA bits may not be required, let me check that out."
2023-05-31 21:49:59,"if you have your own builder, make sure"
2023-05-31 21:51:46,we had this issue in our case as well
2023-05-31 21:53:01,Royalties waived off for commercial and research use for Falcon 40B
2023-05-31 22:16:00,Movie directors will hate you more!
2023-05-31 22:17:56,"Thanks, what was the underlying reason? Model size and quantization for pretrained models? Anything else?"
2023-05-31 22:21:28,just changing pytorch image helped me
2023-05-31 22:23:30,"Thanks, that is helpful too"
2023-05-31 22:54:47,https://openai.com/research/improving-mathematical-reasoning-with-process-supervision OpenAI announced that they are training their reward models to provide reward for every thought (reward shaping) than giving reward at the last step for mathematical reasoning tasks.
2023-05-31 22:59:21,"If all in your company follow consistent versions (python, torch, and even models) then create slim base images (with version combination) and push them to your repo. All other teams now can create images on top of these base images."
2023-06-01 06:52:34,https://twitter.com/kiwicopple/status/1664027051312001027?s=19
2023-06-01 06:53:48,"This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX"
2023-06-01 08:30:31,Falcon models have been made Apache2.0! good news !
2023-06-01 09:34:51,TIL https://aviary.anyscale.com/
2023-06-01 09:49:45,Funny translations
2023-06-01 09:51:30,Surprisingly dolly v2 is decent. Did not expect!
2023-06-01 09:51:46,"Also demonstrates that Dolly, returned the correct answer in the second trial though .. the first trial was wrong. So inconsistent a bit"
2023-06-01 09:52:32,There’s a lot more to come from supabase. Just one of the cool stuff team has been brewing :)
2023-06-01 09:53:15,Postgres support?
2023-06-01 09:54:09,Anyone used any generative tools for auto/assisted ground truth annotation of images or LiDAR with boxes/semantic segmentation labels?
2023-06-01 09:55:13,Supabase has always been postgres under-the-hood: they are productizing pgvector better
2023-06-01 09:57:03,"That's my point - the fact that their lingua franca is PG, that results in a solid DX"
2023-06-01 09:57:30,But I am hearing PGVector doesn't do well at scale
2023-06-01 10:03:10,This is the same old RLHF pipeline. They (I think karpathy) just explicitly showing two parts of RLHF - Reward modeling and then using Reward network to train policy network.
2023-06-01 11:28:21,Some of them are more excited & optimistic than you would believe !
2023-06-01 11:53:05,How about TVs with GPUs that can automatically make HD videos out of old low resolution videos with GFGAN or something similar.
2023-06-01 11:56:51,Don’t TVs already have chips that have GPUs in them? DLSS has been in gaming consoles and  rDNA architectures allow for similar capabilities.
2023-06-01 12:01:26,"Interesting, got to check it out and update my knowledge. Not sure my 800$ TV has 1000$ GPU chip but I may be wrong."
2023-06-01 12:06:45,"How about we make every thing kids friends and all the violence and blood is replaced by flowers and rainbow based on settings, in real time 😜"
2023-06-01 12:08:14,Cc Rahul [PHONE REMOVED] is doing this
2023-06-01 12:08:42,That's the reason this group has DeepMedia in it
2023-06-01 12:09:10,Not in real time (yet) though. :)
2023-06-01 12:09:19,Add me as an early tester. My 5yo loves demon slayer and May be this will give me a moral victory
2023-06-01 12:09:44,Hahah will DM.
2023-06-01 12:10:15,We are doing next year prediction anyway😜 the way we are moving it’s definitely will be a thing.
2023-06-01 12:10:34,More like 2 months.
2023-06-01 12:14:10,Well a GPU to do upscaling doesn’t have to be 1000 dollars. I could be wrong but it does not have to be the stereotypical GPU which looks like a Casio watch had a baby with Crysis 2
2023-06-01 12:16:24,"My experience with GFGAN is that when I upscale low res image to 4K, it take a significant amount of memory. Now, I’m not aware of other techniques so I’ll refrain from making assumptions."
2023-06-01 12:19:29,There is a lot of nuance to the topic of aspect ratios in film making and a rich history behind it...
2023-06-01 12:20:20,I don’t play games so had to literally search Crysis 2 to understand reference 🤣
2023-06-01 12:20:33,https://youtu.be/wlUV6y5TUko
2023-06-01 12:21:10,This is a good primer on aspect ratios and the problems with manually or automatically changing them...
2023-06-01 12:22:12,Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it
2023-06-01 12:27:56,Cc Rajeev [PHONE REMOVED] was earlier working on game assets but moved away from it
2023-06-01 12:27:55,"I’m sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home."
2023-06-01 12:29:10,"That is very cool. A completely digital persona who can interact with you across virtual and real worlds, or something like this."
2023-06-01 12:29:18,We can port this to telegram
2023-06-01 12:32:35,Sticking to WhatsApp in the interest of serendipity. I don't expect Crysis2 to be mentioned on Telegram for instance. 
2023-06-01 13:41:59,There’s a section in this video which discusses video reconstruction from MRI data collected using visual stimuli. Mind blowing stuff. https://youtu.be/eXttLLdlzaI
2023-06-01 14:35:20,"Hey folks, which vector store would you recommend for production application ? "
2023-06-01 14:42:13,"Weaviate is quite accessible, great DX and [PHONE REMOVED] runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free"
2023-06-01 14:44:17,"We have just migrated off pinecone to weaviate, and could not be happier. Great dev ex and gives us the right amount of flexibility."
2023-06-01 14:44:18,We're using Redis in production now. Langchain comes with Chroma DB which works for smaller use cases
2023-06-01 14:44:22,"Wait, I might be wrong on this — [PHONE REMOVED] uses Pinecone"
2023-06-01 14:45:43,Supermeme.ai also uses pinecone I believe
2023-06-01 14:48:47,I use Pinecone.
2023-06-01 14:48:55,what type of flexibility?
2023-06-01 14:50:42,We use Pinecone at Nintee
2023-06-01 14:50:44,Pretty good
2023-06-01 14:52:55,hows the pricing scaling for you?
2023-06-01 14:54:27,"Folks using pinecone, are you charged for concurrent requests as well or are you charged just for the amount of vector embeddings you store?"
2023-06-01 14:55:00,Ramsri recommended pinecone even when he faced issued. That was proof enough for us
2023-06-01 14:55:06,I have the same question. Their QPS ratings are a little fuzzy so its not clear at all how many pods you actually need
2023-06-01 14:56:06,Openai embeddings k according you can store 2.5 million embeddings per pod. But unsure if this counts Metadata limits also
2023-06-01 14:56:25,"[PHONE REMOVED] we're discussing vector databases, and thought it'd be good to hear why you recommend Pinecone"
2023-06-01 14:57:07,"There are a few good ones out there that have personally used but for a production application the choices I wud make would be governed by scale/precision , integration with the ecosystem etc. Making Pinecone and Chroma easiest/fastest to integrate with"
2023-06-01 14:57:49,Its per instance / pod type. We are small and only have a single pod now. 
2023-06-01 14:57:52,Caveat: Chroma is very weird. Takes 2G to store 1.2G worth of embeddings and so on. Won't recommend for production
2023-06-01 14:58:20,"Sure! :) I am not Pinecone's ambassador, haha! I think nowadays Weaviate, Qdrant, Croma all are equally competent and capable"
2023-06-01 14:58:55,"Seconded, anything upto 10-20 QPS and a few 100K embeddings should go to pgvector!"
2023-06-01 14:59:02,One thing we do is store embeddings in a local Postgres so changing vector store db is easy
2023-06-01 14:59:38,We are moving to hybrid search and want to the ability to weight sparse VS dense. U can do this in pine one but it’s more of a pain. 
2023-06-01 15:01:39,Any comments for caching questions in a QnA setup to avoid GPT call? I am checking https://github.com/zilliztech/GPTCache but not sure of that's the best direction.
2023-06-01 15:04:50,Exact questions rarely come in production
2023-06-01 15:08:40,"True, but similar questions are frequent. For example - 'What happens to payment page if product is out of stock', I found 20+ variants of this in a manual review. I only took a 10% random sample for review."
2023-06-01 15:10:16,"Embed the question, do a look up and provide the answer if the similarity score is above X? Ideally only if the user upvoted or approved teh answer"
2023-06-01 15:11:26,"Yup, that's my current setup.   I felt GPTCache might be doing something smarter so reached out to the group."
2023-06-01 15:35:18,"This was the paper from Recsys on what TikTok does, that I spoke a day ago."
2023-06-01 15:35:37,https://arxiv.org/pdf/2209.07663.pdf
2023-06-01 15:40:11,[PHONE REMOVED] : ☝️
2023-06-01 16:08:05,"Hi all, looking to make a marketing oriented video using Runway ML. Would anyone be interested in taking a quick paid gig for it?"
2023-06-01 16:09:46,"We are sort of having the same conversation over and over again. Thought it might be good experiment, if we can create a community curated notes. The idea being, the community edits and add *short big tested takeaways* content, in a specific overall structure (which will get getting updated over time) as we have discussions. Just so that we have time to learn the structure of the document, I thought we can roll out edit access slowly. Everyone has view access immediately, please request edit access from the document directly, if you want to edit (I can't handle 1000 DM ;). The quality of this is in each of our hands, hoping we can make something amazing out of this. Just an experiment, lets see how far this goes. We can start with the most frequently asked questions, that way we have most bang for the buck. Here is the doc: https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#heading=h.ir323h4vucu"
2023-06-01 16:47:07,https://www.jugalbandi.ai/
2023-06-01 16:56:09,It featured in MSbuild
2023-06-01 16:56:33,Lol considering that they got highlighted in ms build that'd be a no brainer
2023-06-01 16:56:52,I think MS invested in them
2023-06-01 16:57:51,Added [PHONE REMOVED] from AI4Bharat here
2023-06-01 16:58:50,Please bother him judiciously
2023-06-01 16:59:14,Good idea to possibly make this a Github repo? 
2023-06-01 16:59:27,Welcome to the group Sumanth!
2023-06-01 17:01:58,*reach them
2023-06-01 17:02:05,[EMAIL REMOVED]
2023-06-01 17:02:13,on their site
2023-06-01 17:03:16,haqdarshak.com is about schemes that citizens can avail.
2023-06-01 17:03:35,wonder if this summarizer is just a wrapper to chatGPT :) https://summarizer-fer6v2lowq-uc.a.run.app/
2023-06-01 17:05:42,👆from opennyai (just realized its a play on nyaay🤦🏻‍♂️)
2023-06-01 17:08:32,"I am meeting Saurab this evening, will ask him to join the group if he is interested."
2023-06-01 17:18:56,Hey [PHONE REMOVED]!✌🏼
2023-06-01 19:20:11,"Hi Saurabh, Welcome to the group. There are bunch of folks who are very excited by your work on Jugalbandi and OpenNyAI. [PHONE REMOVED] had worked on legal AI before."
2023-06-01 19:20:33,Thanks a ton Sumod :)
2023-06-01 19:21:00,[PHONE REMOVED] - Would be very happy to chat about Legal AI.
2023-06-01 19:21:29,[PHONE REMOVED] also worked on Legal AI with his startup so there are quite a few Legal AI folks here already 🥳
2023-06-01 19:22:52,"[PHONE REMOVED] sky is the limit bro, great to see you here."
2023-06-01 19:42:27,Hi Saurabh - nice to see you here!
2023-06-01 19:43:33,Hey Vishwam! Glad to see you too here :)
2023-06-01 19:44:18,[PHONE REMOVED] [PHONE REMOVED] - glad to see you here too!
2023-06-01 20:27:13,Welcome to the group Saurabh. Would be great to chat.
2023-06-01 21:04:16,"By the way folks, we are curating OpenNyAI residency this year. You should check it out."
2023-06-01 21:32:48,From another group….
2023-06-01 21:32:50,*Call for Papers: AI-ML Systems 2023*
2023-06-01 22:12:45,Hey thanks for sharing. Will the papers be published in ACM/IEEE proceedings? (Didn't find exact info on the website)
2023-06-01 23:28:53,I asked chatgpt a logic problem and it realized its mistake and its self correcting.
2023-06-01 23:29:00,Its just generating on and on and on
2023-06-01 23:31:12,https://chat.openai.com/share/5adb1eea-3bf0-42ef-ab2d-3543abcb1457
2023-06-01 23:31:27,phir bhi wrong hai. but this is an interesting development
2023-06-01 23:32:17,What’s your hypothesis? Why is it happening?
2023-06-01 23:33:11,"This is the first time I've seen it happening. With 3.5 it was wrong and just said yes, I'm wrong and this probably can't be solved so good luck"
2023-06-01 23:33:36,I'm guessing the loss dropped real low
2023-06-01 23:35:19,Once it makes a mistake it’s reinforced via context
2023-06-01 23:35:31,3.5 lacks reflection abilities
2023-06-01 23:36:21,I've yet to try with 3.5
2023-06-01 23:36:36,Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.
2023-06-01 23:36:36,GPT-4 can sometimes reflect on itself
2023-06-01 23:36:40,It emerged
2023-06-01 23:37:40,Maybe it’s trying to spit out anything until it finally receives a positive reinforcement 🤔😅
2023-06-01 23:37:55,This is because the model has to do multiple things 
2023-06-01 23:38:41,The model thinks for fixed time and then outputs the best token found after it
2023-06-01 23:39:02,This is a fundamental limitation of transformers. They are fixed in depth.
2023-06-01 23:39:23,Whereas we can decide to tnink harder
2023-06-01 23:39:46,"Here we have to provide hints think hard , step by step . But these are ultimately hacks"
2023-06-01 23:41:06,For eg GPT-4 cannot play tic tac toe optimally . Because that needs thinking ahead to some arbitrary depths.
2023-06-01 23:41:16,But that also doesn’t mean that it is stupid
2023-06-01 23:43:41,To fix this either you can fine tune / prompt on many different ways ppl plan on common tasks. That will plug the gap.
2023-06-01 23:44:31,My guess is there's another prompt here acting
2023-06-01 23:45:47,There's definitely an agent at play here. Because I'm using the browsing model
2023-06-02 00:26:47,"does anyone have any examples of papers/prompts that can do one-shot/few-shot classification of things like spam, fraud, etc. that kind of things ?"
2023-06-02 00:34:09,Let me find it
2023-06-02 00:35:54,Check out the work of Yao Fu https://twitter.com/francis_yao_/status/1654804366002638849?s=46&t=6c5AUaH7z7YH7nCchlCSSQ
2023-06-02 00:36:28,TL;DR - the best way is few shot - ie few examples + chain of thought in the examples before generating the answer
2023-06-02 00:38:29,Eg 
2023-06-02 00:39:43,"More detailed studies here on diversity, recency bias etc https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
2023-06-02 00:40:28,Lmk how it goes we can debug / improve
2023-06-02 00:42:37,Sklearn announced scikit-llm specifically for this purpose 
2023-06-02 00:45:07,Likewise spacy announced spacy LLM for all standard NLP pipelines. Spacy used to be quite popular for quick and easy industrial applications before LLM rage took over 
2023-06-02 00:56:05,"Quick question, is there an API version for plugins yet?"
2023-06-02 01:11:25,Extra credit - you can check token probability for spam / not_spam for even more nuance
2023-06-02 01:11:30,"won't be an api version of plugin imo, since that would defeat the point of plugin but the apis powering those plugins might be released sometime maybe"
2023-06-02 01:12:21,Langhcain has done work on this. can look this up
2023-06-02 01:15:26,What was this then?
2023-06-02 01:48:20,Yes. But text to sql dataset. And enriching dataset instead of generating from scratch because that works better.
2023-06-02 01:51:26,I can't see this message. Also the plugin repo is available to work on top of if you want to create a new plugin
2023-06-02 01:54:45,https://github.com/teknium1/GPTeacher
2023-06-02 01:54:46,I need to replace myself with a langchain agent that shares papers
2023-06-02 01:59:04,so i was indeed thinking of it in a few shot + COT way. but i was not very good or successful. so was looking if people had already figured out nice prompts and chains for this.
2023-06-02 02:00:11,that’s not what I mean.
2023-06-02 02:00:20,Share the task / few test cases and I can try .
2023-06-02 02:01:16,"i have already built a fair amount of chains, so i understand the general space...but am wondering if there is any specific ones that have worked here."
2023-06-02 02:04:36,Yes RAG will definitely work. If you can recover similar examples both positive and negative along with their Thought chains .
2023-06-02 02:04:54,You can use embedding matches maybe
2023-06-02 02:05:38,If even that is not enough you have to bite the bullet and go into fine tuning etc
2023-06-02 02:08:51,Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain
2023-06-02 02:09:14,https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
2023-06-02 02:10:06,Also pay attention to chunking when calculating embeddings. Better chunks would give better embeddings
2023-06-02 02:11:55,When you go down fine tuning route you can fine tune one model to detect fraud spam etc . And then it’s embeddings will better reflect the domain.
2023-06-02 02:12:09,"Unless the spam you're trying to classify is novel, zero shot spam classification using GPT should be fine."
2023-06-02 02:13:10,However I have worked in this space on non ML parts . Adversarial ML is a whole different can of worms
2023-06-02 02:13:31,The speed of retraining becomes critical
2023-06-02 02:14:38,"And also combining other signals and not just from the content. Reputation scores of IP , account , phone"
2023-06-02 02:16:49,And creating hold out sets to prevent degenerate feedback loops
2023-06-02 02:17:40,Could you explain what u mean by this ? So train a model to generate embeddings ? I didn't understand the meaning of this.
2023-06-02 02:18:54,"Multi task learning . Metas classifiers for abuse for eg are trained on many different tasks. Spam , fraud , terrorism. The embeddings of this model are very powerful as a result . Same idea applies to other models including LLM"
2023-06-02 02:19:30,Similar to how FLAN is fine tuned on a whole battery of tasks
2023-06-02 02:20:19,"Those same embeddings can be used for things like RAG into even more powerful LLMs , search etc"
2023-06-02 02:20:52,I’m not an ML expert so others who have surely done this can add more
2023-06-02 02:23:10,they were  generating embeddings using a classifier ? hmm.. i dont think i have ever looked into that.
2023-06-02 02:36:34,Yeah those embedding can be used in other classifier for other tasks
2023-06-02 02:37:08,https://research.facebook.com/publications/deep-entity-classification-abusive-account-detection-for-online-social-networks/
2023-06-02 06:54:58,Thanks everyone on the inputs 
2023-06-02 06:56:50,Caching will be useful in BI sort of use cases where different people are trying to ask same /similar questions
2023-06-02 06:58:05,Any interesting space tech newsletters i can follow?
2023-06-02 07:07:38,We’ve been trying our version of semantic cache for knowledge retrieval and text2sql and it’s surprisingly been really good with a decent F1
2023-06-02 07:08:55,GPTCache is a great starting point. On top choosing the best embedding model and then cleanup query before store improves accuracy a whole lot!
2023-06-02 07:32:29,https://twitter.com/omarsar0/status/1664441085693657088?s=46
2023-06-02 09:09:05,"This is awesome. And super useful. I'm trying to do something to manage DBs with plain text. Setting up indexes, managing slow queries, running migrations, managing Wal, etc."
2023-06-02 09:22:35,who's in control? the programmers or the program?
2023-06-02 09:26:36,I see…. thanks!
2023-06-02 09:53:54,https://research.nvidia.com/labs/dir/neuralangelo/
2023-06-02 10:11:09,Anyone has access to the new alpha model from OpenAI which does function routing better?
2023-06-02 10:15:52,What model is this?
2023-06-02 10:17:38,"GPT4 is better with function routing or ""actions"" in the agent parlance from what we've seen. Don't know if there's any new release after GPT4. Is that the one you are talking about?"
2023-06-02 10:29:03,I don't even have access to code interpreter yet 🙁 does anyone know how to get it?
2023-06-02 10:29:18,"(I mean can I ask openai to enable, etc)"
2023-06-02 10:50:06,Is anyone tried chatgpt as the translator ? Or arabic bot ? I have tried it looks like it is a coin toss if u give propts and all properly sometimes answers are good and sometimes its not much . As its not train wrt to translation i think that is expected but i did not think i will see some good reaults as well . Anyones exp with this ?
2023-06-02 11:01:56,On the onset I have seen it being a pretty good translator. I think vocabulary and sentence construction goes off when prompt is more complicated. I think a little bit of fine tuning on good curated data should be able to bump up the performance.
2023-06-02 11:05:31,I guess in private alpha. Will try to get more details
2023-06-02 11:53:35,As we know that the tiiuae/falcon-40b-instruct model has an Apache-2.0 license.
2023-06-02 12:23:39,Is there an economic case for using falcon over GPT-turbo ?
2023-06-02 12:24:00,"Hey folks looking for help on how you are managing prompts, flows for calling openai api"
2023-06-02 12:24:01,I haven’t done detailed calculations but it seems to me any such approach in practice will cost a lot more
2023-06-02 12:24:41,Check out airflow . You need a data orchestration framework.
2023-06-02 12:24:47,I've used Dagster for chain and filter kinda operations. Works like a charm
2023-06-02 12:24:49,Airflow should work too
2023-06-02 12:25:09,Nirant Bot is always faster 😁
2023-06-02 12:25:21,Has he already replaced himself 🤔
2023-06-02 12:27:30,Thanks..
2023-06-02 12:27:30,Any sufficiently fast typist human is indistinguishable from an AI Model 🤣
2023-06-02 12:27:38,Thank you
2023-06-02 12:27:47,just some feedback - This does not take into account sharding yet
2023-06-02 12:35:52,"That’s a million dollar question. If we keep just the performance in terms of quality away, it should totally be cheap to host it yourself as long as the base infrastructure to inference is good. So hosting it on Azure which is what MS is preaching might be one way. Even AWS now provides a enterprise grade LLM hosting and fine tuning support on sagemaker. I think inferencing is where most of the cost is. Maybe we need to do a costing benchmark across different modes of deployment options."
2023-06-02 12:36:03,I can provide that for Laama and Vicuña on GCP
2023-06-02 12:36:42,I suspect the utilization level for GPU would need a certain scale. If your GPU is idle then it can’t be cheaper
2023-06-02 12:37:01,And if you spin it up on demand then cold start time increases
2023-06-02 12:38:09,Yeah. There’s probably a threshehold you need to cross in terms of users to counter for cold start problems and all. But also the GPU availability across the globe is a bottleneck.
2023-06-02 12:39:01,So depending on the size of model seeing if you want dedicated GPUs or something else that will start becoming a real question as well
2023-06-02 12:39:23,It’s not just that . OpenAI I suspect has a distillation system that benefits from scale and usage . That’s why turbo version drops a few months later. It’s difficult to replicate all this.
2023-06-02 12:40:13,"And features like json output , adapters , state can be added by OpenAI over time making the case for self hosting even weaker on short term economic grounds."
2023-06-02 12:40:43,Yeah. Totally possible!
2023-06-02 12:41:44,If you get the storage layer is correctly built you can get the coldstart to couple of seconds
2023-06-02 12:41:59,Which thereby makes the utilisation super high
2023-06-02 12:42:28,Ideally like a serverless abstraction
2023-06-02 12:44:30,"Only economical way I see possible, compared to turbo, is hosting on-premise on a6000. Cold start latency may disrupt use experience, even additional 2 seconds."
2023-06-02 12:45:09,"Yes, we need to do all the processing without use of any external APIs."
2023-06-02 12:46:09,A single On premise can go down any time. Then you'd need redundancy.
2023-06-02 12:48:16,"Of course, one day of A100 on aws is like 50M token of turbo. Having redundancy will be still cheaper"
2023-06-02 12:50:37,Open AI / Microsoft are now building the highest possible standards of data security and compliance.
2023-06-02 12:52:25,"On Prem is cheaper, but the problem is once you buy the card , you have to also pay for network and it’s really hard to do Autoscaling if the QPS becomes fluctuating"
2023-06-02 12:53:26,For Tranining I would highly recommend On Prem
2023-06-02 12:54:05,Agreed.
2023-06-02 12:54:31,"Once you have that many daily users, yes, ~50k request per day. There aren’t many production use cases."
2023-06-02 12:56:28,"Yeah you need things like infini band networking , custom racks with NVLink. Redundancy . It all probably adds up ."
2023-06-02 12:56:40,"Yes , there are cheaper players you can get cheats GPUs , if you at willing to do the dev ops yourself you can significantly get the cost down"
2023-06-02 12:57:26,How many tokens per second can an A100 do with falcon ? And how many do you need
2023-06-02 13:00:07,https://www.youtube.com/watch?v=Rk3nTUfRZmo
2023-06-02 13:00:21,I don’t think this can be easily replicated
2023-06-02 13:04:28,This is a great video
2023-06-02 13:05:09,Microsoft has built up a good 6-12 months lead all things put together
2023-06-02 13:05:23,"This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds."
2023-06-02 13:09:13,"I’m sure a100 won’t be more than 80, that’s slow too. And this is q4 to accommodate on single GPU."
2023-06-02 13:10:44,As I suspected
2023-06-02 13:11:33,Then the question is also if OpenAI is eating losses
2023-06-02 13:11:41,"Nothing in near future beating Turbo, and when we figure out OAI will reduce price of GPT4.5 turbo to that level"
2023-06-02 13:12:00,Yup . Absolutely masterful strategy 🙇🏽
2023-06-02 13:12:03,Why? What about scaling use-cases?
2023-06-02 13:13:48,Speculation- turbo only has 1-2 B parameters and maybe further quantized
2023-06-02 13:15:07,OpenAI has published it themselves that 1.5B versions of GPT are not that bad
2023-06-02 13:16:01,In terms of using OSS models. May be my mistake using the word use cases. Probably production applications using OSS models at this scale.
2023-06-02 13:16:51,Still it has higher score than 65B LLaMa
2023-06-02 13:18:17,"Also, excessive RLHF help me to trust the turbo inference in production. I’m scared to death with LLaMa hallucinating in front of Farmers."
2023-06-02 13:18:30,Do try guardrails-ai.. You can run the group of prompts in sequence based on the open ai results/
2023-06-02 13:50:59,Check out zero shot Nas. Quite a good paper
2023-06-02 13:56:22,https://arxiv.org/abs/2301.11300
2023-06-02 13:57:08,It can used for classification problems as well. Quite efficient
2023-06-02 15:38:37,A question on deploying a web app  on ai - 
2023-06-02 15:39:50,You can try fly.io and railway.app
2023-06-02 15:44:56,Vercel is pretty seamless if you are using Nextjs
2023-06-02 15:46:10,I mean they created it
2023-06-02 15:48:17,Azure/ DigitalOcean? 
2023-06-02 15:49:14,can hook the build action directly to your github repo
2023-06-02 15:49:46,"though this is pretty elementary; I’m not sure if you were asking from a competitive overhead sort of angle , sorry"
2023-06-02 16:51:52,"+1 for fly and railway, easier hosting (can do cd via GitHub actions). "
2023-06-02 17:09:21,Quite an interesting thread on migrating from fly to render. Check it may help
2023-06-02 18:37:32,Has anyone been able to increase GPT4 rate limits ? Any tips ?
2023-06-02 18:42:17,"Azure OpenAI, pay for dedicated Gpt3.5 and you get very generous GPT4 limits too"
2023-06-02 18:43:29,"no, they don't increase"
2023-06-02 18:43:34,how to get approved for GPT4?
2023-06-02 18:50:19,Try chaining the prompts. We are doing that.
2023-06-02 19:38:33,Is anyone using GPTCache here ?
2023-06-02 19:40:56,think they do both. ExactMatch and SemanticMatch
2023-06-02 20:58:28,Sckit learn cosine similarity and qdrant cosine similarity seems tobe quite different
2023-06-02 20:59:12,Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results 👍
2023-06-02 20:59:41,Anybody facing such difficulty and solving them would be great to know
2023-06-02 21:23:24,"All vector stores approximate distance for performance, scikit is exact search"
2023-06-02 21:42:39,"Along with what Nirant said, most of them will have an option to set search to exact or approx. Be aware exact will lead to lower qps/latency. Pretty sure qdrant too will have it"
2023-06-02 21:43:08,Yes that's what I was after
2023-06-02 21:44:54,Yes it has an exact param
2023-06-02 21:44:59,Thanks
2023-06-02 21:49:07,Exact true unfortunately did not help
2023-06-02 21:49:23,Will find out more
2023-06-02 21:51:19,Could be that you're embeddings are not normalised?
2023-06-02 21:52:02,If they're not normalised you should be using l2 instead of cosine
2023-06-02 21:54:43,"Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup."
2023-06-02 21:54:44,Question:
2023-06-02 21:55:19,Asking for local embedding reasons
2023-06-02 21:55:55,"Don't know much about Qdrant internals, so can't help much more."
2023-06-02 21:59:54,I am using Sentence Transformer embeddings
2023-06-02 22:00:21,Which model?
2023-06-02 22:00:29,Therefore would it not do it.Let me check that
2023-06-02 22:01:08,All minilm l6 v2
2023-06-02 22:01:28,This is normalized
2023-06-02 22:02:46,https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
2023-06-02 22:04:59,This is weird. Because I think last year someone asked nils Reimer this question and he had mentioned that you can use cosine for this. So I assumed it was. 
2023-06-02 22:07:57,Qdrant does normalisation internally when adding vectors I believe.
2023-06-02 22:26:13,You are correct
2023-06-02 22:26:29,Let me do DOT similarity
2023-06-02 22:34:46,I’m not sure of qdrant but there must be some way to retrain the index to refresh the clusters of index 
2023-06-02 22:36:37,Does this work 🥹
2023-06-02 22:36:39,"if ur result is better with non-normalized vectors, try reducing the size of chunking. intuitively non-normalized cosine product is due to the shorter vectors."
2023-06-02 22:38:17,I've always wondered what's a good chunk size for vectors.. has anybody tested with different chunk sizes for RAGs?
2023-06-02 22:39:42,[PHONE REMOVED] can comment on this I guess as they have done quite good number of experiments for fixing chunk size.
2023-06-02 22:58:40,Try a smaller number and go bigger
2023-06-02 22:59:04,"so, just hit & trial then?"
2023-06-02 22:59:56,Yes. Few things to keep in mind 
2023-06-02 23:00:16,Different docs chunk different
2023-06-03 01:39:44,Is there a way to use any AI technique to see how some of YT channels do in setting their narrative? Which line is dominant and which one gets ignored. Both pro- or anti- on political topics.
2023-06-03 01:41:56,You can start by identifying it yourself. Then find a pattern. Then try automate it
2023-06-03 06:41:33,Can you give some more details ?
2023-06-03 09:50:17,LLMs can help in this. But would need to formulate a paradigm first as a solution then use LLM as a tool to achieve the objective.
2023-06-03 10:49:08,Happy to help! Can you DM?
2023-06-03 10:50:17,Update: Strangely enough changing the prompt worked
2023-06-03 10:50:22,in Qdrant
2023-06-03 10:54:12,is there a way to train our own model with the data we have?
2023-06-03 10:54:13,does dalai ai does it?
2023-06-03 10:56:54,Dalai is a local execution/inference and only works with Llama to the best of my knowledge. Has that changed?
2023-06-03 10:57:50,how about smol ai?
2023-06-03 10:58:24,we have this huge dataset of case filings & want to use it to build our own model
2023-06-03 11:01:41,"smol is not an AI model, is a clever way to call GPT4 APIs"
2023-06-03 11:03:15,oh got it
2023-06-03 11:11:55,Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?
2023-06-03 11:12:46,Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case
2023-06-03 11:12:46,I think the terms say that they keep data on their severs for 30 days for safety and compliance audits
2023-06-03 11:12:55,Exactly
2023-06-03 11:13:08,And they promise to not use that data for training
2023-06-03 11:13:27,"You can opt out of this, in both openai and azure"
2023-06-03 11:13:59,We are still on openai. Should switch to Azure.
2023-06-03 11:14:00,Anyone from here at the GenAI hackathon in mumbai today? Please react with a 👍 to this message
2023-06-03 11:14:45,All the best to all participating! Send pictures 🥳
2023-06-03 11:15:49,"Been using Azure OpenAI for a month Now. Every individual deployment has max 120 transaction per second limit, which is fine in most cases, but you can roll out multiple instances, and shuffle."
2023-06-03 11:18:52,oh nice. That way we can serve more requests. Nice.
2023-06-03 11:24:25,Forgot to mention but I’m using Turbo and not GPT4 from Azure OpenAI. Been on waitlist for 5+ weeks and they are saying GPT4 access is very difficult right now due to GPU shortage.
2023-06-03 11:26:59,GPU shortage I have also heard from AWS side
2023-06-03 11:27:36,The requests / minute for GPT4 is 18 on Azure OpenAI service right now. That's a fairly small number of requests
2023-06-03 11:27:59,"I think that's why from an inference side, I believe we will have much smaller models which can potentially be hosted locally on the user's device and the ecosystem is available as API interfaces and how a user wants to be connected to internet or access govt. services is something that they get done via these LLM assistants."
2023-06-03 11:28:03,Gorilla kind of thing
2023-06-03 11:28:31,The power of Gorilla is that it's trained to do better tool selection
2023-06-03 11:29:18,"in legal and rights and entitlement space as well, these tools e.g. all the acts in India or a particular judgement may become available to these LLM legal assistants"
2023-06-03 11:29:49,"So you can have two deployments in each of the 4 data centers that have OpenAI services. 144 requests per second are still decent. Of course, you need the access first."
2023-06-03 11:31:14,"Agreed, that's not bad"
2023-06-03 11:32:21,Anyone deploying models like Falcon on their (business) applications? What is the performance like?
2023-06-03 11:35:39,I just got it running in Colab on A100: https://colab.research.google.com/drive/1Fjwq3GPCqNTlWJG2T07vIRJw4L9_nkfj?usp=sharing
2023-06-03 11:36:08,(Official HF Instructions are broken)
2023-06-03 11:37:03,Yes needed to install more dependency than what HF mentioned
2023-06-03 11:39:05,And `pipeline` is also broken if you don't load the model separately
2023-06-03 11:40:59,What's the context token limit on falcon?
2023-06-03 12:04:07,Pretty cool Nirant! These are premium Colab instances? What are the charges like?
2023-06-03 12:06:31,https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595
2023-06-03 12:06:41,And a nice comparison
2023-06-03 12:28:09,More context - https://www.reddit.com/r/LocalLLaMA/comments/13yfask/manticore13bchatpygguanacoggmlq4_0_americas_next/
2023-06-03 12:53:56,"Yeah, Redis does get expensive - more than anything hidden costs of PaaS in the cloud get me."
2023-06-03 12:55:39,Fantastic
2023-06-03 12:55:45,"To be fair, this is a High Availability setup in redis cloud."
2023-06-03 13:51:55,Interesting open source tool - Ul visual tool for LangChain
2023-06-03 14:05:12,"Any best resources for creating charts/graphs from data, open-source ""Chart-GPT"" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives."
2023-06-03 14:15:24,D3.js. They have Python bindings as well
2023-06-03 14:28:32,Chart.js is also a good option for basic garphs. We implemented something where ChatGPT generates python code that can take query object as input and output chart.js params which can be directly passed onto Frontend.
2023-06-03 14:34:12,Consistent Policy around Events: 
2023-06-03 15:23:17,I think if you have the code interpreter plug-in enabled that’s the best way to go?
2023-06-03 16:16:39,https://youtu.be/slEMhl1U1_s
2023-06-03 16:34:52,https://youtu.be/BwNdj4zNEuk
2023-06-03 16:34:56,Tbis stuff is wild 😁
2023-06-03 16:43:01,https://youtu.be/DP9EY4xMlTE
2023-06-03 16:51:40,This is one way to convert me into a copyright activist. That song got butchered so bad.
2023-06-03 16:52:03,I really like this one
2023-06-03 17:03:58,3:35 to 4:05 is 🤐
2023-06-03 17:04:16,There’s a trump Coldplay cover
2023-06-03 17:04:49,https://youtu.be/omRTS-XsEGU
2023-06-03 17:05:21,Listen from 3:00 😁
2023-06-03 18:41:37,i found this very good!
2023-06-03 18:56:17,Brilliant. The Frank Sinatra cover of Bon Jovi is even better. How did they build this?
2023-06-03 18:57:19,Damn!
2023-06-03 18:57:56,https://www.youtube.com/watch?v=rNKJcoSB8YU
2023-06-03 19:31:27,Is it possible to use a different tokeniser while training a LLM model cia LoRA/QLoRA ? I am assuming I will have to make changes to the model as well. If anyone has any resources on this that would be great.
2023-06-03 19:57:27,I don’t know 😁
2023-06-03 20:23:58,by doing that you might be effectively throwing away all the learning in the embeddings layer
2023-06-03 22:17:36,Best diagram based implementations exist via mermaid js code generation. There's a plugin for that as well in chatGPT plus.
2023-06-03 22:31:20,"Yeah,  wanted to understand if there is a way to mitigate that. Thanks."
2023-06-04 07:54:43,Hey folks! Welcome [PHONE REMOVED] 👋🏼
2023-06-04 08:42:27,Is there a better resource to prompt engineering than https://github.com/dair-ai/Prompt-Engineering-Guide that I may be missing? I find it pretty good along with a list of papers and seems to be kept fairly up to date. But who knows what else I might be missing? Any further pointers appreciated
2023-06-04 09:18:56,nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
2023-06-04 10:00:06,https://github.com/brexhq/prompt-engineering
2023-06-04 10:50:24,One idea Id like your inputs on is the following;
2023-06-04 11:12:59,Is there a reliable way to inject knowledge into a RLHF trained model?
2023-06-04 11:13:06,For text generation
2023-06-04 11:13:53,"What does 'inject' mean? What use cases do you've which an in-context, dynamic prompt does not cover?"
2023-06-04 11:17:24,"2048, with a 65K vocab"
2023-06-04 11:19:47,Falcon is also trained with Alibi Position Encoder/Linear Attention (https://arxiv.org/abs/2108.12409v2) — so you can finetune and increase context window as well. 
2023-06-04 13:10:21,"Qdrant not writing to storage , therefore works fine it is running , but data cannot be retrieved once stopped and restarted"
2023-06-04 13:10:27,Did anybody face this problem
2023-06-04 13:10:53,"In 1 machine, I am having this problem while in the other follows the expected behaviour"
2023-06-04 15:27:25,"Since this is device, config specific — do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH"
2023-06-04 17:33:54,Sure
2023-06-04 18:06:55,Imagine making QnA engine on the No moat article. You have chunk & indexed the article. 
2023-06-04 19:05:44,Fine tuning on enough instances of such information is  what’s ideally needed. But it doesn’t work always from what I’ve read
2023-06-04 19:05:57,Current techniques need a lot of data to imbibe something
2023-06-04 19:06:26,Embedding etc is just a faster hack
2023-06-04 19:13:04,Model Editing methods use logits and alter or update meaning of tokens. 
2023-06-04 19:07:22,"Hierarchical chunks - title , article summary , then children - paragraphs and so on. This is essentially a search engine type problem."
2023-06-04 19:08:27,If I ask “who wrote the google no moat article” it won’t match any chunk per se
2023-06-04 19:20:44,The interesting thing is the models do learn inside the context. But then it can’t be stored in the model.
2023-06-04 19:21:02,Increasing context window is a good hack too
2023-06-04 19:30:40,"Fine-tuning here is not a new model, just fine tuning on top of GPT3.5/4."
2023-06-04 19:32:14,what would this fine tuning involve?
2023-06-04 19:33:25,Following the guide here :
2023-06-04 19:34:27,it's for gpt-3. Not available for 3.5/4
2023-06-04 19:36:06,"I'm not the expert here, hence the request for help"
2023-06-04 19:39:02,You can't finetune GPT3.5/4
2023-06-04 19:40:51,Thanks. Looking for guidance from anyone who has made customer support both or Q&A bot in production
2023-06-04 19:41:45,I’m working on this for work. This is not as easy as it looks. Like the steps aren’t wrong or anything but it needs a lot of work to make it work properly.
2023-06-04 19:42:06,I'm new to this but wouldn't semantic search be better than finetuning?
2023-06-04 19:42:49,No not really. Fine tuning can make deeper connections inside what the model knows. Vanilla embeddings are very fuzzy
2023-06-04 19:43:04,For this case?
2023-06-04 19:43:30,No semantic search is good once you have the answers in the DB .. but customer support can be fluid ..
2023-06-04 19:44:48,It depends on complexity of the task as well. For eg coding
2023-06-04 19:45:51,If we are just retrieving snippets and showing that’s a search engine.
2023-06-04 19:58:02,If a customer is valuable enough spending a few dollars on them for a case is worth it
2023-06-04 20:04:56,is bard doing a version of this (embedding lookup) or are they doing frequent retraining and/or fine-tuning?
2023-06-04 20:07:50,"None of these. It's just a more recent freeze of the weights and data. And combined with Internet search, looks like it's recent"
2023-06-04 20:14:25,Yup same thoughts!
2023-06-04 20:16:56,Thats the costly slow backup option for sure. Like in the problem statement I gave we can just match article titles and then add the whole article in the context for answering.
2023-06-04 20:22:36,A related question to this
2023-06-04 20:41:08,Changing sampling alone goes a long way for code updates :)
2023-06-04 20:45:00,That’s not how NLP models work. You cannot dynamically add new training data to transformers. You may be able to hack some params using some “helper” models but updating the original model is not possible.
2023-06-04 20:58:25,Did not get you!?
2023-06-04 20:59:46,Hoping for some breakthrough!
2023-06-04 21:06:16,The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!
2023-06-04 21:09:12,https://aclanthology.org/2022.conll-1.4.pdf the non-anonymous one.
2023-06-04 21:16:52,https://arxiv.org/abs/2104.08164
2023-06-04 21:38:17,So there’s is a paper from deep mind called RETRO that shows a way to do it. If someone can figure out a way to hack this into present models . But it’s basically a serious research question
2023-06-04 21:39:14,"I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues"
2023-06-04 21:40:31,Webgpt is what chatgpt with browsing is
2023-06-04 21:40:45,Yeah but ppl have said it doesn’t work well
2023-06-04 21:40:57,They've made some improvements
2023-06-04 21:41:02,"Just read through your article, looks great!"
2023-06-04 21:45:26,Azure is 3x faster than OpenAI for Gpt3.5 
2023-06-04 21:46:49,Do they mean turbo? That is anyways really fast.
2023-06-04 21:47:13,I've heard azure gives better uptime as well
2023-06-04 22:17:05,Can confirm this by using it in prod. But the default rate limits for some are low. Like chatGPT is 300 / min as opposed to 3500/min with OpenAI. But with azure I thinkyou get 99.99% uptime which is a big plus
2023-06-04 23:04:00,"Q. for Nirant , others : are you aware of papers/efforts on continuously ""online"" learning LLMs ?"
2023-06-04 23:40:34,"Look at Never Ending Language Learning, Never Ending Image Learning projects. They've been running for couple of years."
2023-06-05 00:19:12,https://www.cloudskillsboost.google/paths/118
2023-06-05 08:25:30,That was so quick.
2023-06-05 08:32:53,Llama cpp is doing 40tok/s inference for 7B model on a Macbook M2 Max. 24tok/s with 13B and 5tok/s with 65B models. 
2023-06-05 08:35:41,Noob question: does finetuning affect inference speeds?
2023-06-05 08:36:28,What tokenization method works best for Indic languages as the character level tokinization has higher token count for a Hindi sentence?
2023-06-05 08:36:57,Sentencepiece
2023-06-05 08:37:06,That's a good starting point
2023-06-05 08:43:59,What about spacy? How do the two compare
2023-06-05 08:44:41,SpacCy*
2023-06-05 08:44:53,Nope
2023-06-05 08:47:45,Spacy I'm not sure.
2023-06-05 08:48:35,For tokenization its better to be subword level than word level
2023-06-05 08:49:22,Spacy would do word level.
2023-06-05 08:50:16,"*spaCy is word level tokenisation, so if you're doing it for humans — perhaps among the best. Right there with Stanza (Stanford). "
2023-06-05 08:55:35,What’s your goal?
2023-06-05 09:00:00,"GM fam, Anyone has the link to the doc shared in this group which had the summary of all recent discussions ?"
2023-06-05 09:24:52,Did you mean this? 
2023-06-05 09:25:46,"Yes, thanks."
2023-06-05 11:45:04,Is there any Event link from where I can register for this event ??
2023-06-05 11:45:34,https://lu.ma/fvm2odkj
2023-06-05 11:53:47,GPT-3.5 in ChatGPT now points to ```…/?model=text-davinci-002-render-sha```  
2023-06-05 12:00:30,its been like that since April as far as i can remember
2023-06-05 12:01:20,Is there a good source of use cases of GenAI and users from India? As in what companies are building? what traction?
2023-06-05 12:04:58,Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?
2023-06-05 12:15:50,yeah it was using turbo but they changed to 002 after GPT4 rollout i think
2023-06-05 13:38:48,https://aviary.anyscale.com/
2023-06-05 13:40:07,https://github.com/ray-project/aviary/
2023-06-05 13:40:21,"No sir, it’s by Anyscale"
2023-06-05 13:41:17,"Ah my bad, but still a good resource"
2023-06-05 13:42:57,haha definitely
2023-06-05 13:44:38,"[PHONE REMOVED] I happened to notice this as well. Check this, might help"
2023-06-05 13:45:03,Not a different model I believe if we go by the analysis
2023-06-05 14:27:28,https://twitter.com/bigansh/status/1665643668605378560
2023-06-05 15:54:02,Anyone here who has run one of these open source LLMs in cloud with a webserver attached to it?
2023-06-05 16:03:58,[PHONE REMOVED] has built something similar for his company
2023-06-05 16:09:46,Are you having an issue loading the model?
2023-06-05 16:12:32,"Nope. I was successfully able to do this in my local, I can replicate that on ec2, but I wanted to do it via sagemaker cause of better infra support. "
2023-06-05 16:47:48,"Sam Altman, IIIT-D, Delhi, Thursday. "
2023-06-05 16:50:52,Tickets unavailable it says 🫡
2023-06-05 16:54:14,"yeah, i got some waitlist. "
2023-06-05 16:59:33,I have a ticket for this but I'm in Chennai and won't be able to make it. Happy to give it away to anyone from Delhi – can change the name & details on Eventbrite.
2023-06-05 17:00:56,Dibs
2023-06-05 17:49:38,Apologies for posting job here. I wasn't aware it's against the protocol
2023-06-05 18:10:58,Guys one question to people using cohere models in production. Specifically the embedding and rerank models.
2023-06-05 18:16:04,Wonder why they chose IIIT. Hope it wasn't a typo from the media team :P
2023-06-05 18:19:42,"Iiit d has done some work in nlp as well. Remember this in 2019 when was working in unfound news and fact check stuff was high priority they had released a paper with an approach. Don't remember it now, it was also not feasible to implement in prod at the time"
2023-06-05 18:20:47,Here is a hint: https://cai.iiitd.ac.in/index.php/faculties
2023-06-05 18:24:50,Lol - so you're saying the profs they have are deeper in the space. Interesting
2023-06-05 18:25:57,"I know this guy, Raghava Mutharaju, he was in my research lab but joined PhD program when I finished."
2023-06-05 18:26:25,Anyone with experience handling production grade facial recognition applications? Looking for some suggestions/ recos on tech stack for various stages of the pipeline.
2023-06-05 18:26:32,"Also it is called Infosys center, Infosys was one of the first investor in OpenAI"
2023-06-05 18:26:51,*Donner*
2023-06-05 18:28:24,PSA: 
2023-06-05 18:29:24,I would suggest search previous chat or your site first. Many repeat questions.
2023-06-05 18:30:47,"Also, I feel iffy about giving space to discussions which have done more harm than good e.g. face apps, deep fakes already. It's no longer a hypothetical"
2023-06-05 18:32:47,Didn't know this. Thanks!
2023-06-05 19:23:57,Hello! 
2023-06-05 19:24:38,"PS: Staying on brand, the entire list is generated by ChatGPT"
2023-06-05 19:31:02,Anyone attending the Sam Altman delhi meetup on 8th June ?
2023-06-05 19:33:16,the tickets got sold out so quickly
2023-06-05 19:38:13,Low key happy that Sam Altman sold out faster than many bad concerts!
2023-06-05 19:39:22,Imagine touts selling tickets for this in black
2023-06-05 19:41:21,Hope they have someone asking smart questions
2023-06-05 19:41:58,If you were given the opportunity what would you ask?
2023-06-05 19:41:59,Do the questions need to be before September 2021?
2023-06-05 19:44:35,"How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models."
2023-06-05 19:44:45,I would ask for better guidelines for finetuning. 
2023-06-05 19:45:46,Why would you ask tech question to sama?
2023-06-05 19:45:52,How technical can you ask questions here
2023-06-05 19:46:30,Fair point. But I also think he has a close eye on the technical side as well
2023-06-05 19:47:05,I don't want to ask questions on agi because I don't trust him to give the right answers
2023-06-05 19:47:19,"Not how, why? Find OpenAI folks on twitter for tech questions."
2023-06-05 19:47:41,May be ask why he changed his stance in last two-three months
2023-06-05 19:47:49,Official OpenAI Guide on Prompting: https://platform.openai.com/docs/guides/gpt-best-practices/strategy-test-changes-systematically
2023-06-05 19:48:16,What did they find in training that suddenly they are all into regulations?
2023-06-05 19:48:33,"I can't believe bulk of their entire advice boils down to ""use regression tests"" 🫢🤯"
2023-06-05 19:49:04,This I don't trust him to give the right answer because of conflict of interest
2023-06-05 19:49:33,If that has to happen azure will have to upgrade their could centers in india significantly ryt
2023-06-05 19:50:00,Cloud*
2023-06-05 19:50:24,Fair point. But changed to what. Is it that article which was deleted recently or the one that he gave at the US congress
2023-06-05 19:50:29,"Yeah, that's why it is a good question. That means more GPUs in India."
2023-06-05 19:51:15,"I suspect recent ""soft"" export bans from US will block something like this even if Tata says I'll pay you for the entire inference compute"
2023-06-05 19:54:10,"I guess GPT4 will be beaten by OSS soon anyway, but US is not going to stop training GPT5, 6 and these senate committees will start placing an embargo on the export of next"
2023-06-05 19:55:59,Will openai look to reduce the prices of the older models as it gives preference to chat models
2023-06-05 19:56:17,"On fun side, asking him about Atman <> Brahman philosophy, he is deep into that philosophy"
2023-06-05 19:56:36,Has Sama tried Sama juice 😂
2023-06-05 20:00:07,What has your experience been with OSS. I've found for my use cases there is a significant difference still. Although there are a couple that have given surprisingly good results
2023-06-05 20:01:05,I have been fine tuning open-source models and testing them out.
2023-06-05 20:01:16,"I'll wager that nothing comes close to GPT4 in task planning, multi step reasoning beyond 3 before 2024 Q1"
2023-06-05 20:02:13,I'm thinking a good solution might be OSS for small use cases.
2023-06-05 20:03:37,You can add even coding to that list too. 
2023-06-05 20:03:41,"Yeah, this can get competitive, but this is narrow AI again — just a different kind of narrow than 2019"
2023-06-05 20:03:58,"Ohh yeah, QA, Summarisation — most things are competitive"
2023-06-05 20:05:30,"The replit model, have you tried it? They say it's pretty good"
2023-06-05 20:06:53,"If wwdc goes well today, all everyone is going to be talking about is VR for the next few weeks."
2023-06-05 20:07:47,StarCoder and the Teknium Finetune are both better
2023-06-05 20:08:01,"No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing."
2023-06-05 20:08:19,Agree
2023-06-05 20:09:28,Did you stop tinkering after trying n/e models? 🤣
2023-06-05 20:09:40,"I also ran out of my 8TB storage, no time to upgrade 😂"
2023-06-05 20:15:56,https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5
2023-06-05 20:16:01,Seems like quite the smear campaign
2023-06-05 20:16:41,One motto we have at our company for ML folks is to “be a generalist when it comes to inputs and a specialist when it comes to outputs. That’s because only a generalist knows what tradeoffs are possible and worthwhile”
2023-06-05 20:18:11,I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.
2023-06-05 20:18:42,Jokes on anyone who takes their technology news from Forbes
2023-06-05 20:19:20,I agree
2023-06-05 20:19:41,"The whole article is just a series of claims that can be called ""problematic"" at best"
2023-06-05 20:23:55,"He is also SV outsider, and was going heads on to YC mafias. 😂"
2023-06-05 20:32:49,On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.
2023-06-05 20:34:04,I will also add nyt and vice to this list
2023-06-05 20:36:01,Isn't vice bankrupt?
2023-06-05 20:36:59,Github Feed is severely underrated e.g. one could tell GPT4 was coming out when they pushed the changes to Python lib xD
2023-06-05 20:38:33,Even the Emad piece mentions this: https://github.com/CompVis/stable-diffusion
2023-06-05 20:43:20,Yes
2023-06-05 20:46:15,https://www.linkedin.com/company/generative-ai-media-marketing-creative-conference/
2023-06-05 20:47:44,"They have a newsletter, it's more focused on new domains (mostly related to media) where genAi is applied"
2023-06-05 21:47:49,"I was sad to see my name in the list of inactive users, and then I realized it was because I hadn't posted any updates from my previous prompt injection updates for a while. So, to avoid being classified by chat GPT as inactive again, here is my latest prompt injection (complete prompt posted in an earlier message)."
2023-06-05 22:07:44,"Shashank(me) was mentioned in the sheet, there are 3 Shashanks here 😂. "
2023-06-05 22:08:36,This is fantastic stuff.
2023-06-05 22:08:52,"Is there a good guide anyone knows to prompt injection techniques, and more generally, LLM based chat bot testing"
2023-06-05 22:11:21,"Was drooling all over his 20vc podcast untill I read this. Tall claims in the podcast but most of them sounded reasonable with hard work. Did not know the past then, in the back of my head the proof was mid-journey. Not sure what to make of any of this, inclined to believe the article now with Rahul Yadav recency bias ☹️"
2023-06-05 22:16:35,From now on we'll probably just remove the least active N users ourselves. If they want back in they can text us.
2023-06-05 22:25:04,Good one
2023-06-05 22:25:17,"Wow, that was a crazy article. Glad these are getting written"
2023-06-05 22:37:54,It is tough to separate signal from noise with many of these articles. We’ve seen smear pieces and hit pieces in the past and we also know the value of not turning a blind ear to things like this lest we get another Theranos or another FTX but most of us consuming this news from thousands of miles away have so little context
2023-06-05 22:38:20,"emad wrote a counter. frankly, that Forbes piece exaggerated a lot of growing pains associated with running a startup, figuring stuff out."
2023-06-05 22:43:59,Hard to separate growing pains from mismanagement. So much of this is subjective.
2023-06-05 23:54:55,Are you guys following this?
2023-06-05 23:55:01,It's absolutely breathtaking
2023-06-05 23:55:19,And finally Apple does AR
2023-06-05 23:55:49,AR has always been the real goldmine
2023-06-05 23:56:09,This is surely a revolution in AR
2023-06-05 23:56:15,And with no controllers
2023-06-05 23:57:43,I was having a conversation with [PHONE REMOVED] today about monitors. 
2023-06-05 23:57:52,Yes it is. A giant leap.
2023-06-05 23:57:54,Now I think he should get this
2023-06-05 23:58:13,Eyes are the monitors now
2023-06-05 23:58:51,I originally wanted buy a 49incher like [PHONE REMOVED] but I'm strongly reconsidering.
2023-06-05 23:59:03,Imagine Gen AI for this?
2023-06-05 23:59:15,So far quantisation has mainly been for NLPs
2023-06-05 23:59:24,I foresee the same for vision models now
2023-06-06 00:00:24,This is absolutely magical
2023-06-06 00:00:33,GenAI + AR
2023-06-06 00:00:37,In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds
2023-06-06 00:00:40,"Was just telling one of my friends that Apple just saved them (MagicLeap) or Apple is screwed. AR is until now is like Afganistan, the place superpowers go to get beat. Let's hope Apple has figured out 🤞"
2023-06-06 00:00:55,This can then be mixed with AR in very creative ways
2023-06-06 00:01:11,that eye reveal thing. tuning immersion using crown. 👌👌
2023-06-06 00:01:15,Shopify is doing some great work here
2023-06-06 00:01:27,Taking deep work to next level
2023-06-06 00:01:44,What exactly? I'm very intrigued
2023-06-06 00:01:45,They really nail the UX
2023-06-06 00:03:33,yup. rest of the safari etc demos aren't that exciting. 
2023-06-06 00:04:45,This is something they did sometime back: https://twitter.com/strangenative/status/1640741787105984512?s=46&t=WT1iAtjftW-5_e62F8FZTg
2023-06-06 00:04:49,"and the interface with Mac was just shown, this is exciting. Imagining not using a physical extended monitor for work!"
2023-06-06 00:05:23,"Some players tried this earlier, like Nimo Planet. But this seems miles ahead"
2023-06-06 00:06:23,The only concern I’m seeing is where’s the dangling cable connecting to 😅
2023-06-06 00:07:55,The new Quest 3 looks really good. Meta has done really well with their oculus devices
2023-06-06 00:08:01,Spatial Video !
2023-06-06 00:08:29,"Yes. This seems way ahead. A part of it is because of the ecosystem effect. The userbase is, in a way, trained to imagine at a scale of the bandwidth they want them to access (their diverse products)."
2023-06-06 00:09:14,Looks like going for a kill on the profit pools of TV screens for sure
2023-06-06 00:10:59,This is crazy stuff. The impact on entertainment is massive.
2023-06-06 00:13:38,"Though it will boil down to how long can you have a thing right infront of your eyes wrapped around. If this is the future, the user will adapt I suppose."
2023-06-06 00:14:30,Eye strain and headache from weight imbalance are common with headsets.
2023-06-06 00:15:41,The stuff on EyeSight and the responsiveness to gaze for icons and buttons are the kinds of UX Apple has nailed
2023-06-06 00:16:38,For those who want a textual summary
2023-06-06 00:18:06,"Yeah that and they really think hard how to make it work. Like recording in 3D (am assuming) for capturing life moments, this is a use case that MagicLeap or even Daqri could have done. None did it."
2023-06-06 00:18:23,So it’s an external battery
2023-06-06 00:19:29,Yes. Its Crazy!!!
2023-06-06 00:21:42,Interesting choice. They put processors in the device and battery outside. Seems like pretty high res.
2023-06-06 00:22:30,Power of prop silicon ! 🙇‍♂️
2023-06-06 00:22:34,Exactly. This allowed to get the form factor a lot better
2023-06-06 00:27:12,No most of them moved the processors outside due to heat issues. Our faces are particularly very sensitive. So seems like they have solved heating really well or they actually have more than battery in puck or whatever they call it.
2023-06-06 00:27:28,*them = others
2023-06-06 00:31:10,"Though I am completely mesmerised by visionpro, still looking for tickets for Sam Atlan's delhi visit - do share if someone wants to sell/can help with tickets 🙏🏼"
2023-06-06 00:32:59,The only thing this is changing is your bank balance.
2023-06-06 00:33:52,$3499
2023-06-06 00:39:01,The price is way too much though- even the meta quest pro is available for $1000 🥲
2023-06-06 00:40:24,Same here - ready to fly down to Delhi in a days notice. Couldn’t get my hands on the tickets 😭
2023-06-06 00:44:05,Im saving up 🫠
2023-06-06 00:47:03,"quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem."
2023-06-06 00:48:07,But the power is ability for all apps to be integrated.
2023-06-06 00:50:06,Vision Pro might not be directed to the masses yet. We didn’t really think they’d price it for less than an Iphone 14 pro did we 😂
2023-06-06 00:50:12,I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those
2023-06-06 00:51:24,"Right, Meta Quests are more mixed reality. This is full AR"
2023-06-06 00:51:44,I have the quest 2 and it's priced just right. The quest pro was considered expensive- and now apple knocks the pricing out of the park 😂
2023-06-06 00:51:49,How nicely they normalize walking around the house wearing a head gear
2023-06-06 00:51:55,Oppo right around the corner now to release their copy 🤙
2023-06-06 00:52:38,Quest pro is pretty similar with its see through capabilities 
2023-06-06 00:55:35,"I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases."
2023-06-06 00:56:20,What's colocalization?
2023-06-06 00:57:01,Can’t wait to see how well they’re doing the face reconstruction
2023-06-06 00:57:41,That would be super compelling for doing remote experiences together with people
2023-06-06 00:59:23,"Localise multiple people wearing with each other and thus shared sort of experience. So magic leap etc can detect a table that both people of you see, then understand 3D structure of the table. You show same animations (think characters jumping out of top of your table) for both users from different POV on top of this surface."
2023-06-06 01:02:21,They've gotten themselves in a great position. It's truly something to marvel at.
2023-06-06 01:03:10,Imagine characterAI
2023-06-06 01:03:13,With this
2023-06-06 01:03:37,I'd love to talk to a few people in history face-to-face
2023-06-06 01:03:47,Instead of a chat interface
2023-06-06 01:04:58,Possibilities are endless. And they’re not releasing it now. So by then who knows we might have this and much more 😄
2023-06-06 01:07:13,I have high hopes for wearing comfort factor and face reconstruction - these were my #1 sore points with the quest
2023-06-06 01:08:53,Agents just got a bit too real 😁
2023-06-06 01:10:06,Is this a consumer device though?
2023-06-06 01:10:48,Will be really nice to see healthy competition here
2023-06-06 01:12:55,Apple does so much of ML that’s neatly tucked into functional use cases - even stuff like moving wallpapers
2023-06-06 01:20:29,"Will be interesting to see what you can train and fine tune on the new Mac Pro - it’s only slightly more expensive than a fully tricked out RTX 4090 gaming PC, did I get that right ?"
2023-06-06 01:23:10,India store price doesn’t look great 😄
2023-06-06 01:23:55,Mac Pro with M2 Ultra has 192 gigs ram 😂
2023-06-06 01:29:28,Not sure if this has been shared earlier but i found this website to be amazing for use case based prompting
2023-06-06 02:11:12,"They already have ridiculously accurate model in true depth, I think they probably didn't want to wash you face with LiDAR for long periods of time. So they probably used LiDAR based keypoints + facial fiduciaries to do things like low fidelity cartoon character animation one could do now. This solution is because they can't capture your face because it is blocked by the device. So they are forced to provide minimal deformation sort of model."
2023-06-06 02:12:07,LiDAR to provide base structure.
2023-06-06 02:12:45,"Above is guess, they might as well just be using just facial key points."
2023-06-06 02:51:08,M2 is known to be power efficient. So it probably doesn't generate significant heat to begin with
2023-06-06 02:54:07,"The battery pack can easily be offset to the back strap as well, making it kind of offset the main device."
2023-06-06 02:56:35,There’s a paper around here that did face reconstruction using only top view camera feeds
2023-06-06 02:59:03,it might be the case that the device can handle a few minutes on its own while the user switches the battery when one runs out. Paired with prop silicon this would mean many hours of use
2023-06-06 03:09:39,https://youtu.be/hkSfHCtpnHU
2023-06-06 03:16:56,What you’re talking about here btw is also old tech - https://youtu.be/dVa1xRaHTA0 - and I really doubt they are using face id data for training a face reconstruction model. Face ID never leaves the device afaik
2023-06-06 04:05:58,Removed for self promotion more than once
2023-06-06 07:49:04,Unity popped 17pc last night on the partnership announcement
2023-06-06 08:12:00,Overall I don’t see anyone really buying these Apple VR headsets apart from the same crowd that buys Mac pros. And that excludes most of us
2023-06-06 08:12:45,"All said, incredible looking product"
2023-06-06 08:26:56,I have a contrarian view.
2023-06-06 08:28:35,Try the skybox blockadelabs 360 image generation in your VR browser. Works great on my pico and oculus.
2023-06-06 08:29:05,I use them for 3.5 hrs without any issues. Have been using headsets for 5 years now
2023-06-06 08:29:30,"A couple of hours max. Because you tend to blink less often, makes my eyes dry. The other factor is weight imbalance. Improperly fit headsets can cause headaches and neck strain, but there are lots of ways to fix that."
2023-06-06 08:30:49,"I have two VR and an FPV drone VR, all of them collecting dust."
2023-06-06 08:31:11,"I have the Occulus 2, and I can’t use it for too long, max an hour. Also there is the https://en.m.wikipedia.org/wiki/Vergence-accommodation_conflict. Since the focal point of the lens of the eyes and the stereo conflict, it may cause issues for some people."
2023-06-06 08:31:30,"Often its the battery life that is the constraint for me, not comfort (I use a quest 2)"
2023-06-06 08:31:45,"Magic leap was trying to fix it with their light field display, but they didn’t come too far yet."
2023-06-06 08:32:05,"It's fun for couple of hours, days then the novelty wears down quickly."
2023-06-06 08:40:58,"Yeah, Very curious to know how they have managed VAC. Atleast for 2-3hr periods of usage. If they can do that, it will enable a whole bunch of  application. But Apple being Apple, I am guessing they have a solution."
2023-06-06 08:45:46,"Battery: I think you can do both 2hr and plugged in it seems. Their res is very high, guessing early 4k x 2.5k or so, almost thrice of Quest 3. Weight imbalance: I am guessing they have solved it. Else they are screwed. Yeah, I think the real thing is do they have apps with sticky workflow."
2023-06-06 08:51:31,"DAQRI, MagicLeap, Holo lens all had nice 3D rendered promo videos which were very far from real product and they couldn't close the gap soon enough. Disclaimer: Did some work for DAQRI in 2014-2016 period."
2023-06-06 09:21:27,"Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707"
2023-06-06 09:26:53,https://twitter.com/sterlingcrispin/status/1665792422914453506?s=46&t=v5MAnKU6XwMWCzMNzmBUuA
2023-06-06 09:27:10,"One of the coolest results involved predicting a user was going to click on something before they actually did. That was a ton of work and something I’m proud of. Your pupil reacts before you click in part because you expect something will happen after you click. So you can create biofeedback with a user's brain by monitoring their eye behavior, and redesigning the UI in real time to create more of this anticipatory pupil response. It’s a crude brain computer interface via the eyes, but very cool"
2023-06-06 09:28:56,"Nice feature, but I foresee the same kind of research used for UX dark patterns in VR headsets in the future - we already see how effective these can be at guiding/interrupting user behaviour on regular websites"
2023-06-06 09:30:13,"Makes a lot of sense to pursue this line of research because outside of the big research labs, most companies won't build completely new LLMs, but will build on top of the big LLMs and their capabilities in a specific area, sub-problem, domain."
2023-06-06 09:30:28,"Really interesting paper, thanks for sharing"
2023-06-06 09:31:42,Can a RLHF tuned model be considered a foundation model?
2023-06-06 09:33:09,"You can do whatever, say whatever as long as you can popularise your terms like RLHF or Foundation Model 😉"
2023-06-06 09:34:10,fair enough.
2023-06-06 09:35:17,andrew ng changed the game when he marketed the term deep learning. Or maybe  it was someone else.
2023-06-06 09:37:50,We were just yesterday talking about step by step thought process capability of GPT4.
2023-06-06 09:56:45,OpenAI updated their developer docs last night . Pretty neat https://platform.openai.com/docs/guides/gpt-best-practices
2023-06-06 09:58:37,OpenAI should do this as a successor to fine-tuning.
2023-06-06 10:29:15,also by Subhabhrata (though not the first author) is the ReWOO paper addressing reasoning - https://arxiv.org/abs/2305.18323 I think this can be a potential game changer too.
2023-06-06 10:33:26,I have been looking to buy Oculus for a while but could not find anywhere to test it in India. 
2023-06-06 10:39:09,"My company had bought one from the US. After around 30-40 minutes of usage with specs, you do feel dizzy (sample size was small though)"
2023-06-06 10:50:28,"This guy spends 40-50 hours per week working in VR and finds good productivity gain: https://medium.com/immersedteam/working-from-orbit-39bf95a6d385 In my experience the number of pixels in quest 2 is not enough for me to replace monitors with it, but I don't find it tiring if used for few hours. I do experience heavy motion sickness if the scene is moving and I can't use it for more than half an hour"
2023-06-06 10:50:29,"My initial experience with oculus was mind blown, it was the first genuinely new user interface I experienced since keyboard screen and mouse. "
2023-06-06 10:52:13,"Anyway, from a Gen AI perspective, I think a spatial and gestural interface is particularly disruptive"
2023-06-06 10:52:22,My Oculus has been gathering dust
2023-06-06 10:52:28,Because it offers an alternative to text as generative input
2023-06-06 10:54:06,Please feel free to gift me. I accept donations.
2023-06-06 10:56:52,"Lol, but it’s fun for flaunting when wiser friends are around"
2023-06-06 11:00:49,Organise a oculus testing activity for the group
2023-06-06 11:04:07,I’ll get one in the next meet-up
2023-06-06 11:19:39,has anyone here experimented with Neurosity Crown? and the membership?
2023-06-06 11:21:43,Which version do you have.  I have quest and I can easily spend hour...
2023-06-06 11:33:33,Same here. Has been sitting in the shelf after a month of getting it.
2023-06-06 11:35:57,"A couple of my colleagues have dry eye issues - due to excess device use. We need more AR tech that doesn't put a big screen in front of your eyes, closer to it, but uses other senses to inform us about the environment. I'll buy some of that kind of tech if it is interesting"
2023-06-06 11:36:29,I went from Oculus Go in 2018 to HTC Vive. Bought and returned Quest 2. Got Pico4 which is good for giant screen content and watching F1. Works well with both spectacles and contact lenses.
2023-06-06 11:40:47,Immersive travel using 360 images generated by stable diffusion seems to work quite well. 
2023-06-06 11:42:11,"Thinking more critically about the Apple VR headset release it doesn't do anything fundamentally different compared to the likes of Oculus VR, it is an upgrade for those really into the space. Sensing this trend lately at Apple in building mass market stuff like M1/M2 Macs and then also having Studio/Earpods Max/Mac Pro/iPad Pro M1-M2 and now their VR headset - all of these are for a small sliver of users."
2023-06-06 11:42:38,Not to mention Apple Watch Ultra
2023-06-06 11:46:55,Have a question regarding instruction tuning. I have come across two methods of fine-tuning:
2023-06-06 11:47:38,If I was an Apple investor I'd love these new demos but I'd be wondering where the cheddar is going to come from. Maybe gaming? One possibility since Nvidia despite its trillion dollars market cap isn't able to attract mass market GPU buyers. PC gamers seem more and more black pilled about the GPU scene from what I can tell. Generative AI won't necessarily change that market since mass market GPUs like the (underwhelming) 4000 series are not targeted at AI dev teams
2023-06-06 11:50:44,The quest 2 I think ?? I got early last year. Not sure exactly.
2023-06-06 11:54:44,"Yep, not a good experience with glasses."
2023-06-06 11:55:36,"Depends a bit on your masking e.g. one trick to mask some part of instructions too and that seems to improve generalisation in small models. But to the best of my knowledge, in most cases -- we do calculate loss on the entire prompt/context, right?"
2023-06-06 12:01:48,Thinking of getting a VR headset myself. Which one of pico4 vs quest2 do you prefer?
2023-06-06 12:05:35,yes
2023-06-06 12:06:01,Calculating loss on the entire context does work reasonably well in my experience but a lot of the repositories that I have come across recently mask the input completely. So I was wondering which is the better way to go.
2023-06-06 12:07:26,https://developer.apple.com/wwdc23/topics/ml-vision/  They are releasing access to segmentation (human/animals) and pose (both again) for Devs. Their own embedding for 27 languages as well. Quite a few interesting things.
2023-06-06 12:59:27,Does it find otp from messages? Or anything else as well
2023-06-06 13:00:10,This is a joke. But yeah I think if it can connect to your phone messages
2023-06-06 13:00:22,This is a long standing apple meme joke
2023-06-06 13:00:30,Ohh😅
2023-06-06 13:54:28,https://aistartupstrategy.com/home
2023-06-06 13:54:44,what do y'all think of this?
2023-06-06 14:21:24,Excellent thread... Which begs the Q: are there good thread summarisers? Maybe a browser extension?
2023-06-06 14:22:22,I am not sure I understand a 100%. 
2023-06-06 14:26:13,A16z also has the same kind POV for B2B https://a16z.com/2023/03/30/b2b-generative-ai-synthai/
2023-06-06 14:34:56,"Hello, has anyone tried TheBloke/falcon-7b-instruct-GPTQ? If yes, any reference notebook having the implementation?"
2023-06-06 14:36:38,I agree with this 100%
2023-06-06 14:37:14,"My 2c: The OP is less gung ho about the long term business use case of creative AI, it seems. He says consumption ML (recommendation algorithms?) makes more business sense. Kind of when Andrew Ng said most ML was supervised, though unsupervised is more cool.  The thread has others interesting replies though"
2023-06-06 14:37:27,"This is great, thanks for sharing."
2023-06-06 14:38:28,I am still wondering what it implies for marketers. How do we stay ahead of the curve. 
2023-06-06 14:39:22,I do agree with him - the novelty of using the new platforms will wear off.
2023-06-06 14:40:00,There's an initial shock and awe when new tech is introduced to us but we get used to it pretty quickly also
2023-06-06 14:40:22,I think that’s the only meaningful advice right now. Nobody in the world knows how all the pieces will interact with each other and the end effects on individual industries and roles.
2023-06-06 14:42:36,"Novelty will wear off, but we are also truly limited by our imagination today. So new use-cases will keep coming even if we choose to ignore the seismic shifts of more capable models or larger context windows or faster latencies."
2023-06-06 14:45:04,"Hmmm. One of my theories is that the noise will increase manifold, so the ability of a marketer to differentiate their brand will become even more significant."
2023-06-06 14:46:32,"For eg, it used to take 2 hours and someone really skilled to do the equivalent of Photoshop background filler. "
2023-06-06 14:48:49,is the question from the perspective of the photoshop expert or the person who commissioned that assignment?
2023-06-06 14:51:07,From the pov of market demand. Differentiating yourself (a photoshop expert) in a market where ai wrappers can do in minutes what took you hours.
2023-06-06 14:51:16,So strategy will become more imp
2023-06-06 14:52:44,"Yes, your ability to decide the plan/instructions/imagination becomes the differentiator"
2023-06-06 14:55:14,"Also, when turn around time reduces beyond a certain threshold because of tool improvement, people with overlapping skill sets become dramatically more leveraged"
2023-06-06 14:56:09,Say the marketer who now knows how to use Photoshop will have way higher productivity than someone who needs one more person to be productive 
2023-06-06 14:56:57,Makes sense.
2023-06-06 14:57:43,I was speaking to a senior data scientist at swiggy last weekend and she suggested to look at all ai tools and this entire wave as a new computer that's way more powerful than what we have on hand.
2023-06-06 14:57:58,"At the end of the day, marketers need not try to understand how these tools work."
2023-06-06 14:58:02,Just need to be able to use them
2023-06-06 15:54:04,https://www.youtube.com/watch?v=sKFwS0TEHHM
2023-06-06 17:02:15,does the feel like a similar angle that mojo is taking
2023-06-06 17:06:00,*who all are attending
2023-06-06 17:06:50,"Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?"
2023-06-06 17:08:25,I guess i'm not cool enough to get an afterparty invite 😀
2023-06-06 17:10:31,this is different right. I just signed up and saw that there r about 100 tickets left
2023-06-06 17:10:44,https://bit.ly/43qE9GD this is link btw
2023-06-06 17:14:13,"thanks, I RSVP'd."
2023-06-06 17:15:07,"Have a test battery of some sort to, commit frequently and log both the prompt and output"
2023-06-06 17:15:57,True but no way to measure sensitivity or accuracy iteratively against a gold standard answer yet right?
2023-06-06 17:18:55,"is this truly generative (e.g writing something). Then it's tough. But if it's more objective, then why can't you measure? See this sheet for example for logic tests https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595 What this guy has done for m questions across n LLMs you can do for p prompts for the same LLM and check the output (I hope I'm understanding your question correctly)."
2023-06-06 17:22:02,"Not sure what you mean by sensitivity or accuracy in the context of generated text, but you can use task-specific scores e.g. ROUGE/BLEU for summaries and so on"
2023-06-06 17:22:08,This is interesting. Unfortunately I’m looking at written support responses to user queries and need to test this on a number of inputs links/queries + different prompts to find the ideal output.
2023-06-06 17:25:09,https://vickiboykis.com/what_are_embeddings/
2023-06-06 17:27:17,"We do use embeddings, but it’s still a veery iterative process :)"
2023-06-06 17:27:50,"Hey Folks,"
2023-06-06 17:28:20,Would love to chat with anyone who does prompt engineering on a regular basis to understand best practises. Do lmk :)
2023-06-06 17:30:33,You can check this too: http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
2023-06-06 17:31:52,"NICE, looking like few seats are left now"
2023-06-06 19:38:28,"-> Since we could not accommodate everyone at the afternoon meetup & we got an overwhelming response, hence opened up an after-event party, just after the meetup so that more folks can meet, learn and showcase their products.  "
2023-06-06 19:52:23,Does anyone know of startups working on AI in the legal domain .. i need some help/advice. It would be great if anyone could DM me.
2023-06-06 19:53:36,[PHONE REMOVED]
2023-06-06 19:57:04,"and so as Nirant suggested, you should be able to use ROUGE/BLEU scores and rank your prompts then?"
2023-06-06 19:59:19,DMing you ..[PHONE REMOVED] and few others are building in this space as well.
2023-06-06 20:04:40,Does anyone know of a media production house using Gen AI in their workflows?
2023-06-06 20:12:31,cc [PHONE REMOVED] thought this might be interesting to you
2023-06-06 20:13:26,"Hi, I know a few, who are doing this."
2023-06-06 20:13:40,We’re trying a few things at The Viral Fever. Please DM
2023-06-06 20:13:54,Would love to know more
2023-06-06 20:14:04,"Sure, lets talk on DM?"
2023-06-06 20:32:19,Has anyone here tried to fine-tune Falcon-40B or 7B?
2023-06-06 20:34:16,yep I have tried it 
2023-06-06 20:35:13,Yes I wear glasses too. It's a bit tricky to setup. Initially
2023-06-06 20:44:37,Added Abhishek Sagar [PHONE REMOVED]. Currently VP Engineering at Zomato
2023-06-06 20:52:04,Official Hugginface instructions on training Falcon7B with their PEFT lib huggingface.co/blog/falcon#fine-tuning-with-peft
2023-06-06 20:56:41,Thanks Pranjal. Looking forward to learn and collaborate here
2023-06-06 21:04:46,We have invested heavily in building a benchmark. Run it on every commit. Tag ground truth queries with tags so that you can get quick feedback Om which kind of queries fail
2023-06-06 21:21:30,https://huyenchip.com/2023/04/11/llm-engineering.html
2023-06-06 21:48:52,"After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock) "
2023-06-06 21:49:48,Langchain's investment seems to be making a difference - at least in code that has changed. Some API changes clearly visible in versions weeks apart
2023-06-06 21:52:03,Do you like those changes? Want to elaborate which ones caught your eye?
2023-06-06 21:53:02,Actually something that used to work earlier doesn't work. With the Langchain SQL agent. :D
2023-06-06 21:53:21,That said it is probably just us trying to get up to speed. We'll get there
2023-06-06 21:53:41,"The list of demos, APIs which are core and now broken/no longer maintained is very long"
2023-06-06 21:54:03,Indeed!
2023-06-06 21:54:11,seems like they are going to build another Jina
2023-06-06 21:54:39,All ML tools converge to Jina and Haystack 🤣
2023-06-06 21:55:05,"Haystack seemed very promising, I haven't tried it yet, but was seeing the docs"
2023-06-06 21:55:39,Anyone know a good guide to testing chat bots? Really interested in that right now
2023-06-06 21:56:09,"Full end-to-end testing, with automation."
2023-06-06 21:58:21,I say this with some degree of exposure e.g. I used to head ML for Verloop.io — Nykaa's chat support bot maker: 
2023-06-06 22:00:55,Happy to chat. Do we want to do a group call this week? On legal side?
2023-06-06 22:00:58,"For conceptual design of *testing* chat bots, Rasa continues to be the highest return on your reading effort: https://rasa.com/docs/rasa/testing-your-assistant/#how-to-write-test-cases"
2023-06-06 22:01:48,We built some chat bots on Rasa to act as fasting coach (at Nintee)
2023-06-06 22:02:06,"Thanks, Nirant. I am familiar with Rasa for NLU, perhaps time to revisit in this context"
2023-06-06 22:09:00,Nat Friedman and Daniel Gross have invested in Llama.cpp — the company is called ggml.ai 
2023-06-06 22:12:21,"While I don’t know much in NLU for chatbots ,I’ve evaluated and piloted quite a fair bit of 3rd party SaaS integrations including Verloop,Yellow and Haptik for customer care and support queries."
2023-06-06 22:23:30,Would love to hear thought if someone has compared Google's STT vs Whisper or any other model. Any pros/cons for both to decide which one to use if performance is a big weighting factor?
2023-06-06 22:24:10,Prompt injection is top of mind for me right now. Anyone looked at automated prompt engineering ? There’s work done on this and published as a paper (with code)
2023-06-06 22:30:31,This would have been shared earlier in the group 
2023-06-06 22:32:11,I’ve come across guidance but we’re figuring out how langchain and this fit in together. Have you built with this framework and do you have suggestions?
2023-06-06 22:32:41,Kor is interesting for some use cases. Specifically structured data extraction
2023-06-06 22:33:19,"No I haven’t used it.I’m still figuring it out too,feel that it’s slightly complicated 😅"
2023-06-06 22:39:11,I hear you. Lots of frameworks at this stage. Just the state of the tech right now
2023-06-06 22:39:58,i am  using langchain for the agents part of it
2023-06-06 22:42:24,"people who are using langchain here, just curious - which agents are u folks using ? "
2023-06-06 22:43:37,Has anybody setup privategpt? I am thinking of using it for a project in my org. I wanted to see if there are any caveats / pitfalls before hand
2023-06-06 22:44:04,Is this similar to guardrails.ai?
2023-06-06 22:44:13,"Yeah, you can't use it your org. Research license only for Llama"
2023-06-06 22:45:06,Using SQL and the ones you mentioned
2023-06-06 22:45:47,Thanks Nirant.
2023-06-06 22:46:53,"If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct"
2023-06-06 22:47:02,That is permissively licensed
2023-06-06 22:49:41,"If we use Azure OpenAI and we don’t choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?"
2023-06-06 22:50:39,"Guardrails is for making sure LLM output is in desired schema, they're talking about prompts in the other message"
2023-06-06 22:51:01,data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders
2023-06-06 22:51:39,Those regulations do apply to us. Thanks Sandeep for your input.
2023-06-06 22:53:16,Azure should make these models available in the India region. Any idea if that is in the works?
2023-06-06 22:55:38,This was a question someone wanted to ask Sam Altman
2023-06-06 23:00:25,"my bet is not possible - unless US regulations on export of LLM gets clarified. will take some time, but eventually will happen."
2023-06-06 23:00:34,until then - it is Falcon 40B
2023-06-06 23:20:25,Sandeep - are you fine-tuning falcon-7/40b for custom use?
2023-06-06 23:28:50,Even I interpreted the meaning of the excerpt the way ChatGPT thought of it.
2023-06-06 23:31:48,[PHONE REMOVED] what is your take on Tree of thought?
2023-06-06 23:34:33,based on the video.
2023-06-06 23:39:47,"I mean, does it make sense to say “there is an embeddings model for gpt-4” or are they unrelated/independent?"
2023-06-06 23:59:55,"Completions model accept plaintext toh, so whether you embed or not pre-completion is independent/use-case wise."
2023-06-07 00:05:35,not really - im on the side of working with prompts and vector db to do the same stuff that a finetuning would.
2023-06-07 00:08:33,They are independent. I choose HF's instruct over ada-002 usually.
2023-06-07 00:11:35,7b fine-tuning to get a reasonable QnA performance with all prompt engg possible.
2023-06-07 00:14:14,super interesting. ur saying the prompts havent worked ? are u using the standard langchain chains/prompts ? 
2023-06-07 00:16:13,Can you share model card for this?
2023-06-07 00:16:50,Folks basic question - when does one use LlamaIndex vs Langchain ?
2023-06-07 00:17:41,"Yes, it worked reasonably well with gpt-3.5, even zero-shot was okay in some cases."
2023-06-07 00:21:52,"this is very interesting. i am pretty sure u will get bang for buck by writing custom chains for falcon. unfortunately i havent done so, or i would have pointed out."
2023-06-07 00:22:28,This thread from [PHONE REMOVED] answers it well
2023-06-07 00:25:27,No clue how to approach it but worth a shot. Are you hosting privately as well? I want to understand cost and scaling dynamics.
2023-06-07 00:28:17,"not yet. but there seems to be a whole bunch of startups who are providing inference hosting. its generally commodity, but the key is going to be GPU rates/availability which seems to be the blocker these days."
2023-06-07 00:28:31,that said AWS Sagemaker might end up being the cheapest.
2023-06-07 00:28:43,P.S. Falcon was trained on sagemaker
2023-06-07 05:11:35,"Well deserved. ggerganov single handedly making Bulgaria an AI power house. Meanwhile, Nat and David Gross have been supporting many Indie hackers, challenges and sponsoring similar events here in Bay, too. We don't have any significant project like this coming out of India. Not even fine tuned models like what Teknium is doing."
2023-06-07 08:29:17,Has anyone built their own GPU rig or knows someone who has?
2023-06-07 08:46:06,[PHONE REMOVED]  have you guys done anything like this?
2023-06-07 09:12:18,Woah!!!
2023-06-07 09:16:59,cc [PHONE REMOVED] [PHONE REMOVED]
2023-06-07 09:17:53,Ty! 
2023-06-07 09:21:15,I need help with board specs to build 7 3090 GPU rig and dealing with multi PSU pwm sync. Any suggestion?
2023-06-07 09:21:39,whoa that is cool!
2023-06-07 09:24:57,I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data. 
2023-06-07 09:34:22,"On text gen evaluation, I found this prompt in the new Andrew NG course on LLM"
2023-06-07 09:35:57,Does anyone here use Jina?
2023-06-07 09:44:38,"in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that."
2023-06-07 09:45:12,also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity
2023-06-07 09:46:31,"it also has domain adaptation, etc. But honestly, the BERT vocab isn't so big (intentionally) so there might be trade offs depending on the data you have."
2023-06-07 09:46:37,Yes I explored this one. But this requires you to have a pair of sentences with similarity score for training.
2023-06-07 09:48:31,Does FAISS have domain specific adaptations ? Will definitely explore this one.
2023-06-07 09:52:07,"FAISS is a similarity library, and does not support finetuning or training vectors. Did you mean to say that direct vector similarity works?"
2023-06-07 10:13:08,"yes, in our final implementation we trained vectors using fasttext on our own corpus and then the similarity is using faiss."
2023-06-07 10:39:22,Just saw this: LLM with 5 million token window (can engulf a company's whole codebase)
2023-06-07 10:42:33,What’s a gpu rig? Do you mean a computer or like those crypto garages
2023-06-07 10:44:45,"Actually this is the question I'll try to ask Sam Altman tomorrow, if I get a chance to."
2023-06-07 10:57:43,We have a 3070 rig for gaming. Looking to build a larger for ML.
2023-06-07 11:00:15,OpenAI is maai baap 🥲
2023-06-07 11:04:24,When's the next Gen AI meetup?
2023-06-07 11:06:03,"24th June tentatively, hasn't been announced anywhere yet — experimenting with a format change, might not do talks this time"
2023-06-07 11:09:19,Sure
2023-06-07 11:28:17,Does fasttext provide non supervised training on corpus ?
2023-06-07 11:28:51,"Yes. fasttext is popularly used for embedding, you do not need labels."
2023-06-07 11:31:17,I thought so too. Evaluated it for similarity but end up using nmslib.
2023-06-07 11:34:30,Does anyone know of any api/tools that implement something like this? 
2023-06-07 11:38:04,"aieeeeee I wrote FAISS when I meant fasttext. Sorry for the confusion, my bad ... 🤦‍♀️"
2023-06-07 11:41:25,```fasttext``` is a text classifier right?
2023-06-07 11:43:37,Fasttext is embeddings.
2023-06-07 11:44:26,word vectors specifically.
2023-06-07 11:44:35,See https://fasttext.cc/docs/en/unsupervised-tutorial.html
2023-06-07 11:44:43,"*subword vectors, and for the longest time — the best subword vectors"
2023-06-07 11:45:28,"And even today, if you're doing something like really fast, think Cloudflare Edge workers or Raspberry Pi — the best quality vectors you can train there in theory"
2023-06-07 11:47:10,"might be a noob question sorry as I’m learning on the go, but how is it different from an embedding model like openai’s or HF’s?"
2023-06-07 11:47:32,"And thanks to this approach, it's quite tolerant of spelling mistakes!"
2023-06-07 11:49:02,1. It works™️
2023-06-07 11:51:41,okay so you don’t have to call the API everytime
2023-06-07 11:52:09,you can run it locally. very lightweight.
2023-06-07 11:52:35,Has anyone deployed Qdrant in production cloud ? Would be interested to hear
2023-06-07 11:52:35,Locally is best I think
2023-06-07 11:52:52,Cloud as in Azure AWS Gcp own subscription
2023-06-07 11:54:38,i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index
2023-06-07 11:54:46,"Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too."
2023-06-07 11:54:50,"Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence."
2023-06-07 11:56:09,worked great and was zero cost since we computed the embeddings on our laptop and updated production open source a couple times a day however today i would go with open I embeddings endpoint
2023-06-07 11:56:37,Yes Docker Qdrant on cloud Azure AWS that's what I am after
2023-06-07 11:56:49,i used hf sentence transformer for creating embeddings before worked great
2023-06-07 11:58:06,this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text
2023-06-07 12:02:45,you mean chunking the documents right?
2023-06-07 12:03:32,"Need some suggestions,"
2023-06-07 12:09:42,You want to use one that is better for search.
2023-06-07 12:13:28,"So search part I can experiment with different models like MiniLM or instructor-xl. But should I go for an ""instruct"" model or a ""chat"" model, will that matter much in the performance?"
2023-06-07 12:15:25,That won't matter. Quality of the model will matter.
2023-06-07 12:18:05,"Also for POC purposes, I am using ChromaDB. Do you suggest trying Weaviate etc? I think the search will differ."
2023-06-07 12:27:43,"Weaviate supports hybrid search, which we know from MIRACL and BIER both is better than doing just Vector Similarity"
2023-06-07 12:28:32,"It's also wayyy more performant than Chroma e.g. in RAM usage, QPS etc"
2023-06-07 12:29:44,😂😂
2023-06-07 13:18:11,This is for the people have created custom Langchain agents- Can you suggest how to create a Langchain agent for a python library?
2023-06-07 13:19:14,Look up Yolo pandas source code
2023-06-07 14:57:36,"I didn't do it for any lib, but I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook."
2023-06-07 14:59:37,>*I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook*.
2023-06-07 15:30:30,Loud and clear 🤪
2023-06-07 16:03:39,is it just me or is the openai completion api throwing more errors than usual today?
2023-06-07 16:07:42,"yes, for me as well. Had to restructure the entire prompt pipeline to accomodate for the subtle change."
2023-06-07 16:19:21,"Nirant,"
2023-06-07 16:20:22,https://github.com/beir-cellar/beir
2023-06-07 16:21:23,https://project-miracl.github.io/
2023-06-07 16:38:41,Curious about this - what kind of errors led you to change prompt pipeline?
2023-06-07 17:03:53,I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?
2023-06-07 17:05:58,Ofc i don't agree that llm apps have no inherent (tech) moat.
2023-06-07 17:06:02,"The question isn't about moats around LLMs, it is about building viable businesses using it. I think VCs should probably look at the fundamentals of the business more than just the fact that the team happens to be using LLMs."
2023-06-07 17:07:17,Yes. But argument is if business fundamentals are built on top of LLMs which have no moat. Anyone can build the business on top of the shiny llm tech
2023-06-07 17:07:37,I think at need to define what really a moat is here.
2023-06-07 17:07:59,Does it mean no moat?
2023-06-07 17:08:16,Yes. We are talking about inherent product moat i.e. technology moat.
2023-06-07 17:08:33,Do you call Google a tech moat or distribution moat?
2023-06-07 17:08:42,Defensibility will depend on the nuances of the problem they are solving. In business context. In stickiness with users. In operating model etc.
2023-06-07 17:09:24,Also a lot of tech moat is a function of distribution and a lot of distribution moat is a function of tech. 🤷‍♂️
2023-06-07 17:10:12,Google had a huge tech moat when they started. It was founders research thesis put to commercial use.
2023-06-07 17:10:25,I would argue that the presence of a moat is owed to production traction in the market. Does Pytorch have a moat? i'd argue yes. Does Azure or big cloud have a moat? I'd again say yes.
2023-06-07 17:10:40,*product traction in the market (not production traction)
2023-06-07 17:11:04,Then you’re saying moat is temporal too. Fair. 
2023-06-07 17:11:57,I don’t know how PyTorch needs to be evaluated here since it’s not a for profit business.
2023-06-07 17:14:32,"Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples"
2023-06-07 17:15:04,Do you think they have a tech moat? Id like to argue they have a distribution or capital moat.
2023-06-07 17:15:11,Yep. Absolutely. Now the question becomes if everyone is positioning to increase productivity (more specifically business productivity) what happens to product lifecycle and moat lifecycle. 
2023-06-07 17:15:15,A temporary moat is just a head start. A moat is a long term deterrent to new entrants.
2023-06-07 17:16:36,"as a VC actively investing in GenAI I wanted to provide some nuance from the ""other side"". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of ""attempts"". That said, if your only moat is ""building on LLMs"" then it's equivalent to when you were in the late 90s and were saying your only moat is ""building on the internet"". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so ""being early was the moat"" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last."
2023-06-07 17:17:45,Most complete opinion I've read in this chat
2023-06-07 17:18:01,Moats of most large businesses have been on sourcing / distribution in the longer term. Most early technologies will be very easy to replicate (unless proprietary). VCs should be betting on good founders with a long term vision building in a growing market. Just being on an early tech edge is foolish imo.
2023-06-07 17:24:34,"I think if you learn how to talk to LLM which is not very steep learning curve then ""Anyone can build a wrapper"". "
2023-06-07 17:33:40,"As a compute user, I'm also bullish that more large enterprises will see their costs go down by adding self-owned compute to their cloud usage — DC design will have to evolve to adapt for this"
2023-06-07 17:34:19,Intel Bangalore works on Intel Habana Accelerator. We could get someone to talk at one of the events
2023-06-07 17:34:20,As someone who has actively worked with global Telcos and around network and data centers.. was in awe of this DC thread from [PHONE REMOVED] earlier today
2023-06-07 17:35:21,IMO here are the ways to look for moats in the LLM land (from the tech perspective) as it stands today. 
2023-06-07 17:44:01,Amazing. This kind of defines the nuances in a structured way. I can probably add 5th point after QA is - memory management. 
2023-06-07 17:48:49,"My intuition is that LLM API apps have a very limited moat, but apps built atop open-source LLMs with the right amount of messing around will have solid moats."
2023-06-07 17:50:52,And some new features/frontiers
2023-06-07 18:29:36,You can watch it live here: https://www.youtube.com/watch?v=AiE7FsdRzz8
2023-06-07 19:42:00,"personally I'm not convinced that vanilla prompt engineering is a moat. In my mind, prompt engineering is to llm what SEO is to search. You are trying to outsmart others but it's all kinda hacky. Pretty soon, everyone else is also doing it, so you are back to square one. Or (worse) the underlying algorithm changes and all your efforts are gone. There is something to be said about generating prompts intelligently using some proprietary data, feedback or using some other LLMs that can be a lasting moat which I look to capture in (2) (d) in my list. Happy to hear from others"
2023-06-07 19:44:44,What about an autogpt style prompt engineering?
2023-06-07 19:46:43,LLMs are like databases.
2023-06-07 19:49:48,"My long thesis - infrastructure is the model. The pipeline is - including the prompt selection, inference, prompt caching, jsonforming, private data filtering, etc etc."
2023-06-07 19:49:57,"This would depend heavily on the underlying model itself. If everyone is using the same model, everyone is also going to use same best practices to get functional autoGPT behaviour."
2023-06-07 19:54:08,It was funny to listen to the questions asked by learned men/founders/VCs to Sam Altman. I mean - Are these the same people giving full time gyaan on all platforms asking some questions to just get noticed or for the sake of asking questions. :/
2023-06-07 19:54:35,I think the moat is you throw many things at the wall and see what sticks.
2023-06-07 19:56:29,Don't call LLMs databases. I know it might have good recall but this just gives more ammo to people who think all LLMs do is memorize and plagiarize work
2023-06-07 19:57:20,Care to share a few examples ?
2023-06-07 20:02:12,"Disagree. There’s at least some amount of logic/reasoning which is a game changer. See the Sparks of AGI talk (or paper) https://youtu.be/qbIk7-JPB2c I think most of the wow going ahead is going to be in the reasoning/planning/logic side of things. I don’t see LLMs replacing databases as such. Again, happy to hear thoughts otherwise"
2023-06-07 20:02:55,"I don’t mean it in the sense of what databases do, but in the sense of they being infra components"
2023-06-07 20:08:05,Kunal Shah asked sama a very interesting qn at the ET TCS event today.
2023-06-07 20:11:33,"The other thing which was cool, and he’s of course said this many times but it’s always interesting to hear it again, is that energy and intelligence are two core units of our world, the decreasing costs of which have traditionally driven technology and society forward."
2023-06-07 20:16:30,"Btw I hope this is interesting, just thought I’d share what stood out for the group’s benefit."
2023-06-07 20:16:43,That’s interesting insight
2023-06-07 20:17:40,This will make a killing in the Philosophy group!
2023-06-07 20:24:14,"I’ve wondered about the hypothesis of whether empowerment really brings betterment. Lest I get called out that is something to think about. When we build new differentiated capabilities and tech and put it in the hands of people, are we doing the fundamentally right thing? What is the right thing and how would it be decided? These are questions of technology and ethics. One of the old sci-fi shows I liked often saw this kind of theme and it makes you think about whether capitalism combined with a scientific / technological industrial complex produces more inequality and overall more downsides than upsides."
2023-06-07 20:24:34,This is probably a post for the philosophy group though. Sorry to have posted here
2023-06-07 20:28:25,"AI, Policy and Philosophy group link for reference: "
2023-06-07 20:50:22,I have another opinion. Moat is the sum of all advantages. So model also ads to moat.
2023-06-07 20:51:40,"Pratik worries so much about ads, it adds up to ads"
2023-06-07 20:52:38,Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell
2023-06-07 20:54:00,Today Sam compared GPT4 to the old Nokia brick phones and said GPT15 will be very different and we won't remember GPT4. Just FYI. 
2023-06-07 20:54:11,Strange. Is he making a case that intelligence can't be substrate independent?
2023-06-07 20:54:49,"I tbh found that question bit rhetorical. Like kunal already has an answer in his mind and he wants to validate his point of view. Also, what sama answered was equally interesting. 😬"
2023-06-07 20:58:41,"The Gujarati in me thinks this is fair game, the engineer in me thinks this is blasphemy. The net result is I've not made anywhere close to the money this person has made from git cloning langchain docs"
2023-06-07 20:59:25,Something I know by talking with one of the founder is many of them actually tried training davinci on docs and failed and then they came to know RAG works better
2023-06-07 20:59:42,What’s his MRR?
2023-06-07 21:00:06,"And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me [PHONE REMOVED] bhai — so clearly, distribution wins over knowledge. Everywhere."
2023-06-07 21:01:08,It was 60k last month.
2023-06-07 21:01:28,"Yes, who asks Wes Mckinney about Pandas for example - poor guy probably is busy building away and being ignored. And this is also the reason why Bernard Marr's articles on AI are everywhere 😅"
2023-06-07 21:01:42,Good for them!
2023-06-07 21:02:56,That’s why I want to learn frontend. AI is looking a weak part of my own moat now
2023-06-07 21:03:24,[PHONE REMOVED] se seekho
2023-06-07 21:03:54,We've had this convo. And we've digressed quite a bit from the topic :)
2023-06-07 21:04:25,Context window se baahar ho gaya
2023-06-07 21:04:44,Need a vector db for my brain
2023-06-07 21:20:23,"My motivation is that if my AI SaaS apps fail or I get bored in a few years, I wanna be atleast the most eligible CTO in the market 😅"
2023-06-07 21:20:58,I think this becomes more important now that our jobs are starting to come in the line
2023-06-07 21:24:39,"Deepmind trained alphazero style (SoTA models on Go, Chess and Shogi) Reinforcement Learning agents to find faster algorithms for sorting and hashing. In this algorithm finding game, their state was assembly instructions selected till now and information in registers and action was the next instruction to add to the algorithm. This problem will be as complex as playing chess or Go and the algorithm for sorting discovered by AlphaDev is 70% faster for shorter sequences and 1.7% faster for long (>250,000) sequences. https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"
2023-06-07 21:24:41,https://www.youtube.com/live/AiE7FsdRzz8?feature=share
2023-06-07 21:28:39,"Also feel there's a bit of an over indexation on moats. It makes perfect sense for VCs - their business model is to search for an outlier co, a 100xer that has strong defensibility"
2023-06-07 21:30:18,Fair plan
2023-06-07 21:32:51,"What happens when we deliver the same experience on a platform which provides many more opportunities to deliver value, is that new experiences overtake the ones we initially port to it. We see this pattern with other games too - we ported pong to a digital medium, but soon discovered asteroids can be a more fun game, and we could never have devised an asteroids game or a bricks game and its mechanisms in real life"
2023-06-07 21:34:02,"The same thing will happen with AI - we build solutions to real world problems with AI techniques, only to discover that there is a set of impactful AI specific capabilities that can drive even more value from AI than the ones we set out to solve. And these couldn't have been solved without the AI"
2023-06-07 21:35:40,Just a take from side for the sake of an argument: Distribution and knowledge both are leverage of their own kind. They both also lose their value when your competitors have access to the same level of distribution or same level of Knowledge. 
2023-06-07 21:37:54,This is true. There has to be a term to describe the asymmetrical success of bullshitting.
2023-06-07 21:38:49,Brandolini's law 🤣
2023-06-07 21:39:26,TIL https://en.wikipedia.org/wiki/Brandolini%27s_law
2023-06-07 21:40:30,Idea for metaverse room - where Brandolini's law and Hanlon's razor meet
2023-06-07 21:49:12,"Indeed. That's a great example. Using the same analogy, it's probably a good idea to start making pong, even if others are as well. You'll probably discover the idea of asteroids along the way"
2023-06-07 21:52:35,This is why AI-native startups (starting now) have a different kind of advantage over existing incumbents (who have distribution advantage)
2023-06-07 21:57:26,"How to change pose of a person keeping identity constant, like i wanna take a source image, just change the direction in which a person is looking and regenerate the image"
2023-06-07 22:01:08,Can anyone give a tl;dr of Sam Altman's Econ Times talk? Or the most interesting bits?
2023-06-07 22:02:32,Or is it worth watching in full? (had planned to watch but randomly saw Prasoon Joshi in the audience so kinda depriortized it abhi)
2023-06-07 22:03:00,Lol
2023-06-07 22:06:27,LLMs outperform RL at game play by studying papers and reasoning through chain-of-thought. 
2023-06-07 22:11:38,New open source text to video model: potat 1 by camenduru
2023-06-07 22:20:36,came across this via LiverDoc's thread?
2023-06-07 22:21:11,Ya he's been on a crusade against fitness influencers recently
2023-06-07 22:28:56,"[PHONE REMOVED] - two questions from this, when I load the dataset via HF, the feature order is reversed (answer, question), was it same with you?"
2023-06-07 22:30:38,Complex Product processes can be moats as well.
2023-06-07 22:48:58,Doing complex and boring things are great moats!
2023-06-07 22:53:26,Using RL to improve sorting algorithms
2023-06-07 22:54:24,"This is scary and exciting at the same time. Alphadev could next discover the best possible compression algorithm, graph traversal algorithms and humans would start completing relying on alphadev like AIs."
2023-06-07 22:55:37,These algorithms have been integrated in llvm c++ sort library replacing previous known human benchmarks.
2023-06-07 23:03:36,"The policy is “Authors must make available upon request, to editors and reviewers, any previously unreported custom computer code or algorithm used to generate results that are reported in the paper and central to its main claims.” Deepmind has a history of publishing in nature (since DQN paper in 2015) and they have never shared source code ."
2023-06-07 23:06:42,Checkpoints for Openllama - anyone tried it yet?
2023-06-07 23:31:06,Got an extra ticket for a friend for tomorrow’s sam altman chat happening in iiit delhi. DM if anyone’s interested in getting one.
2023-06-07 23:32:41,Reminds me of Saurabh Mukherjea’s article on forming moats ([PHONE REMOVED] don’t hate me for mentioning him)
2023-06-07 23:37:48,Hi all
2023-06-07 23:53:42,They've shared implementation as llvm already integrated this in STD c++ sort library.
2023-06-08 00:05:21,They shared C++ implementation of the sorting algorithm discovered by AlphaDev. But they haven’t shared code of training AlphaDev.
2023-06-08 00:06:33,But deepmind usually doesn’t open source their code at all..Meta comes in and builds an open source version of deepmind papers.
2023-06-08 00:09:27,Ohh ok. Misunderstood the reference.
2023-06-08 00:10:04,Yes true.
2023-06-08 00:26:56,We have. They actually asked lots of detailed questions multiple times and it seemed like the quality of the response matters to them.
2023-06-08 00:55:53,Thank you - might DM you for more information but will reapply for now.
2023-06-08 01:16:23,I've been trying to get access to Claude 100k for hobbyist experiments and couldn't get it even after trying twice. 
2023-06-08 01:20:34,We just gave them our use case and how we plan to use it. It was a technical answer
2023-06-08 01:21:46,What's the usual time they take to assess your application? Might need to brute force this one with multiple answers. Knowing how long should I wait before trying again would help.
2023-06-08 01:21:52,"Can someone tell me how ```FAISS``` is better than a custom nearest neighbor classifier that one can build in Python, i.e., say using scikitlearn’s ```KNNClassifier```?"
2023-06-08 01:29:40,I'm obscuring a few details for shorter answer - FAISS is awesome. They employ a bunch of techniques.
2023-06-08 01:30:41,Kind of like they went ahead and decided to improve SOTA block for each and everything in the pipeline for nearest neighbour similarity search and clustering.
2023-06-08 01:35:40,"So does it only improve scalability, or are there minute advancements in the underlying algorithm as well, i.e., in terms of complexity?"
2023-06-08 01:37:30,1. It's not better in algo. It's better in performance. FAISS is fairly hand tuned.
2023-06-08 01:50:55,Mostly under the hood optimisations in the pipeline. 
2023-06-08 01:53:35,And their really meticulously maintained GitHub repo with test suite for ann benchmarking you can try yourself - https://github.com/erikbern/ann-benchmarks/
2023-06-08 01:59:00,What is the definition of ```recall``` ?
2023-06-08 02:00:04,in this context
2023-06-08 02:00:59,thank you very much
2023-06-08 07:07:16,https://twitter.com/albtaiuti/status/1666464784995459074?s=48&t=dSB_vXgXsC6qhF1TYEKlZw
2023-06-08 07:19:15,"GM fam, does anyone know of any test to determine consciousness of a system ? OpenAI claims that chatgpt4 isnt conscious, but how can they be certain if a future version of chatGPT is or isn't conscious ."
2023-06-08 07:22:33,This is perhaps best answered and discussed in the philosophy group of the community.
2023-06-08 09:40:20,"Good morning folks. Any laptop recommendations for text based LMs/NLP work? Cheaper the better, other functionalities irrelevant."
2023-06-08 09:45:38,Do you want to train ML on laptop or just do basic work on it and use VM for training?
2023-06-08 10:00:22,What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?
2023-06-08 10:03:37,https://twitter.com/RajanAnandan/status/1666641010284449792?s=20
2023-06-08 10:09:00,#truth 
2023-06-08 10:10:52,same question 
2023-06-08 10:17:50,"Train on laptop, yes."
2023-06-08 10:30:05,Sam had his Tony stark moment. 🤷🏻‍♂️
2023-06-08 10:30:24,But didn't like his shrewdness.
2023-06-08 10:31:52,Good that Rajan sir took it sportingly. We shouldn't stop trying.
2023-06-08 10:38:44,I'd say invest then
2023-06-08 10:38:47,Razer blade is really sleek
2023-06-08 10:39:11,Top class build quality. Latest model is ryzen 6900 with Nvidia 3080 gpu
2023-06-08 10:39:56,What’s wrong with what he says?
2023-06-08 10:40:02,"If you don't want to get into Macs, it's the best"
2023-06-08 10:40:13,I also would recommend the Asus rog x13 or z13
2023-06-08 10:40:26,Or even the G series
2023-06-08 10:40:35,"But these are very sleek, very portable and powerful"
2023-06-08 10:52:37,Most of my college folks use alienware gaming laptops for ML training because of high configuration.  
2023-06-08 10:53:03,Will check it out 👍🏽👍🏽
2023-06-08 10:54:41,"Friends, I think we've discussed laptops/personal compute quite often here -- and this forum isn't uniquely the best places for that. The wider web has more than enough answers which address ML specific needs. "
2023-06-08 10:55:15,"Thanks, this is super useful 😊"
2023-06-08 11:23:51,https://twitter.com/goodside/status/1666598580319035392?s=46&t=URoDrV5X7GPNPYSgYW42Dw
2023-06-08 11:25:30,"These are called ""Glitch Tokens"" and a well known artefact of all token-based LLMs, dating back to embeddings themselves: https://www.youtube.com/watch?v=WO2X3oZEJOA&t=224s"
2023-06-08 11:26:53,https://twitter.com/TheEthanDing/status/1666109071278104578
2023-06-08 11:27:40,I just read Llama index raised 8.5m
2023-06-08 11:29:30,"In all my discussions with Google and Microsoft, they have been saying they are using langchain for their work"
2023-06-08 11:29:43,"I am terribly sad that Langchain and Pinecone are not listed companies, I'd have made a killing shorting them"
2023-06-08 11:29:47,"Microsoft has something of their own as well, semantic kernel  IIRC"
2023-06-08 11:30:22,So in the long term definitely we will have better platforms built. But as of today this we what most folks use
2023-06-08 11:30:24,https://github.com/microsoft/semantic-kernel
2023-06-08 11:30:58,"But that's part of any new tech evolution, right?"
2023-06-08 11:31:23,"If you notice the folks Llama has been hiring, they're not a thin client which most folks are thinking about them. They're definitely looking to integrate backwards in the _same spirit_ as Ethan bhaiya said"
2023-06-08 11:34:36,"Looking at their work, they seem to be building towards having all types of data sources integrated with LLMs. It's a smart move as that is cumbersome. Moat like"
2023-06-08 11:37:09,Llama index has more potential than Langchain as a company
2023-06-08 11:37:56,"Man, you realize the impact of open source contributions when you see the growth of such products"
2023-06-08 11:38:32,"This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it’s all open source man"
2023-06-08 11:38:38,The community is driving it
2023-06-08 11:38:54,new strategies*
2023-06-08 11:39:02,Where is the +1000 emoji when I need it
2023-06-08 11:40:53,I know someone at the HF0 Residency is building a framework for creating Agents. He has a lot of credibility
2023-06-08 11:41:09,"Langchain, llamaindex have positioning as hubs of all activity around LLMs, all new stuff like babyAGI, autoGPT, privategpt got sucked really fast into the langchain ecosystem."
2023-06-08 11:41:10,As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.
2023-06-08 11:42:42,Our boy is maybe too busy with developer advocacy haha
2023-06-08 11:53:15,"To this point, since I just moved from a ML/ Data Scientist role to a VC role, one of the things I wanted to do is contribute back to the community. (I literally owe my career to them). "
2023-06-08 11:53:15,How exactly?
2023-06-08 12:15:08,"I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods."
2023-06-08 12:20:09,"Curious - how much do these cost? And what kind of investment in terms of time, money, and human resource we're looking at here?"
2023-06-08 12:21:41,Amjad Massad of replit is always on point with his wit !
2023-06-08 12:25:26,"True. Throwing 10M is not to going to create another OpenAI. Also, I talked about this thing two days back that we haven’t even seen fine tuned Llama, like Teknium is training, from India, which will cost 2-3k. Because India is not focused on indie hacking, taking a deep problem heads on, but everyone wants to build quick tool to raise money."
2023-06-08 12:26:44,And May be investor mindset also set the the tone for entrepreneurs.
2023-06-08 12:27:04,Just saw this - https://twitter.com/etnowlive/status/1666460799093620738?s=46
2023-06-08 12:27:24,"i think it boils down to research mindset, barring a few universities in india, we don't have a research culture"
2023-06-08 12:27:35,"VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups"
2023-06-08 12:28:11,Ilya used to charge $1M/year in 2017. That's one senior exec at OpenAI.
2023-06-08 12:28:34,Midjourney is an example of a small bootstrapped team taking on OpenAI and building a better foundational model
2023-06-08 12:29:00,"Safe to say we don't have affordable talent to make a super computer either, which Azure built specifically for LLM training and inference workloads for OpenAI. "
2023-06-08 12:29:02,1 million per year as a salary in SF is more common than we might think. Only normal that well funded startup talent receives such money
2023-06-08 12:29:02,…
2023-06-08 12:29:03,"I mean, look at the number of Asians (Chinese, Japanese, Koreans) building LoRA on Civitai, and look what we've for desi celebs/art forms. If we don't even have 10K LoRAs, where the talent, compute, cost —  is basically hobby tier: $100 or less —  I don't think we've a fair shot at even training GPT4."
2023-06-08 12:29:20,I think you should talk to a vc before being this strongly opinionated.
2023-06-08 12:29:22,"We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI) "
2023-06-08 12:29:49,what is the benefit for commercial entities doing academic research?
2023-06-08 12:30:32,I suspect that is part of the issue — this is NOT research
2023-06-08 12:31:12,TCS sponsored ET for hosting Sam 😅
2023-06-08 12:31:15,foundational models are not research? do you mean taking existing architecture and replicating runs?
2023-06-08 12:31:34,Why do you need $200k?
2023-06-08 12:31:34,Falcon-sized Foundations Models are not research
2023-06-08 12:32:00,So that I can afford engineers like you in addition to the compute and data. I don't think it's fair to ask you to volunteer your time.
2023-06-08 12:32:07,Or pay you below market rates either
2023-06-08 12:32:08,I kind of agree. We started with llama index and are now building outside of it - we're obviously very small and exactly fit their usecase but it just does not work for prod (scale etc)
2023-06-08 12:32:41,Did you've to step out become of complexity or scaling challenge
2023-06-08 12:32:43,[PHONE REMOVED] I think 200k isn’t enough btw
2023-06-08 12:32:46,But you can do it yourself with your 10k budget and keep all the equity. My point is it does not require many engineers
2023-06-08 12:33:00,"Fair, I'll ask [PHONE REMOVED] for the rest"
2023-06-08 12:33:04,"Pay entry level salaries of 3.2 lakhs in 2023, and sponsor million dollar conferences. Priorities are right."
2023-06-08 12:33:11,Equity (startup)
2023-06-08 12:33:25,It either requires money or time no?
2023-06-08 12:33:37,One person will take a lot of time.
2023-06-08 12:34:27,"As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is ""hopeless"""
2023-06-08 12:34:29,"The thing is Ilya, Karpathy, Alex are probably one in generation scientists, they are 10x valuable than Sama. But Sam decided to use his life savings and place a bet on them as an investor first and then operator. Where are those investors in India who will seek talent and then enable them like that, instead of building cheaper Indian copies of established US business models."
2023-06-08 12:34:32,People should not join if they don’t like the salary. Employee can always decide to fix their pay
2023-06-08 12:34:46,bit of both
2023-06-08 12:35:15,Aah. I've a lot of questions around this. DMing.
2023-06-08 12:35:27,"Alpaca, koala were made in days by a small team right?"
2023-06-08 12:35:43,"Things are changing, but salaries in ITES are still low - and each of those companies wants to build next gen tech but pay peanuts to young talent"
2023-06-08 12:36:06,Why?  Curious to hear your thoughts on this...
2023-06-08 12:36:16,Perhaps a lesson in this is that organization scale itself doesn't lend scale capability to execute
2023-06-08 12:36:17,Want to know more
2023-06-08 12:36:35,"they're answerable to their LPs and usually, they compete with PE firms for better returns. there needs to be commercial incentive. And even before that - I second what paras said. there should be government/research incentive before commercial and India isn't just there yet."
2023-06-08 12:37:36,curious - is it possible to build for India from outside by convincing outside talent?
2023-06-08 12:37:56,I'm happy to work with anyone interested in India style LoRAs. 
2023-06-08 12:38:11,Sorry but a lot of people they hire are not ‘talent’. They are a product of a terrible education system. Many of these companies become the place where they actually gain education
2023-06-08 12:38:21,Don’t you have like 5 friends to do this now? And anyways you don’t need a lot of people to do it now that you know the recipe. Training 7b model is not an infra problem when you know it costs only <1k
2023-06-08 12:38:37,Desi founders can't pay Bengaluru salaries which match Tower Capital. I doubt we can hire anyone at SF salaries
2023-06-08 12:38:52,there's a lot of indian diaspora sitting around doing basic programming.
2023-06-08 12:38:54,Who has that kind of money in India? 
2023-06-08 12:39:03,Aeee. You and I are not doing this peanut 7B models for pure marketing
2023-06-08 12:39:56,outside india. I have friends who are applied scientists at Microsoft and OpenAI with big fat salaries looking to do something for India but they just don't have the right channels.
2023-06-08 12:40:04,We not doing it is not a proof that it cannot be done. Just misplaced priorities
2023-06-08 12:40:50,"Ask any of them to take a ""3 month sabbatical"" and do this for us — and you'll see how many of them respond :)"
2023-06-08 12:40:55,*with us
2023-06-08 12:41:06,Been there done that. No one does.
2023-06-08 12:41:07,[PHONE REMOVED]
2023-06-08 12:41:29,Don’t they have a non-compete?
2023-06-08 12:41:33,lmk if they are looking for opportunities haha
2023-06-08 12:41:39,have anything to contribute?
2023-06-08 12:41:54,.
2023-06-08 12:42:33,"I think [PHONE REMOVED]  mentioned how it is important to get to the deep roots of problems and solve them. That *generates* value, and investors will come looking for such talent. That's what we need, perhaps, not a new initiative to have the best come and build for India in India (at exorbitant cost to our investors/companies)"
2023-06-08 12:42:33,"My experience in this department is summarised best by: Talk, even before LLMs was cheap"
2023-06-08 12:43:03,"well, a lot of them have left their full-time jobs to come to build for India."
2023-06-08 12:43:10,at least in my network.
2023-06-08 12:43:12,"Sama found Ilya before DL phenomenon started. Waymo, Tesla picked up whole CMU and stand firm team. May be someone had picked up Bhasini team before they moved out of India to work for Azure."
2023-06-08 12:43:22,"""lot""? Less than 0.1%."
2023-06-08 12:43:24,Will touch base.
2023-06-08 12:43:44,"No, they've come to build a business with 100% equity and realised that cost of living and talent is cheaper in India. Don't confuse the two."
2023-06-08 12:44:10,"yes, was just about to mention that. not sure if their interest lies in research."
2023-06-08 12:44:15,"Waymo, Sama and Tesla have very big pockets before they did so."
2023-06-08 12:44:36,"To reiterate, 13B, 40B models are not research. They're engineering problems today."
2023-06-08 12:45:11,A thing where India shines is frugal & cost-effective engineering - all of our success stories have been that
2023-06-08 12:46:45,Just one thought. I read the orca paper. Pretty interesting. But my main takeaway was that the models don't have great training data. I think we can work to that.  There's a few ways
2023-06-08 12:47:44,No one does. 
2023-06-08 12:48:00,Do you mean it has data quality issues ?
2023-06-08 12:48:07,"agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?"
2023-06-08 12:48:28,+1. Not twice but once in my case. But similar thoughts
2023-06-08 12:48:30,"No, we need to do English because we need to have the talent and skill to do this."
2023-06-08 12:48:51,I also don't think we've a talent shortage — we can pull if there are investors.
2023-06-08 12:48:57,Profit/Non-Profit
2023-06-08 12:49:11,"May be then we will never have anything big because our Unicorns’ account sheets are not healthy to invest in future, old elephants are full of bureaucrats, and investors are not big enough to take bets on big ideas."
2023-06-08 12:49:22,Yes. Big time
2023-06-08 12:49:22,"but why re-create a me-too model? if high quality, english open source models exist, why spend energy there?"
2023-06-08 12:49:33,i'd be interested if we garner enough VC interest.
2023-06-08 12:50:00,Why does it have to me-too? 
2023-06-08 12:50:14,The plain vanilla LLM is the basic skillset you need to even think about doing these
2023-06-08 12:50:34,or if any VC would be willing to take the bet.
2023-06-08 12:51:03,See waiting for any validation sets up unnecessary hurdles. As it is we haven't started. 
2023-06-08 12:51:28,*Samiksha
2023-06-08 12:51:43,I think that's why Rajan sir laughed when he mentioned the 10mil bit.
2023-06-08 12:51:46,Why do you need VC interest to be able to build a product? 
2023-06-08 12:51:50,hmm.
2023-06-08 12:52:21,"well, good foundational models are good at these skills."
2023-06-08 12:52:31,This group is enough. We don't need more. Folks here can come up with hundred different ideas. Just few of us need to start.
2023-06-08 12:53:15,"You're right. They're adjacent, slightly different. To be clear, StarCoder is better at Codegen than GPT4. "
2023-06-08 12:54:06,And Replit sized 1.3B models are still quite valuable because of how powerful and cheap they're
2023-06-08 12:54:30,Yeah so training a 1.3B model won’t be costly.
2023-06-08 12:54:50,"its a personal reservation - that I wouldn't want to waste my life in building something that someone might not fund, eventually. And I think I am not alone in this. its very difficult to gauge VC/or lets just say risk capital interest."
2023-06-08 12:55:07,Is there any benchmark supporting this?
2023-06-08 12:55:23,Inside track: Teknium is working on one.
2023-06-08 12:56:54,things are different in west. You get money for trying. I think someone mentioned earlier that we don't have experiment capital in India/or appetite. So I'd understand a founder's dilemma to raise money for money.
2023-06-08 12:57:12,pl correct me if am wrong.
2023-06-08 12:57:47,Dont you think that someone funding or not shouldnt be the decision maker but rather your depth of the problem the decision maker on whether the idea can make money.
2023-06-08 12:57:52,I work with MSRIT Bangalore students. 
2023-06-08 12:58:36,we're talking deep-tech only here.
2023-06-08 12:58:42,StarCoder doesn't have a VS Code extension which is any code. But happy to do a walkthrough of both instruct and auto-complete finetuned models from Replit.
2023-06-08 12:58:59,ISRO doesn't have to worry about a competitor paying them a higher salary. so easier to be cost effective there.
2023-06-08 12:59:04,This domain also presents a unique challenge of having money not necessarily leading to progress.  Getting GPUs and assembling clusters have long waiting times now.
2023-06-08 12:59:12,You think deep-tech doesnt need to have a business value?
2023-06-08 12:59:25,deep-tech only changes return timeline for capital.
2023-06-08 13:00:07,"okay, are they willing to wait that long?"
2023-06-08 13:00:44,Indian VCs dont have that deep pockets from my prelim research. There has to be some decent sized wins to be able to do that. There arent many unfortunately.
2023-06-08 13:00:55,exactly.
2023-06-08 13:01:19,plus not to forget outside competition.
2023-06-08 13:01:31,tech is and will always be global.
2023-06-08 13:02:23,"Yes. So, raise from a non Indian VC if the product is great?"
2023-06-08 13:02:27,we can do 1 to n tech here but 0 to 1 in any field hands-down balls-deep is extremely difficult.
2023-06-08 13:03:41,"Many investors in India need to embrace risk - not enough of them do, so the likes of Antler, Sequoia and others swoop in to make dividends on our builders and talent."
2023-06-08 13:03:53,"Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model’s geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan"
2023-06-08 13:03:54,"We need Patrons, pre independence or near independence India. Likes of Tatas and Birlas, to invest in long horizon projects. Right now only institute that is can do invest in deep tech is probably the GOI."
2023-06-08 13:04:12,Why blame VCs for this?
2023-06-08 13:04:25,We've discussed this in plenty of detail. Just last week. Please scroll up.
2023-06-08 13:04:38,How man?
2023-06-08 13:05:05,From what I have seen - cheap hard-tech MVP that can be scaled from a manufacturing pov can guarantee great returns as government and policy support is well-defined.
2023-06-08 13:05:15,Look at funds like GVFL
2023-06-08 13:06:21,"Not true na, how?"
2023-06-08 13:06:45,https://zerocowfactory.com/ <--- something like this.
2023-06-08 13:07:09,"talent can go overseas, correct?"
2023-06-08 13:08:07,He's right. NASA has to compete with the likes of Lockheed and SpaceX for talent - not the case with ISRO. Plus aerospace engg or education talent in India hasn't distinguished itself as tech talent perhaps has
2023-06-08 13:09:05,Why not ISRO? Do they have a laxman rekha on their engineers lol?
2023-06-08 13:09:17,"True. They are missing home runs to grow pockets first,  then invest some in long horizon projects."
2023-06-08 13:10:17,In fact the Laxman Rekha is around ISRO. Private defence/space tech companies in India have tall regulatory walls to scale before they can be productive
2023-06-08 13:10:40,*productive and profitable
2023-06-08 13:12:00,"No but what can bear them working for the likes of SpaceX/NASA? Had a friend in college, shifted to US, joined MIT's space eng program and now she's aiming to be an astronaut."
2023-06-08 13:12:12,from working*
2023-06-08 13:12:49,Decidedly off topic for this forum. Maybe move this convo-fork to DM?
2023-06-08 13:12:58,"With all factors equal, it's obvious that a region with more funding is likely to prosper than other regions."
2023-06-08 13:13:21,Sure.
2023-06-08 13:15:10,"Frugal innovation is hard to do when the price and targets are set by an increasingly global market and talent pool. If cloud costs the same everywhere, talent costs the same everywhere, but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base), investors should want to invest here because they get dividends"
2023-06-08 13:15:55,"""but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base)"" - Not enough proof yet on if they can make money."
2023-06-08 13:16:41,"I've tried it, it's terribly slow 😅"
2023-06-08 13:16:46,This question is going to define India at 2045. If we believe in this or not.
2023-06-08 13:17:30,"More proof (depending on use case of course) perhaps than the guys who funded the ""Yo"" app or Juicero had. Idiotic products get funded in Si Valley sometimes because it is possible to throw money around there. Discerning investors won't do that in India even for legit use cases at the same level"
2023-06-08 13:17:49,"Heck, they even funded Nikola millions of dollars without a single truck produced and that turned out to be a scam"
2023-06-08 13:18:07,The details to setup the extension and using it via shortcuts is all there on the installation page on the vs code extension itself.
2023-06-08 13:18:29,Are you saying India doesnt have enough weird ideas being funded? :P
2023-06-08 13:19:04,Hehe. I think it is a signal of risk. Shitty businesses will fail in a downturn but good ideas will make hay during an upswing.
2023-06-08 13:19:43,Half-good ideas even if they're sometimes boring can also do well if given a chance. I think that kind of thing doesn't happen often enough here.
2023-06-08 13:20:06,"Also, if your req. is just to get a free decent code autocomplete - please check codeium/AWS Toolkit Codewhisperer."
2023-06-08 13:20:52,Yes. Codeium is also quite decent
2023-06-08 13:24:51,"GitHub copilot is free for students (they need to provide supporting documents). There are some pretty amazing tools in their pipeline. I've tried their copilot chat, copilot labs tools (explain, translate, brushes etc.), Copilot for command line. All are really good"
2023-06-08 13:25:32,"cc [PHONE REMOVED] if students are familiar with Git and Github, Github Copilot is easiest to use."
2023-06-08 13:30:38,https://education.github.com/pack/join
2023-06-08 13:35:17,Point taken but an ecosystem like berkeley/bair takes decades to build !
2023-06-08 13:36:56,If only I had 4-5 AI researchers on my payroll......
2023-06-08 13:40:37,Is this wav2lip team? This is base for SadTalker and other oss models that can easily and cheaply replace D-ID.
2023-06-08 13:42:19,"There are world class researchers building high impact projects in India, especially in academia & industrial research labs(MSR work on native languages)."
2023-06-08 13:46:04,"Nirant, how does copilot compare vs replit ghostwriter ?"
2023-06-08 13:46:32,Is anyone here at the Sam Altman meet at IIIT DELHI today?
2023-06-08 13:49:10,"This is the David Vs Goliath thing. If it was impossible, OpenAI would not have been able to stress out Google. And many other startups would not have disrupted the leaders. It happens all the time as per the history."
2023-06-08 14:56:57,https://twitter.com/huggingface/status/1666737999990730752?t=mM6813k-AXjJXMoQxLResw&s=08
2023-06-08 15:26:19,https://twitter.com/brijbhasin/status/1666663734385979392?s=46
2023-06-08 16:03:36,"We've discussed this aplenty. As earlier, will ask the the next contributor to chip in with code, data or money."
2023-06-08 17:37:33,"Hey guys, how bad were the questions that were asked to Sam Altman yesterday? Lot of people dissing on Twitter"
2023-06-08 17:37:40,When is the iiitd chat?
2023-06-08 17:39:08,It’s happened. https://www.youtube.com/live/Pig9WbMN1lQ?feature=share
2023-06-08 17:39:41,not bad at all. not even a week of memes.
2023-06-08 17:40:14,Lol they're blowing out of proportion.
2023-06-08 17:40:20,Let's just put it this way - an AMA on r/India would've given us 100x interesting discussions at 99x lesser logistical costs
2023-06-08 17:40:22,Here comes the maestro! 😂
2023-06-08 17:42:51,Were the people there any AI people ki nahi?
2023-06-08 17:53:23,All I need with evening coffee is second hand embarrassment from watching this.
2023-06-08 17:53:59,Roast of AI when?
2023-06-08 18:16:21,[PHONE REMOVED] +1
2023-06-08 18:16:38,The IIITD session today was not bad. The moderators were pretty brutal on media and VC.
2023-06-08 18:17:10,The anchor was unbearable tbh. The other prof was up to the chop
2023-06-08 18:18:51,"Knew it long back, hence in the profession. Can’t imagine a code for sarcasm"
2023-06-08 18:19:06,Algo for badshah songs is still possible
2023-06-08 18:19:51,Is anyone working on converting complex-to-use software(most enterprise saas software) to chat-based interface software?
2023-06-08 18:25:08,"Don't worry, can't take your job since you don't get paid anyway Garv."
2023-06-08 18:32:33,What makes you say so?
2023-06-08 18:36:29,Ha anyone tried to solve for a contract analysis use case using AI?
2023-06-08 18:49:28,I randomly picked 36:00 in and was promptly amused
2023-06-08 18:49:36,Accidentally pre-empted
2023-06-08 18:49:54,Did anyone ask him what his background in AI is ?
2023-06-08 18:50:48,I still clearly recall the days when everyone was building a location based mobile app and Loopt was one of the also rans
2023-06-08 18:51:48,Yes dm-ing.
2023-06-08 18:51:53,It’s amazing the trajectories that are available to an take on a playground of fertile innovation
2023-06-08 18:55:08,you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )
2023-06-08 18:59:59,[PHONE REMOVED] Do you know on what Ashish Vaswani and Niki Parmar working on after leaving adept?
2023-06-08 19:04:13,I was looking for more like ChatGPT. Everything is just chat. More or less it also solves the problem. How they are doing it?
2023-06-08 19:08:26,Nahi
2023-06-08 19:10:43,It will interesting to see what they come up with.
2023-06-08 19:22:12,Would you like to more precise?
2023-06-08 19:22:52,"If you want to highlight particular clauses in a long contract, try using squad dataset"
2023-06-08 19:23:26,"There is a paper on it, they have also trained a roberta based model for the same"
2023-06-08 19:25:37,https://arxiv.org/abs/1606.05250
2023-06-08 19:31:26,"Half serious, half joking q :"
2023-06-08 19:43:53,We are building a gpt bot that can have multi-turn conversation with the user based on a given text document. 
2023-06-08 19:45:52,Dropped in to joke on the same but beaten by your meme.
2023-06-08 19:46:02,"If I am unfunny, model trained on me will be unfunny too"
2023-06-08 19:48:01,here's my 2s prompt...
2023-06-08 19:48:08,You are a support bot answering technical support questions about networking.
2023-06-08 19:48:17,and here's the response
2023-06-08 19:48:18,"To effectively troubleshoot your VPN issue, I would need the following information:"
2023-06-08 19:48:23,there you have it ... 🙂
2023-06-08 19:51:08,"Here's how I would design something for the challenge, just for the kick:"
2023-06-08 19:53:41,Would loove to see results. Can i DM you
2023-06-08 19:58:25,Yes. What sort of analysis
2023-06-08 20:03:27,😂 sure.
2023-06-08 20:03:40,https://www.linkedin.com/posts/rishi-sunak_as-the-world-grapples-with-the-challenges-activity-7072467476185243648-ttl8?utm_source=share&utm_medium=member_desktop
2023-06-08 20:04:38,"Seems Rishi Sunak is directly Taking some AI lessons from Sir Narayan Murthy, father-in-law to rishi sunak"
2023-06-08 20:07:33,I would love to join in on the effort Abhishek ! 
2023-06-08 20:10:28,I also want to know what these folks are doing: https://samaya.ai/
2023-06-08 20:25:07,[PHONE REMOVED]
2023-06-08 20:36:14,i would like to see a benchmark of this finetuned model..versus a non-finetuned model with jokes in a vector db/embeddings. and just using retrieval q&a
2023-06-08 20:40:33,Who wants to volunteer to do the RLHF ? :)
2023-06-08 20:43:56,"If there are people willing to do the comparisons, I can help out with RLHF training part. We will need large amount of comparisons."
2023-06-08 20:52:23,"I am familiar with solutions using symbolic representation and DSLs to some extent. With gen AI, i have seen people make plugins that use openai APIs to simplify clauses."
2023-06-08 20:55:47,I was thinking of using Deepspeed chat for this. But haven't put it into use yet. Do you have other methods in mind?
2023-06-08 21:06:22,"I had written scripts to train with RLHF. Writing these scripts directly or using deepspeed chat or TRLX is comparatively easy task. To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring. Also quality of SFT model determines how many comparisons we need. Sometimes both comparisons are bad and have to throw them away after evaluating."
2023-06-08 21:12:58,Yeah we won't have that many sets of instruction response pairs for this task in the first place. I don't think we'll get even 1000 instruction-joke pairs on this. Most of the content would also be in Hinglish and some work would need to be done to make it fit for the instruction tuning.
2023-06-08 21:19:03,"> To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring"
2023-06-08 21:20:43,This ui should have a positive affirmation message after every few annotations to keep the motivating
2023-06-08 21:20:50,Motivation *
2023-06-08 21:29:39,https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence
2023-06-08 21:33:40,"I haven't read the SLiC-HF paper yet. So can't comment on Pairwise Ranking. With DPO, they don't mention if DPO - Direct Preference Optimisation reduces sample complexity(number of comparisons needed to train equivalent of RLHF model.) But they do claim training with DPO is stable. So am guessing we might be able to do with 10 - 25% less samples. (Pure speculation from my side)."
2023-06-08 21:45:31,"SFT is supervised finetuning. Alpaca model is an SFT model built on top of Llama model. With SFT, we take the base language model (like Llama) and then finetune it on few thousands of prompt- response pairs. If we want our SFT model to follow instructions, we would curate few thousand examples like this - ""Prompt"": ""Explain the moon landing to a 6 year old""; ""Response"": ""People went to the moon, took photos and sent them back to the earth."". If we want SFT models to be chat models, we will keep the previous chat history in prompt and in response, we will add  whatever reply would be given to the last message in chat. SFT is effective when we have > 1000 examples; but can be useful with >100 examples too. If we have a good enough SFT model(Most outputs are at least somewhat funny), around 1000 - 2000 comparisons should be enough to see the magic of RLHF. (But here we will be operating with Jokes; so hard to predict.)"
2023-06-08 21:49:38,Btw for those interested in papers about Reasoning … this is Disneyland 😀 https://github.com/atfortes/LLM-Reasoning-Papers
2023-06-08 21:52:15,Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.
2023-06-08 22:08:48,"For this specific task, we actually need Garv's stand up or other similar comic sets as content. Generating content via api distillation won't help here as we need exactly one specific users style to be copied."
2023-06-08 22:30:37,new wrapper: simpleaichat
2023-06-08 23:29:16,https://twitter.com/francis_yao_/status/1666833311279517696?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Yao Fu et. a. found out prompts which gave accuracy of around 61 % on MMLU. Llama paper claims 63 % accuracy; but the best accuracy reported with open source prompts using Llama on MMLU was 48% till now. So Llama models are mostly as good as claimed by authors.
2023-06-08 23:47:33,Occam's razor!
2023-06-09 01:04:11,Not sure of Jason's intent though but ❤️🔥
2023-06-09 01:54:22,It should be called Everest Project instead of Manhattan.
2023-06-09 01:57:30,dozen manhattan projects is a wild claim. doubt if he's being sarcastic.
2023-06-09 02:01:17,The Manhattan project was 0.9% of US GDP. Rounding to 1% that's a hilarious amount to spend to spite a bay area visitor
2023-06-09 02:02:23,"Our USP has always been great quality at low price (ex. Mangalyaan), it makes more sense in the Indian context to work on efficient training and inference."
2023-06-09 02:03:22,"Not sarcasm. I think he doesn’t like OpenAI and Sama, since he was banned from YC demo days."
2023-06-09 02:05:51,these guys and their vendettas lol.
2023-06-09 02:05:59,This is my review of the orca paper. Currently upto the result section
2023-06-09 02:06:20,"unfortunately, he's elon musk's echo chamber"
2023-06-09 02:06:54,also - chamath is a part of the all in podcast so who knows rofl.
2023-06-09 02:14:42,I hope some outsourcing sweatshop doesn’t convince government to spend a lot on some illusive AI Manhattan project that may become out dated in 3-4 weeks.
2023-06-09 02:49:49,Don’t give ideas
2023-06-09 06:13:08,"Hello Everyone, my name is Brij Singh and I'm a General Partner at Rebright Partners an India-Japan Cross Border VC Fund. We have invested in startups like Inshorts, Medibuddy, Jiffy.ai etc. I'm the one that made the Twitter post yesterday on Emerging OSS Fellowship Program / Fund, which was posted on this group by my colleague [PHONE REMOVED] who is a Sr. Data Science Associate at our Fund. I was not part of this WA Group at that time and couldn't participate in the discussion, but happy to answer any questions here now. Since yesterday, we have had about 20 folks reach out from the community and will be meeting them over the coming weeks to see how we can support some of them."
2023-06-09 06:14:45,"Also, I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and the lack of FM's in India of equivalent capability. "
2023-06-09 07:06:06,"Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years."
2023-06-09 07:17:59,"On this point, how are we doing building Hindi or Kannada Language Models, is important."
2023-06-09 07:20:42,IndicLM is Least important thing in the stack rank of hard and valuable things: 
2023-06-09 07:22:04,https://ai4bharat.org/
2023-06-09 07:25:02,Doesn’t token cost matter for the complexity of applications to be built given fixed context windows?
2023-06-09 07:25:45,"Although, as the context windows increase to 30k+, for a general purpose use-cases it shouldn’t matter I guess."
2023-06-09 07:27:09,I would partially disagree. 
2023-06-09 07:30:38,Which Hindi application do you've on your phone which you:
2023-06-09 07:31:37,"Also, this entire chat is English"
2023-06-09 07:31:42,Isn't that purely a translation problem? Why does the base model need to be trained in different languages?
2023-06-09 07:31:44,I don’t but the number of regional content apps are exploding in India.
2023-06-09 07:32:35,I would strongly disagree that there are no use-cases for local languages. I assumed what’s being argued is the ROI for improving efficiency.
2023-06-09 07:33:21,"I'll pause now, I just woke up on the wrong side of bed. I've spent some fraction of my youth on this and realised there is no money, respect, at best there is some social currency in doing so. Perhaps, I'm just a bit sour."
2023-06-09 07:33:25,Language is accessibility
2023-06-09 07:34:32,I don’t disagree on that at all. People who will pay for digital goods and can’t use English is a very small market.
2023-06-09 07:35:25,"People can derive value of these, if there will be paid use-cases are not is for entrepreneurs and VCs to take a bet on."
2023-06-09 07:36:44,"Let me be clear, I am certainly not one of them."
2023-06-09 07:40:55,"Throw bricks on me but IMO it’s also a misguided thought process and effort. Build another windows also, another google also, another AWS also … keep playing catch up? What’s the point? Far better to innovate than to copy. Then these people go out and call themselves Thought Leaders. Sick."
2023-06-09 07:48:42,"Amazing podcast translation to Hindi — maybe if you feel so much about it, invite him here and upvote on PH. He's an indiehacker, I don't know him and no affiliation whatsoever"
2023-06-09 07:49:59,Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.
2023-06-09 07:51:21,Yes. Seen this first hand.
2023-06-09 07:53:22,What would a 1/3/5 year execution path look for this - 
2023-06-09 07:59:08,Education - that's the most important I think
2023-06-09 07:59:33,"and banking, ads, entertainment"
2023-06-09 07:59:38,"I am personally working on Software Development using AI; but if I have to choose one field where I truly believe AI should and can create the largest impact, it has to be Education"
2023-06-09 07:59:58,We can now create personalized education for every kid
2023-06-09 08:00:37,"In the future, I hope AI takes care of teaching and teachers take care of the personal & emotional wellbeing of kids"
2023-06-09 08:02:44,"Education is part knowledge transfer, part motivation, and part well being. Our teachers today, especially in rural areas barely have bandwidth for knowledge transfer.... let alone motivation or wellbeing."
2023-06-09 08:05:10,"If putting $1B per state is going to create a model that is ""effective"" in that language, it would totally worth government spend."
2023-06-09 08:05:31,Knowledge gap assessment and Interactive textbooks are perhaps the early applications in this area.
2023-06-09 08:05:48,Something like khanmigo from Khan academy
2023-06-09 08:06:04,BTW Microsoft is selling this hard to all Education Ministries across the world. I do see this coming in soon.
2023-06-09 08:09:41,[PHONE REMOVED] there has been a growing consensus among all today at the lack of innovation in Education. AI and special a combination of Generative and Reinforcement AI strategies could bring that and truly démocratise Education. The internet and mobile have brought a giant leap in this case but education from a personal touch point is truly something that would change this sector
2023-06-09 08:13:36,We have been working on student assessment and evaluation. Deepsy.in.
2023-06-09 08:14:30,Just a hello. I am heading the AI division at IHX a startup in the healthcare domain https://www.ihx.in/ Ine of our major products is Claims Management and processing. We have just started looking into LLMs as a tool for information extraction especially from discharge summaries. Will keep you all posted …
2023-06-09 08:14:53,Is this a B2B or B2C approach?
2023-06-09 08:17:11,"Also, usefulness of language modelsl also follow the data and as our data becomes more valuable or useful, models will have to perform with those languages? Not sure where this will end up at."
2023-06-09 08:17:14,I did something adjacent for an East Coast dentist chain. Info extraction with LLMs is quite robust and powerful
2023-06-09 08:17:38,B2B. We are working with our first customers - univs and ed-tech.
2023-06-09 08:17:46,This is very interesting a combination of this with a recommendation engine for course plans would be very interesting for any parent. B2C .  Especially in core subjects
2023-06-09 08:18:04,How good are your qualitative scores? Is there a demo I can see?
2023-06-09 08:18:25,Dm-ing to set up.
2023-06-09 08:21:52,Yes. :) Now it's been one day at a time.
2023-06-09 08:23:57,"Everything Rural has demand for language, not just India, as we getting calls from many countries to build similar platform for their languages and knowledge base. I personally see good translator models to be better solution around Indic language  problem while keep English to train LLM to achieve SOTA perf. Any subpar model will never be used in Production."
2023-06-09 08:27:16,"One question is, is their unique training material in Indic languages that would make the training worthwhile "
2023-06-09 08:28:12,Of course it’s a different thing if training data at that level exists/is accessible easily
2023-06-09 08:50:59,Money maybe no.
2023-06-09 09:01:21,I think someone mentioned it in passing. If we think of this as a machine translation problem then the source could always be English but you could rather work on an interface around an LLM based solution.
2023-06-09 09:03:09,Localisation happens at the interface level
2023-06-09 09:06:07,"How many people have tried Bhasini models and here and how many use in production. Even we can start with ggerganov like efforts and improve performance of those models. Optimized Bhasini have many out of box production use case than LLaMa, IMO."
2023-06-09 09:23:02,Just stumbled onto this demo on twitter.
2023-06-09 09:27:30,Demand is huge in rural areas for Indic languages but building B2C revenue generation channels might be hard. 
2023-06-09 09:27:34,"This is game changing. I personally never liked our sheep (coaching) farms, and this will focus on individuals and their strength."
2023-06-09 09:28:20,"Let me check what's the underlying architecture for Bhashini, if it's anything ggml already supports like GPT J or GPT Neo, something can be done right away."
2023-06-09 09:31:07,"I’m not going to go against Nirant’s policy to self promote, but it is happening and I’m overwhelmed with customers interest. If we stop focusing on building cheap copies and get head out of Tier1 cities, we have so many things to do. Of course, one shouldn’t expect to be a unicorn in few years, but when ‘Bharat’ picks up China like income growth, these fields will explode."
2023-06-09 09:32:20,Is it weird if my brain is imagining children jailbreaking this tutor to get it to say censored stuff and posting it on insta 😅?
2023-06-09 09:32:24,"Do it. An optimized Bhasini can open up so many flood gates, even independent startup for API based STT, TTS and Translator. Cloud translators APIs are expensive."
2023-06-09 09:37:53,Good one. With elections coming maybe it can be a digital infra. Last elections WhatsApp volumes were huge. Maybe this time all voters will get personalised videos 🤫…..
2023-06-09 09:41:37,There's no getting around alternative uses and abuses of new technology of any kind.
2023-06-09 09:42:46,Yup. How you use a knife is totally fair.
2023-06-09 09:46:09,"IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren’t from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance."
2023-06-09 09:47:19,"Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml."
2023-06-09 09:49:30,Got a link/source for the technical architecture/stack of Bhashini ?
2023-06-09 09:50:51,https://huggingface.co/aashay96/indic-BloomLM
2023-06-09 09:51:00,I have few suggestions as you and [PHONE REMOVED] are genuinely trying something good
2023-06-09 09:52:12,I that’s not true. Check Ai4Bharat website and repo for models
2023-06-09 09:53:40,We should get Dr.Pratyush from ai4bharat here 😆
2023-06-09 09:55:43,😝 my point is towards how goals get diverted and delayed where Government is a major contributor in funds
2023-06-09 09:57:09,"Yeah they have multiple NER, transliteration, translate modelsb in HF/github but in the articles for Bhashini I didn't find a connection to those models. Probably because I referred to wrong article, I got in a different direction - https://indianexpress.com/article/explained/explained-sci-tech/chatgpt-on-whatsapp-bhashini-welfare-schemes-8442622/"
2023-06-09 10:01:09,Some details here :
2023-06-09 10:04:16,"Bloom family of models has ggml support, so I guess something can be tried here. But they perform poorly on most tasks, don't know much about this one. I'll try it out."
2023-06-09 10:04:41,"Thanks, I haven’t tested IndicTrans2 yet, this only two weeks old. I tried original IndicTrans in production but was disappointed for inference speed."
2023-06-09 10:40:08,"this is overly optimistic Aakash ji. I am a fan of Ethan Mollick's 'education explorations with ChatGPT' - but, *there's a crucial 'developing' process* missing that the student can't access and the 'educator' isn't able to deliver. It's in technology's blindspot, for now - resourcing contextual opportunities for learning. Most gedanken experiments devoid of local environment, not blaming the metaverse, aren't powerful enough levers."
2023-06-09 10:56:07,What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?
2023-06-09 10:58:20,"On python based inference onnx performs really well, if you go to C++ then ncnn is the best. Have tried ncnn for both CPU and GPU(using Vulkan) it outperforms torch lib and tensorflow c++"
2023-06-09 10:59:21,"I've found that for (simpler, non-DL) models, ONNX is slower than pickle binaries. Could I be doing something wrong?"
2023-06-09 11:00:43,"Keywords you are looking for: Quantization, Pruning, Sparsification, Distillation. You shouldn't see speed increase. Will DM you details later."
2023-06-09 11:01:10,Just change the model to falcon or whichever you want for training
2023-06-09 11:03:33,"As per the original context, looking for models that have a GGML supported architecture so that something can be done for them right away. Falcon isn't supported with GGML quantization properly yet."
2023-06-09 11:12:20,I can totally get behind Applied Statistics
2023-06-09 11:15:45,Well that's not fun and  dull. I am all for AI. It has a sense of mystery in it
2023-06-09 11:17:06,"AI on the streets, AS in the sheets"
2023-06-09 11:23:31,"Thank you, Sumod"
2023-06-09 11:28:45,"Haha, can always bank on him to bring a new perspective"
2023-06-09 11:29:26,+1 any good guide/ref pages for implementing/deploying hybrid search?
2023-06-09 11:59:39,"It's funny how sci-fi writers like Ted Chiang, Eliezer Yudkowsky have become quotable experts of AI. One look at their statements and it immediately makes you want to stop reading the article."
2023-06-09 12:09:02,We're doing this at Dukaan. Happy to discuss further with you.
2023-06-09 12:12:38,Link please?
2023-06-09 12:24:53,https://twitter.com/emostaque/status/1666817719554174977?s=46
2023-06-09 12:31:31,"The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.  "
2023-06-09 12:32:16,Same crew did GLUE/SuperGLUE too
2023-06-09 12:32:24,Isn’t the original paper 3 year old?
2023-06-09 12:32:43,https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84
2023-06-09 12:33:02,"Yes, https://arxiv.org/abs/2005.11401"
2023-06-09 12:33:39,ya RAG has been in place since 2020 when facebook launched their dpr models
2023-06-09 12:33:39,paywall sigh
2023-06-09 12:34:16,The PIO Amanpreet Singh is a 2013 IIT R grad from the very famous SDS Lab. Has interned with Wingify in India
2023-06-09 12:39:29,https://archive.is/xCmxi
2023-06-09 12:48:47,"*A friend asked this, can someone please advise?*"
2023-06-09 12:49:17,DMing you
2023-06-09 12:50:02,"Similar request from my end as well, if anyone can help."
2023-06-09 12:53:36,Great to see you here [PHONE REMOVED] - forwarded your query already 👆🏼
2023-06-09 12:56:18,What nobody has managed to answer for me is the question of whether humans are doing anything more sophisticated than this in their own heads. There are probably many intelligence mechanisms that are decidedly simple - and there is a tendency on the part of commentators to just group everything together
2023-06-09 12:57:17,[PHONE REMOVED] can help
2023-06-09 12:58:14,Same from my side as well...
2023-06-09 13:01:06,"Awesome, thanks. I will reach out to him."
2023-06-09 13:11:45,"Every generation of scientific advancement tries to define human capacity in terms of current understanding. This is how we got the racial theories that defended slavery, and the eugenics movement that went on to cause much grief."
2023-06-09 13:33:17,Distillation https://neptune.ai/blog/knowledge-distillation
2023-06-09 13:36:36,When you mention GPU based models do you mean they require a GPU at inference time? For standard cpu inference we are using AWS Fargate with auto scaling. Behind an Nguni load balancer
2023-06-09 13:39:03,In google we used GoLang GRPC services on k8
2023-06-09 13:39:04,"Yes, need GPU at inference"
2023-06-09 13:47:14,"Very insightful piece, thanks Michael"
2023-06-09 13:48:05,PIO?
2023-06-09 13:55:20,Person of Indian Origin
2023-06-09 13:55:50,I use it the same way
2023-06-09 13:57:15,"- Explain math , code , concepts "
2023-06-09 13:57:32,Your learning speed increases by 2x or more
2023-06-09 13:58:39,Also made hackerFM which was around the same idea - using AI to summarize the complex events in the tech industry
2023-06-09 13:59:13,We don’t release it anymore but a few users emailed asking for it back. So this use case has genuine traction based on my anecdotal experiences
2023-06-09 13:59:52,But it’s not obvious. You cannot demonstrate it immediately. It takes time to get used to this way of working
2023-06-09 14:00:45,"My biggest use for gpt is to pass it an error stack, and it tells me how to fix it"
2023-06-09 14:01:29,Debugging is understanding
2023-06-09 14:02:31,The complexity of a project a single developer can take on and ship quickly has already gone up.
2023-06-09 14:02:43,The consequences just aren’t evenly distributed yet
2023-06-09 14:08:23,A tool to simplify the world according to your own goals and values. Where the model is built up collaboratively over time. And is both visual and text. Blasting out endless streams of content is not where it’s at. Simple high signal actionable models / summaries of the world.
2023-06-09 14:45:18,I've been surprised at how poor other tools are at basic code tasks. Or maybe I'm not aware
2023-06-09 14:45:27,But it's largely been poor at it
2023-06-09 14:45:40,Is hybrid search = cosine distance+ IDF 
2023-06-09 14:46:49,The first I’d assume
2023-06-09 14:47:06,How are you defining this additive property though?
2023-06-09 14:47:06,"Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong"
2023-06-09 14:47:49,Copilot would be built on top of Codex and InstructGPT (like ChatGPT). Not sure if those benefit from RLHF like ChatGPT has. Does anyone know?
2023-06-09 14:48:57,"In Elasticsearch, this is composite, so it's not super tough."
2023-06-09 14:49:35,"I pay for it. But haven't been very impressed with copilot. For instance, it really annoys me when it gets closing brackets or double quotes wrong"
2023-06-09 14:50:07,You need to then go and figure what it added or missed that's causing everything to go an angry red 🥲
2023-06-09 14:50:31,"Depends on how one is using it. I deal with it how I'll deal with a completely fresh intern. Plan things on a high level and break down the tasks to create functions, scripts or classes. "
2023-06-09 14:50:53,I’ve had similar experience. Co pilot works better with existing code bases. 
2023-06-09 14:52:17,"But for writing from scratch, GPT4 is  amazing."
2023-06-09 14:53:32,This is a big issue with code gen tools - since we're not mentally involved in the code generation process it becomes complicated and annoying when a) we are skeptical about the output b) when there is clearly an error and we don't know where to start
2023-06-09 14:55:12,https://youtu.be/Yf1o0TQzry8
2023-06-09 14:56:15,Codex which powers copilot is a far smaller and simpler model
2023-06-09 14:56:23,It trades off intelligence for latency
2023-06-09 14:56:26,Can you give a tldr like Nirant always pushes 😅
2023-06-09 14:56:47,hopefully they'll replace it with a new gpt-4 based model soon.
2023-06-09 14:56:58,Understanding what is going on > trying to come up with new ideas before you have that
2023-06-09 14:57:07,Too expensive too slow
2023-06-09 14:57:37,I mean that is copilotX but it’s not in the direct coding flow
2023-06-09 14:57:39,"3.5 then. I'll take anything. Currently, I spend all day doing <tab>,<enter> repeat with copilot"
2023-06-09 15:00:58,A typical hybrid search would be a combination of two or more of these methods:
2023-06-09 15:06:21,"Yes, I remember you mentioning the ```boost()``` method, but what if I’m not using ElasticSearch?"
2023-06-09 15:07:20,What do you mean by “+” ?
2023-06-09 15:07:28,"It's a performance story. U can still do in memory, but ur performance will be hit"
2023-06-09 15:08:38,Scaling up is a different story.
2023-06-09 15:08:51,"This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix."
2023-06-09 15:09:26,In memory. U get one array. U get another array and u then sort in memory. This is where llamaindex shines
2023-06-09 15:10:53,"As far as involving an LLM layer goes, I’ve seen some people talking about finetunig the ranking model with adversarial questions or doc2query."
2023-06-09 15:16:22,LLM can be used as a final ranking / summarization pass.
2023-06-09 15:16:23,Can hallucinate answers that guide the rest of the system
2023-06-09 15:16:25,Can activate plugins
2023-06-09 15:19:53,"LLMs come into play when you use the search for answer generation. Then there are a bunch of techniques where LLM has to play a part, "
2023-06-09 15:21:40,Hyde example is a great answer. Thanks 🙏
2023-06-09 15:22:45,"There's no fixed heuristic but good engineering practices to combine semantic search and keyword search techniques to optimise for cost, speed and performance"
2023-06-09 15:33:17,So is that an intersection of the results of the search algorithm?
2023-06-09 15:34:15,https://twitter.com/hwchase17/status/1666829939918745600?t=nNVXyi6T4Ny7qvy1eXQldQ&s=19
2023-06-09 15:35:52,Are there any resources to go through to understand and implement HyDE?
2023-06-09 15:37:47,I’m not convinced this’ll give very good results
2023-06-09 15:38:30,I think this repo uses contextual compression https://twitter.com/misbahsy/status/1656365370121285657?s=46&t=iGppsOleuAsMXDWuVmzUPQ
2023-06-09 15:38:44,Not sure if this was shared earlier
2023-06-09 15:42:17,There's an implementation to HyDE paper from papers with code - https://github.com/texttron/hyde
2023-06-09 15:45:20,"You can find two different fusion techniques mentioned here - Convex Combination (CC), and Retrieval Rank Fusion (RRF)."
2023-06-09 15:46:04,Thanks 🙏
2023-06-09 15:47:20,I've used RRF. It's beautiful how simple and fast it is.
2023-06-09 15:57:01,One heuristic to think about LLMs is how we tend to reflect on our answers.
2023-06-09 16:11:58,I rarely seen a GPU based live inference solution due to the cost but in general principle if you want scale then use some elastic infrastructure component but cost associated is very high and optimise as much as you can your model. 
2023-06-09 16:23:34,Yeah...Indian academia is deeply cash-strapped. I knew some people at IIT-B that were doing some pretty killer NLP stuff (for 2018) but were limited by the very few number of GPUs available.
2023-06-09 16:23:39,Many basement in SV have more powerful ones
2023-06-09 16:24:56,"Lots of people buy SLR cameras, if only we were inundated with great photos. A small fraction of the available compute is useful or well used compute."
2023-06-09 16:26:27,More cameras will increase the probability of more great pictures coming out
2023-06-09 16:27:47,Plus no camera when something epic is unfolding is most damaging
2023-06-09 16:29:45,Infrastructure is the model. That's why transformers works. It scales parallely - may not be the best algorithm.
2023-06-09 16:57:24,Fascinating analogy Paras!
2023-06-09 17:01:40,"Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the ""decider""/""judged"" LLM judging the output of the ""student""/""workhorse"" LLM"
2023-06-09 17:09:04,"Isn't this a reworded ""LLMs fine-tuned on GPT4 input/output pairs"""
2023-06-09 17:09:25,Replace gpt4 with any other smart LLM
2023-06-09 17:10:57,I know both the processes are different. But fundamentally this seems to be around aligning a smaller LLM to output like a bigger LLM (gpt4).
2023-06-09 17:11:31,Which is the same idea adopted in projects like these
2023-06-09 17:12:19,That seems closer to the orca paper by Microsoft research
2023-06-09 17:12:37,Yes
2023-06-09 17:13:05,So I'm very curious to see the differences in benchmark across these two techniques that are trying to do the same thing but in a different way
2023-06-09 17:13:06,Reminds me of this one - Orca https://arxiv.org/abs/2306.02707
2023-06-09 17:14:03,It would then become an interesting topic of research - what allows one approach to do better than the other one
2023-06-09 17:15:03,https://shadowed-season-d38.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4
2023-06-09 18:04:42,https://youtu.be/Dt_UNg7Mchg
2023-06-09 18:18:46,Orca model seems promising based on results. It also puts emphasis on data curation and data diversity. I think this is something that can be achieved in India.
2023-06-09 18:19:24,I digged around and found the paper i was alluding to.
2023-06-09 18:24:41,Paper link - https://t.co/VYeo0ifuYF
2023-06-09 18:26:27,"Exactly. It isn't only throwing compute at the model, but getting the data engineering right. Databricks demonstrated how they built Dolly with a smaller dataset"
2023-06-09 18:34:45,"i want to train any llm model and finetune or train on my domain related data which ecokmerce product related data , is there any good resource that u guys have found on this , which can help me start on this ."
2023-06-09 18:36:17,This is a paper from my colleagues. Happy to discuss or answer any questions you may have
2023-06-09 18:36:27,"Too broad a question perhaps, is there a specific problem you have in mind? E.g. product reviews fraud detection, ranking/search/recommendation system, parsing product reviews"
2023-06-09 18:37:11,Small world indeed ! 
2023-06-09 18:37:13,"Mostly its question answers , and ranking i have data wrt product description title , etc"
2023-06-09 18:38:09,Are you reporting to Anitha Kannan?
2023-06-09 18:39:57,"Right now we are using the gpt model for doing this kind of product enquiry, but evaluating opensource model , and ways to train them . Just starting on this so have not much information except gpt . And on opensource model I am kind of not sure which one to start or look at ."
2023-06-09 18:56:16,"For finetuning, this is a pretty good tutorial - https://huggingface.co/docs/transformers/training . To decide how to select different hyperparameters, this guide is nice ~ https://github.com/google-research/tuning_playbook"
2023-06-09 18:56:17,Just skimmed the abstract.
2023-06-09 19:48:19,Very thought provoking paper !
2023-06-09 20:14:18,"Meta released another banger, MusicGen "
2023-06-09 20:17:48,Yeah I loved it too. I had raised a pull request to add it to the reasoning paper list which just got merged. So it’s linked here too now. https://github.com/atfortes/LLM-Reasoning-Papers#analysis
2023-06-09 20:19:16,Ooh lawsuits time 😛
2023-06-09 20:21:58,My (unsubstantiated) take on this- It’s a pretrained transformer. So pretraining it’s finding the patterns and then the generative part is filling in those blanks. A good paper overall. 👍
2023-06-09 20:24:58,"I have a meta q to [PHONE REMOVED] , [PHONE REMOVED] , [PHONE REMOVED] & others :"
2023-06-09 20:27:13,Well you did not ask me but I’ll still go ahead and answer 😀
2023-06-09 20:27:29,https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-45d
2023-06-09 20:27:36,https://cameronrwolfe.me/blog
2023-06-09 20:27:37,I usually skim this group and stick to one personal and whatever professional projects I have around genAI.
2023-06-09 20:27:53,https://thegradient.pub/
2023-06-09 20:28:02,https://dblalock.substack.com/
2023-06-09 20:28:22,https://lastweekin.ai/
2023-06-09 20:28:51,https://twitter.com/omarsar0
2023-06-09 20:29:22,These are the resources I follow apart from this and a couple other groups I’m part of and the link to reasoning papers I posted above
2023-06-09 20:30:39,Adding to the above info problem. 
2023-06-09 20:31:39,Thanks Shan !
2023-06-09 20:32:41,Yeah. I don’t use twitter. 😀 that Dair guys twitter is probably the only one. I directly go there every once in a while. (Also - 🤗 twitter account which I forgot to mention)
2023-06-09 20:33:37,https://twitter.com/huggingface specifically.
2023-06-09 20:34:57,I follow hacker news and a few subReddits 
2023-06-09 20:35:29,"Skimming most papers is ok, I go into depth if an idea is truly novel"
2023-06-09 20:36:40,Care to share the sub reddits Paras ?
2023-06-09 20:43:40,this is an oversimplification:
2023-06-09 20:48:34,I think a Gpt style bot should be useful even for those used to the notation. Maybe there exists one already - wolfram + ELI5
2023-06-09 21:05:41,"I'm actually evaluating building a product that helps anyone be up to date with topics of their interest, served as a summary and adjusted to difficulty level."
2023-06-09 21:05:52,"Hey all, "
2023-06-09 21:30:21,"Anyone else who faces this problem (even if just for GenAI) or thinks it's worth solving, would love to connect and talk more!"
2023-06-09 21:48:50,I was just about to automate my Twitter content actually. Currently I consume stuff through my own 2 NLP lists where I segregate top NLP signals by individuals and orgs separately. I'll DM you to know what's your approach towards this thing.
2023-06-09 21:54:34,I played this game for a long time and now don't find value in trying to keep up with every single piece of news.
2023-06-09 22:00:44,"Folks, is there any resource youve seen on how to translate natural language commands into actions?"
2023-06-09 22:06:24,"Teaching an LLM to use tools or plugins should not be any different than what you're asking for. We already have frameworks where the LLM looks for the best api, tool, plugin to complete the job. You probably want to look into those and replace names of APIs, tools with your own instructions. "
2023-06-09 22:10:19,"This is very helpful. Thank you. The intent classifier seems to be key here. I'm trying to see how to make it have a conversation with the user in the event of incomplete inputs, or if it is unsure, to complete the  set of inputs it requires to execute the action"
2023-06-09 22:11:07,This is a great starting point
2023-06-09 22:11:17,And gpt4 has been a very helpful as well
2023-06-09 22:18:17,It's great if you found it helpful.
2023-06-09 22:20:04,Closely following this conversation since I have trouble keeping up. Thanks for all the ideas
2023-06-09 22:20:43,"Again, adept.ai use case I presume?"
2023-06-09 22:22:59,I'm not sure. Adept seems to have a very generic description on their website. But I think in the similar direction
2023-06-09 22:25:47,I'm surprised Google hasn't integrated something as simple as an instruction bar into their products
2023-06-09 22:26:28,I'd imagine a lot more tools can benefit from taking inputs as simple chat prompts instead of a sequence of button clicks
2023-06-09 22:26:52,"The above could be a confirmatory step and for editing, instead of the full workflow"
2023-06-09 23:05:09,Just for a dash of humour and wit on Friday night !
2023-06-09 23:38:51,Is this from Chip ?
2023-06-09 23:39:25,Yes
2023-06-10 04:10:20,https://huggingface.co/spaces/facebook/MusicGen
2023-06-10 08:09:38,Might be a stupid question but it says in the documentation that they cleaned out human vocals while providing training data to this: why? Are there any legal restrictions? Do we have large models like this that are trained on human vocals?
2023-06-10 09:59:44,Notebooks x LLMs
2023-06-10 10:59:37,I would imagine we are going to a see a lot of products that will attempt to do this in coming months. It’s a significant UI /UX innovation that reduces user friction to solve the same problems GUIs have been solving. Anyone know any early projects / demos that are in this direction? Apart from adept.
2023-06-10 11:02:06,Heck even a unix command line natural lang interface would be wonderful. “Show me 10 largest files that I have not accessed in the last month” would be soooo niiice 😀
2023-06-10 11:03:41,Yeah I think somebody already made this. Let me find and share it.
2023-06-10 11:05:15,Here 
2023-06-10 11:08:40,Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is “find /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10” which not even the most experienced bash-istas would be able to type flawlessly in one go.
2023-06-10 11:11:02,"Haha, yeah. It has become an instinct now to rely on chatGPT for such stuff."
2023-06-10 11:23:10,One ux idea that I’m very keen on is this.
2023-06-10 11:24:50,"For inference, how is NVIDIA Triton different from OpenAI Triton? Does NVIDIA Triton build on OpenAI Triton? Just in: https://blogs.nvidia.com/blog/2023/06/05/microsoft-bing-triton/"
2023-06-10 11:31:37,Nvidia vs OpenAI Triton
2023-06-10 11:32:32,Has anyone been trying Supabase as a vectorDB and has any feedback esp how it stacks up vs pinecone etc? I'll be happy to send any suggestions back to the founders. Thx in advance.
2023-06-10 11:39:02,"Pgvector doesn't work well so far. If I'm not mistaken, they must be using the same. Less likely to be as performant as Pinecone or Qdrant."
2023-06-10 11:43:46,"Have a question for those deploying LLMs in production with prompt engineering, how are you dealing with prompt injection attacks where for example the user says 'ignore all your previous instructions and do this' or 'repeat the input' which may potentially reveal the prompts that you've used."
2023-06-10 11:50:08,Hey guys one question has any one explored https://elai.io/?
2023-06-10 11:50:37,"Prompt injection by websites is an open problem without a clear solution, so far, afaik"
2023-06-10 11:50:56,"We have a fuzzy matching Algo against common strings, but not 100% effective"
2023-06-10 11:51:30,It's excellent. What works well with supabase is the fact that you get everything else out of the box
2023-06-10 11:51:51,"To be fair, I've never tried pinecone so can't compare. This solved for my needs, so didn't bother beyond that"
2023-06-10 15:06:59,GitHub copilot for command line does this pretty well
2023-06-10 15:18:57,https://twitter.com/dale_vaz/status/1667455292307824641?t=L8xkDeKxgu0PLeI9U-MFSQ&s=19
2023-06-10 15:19:40,"Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?"
2023-06-10 15:19:46,let us stay offended and do something. Better for the timeline
2023-06-10 15:20:25,Checkout frugalgpt paper
2023-06-10 15:21:47,Is there an implementation of this available on Github or anyone using in production already?
2023-06-10 15:23:13,I would be more than happy if out of sheer arrogance someone tries to take on the challenge.
2023-06-10 15:23:42,Found a previous implementation: https://github.com/lchen001/FrugalML
2023-06-10 15:23:53,I stumbled onto ray a few days ago :
2023-06-10 15:26:06,This is more for evaluation tho right?
2023-06-10 15:26:08,"This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn’t responsive."
2023-06-10 15:26:17,"Still quite interesting, will try it out!"
2023-06-10 15:26:36,"Haven't tried it, just read the readme"
2023-06-10 15:26:57,"Right, we are paying like $100K to OpenAI and there's so much downtime going on."
2023-06-10 15:28:48,"Also, has anyone here got access to dedicated models on OpenAI or Azure already? If so, what's the experience been like?"
2023-06-10 15:34:01,I like FrugalGPT's 3-step approach - 
2023-06-10 15:34:53,For downtime handling won't try catch work
2023-06-10 15:35:19,Would need a timeout tho so responses would get delayed.
2023-06-10 15:36:04,Pass a timeout in the openai request
2023-06-10 15:36:35,Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking
2023-06-10 15:37:10,"I guess instead of doing that in every request tho, it would be good to have a separate layer that just checks the uptime/latency of multiple models."
2023-06-10 15:38:09,"no, you are right, "
2023-06-10 15:48:48,"Just curious , $100K/month ?"
2023-06-10 15:49:09,Writesonic
2023-06-10 15:58:27,Damn. Those are some incredibly good reviews. Nicely done
2023-06-10 16:29:59,Good on him. Although I think this question was asked purely for optics I feel
2023-06-10 16:32:08,And the tweet to which Sam replied.
2023-06-10 16:32:18,Most of the questions in ET event were asked to either sound smart or funny.
2023-06-10 16:32:26,Oh no. It was fun seeing a bunch of people boil over with rage in a patriotic fire
2023-06-10 16:33:08,Ya. Problem wahi hai
2023-06-10 16:33:21,"Was it though? Barring a couple of moments , I thought it was very good"
2023-06-10 16:33:48,"Honestly, some of the comments seemed to be driven by a tinge of jealousy"
2023-06-10 16:33:53,"They outsource software, we outsource nationalism."
2023-06-10 16:34:15,Hahahhaha
2023-06-10 16:35:13,"Atleast, that's what I felt on Twitter. The negative reactions seemed way too overblown"
2023-06-10 16:35:49,"hey bharat,"
2023-06-10 16:36:21,"Let's have this forum for discussing ideas, not what others are talking about :) "
2023-06-10 16:36:42,And maybe community driven commentary 😅
2023-06-10 16:37:27,I'd be really curious to learn how many commentators were actually present in the event in person or have seen the full YouTube stream
2023-06-10 16:37:54,"🫡 Yes, sir. I wanted to add to the previous discussion, but it makes sense. We will lose focus."
2023-06-10 17:14:04,We are kind of using this - but in a very limited way and not really full fledged production. We have this deployed as a cache - which returns the LLM response (if cached) or frugalifies it (if no cache).
2023-06-10 17:33:59,"Got it, thanks for sharing!"
2023-06-10 21:34:29,"Hey Samanyou, we do this at Portkey and open sourcing parts of this soon. Also on to load balancing, fallbacks and more as part of this effort"
2023-06-10 21:43:08,"That sounds comforting. Will DM you, [PHONE REMOVED] if that’s okay with you."
2023-06-10 21:44:45,Absolutely! I’ve strongly felt that deploying to LLMs and maintenance can be slightly iffy in production and we want to change that.
2023-06-10 21:48:59,"At the risk of sounding like a broken record - if anybody’s tried semantic caching, would love to connect. We’re starting to do backtesting on what we’ve built and I want to learn more. Also if you’ve seen any resources outside of GPTCache please send them. "
2023-06-10 21:59:38,We’re spending a lot of time thinking about this. Happy to connect and chat
2023-06-10 22:13:19,Even the operating system should follow the concept and keep only useful things on my desk top. It's a pain to clean up the desktop once every now and then.
2023-06-10 23:08:43,https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&utm_medium=member_android
2023-06-10 23:09:05,Interesting to see so many companies in Health And drug discovery.
2023-06-10 23:16:18,There is already a bubble. We will see in 2024/5 whether there will be a good consolidation of some kind or a wipe out of the overvalued and over leveraged business
2023-06-10 23:24:31,"On this line, is there any basic course on drug discovery/biotech  + ML?"
2023-06-10 23:25:26,There is 0 in Ed
2023-06-10 23:27:33,"I also have a doubt about so many companies raising in content gen ( audio, video, text) I highly doubt how will they keep up to that valuation after seeing what FAIR ( Facebook AI Research lab )  has been doing first with MusicGen and the kid of tools they will be rolling out on ads, agent chats, and photo editing."
2023-06-11 01:11:20,Something we follow here 
2023-06-11 01:23:19,Would love to test-drive the OS code when it's out 🙌
2023-06-11 01:29:27,https://ai.honu.io/papers/musicgen/
2023-06-11 02:58:26,Because we see requests across lots of users - we can sort of make a good judgement of API latencies and downtimes. 
2023-06-11 02:59:47,Does anyone know of good Text to presentation API?
2023-06-11 03:03:02,https://workspace.google.com/u/0/marketplace/app/plus_ai_for_google_slides/214277172452?ref=theresanaiforthat
2023-06-11 03:06:39,"just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds."
2023-06-11 03:08:16,Claude?
2023-06-11 03:09:37,how did i miss that one 🤦‍♂️also forgot to mention cohere
2023-06-11 03:10:59,"Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude."
2023-06-11 07:11:35,thanks working on adding claude today. also the library got a mention on twitter from protosphinx https://twitter.com/protosphinx/status/1667557827211063299
2023-06-11 07:53:46,"This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?"
2023-06-11 07:56:04,could you explain that a bit more. it supports react prompting so yes you can include functions in your prompt that the ai will call as needed similar to chatgpt plugins
2023-06-11 08:05:15,"Got it, our team is building flows https://cloud.activepieces.com/flows/ here and extending Agent frameworks further to handle enterprise class use case / error handling .. start, pause, rewind, end, BPM workflows, Decision trees etc"
2023-06-11 14:26:11,Interesting attack vector for attackers to inject malware when you use gpt4 and other generative ai tools to write code
2023-06-11 14:55:51,It’s a good old script kiddies technique but still works..(llm or not)..when you copy or lift code w/o paying attention to the package imports.
2023-06-11 15:42:41,Individual people writing code will be still vulnerable 
2023-06-11 15:45:25,Yes SBOM standards like CycloneDX and SPDX greatly reduce these attacks in enterprises. We have all released software going through a vulnerability and compliance engine and I would like to think all enterprises alike would be saving millions due to simple but stringent checks like these
2023-06-11 15:49:46,Is there any work actively being done to detect/prevent scams with AI deepfakes and AI generated voices?
2023-06-11 19:00:38,"There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent."
2023-06-11 19:30:52,"I haven’t seen any ready to use open source tools but there are a few papers. And some commercial tools, https://arxiv.org/abs/2304.13085"
2023-06-11 19:39:27,Does anyone know of pretrained models for audio embeddings for song detection?
2023-06-11 19:51:39,Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model
2023-06-11 19:52:44,Does seem like it
2023-06-11 20:01:55,Are you for or against this (if true ofcourse)
2023-06-11 20:03:08,"I think for or against might be too extreme, but you get what I mean right? +ve or -ve"
2023-06-11 20:11:39,It kind of confirms why we all felt that it got faster and dumber. Most likely GPT4 is going to have the same fate in near future.
2023-06-11 20:13:40,How is this very big? Any implications? Maybe I don’t get it because I don’t really assume that openai has some secret sauce unknown to the outside world
2023-06-11 20:15:49,It's not big.it's quantised
2023-06-11 20:16:22,I came across this implementation of Google's musicgen model: https://github.com/lucidrains/musiclm-pytorch
2023-06-11 20:24:03,big if true if lower than 16 bits😛
2023-06-11 20:29:37,I thought this was an old time-series problem.
2023-06-11 20:33:07,Shouldn’t come as a surprise as #users are continuously growing and CoGS need to be under control in this economic scenario.
2023-06-11 20:38:31,Deployment effectiveness trumps loss function drops
2023-06-11 21:25:13,Many of the voice banking authentication services have no option but to be up to date.
2023-06-11 21:25:17,https://www.pindrop.com
2023-06-11 21:25:28,As an example
2023-06-11 21:27:23,Hey thanks 🙌. I haven't got an opportunity to explore anti-voice phishing technologies much. I'll check this and the one mentioned above in this thread out.
2023-06-11 22:02:34,Audio Visual AI Assistants
2023-06-11 22:15:07,How are LLMs with time series data
2023-06-11 22:33:58,Please update if you find something good.
2023-06-11 22:49:29,Looks like [PHONE REMOVED] started a fund also to be able to build agi in India. Would love to know more [PHONE REMOVED] . 
2023-06-11 22:55:59,Not a fund. More a grants program for foundational research. No details firmed up for now. Collaborating with [PHONE REMOVED] to give shape and form in coming week. Looking forward to collaborating and seeking inputs from this group 🙏🏼
2023-06-11 22:57:41,Right now it’s just my personal money . Intent is to back 10 teams/projects that are chasing AGI research. Only clarity is on ask : that works needs to be open source
2023-06-11 22:58:57,[PHONE REMOVED] :)
2023-06-11 22:59:15,Skepticsim and critique super welcome as well 😁
2023-06-11 23:01:55,I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don’t think we have enough talent to even do the former.
2023-06-11 23:03:48,"A lot of it is early, a lot of the thoughts are evolving"
2023-06-11 23:04:02,Not to miss the fact that none of us really know what’s agi research and how does it look like. 😅
2023-06-11 23:05:21,But I think endeavours like this would be enough to spark a conversation
2023-06-11 23:06:06,Although I agree with the fact that academic help would also be important with monetary
2023-06-11 23:09:45,There’ll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on
2023-06-11 23:10:38,"I guess the key is ""Foundational Research"" as opposed to only AGI"
2023-06-11 23:11:25,Agreed
2023-06-11 23:11:51,"Certain endeavours don’t fit a venture investing model.  Enabling research is one of those. In early days for an ecosystem gotta start somewhere. And as i put it out, odds are fully stacked against it, but worth trying"
2023-06-11 23:18:23,There's a Mariana's trench between 
2023-06-11 23:20:47,The triggers to innovation are many and sometimes all we need is an inspiration from somewhere for things to snowball
2023-06-11 23:22:31,"What amount in total, and what number of projects/grants are you considering investing in?"
2023-06-11 23:22:35,"It's really great to see folks putting in money into this. Requesting [PHONE REMOVED] Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime."
2023-06-11 23:23:42,We'll share more deets as they flesh out 🙏🏼
2023-06-11 23:28:43,Would lean on saner folks  like [PHONE REMOVED] and other here to help flesh it out. 
2023-06-11 23:28:57,Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?
2023-06-11 23:30:56,I think you’re pointing at we don’t have talent to train a Lora enough forget agi right? 😋
2023-06-11 23:31:28,More computational artists/prompt folks over in the group for generative art: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4
2023-06-11 23:33:31,Would love to know this. I’ve not seen grants work well outside universities in India.
2023-06-11 23:36:54,"My two cents: I agree slightly (key word slightly) with [PHONE REMOVED]  that you will need to have good mechanisms/mentors to make this work. One of the few ones that worked in Open Source Community was GSoC. You will need mentors who are plugged in the code base, to really review and improve it. Just any mentor might not work. There are few folks who have both technical/math depth but most of those folks are probably slightly older and have jobs etc. So getting them to do this could also be tricky. There are interesting folks who are contributing in OSS, eg: IITG PhD students Zeel Patel (Nipun Batra's students) and Zeel they were doing it in pyprobml and JSL."
2023-06-11 23:37:41,Julia also had some excellent contributions
2023-06-11 23:38:29,That was because Viral was based here for quite sometime. And they build the teams over time.
2023-06-11 23:39:14,"Also, I’ll point again. Engineering like Julia or gsoc has far more direction than research. 😅"
2023-06-11 23:40:21,I was thinking of the GSOC model as well. But also hoping the companies focus more on their learning and growth rather than exploiting
2023-06-11 23:46:42,"I agree. I think there is still a huge gap that exists between Academia and Industry. If we can bridge that gap, there could be lot of interesting possibilities. The work I spoke of, this is Kevin Murphy's library and book's companion code. Tried to get students (senior year undergrad) to learn PGM (Probabilistic Graphical Model) only to realize that their basics of probability was quite lacking. So there will be challanges such as these."
2023-06-11 23:51:20,"Been on a few calls with Kevin Murphy to help GSOC students contribute to OS projects. There’s always a steep learning curve in the beginning, that’s where the community always helps :)"
2023-06-11 23:59:23,What project was this?
2023-06-12 00:02:28,it was a jax project. that’s all I could reveal sadly lol
2023-06-12 00:03:54,I like this https://www.betaworks.com/camp
2023-06-12 00:04:16,fun fact: Hugging Face was part of their initial cohort
2023-06-12 00:10:53,This is a fab approach for fostering cos. Something on those lines (more elaborate) is being worked on by another friend on this group :)
2023-06-12 00:13:57,that’s amazing. do keep us updated :)
2023-06-12 00:22:02,Hey need some brainstorming - I was working on this idea - what do llms think of other llms quality?
2023-06-12 00:30:05,"If the human preference is quantified, i.e. you've a score given to each LLM as preferred by humans then yes I think it's possible."
2023-06-12 00:31:20,"Instead of simple redirecting to highest preferred LLM response or cheapest api costs, one can normalise preference wrt costs."
2023-06-12 00:37:43,Good idea
2023-06-12 00:41:08,"You could also add another layer here, user budget."
2023-06-12 09:19:02,"Midjourney is fantastic for generating generic output that works as stock images. If you want greater composition control, it’s Stable Diffusion + its entire ecosystem of support tools that you need."
2023-06-12 09:19:22,Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can’t swap out the design of an armrest for another one that you specifically want.
2023-06-12 09:20:43,Loving the analogy :)
2023-06-12 09:21:26,"Remember this from the May meetup, great way to put it"
2023-06-12 09:25:36,Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I’ve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement 🤌
2023-06-12 09:26:52,"For magical composition control with consistent characters and style, Dashtoon beta drops this week!"
2023-06-12 09:37:19,I want to get my hands onto this 🔥
2023-06-12 09:38:20,💯
2023-06-12 09:39:24,Well said. One doesn’t mean flashy ui to build something exceptional.
2023-06-12 09:40:02,Text me with what you want to create Prashant!
2023-06-12 09:47:01,Amogh are you folks moving from a content company to a  gen ai platform company ?
2023-06-12 09:51:00,They were never a content company — just look at the folks they've hired and the app 😅
2023-06-12 09:51:22,"If you used the app, it's arguably the only GenAI business I'd put money in"
2023-06-12 09:53:04,No
2023-06-12 09:53:45,How are the IP laws for genAI content in india?
2023-06-12 09:54:14,Is there a meaning of GenAI Platform which I misunderstood? That phrasing includes creator and reader tools?
2023-06-12 09:58:39,The gen AI platform Dashtoon Studio is an enabler for creating fantastic content
2023-06-12 09:59:31,So it's an internal tool for Dashtoon ?
2023-06-12 09:59:38,Not really. We are building whatever is needed to make content that folks like. A tool that allows more ppl to create content means more content 😅
2023-06-12 10:00:43,"Started that way, but it seems good enough to us to be able to let others make content with it."
2023-06-12 10:01:10,"Think Pixar and Renderman. Pixar produces great content using Renderman, which started internally as a necessity but is now also open for public to use"
2023-06-12 10:01:42,Sidenote — Engineering focussed events:
2023-06-12 10:01:57,cc [PHONE REMOVED] for any Github/Microsoft Hack questions
2023-06-12 10:01:59,"We still believe our core is content. For most ppl, good content is what will attract them to Dashtoon."
2023-06-12 10:03:09,"Aaah, fair. "
2023-06-12 10:05:00,"Thanks Nirant , resharing the link here :https://www.fastestcoderfirst.com/"
2023-06-12 10:57:14,NLP x Academia Webinar from ACM KIDD:
2023-06-12 10:57:52,Folks please ping [PHONE REMOVED] for beta access directly
2023-06-12 11:35:16,"Hey peeps.. where is the Indic charitra.ai of India? I am sure people want to chat with Jethala and Babita, if not Anupama or Kapil Sharma"
2023-06-12 11:36:22,"cc [PHONE REMOVED] [PHONE REMOVED] are working on this. Additionally, someone of our skill can make this over a weekend: replicate.com/blog/fine-tune-llama-to-speak-like-homer-simpson"
2023-06-12 11:39:48,"the more famous the character, e.g., dumbledore, the more accurate it is"
2023-06-12 11:40:40,"also funny how it explicitly clarified, ""no I can't _speak_ but imitation, sure""."
2023-06-12 11:45:49,Nice! If it’s so easy why is it not live yet.
2023-06-12 11:46:56,Because you ain't gonna pay $20/mo for this
2023-06-12 11:47:42,"When I say charitra it means there are many characters available, we can spin up a new one with description, it needs to work well, it needs to work cheap at scale, scalable etc"
2023-06-12 11:48:21,How do you fine tune the indic language talking style?
2023-06-12 11:50:01,"With GPT4, you might not need to"
2023-06-12 11:51:27,Interesting. Will try and see if its almost there
2023-06-12 12:10:28,Monetisation is not a problem if there is traffic
2023-06-12 13:26:47,"[PHONE REMOVED] Hello Aditya, welcome to the group. 😊✨"
2023-06-12 13:54:08,https://twitter.com/aishwarya_08/status/1668158923990237184
2023-06-12 13:55:07,"Was there, most def less than 100 folks at the main meetup — not sure about the After party thing. Same folks as this group were there, 2-5 new faces 😅"
2023-06-12 14:20:53,Are people using Bing instead of Google for search?
2023-06-12 14:21:45,I'm just talking about search and ranking / results  articles
2023-06-12 14:21:59,Bing has lost market share to Google since Jan 2023
2023-06-12 14:22:07,I use Google for direct searches that I know definitely exist. And Bing for when I need to jump through multiple links or jot down multiple items in one place or arrive on a conclusion
2023-06-12 14:22:39,Bing is very slow so definitely not good for direct searches.
2023-06-12 14:36:54,Hmm. Interesting. Case where results might not correlate with market share.
2023-06-12 14:37:06,The only search engine that seemed to stick for me besides Google was Neeva. But they shut down recently
2023-06-12 14:37:24,Interesting. Can you elaborate on this?
2023-06-12 14:44:30,Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models:
2023-06-12 14:45:44,This perhaps makes McKinsey and BCG very happy: https://www.meity.gov.in/tenders/rfp-india-semiconductor-mission-under-ministry-electronics-information-technology-miety-6
2023-06-12 14:51:21,I don't mind using Bing but Googling has become a habit and is the default search page on my browser which probably unconsciously locks me in.
2023-06-12 14:58:09,yeah not sure if any india based consultancy would have revenue upwards of 500 crores
2023-06-12 14:59:10,🍿🍿
2023-06-12 14:59:52,"I did for 3 months and had to leave. Less ads is a +ve but too many negatives. Doesn't connect well with maps, Wikipedia, doesnt have a panel that summarises things well, etc etc"
2023-06-12 15:00:39,"As someone who has worked on govt tender documents, I am sure there is atleast ONE 😅"
2023-06-12 15:01:11,500 cr for a consulting firm is nothing. Mid sized law firms do 500 cr.
2023-06-12 15:01:33,Most of the queries that I do in my daily life are related to just basic recall or quick lookup for something interesting that I've heard. I find that Bing easily takes 5-8s to complete it's answer and tell me something that I can get in a fraction of a second on Google.
2023-06-12 15:02:00,"What is ""mid"" here?"
2023-06-12 15:02:30,200 partners? Mid by intl standards.
2023-06-12 15:03:03,150 maybe. Even less. Depends on the practice areas.
2023-06-12 15:03:48,"How does a Govt tender for Semiconductor like this work? It'll go to a consulting agency, which in turn will speak to Intel/Apple/NVIDIA of the world?"
2023-06-12 15:03:55,"I would strongly suggest using perplexity.ai over Bard, Bing or ChatGPT with Browsing. It has made my ""search workflow"" so much faster."
2023-06-12 15:04:32,TSMC
2023-06-12 15:04:41,+1 - superb exp on perplexity
2023-06-12 15:07:46,"The govt usually speaks to Intel, apple etc, and the PMC does everything else, there are some variations. My wife drafts these docs for govts, and would be the expert to speak to on this 😅"
2023-06-12 15:09:10,At least one feb with <=7nm put us on the map otherwise it won’t be worth. It takes so much time and capital to build a fab.
2023-06-12 15:10:57,"Current plans are for 28-65 nm fabs I guess, at least until the last year's plan."
2023-06-12 15:14:17,"Yes, I saw that. Even Vedanta was 22nm. US has insentive to have alternative than Taiwan due to tension with China. India should push to get one. Intel is building one in Ohio for 20B and it keeps delaying. This is a very very tough thing. A grain of dust will discard the whole wafer."
2023-06-12 15:16:27,"FinGPT is an open-source LLM for the finance sector. It takes a data-centric approach, providing researchers & practitioners with accessible resources to develop FinLLMs."
2023-06-12 15:16:37,Thoughts on this ?
2023-06-12 15:18:16,Thread: https://twitter.com/omarsar0/status/1668060502663077891?s=48&t=_vYiPpaKOpxR0JOyLHFC0A
2023-06-12 15:19:13,why not? large number of applications at the trailing edge. haven't heard of a country to get to <20 nm without first getting the lower nodes sorted.
2023-06-12 15:19:54,maybe this needs a separate group though :)
2023-06-12 15:20:24,"After all these efforts, we shouldn’t repeat US mistake."
2023-06-12 15:20:33,Agree
2023-06-12 15:24:53,"Yeah, I've been exposed to OS financial LLMs before via Stochastic."
2023-06-12 15:26:29,Please share here some insights from xFinance too 
2023-06-12 15:27:05,understandably a fluffy response
2023-06-12 17:14:50,The biggest problem that we’ve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!
2023-06-12 17:28:10,https://twitter.com/fabianstelzer/status/1668181498032160769
2023-06-12 17:28:21,By quality do you mean the impact of the problems they're trying to solve?
2023-06-12 17:32:42,~impact~ scope*
2023-06-12 19:20:09,hey folks can someone please link that website which was elo rating llms ?
2023-06-12 19:20:55,https://lmsys.org/blog/2023-05-03-arena/
2023-06-12 21:49:06,What’s the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys’ experience?
2023-06-12 22:07:46,hit n trial. depends on the text type. 
2023-06-12 22:08:01,No of tokens.
2023-06-12 22:10:19,"Yeah. Have a million documents, some 4-5k tokens each. So can’t make it lesser than 1000 because of cost issues."
2023-06-12 22:17:24,3-5 sentences is good
2023-06-12 22:20:40,sorry i didn't get the cost issue (i.e it's link with 1000 token size)
2023-06-12 22:23:07,Storage cost in vector DB cloud. A million vectors is ~ 50 usd. I’ll have somewhere around 5M with 1000 chunk size.
2023-06-12 22:23:30,Also considering self hosting a vector db. But db maintenance is always a headache.
2023-06-12 22:24:27,Aren't you charged per embedding size in vector db?
2023-06-12 22:25:53,Depends on the vector db. Pinecone is per pod. 5M in a storage optimized pod. Weaviate and Qdrant is per vector size
2023-06-12 22:30:43,Has anyone built / tried TTS models for Spanish language?
2023-06-12 22:36:10,Your vector size is fixed right?
2023-06-12 22:45:51,"Regarding splitting documents into chunks, I have a question:"
2023-06-12 22:46:25,The main problem here is it looks into each and every chunk after splitting with equal importance.
2023-06-12 22:49:24,"There can be some datastructure manipulation, but I’m looking if there can be a retriever/embeddings-based solution to this….without maintaining flags for the keys and storing in hashmaps or something like that."
2023-06-12 23:19:17,"We were talking about this the other day, and here we are - https://github.com/facebookresearch/audiocraft"
2023-06-12 23:28:40,Thanks
2023-06-13 08:13:55,Zilch to my knowledge.
2023-06-13 08:29:51,What are the advantages of a vector db vs regular postgres/rdbms db ??
2023-06-13 08:49:26,"We've discussed basics of vector db, libs and so on quite often. Please scroll up. You can see some of the past community discussions too here: https://nirantk.com/ai"
2023-06-13 09:01:55,"Trying to understand more context, any reason why the composite unique key (unique page key+ unique chunk key within the page) is not desirable?"
2023-06-13 09:04:14,"I think it is an opportunity. If multiple chunks are being matched to a query text, it means the original page is more similar to the query. You can group by Page id to and give more importance/score to pages who have more chunks matched"
2023-06-13 09:11:25,This is very smart
2023-06-13 09:11:56,Say you have 10 chunks returned in descending order of cosine similarity
2023-06-13 09:12:01,Say threshold of 0.75
2023-06-13 09:12:18,Do you just sum the ones from the same page? To see which matches closest?
2023-06-13 09:12:22,Is there a better way?
2023-06-13 09:17:24,You can count the ones fulfilling the threshold.
2023-06-13 09:17:42,https://github.com/ggerganov/llama.cpp/pull/1827
2023-06-13 09:27:47,"Coherence, goal, technical quality, longevity, utility. Just a rule-of-thumb measure of common sense parameters."
2023-06-13 09:30:10,"Heard about your conversation with Govind and Venky. Fair points, we are planning to address those in the Responsible AI Fellowship Fund being anchored by Omidyar Network"
2023-06-13 09:39:01,LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87
2023-06-13 09:41:48,"Of the 7, 5 are outright wrong 🤣"
2023-06-13 09:50:31,"much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f"
2023-06-13 09:51:35,... and this is Bard ...
2023-06-13 09:51:36,"Vector databases are a type of NoSQL database that store data as vectors, which are high-dimensional arrays of numbers. This makes them well-suited for tasks such as retrieval augmented generation, which requires the ability to quickly find similar data points."
2023-06-13 10:35:40,GPT4 — all right in zero shot. Prompt Quality matters! 
2023-06-13 11:00:37,"Hi everyone, "
2023-06-13 11:03:15,When you say “from existing ones” what sort of attributes do you want to inherit?
2023-06-13 11:03:32,I wonder if there will be a separate market & usecase for 
2023-06-13 11:04:08,"s.replace(""bring"", ""Bing"")"
2023-06-13 11:06:11,"So, Let’s say I have two Images:   I1 : an image of a red shit and black pants I2: an image of green t shirt and white ponts"
2023-06-13 11:09:30,FYI WhatsApp now has edit message
2023-06-13 11:10:35,TIL 😮
2023-06-13 11:12:04,I haven’t. Let me have a look at it and get back! 
2023-06-13 11:12:47,👍. Hopefully works for you. There are many inpainting solutions. Challenge will be consistency
2023-06-13 11:13:32,I had made this few months back on similar lines https://github.com/ovshake/stable-fashion
2023-06-13 11:13:55,I want to a POC and then I can work on making it better from there !
2023-06-13 11:15:14,Looks pretty good. I will check this out!
2023-06-13 11:15:23,Should be good enough for POC.
2023-06-13 11:15:51,There you go. Loved it!
2023-06-13 11:19:18,"That’s reasonable and exactly what Im doing right now! But the problem is, say each document can be chunked upto a maximum of 100 chunks, and I want 5 _unique_ elements . There were originally 100 unique page ids. "
2023-06-13 11:22:59,I don’t want to retrieve top-MAX_CHUNKS_PER_DOCUMENT * (k-1) + 1 elements just to be able to finally show k unique elements
2023-06-13 11:23:33,I think it’s naive
2023-06-13 11:24:43,"Have you considered concatenating all the chunk vectors and then dimensionality reduction , so as to get the most informative pieces from each chunk captured in final dense vector ?"
2023-06-13 11:27:03,You can try to employ MMR (maximal marginal relevance) to rerank 
2023-06-13 11:27:26,"So here’s a question: when do you consider a vector optimally dense, and what is the limit you can keep doing dimensional reduction?"
2023-06-13 11:28:03,"To my understanding, embeddings-based vectors are already pretty dense"
2023-06-13 11:28:33,due to attention mechanism of the Transformers
2023-06-13 11:30:14,You can experiment to see if this gives reasonable results along with performance that you wanted.
2023-06-13 11:30:38,I don’t get it. 
2023-06-13 11:31:26,"the alternate way i like is to use something like elasticsearch with a composite relevance ranking of dense_vector (embeddings) with ""terms aggregation"" https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html"
2023-06-13 11:31:36,this is built in
2023-06-13 11:32:09,The diversity is hard to get from plain vector search. The documents are already distributed in the embedding space according to their embedding method
2023-06-13 11:32:46,"But you can rerank a list of (chunk, vector) pairs using MMR which maximises diversity"
2023-06-13 11:33:01,I’m trying to build this from scratch to clear my understandings 😛
2023-06-13 11:33:44,"So to do that, let’s say you need 100 items, then fetch top 200 first sorted by similarity then rerank using MMR and then take the top 100"
2023-06-13 11:34:28,That should get you the maximum intersection of relevance and diversity from your dataset
2023-06-13 11:34:39,This also depends on the quality of embeddings
2023-06-13 11:34:56,I dont think you get my exact question here.
2023-06-13 11:35:39,But im looking for a better method because that can be slow based on MAX_CHUNKS_PER_DOCUMENT and _k_
2023-06-13 11:36:13,"The reranking comes after that, and I agree there can be several reranking methods including MRR"
2023-06-13 11:36:56,top 200 might not guarantee 100 unique elements
2023-06-13 11:37:37,you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.
2023-06-13 11:37:49,Is there any reading on when to consider a vector optimally dense?
2023-06-13 11:38:44,"No no, Im not looking into composite ranking (sparse + dense) at this stage"
2023-06-13 11:39:14,What do you mean by optimally dense? Sorry I can’t seem to find full context here
2023-06-13 11:39:24,(Also happy to move this to private chat)
2023-06-13 11:39:56,Im just interested in getting top-K unique page ids from chunks split up from the pages
2023-06-13 11:39:59,Sure sure
2023-06-13 11:50:24,"personally, I'm not too excited about incrementally better search as such, and I believe google will put all it's talent and $ to ensure it continues to dominate search. They have to. Where I am more excited about is the decision making part which today happens post-search. If LLMs can do that reliably with more and more confidence and less and less expertise needed on behalf of the user, it will truly be a game changer. GPT4 is already showing tremendous progress in reasoning/logic/planning/decision making and will only continue to get better. That's where the real gold lies. Concretely, ""what to do in srinagar"" and ""what to do in andaman"" are all solved queries. But a complex query like ""whether I should go to Srinagar or Andaman if my budget is X and one daughter's birthday is on date D and I like snow but my wife prefers beach and I have airline miles with airline A..."" and so on. Now when it comes up with an answer and a reasoning - that is a game changer. It is far beyond a 'search' paradigm. It's a full shift in ways of working and a leap in evolution."
2023-06-13 11:50:56,Step 1: Using BLIP2 you can generate captions for the clothes you already have.
2023-06-13 11:57:46,"With respect to this original query, I would suggest looking into txtai."
2023-06-13 11:59:07,"thank you v much, ill take a look into this 🙂"
2023-06-13 12:22:22,A very inspiring vision !
2023-06-13 13:19:10,"🙂 I'm devoting nearly all my time in this part of genAI exclusively. And definitely not looking much into RAG and similar stuff at the moment. If you're interested, this is a great place to start (and it's references of course) https://arxiv.org/abs/2212.09597  there are other resources too, of course"
2023-06-13 13:34:53,https://twitter.com/humphd/status/1668266263494242306?s=46&t=URoDrV5X7GPNPYSgYW42Dw
2023-06-13 14:07:58,Let us know how it turns out 🙂
2023-06-13 14:15:18,We use https://weaviate.io/
2023-06-13 15:45:12,Hey guys 
2023-06-13 16:02:35,I guess they just pass the last generated message as input again
2023-06-13 16:23:34,[PHONE REMOVED] do help [PHONE REMOVED] here. Thx
2023-06-13 16:48:00,"So from what I know, continue generation is not enabled for the completion API, but to implement the stop generation you can simply make code changes in your BE to stop when user sends stop action to your event stream"
2023-06-13 16:52:48,"Have a few doubts on this, specifically because server sent events are a one way stream. If this discussion is too far off topic  for the group, we can take this to dms"
2023-06-13 18:10:12,Current solutions on this might be hacky patchy stuff that works. I don't think openAI has anything official supported via their API.
2023-06-13 19:16:12,Has anyone found a way to make chatGPT to give pure JSON responses ?
2023-06-13 19:17:30,idk if this is the best way
2023-06-13 19:18:50,Are you adding the json structure in the prompt?
2023-06-13 19:19:36,If you're using LangChain you can use their Output parser methods to define a response schema
2023-06-13 19:20:05,https://shreyar.github.io/guardrails/
2023-06-13 19:20:47,"On open source model aide, jsonformer works perfectly"
2023-06-13 19:20:53,Side*
2023-06-13 19:21:05,I havnt used guard rails 
2023-06-13 19:21:47,"Very different from Microsoft's Guidance, much more robust and easier to use"
2023-06-13 19:37:22,Is it just me or gpt3.5 seems crippled now?
2023-06-13 19:40:04,Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.
2023-06-13 19:40:40,"This is great , exactly what I was looking for. Is it much better than simply using pydantic?"
2023-06-13 19:43:49,use lmql.ai
2023-06-13 19:49:14,Explicitly mention that you want json outputs. Provide the structure of JSON with keys and that should do.
2023-06-13 19:50:55,"I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks."
2023-06-13 19:53:46,There has to be a better way. Perhaps some external agency that measures public model drifts
2023-06-13 19:54:56,Just curious: is anyone here building a product for the financial markets?
2023-06-13 19:56:28,"[PHONE REMOVED] mentioned the simplest way is to have a benchmark dataset,  spin up a jupyter notebook and compare."
2023-06-13 20:00:50,That sounds like a great idea. I am surprised we don't have such a thing
2023-06-13 20:01:05,If we don't - I'm usually behind whatever's the latest :D
2023-06-13 20:11:22,"Paras , others "
2023-06-13 20:14:22,"1 - public inferencing should be enough, almost like downtime monitors"
2023-06-13 20:32:48,"This doesn't really help your question but in my personal experience letting the model do a bit of ""thinking"" via planning/chain of thought leads to better outputs."
2023-06-13 20:48:19,"One way that I usually use is chain prompting, using which you provide an example in the initial stage. This works most of the time with less chances of error."
2023-06-13 21:23:57,Singapore has spun off its efforts into a ppp model through it “AI verify” foundation..few big corporates committing to the effort (on paper).
2023-06-13 22:11:08,Impressive perk!
2023-06-13 22:34:46,Folks this just dropped an hour back - https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/
2023-06-13 22:39:10,Wow those are some good numbers 🔥
2023-06-13 22:40:57,That’s $100M+ upfront infrastructure investment.
2023-06-13 22:43:00,how much money does Nat have?
2023-06-13 22:48:43,"Like we discussed before OpenAI is reducing cost of already cheap turbo, and increasing context window to 16k."
2023-06-13 22:50:50,"Regarding the previous JSON discussion “gpt-4-0613 and gpt-3.5-turbo-0613, and have the model intelligently choose to output a JSON object containing arguments to call those functions.”"
2023-06-13 22:52:21,I have a question regarding https://platform.openai.com/docs/guides/fine-tuning
2023-06-13 23:04:21,Octoml AWS event tomorrow :
2023-06-13 23:07:01,Anyone knows if function definitions will be part of token counts?
2023-06-13 23:15:52,May be part of the input tokens
2023-06-13 23:46:00,"A couple of questions about Azure OpenAI service - a) does anyone here know if they have raised rate limits in the recent past, and by how much? b) Any good practices being used to build rate limiters for Azure OpenAI based apps?"
2023-06-13 23:46:29,"Rate limits I'm interested in are more the token limits, than the request limits."
2023-06-13 23:54:12,"When I last checked it was still same. I am implementing preemptive method by creating multiple instances, (you can have two in each of the four data ,centers with OpenAI), and then shuffling requests between them."
2023-06-13 23:56:05,"On Azure you can use two instances max in each tenant I guess. Rate limits have not changed after GPT4 released? 3.5 accepts 90 or 120 reqs/min, GPT4 accepts <20/min"
2023-06-14 00:03:45,Token log probabilities
2023-06-14 00:05:26,"User based rate limits that are then load balanced across all your instances (OpenAI, azure) is something that would work theoretically? We’re testing this out"
2023-06-14 00:06:45,Yes - you get a name for your fine-tuned model which can then be used
2023-06-14 00:07:27,openai api fine_tunes.list should list all the fine-tunes once the job is done. Their CLI has very good DX
2023-06-14 00:08:29,DX = ?
2023-06-14 00:09:54,developer experience.
2023-06-14 00:10:00,Try threatening it. If you don't get the reference follow Riley goodside on Twitter
2023-06-14 00:11:48,I give the expected json response object in markdown. It works over 95% of the time
2023-06-14 00:12:36,markdown ? didnt understand . is this part of the prompt
2023-06-14 00:13:42,Yes. Give me an input you want in json format
2023-06-14 00:13:57,I'll share some prompt hack
2023-06-14 00:18:17,I'm actually being serious here
2023-06-14 00:19:42,"Haha, yeah I remember this. He tried this on Bard."
2023-06-14 00:20:21,https://twitter.com/goodside/status/1657396491676164096?t=BWY3Fp5rMqfNt-8HmOi2PQ&s=08
2023-06-14 00:25:26,Chatgpt with browsing has a very error rate in browsing and clicking links
2023-06-14 00:37:15,"Interesting video about AI in SV - innovation, including generative AI is discussed https://youtu.be/cHXCsVgWHxU"
2023-06-14 00:51:05,They’re storing all fine tuned models people are generating? 😮
2023-06-14 00:51:25,https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/
2023-06-14 00:51:29,Why so benevolent
2023-06-14 00:52:52,They’re charging you for it :)
2023-06-14 00:57:56,oh so the storage has a separate cost than just calling the finetuning api?
2023-06-14 01:03:08,Hmm.. not sure if they expire fine tunes at the moment. So you pay to create a fine tuned model and then to use it. Storage doesn’t cost anything. That’s benevolent I guess (not sure if this is a large expense somehow though)
2023-06-14 01:04:11,Fine tunes don't expire. You need to delete it with owner access login
2023-06-14 07:07:53,"We constantly see a drift happening due to the nature of our domain. The idea is to have some representation vector for your dataset (embedding) and monitor the distance based on this. In general a changing confidence score could also indicate drifts. There are some open source packages from IBM and seldom that I have used for offline Alibi, AIX360."
2023-06-14 08:19:40,"I'll DM you, we are planning to build this on E2E and Jio Datacenter infra"
2023-06-14 08:20:08,So investment of $30M odd ? ..
2023-06-14 08:20:41,"Arre sir, you'll get enterprise discount. Should be closer to $10M with those?"
2023-06-14 08:22:32,great
2023-06-14 08:22:45,So the plan with Reliance is to do a in-kind investment of sorts ..  its still under discussions  .. so can't share too much in public
2023-06-14 08:24:30,So startups will give equity to Reliance + payment for usage ?
2023-06-14 08:24:55,[PHONE REMOVED] : I’m in
2023-06-14 08:25:26,"No, it will be an independent Fund ... Reliance might be an in kind LP in that .. no direct startup equity"
2023-06-14 08:25:52,usage payments etc need to be figured out .. still early in discussions
2023-06-14 08:27:25,Could also be E2E .. or Adani .. we'll see
2023-06-14 08:28:05,I was in discussion with NIT Raipur (my alma mater) in regards to data center usage for startups. They struggle to provide pay as you go pricing because they don’t have the right calculation metric.
2023-06-14 08:28:30,I too am in. Happy to contribute.
2023-06-14 08:29:20,For inference .. we are planning to use my portfolio company Qblocks.cloud to aggregate spare capacity in Top Univs .. .my colleague [PHONE REMOVED] can share more details if you DM him
2023-06-14 08:30:03,Oh great. I can connect them with NIT raipur team as well
2023-06-14 08:30:07,That's 400x times of IISc
2023-06-14 08:31:33,"Thanks, please do .. Qblocks can probably orchestrate a small cluster and we can price according to what capacity the Univ is able to provide"
2023-06-14 08:32:25,[PHONE REMOVED] I know a guy who setup Tesla’s 2 data centers and used to run the show. In case that helps.
2023-06-14 08:32:55,"If [PHONE REMOVED] can afford to pay him+team, why not?"
2023-06-14 08:33:09,Pls add back of envelope estimates to your call to action tweet to Mr Gurnani
2023-06-14 08:33:42,The guy is an Indian so hopefully he will help us a mentor.
2023-06-14 08:34:02,😅😅
2023-06-14 08:34:47,I'd not insult his team's intelligence by adding my back of the envelope estimate. [PHONE REMOVED] can share better estimates — but he's rarely up in IST.
2023-06-14 08:34:52,Yes we can.  Please connect
2023-06-14 08:36:04,I don't really think Mr. Gurnani was serious about all these😅
2023-06-14 08:37:37,"$10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?"
2023-06-14 08:38:31,"Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?"
2023-06-14 08:38:32,"It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?"
2023-06-14 08:38:58,"He is retiring in Dec 2023 and this can be his new mission. So, there is a chance that he’ll consider it, particularly if he knows that it doesn’t cost a lot of money"
2023-06-14 08:39:13,I have long believed that the only pending piece in the  Indian ecosystem as a whole is great people coming together. A lot of times smartest of the brains do not want to collaborate with other smart people. (Thoughts in my personal capacity)
2023-06-14 08:39:15,"AWS can offer higher uptimes, better security, better tooling etc etc .. today is H100 tomorrow will be Z100"
2023-06-14 08:39:32,"Compute can be >40% of startup burn, you bring it down to 10-20% — isn't that better for your folio?"
2023-06-14 08:40:44,"If anything, affordable compute is a huge pull for someone serious about doing AI-heavy features and services in their tech stack"
2023-06-14 08:40:44,Yes it will be better. We can finance one. But AWS and others offer $200K free credit to our portfolio.. so the startups don't need to go to any other platform
2023-06-14 08:41:00,Only thing is someone or a team needs to own it. Like you putting your face and name to it.
2023-06-14 08:41:44,Saw this tweet earlier today and thought it might be relevant to the discussion https://twitter.com/nathanbenaich/status/1668751988853555201
2023-06-14 08:44:02,Will do. Texted the Director of data
2023-06-14 08:50:07,"Rumours: Singapore is hosting a ""Come back to SG"" program for top tier AI talent with SG connections. @swyx and @eugeneyan should be on the invite list"
2023-06-14 09:08:50,I'm surprised ME hasn't jumped on this train
2023-06-14 09:09:14,"Strategically, this seems to be something right up their alley. Cheap power, tons of money to throw about on infra, low marginal tax rate,"
2023-06-14 09:09:29,And a deep desire to attract talent to reduce oil dependence
2023-06-14 09:09:41,Is there some Saudi program of free gpus? :)
2023-06-14 09:21:38,They are already winning in the AI game. They did it right.
2023-06-14 09:37:19,"Serious question, how does anyone keep tabs on this group? 😅"
2023-06-14 09:37:56,There is a genAI summary chrome extension coming for that :/) just joking 🙃
2023-06-14 09:38:07,Daily morning routine of reading through things to catch up pre sleep. Seriously. No sarcasm
2023-06-14 09:38:27,Takes me about 30 mins if i do it properly. But worth it
2023-06-14 09:39:33,"Just read finLLM paper. Doesn’t RLSP sound a little weird. They didn’t release any details also. Instead of focusing on making it give the correct answer, it has to now predict the correct stock price in the future."
2023-06-14 09:39:38,Post sleep
2023-06-14 09:40:13,"I'm super curious how do these big data centers get built? And are there easy ways to ""provide"" compute when you self host? I'm sure there should be platforms already but would love to know more about this [PHONE REMOVED]"
2023-06-14 09:46:10,You have to bleed AI bruh .. you will then live and breath this group 😇
2023-06-14 09:47:52,whatsapp needs a search by message reactions feature😂
2023-06-14 09:48:58,I found out that people who personally own Nvidia DGX just share access via SSH to known individuals.
2023-06-14 09:49:34,But then how does the payment come into picture? Is it just manual tracking and then invoicing it later?
2023-06-14 09:49:59,a16z will say crypto here
2023-06-14 09:50:07,😂
2023-06-14 09:50:45,Also it's wild that people personally own DGXs
2023-06-14 09:51:17,"Probably just landing for free or grant from personal DGX in garage. Folks are not crazy about making money here for personally owned rigs, just let people hack on it."
2023-06-14 09:51:37,Makes sense
2023-06-14 09:51:50,Isn't that the first condition to move into Hayes valley 🤣
2023-06-14 09:52:48,"Nat and Daniel give huge grants to indie projects, I'm sure that many folks are going to get access to Andromeda nodes as grants."
2023-06-14 09:54:09,"Yeah, that's for sure going to be a crazy ride"
2023-06-14 09:54:31,Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.
2023-06-14 09:55:00,"I thought it was clever. although I haven't delved into the details. Also, not our domain so I may not get into it."
2023-06-14 10:03:04,Any good meetups that you'd recommend? (other than ours)
2023-06-14 10:07:27,"I usually go to SF Tinkerer meetup run by Alex (Copilot fame) and Rahul. I have found many others mostly networking events, which I'm not very fond of."
2023-06-14 10:09:51,https://forms.clickup.com/8459928/f/825mr-5991/ZM34QXAROUNR0TLZBR
2023-06-14 10:19:25,"Better resource optimization, more scale, less maintenance overhead."
2023-06-14 11:00:20,"Not discounting the business risk, but that's why it's called ""Venture"" Capital and not Fixed Deposits, right? "
2023-06-14 11:02:16,And if we're saying an Indian cloud will have worse resource utilisation and more maintenance overhead — we're anyway accepting that Indian markets are not mature and Indian talent (for infra) is worse than AWS
2023-06-14 11:02:17,The J-curve for talent maturity does not start at profitability or insane margins on day 1 or even day 1000
2023-06-14 11:03:17,"Someone has to absorb the risk of a possible loss for the ecosystem to mature — could be GoI as Sandeep [PHONE REMOVED] insists often, or a PPP as Brij [PHONE REMOVED] & friends are trying"
2023-06-14 11:16:34,"Fair, but it’s a lot more than just setting up GPU rigs. For hosting production grade applications and not just academic projects, a whole lot of things need to be considered such as availability, up time, resource optimization, cloud gtm etc. the investment required would be much more than 30M imo. Even AWS took some ten years to be profitable. "
2023-06-14 11:19:16,I think [PHONE REMOVED] and [PHONE REMOVED] are better informed on how the orchestration would work
2023-06-14 11:20:27,Please check out qblocks.cloud - we are one of the investors with carya ventures. They have been able to build out an asset light GPU platform and a lot of companies are using it for training + deployment (infact they have an api platform as well which comes cheaper than openai’s whisper api)
2023-06-14 11:20:32,They said this about rockets btw. And a nuclear program. Scrappy is a superpower
2023-06-14 11:21:14,"More power to the folks actually doing it, and getting started. It's hard to get 100m capital committed immediately, even to get started"
2023-06-14 11:21:44,Far easier once there's some momentum
2023-06-14 11:22:15,Easier to sieve the folks who are actually doing
2023-06-14 11:23:00,"If there is momentum and need, there is more than enough risk capital availability just within our country.  But we need to do this iteratively and hit milestones methodically"
2023-06-14 11:23:06,"Okay awesome, will reach out to them! Thanks!!"
2023-06-14 11:39:24,I checked this out. Prices were comparable to runpod.io
2023-06-14 11:44:31,qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.
2023-06-14 11:55:21,Uptime for data center cluster is at par with with cloud providers. You can chat more with [PHONE REMOVED] on this
2023-06-14 11:58:26,Agreed. But what scale are we taking about? 1000+ gpus for end to end training I am assuming?
2023-06-14 12:05:32,That's for you. There are 1000 teams who need that.
2023-06-14 13:47:55,Hey Sandeep. We are solving for reliability as well by pooling in GPUs from tier 2/3 DCs as well across the globe. Would love to do a deep dive.
2023-06-14 13:57:58,Well I want to stand a bit apolotically away. However the commonly understood standard for data center reliability is the Tier classification. 
2023-06-14 13:58:28,"If u want to make a claim that you are solving for reliability, you will have to get an independent audit granting you a Tier classification."
2023-06-14 14:00:03,"Fyi, this is called TIA-942 audits (one among many)"
2023-06-14 14:02:06,We have partnered with Tier 2/3 and even Tier 4 DCs. And these tiers are not defined by us but the audits they have done at their side prior to onboarding their GPU servers on our network which are further available on demand to users.
2023-06-14 14:04:23,"If ur GPU span multiple datacenter while training...like 1 GPU is in data center A and another is in B and u stitch them together, then the TIA 942 is invalidated."
2023-06-14 14:06:37,my honest opinion is that this battle is not worth fighting. anyone is willing to accept this non-Tier grade reliability in exchange for aggregate availability. 
2023-06-14 14:13:02,"It's the first scenario I'd say. Since we are not dependent on a single provider and not only data centers. We have pooled in GPUs from independent small providers and data centers, leading to more optionality as well. From 8GB to 80GB GPUs + in quantity."
2023-06-14 14:37:02,[PHONE REMOVED] talked to AI architect at cerebras system
2023-06-14 14:37:08,He is willing to help as well
2023-06-14 14:44:54,"Does anyone have ideas or doing 'governance checks' for their models ? for me is an independent review of the architecture towards what's the focus or what's not the focus - i want to see how models can be helpful for communities; another level can be audit of training data of what's included and what's not (which prompts makes models hallucinate or lie?) and then a strategic/business audit (environmental and social) ... trivially, *are we wanting AI to be our master, slave or friend or somewhere in-between?* grateful for anticipated feedback."
2023-06-14 15:08:12,Crypto miners have a moat now
2023-06-14 15:09:43,"so, there's a GPU shortage?"
2023-06-14 15:17:16,Nat.dev?
2023-06-14 15:18:17,https://aviary.anyscale.com/
2023-06-14 15:44:44,For a future project I’m looking to interact with data scientists / ML specialists who have been involved in developing AI-powered technology to be employed in rural/farming contexts in India. If you have any information to share please let me know. I can also be reached here: [EMAIL REMOVED]
2023-06-14 16:35:18,https://www.moneycontrol.com/news/business/startup/indian-saas-giant-zoho-joins-the-large-language-model-race-10795551.html
2023-06-14 16:35:55,[PHONE REMOVED] you can probably reach out to him instead of Gurnani
2023-06-14 20:17:10,Has anybody started using function calls as published by OpenAI today ? 
2023-06-14 20:17:54,https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw
2023-06-14 20:28:35,Thanks for sharing this! This is the exact problem I was grappling with 
2023-06-14 20:41:26,Yes we did today. Just doing web search now and then next is jira ticket update
2023-06-14 21:04:45,You can also refer the openai cookbook 
2023-06-14 21:31:10,[PHONE REMOVED] is a machine ! :)
2023-06-14 21:33:38,If this library continues to integrate more stuff I can see it become a really popular open-source library
2023-06-14 21:34:54,Yeah. Although I like it in this type of format where I can write the code in my own style without learning a separate syntax.
2023-06-14 21:38:56,Logan on twitter is great for all openai announcements and updates
2023-06-14 21:38:57,"[PHONE REMOVED] in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?"
2023-06-14 21:39:00,“Colab notebook to get unchained” 😂
2023-06-14 21:39:32,Dev rel at openai. That's his job
2023-06-14 21:40:45,"i know, it was a PSA to follow Logan :)"
2023-06-14 22:05:17,Am still working on that. It's not great. Need to figure out more here whether it's the way the function was defined etc.
2023-06-14 22:13:25,ok figured it out. Need a good system message in my case.
2023-06-14 22:17:41,Is there some new way to ask the API for json (by specifying required and optional fields in a schema)? Like through functions or something? Or will old prompts just work better now
2023-06-14 22:18:18,Any example or is it secret sauce? (I understand if it’s the latter)
2023-06-14 22:20:02,"not that much of a secret sauce. If you're in Mumbai and coming to the meetup on Saturday, will share over there 😜. we can actually discuss this on DM because message is specific to type of functions being passed"
2023-06-14 22:20:55,Nope. JSON is still not guaranteed.
2023-06-14 22:21:48,Yeah just saw a tweet reporting the same. Hallucinating placeholder values in the schema
2023-06-14 23:03:36,"3.5 gets it right about 3/5 times, which is an improvement from GPT4-0314 of 1/5"
2023-06-14 23:04:09,is that what 3.5 stands for
2023-06-14 23:08:32,No it’s an instruction tuned gpt3
2023-06-14 23:08:55,Sarcasm tha
2023-06-14 23:09:11,3.5 3/5
2023-06-14 23:19:09,insane speed of execution!
2023-06-14 23:25:57,What is the algorithm here?
2023-06-14 23:40:22,"Langchain still seems to have so many issues, the tokentextsplitter is non deterministic and doesn't split evenly and doesn't even confine to token limits imposed, if the input text is too long 💀"
2023-06-14 23:43:04,Agree 💯
2023-06-14 23:44:04,"The ReAsk? 3 min to write the code, 2 hours to test it 🤣"
2023-06-15 00:10:10,https://hackathon.bio/#projects
2023-06-15 00:11:05,cc [PHONE REMOVED] since we discussed SAM+ImageBind for Pathology and Radiology
2023-06-15 00:29:55,This is so cool!
2023-06-15 00:35:45,"Building on top of this, I shared some of my speculations here - https://twitter.com/177pc/status/1669056794864533504?t=1fJWSKe-x_yBKC-ciZIiig&s=19"
2023-06-15 00:41:42,A good founder friend of mine (please don't ask who) told me a version of this a few hours ago -
2023-06-15 01:43:56,StarCoder — my fav code LLM has hit VC-verse: https://twitter.com/AstasiaMyers/status/1669025589213425664
2023-06-15 01:45:12,Are you using it with some vscode extension or just checking benchmarks?
2023-06-15 01:46:27,"Not VSCode, that's still Copilot — StarCoder is slower and worse. Copilot changed the experience a bit and gives a lot more coherent output too."
2023-06-15 01:47:17,I dont want to renew Copilot as I think it's not worth it anymore and the new WizardML star coder had a better benchmark than 3.5
2023-06-15 01:49:06,I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.
2023-06-15 01:50:04,"Soon almost everything will be better than 3.5, partially because people have started to figure out how to game the leaderboard. Kaggle-mindset trickling in."
2023-06-15 01:51:34,cc [PHONE REMOVED] [PHONE REMOVED]
2023-06-15 01:54:19,We need eval test for eval tests.
2023-06-15 02:13:05,"Same old story, just in a new dress"
2023-06-15 02:14:44,Standardization is required to draw a fair comparison between various approaches
2023-06-15 02:15:08,...applications
2023-06-15 02:15:41,"Just curious , do you work on cancer related applications ?"
2023-06-15 02:37:31,I used to long back on pathology at morphle labs 😅
2023-06-15 02:43:16,"There is a repo for exact use case, someone needs to build a VS code extension around it."
2023-06-15 02:46:18,"First release was just two weeks ago, a good opportunity for someone to gain quick fame."
2023-06-15 02:51:59,But definitely they will improve. and humaneval pass@1 is not a very good evaluation too.
2023-06-15 02:52:29,https://twitter.com/theblokeai/status/1669032287416066063?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw WizardML 57
2023-06-15 02:52:45,I think there's a WizardLM-Starcoder 15B version today from TheBloke that surpassed GPT3.5
2023-06-15 02:52:50,Yeah this one.
2023-06-15 02:53:46,But I've not tried it out myself yet.
2023-06-15 02:55:18,"Alex created CoPilot so can be trusted, if he is right $500k/month commitment for Azure GPT4-32K api access 🤯 https://twitter.com/alexgraveley/status/1669091417262817280?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw"
2023-06-15 03:15:58,Any LLM benchmarks so far in the context of mathematical reasoning?
2023-06-15 03:31:30,I want to run ggml alpaca eval for this model and see the difference in benchmark performance.
2023-06-15 05:41:41,"[PHONE REMOVED], [PHONE REMOVED] and I were discussing this just a couple of days ago. Wouldn’t that still cost you more than $20/month though? And for a worse experience?"
2023-06-15 05:42:32,Using it against GPT-3.5/4 might be cheaper given you are just paying for the actual usage and I am sure they are dramatically subsidizing the real cost.
2023-06-15 05:43:51,Have you tried https://github.com/ai-genie/chatgpt-vscode ?
2023-06-15 06:37:55,"I have many 3090s at home, If WizardML is beating GPt3.5, it will be better than CoPilot. This setup is to replace the copilot and not GPT4."
2023-06-15 07:48:46,https://arxiv.org/pdf/2306.07303.pdf
2023-06-15 08:27:39,https://docs.google.com/document/d/e/2PACX-1vSOgnt4XInS1A6LXM3VZbbcx3ZG-IaRUrBV4Iotnmns0i38IbP5C48mT1eTrmOcxyzUcljIjpFwJaj5/pub
2023-06-15 11:36:53,"yeah man, it’s pretty wild"
2023-06-15 11:37:45,Accelerators are coming in different shapes and sizes hahaha
2023-06-15 11:38:36,"That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here."
2023-06-15 11:39:28,“Decent ones are earning ~1M”
2023-06-15 11:40:24,curious. any resources similar to levels.fyi to read more about it?
2023-06-15 11:43:39,I learned from recent tweets that I saw from Emad and some other sources who were struggling to hire.
2023-06-15 12:02:13,Has anyone noticed OpenAI APIs throttled for India? I'm having drastic latency issues for servers in India compared to the US. Even 3.5-turbo.
2023-06-15 12:03:32,lol
2023-06-15 12:13:18,Would need to compare to US or other regions for this. What's your reasoning?
2023-06-15 12:14:51,"No reasoning yet, just asking to confirm."
2023-06-15 12:15:35,Yesterday I saw [PHONE REMOVED] having a similar issue.
2023-06-15 12:16:00,Not facing such with 3.5. 4 is slow during peak us hours.
2023-06-15 12:30:35,"Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency 😅"
2023-06-15 12:33:12,That's a fact
2023-06-15 12:51:56,+1 on this 
2023-06-15 14:00:06,Interesting video featuring Karpathy - discusses GPT training process https://youtu.be/bZQun8Y4L2A
2023-06-15 14:00:45,or by seeing chatgpt response.
2023-06-15 14:25:45,"Stumbled upon Langkit from whylabs, will share my feedback soon. "
2023-06-15 14:27:11,This is quite interesting
2023-06-15 14:27:16,The overall LLM ops stack
2023-06-15 14:28:05,"Which other tools have you used to monitor, observe, test  LLMs"
2023-06-15 14:29:13,I suspect this will be rarely. Plugins are a poor design primitive.
2023-06-15 14:30:22,Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.
2023-06-15 14:30:50,"ChatGPT is an AI and a SaaS. Sam wants to built AGI but also tonnes of tools, apps"
2023-06-15 14:31:29,I missed that. Noted.
2023-06-15 14:31:36,Which interview was this? Any link?
2023-06-15 14:31:58,I think it was in a blog
2023-06-15 14:32:04,I'm still collecting offerings and evaluating what they really do. Arize and Truera promise a few things but I'm  picking this because I have used other solutions from whylabs.
2023-06-15 14:32:34,"Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic"
2023-06-15 14:32:40,Hey seems it was taken down. This is the best that came up sorry - https://matt-rickard.com/chatgpt-plugins-dont-have-pmf
2023-06-15 14:38:28,"First part +1, I'm deep diving into how temp parameter interacts with matrices to change the next word probabilities. Topk and topP are just filtering. My hunch was they just pass that to random selector if it's non zero and for zero it picks the top word. But I don't want to believe that. "
2023-06-15 14:38:35,Got it! Seems like openai took it down.
2023-06-15 14:44:05,Found it - https://web.archive.org/web/20230601023730/https://humanloop.com/blog/openai-plans
2023-06-15 14:45:35,he said this in person at the IIITD session as well. he touched briefly and then Eleti (openai engg) expanded on this very thing.
2023-06-15 14:46:15,"he said ""plugins in its current form"". i think thats why they are doing all these functions, etc releases. plugins will come back definitely"
2023-06-15 15:21:04,It generally is non deterministic. I think temperature is a pseudo parameter - like a loose lever you can play with. Not a proper controller for the nature of the output
2023-06-15 15:21:07,it was in one that was deleted
2023-06-15 15:34:37,"Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?"
2023-06-15 15:37:12,I can definitely tell you that they both do compete for same customers
2023-06-15 15:37:18,Microsoft's winning pitch so far has been Open AI APIs inside customers' VPCs
2023-06-15 15:43:21,From what I know.. MS product roadmap is more head on with Google. With OpenAI they are ok to go for same customers however their marketing team's mandate is that positioning /promoting MS products should not diss or jeopardize openai.
2023-06-15 16:51:15,True deterministic output using t=0 isn't possible since true t=0 doesn't really happen.
2023-06-15 16:52:23,Notice that t=0 is an approaching limit and can't really be 0. So what you get in implementations in all the libraries is high determinism not true determinism.
2023-06-15 16:52:35,https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers
2023-06-15 16:54:37,"Wait, what — Obsidian has a way to publish notes to web on a custom domain?"
2023-06-15 16:56:15,I didn't even notice that.
2023-06-15 16:56:32,"Obsidian Puvlish has that option , yes"
2023-06-15 16:56:50,* publish
2023-06-15 16:59:54,https://twitter.com/levelsio/status/1669269424543793153
2023-06-15 17:00:20,Virtual Cataloging companies making some good money!
2023-06-15 17:12:30,Distribution is the differentiator here
2023-06-15 17:16:26,Danny Postma and Levelsio are both chad and top of their AI SAAS game
2023-06-15 17:16:57,Why do you say that?
2023-06-15 17:19:31,"Pieter levels makes 3M per year as a solo developer, with 300k+ Twitter fillers. His products aren’t necessarily different- it’s just that people buy when they see it’s him."
2023-06-15 17:28:07,Does he have 300K follows because he builds cool things?
2023-06-15 17:28:49,Absolutely
2023-06-15 17:28:55,And sells it well.
2023-06-15 17:29:01,Curious as to what you found as good or better as photoai.com or headshotpro . Org 
2023-06-15 17:29:44,"What I meant was that it compounds now, and so it’s years of effort that allow him to build stuff that gets traction from day 1 even if not differentiated."
2023-06-15 17:32:30,I’m a fan and subscriber of both of them. Things get better as they get used and get feedback too. So building that early distribution helps them iterate much faster — postma literally improves his product every 3rd day and he has earned that rich feedback loop too by being so consistent. Please do not mistake me for detractor of the 2 indie legends 🥲
2023-06-15 18:06:06,"im not sure if this is the cause, it's like saying true random numbers can't exist what we get is pseudorandom numbers (which is true but a human can't detect that reliably)"
2023-06-15 18:06:23,i use it too https://notes.invertedpassion.com/
2023-06-15 18:09:47,"It's a limitation of implementation. Lack of true randomness isn't there because humans can't detect it reliably but because computers use external sources that are deterministic. As long as the initial seed or source remains the same, the same random sequence can always be produced."
2023-06-15 18:10:26,"maybe you're right, slight floating point differences can get amplified in a deep network"
2023-06-15 18:12:20,"Anyway, given that softmax usage of temperature is the same as the one I shared, how do you think you'll arrive at true value of softmax with t=0? It'll always be a number very close to 0 but never zero. So it'll always be highly deterministic and never true deterministic."
2023-06-15 18:32:32,What platform is this? Lambda labs?
2023-06-15 18:36:42,Seems andromeda cluster. Not sure what it is though. 
2023-06-15 18:42:10,This is lambda lab page.
2023-06-15 18:48:03,You just remove T from the equation entirely if T is 0?
2023-06-15 19:22:56,autoevaluator.langchain.com/playground
2023-06-15 19:23:34,"Peak AI: Calling a grid search with a static front end ""Evaluation Platform"" "
2023-06-15 19:24:13,When marketing teams go overboard ! :)
2023-06-15 19:25:36,Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC
2023-06-15 19:31:57,looks like a job for jupyter meowbooks
2023-06-15 19:32:14,The inspiration we all need :)
2023-06-15 19:32:54,"Winning the meme wars is important, not too long ago — disease and cancer were seen as ""what God ordained"""
2023-06-15 19:38:17,This isn’t even the first time. 3rd ai wave since 2014 and same story everytime
2023-06-15 19:48:11,"LOL. We may yet see ""steel man the AI"" on a gen AI pitch deck sometime soon"
2023-06-15 19:48:36,"Also, 10m seed round - reminds me of ""a small loan of a million dollars"""
2023-06-15 21:13:10,https://www.reddit.com/r/LocalLLaMA/comments/149abrg/creating_a_wiki_for_all_things_local_llm_what_do/
2023-06-15 23:26:34,https://lab45thinktank.com/genai-accelerator-program/
2023-06-16 06:31:40,"Great intent; most important step here will be introduction to Wipro clients. If it works, pretty fabulous."
2023-06-16 11:36:54,Does anyone has expertise in multinode distributed training using Pytorch? Any help would be highly appreciated
2023-06-16 11:39:51,https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers
2023-06-16 11:39:58,Also H100 on lambda labs is 1.99 USD/hr now
2023-06-16 11:40:01,Just use accelerator or Lightning
2023-06-16 11:40:06,Accelerate*
2023-06-16 11:42:24,Google released virtual try-on today. Interestingly has only the upper body cloths as example and lower body is left for future. Any idea why they might have left that? tough to crack? 
2023-06-16 11:46:26,"Ok, I will try. Thanks."
2023-06-16 11:46:50,I will bug you again if I face any issues. 🙂
2023-06-16 12:44:18,"had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u"
2023-06-16 12:48:23,Concise but not precise answer - ML/DL computations are primarily matrix multiplications on ground level and GPUs allow you to perform 1000s these computations parallely. CPUs can parallelise as well but they usually have way less cores that means way lesser parallelism.
2023-06-16 12:50:17,A more detailed answer would involve explaining how modern architectures are also designed to primarily benefit from GPUs and modern GPUs again are designed to get best performance in AI.
2023-06-16 12:50:22,GPUs have SIMD architecture i.e. Single instruction multi data. Which enables them to do parallel processing at scale across thousands of smaller cuda cores (cuda cores are in nvidia GPUs). They are smaller than a typical vCPU found in a normal CPU chip but they are in very large quantity and thus they can process a large amount of data in parallel leading to faster results.
2023-06-16 12:53:53,"As an example an RTX 3090 GPU has ~ 10,000 cuda cores which is quite a lot."
2023-06-16 13:00:31,"For very simple question, you can always ask ChatGPT."
2023-06-16 13:01:28,Use the prompt - explain me like I am a 5 year old.
2023-06-16 13:03:38,"a very eli5 way to look at it is a CPU consists of a few very smart workers (cores) that do high quality work extremely fast. a gpu, in comparison, is thousands of not as smart workers, but can now consume larger workloads and operate in parallel. its a quantity over quality thing"
2023-06-16 13:07:15,"adding to that, due to the recent surge in gpu usage for ML training, it has also been highly optimized for instructions specific to the ML context, at both the hw and sw levels"
2023-06-16 13:08:57,this simple video explains at a high level: https://www.youtube.com/watch?v=-P28LKWTzrI
2023-06-16 13:25:04,Anyone from this group present at AWS dev day bangalore? Happy to catch up.
2023-06-16 18:38:28,"folks interested in biomedical, drug discovery applications of ml, might enjoy this interview :"
2023-06-16 20:02:38,Surprised that you can’t create an enterprise account on Stability AI
2023-06-16 21:10:19,Ping hardmaru they’ll implement in the next 1 week
2023-06-16 21:24:51,Alot of people don't know this but Wipro is StabilityAI's distribution partner
2023-06-16 21:26:47,Link is - Eros (yes the Bollywood powerhouse) Investments. They are an investor in StabilityAI
2023-06-16 21:27:02,And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms
2023-06-16 23:19:54,What does distribution partner here mean?
2023-06-16 23:25:30,Wow
2023-06-16 23:25:31,This is interesting
2023-06-16 23:45:06,I don't fully understand it myself but my guess is:
2023-06-16 23:49:21,[PHONE REMOVED] do they have their own Model ? 
2023-06-16 23:58:55,You can find Stability's models on their website. I don't think Eros or Wipro have their own models
2023-06-16 23:59:25,Hmm got it
2023-06-17 00:02:50,https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android
2023-06-17 00:03:06,Meta AI is literally next level I think
2023-06-17 00:07:43,In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.
2023-06-17 00:08:58,Actually waiting for llama v2 eagerly.
2023-06-17 00:10:38,Very exciting !
2023-06-17 00:12:00,I think they'll have supplementary detection models too. Meta AI as far as I know is very ethical and safeguarded
2023-06-17 00:12:02,That's what I hope :)
2023-06-17 00:14:11,Then there will opportunity for new startups to detect deep fakes.
2023-06-17 00:15:03,Detection is always a one order higher difficulty problem than generation. We really didn't have a very high neural voice generation until few months back. But now it's hard to detect whether the speaker is human or not especially over a call.
2023-06-17 00:15:35,Everything we are seeing looked impossible 6-8 months back.
2023-06-17 00:16:05,"Yes, it's like a fold in time. Everything got pulled in."
2023-06-17 00:16:18,The new mission impossible film is going to look so realistic
2023-06-17 00:18:10,"A year back when Netflix had that interactive movie/shows people were impressed, it will possible soon to replace everything Tom Cruz says with my voice. 😂"
2023-06-17 00:19:27,Mission impossible had vision pro 20 years ago. 😂
2023-06-17 00:32:14,"Bander snatch , was a cool concept"
2023-06-17 01:17:36,"I am not sure how to put this message across, there is a huge inferiority complex associated to this. But here I go."
2023-06-17 01:18:33,"Late night, sleep deprived rant.. 😔"
2023-06-17 01:20:51,Can't people just be paid real cash for computation instead of a cryptocurrency?
2023-06-17 01:22:50,"Hey guys has anyone experimented with code chunking strategies, I want to create a vector store of cpp files"
2023-06-17 01:29:10,"True, but this  might act as a incentive for those who don't understand the importance of the actual hash calculations but will be rewarded for the compute."
2023-06-17 01:31:52,"as far as I understand if I am renting my compute for hash calculations or any other computation, I would mostly prefer to be paid in a currency which is least volatile."
2023-06-17 01:36:01,Hey we are doing this already at Q Blocks 👋
2023-06-17 01:53:26,"Please dm me, would love to chat"
2023-06-17 02:17:12,"Yeah, there are 2 approaches that I'm aware of and experimenting with whatever limited time I've"
2023-06-17 02:18:00,"Since you mention cpp files specifically, are you looking for a cpp specialised chunking strategy?"
2023-06-17 02:24:42,"something weird going on with langchain py docs, but here's a link to the code chunking utils in langchain js: https://js.langchain.com/docs/modules/indexes/text_splitters/examples/code#:~:text=/*%0A%20%20%5B%0A%20%20%20%20%27-,cpp,-%27%2C%20%20%20%20%20%20%27go%27%2C%0A%20%20%20%20%27java"
2023-06-17 02:29:44,https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter
2023-06-17 02:29:59,"Yeah I think chnuking strategy do need to be lang specific. Also, does ada-002 beats all guidance holds true for code retrieval as well."
2023-06-17 02:41:45,In my experience most people seem to do well or not bother in detail about which chunking strategies they are using for code. Maybe you've tried out the python langchain code splitters for cpp?
2023-06-17 03:05:59,https://arxiv.org/abs/2306.08997
2023-06-17 03:22:24,"Have not experimented much, I am trying to create an agent and creating a tool for that agent to retrieve relevant code. Will definitely use the long-chain cpp implementation and share my findings."
2023-06-17 05:34:27,"This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund. "
2023-06-17 07:28:51,"Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you."
2023-06-17 07:34:05,PSA: 
2023-06-17 07:55:34,"Goldberg having a field day with GPT4 evaluation ""hacks""  "
2023-06-17 08:06:54,I love his sense of humour.
2023-06-17 08:16:32,Haha. Reminds me of that incredible foreword in another textbook
2023-06-17 08:19:18,Isnt this the same paper where everyone is being amazed about the “expert prompting “ strategy ? 
2023-06-17 09:43:30,"Context: I am not from a technical background, learning from Google University of Search (🙈) and looking for a mentor / guide."
2023-06-17 09:50:20,https://lu.ma/genAI-mumbai-june
2023-06-17 09:56:31,"Does anyone have access to code interpreter in chatgpt? If so can I please get an overview of it's usefulness? AI influencers are going Gung ho over it that it will eat developer jobs, just wanted to know what's the reality."
2023-06-17 10:01:37,"[PHONE REMOVED] are you aware of any meetups , hackathons in delhi ?"
2023-06-17 10:01:39,"Not very off. Code Interpreter is better than GPT4 at long context code understanding, being able to tell objects and dictionaries apart in Python, getting what a happy path convention is and similar clever things."
2023-06-17 10:02:32,I hear a certain AI CEO was there recently. Some great audience questions. 
2023-06-17 10:02:54,Don't you diss my hometown :)
2023-06-17 10:04:10,Any idea when this will release for regular chatgpt plus users as they had talked about this in march (it seems to be in the chat.openai.com app). Also is there an equivalent in the API?
2023-06-17 10:04:55,And finally is this for gpt 4 only or does gpt 3.5 also have this functionality?
2023-06-17 10:06:32,No Code Interpreter API. GPT4 only.
2023-06-17 10:08:29,Thanks a lot!
2023-06-17 10:24:43,I’m desperately waiting for it too. Despite being a paying user (gpt plus)
2023-06-17 10:32:36,"I don't think that's indicative of much except the High population of 18-25 year Olds in India who are studying in schools and colleges and have the best ""academic"" use of chatgpt"
2023-06-17 10:32:45,If you get what I mean🤭
2023-06-17 10:33:29,Lol yes fair point
2023-06-17 10:34:10,If there are statistics on chatgpt+ that would be more indicative as openai has not adjusted pricing for PPP
2023-06-17 10:34:32,Oh these are search statistics
2023-06-17 10:34:45,A permissively licensed implementation of llama's technical paper - OpenLlama finished training it's 13B model on 1T tokens and has released it.
2023-06-17 10:34:54,https://github.com/openlm-research/open_llama
2023-06-17 10:40:23,LocalLLama subReddit is quite active https://www.reddit.com/r/LocalLLaMA/comments/147lmku/which_best_uncensored_freespeech_llm_models/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
2023-06-17 10:44:37,It's one of my primary hangout spots recently.
2023-06-17 11:15:25,Enjoyed the first episode on generative AI in Black mirror’s new season
2023-06-17 11:20:49,"Yeah, the one names “Joan is awful”, right?"
2023-06-17 11:22:11,*named
2023-06-17 11:25:53,"Aw, spolier"
2023-06-17 11:25:58,I have seen it
2023-06-17 11:31:17,How can it be a spoiler? It's a documentary iykwim
2023-06-17 11:37:25,We are living through it ! #cleverjokesftw
2023-06-17 11:38:18,"any pro tips for video input in SD animations? runwayML is known, other options please! :)"
2023-06-17 11:41:17,interesting graph !
2023-06-17 11:42:38,UBI discussions are perhaps best suited for the Policy & Philosophy fork? 
2023-06-17 11:43:06,Now spatial computing will be the most searched term soon
2023-06-17 11:50:18,"Few others in my to-try list: https://github.com/Scholar01/sd-webui-mov2mov, https://huggingface.co/spaces/fffiloni/ControlNet-Video"
2023-06-17 11:54:37,We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik
2023-06-17 11:56:27,"in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India."
2023-06-17 11:59:08,"That's not my contention, my contention is that gen AI isn't accelerating industrial automation"
2023-06-17 12:05:20,"I would, largely, agree with that."
2023-06-17 12:08:34,Not true! The work is now towards robotics foundational model -
2023-06-17 12:09:57,Can't find the lecture right now but iirc Boston dynamics doesn't even use ML and depends heavily on classical control systems algos.
2023-06-17 12:12:23,thanks for sending this link.
2023-06-17 12:13:24,https://github.com/AntonOsika/gpt-engineer
2023-06-17 12:14:58,"Yeah, I'm not holding my breath on Google shipping this to a factory near you"
2023-06-17 12:16:22,My take. 
2023-06-17 12:51:11,https://www.linkedin.com/posts/1rohitagarwal_portkeyai-on-twitter-activity-7075700450926206976-DLVy?utm_source=share&utm_medium=member_ios
2023-06-17 12:52:47,Ability to cache semantically similar prompts seems novel
2023-06-17 12:56:02,Spent a lot of time tweaking stuff - works very well now for RAG use cases
2023-06-17 12:58:31,"Great job, Rohit! Keep slaying"
2023-06-17 13:28:16,https://youtu.be/DUUTHkQrYy0
2023-06-17 13:30:25,Tricking chatGPT to do piracy
2023-06-17 13:31:34,Do they work?
2023-06-17 13:35:38,What is the correct approach for implementing GPT with analytic reports .
2023-06-17 13:40:39,"im interested in the same. if anyone has prompts, that would be super useful"
2023-06-17 13:53:20,"you want a way to generate new content based on a ranked/filtered content piece, did I understand it correctly?"
2023-06-17 13:56:41,yep .
2023-06-17 13:58:07,"i was thinking a 2 step query , one to sql to sort . other to pass it to llm to refer and create"
2023-06-17 13:58:55,that's what i can think of too.
2023-06-17 13:59:52,"in creation step, are you planning to add some more context? around the lines of central themes/main points of the actual content."
2023-06-17 14:01:43,yes creation involves - similar central themes + a web browsing agent if content requires the latest context  .
2023-06-17 16:54:39,Hopefully Abhinav is not revealing Longshot secret sauce 🙂
2023-06-17 16:55:41,"The award for the nerdiest, funniest prompt goes to ....."
2023-06-17 16:57:16,I can't imagine why we work so hard as a community of AI practitioners and end up making this 🤣
2023-06-17 16:58:15,Probably some sort of pseudo random generation. But the bypass is clever
2023-06-17 17:28:32,Hey guys one quick question: does anyone here have experience hosting python web apps on Replit? Want to understand how well dk they scale and what are the trade offs in terms of performance etc or hosting your api backends on platforms like Replit
2023-06-17 17:33:48,Cc [PHONE REMOVED] can help perhaps?
2023-06-17 17:55:25,"Hey my friend is working on a side project, here’s the intro incase somebody wants to get in touch. :)"
2023-06-17 20:05:35,Any such discussions/talks in Bangalore anytime soon folks? Would love to catch up!
2023-06-17 20:07:03,Yupp. Learnt a lot
2023-06-17 20:07:13,https://www.reddit.com/r/ChatGPT/comments/14agito/meta_will_make_their_next_llm_free_for_commercial/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=3&utm_content=share_button
2023-06-17 20:09:40,It was a very detailed talk by soumendra on the details of Lora.
2023-06-17 20:15:21,"Nice, where was this"
2023-06-17 20:28:33,Anybody into biomedical informatics?? Looking to talk and know more about it .
2023-06-17 20:40:26,Mumbai generative AI meetup
2023-06-17 20:51:41,Recording or slides please
2023-06-17 20:52:46,Yeah will share once we get videos from our photography partner
2023-06-17 21:12:07,Happens every month. Next Sat likely next one.
2023-06-17 21:13:16,Do share deets
2023-06-17 21:13:41,In progress 😅
2023-06-17 21:13:46,Will share by Monday.
2023-06-17 21:14:40,"folks, any reading materials or pointers to start learning about the RAG stack?"
2023-06-17 21:18:09,RAG video on youtube by the researcher itself
2023-06-17 21:22:31,Totally. Looking fwd to the ebook
2023-06-17 21:57:23,Is that an official name now? RAG stack
2023-06-17 22:08:46,Has anybody used 2markdown.com here?
2023-06-17 22:13:50,going by what's being used 😅
2023-06-17 22:48:46,"Uhh, what's RAG? 😅"
2023-06-17 22:49:23,retriever augmented generation
2023-06-17 22:49:24,retriever == vector database
2023-06-17 22:51:11,Retriever I would expand is all the steps to filter out relevant data to send to your LLM model for generation.
2023-06-17 22:57:16,"so since you never divide by 0, there's always a chance of a slight variation happening even though its very small"
2023-06-18 01:30:05,"Q - What is the more holistic evaluation metric as of now (from developing apps point of view) and is designing a holistic evaluation metric even a possible goal to chase? More tactically, are we even converging towards it? "
2023-06-18 03:25:15,Some questions have exact answers. This one doesn't - How can we design a perfect evaluation criteria for LLMs? We probably would grow towards that evaluation criteria or make-do with crowd evals for some time.
2023-06-18 07:54:50,Request for speaker - I'm trying to organize a community AI webinar on Thursday. Have requested Nirant to talk about GPT Functions. Need a second speaker to get into a more conceptual topic with learnings from production. 
2023-06-18 08:03:20,"This was pre foundational models era, a company in Estonia was doing it. Ended up pivoting to predict deep fakes in the NFT space. Then raised $25M. I think it's called the NFT port. Take a look at it"
2023-06-18 10:43:04,I love the soft poem to calm the engineer busy debugging
2023-06-18 11:07:22,"""Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry—in particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool."""
2023-06-18 11:10:11,Another quote that really resonated with me :
2023-06-18 11:22:35,the road to hell is paved with good intentions
2023-06-18 11:23:05,So is the road to heaven
2023-06-18 11:23:11,You never know where it forks ;)
2023-06-18 11:24:26,no good deed ever goes unpunished
2023-06-18 11:24:37,(Let's fork to Philosophy on this one)
2023-06-18 11:25:14,"Why you got to shine a realistic light on my utopian dreams, Nirant ? :)"
2023-06-18 11:29:26,"It was in beta mode for a while now. Only issue was it worked sometimes only, because they would give the message unable to connect with gpt"
2023-06-18 11:32:05,"interestingly, nothing in production is using opensource models. pretty much GPT is a monopoly."
2023-06-18 11:32:32,"Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc"
2023-06-18 11:32:37,nothing in open source even comes close to even GPT3.5-Turbo on absolutely any task which you'd want to put in production
2023-06-18 11:32:55,Code Interpreter ftw
2023-06-18 11:40:11,Do you mean retrieval of structured data?
2023-06-18 11:41:21,Connecting models to work with structured data is a pretty active area of work at the moment.
2023-06-18 11:45:46,"there isn't a secret sauce to get insights on tabular data. Think of it as a chunking problem and each row is a chunk. Look up the code of yolo-pandas and the prompts they are using, that should be able to give you an insight of how they are doing."
2023-06-18 11:49:12,"yup. only model that is close on some tasks are more closed models such as claude, in some cases cohere and some cases nlp-cloud's own finetuned models"
2023-06-18 11:50:07,"I would say, use techniques of RAG and you can apply them here on tabular data."
2023-06-18 11:53:32,this is interesting. so u chunk a whole row - with column labels i presume ?
2023-06-18 11:55:10,If each row is a chunk then global context of the data is lost right?
2023-06-18 11:55:27,"yes, that is a strategy that has worked when we've tried."
2023-06-18 11:55:39,Can you elaborate on this?
2023-06-18 11:56:17,"If I am chunking on row+ column names, and if I ask it a question what does the trend looks like, how will it answer that?"
2023-06-18 11:57:15,The original q. prompted this gen ai which can do data science wishlist flow 
2023-06-18 11:58:59,"I don’t have access, and is that available through api?"
2023-06-18 11:59:32,GPT Plus users seem to have it by default. No API.
2023-06-18 11:59:57,see you have to work on constraints anyways which is your context length you can pass to openai.
2023-06-18 12:00:43,I don't have it. I don't know what's the deal with this by OpenAI. they haven't opened to all plus customers
2023-06-18 12:01:06,I have access to all plugins minus code interpreter
2023-06-18 12:01:26,I dont🤨🤨
2023-06-18 12:01:55,Got it. Thanks
2023-06-18 12:04:49,"Much like God, OpenAI works in mysterious ways"
2023-06-18 12:05:59,"its manual, influencers get early features. regarding access, I think its heavily based on access history. We got openai gpt-4 access in a day, when it became public, companies like jasper through  connections etc had access a little earler, which goes in line with their access history."
2023-06-18 12:07:02,I have a conspiracy theory - openai’s token generation latency is random to make us believe the model is thinking
2023-06-18 12:07:50,I have another. someone is manually typing your answers on chatgpt 😜
2023-06-18 12:26:26,Can this strategy work if you don’t have Code Interpreter access ?
2023-06-18 12:26:26,Second this. In fact when I took the plus subscription it was jarring to the eyes seeing the 3.5 version too fast.
2023-06-18 14:15:51,Open source Multimodal LLM from Tencent
2023-06-18 14:36:48,update on this - 
2023-06-18 14:39:45,https://twitter.com/EdenEmarco177/status/1670064627269484545?t=VxZkvzI7oQ0xbUxcB25uTQ&s=08
2023-06-18 16:11:58,No 😞
2023-06-18 16:12:40,Not default
2023-06-18 16:12:42,I don't :(
2023-06-18 18:49:17,"Go to settings and turn on beta features, if you haven’t. Then you should see it. Also do this on web, you don’t see this setting on mobile app."
2023-06-18 18:50:01,have done it. its an alpha feature. not there for everyone
2023-06-18 18:50:59,Yeah not available for me either. It isn't rolled out for everyone as yet it seems
2023-06-19 07:17:24,Stumbled on a cool project danswer (built using qdrant)
2023-06-19 08:55:39,Any cost estimators for compute needed to fine-tune OSS models? Worried about the hole in my wallet due to compute😅
2023-06-19 08:58:15,https://github.com/alibaba/Chat2DB
2023-06-19 09:00:00,might be slightly outdated with llama models in play now
2023-06-19 09:10:24,Bytedance (TikTok) has bought $1B of NVIDIA GPUs: Split between A100 and H100 (Chinese fork called H800) 
2023-06-19 09:10:32,h/t @abacaj on Twitter
2023-06-19 09:13:35,"Interesting, have you evaluated it? would you know any other state of the art model for this use case?"
2023-06-19 09:15:57,Thank you!
2023-06-19 10:11:07,Anyone working on interface of robotics and LLMs here?
2023-06-19 10:32:56,Custom schema extraction using openai function from [PHONE REMOVED] 
2023-06-19 10:33:27,[PHONE REMOVED] has good experience in m robotics
2023-06-19 10:35:55,Folks any good read on business side of Google?
2023-06-19 10:36:36,https://stratechery.com/company/google/
2023-06-19 10:55:21,I also enjoy reading Not Boring by Packy M. He has a couple of recent ones.
2023-06-19 11:43:00,"I believe Balaji of Mitra Robotics is here in the group, can someone who knows him mention him?"
2023-06-19 12:44:36,Yes. We have been making social robots since 2020 for use in geriatrics.
2023-06-19 12:45:22,Balaji is my cofounder - happy to answer question about robotics and LLMs - DM me plz.
2023-06-19 15:48:46,1 trillion+ params for gpt-4? The other day I watched zuckerberg estimate that it was around 650B params.
2023-06-19 16:01:07,Anyone has the group invite link? Can you please add
2023-06-19 16:02:24,Did they use the circle diagram on Twitter as reference
2023-06-19 16:03:57,"I would trust this, but feel it's smaller"
2023-06-19 16:19:41,Also for folks in this group. We have tried writing an eBook from what we have learned through our conversations with different enterprises/startups using LLMs
2023-06-19 16:55:10,Plug 🤙
2023-06-19 17:26:00,2 questions for model deployment:
2023-06-19 17:28:17,Use Apache TVM or HuggingFace Optimum to optimize the models. This is not a logical optimisation...just a compiler optimisation. Quite safe in general
2023-06-19 17:28:24,"I'm interested in #2 - what kind of chat logging functionality do you expect? The standard logging library can be used, with chat and other history stored in DB tables. This is in addition to general app logs I guess"
2023-06-19 17:35:04,"Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library"
2023-06-19 17:36:59,Just the standard Python logger may work https://pypi.org/project/logging/
2023-06-19 17:38:56,I use this for logging: loguru.readthedocs.io/en/stable/index.html
2023-06-19 17:39:05,"I don't know if there are purpose built frameworks for logging chat history, that may be worth it."
2023-06-19 17:39:11,"My primary use case is often debugging logs, analytics logs are secondary"
2023-06-19 17:43:02,"From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/"
2023-06-19 17:44:41,Have seen Rasa features/docs referenced at least twice in the last few weeks here. :)
2023-06-19 17:45:23,anything similar for JS/TS ?
2023-06-19 17:46:16,It is quite robust so rightly being sited as well 🙂
2023-06-19 17:48:12,"The data structures/fields we care are similar between JS/TS and Python. The SDK/API for how to use those is quite often specific to workflows e.g. Support bots have the implicit goal of reducing interactions, while goal-oriented bots like sales want to do something different altogether."
2023-06-19 17:57:30,https://github.com/getzep/zep
2023-06-19 18:21:17,We implemented Rasa for an insurance company in the Middle East a few years ago. The experience was not good. I have not tried it recently with the ChatGPT integration.
2023-06-19 18:32:23,"We have had good experience so far with it. Currently experimenting with the ""intentless"" aka more conversational aspects"
2023-06-19 18:33:08,Very cool. Thank you
2023-06-19 18:34:02,"how do u use rasa for LLM applications ? is it like langchain - as in, do u tie prompts and chains using rasa proprietary SDK ? "
2023-06-19 18:41:44,I’m thinking of using Rasa only for engineering pieces such as logging. Whereas we rely on langchain and the like for LLM calls and prompt engineering
2023-06-19 18:41:45,We don’t build intent based chat bots anymore anyway - at least not in the way we used to
2023-06-19 19:25:21,"Given that RASA is a little heavy, are there not simpler tools for logging purposes? "
2023-06-19 19:37:46,"Yeah, I agree. It is easier to build custom frameworks or use Langchain, except perhaps where you're mixing intent based and LLM based bot workflows in the same app"
2023-06-19 19:40:22,Weights and biases is extremely good here.
2023-06-19 19:42:53,"[PHONE REMOVED] Thanks. Do you use cloud hosted or self-hosted w&b? I guess the personal / free tiers are for non-commercial use, so asking..."
2023-06-19 19:43:41,We already use Databricks extensively so there's a lot of overlap between what they offer (MLFlow centric) and W&B as well
2023-06-19 19:44:38,MLFlow doesn’t capture 1/10 the info compared to W&B for a training run
2023-06-19 19:46:17,"If just the parameter, model files, metrics is what you need ML flow is probably the correct fit, but if you want things like gpu/cpu utilisation etc w&b provides that"
2023-06-19 19:49:15,"Yeah, we aren't training LLMs or deep nets from scratch at the moment, so MLFlow suffices for our use cases. That said I see your point. Makes a lot of sense when training something much more involved. Our workflows have shifted to LLM backends almost entirely"
2023-06-19 19:49:51,Integration in databricks is straightforward btw - https://docs.wandb.ai/guides/integrations/databricks
2023-06-19 19:51:15,"I like W&B Prompts though, seems quite nice."
2023-06-19 19:53:40,i personally use self hosted. with some of the NBFC where edgechains is starting to be deployed - it is hosted of course. nobody wants to run infra if they can avoid it.
2023-06-19 19:58:36,"Indeed - even big banks and telcos are cloud users these days anyway and so many use PaaS, very attractive for good reasons despite the expense"
2023-06-19 20:07:59,using this extensively right now to debug some perf issues 😅
2023-06-19 20:40:57,That's really nice. Is there a similar feature in Langchain?
2023-06-19 20:46:50,Yes
2023-06-19 20:47:08,langchain server comes with tracing
2023-06-19 20:49:04,"Been a while since I used mlflow (moved to w&b), but I remember being able to fix most of the missing parts by monkey patching the classes. Moved to w&b because didn't wanted to maintain artefacts by myself"
2023-06-19 22:01:36,Just saw this on hn.
2023-06-19 22:17:06,"It's an interesting prospect to organise the open sourced LLMs in a single system. But each SoTA model brings something newer with it and the fine-tuning, RL space is especially volatile. "
2023-06-19 22:19:09,Bento has been around in the MLOps space for a while. The OpenLLM capability will really be nice for those building models. Not sure others using commercial APIs will jump on this
2023-06-20 00:33:26,OpenLlama vs Falcon. Any opinions here ?
2023-06-20 00:37:42,OpenLlama is very good and they've released until 13B parameter versions only but their performance is at parity with Meta's llama release.
2023-06-20 00:38:27,"Unfortunately, they don't seem to be trying to release bigger versions 33B and 65B for now so overall utility remains capped 😔"
2023-06-20 01:04:25,"We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there."
2023-06-20 02:02:26,He meant this https://arxiv.org/abs/2305.20050 I missed out on it.
2023-06-20 04:02:55,Really neat demo !
2023-06-20 07:20:11,Surprised the simple framework mentioned in the abstract wasn't paid attention to (pun intended) before. Quite interesting.
2023-06-20 09:01:40,Zuck will be GOATed
2023-06-20 09:55:36,"https://twitter.com/NirantK/status/1670957393403052032?s=20 - This Saturday, we have GenAI meetup hosting [PHONE REMOVED] and Amod. "
2023-06-20 09:59:38,"Description says ""May meet-up""..."
2023-06-20 10:01:11,Some edits required I guess.
2023-06-20 11:21:05,Can you explain this? Is this specific to code interpretor
2023-06-20 11:22:41,"Yes, and some specific plugins. "
2023-06-20 11:23:33,Ah yeah. Seen that. For gpt4 
2023-06-20 11:29:57,"There's also that ""Continue Generating"" button which appears for longer answers right?"
2023-06-20 11:30:32,"Yeah, but the button is almost always jankier. I like it a lot more when it just goes and does the thing in and of itself"
2023-06-20 12:00:33,Peeps who are intersted in Mechanistic Interpretability might like this conversation: https://twitter.com/MLStreetTalk/status/1670429782616469504
2023-06-20 12:03:06,Doing this in streaming is a challenge so eager to see how they have done it both from AI and software perspective
2023-06-20 12:03:26,Interesting format proposed
2023-06-20 13:58:24,"There's a tool called Slayer.ai which allows you to generate audio up to five minutes long, using a prompt. This is an example of a ""podcast episode"" I created with it https://app.slayerai.com/player/3c5983ff-6205-4bef-aaa5-378abd6150c7 - you can choose one of many voices, or a conversational format with 2 voices. The title of the podcast is all I had to provide. As with other generative models, this may suffer from hallucinations and other issues, and the content in it may not be accurate. That said, this was generated in five minutes, and the many YouTube farms which exist for putting content up are only going to benefit from this kind of thing. Worth exploring where the boundaries lie for keeping this kind of tech useful and what can prevent it from being turned into a spam and misinformation machine."
2023-06-20 13:59:42,"If you've questions for [PHONE REMOVED] or Amod e.g. around AI anxiety, code generation, FOSS vs Closed Source, Hardware optimisation and so on — ask! "
2023-06-20 14:00:20,"Made me think about a number of things here: a) can someone use this to feign subject matter knowledge, b) can this be more useful if I were to supply a transcript to it? c) where do we draw the line in terms of generative AI content for use in public forums, talks, videos, lectures..."
2023-06-20 14:03:57,cc Samhan [PHONE REMOVED] built https://hackerfm.com/
2023-06-20 14:04:38,Yes but it’s kind of inactive now. But you can check out the previous episodes
2023-06-20 14:07:13,I have thought about this - it’s actually not easy to make a talk / video that is interesting and engaging. But I do believe it’s possible to make content that is truly thought provoking.
2023-06-20 14:59:56,I’ve tried it.
2023-06-20 15:00:20,I think for question generation T5 is better
2023-06-20 15:02:03,7b-instruct was not great with in context learning and ended up repeating things in the prompt even though it was properly instructed. Ended up using Vicuña 7B which gave better results.
2023-06-20 15:03:59,Falcon 7B instruct base isn't good enough
2023-06-20 15:04:29,You need to use Falcon guanaco trained model for 7B or h2o ai trained falcon 7B
2023-06-20 15:04:42,https://huggingface.co/h2oai/h2ogpt-gm-oasst1-multilang-2048-falcon-7b
2023-06-20 15:04:59,I can't guarantee they will crack your use case perfectly but they're more coherent.
2023-06-20 15:05:22,https://huggingface.co/ybelkada/falcon-7b-guanaco-lora
2023-06-20 15:07:35,Any 7B model other than MPT 7B chat mostly talks nonsense in various cases. MPT 7B chat can even perform QA given context and thus RAG by extension.
2023-06-20 15:08:47,ok thanks guys will try the vicuna and MPT 7B.
2023-06-20 15:09:36,Falcon doesnt work with RAG ?
2023-06-20 15:10:16,"It works very well actually. And MPT isn't commercially licensed, has worse data, so I wouldn't touch it with a 10 foot pole."
2023-06-20 15:11:06,"As per my tests, Not very well at 7B base or instruct. But instruction tuned falcon 7B by h2o ai or guanaco lora do better."
2023-06-20 15:12:28,"Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style — which often makes perf better."
2023-06-20 15:15:40,Is there anyone from Adobe here? Esp someone familiar with their document services APIs
2023-06-20 15:20:13,"Not from Adobe, but I've worked with their WEM platform as a file repository"
2023-06-20 15:21:42,what do u mean by squad dataset style ?
2023-06-20 15:22:49,"Looking at the datasets used and recent papers like orca have highlighted, the need for high quality and diverse data. You have some capital how would you go about organizing this process?"
2023-06-20 15:24:51,Yeah 40B is definitely way superior. Actually there's a gulf of quality between the 40B and 7B models.
2023-06-20 15:26:21,SQuAD is basically how we traditionally used to test for QA performance in NLP.
2023-06-20 15:26:27,"I believe it means, the finetuning data is in the form of the squad dataset. Squad is an old qa dataset where question context and answer is there"
2023-06-20 15:26:41,sure. but nirant is talking about RAG in the squad style.
2023-06-20 15:26:56,how do u do RAG with the squad dataset style ?
2023-06-20 15:27:03,Rag is basically that but at a higher level.
2023-06-20 15:27:43,"If I was to guess, it should mean SQuAD format for QA and additional context for RAG."
2023-06-20 15:27:48,ok. i dont understand what that means. how i (or many people ) use RAG is by stuffing embeddings into context. so i dont understand what using RAG in squad dataset style is
2023-06-20 15:31:33,RAG is 
2023-06-20 15:34:51,"so i genuinely dont understand the meaning of word ""training"" here. are we discussing falcon finetuning ? i didnt know people were doing it. "
2023-06-20 15:38:27,"Yes, we can finetune Falcon with PEFT"
2023-06-20 15:39:40,PEFT was actually well explained by [PHONE REMOVED] in the meetup
2023-06-20 15:40:45,interesting. i was NOT aware of this. i thought falcon was not very successful with finetuning. any benchmarks on this ? just checking. playing a lot with falcon these days
2023-06-20 15:47:00,QLoRA + SFTrainer from TRL fine tuning of Falcon 7B was completed in just 30min on Guanaco dataset with 1x A100 80G GPU.
2023-06-20 15:48:08,"And it even works with T4 but you'd run out of disk space on free colab. If you've around ~140G disk space, it will take around 3h 45m on T4."
2023-06-20 15:49:14,There's no standardisation with fine tuning methods right now so you'll find lightning ai guys using adapter V2 mostly with Lora and some other 4 bit fine tuning methods also exist other than QLora like Falcontune.
2023-06-20 15:49:45,I've not tried all but one - QLoRA + SFTrainer
2023-06-20 19:44:39,Is Google Colab available or opensource framework for finetuning guidelines
2023-06-20 19:46:20,Falcon has finetuning with PEFT script: https://huggingface.co/blog/falcon#fine-tuning-with-peft
2023-06-20 19:56:30,"ElevenLabs — which I know lot of projects/startups to be running in production has raised $19M Series A from Gross, a16z:"
2023-06-20 20:16:44,https://www.linkedin.com/posts/genai-works_chatgpt-artificialintelligence-activity-7076858659376410624-tVpA?utm_source=share&utm_medium=member_android
2023-06-20 20:18:47,"Yeah, [PHONE REMOVED] shared this in the morning, I also called it a ""langchain killer"" "
2023-06-20 20:19:24,"The videos are quite impressive tbh, here is a 59s preview: https://www.youtube.com/watch?v=6SNfeVop4zM"
2023-06-20 20:21:37,"Thought that it was only an infra, they gave a feature to just plug and play it directly. "
2023-06-20 20:24:02,"Given that it's Microsoft, they'll first build even deeper Microsoft Teams integrations than anything else 🤣"
2023-06-20 20:24:25,And they've a Notion alternative of their own
2023-06-20 20:27:39,Very interesting. If anyone is interested in building a chatbot that gives you GPT4 interface on your document and have a Telegram bot - voice2voice very quickly they should check jugalbandi.ai 
2023-06-20 20:28:23,http://jugalbandi.ai/api
2023-06-20 20:29:15,"If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library."
2023-06-20 20:29:46,"Thanks for adding me, Nirant."
2023-06-20 20:33:44,SageMaker?
2023-06-20 20:37:06,my bad! yes.
2023-06-20 20:51:46,"Better data wins, proprietary data will be king maker in this case"
2023-06-20 20:55:17,*streamlit like service
2023-06-20 21:15:49,Guys has anyone worked on code retrieval tool for an agent. Like agent will get the relevant code from a vector store then it should fetch all the relevant code fragments like headers class def etc. Is there any implementation? Thanks!
2023-06-20 21:51:53,This course launched recently https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - taught by Matei Zaharia (Databricks) among others
2023-06-20 22:07:37,sumo
2023-06-20 22:09:07,I'm using the exact same GPU and model but interface is databricks. My inference is under 30s for a max of 200 tokens. Happy give your setup a look.
2023-06-20 22:13:23,"It's really cool, I had demo with the lead last week. Vector support is coming in July, but when that’s available and has good perf, it's can be killer for both Langchain and vector dbs. The response time without vector is also impressive right now."
2023-06-20 22:16:07,Prob some memory leak
2023-06-20 22:16:49,What does your resource utilization dashboard say?
2023-06-20 22:28:54,about the Azure OpenAI service well it is the replit vs enterprise software conversation. it is not unique to generative ai or azure generally speaking. 
2023-06-20 23:47:57,Does anyone know what hugging face embeddings do?
2023-06-20 23:48:18,I am using instruct from hugging face to generate embeddings and using falcon 7b for query
2023-06-20 23:48:24,Am I doing it correctly?
2023-06-21 03:12:49,https://twitter.com/soumithchintala/status/1671267150101721090
2023-06-21 07:27:32,Free community bootcamp or a paid event?
2023-06-21 07:27:59,Great initiative. 
2023-06-21 07:29:36,"Hi Pratik. There is a free component and a paid component. Most of our course materials we are building would be free, the live classes would be paid."
2023-06-21 07:31:27,"Thanks Saurav. One thing about architectures is as you rightly pointed out, things get outdated very quickly. We want to cover more of the foundations and concepts that has more shelf life. For instance, the underlying foundations of LLMs have not changed in years, while a lot of frameworks have arrived. We want to help students focus on the science and practical understanding of it and want to give tools and framerworks as additional reading."
2023-06-21 07:37:10,🤔 https://twitter.com/alexgraveley/status/1671213996735594503?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg
2023-06-21 07:45:07,That title bump must have been worth $100K min? Why is that being rounded to zero?
2023-06-21 07:49:35,"Mostly title bumps are not proportional to level bumps, otherwise he wouldn't bring it up as far as I know him. But then 🤷‍♂️"
2023-06-21 07:50:30,"If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in."
2023-06-21 07:50:34,"I'll take 4 to 1 odds that Geohot is repeating something he heard from some rumourmill without thinking. 8 MoE and 16 inferences, why?"
2023-06-21 07:51:29,"Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols"
2023-06-21 07:53:14,16 inferences makes sense. That could be the reason why openai dropped `best_of` from the chat completion models - because they’re already considering 4 candidate completions
2023-06-21 07:53:48,logits and best_of were dropped to prevent/discourage distillation
2023-06-21 07:54:29,How?
2023-06-21 07:56:07,I leave Defence Against Dark Arts as an exercise to the reader
2023-06-21 07:59:24,Yeah I'm guessing since he's making it public it was probably not worth anything else someone from Github would've called him out from it
2023-06-21 08:00:53,"People have been testing GPT4 for almost a year now, and I am surprised how profoundly they are able to keep it secret."
2023-06-21 08:02:17,SF rumor mill reports of strict NDAs for anyone leaving.
2023-06-21 08:02:24,"Friends, we've ~20 slots left in the group. "
2023-06-21 08:03:13,"OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc."
2023-06-21 08:04:16,Making Sam Altman is more dangerous than AGI
2023-06-21 08:07:03,Good set of topics. Only suggestion is maybe you could move 8 to 1 or 2. Will make the students appreciate the importance of data much earlier.
2023-06-21 08:12:15,https://lu.ma/generativeAIJune - says registration closed
2023-06-21 08:26:12,"The numbers might be off completely but earlier with GPT3.5, this was like the best guess in the market."
2023-06-21 09:07:19,"This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112"
2023-06-21 09:09:12,"For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval."
2023-06-21 09:11:35,🙏 I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. 🤯
2023-06-21 09:14:22,I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.
2023-06-21 09:15:13,Tortoise is FOSS and competitive to ElevenLabs for Western accents
2023-06-21 09:16:15,Thanks Nirant. I tried this too. I need it for Indian accents. Fails terribly and just ingests 5 seconds of audio.
2023-06-21 09:17:53,This paper and repofusion are definitely 2 really interesting picks of the day for me as smaller models achieving performance parity with models 70x their size
2023-06-21 09:20:19,"Models like these along with gglm and quantization are opening up so many possibilities for local inference. I earlier thought it will take couple of years for inference to come native on mobile level silicon, but it is happening so fast."
2023-06-21 09:21:57,"Yes, inference on edge is totally happening by end of 2023 in commercial capacity 🤞"
2023-06-21 09:22:11,"I am very skeptically of believing these results. More often than not, they've some data leak or distillation of some other sort going on. Or overfit to a specific task/dataset, not even domain."
2023-06-21 09:22:44,"*these => 20-30x smaller models, trained from scratch, no arch change kinda ideas"
2023-06-21 09:22:53,"True, that chance is there."
2023-06-21 09:25:17,Took me 10s to find the trick: 
2023-06-21 09:25:37,"phi-1 is from Microsoft Research, so hope they are not bluffing."
2023-06-21 09:25:39,"It's single line code completion, unlike what StarCoder or CodeGen does — and is specific to a repo"
2023-06-21 09:27:08,And the entire test eval is 200 Java repositories 🤦🏾‍♂️
2023-06-21 09:28:39,I thought they have -https://techcommunity.microsoft.com/t5/integrations-on-azure-blog/integrate-azure-open-ai-in-teams-channel-via-logic-app/ba-p/3776048
2023-06-21 09:30:56,Highest trust at the moment: 
2023-06-21 09:31:18,"OpenAI Evals is pretty good too, but not trusted for obvious reasons"
2023-06-21 09:32:02,"I track the leaderboards, but they are more through ELO ratings with head-head evaluations than by one standard benchmark applied equally across all of them."
2023-06-21 09:32:53,I take back. I see that they have added more benchmarks now.
2023-06-21 09:32:54,I'm confused. Open LLM Leaderboard does not have any ELO or head on comparisons
2023-06-21 09:35:31,I'm talking about the Human&GPT evaluations tab.
2023-06-21 09:42:20,sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.
2023-06-21 09:44:46,"Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups."
2023-06-21 09:46:39,"and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft"
2023-06-21 09:47:07,Without sacrificing performance
2023-06-21 09:47:37,Scaling can take us far and can result in a lot more emergent properties. There is no evidence against the contrary. However it doesn't make business sense to serve a slower beast.
2023-06-21 09:53:45,Seems parameter scaling works but data scaling laws are broken and at the least misguiding.
2023-06-21 09:53:51,"From what I have read, Sam has said the opposite of ""he also said scaling still works"" publicly."
2023-06-21 09:58:05,What are your thoughts on Yanns proposed JEPA - https://youtu.be/OKkEdTchsiE
2023-06-21 10:03:26,What is your guess on the other top 3 ways?
2023-06-21 10:05:20,"Bigger context, low bit lossless inference, task-based specialisations"
2023-06-21 10:12:22,Does the first 2 guarantee higher performance for usual text length gen? The last sounds like downstream task based finetuning unless you are referring to training different expert models (although I don’t understand clearly how do you decide expertise per model for training and routing for inference to these experts(maybe a classifier) or do you just merge all models weights by averaging?)
2023-06-21 10:15:49,Wikipedia search using the KE Sieve model. 36 million passages embedded. Small model index embedding size(544 dimensions) 2.3 GB. Large model index embedding size(2224 dimensions)-10GB.
2023-06-21 10:18:45,Project idea: semantic search on quotes 
2023-06-21 10:19:13,Isn’t google supposed to do this?
2023-06-21 10:22:24,"There's some drop in quality of inference currently for first 2 but that will be one of the ongoing areas of research with improvements like RMT/Longformer. For the third one, we already have routing functions/gating networks approach to first route the subtask to an expert then mix results together (haven't read how they mix it up finally)."
2023-06-21 10:22:29,It’s working a bit when you just check the images as google must have indexed emb of text found in image
2023-06-21 10:23:32,Bard does it pretty well. Bard is good with literature and quote and literature knowledge in general
2023-06-21 10:27:54,"Haven't read the I-JEPA paper yet, it's a completely different approach than LLMs"
2023-06-21 10:32:18,Thanks. I’ll try
2023-06-21 10:32:43,"Nah, it wasnt doing it"
2023-06-21 11:20:20,"Nothing is there for Indian accent voice cloning, yet. May be after Meta releases Voicebox weights, there is a possibility."
2023-06-21 11:21:12,Thanks Prateek. I will look up what's voicebox is.
2023-06-21 11:22:07,https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/
2023-06-21 11:26:21,"We trained Voicebox with more than 50,000 hours of recorded speech and transcripts from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese. "
2023-06-21 11:27:27,AI4Bharat has good Indian language corpus. https://ai4bharat.iitm.ac.in/datasets
2023-06-21 11:27:41,Yea meta one is cool but Hindi support not there 
2023-06-21 11:27:55,"They also have model endpoints for speech2text, translation and text2speech in Indian languages. Mostly works well, barring some translation issues here and there."
2023-06-21 11:29:11,https://github.com/OpenNyAI/jugalbandi-api/blob/main/translator.py 
2023-06-21 11:29:23,Is gpt-4 just an agent over several gpt-3.5 models? 😜
2023-06-21 11:31:29,(1) Let's see if they release weights
2023-06-21 11:31:32,But custom voice cloning is there?
2023-06-21 11:31:41,Yeah. Perfect
2023-06-21 11:33:07,"I have used those models, but have been complaining about production readiness for self-hosting."
2023-06-21 11:33:24,Oh it has become quite stable now.
2023-06-21 11:33:45,They are burning significant amount of GPU and have clusters of it
2023-06-21 11:35:03,I think this is possible 😅
2023-06-21 11:36:21,This was either a top quality hallucination or an internal step which was given as output
2023-06-21 11:36:22,As someone said (in this group) GPT4 works in mysterious ways 😅
2023-06-21 11:37:47,[Need help] Have a silly problem that our company's access to GPT4 APIs hasn;t come through. We have applied many times on the website with logical explanation that many things only work on GPT4 but silence .... has anyone else experienced it? Any workarounds or help to get the API access. (yes I have GPT subscription also). We were about to release a product and now this silly issue
2023-06-21 11:38:19,I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story
2023-06-21 11:39:33,"Can you link to google style MoE, for a better understanding  of how it actually works"
2023-06-21 11:39:56,https://paperswithcode.com/method/switch-transformer
2023-06-21 11:42:58,"There is also TaskMoE, which is a distillation mechanism"
2023-06-21 11:43:16,Blog: https://ai.googleblog.com/2022/01/learning-to-route-by-task-for-efficient.html
2023-06-21 11:48:26,This sounds like ensemble rather than Switch MoE
2023-06-21 11:49:25,So it is an agent over several 3.5 models. Then GPT-5 will be an agent over an agent. AI bureaucracy
2023-06-21 11:50:39,GPT-4 is a kaggler
2023-06-21 12:06:51,"[PHONE REMOVED] has asked me to remove this post. Will be doing it in five. If anyone else had a viewpoint to share in this time on posts related to hackathons and meet-ups and where they should go, happy to hear and learn."
2023-06-21 12:07:10,One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects
2023-06-21 12:08:00,Similarly for text to speech in Indian languages
2023-06-21 12:09:02,Any link to models for these too?
2023-06-21 12:10:17,"Not yet, but the plan is to publish datasets along with models"
2023-06-21 12:11:33,Whisper models?
2023-06-21 12:11:35,I see 2 languages so far. Which others are being worked on ? Is there a way to contribute ?
2023-06-21 12:15:10,Language info provided the website  Access to the couple of languages now available through ASRU challenge this year
2023-06-21 12:15:35,I see.
2023-06-21 12:49:24,Anyone here using WIT to convert user intents into actions for your products?
2023-06-21 12:57:21,what is WIT ?
2023-06-21 12:58:58,An older Meta AI product that’s used to understand user intent and convert to actions. Like a basic version of OpenAI functions.
2023-06-21 12:59:31,https://wit.ai/
2023-06-21 13:08:01,Ohh! Old memories from 2016
2023-06-21 13:32:51,More like nightmares 🤣
2023-06-21 13:33:54,"https://arxiv.org/pdf/2306.11644.pdf ""Textbooks are all you need"" - a small model trained on high quality ""textbook quality"" data"
2023-06-21 15:02:03,https://www.linkedin.com/posts/metaai_cvpr2023-activity-7076997142204055552-TCIC?utm_source=share&utm_medium=member_android
2023-06-21 15:03:31,Synthesia just raised 90 million for this.
2023-06-21 15:10:44,Is this similar to how gan.ai trains their model based on a 2minute user video
2023-06-21 16:01:12,"I use them fairly regularly. Even outside of AI voiceover, their feature set is pretty robust. And the interface is super intuitive and easy to use."
2023-06-21 16:21:31,"is it possible to share a private huggingface space as a demo externally, without exposing the code? Basically, I want to use huggingface hardware instead of self-hosting the gradio/streamlit app"
2023-06-21 16:48:03,There's a clumsy way I'm aware of. Possibly others know better.
2023-06-21 16:50:18,yeah I'm thinking of rolling it out publicly
2023-06-21 16:57:06,"There are ways you can hide your creds, if that's your main concern"
2023-06-21 16:59:48,not just the creds. there's secrets in HF for that. Asking for keeping the code private
2023-06-21 17:02:11,There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets
2023-06-21 18:06:28,https://twitter.com/MetaAI/status/1671211532599046144?t=IzhQ0OA72FgEadVfRvhx2g&s=19
2023-06-21 18:11:31,11labs works fine for Indian accents. What issues are you facing?
2023-06-21 18:12:44,"Well, I'll dm you. Long discussion. Thanks for the info tho."
2023-06-21 18:12:54,Sure
2023-06-21 18:18:37,"I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels."
2023-06-21 18:24:54,Is the openai function based on a paper? How to do it for an open model?
2023-06-21 19:36:29,"Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it"
2023-06-21 19:43:56,Interesting but might just be a feature on YouTube's roadmap
2023-06-21 19:46:26,"In most cases, I've seen that these YouTube summary extensions or apps support limited videos. Does this support every video?"
2023-06-21 19:50:05,Mistral raised its round just days after hiring staff using a Google Doc memo. Here is the doc
2023-06-21 19:50:30,Most of it theory yet the team is great
2023-06-21 19:51:50,"They are all big names in the founding team - deepmind, llama architect, etc"
2023-06-21 19:53:44,"""At the end of 2023, we will train a family of text-generating models that can beat ChatGPT 3.5 and Bard March 2023 by a large margin, as well as all open source solutions."
2023-06-21 20:01:05,Langchain does similar functionality using React
2023-06-21 20:06:51,i asked the same question today. i think all base models will need to put this feature as tablestakes. the usability advantage is too high.
2023-06-21 20:07:47,nope. openai functions magic is not function invocation - it is formatting the JSON to match the function signature. it is insanely hard to do this without the new release of openai. we have all struggled with jsonformer etc to match function signatures and it mismatches very frequently
2023-06-21 20:15:05,Have you tried this with gpt4? The non function model?
2023-06-21 20:15:48,How consistent is the output json using functions? I was reading somewhere that it still hallucinates
2023-06-21 20:21:39,Yeah these kinda stuff happens a lot. We don’t rely on a single model for classification. Ensemble your way to glory.
2023-06-21 20:22:35,"not sure, need to explore more"
2023-06-21 20:22:50,"Has anyone tried adding, gpt don't train using this data "
2023-06-21 20:28:22,"adding as in ""Add 2+2"" kind of thing?"
2023-06-21 20:31:49,Just append this line to your prompt
2023-06-21 20:37:39,These models need their training and inference data to be similar in encoding and patterns. 
2023-06-21 20:39:12,"Maybe other people have better methods but this is what I tried and use in my systems. Also, make sure that your training/inference characters aren't lost in encoding. In most cases, it won't but can't guarantee for everything."
2023-06-21 21:06:11,Encode? Convert to utf8 ?
2023-06-21 21:15:39,Does anyone have experience doing differential privacy for LLMs (fine-tuning)? I would like to have a chat about your experience.
2023-06-21 21:44:06,"Yeah *utf-8* is one kind of character encoding, I meant *unicode* character encoding as it has counterparts of it's own for each type of encoding to minimise information loss."
2023-06-21 21:45:07,"It's not guaranteed but its possible that you've some issue of having characters from different encoding in training and inference data. If the model doesn't recognise any kind of tokens, it'll go haywire typically. We want to keep the tokenisation of inference time exactly the same as tokenisation of training time."
2023-06-21 21:47:03,"This is hard because we are gathering data from all kinds of sources like docs, web or just tabular data. So encoding differences are a latent factor sometimes that drop the model performance. Take my word with a grain of salt as it's speculation on my part for what your issue might be."
2023-06-21 21:49:04,What do you mean by *Differential privacy*?
2023-06-21 21:50:54,Me thinks it has something to do with federated learning
2023-06-21 21:51:16,Differential privacy
2023-06-21 21:52:27,Thanks a lot 😄
2023-06-21 22:28:01,Didn’t expect VisProg to win the Best Paper award at CVPR 🤔
2023-06-21 22:38:12,"Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?"
2023-06-21 22:52:46,How many tokens are you generating?
2023-06-21 22:57:39,"There is a paper on cuad dataset, not a perfect match for what you are looking for--but you might find some interesting ideas"
2023-06-21 22:58:16,Yea I have tried it but it's specific for contracts
2023-06-21 22:58:28,Fine tuned deberta v2
2023-06-21 23:06:24,"How many urls are in the array you're passing? If there's a lot of Javascript in these websites, it can take a while for selenium to load the pages"
2023-06-21 23:06:53,Just 1
2023-06-21 23:07:13,DMing
2023-06-21 23:38:26,https://twitter.com/jsngr/status/1671561341893742592?t=w2UURl05_L5aKAndPmT50g&s=08
2023-06-21 23:38:41,Figma acquired diagram
2023-06-21 23:39:32,We'll see a lot more of this. The big guys who have scale distribution are going to lap up any good tools.
2023-06-21 23:39:59,It's a pretty neat exit ramp for small teams building in AI
2023-06-21 23:40:50,How does the selenium url loader work?
2023-06-21 23:41:10,I mean how good are the results
2023-06-22 00:07:38,How to downalod this? The download button is missing
2023-06-22 01:16:32,"The other option is trying to contact the jugalbandi.ai folks which ( according to my understanding, others correct me if I am wrong) exposes an API wrapper on top of the Bhashini models[0]"
2023-06-22 01:20:23,Here is a post from Saurabh of jugalbandi.ai team
2023-06-22 01:21:54,Bhashini doesn’t have a bhojpuri model
2023-06-22 02:05:51,"Hi all, what's the current consensus here on the best ai coding tool extension for IDEs?"
2023-06-22 02:06:53,You mean excluding copilot?
2023-06-22 02:08:25,Yeah. Copilot is good at keeping context of your whole codebase. But gpt 4 is way better when it comes to intelligence? Generates better tests etc
2023-06-22 02:12:52,"There's nothing that is even better than GPT3 in coding except GPT4. If you want to use GPT4 as copilot, try codegpt.co"
2023-06-22 02:13:28,If you've your own api key then GPT3/4 both are available for use in their extension
2023-06-22 02:14:14,Otherwise you can pay and use GPT4 for coding with their extension
2023-06-22 02:46:41,Was anyone successful in loading a gpt4all model?
2023-06-22 02:48:49,"You can load it easily via privateGPT, their chat client or directly via their python bindings."
2023-06-22 07:22:20,This is intriguing
2023-06-22 07:29:50,"Okay, this is the most ""Sparks of AGI"" behaviour I've seen! "
2023-06-22 07:33:02,Azure Quantum Elements is here to work with AI
2023-06-22 07:52:12,Does it have a world view of time ( response time )
2023-06-22 07:54:10,I don't know either way. But there is definitely some state information which OpenAI passes to the LLM. You can see this when you try to resume a stale Code Interpreter or Bing convo
2023-06-22 08:20:23,+1
2023-06-22 08:21:44,This is to create documents I presume? Or just parse complex legal docs?
2023-06-22 08:22:10,"And to what degree of customization? I've seen it do very well on boilerplate stuff like NDAs, and basic vendor agreements"
2023-06-22 08:23:25,"Actually to create documents, expert analysis out of legal docs. And create line of questioning etc. for the expert analysis"
2023-06-22 08:23:33,Have you tried a RAG system using one of the GPTs to generate responses?
2023-06-22 08:23:40,Interesting read on RLHF:
2023-06-22 08:36:12,https://arxiv.org/abs/2212.08073
2023-06-22 09:10:39,Just found out that I have access to chatGPT plugins. But there seem to to too many of them already.  
2023-06-22 09:20:08,Nothing in plug-in works as well as expected at least for me. I thought web search was going to be good but I the tool fails most of the time and it’s so slow I would rather use Google or Bard for it :P
2023-06-22 09:27:05,Try perplexity.ai
2023-06-22 09:29:03,🫡 Yes sir!
2023-06-22 09:35:11,open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.
2023-06-22 09:41:22,Something for [PHONE REMOVED] to consider adding to his OSS project maybe?
2023-06-22 09:41:29,Interesting!
2023-06-22 09:44:06,This is actually superb for us!
2023-06-22 09:50:55,It is still in the early stage. But it may give a good design idea.
2023-06-22 11:27:08,"Could it be because the Bing browsing plugin also uses a model trained on ""browsing journey"" style data?"
2023-06-22 13:11:19,Looks like a busy day for [PHONE REMOVED] today 😅
2023-06-22 13:11:47,"Just angry with Docker, but using it productively 😂🙈"
2023-06-22 13:13:12,Is there an easy way to not be angry about Kubernetes?
2023-06-22 13:13:21,Asking for a friend
2023-06-22 13:17:25,Looks like Nirant's spring cleaning day :D
2023-06-22 13:18:36,Just when you thought lay-off season is behind us
2023-06-22 13:19:50,Feeling anxious :D
2023-06-22 13:19:57,Are there folks still waiting for GPT4 API access?
2023-06-22 13:20:10,Cache eviction in progress.. :)
2023-06-22 13:20:39,Frantically checking WhatsApp every 10 seconds
2023-06-22 13:20:44,Woahhhh 😂😂😂
2023-06-22 13:21:00,"Haha, it’s like am I next?"
2023-06-22 13:21:11,"Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy"
2023-06-22 13:21:15,But like what is the criteria?
2023-06-22 13:21:21,reaching out over email might help. That's what we did
2023-06-22 13:21:28,Wonder how many people are messaging rn to ensure recent activity and avoid being kicked
2023-06-22 13:21:45,who was that marvel guy who snapped half the population out of existence
2023-06-22 13:21:48,Training data has reached cutoff
2023-06-22 13:21:52,[PHONE REMOVED] is that guy today
2023-06-22 13:22:11,Niranthanos
2023-06-22 13:22:24,No more data can Influence nirantgpt now
2023-06-22 13:23:01,<insert nervous laughter noises here/>
2023-06-22 13:23:03,Hello! 
2023-06-22 13:23:04,Squid Games: GenAI edition
2023-06-22 13:23:44,This is still open.
2023-06-22 13:24:54,What's your exact use case? I know flan family is very good but helps to know which use case is better than Falcon series.
2023-06-22 13:25:15,Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from
2023-06-22 13:25:51,Probably write a script to look for your name to be a forever lurker 😛
2023-06-22 13:26:29,Ig lurking is still acceptable if you remove the name :)
2023-06-22 13:26:34,But then they would be an active member no 👀😂
2023-06-22 13:26:58,I mark myself safe during the *Group purge*
2023-06-22 13:27:02,Does WhatsApp not provide APIs for user insights? If they don't they really should
2023-06-22 13:27:59,"Try applying for Microsoft for founders. You get access to their program, which provides azure credits and openAI as well. Maybe that can work. https://foundershub.startups.microsoft.com/"
2023-06-22 13:28:10,Viable Twitter based business model
2023-06-22 13:28:19,I'm in it but that just awards credits
2023-06-22 13:28:20,Not gpt 4 access afaik
2023-06-22 13:29:13,"Keeping access to this group has become more difficult than getting Claude access, thanks to Niranthanos"
2023-06-22 13:29:25,"It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)"
2023-06-22 13:29:55,Wait Nirant added someone🤯 ig cleanup is over
2023-06-22 13:29:58,[PHONE REMOVED] made his way back 🗣️
2023-06-22 13:32:47,"Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?"
2023-06-22 13:32:48,I never received my 2.5k open ai credits
2023-06-22 13:33:08,You have to avail the benefit in the founders portal I believe
2023-06-22 13:33:32,"Use tools like https://nas.io/whatsapp ? (not used, no affiliation)"
2023-06-22 13:33:57,yeah I did I also mailed both open ai and Microsoft support
2023-06-22 13:34:34,Might help to just sort this list alphabetically :)
2023-06-22 13:34:57,Oh. I actually never availed the openai credits. I thought of saving them for a usecase my startup might need later. Rn I'm just playing around with free credits and gpt+
2023-06-22 13:35:23,That's sad
2023-06-22 13:35:29,I thought they provision it like they did the azure credits
2023-06-22 13:35:33,yeah I am using azure open ai for all my prototypes
2023-06-22 13:35:57,there are many ppl facing the same problem
2023-06-22 13:36:20,"Since you're in the foundershub, would you mind telling me which stage you've reached?"
2023-06-22 13:36:49,Same here. Applied from both of my companies with real logical reasons but nothing but silence as dark as deep space :)
2023-06-22 13:37:16,I believe we can reach growth stage but the main barrier for me is incorporation in 2nd stage itself :(
2023-06-22 13:37:26,Cluster removal among discussion reminds of the last dinner scene of Don't Look Up 🫨
2023-06-22 13:37:38,oh created dummy start up just to get azure credits 
2023-06-22 13:37:44,Ah ok
2023-06-22 13:38:33,Yea the credits are definitely useful :). But I believe they require you to use them In a tenant and not personal account
2023-06-22 13:40:42,Pausing now. Stopped with 256 people to go. Felt like an shubh number
2023-06-22 13:46:46,seemed fun
2023-06-22 13:48:23,Not at all 😭
2023-06-22 13:48:36,You're free to pick up the next 256 and give it a spin 😅
2023-06-22 13:48:47,You can request higher.
2023-06-22 13:50:35,any programs where I could apply for Stability AI api credits as a startup?
2023-06-22 13:52:22,or wondering if Midjourney has a closed group of folks to use their official api
2023-06-22 13:52:31,Saw this thread reverse engineering gpt-4 speculated param number.. 
2023-06-22 13:55:31,"Midjourney does have an app that a closed group of folks have been given access to, but an API within it hasn’t been spoken about in their office hours from my understanding."
2023-06-22 14:08:37,edit access is not there how to remove ?
2023-06-22 14:10:30,We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.
2023-06-22 14:13:45,yes. there is very less commonality between the prompts that work for 3.5 and 4. 
2023-06-22 14:14:54,Any suggestions / materials I can look at to tune prompts specifically for each model?
2023-06-22 14:19:09,"In the article by Humanloop, author wrote OpenAI plans to use quantisation"
2023-06-22 14:20:21,There was something shared earlier about the 3.5 turbo models being quantised
2023-06-22 14:21:10,"Thanks, i have not seen that article, can you pls share link? Is this the sama interview article where he mentioned open sourcing a smaller model?"
2023-06-22 14:24:15,This was the article shared by another member of the group earlier - From Sama’s chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans
2023-06-22 14:24:38,The original article is removed so this one is an archive
2023-06-22 14:26:21,Seems you bookmarked 😬
2023-06-22 14:27:17,Noicee 👍
2023-06-22 14:33:29,Thank you
2023-06-22 14:50:35,Emerging architecture for Llm apps via a16z
2023-06-22 14:54:30,Good read for most people ramping up right now. Strong recommend.
2023-06-22 14:56:43,They have also released JS stack for prototyping AI projects - https://github.com/a16z-infra/ai-getting-started
2023-06-22 14:57:07,There was one from sequoia a week back which was more business focussed 
2023-06-22 15:00:41,#openai triton - any idea how much is the interest in writing custom  DL kernels in triton outside openAI? I haven't seen much activity in GitHub on this from folks outside openai. And any comparison between this and mojo from modular.ai(Chris lattner)?
2023-06-22 15:01:33,"Mojo isn't FOSS, and has no DL kernels yet to the best of my knowledge. They don't even have CUDA support?"
2023-06-22 15:02:51,https://twitter.com/gokulr/status/1671594605886976000
2023-06-22 15:06:08,"They had a few sample dl operator implementations in their YouTube videos,  Reg Cuda support, how are they doing GPU HW abstraction? - Direct metal support?"
2023-06-22 15:06:40,My guess was they would have a lowering from mojo thru mlir to ptx?
2023-06-22 15:07:02,"Aah, I'd missed the Youtube video. Would you mind sharing the link if you've it handy?"
2023-06-22 15:07:37,It was a couple of months ago. Will search and send.
2023-06-22 15:18:34,Here is the keynote 
2023-06-22 15:19:09,"Not directly related to GenAI, but has anyone here evaluated Hevo and Fivetran? Wanted first hand feedback / comparison of the two pipeline platforms. Pls DM"
2023-06-22 15:49:58,"Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background."
2023-06-22 15:55:58,Streamlit and Gradio may cover most of your demo needs in python stack
2023-06-22 15:56:12,"Hf gradio , streamlit"
2023-06-22 15:58:49,"I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time."
2023-06-22 15:59:27,I am really in awe of the twitter indie devs (pieter etc) who do all of this single handedly.
2023-06-22 16:00:34,also check Atri labs which is an Indian founding team
2023-06-22 16:00:35,https://github.com/Atri-Labs/atrilabs-engine
2023-06-22 16:02:21,https://gradio.app/sharing-your-app
2023-06-22 16:07:41,"we are trying to build the opensource production-ready SDK here (open source of course). am probably a week away, but happy to send it to you when up."
2023-06-22 16:10:05,"Thanks for all this pointers, I will check them out. Sure [PHONE REMOVED] I am looking forward to that, you will save me a lot of time!"
2023-06-22 16:12:47,"well, i dont know if i can claim to be all that grand !"
2023-06-22 19:09:10,Do we get kicked for not interacting here?
2023-06-22 19:11:36,"This is really frustrating. I miss consistency: given the same inputs (text, and params) will always give you same output"
2023-06-22 19:13:54,"Hey does anyone know how to request for more quota for vms in azure ML studios ,to get A10 or A100"
2023-06-22 19:29:59,Yes
2023-06-22 19:37:33,https://crfm.stanford.edu/2023/06/16/anticipatory-music-transformer.html
2023-06-22 19:39:13,cc [PHONE REMOVED] can you help?
2023-06-22 19:40:16,"cc Shubham [PHONE REMOVED] for all questions AWS including Bedrock, Code Whisperer etc"
2023-06-22 19:40:23,"Not just between 3.5 & 4, we’ve had to revamp our prompts with every new update for 3.5. I’m praying it becomes more consistent soon enough."
2023-06-22 19:41:11,Gets even worse when you use functions or ask it to return structured outputs
2023-06-22 19:41:32,"The deviations are quite high. Don't have quantifiable data on it, but qualitatively, you need to rework a lot of the prompts"
2023-06-22 19:42:55,Yes true and they upgrade it without much headroom for you to plan the migration.
2023-06-22 19:44:22,Prompt engineering is truly like playing whack a mole :)
2023-06-22 19:45:14,You can use the hack to make chatgpt act as prompt gpt. And then it would generate the prompts for you
2023-06-22 19:45:49,Interesting
2023-06-22 19:46:23,"I think someone mentioned streamlit already. I use it often and love it. Haven't used gradio as much as I want to though. What is preferable for a production grade app? Let's say that we need a smallish footprint as far as possible, responsive interfaces - which of these two works well? Or do we just use a custom react app of some kind?"
2023-06-22 19:48:04,"Isn't that the expected behavior tho, when you update a model and train it on more recent data?"
2023-06-22 19:49:25,"We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon"
2023-06-22 19:49:37,Something on streamlit*
2023-06-22 19:53:07,Not seen this
2023-06-22 19:54:03,Streamlit has problems in scaling you may try simple flask or any simple framework on kubernetes container apps aks and blah
2023-06-22 19:54:20,what problems streamlit has with scaling
2023-06-22 19:55:49,Try file upload and make aks multiple node you may see errors
2023-06-22 19:56:22,It is a known error which you will find in forums acknowledged by streamlit
2023-06-22 19:56:35,They may solve it later
2023-06-22 19:57:39,"so the issue is only with file upload, not with scaling ?"
2023-06-22 19:57:43,I got this problem and switched to flask
2023-06-22 19:57:56,"I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case. "
2023-06-22 19:58:42,This was the problem I faced  which was basic .
2023-06-22 20:00:28,Moreover this is a manifestation of a problem. The root cause is something more than file upload which I should have remembered but forgot
2023-06-22 20:01:25,Streamlit I use very extensively for my POC and demos to articulate something
2023-06-22 20:01:41,Much better than presentations
2023-06-22 20:02:07,Goodhart’s law will kick in pretty soon :)
2023-06-22 20:02:16,"Same, very fast uptime for POCs and demo."
2023-06-22 20:03:33,By this time all might.have realised that I am a fan of Streamlit and it is a boon for people who struggle with JS frameworks and HTML CSS
2023-06-22 20:07:20,JS frameworks are my antithesis 😂
2023-06-22 20:27:53,That’s awesome. Looking forward to it
2023-06-22 20:28:40,https://gooey.ai/explore/
2023-06-22 20:30:04,Exactly. That’s my experience with streamlit at least. Plotly dash is interesting too but beyond simple dashboards I haven’t built anything major with it. There are even very involved and hard core R Shiny apps out there. Depending on the use cases it may suffice for some teams. But streamlit is great for quick prototypes and proof of concepts.
2023-06-22 20:33:49,"There’s one design flaw with all 3 of these tools, and literally everone who’s built a python frontend framework has made too - to store per client session state on server over a websocket. This makes scaling impossible and client bundles huge for time to first render"
2023-06-22 21:06:12,How do you handle customisation? Is it possible to add responsive new components or modify components without knowledge of React js?
2023-06-22 21:18:13,https://huggingface.co/mosaicml/mpt-30b
2023-06-22 21:21:49,Seems damn cool. 8k context length. And beats almost all other open source LLMs expect WizardCoder on HumanEval.
2023-06-22 21:22:43,Mosaic has an unreliable history of changing license after release. Buyers beware
2023-06-22 21:27:09,Checking with my Infra team
2023-06-22 21:30:28,"Base model is still apache. Their chat and instruct models are cc-by-nc. Chat model is finetuned for 1.5B tokens for 6 epochs, so total 9B tokens.  Someone else might soon finetune on some other mixture of dataset. Hopefully something like WizardMPT."
2023-06-22 21:46:00,"Facing an issue with the utilization of the s3boto library in the langchain system. The library's unstructured file loader fails to effectively process files with formats such as PDF or any other file extension. As a result, there is no feasible method to stream S3 files into the system, taking into account their file types, and generate embeddings."
2023-06-22 22:03:18,And even the base model trained on datasets that have a bundle of licences. 2 of the 3 core datasets are ODC-BY and 1 - stack dedup is a bundle of licences which isn't clear from HF info
2023-06-22 22:03:59,The chat and instruct models are still CC by NC so nothing changes there for commercial use.
2023-06-22 22:42:16,https://inflection.ai/inflection-1
2023-06-22 23:00:52,"Wow they're claiming they outperform even GPT3.5 on MMLU, PiQA, Hellaswag, boolq, naturalQA and GSM8k"
2023-06-22 23:03:20,came across these 2 useful links :
2023-06-22 23:12:25,7 pager memos ftw 🙌
2023-06-22 23:29:22,https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html
2023-06-22 23:36:32,they should publish the model card instead of marketing keywords.
2023-06-22 23:37:06,Have they generated the keywords using the model though?
2023-06-22 23:40:54,"They're calling inflection-1 to be in the same compute class as gpt 3.5 and palm 540B. Also 1000s of H100 would mean that their size is huge, probably upwards of 200B? can only speculate."
2023-06-23 00:20:17,I'm not sure how many people here are familiar with GOFAI techniques. There is a lot of history to symbolic AI which was powering lots of simple systems before Alex and Ilya showed how to train NNs more efficiently. We have reached a point where there are 2 broad approaches in front of us and it's not clear which one will lead to AGI sooner:
2023-06-23 00:30:05,"For #1, I found a overview/survey paper from 2022 - https://academic.oup.com/nsr/article/9/6/nwac035/6542460"
2023-06-23 00:34:51,"I'm also interested in being able to teach an abstraction to a language model directly, rather than train things via unstructured data or instruction format. A language model is representative of the abstract relationship between different entities and concepts in the training data, so I was thinking if I can draw out the abstraction or update the abstraction directly via some reasoning inputs."
2023-06-23 00:45:49,could u explain the two problems ur facing ? 
2023-06-23 01:21:00,Need advice on two things
2023-06-23 01:22:07,Are you wanting to implement streaming with openai models or with other models
2023-06-23 01:24:42,"Local model, say falcon or llama"
2023-06-23 01:34:37,https://huggingface.co/blog/sagemaker-huggingface-llm
2023-06-23 01:46:34,I checked this post. It abstract the implementation and gives the container for deployment purposes. I'm interested in learning the mechanics of it but thanks anyway.
2023-06-23 02:01:54,"I've been working on a few use cases where LLMs can help non profits and charity events, is anyone else working on similar areas? happy to join forces"
2023-06-23 02:55:58,Would something like chain of thought prompting and ReAct etc be considered to come from symbolic AI?
2023-06-23 06:53:52,https://twitter.com/OfirPress/status/1672021765135151107?s=20
2023-06-23 07:53:02,DMing you
2023-06-23 08:03:01,"Interesting question, but CoT is not really GOFAI which are highly interpretable. Tree of thoughts is more closer to a GOFAI module where a clear algorithm (just handcrafted heuristics) is driving the control back and forth between the LLM and a DFS/BFS tree parser. ReAct, Flare and other lookup methods help with information reuse. I see them as external memory modules, not compute. Here is an example of how I personally see a successful GOFAI module integrated with an LLM:"
2023-06-23 10:38:43,"Not tried yet , any link how to start with RAG plus gpts (one concern here documents are to be  private)"
2023-06-23 10:41:18,You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)
2023-06-23 10:44:24,Which asr APIs does this use?
2023-06-23 10:46:47,Bhashini by default but it support Google and Azure as well
2023-06-23 10:50:27,"Wait a  sec, https://asr-api.ai4bharat.org/asr/v1/recognize/ takes no api key?"
2023-06-23 10:53:37,https://github.com/OpenNyAI/jugalbandi-api/blob/bf28c720719f211d28f3239fc55835e267e0a7cf/translator.py#L58
2023-06-23 10:53:46,nope
2023-06-23 10:54:31,Does anyone know if there is a way to export Pinecone indices and/or collections?
2023-06-23 10:54:54,We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.
2023-06-23 10:55:13,"I’m not sure what is [PHONE REMOVED]’s experience is but for me both on-premise and APIs didn’t work out in production. Didn’t work out means consistent latency wise. I’m not sure if they added more resources after that, so it could have changed."
2023-06-23 10:56:10,Don't know how to but curious what lead you to this decision? Might be useful for others as well.
2023-06-23 10:57:39,I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.
2023-06-23 11:03:55,"For production grade, speech models for low resourced indian languages like Bhojpuri or Haryanvi, what would you suggest Saurabh ?"
2023-06-23 11:04:51,Azure has better speech to text for indic languages? 😵
2023-06-23 11:06:10,It would be useful to have a primary DB where all of the indexed data is stored. Seems you are on OpenAI emb. Moving to open source emb will eliminate reindex cost issue. But that’s a research effort.
2023-06-23 11:06:44,"Na na. Wait. 😅 multiple things, model quality, GPU availability. My recommendation isn’t with respect to just model quality but also production readiness"
2023-06-23 11:07:37,Ok sorry talking about model quality 😅
2023-06-23 11:07:42,"We are not seeing good retrieval quality on Pinecone for a production level system. When embedding thousands of documents, it is giving irrelevant results. "
2023-06-23 11:08:28,"That's why we moved completely to Azure like two months back, and have Bhasini, and GCP as first and second backups. I have talked to Azure speech research team and also heard from other folks using Azure. Other reason being MS team working closely with Bhasini."
2023-06-23 11:09:23,"How ever we signed MoU with Intel where they want to help on scale for Bhasini, and then working with some Indie hacker folks to see If I can optimize Bhasini models for production."
2023-06-23 11:09:36,"Yes, we are using OpenAI embeddings. Haven't tried the other embeddings yet. How does it compare in terms of the quality?"
2023-06-23 11:10:21,why would u need to re-embed the data ? genuine question - does pinecone transform the data formats to make it non portable ?
2023-06-23 11:10:43,I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug.
2023-06-23 11:11:28,As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db.
2023-06-23 11:11:35,And pinecone also has hybrid search
2023-06-23 11:11:44,"But openai api does it keep docs private,here concern is they don't want to use chatgpt or openai as it's legal documents it might get leaked..not sure"
2023-06-23 11:11:55,"I don't have bandwidth to work on models for quantization or oprimization, so I am taking help from any where possible. Bhasini should be optimized for production and we should be able to host and run optimally, otherwise all the hoopla after Sama's comment will be just chest bumping."
2023-06-23 11:12:10,Similar metrics as per benchmarks but would still require testing to see if it’s actually true
2023-06-23 11:12:30,i did NOT know that pinecone doesnt allow export.
2023-06-23 11:12:41,That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.
2023-06-23 11:13:22,"Right, will try that."
2023-06-23 11:14:41,Are you referring to the tokeniser problem? Pinecone also has support for SPLADE which would bump performance hopefully. I don’t know if others have it
2023-06-23 11:15:51,SPLADE hybrid > Emb model tokeniser hybrid > simple tokeniser hybrid
2023-06-23 11:23:17,https://www.pinecone.io/learn/hybrid-search-intro/
2023-06-23 11:23:39,What do u mean by pinecone has support for a tokeniser ? Cos tokenisation and embedding generation would happen BEFORE insert into vector db.
2023-06-23 11:23:39,It seems to be in private preview right? Have you tried it?
2023-06-23 11:24:23,Any db would be agnostic to the input tokeniser u use to split your data right ?
2023-06-23 11:25:18,I haven’t tried it yet. It’s a 3 month old blog and I think it must be GA now.
2023-06-23 11:28:20,"In my understanding, Pinecone supports sparse vectors which allows indexing with any tokeniser while the other ones does not expose this and handle tokenisation internally for hybrid."
2023-06-23 11:29:15,"Yeah, there was also some nvidia research in this area last year. It was SoTA at that time but don't know the current status for eye positioning."
2023-06-23 11:29:45,For hybrid you need one hot token vectors also to be indexed
2023-06-23 11:30:28,You can come as you please but you can't leave the same 😂
2023-06-23 11:33:06,Getting quite costly too
2023-06-23 11:34:26,I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.
2023-06-23 11:34:35,Do Qdrant and Weaviate allow export?
2023-06-23 11:34:47,Qdrant does I believe
2023-06-23 11:34:55,"Hi Saman, I'm the co-founder of Typesense (https://github.com/typesense/typesense). We support hybrid vector search in the upcoming version and as well as automatic embedding of content using E5 model (both on CPU and GPU). Happy to chat about it or anything related to embeddings/search."
2023-06-23 11:35:29,We just went with them because they seemed the most prod ready but at this point probably a good idea to move out
2023-06-23 11:37:37,Did not find anything on google!
2023-06-23 11:39:01,How to solve this issue
2023-06-23 11:39:05,Which open source solution do they prefer?
2023-06-23 11:39:58,I like and use weaviate
2023-06-23 11:40:33,"Dev mentioned this yesterday as what they implemented - ""We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon"""
2023-06-23 11:40:40,Store state on the client and do server side rendering. I’m using HTML forms too for state so it all works even after disabling Javascript
2023-06-23 11:40:43,"Hey Kishore, happy to test it out. Is anyone else using this on prod right now?"
2023-06-23 11:41:30,but how to do streaming in that case ?
2023-06-23 11:41:54,You underestimate marketing. Also openai pinecone arrangement
2023-06-23 11:42:24,Redis pub/sub + server sent events
2023-06-23 11:43:20,Isn't pub/sub a 2 way communication and server sent one way communication?
2023-06-23 11:43:46,"We have had pure vector search for over a year and so many production users. We've implemented hybrid search for the next version (due for release in a few weeks) and we have been testing the RC build with customers, some of whom are using it on production as well. We also support openai and google vertex embedding integration out of the box. I can share details on DM."
2023-06-23 11:43:54,I was recommended to use weaviate by OpenAI from the early days of KissanAI 🤷‍♂️
2023-06-23 11:44:41,When was this? The pinecone partnership came out in March with the launch of plugins
2023-06-23 11:45:20,Yes. But only use redis as one way publish to push to clients from long running tasks in the server
2023-06-23 11:45:22,Before that
2023-06-23 11:45:38,Cool
2023-06-23 11:46:27,Pinecone had done a huge announcement of their partnership in March and later also raised a ton on money. I'm assuming for marketing purposes
2023-06-23 11:47:08,Yes. Had used in an earlier project which involved rabbitmq
2023-06-23 11:52:20,What vector db is recommended to use for prod right now?
2023-06-23 11:52:50,"Also, for open source dbs, are folks self hosting or using hosted versions?"
2023-06-23 11:52:56,"Related question - how does Pinecone compare to the likes of Milvus, Weaviate?"
2023-06-23 11:54:56,"Also, has anyone tried Mongo vector db yet? Any benchmarks?"
2023-06-23 11:55:50,Is there a good study published on what different GenerativeAI companies are doing currently and what kinds of trends are emerging across? Preferably not from a VC's perspective
2023-06-23 11:57:18,"Interested for the same, currently using pinecone for testing but want to move out before getting locked in some way"
2023-06-23 11:57:18,Not sure who else (what persona) will keep track of the market if not VCs
2023-06-23 11:57:26,redis/elasticsearch thats what we integrate in edgechains
2023-06-23 11:59:34,Sounds controversial to me
2023-06-23 11:59:34,oh so u save both the embeddings and the one-hot together ? and then pinecone internally tokenizes the one-hot. this is something i had no idea that was how hybrid search worked.
2023-06-23 11:59:36,How does Elasticsearch perform for hybrid search? Any thoughts?
2023-06-23 12:00:27,Costs are blown up for vector search as well IMO
2023-06-23 12:00:43,fairly built in. u can create composite rankings or for advanced usecases create a plugin. 
2023-06-23 12:00:46,Kindly do not go that path
2023-06-23 12:01:29,there's no hybrid search in qdrant. is there?
2023-06-23 12:01:38,i know of several banks and LARGE enterprises that are running this in production. redis and elasticsearch are the only game in town if u need compliance as well. no other db is getting ISO/SOC2 certifications in india.
2023-06-23 12:02:01,incidentally Elasticsearch is the only exabyte scale infra that i know of. so i will respectfully disagree
2023-06-23 12:03:47,Pinecone has soc2 no?
2023-06-23 12:07:19,I think both Weaviate and Pinecone must have soc 2 type 2. My disagreement is more because of cost and latency. Selection will depend on how many vectors are indexed & latency. In some cases ES would work out.
2023-06-23 12:07:33,"wont transitively pass in india. in india, ull have to recertify. they are not passing it. "
2023-06-23 12:07:58,It has Gong as customer. So definitely type 2
2023-06-23 12:08:32,"AI grant has scaled to >$1M per winner, no equity"
2023-06-23 12:09:03,again challenge to prove. all of them are using HNSW lib underneath. elasticsearch also. with the added future outlook that Java Panama vector API is being natively built into elasticsearch https://github.com/apache/lucene/pull/12311 
2023-06-23 12:09:54,"this means that in a year, we will have GPU SIMD accelerated vector search built into ES via Panama. I think thats a great bet."
2023-06-23 12:10:09,Okay I do not have clarity on the PII scrubbing and storage
2023-06-23 12:12:43,How easy/difficult is it to fine tune Whisper for different accents or special terminology?
2023-06-23 12:12:56,Interesting take. Maybe later everyone converge to similar and it boils down to implementation efficiency of Rust(Pinecone) Vs Java(ES) Vs Go(Weaviate)
2023-06-23 12:14:17,i wouldnt look at it that way. i will say that pgvector has AWS managed support (https://aws.amazon.com/about-aws/whats-new/2023/05/amazon-rds-postgresql-pgvector-ml-model-integration/) and Elasticsearch and redis have the same. 
2023-06-23 12:14:51,"I had conversation with Hersh, for Indian startups you will need Delaware corp if selected."
2023-06-23 12:17:33,How many vectors are you looking at and what are the dimension sizes?
2023-06-23 12:19:40,Anyone working on ETL/DevOps automation using GenAI? Have a few ideas would like to discuss
2023-06-23 12:20:35,That’s great! My thinking is more around cost and latency rather than security (assuming all can scale well). It will be helpful if we find any analysis on this front to compare them all.
2023-06-23 12:21:42,Let’s say 10M single index no filtering 768 dim
2023-06-23 12:37:22,"Interesting , any other benefits of raising from them over VCs apart from no equity?"
2023-06-23 12:40:58,They are better than most VCs? And compute cluster larger than clouds?
2023-06-23 12:43:14,Compute part is clear .
2023-06-23 12:43:42,They know what they're talking about? 🫣
2023-06-23 12:46:53,"Makes sense , was hoping if someone could speak from personal experience ."
2023-06-23 13:52:44,"Happening today, organized by Nathan Benaich"
2023-06-23 14:03:56,"Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework"
2023-06-23 14:07:29,"I've tried it. It's amazing when it works,"
2023-06-23 14:15:20,"Aside, for the meetup tomorrow, please ping [PHONE REMOVED] for invites. He's the one making the invite list. Not me. "
2023-06-23 14:49:29,https://twitter.com/karpathy/status/1671587087542530049?t=864c5-CnpaISCvt8vNSYYw&s=19
2023-06-23 15:08:04,Does anybody have any reviews about the courses from Nic Renotte?
2023-06-23 15:08:19,Or any other beginner friendly course recommendations?
2023-06-23 15:24:50,This one is for beginners https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - nice course by Databricks featuring Matei Zaharia and others
2023-06-23 15:39:30,Any product folks here building in Generative AI ? I'd like to pick your brains on an MVP that we are set to launch.
2023-06-23 15:39:31,?
2023-06-23 15:44:07,"If you're comfortable sharing a quick preview, lot of builders would be happy to share feedback!"
2023-06-23 15:51:38,We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question
2023-06-23 16:00:52,"We're building genAI products in my team, happy to chat"
2023-06-23 16:13:30,"It'll help to know what Gen AI is capable of first whether in terms of audio, vision or text fields. "
2023-06-23 16:15:26,"By knowing what's possible in vision, audio and text you can then chain these things together to create a completely new product as well. For example, given an image of clothes that a person has in their wardrobe we can answer 2 questions easily:"
2023-06-23 16:15:41,"It's just an example. But along these lines, knowing what's possible allows you to think of replacing existing features or add components in your product. Or build a completely new one from the ground."
2023-06-23 16:47:08,I lead product. Happy to brainstorm.
2023-06-23 17:03:54,Lead ML at my firm - and we have couple of GenAI products to go to production pretty soon next quarter. 
2023-06-23 17:04:10,Happy to help 👍🏽 .. currently working on MVPs in financial services
2023-06-23 17:24:47,I think for this range almost all vector DBs work fine. ChromaDB with a local file system should also work. I have run it for 1 million index with no issues.
2023-06-23 17:30:24,Correct on this.
2023-06-23 17:32:37,"For the love of God, please don't use Chroma and shoot your mem utilisation to the roof"
2023-06-23 17:38:08,https://twitter.com/rowancheung/status/1671893629751939077?t=xotImYsHeIRPrJiTcnGw7g&s=19
2023-06-23 17:43:42,https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/
2023-06-23 19:12:09,What are some good open source data annotation tools?
2023-06-23 19:13:17,CVAT works really well for image annotation
2023-06-23 19:14:36,Looking for text.
2023-06-23 19:15:30,Have you tried doccano?
2023-06-23 19:16:28,"had tried a while back, will check again."
2023-06-23 19:19:53,"for cloud based nosql dbs , which one gives the best amount of storage on a free tier, like over a GB. Mongodb atlas gives around 512mb"
2023-06-23 19:33:15,Argilla
2023-06-23 19:35:10,"also a city in Italy, TIL"
2023-06-23 19:40:24,TIL too
2023-06-23 20:00:13,https://twitter.com/ericmitchellai/status/1671943972829433856?t=QQK1NbVYt_04XuvWj_Sarg&s=08
2023-06-23 20:01:37,Found this implementation for DPO RLHF yesterday. It doesn't need reward models or RL. It's a simpler way to do RLHF or to learn for reference.
2023-06-23 20:17:53,If you are doing something related to segmentation you could additionally use Segment Anything Model (SAM) to speed things up
2023-06-23 20:37:03,AudioPaLM: A Large Language Model That Can Speak and Listen 
2023-06-23 20:54:59,Yea but only if meta and google release api for commercial use. Demos look hot.
2023-06-23 20:56:34,100% expect commercial api by Google by the end of the year 
2023-06-23 20:58:58,Absolutely.. this has huge potential in both streaming and podcasting industry
2023-06-23 21:00:08,"On that note, what’s the best lip synching and face morphing library you guys have seen (to go with text to speech Audio)"
2023-06-23 21:01:36,"You could listen to a French podcast, in Hindi, for example !"
2023-06-23 21:01:40,"And, elevenlabs updated their model as well haha marketing teams fighting out for the voice share "
2023-06-23 21:04:50,Indeed.. when Zuck announced first time on his Instagram broadcast channel.. I was shell shocked..because it was done without huge media fanfare or publicity.. I am bullish on Zuck through his open LLMs and such cool features announcements almost every week
2023-06-23 21:07:29,"In academia, Prof Jawahar's group at IIIT Hyderabad has done amazing work on lip reading and lip syncing in video "
2023-06-23 21:07:30,Deep Fakes tools does it well.. but that dilutes authenticity.. here with audio Palm it still retains the original with runtime speech or voice modifications and translation
2023-06-23 21:09:37,Do they have an API. Don’t see on their site.
2023-06-23 21:10:06,Suggest options with commercial api availability please for lip synching 🙏
2023-06-23 21:10:48,Yeah and movies wouldn't need to be dubbed in any language at all. Probably not so good for voice actors.
2023-06-23 21:11:09,"More research-y, less product-y"
2023-06-23 21:30:24,https://www.thehindubusinessline.com/info-tech/way2lip-promises-to-reduce-drudgery-in-video-content-creation/article65388110.ece
2023-06-23 21:31:32,https://www.neuralsyncai.com/#products
2023-06-23 21:35:18,You could contact him:
2023-06-23 21:45:09,Agree with FAISS
2023-06-23 22:13:47,*Most curious thing I read today -* https://kaiokendev.github.io/til#extending-context-to-8k
2023-06-23 23:05:30,"Have tried to use elasticsearch (opensearch, on aws) as vector index with their approx knn plugin. Faced a lot of issues where the knn circuit breaker would get triggered, after which no index operations could be performed and search would slow down significantly. At the peak, for around 12M vectors (with some metadata), we were using r5.2xlarge instances with 6 data nodes and 2 master nodes (with 200gb ebs volumes), costing around ~$2k/month. "
2023-06-23 23:09:37,"elasticsearch does have pre-filtering with cosine similarity on dense vectors right ? it uses the SHOULD array and u can combine them both. so ""match"" will have ur filter query and script_score will have ur cosine similarity"
2023-06-23 23:14:51,Is there a repository or list for AI tools to make music?
2023-06-23 23:15:13,yes. 
2023-06-23 23:15:22,How has the experience with weaveate been?
2023-06-23 23:18:09,yes. ANN is already in. been a year. not sure if this is exactly what you want...but it is the general usecase that many use. 
2023-06-23 23:25:10,"I am looking for a dataset or service providing company name aliases. For example HP == Hewlett Packard, PWC = Price Waterhouse Coopers."
2023-06-23 23:30:00,"Pretty good. It has handled whatever load we've thrown at it (around 16M vectors), the community is good, and they're actively releasing new features"
2023-06-23 23:32:28,Nice! Are you using their hosted version or self hosted? 
2023-06-23 23:33:28,I think for the hosted version they charge both for vector dimensions as well as queries whereas other dbs only charge for storing N vectors.
2023-06-23 23:46:10,"Ah, this recent finding has been used many years ago but just in a different context. It's extremely similar to Convolutional Recurrent Neural Network, by authors whose names I don't recall. "
2023-06-23 23:47:01,Who knew you could achieve that just by changing a line or two in transformers based LLMs
2023-06-23 23:50:05,https://arxiv.org/abs/1602.05875
2023-06-23 23:50:23,AI of 2016 still relevant today
2023-06-23 23:51:44,Hope newcomers in the field take this as great motivation. The field is not moving too fast for you to feel out of control. Significant contributions can be made if you understand the insides of these supposed black boxes.
2023-06-24 00:12:02,Convolution layer was pretty much the de facto feature extractor before transformers
2023-06-24 00:13:17,"Still is, for images"
2023-06-24 00:14:10,"ViT hasn’t been widely adopted, especially for memory/compute constrained edge deployment"
2023-06-24 00:52:50,Which model is being describes here?
2023-06-24 00:55:43,Context
2023-06-24 01:10:57,"has anyone successfully run HF transformers pipelines on mac m1 chip? whenever I try a model, there's some or the other unsupported pytorch operation"
2023-06-24 01:14:47,I don't exactly remember my pytorch version but I didn't face any issues on M2 pro. It could be an issue with your config.
2023-06-24 08:26:10,This is exactly what we are using and not faced any issue. But we don't have 1M records though. But latency is low and we have all data together in postgresql. Only one component we need to monitor at production.
2023-06-24 09:01:00,A businessy article from me for a change :)
2023-06-24 09:24:43,"Absolutely. Look at deBERTa eval scores for example and if you’re use case fits then BERT based models can take you much further, sometimes even more than massive unwieldy LLMs."
2023-06-24 09:28:18,Also https://github.com/BlinkDL/RWKV-LM for old+newer approaches
2023-06-24 12:15:48,"Hey folks, Udit here! "
2023-06-24 12:16:55,Congratulations! What’s layer 2?
2023-06-24 12:19:40,Where AI's responses are not only limited by GPT's data sources but trains upon your data for precision + GPT for generating answers.
2023-06-24 12:19:54,You can find more about it on OpenAI docs
2023-06-24 12:39:55,Any link to docs &/ casestudies ?
2023-06-24 13:01:43,"Hey, would love to chat more. Ping me :-)"
2023-06-24 13:21:24,"""Layer 2"" is simultaneously the best and worst branding I've seen for a Colab notebook. Impressed with the mktg chops on this."
2023-06-24 13:23:51,"Invites are against email ids, no swaps"
2023-06-24 13:25:01,What’s the venue?
2023-06-24 13:26:00,Shared with invited folks. Will email maps and navigation instructions around 3:30 PM
2023-06-24 13:28:00,Please ping [PHONE REMOVED] for the invites and approvals. He's the one sending them out
2023-06-24 13:32:31,https://github.com/OptimalScale/LMFlow
2023-06-24 13:32:53,https://github.com/OptimalScale/LMFlow
2023-06-24 13:34:30,https://github.com/neuralmagic/deepsparse
2023-06-24 13:35:09,Has anyone tried this neural magic ?
2023-06-24 13:44:49,Sure
2023-06-24 14:06:03,I’m not in it seems. But I understand. Hopefully next time.
2023-06-24 14:18:31,This is interesting.
2023-06-24 15:32:35,Folk's what are the topics for today's meetup ?
2023-06-24 15:58:26,https://hasgeek.com/generativeAI/june-meetup/
2023-06-24 16:00:28,Your mention of deberta reminded me of this list of models trained by Microsoft.
2023-06-24 17:57:53,is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ?
2023-06-24 18:07:44,I got access to LLm powered chatbot.
2023-06-24 18:09:08,I doubt such queries will be passed bu their checks if open ais api is used
2023-06-24 18:09:18,This could be an older model like da vinci or maybe even a custom model
2023-06-24 18:09:48,Yes they're using da vinci-003
2023-06-24 18:09:57,It was awesome
2023-06-24 18:10:41,I tried and deployed cost of inference hardware would be around 7 dollar per hour
2023-06-24 18:18:43,were u using ml.m5d.24xlarge ? 
2023-06-24 18:30:35,Yo can try Serverless deployments for saving infra cost
2023-06-24 18:35:02,"Along with the default ""you are a fintech expert ..."" prompt, you cab additionally place checks like ""for every question asked, evaluate how relevant the question is, answer only when...."" etc"
2023-06-24 18:36:34,"Most likely they're doing this, but this won't work for da Vinci models that well. Which also happens to be the default in langchain..."
2023-06-24 18:39:30,Langchain default being terrible is something which escapes me
2023-06-24 18:39:54,I think we expect too much of a servile  attitude from LLMs. I think I want LLMs which when asked “do you hallucinate” with “don’t you?” as the response
2023-06-24 18:42:05,Microsoft learned from their Tay experience.  iykyk 😂
2023-06-24 19:20:08,You want generation to only be restricted to your context. That's prompt engineering
2023-06-24 19:21:23,"Prompt validation, may be ?"
2023-06-24 19:22:20,Prompt engineering works well here. We've done it with prompt engineering for our retrieval based generations to not hallucinate pretty well
2023-06-24 19:22:31,A trick I use is to ask the LLM to not use their own knowledge and only the one in the prompt that ensures it's grounded
2023-06-24 19:23:32,Provide directions in markup
2023-06-24 20:06:32,May I have the group invitation link ?
2023-06-24 20:10:20,"Hi, I had a few questions about testing chatbots. We've discussed options here like Rasa's testing capabilities before but I'd like to know if there are any test case or test plan strategies someone is already using for LLM based testing. For instance - how do we deal with variability in LLM output? Does vector / semantic similarity matching work at scale for evaluating such outputs? Are there any other ways to test chat bots?"
2023-06-24 20:23:52,I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp
2023-06-24 20:24:45,BharatGPT is here!
2023-06-24 20:24:46,https://www.linkedin.com/posts/amitabh-nag-56039b5_generativeai-conversationalai-ai-activity-7078333831048499200-nh7n?utm_source=share&utm_medium=member_ios
2023-06-24 20:33:46,No no. See the post. You will know what I mean.
2023-06-24 20:34:00,😂
2023-06-24 20:54:37,We are using for finetuning and dev testing - production next quarter. Things are a bit wobbly sometimes but AWS support helps
2023-06-24 20:57:50,But was it hard to restrict the usage to only fintech domain?
2023-06-24 20:59:46,"nopes. I'm already categorising everytime what someone has asked into related or not and then letting the model answer if user has asked < N ""unrelated questions"" yet"
2023-06-24 21:25:04,"Peak community success, creator is here to explain internal deets!"
2023-06-24 21:28:55,"It did not give me ICICI bank details, despite following your bot option"
2023-06-24 21:31:56,"If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin (other than me!) for an invite link."
2023-06-24 21:33:27,☠️
2023-06-24 21:33:36,noted - will solve 
2023-06-24 22:24:05,performance ok ? which model are u using ? we are planning to use falcon
2023-06-24 22:50:17,"why does langchain still use davinci as default? Doesn't 3.5-turbo still work better, even for non chat tasks?"
2023-06-24 23:07:39,For agents GPT4 works significantly better in our experiments so far.
2023-06-25 01:02:53,works with 3.5-turbo as well quite nicely
2023-06-25 01:28:40,"I generally paste each section, get it to explain it to me and then do the complete reading again. def super helpful for quick parsing/absorption"
2023-06-25 01:36:10,"Falcon, flan T5 and a couple more . Performance is good, but nothing to support real time streaming, so going mostly async"
2023-06-25 01:41:03,The texbooks are all you need paper and Orca paper both emphasize the need for high quality datasets. But they contradict on a couple of things. Namely size of the model and the amount of high quality data. Textbooks tries to achieve it on a smaller scale compared to Orca paper. Interestingly both by microsoft research.
2023-06-25 01:56:42,"Of course one thing to note is, the paper focuses on LLMS trained for code."
2023-06-25 01:58:48,"The nuance in the textbook paper is that the model was trained for 7 epochs. Essentially 50B tokens. There was this assumption earlier that the corpus should be entirely unique. https://arxiv.org/abs/2305.16264 this paper showed that upto 4 epochs they saw no issue and the loss kept decreasing. In other words, there was still more signal left in the dataset even after going over it multiple times."
2023-06-25 01:59:56,Can you explain the second part again?
2023-06-25 02:02:54,"In case you dont have a lot of data, you can train a Language model by training it with your data on multiple epochs. This paper showed that upto 4 epochs, the loss for the model decreased in a similar fashion as if you had unique data. Simply put, 50B tokens x 4 epochs loss = 200B unique tokens x 1 epoch loss"
2023-06-25 02:04:19,Ok got it. Was confused because they also focused on deduplicating the data. Have to read that part closely.
2023-06-25 02:05:13,"The other work the textbook paper took inspiration from is  https://arxiv.org/abs/2305.07759. This paper essentially studies the question “how small can a model be and still produce coherent english”, they produce a synthetic high quality dataset and train a model less than 10M parameters in size which generates coherent english."
2023-06-25 02:07:37,"This paper is still interesting because the Orca paper had significantly more data and also a decent number of epochs, Think it was 4 epochs for 5M data set rows and 1M data set rows . So 8 epochs in total. So am interested to see if this is because this paper focused on code or this model can be generally used as well in other tasks like RAG"
2023-06-25 02:08:17,"If it does, then boy do I have some good data to fine-tune and test it on. But interesting to see this textbook type data"
2023-06-25 02:36:46,I like this paper and the Orca paper. They have been pretty easy to read and understand and GPT-4 is also a good assistant here
2023-06-25 10:14:58,"btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details.."
2023-06-25 10:18:19,[PHONE REMOVED]
2023-06-25 10:39:16,Would be curious to learn more on this as well. 
2023-06-25 10:39:49,Hey all! 
2023-06-25 10:42:42,Please DM
2023-06-25 10:49:14,Ethan Mollick got to try out multimodal GPT4
2023-06-25 11:08:19,"Hey Samanyou and Darshan, we can help with this. Will continue on dms"
2023-06-25 11:24:15,Use spot vms 😂❤️
2023-06-25 11:26:48,"i can be of help. If interested, you can DM me as well"
2023-06-25 11:27:41,"Could apply to any team building on the cloud as well. Even in big companies where you've to go to the CFO and board meetings and make a business case for investing in AI. Infra, GPUs, data collection and processing - all expensive. Not to mention the elephant in the room - AI engineer/dev salaries :D"
2023-06-25 11:36:39,Anybody here had a chance to try multimodal GPT4 ?
2023-06-25 12:06:49,"Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for ""not <concept>"" in the vector store produces results containing the concept with highest match"
2023-06-25 12:08:30,Instead of negative prompt will it work if you rank the matching scores in order of least matches first and return top-n least matching ? S
2023-06-25 12:10:16,"We are doing that with Mandi data for farmers and will integrate soon with platform, so farmers can request by voice in their local language. Lots of challenges though."
2023-06-25 12:11:00,What is the core problem you are facing?
2023-06-25 12:11:05,Same here. Building for legal
2023-06-25 12:13:01,"So basically, we use chatgpt to parse the response and identify the keywords to be searched from vector store. I can try to include that in the prompt to maybe change the vector store query to order in ascending order by score -> but was wondering if there is a better solution. In my mind i thought that embedding space should be able to resolve the negation factor on its own and do the inverse on its own"
2023-06-25 12:13:19,"Some queries can return huge amount of data, we have millions of rows, so working on limiting that by set of questions to start with."
2023-06-25 12:14:43,"If its a structured data store, wouldn't adding a limit solve the issue. Just curious to understand since experimenting something similar"
2023-06-25 12:17:01,Dynamically identifying and inserting limiter is what we will have to solve. I.e. ‘give me latest prize of grapes in Nasik mandi’ vs ‘give me commodity prizes from Nasik Mandi’
2023-06-25 12:18:08,We have millions of rows across thousands of commodities and Mandis.
2023-06-25 12:32:53,"Is the data source consistent? As in if you are using SQL, the schemas are constant or different per customer?"
2023-06-25 12:42:31,It is consistent
2023-06-25 12:46:58,What db are you using to store your data and embeddings?
2023-06-25 12:59:27,You can handle these via your final LLM prompt. Or if you're only fetching embeddings I had a reply in this tweet where I had passed it via a encoder decoder model to get the score
2023-06-25 13:23:43,https://www.producthunt.com/posts/youtalk
2023-06-25 13:47:55,could you elaborate little more - how can this be handled by prompt
2023-06-25 13:52:57,LLMs and decoder models are better at figuring out this level of similarity better than the embedding models we use which are more optimized for search.
2023-06-25 14:18:11,thanks for the detailed answer. will take a look
2023-06-25 17:07:04,"I'm building an in-browser semantic search product and I was wondering if I could use tiktoken (but in JS), or should I be using the embeddings endpoint (api.openai.com/v1/embeddings)? They both use the same the same tokenizer - cl100k_base. "
2023-06-25 17:20:00,"Ok, so as I understand the tokenization comes before embedding. OpenAI has not released the vector representation of their tokens, and so it means I have to use their API to get embeddings for gpt-3/4. I can always use an open souce pretrained model (sbert.net/docs/pretrained_models.html) if I wish it to be local first."
2023-06-25 17:21:44,This particular failure could be because you used Bombay instead of Mumbai.
2023-06-25 17:22:07,There's a library called gpt-tokens in node which you could use to calculate tokens locally
2023-06-25 17:22:09,"Yes, but I was performing a semantic search anyway"
2023-06-25 17:22:31,"If openAI embeddings find Bombay and Mumbai semantically same, only then it'll succeed with that instead of miniLM sbert embeddings"
2023-06-25 17:22:48,"Yes, but it is a tokenizer, it won't provide vector embeddings"
2023-06-25 17:23:12,"Yes, assuming OpenAI's embedding is much better"
2023-06-25 17:23:40,There is transformers.js to run any sentence transformers model locally
2023-06-25 17:23:53,"Yes, I'm using that"
2023-06-25 17:24:17,I have a simple version of semantic searching working using miniLM
2023-06-25 17:24:18,I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada
2023-06-25 17:25:35,"Maybe, will try out all-mpnet-base-v2 (best model available at the moment according to sbert.net/docs/pretrained_models.html)"
2023-06-25 17:26:33,I think e5 came out on top in recent mteb benchmark
2023-06-25 17:26:39,Rely on MTEB leaderboard to make your judgement - https://huggingface.co/spaces/mteb/leaderboard
2023-06-25 17:27:09,"Even in that, don't go blindly for top performing embeddings for STS (semantic textual similarity) task"
2023-06-25 17:27:26,You've to consider your performance and cost as well
2023-06-25 17:27:57,How do I consider / measure performance?
2023-06-25 17:28:04,"For example, if you want similar speed as miniLM, look for similar model size and dimensions"
2023-06-25 17:28:27,"Ok, thanks"
2023-06-25 17:28:53,miniLM L6 v2 is 384 dimensions and ~80MB I guess
2023-06-25 17:28:59,Yes
2023-06-25 17:29:49,"So you can find best model for 384 dim first. Since you'll be running it in the browser, you need to consider your performance first. If cost isn't an issue, you can always go with openAI embeddings."
2023-06-25 17:30:31,I could run a better model in my infra I suppose. Will it be cheaper than using OpenAI embeddings endpoint?
2023-06-25 17:33:01,"You can use HuggingFace inference (api is free up to a limit, endpoints for dedicated compute)"
2023-06-25 17:33:42,"Thanks, didn't know that. Much easier to compare each model"
2023-06-25 20:27:09,Quite unhinged and delightful: https://twitter.com/RoyKishony/status/1672280665264386049
2023-06-25 20:30:27,https://twitter.com/sauhaarda/status/1672714475659722754?t=iY5uQgXsoyZp_EMAF2aZ_A&s=08
2023-06-25 20:41:31,"""Paper"" is a bit strong. Just an arxiv submission"
2023-06-25 20:43:00,Yeah fair lol
2023-06-25 21:25:43,this should be understood by the models.
2023-06-25 21:28:33,Could be one of these? They're very high quality code embeddings
2023-06-25 21:31:40,"Ok, so they might have just taken the first layer of these models"
2023-06-25 21:34:44,https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx
2023-06-25 21:35:28,Do you think openai has merged the gpt4-0613 with the old gpt4 model? Because gpt4 seems fast today
2023-06-25 21:35:56,"No, it's a Sunday and folks in US, EU have a life unlike you and me"
2023-06-25 21:36:05,And stop spilling alpha like this 😤
2023-06-25 21:36:27,Sounds like AI generated code has the same flaws as human devs? 🤣
2023-06-25 21:37:48,It definitely does. I have to constantly check the AI generated code because sometimes the logic that is supposed to be in the for loop is outside it? I'm like bhai aise kaise chalega and all it does is apologies
2023-06-25 21:39:34,"GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement "
2023-06-25 21:41:20,Anyone checked out Zeroscope? https://huggingface.co/cerspense/zeroscope_v2_XL https://twitter.com/mrjonfinger/status/1672809085849468929
2023-06-25 21:42:02,This sounds right.
2023-06-25 21:45:27,Which model is this?
2023-06-25 21:45:51,This one which Rajesh shared
2023-06-25 21:46:10,"These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms."
2023-06-25 21:47:17,I get that. But I think this is there from personal experience although might be missing in the model used
2023-06-25 21:49:34,[PHONE REMOVED] any examples of Salesforce with finetuned models ? The ones u linked are basemodels
2023-06-25 21:50:50,"Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4."
2023-06-25 21:53:21,"Especially with named entities, this is a very common problem that generally available embeddings can't solve."
2023-06-25 21:56:15,"Doesn't this also boil down to training data? Going back to the instructGPT paradigm, the model learns to generate code using examples of human code written - not necessarily through full knowledge of the compiler or interpreter underneath"
2023-06-25 21:58:03,Yeah. The training data is better in gpt than most but not susceptible to mistakes
2023-06-25 22:06:35,"On a related note I've often wondered what the embeddings would look like for models like InstructGPT, Codex and so on. Sequences matter here despite the kind of token you compute because programming languages have significant overlaps in keywords and reserved words."
2023-06-25 22:09:21,This is trained on the codegen-salesforce 😂.
2023-06-25 22:09:52,"Ohh, I thought you wanted to see if Salesforce models can be finetuned"
2023-06-25 22:10:04,StarCoder Base
2023-06-25 22:10:35,Something that interested me today - *A ORCA repro effort on OpenLlama 13B base* 
2023-06-25 22:11:20,"Speaking of Orca, Emad of Stability.ai disses it because it's not true FOSS:"
2023-06-25 22:11:23,Isn't the WizardCoder the highest? Or did you mean commercially licensed?
2023-06-25 22:11:50,Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind
2023-06-25 22:12:14,"Ok, got your context"
2023-06-25 22:12:50,"True, orca and phi both have such wonderful results in the paper that not releasing their datasets and models kind of ruins the impact the papers can have."
2023-06-25 22:15:29,Haven't begun my deployment of coder models. You'd recommend starting with wizardcoder or starcoder base ?
2023-06-25 22:16:10,GPT4 is miles ahead of these and will stay ahead for most of 2023
2023-06-25 22:16:15,And perhaps 2024 too
2023-06-25 22:16:42,"But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base"
2023-06-25 22:18:43,Makes sense. 
2023-06-25 22:23:09,You might find these tools interesting as well: 
2023-06-25 22:23:51,Thanks a lot.
2023-06-25 22:28:21,Bloop is one of the most interesting works for this problem for sure.
2023-06-25 22:29:57,https://aider.chat/
2023-06-25 22:41:09,I'll check this out. I'm interested in the different ways people are approaching the problem of treating source code as a document or database.
2023-06-25 22:42:26,I've seen multilevel or unilevel summarisation approaches mostly so far.
2023-06-25 22:44:45,Why replit code ? Genuinely curious. Asking specifically for fine-tuning.
2023-06-25 22:46:22,Small models are easier to finetune frequently and update for auto-complete kinda use cases
2023-06-25 22:47:23,This has been a recent learning
2023-06-25 22:47:25,Is there a platform though that allows me to it well?
2023-06-25 22:47:43,"For me, there's a bigger question of what approach do you take to build the fine tuning dataset for code gen cases for specific repos or source codes."
2023-06-25 22:48:25,Replicate should be launching this soon
2023-06-25 22:50:59,Nice
2023-06-25 22:55:55,Do you take the individual functions and modules and turn them into instruction response pairs? Or do you take the commit messages as Instructions and the commits as responses? Or do you take an unstructured approach and just rely on next token prediction to do the trick?
2023-06-25 22:56:14,"In my mind, an ideal setup would be something that has access to data so that it allows me to switch between models and also automatically fine-tunes those"
2023-06-25 23:49:16,"A ""camera"" that, instead of capturing light, captures your GPS coordinates, looks up some information about your location, plugs those bits into some sentences like Mad-Libs, and sends the whole thing off to an AI to generate an image."
2023-06-26 00:33:45,"Little too broad, but for text in particular — AutoNLP-way of thinking was a thing, and that can still be extended to support these use cases. If I spend enough brain cycles, should be able to do this for code too"
2023-06-26 00:36:25,"Interesting that you call it broad,"
2023-06-26 00:52:24,My summary of textbooks are all you need paper
2023-06-26 02:33:14,That was a great summary of the textbooks are all you need paper. This paper makes me think that current advances are not merely about scale. A relatively small amount of tokens (billions) and fine tuning (millions) on a model that is not particularly large (1 B or smaller) is remarkably good at things like coding and would have been unthinkable a few years ago.
2023-06-26 02:36:07,If the task is narrowly scoped it seems quite doable for anyone in this group with some months of effort to train a model that is competitive with GPT-3. The bottleneck is actually putting together 5-10B “high quality tokens”
2023-06-26 02:36:33,Neither scale nor architecture changes. Primarily a change in quality of coherence of data.
2023-06-26 02:37:17,Who knows maybe even the order in which data is fed can make a difference
2023-06-26 02:38:54,Do you mean we are back to handcrafting high quality dataset on tasks?
2023-06-26 02:39:33,"In my eyes, it's the same thing as creating a ""small monopoly"". Not everyone needs to have a model rivalling GPT3 locally in everything. In most cases, beating it in one or two areas, even if it's your home ground, may add significant value."
2023-06-26 02:40:12,Not quite but it looks we are headed there. The more you hand craft and with more expertise the more results it seems to yield
2023-06-26 02:40:34,So the bottleneck will become the availability of expertise and effort to make really excellent data sets
2023-06-26 02:41:18,See this for eg https://openai.com/research/improving-mathematical-reasoning-with-process-supervision
2023-06-26 02:41:35,"We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans."
2023-06-26 02:41:42,What if you extend this to math problems from old textbooks.
2023-06-26 02:41:46,"I will add, excellent datasets without API distillation from GPT4. Clean commercial excellent dataset."
2023-06-26 02:43:43,Imagine doing this on top of text books are all you need. You will get even further improvement
2023-06-26 02:47:18,Is there a framework to follow for this because I think with enough people combined you can get 5-6 gb of high quality data which can give good performance
2023-06-26 02:49:44,I think we've a 1T dataset that's completely clean since it's crowd created. I think Red pajama is one.
2023-06-26 02:50:35,"But now we've new dataset methodologies that we may want to try out like the ones shared in LIMA, Orca, phi-1."
2023-06-26 03:05:46,Correct
2023-06-26 04:37:23,i always thought gpt4 was ensemble of models. the moe paper sort of proved this theory
2023-06-26 06:37:16,"There is no single ""fine-tuning"" — it depends on:"
2023-06-26 10:58:57,https://news.ycombinator.com/item?id=36460082
2023-06-26 11:09:00,"Yes, sir - which is why thinking if having some/all of these functionalities on one platform will be helpful"
2023-06-26 12:03:22,Good afternoon everyone. My name is Saravanan. I am from a healthcare startup called Amura.
2023-06-26 12:13:59,it works - succinct answers for busy parents
2023-06-26 12:14:07,"from a ""credible"" source"
2023-06-26 12:14:36,I've been there and there is so much content out there it can be overwhelming
2023-06-26 12:15:07,It is retrieval augmented generation. Fetch the relevant results into one helpful snippet
2023-06-26 12:15:23,"Summarization, done well, can be a killer app"
2023-06-26 12:15:24,Long snippet
2023-06-26 12:16:51,its a really good move IMO - as new parents are always looking for relevant information and as a gneartion we are not interested in the advice of the older generation
2023-06-26 12:49:26,"Google search May work for everything probably, but then the user is responsible for the cognitive load of processing and reasoning."
2023-06-26 12:52:27,This is the big draw to ChatGPT for a lot of folks. Lower cognitive load.
2023-06-26 12:53:20,Just like Google was for directory based search engines.
2023-06-26 12:55:45,That’s where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there’s a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it
2023-06-26 12:59:42,A topic for Philosophy group
2023-06-26 13:28:08,Join the philosophy group for this discussion.
2023-06-26 13:28:33,You can join the philosophy group for this discussion
2023-06-26 13:33:00,These risks can be mitigated
2023-06-26 13:37:47,"Speaking of RAG, people are working on Enterprise-readiness for RAG systems e.g. came across this https://github.com/danswer-ai/danswer which looks promising from a design PoV"
2023-06-26 13:40:22,Was noodling on this - very helpful
2023-06-26 13:40:46,Yes. There have been a few tools like this that have come up. This space is heating up now
2023-06-26 13:46:40,What’s the infrastructure running this?
2023-06-26 13:47:16,t3.2xlarge
2023-06-26 14:00:15,is there a difference in performance of running these on t3a (amd processors) or the aws internal graviton processors( constraint of this is that it only supports ARM architecture so diff docker images might be required)
2023-06-26 14:00:33,Haven't tried t3a
2023-06-26 14:00:58,"this is just the indian in me, trying to reduce costs even further. t3a is 60% of price of t3"
2023-06-26 14:01:39,"He'll flip the code to FOSS, go ahead and try!"
2023-06-26 14:01:55,cool
2023-06-26 14:04:11,Are you using Wiki embeddings for testing?
2023-06-26 14:04:40,https://huggingface.co/datasets/kshivendu/dbpedia-entities-openai-1m
2023-06-26 14:11:07,I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase
2023-06-26 14:20:54,"OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year"
2023-06-26 14:21:25,Both codex and gpt3 have this on the playground and inside copilot
2023-06-26 14:21:37,correct
2023-06-26 14:23:01,"Yes, that's how it has been done in multiple cases. That's why I mentioned it as the third option in my comment. "
2023-06-26 14:24:22,copilot even had a neat way of being able to configure how much to take as prefix and how to much to take as suffix
2023-06-26 14:24:26,"Yeah, you mean this - https://arxiv.org/abs/2207.14255"
2023-06-26 14:24:35,When will a nobody like me get it :(
2023-06-26 14:24:48,yeah. this one
2023-06-26 14:24:49,Code interpretor
2023-06-26 14:25:10,Interpreter*
2023-06-26 14:25:53,"Maybe not as good as code interpretor, but I saw some plugins today that talk to your code given the GitHub repo, check these out and see if you like them."
2023-06-26 14:26:27,"arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard"
2023-06-26 14:28:09,I'll probably be that 3rd year intern in a few years.
2023-06-26 14:28:58,Do they randomly roll interpreter out or is it some kind of wait list?
2023-06-26 14:29:02,I'm interested in knowing which companies keep people in internship position for 3 years 😂
2023-06-26 14:29:12,[PHONE REMOVED]  [PHONE REMOVED]
2023-06-26 14:29:53,"I was assuming, 3rd year ya final year student doing internship"
2023-06-26 14:38:23,"Please, none of these are anywhere near any good intern. A good intern is capable of googling the right answer"
2023-06-26 14:39:53,"By this definition, a good intern is harder to find than a unicorn paying 50 LPA salary in BLR"
2023-06-26 14:43:05,"My intern raised white flag in a week, after getting overwhelmed looking at the codebase. Good interns are really like unicorns."
2023-06-26 14:53:07,There should be a tag by which one can filter HuggingFace datasets to just embeddings dumps. Anyone know of a way to do it?
2023-06-26 15:26:29,Was looking for the same. Didn't find anything reliable. The best bets are certain tags and keywords. I can tell you those if you want.
2023-06-26 16:27:41,Is the embeddings title+string or just string?
2023-06-26 16:40:55,What are the different methods to use transliteration from Hinglish to Hindi??
2023-06-26 16:42:54,Ok got it. Thanks for this. Will try to experiment and see if we can create a compressed embedding space on top of this.
2023-06-26 17:28:03,"Yeah, it's been 5 weeks I guess since it moved from 0-1 to 0-2"
2023-06-26 17:29:34,"check this out, works well for transliteration in the Indic context"
2023-06-26 17:57:53,https://twitter.com/alighodsi/status/1673300587419701249?s=46
2023-06-26 18:00:04,Are there any chatgpt plugins making money? How do you even do distribution? I've been thinking about building one but haven't really seen anything useful.
2023-06-26 18:06:43,sama has said that plugins have no PMF. they did a v good job taking the learnings and building openai functions.
2023-06-26 18:09:03,one man army
2023-06-26 18:09:16,plugins themselves aren't making money yet. but it can happen. ones like zapier etc
2023-06-26 18:40:37,They had this capability already with Dolly - but great to see this.
2023-06-26 18:40:41,My card charged 5% TCS for the ChatGPT plus subscription. :(
2023-06-26 18:41:12,Anyone aware of cards/ bank that dont charge this?
2023-06-26 18:43:02,non indian  cards
2023-06-26 18:43:11,amex probably doesn't
2023-06-26 18:44:39,My card didn't levy any taxes other than the 18% govt levied GST.
2023-06-26 18:52:48,"Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?"
2023-06-26 18:57:36,The ranking algorithm that's being used in your vector store isn't working that great? Maybe the search query term is matching a vast surface area of objects from your knowledge base ... and the valuable matches are not ranked to top?
2023-06-26 19:01:44,This sparked another thought. This is probably the oldest and most mature usecase. It seems people are still building this in-house. Are there not good enough services for this already? What are the factors apart from prices that might be forcing people to build this in-house than buying a third party solution
2023-06-26 19:02:06,"What is your chunk suze maybe playing with chunk size may help , by that i mean reducing it to 2000 or 1500"
2023-06-26 19:06:04,"Hi all,"
2023-06-26 19:11:59,Try to store I parquet formats
2023-06-26 19:12:20,*in
2023-06-26 19:15:22,This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?
2023-06-26 19:19:38,"I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view."
2023-06-26 19:19:43,Data analysis*
2023-06-26 19:19:50,"Thanks, that makes sense. I’ll explore it"
2023-06-26 19:20:16,Do you know what frameworks are out there?
2023-06-26 19:26:59,I had estimated this sometime back. You should be able to outsource this task to any of the companies which builds scraper if you don’t intend to maintain the pipeline of newly granted patents. Speak to Arbdossier who I know were working to get this data. 
2023-06-26 19:30:18,"If you're just running your script on a remote server and need access to GPU as well, try modal."
2023-06-26 19:30:43,"Search is something i do intend to work on, but not at the moment."
2023-06-26 19:31:03,Then I would suggest to separate data collection and analysis. Here data collection is more complex owing to different issues you mentioned. Handling data can be done in many ways.
2023-06-26 19:31:45,Then public data might not work. I filed a patent application last year and your best shot at sourcing this is some patent filing firm or a lawyer
2023-06-26 19:32:42,If there's GPU required in this pipeline then feel free to try Q Blocks as well.
2023-06-26 19:33:41,Or sqlite
2023-06-26 19:34:16,Has anyone worked on analyzing amazon reviews using open ai or any open source models? I would like to talk to anyone as I am trying to build a product based on it.
2023-06-26 19:34:47,Yes. I did realise my technical wouldn't sufficient to do them simultaneously either
2023-06-26 19:38:51,"I would like to avoid that due to reasons, despite being a patent lawyer at a firm."
2023-06-26 19:39:15,I was going to understand preferred stack for the task
2023-06-26 20:10:12,We (https://oraika.com) did it. DM
2023-06-26 20:10:52,Had created a small chrome extension to summarise the comments into pros and cons.
2023-06-26 20:39:38,https://twitter.com/DimitrisPapail/status/1673331620034625537?t=oS6eoprFL_3vmvUvwlsw0A&s=08
2023-06-26 20:40:43,"Using chunk sizes of around 2000, right now"
2023-06-26 20:41:23,"With Redis, I see HNSW and FLAT, no implementation of FAISS available. Anyone has any recommendations on which similarity measures to consider?"
2023-06-26 20:41:42,"FAISS seems quite popular, HNSW is also"
2023-06-26 20:42:18,AFAIK FAISS is a library
2023-06-26 20:47:02,Did someone experiment Colbert V2 retrieval ?
2023-06-26 22:02:39,"There are trade offs between flat and hnsw. Don’t remember from the top of my head, with more points hnsw does better"
2023-06-26 22:04:29,Yes! Colebert does better than DPR when the k is small but with larger k-s DPR does better.
2023-06-26 22:19:02,https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform
2023-06-26 22:20:56,Has anyone evaluated their models? seems the recent one is MPT-30B
2023-06-26 22:39:56,Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129
2023-06-26 22:40:57,wiz.io would like to enter this conversation
2023-06-26 22:50:26,"haha. Wiz isn't acquired yet! But given the growth, they might soon send up with an IPO"
2023-06-26 23:25:35,I'm just getting prepared for side effects from the new gpt4 model rolling out tommorow
2023-06-27 00:37:09,One basic noob question 
2023-06-27 00:38:12,The scores differ slightly. So your thresholds need to be adjusted accordingly for what is considered similar
2023-06-27 00:38:13,https://huggingface.co/spaces/mteb/leaderboard
2023-06-27 00:59:06,I believe there are 2 parts of your question.
2023-06-27 01:02:03,#1 Embeddings differ in
2023-06-27 01:04:13,"For all practical purposes, it'll be ok for you to go to MTEB leaderboard and just sort for best embeddings for the task you want and budget yourself to the size of embeddings based on how much compute and data you've to work with."
2023-06-27 05:28:41,Existing Prompts will break or have silent failures starting today!
2023-06-27 05:34:47,Thanks a lot nirant. Is there a link to a blog or changelog? Or is today the cutoff date for the functions update launched a couple of weeks ago
2023-06-27 05:35:29,Hardmaru left StabilityAI. Things heating up.
2023-06-27 05:46:58,Cutoff date
2023-06-27 06:56:05,💡use a rapid writing format like short hand to convert user input into that format>send to GPT>Instruct GPT to respond in the same format>convert to normal text for user output.
2023-06-27 07:08:55,Need something better than short hand. However reducing every input into a a shorter token input and getting output also such has potential. 
2023-06-27 08:33:53,"QQ: Is OpenAI Whisper still the reigning publicly accessible top-tier model for audio-to-text conversion, or has a new contender taken its place? tx 🙂"
2023-06-27 09:01:18,Try https://deepgram.com/ once
2023-06-27 09:47:30,"Register here for the panel with Chief Scientist of MosaicML, Jonathan Frankle! its a little late for India (230am), but it will be recorded as well. "
2023-06-27 10:18:47,Models are okay but they are great to fine tune on.
2023-06-27 11:04:17,https://lilianweng.github.io/posts/2023-06-23-agent/ - detailed blog post on 'LLM Powered Autonomous Agents' from Lilian Weng.
2023-06-27 11:04:34,"Excellent read, just finished it"
2023-06-27 11:11:13,"it just popped up on my twitter feed, was just about to post that,"
2023-06-27 11:17:46,How are you or others finding the new model
2023-06-27 11:19:41,"btw, quick question"
2023-06-27 11:22:05,"DM any of the admins, the contact number they will help you out."
2023-06-27 11:22:48,"DM one of the admins, that's the easiest way for noe"
2023-06-27 11:29:55,"Hey guys, Has anyone here done multi-node distributed training using Pytorch on E2E?"
2023-06-27 11:30:42,We have been struggling with this for some time.
2023-06-27 11:38:01,"Using gpt-4-0613 for few days now. Longer & complex prompts run much better. 8k is great, but some loss happens when you run 8k vs 4k. Claude seems too far behind when compared to this."
2023-06-27 11:38:59,Or anywhere else where we can get multiple H100s at the same price as E2E
2023-06-27 11:49:13,4k? Are you talking of 3.5 turbo?
2023-06-27 11:54:11,no i meant using gpt-4-0613 itself. it supports upto 8912 tokens. found 4k to be a little better at capturing some nuances that the model glosses over at 8k.
2023-06-27 11:55:18,Ok so you mean context length
2023-06-27 11:56:13,I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break
2023-06-27 11:56:42,that'd be a nightmare :)
2023-06-27 13:01:48,How are Mosaic's text models in terms of quality and cost? https://docs.mosaicml.com/en/latest/inference.html
2023-06-27 13:42:54,"Looking for a reviewer for this PR, I've never done JS/TS — so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:  "
2023-06-27 13:52:00,by building the lib from source and using in a ts test? https://blog.logrocket.com/testing-typescript-apps-using-jest/
2023-06-27 14:02:03,"I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23"
2023-06-27 15:13:28,Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?
2023-06-27 15:13:40,"Yup, sounds like a job for next PR"
2023-06-27 15:16:11,Maybe Elasticsearch
2023-06-27 15:17:38,Weaviate supports this
2023-06-27 15:19:52,Every VectorDB does if you've IDs from the metadata query/filter
2023-06-27 15:20:30,Did you try Chroma?
2023-06-27 15:20:58,Good question - I think Weaviate does that (from anecdotal conversations) 
2023-06-27 15:21:06,Hashnode (https://hashnode.com/rix) will speaking about Anthropic in Production and Llama Index contributor Ravi [PHONE REMOVED] will be speaking about Llama Index in production including evaluation: https://lu.ma/ai-talks-4
2023-06-27 15:38:58,Appied- looking forward to attending this - Also does anyone know the average wait time for getting api access approval for anthropic ?
2023-06-27 15:57:21,OpenAI competes for the same $$ as MSFT 🤯
2023-06-27 15:59:22,MS owns 75% of openAI's profits until it's 10B investment is paid off.
2023-06-27 15:59:37,"So it's like heads I win, tails you lose."
2023-06-27 16:00:03,"Were you given access to all the models ? I have applied yesterday, fingers crossed."
2023-06-27 16:01:33,which gives OpenAI lot of incentive to either never declare profit or declare profits and dividend it out asap
2023-06-27 16:01:40,How to get access to the Langchain platform?
2023-06-27 16:02:29,"OpenAI brand is way cooler than MSFT in consumer. If I was Microsoft, I would let OpenAi go consumer and then buy them out while maintaining the brand"
2023-06-27 16:04:01,Interesting !
2023-06-27 16:11:25,Microsoft consumer is way bigger. It has windows and MSN and Bing (which is also profitable) and LinkedIn and Skype and even teams launching for consumers
2023-06-27 16:19:25,"MS owns 49% of openAI anyway, they would not mind openAI increasing itself in valuation. MS is a giant and a household name, so it's not easy for anybody to replace them willy nilly in the short term. Plus they've rights to use openAI products in their own products. Quite a brilliant deal for 10B actually."
2023-06-27 16:20:15,"Yeah, they can continue spending on infra. But guess who provides them infra primarily - Azure 😂"
2023-06-27 16:35:15,"Which begs the question - why would OpenAI do a deal like this, where they give away the first rights to all tech they develop to MS."
2023-06-27 16:37:23,"I guess at the time, access to capital and compute was important"
2023-06-27 16:38:20,ChatGPT was not a sure shot.
2023-06-27 16:40:49,I am talking about the 1 billion $ investment in 2019
2023-06-27 16:42:48,"july 22, 2019"
2023-06-27 16:44:23,"I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct"
2023-06-27 16:58:59,He said he would but the actual money quite merger. He asked for sole  control If they wanted more money. Sam refused and went with MSFT
2023-06-27 17:01:40,the _next_ cage fight will be Musk v Altman
2023-06-27 17:05:29,"Given Musk's recent behaviour at twitter over the last year or so, very wise decion by Sama ! :)"
2023-06-27 17:05:53,*decision
2023-06-27 17:37:13,"Despite his behaviour I think Twitter got better thanks to Musk's acquisition - they actually generate revenue these days, and some features are welcome. Some like sketchy validated accounts are still an issue but also proved that you don't need a huge team like Twitter had to run that scale of application. I could be wrong though - time will tell."
2023-06-27 17:40:28,"I'm very tempted to chime in, but this is most def off topic for this forum 🙏"
2023-06-27 17:40:58,"Thanks, Nirant for keeping me on track."
2023-06-27 17:43:29,Nah... Nowhere close to a bil a year...
2023-06-27 17:43:47,https://techcrunch.com/2023/05/17/elon-musk-used-to-say-he-put-100m-in-openai-but-now-its-50m-here-are-the-receipts/
2023-06-27 17:51:22,Claude & Claude Instant v1
2023-06-27 17:56:20,"yes, looks like proper execution"
2023-06-27 17:56:21,"Does anyone have any rough numbers / guesstimates on what revenue openAI and FM companies are currently run rating at? Similarly, any numbers for other Infra providers?"
2023-06-27 18:02:47,Applied 3-4 days back. But go no confirmation mail about being on the waitlist either. Was it case with you guys as well?
2023-06-27 18:04:38,Yup
2023-06-27 18:06:51,Dealroom estimates $200M for OpenAI in 2023 and $1B in 2024. Source not available.
2023-06-27 18:08:10,"They've taken an integration approach. Generative AI for powerpoint, word, stuff like that."
2023-06-27 18:12:51,"""Now Demis Hassabis, DeepMind’s cofounder and CEO, says his engineers are using techniques from AlphaGo to make an AI system dubbed Gemini that will be more capable than that behind OpenAI’s ChatGPT."" Looks like they are experimenting to improve RLHF as they are vastly experienced on RL.."
2023-06-27 18:16:34,typical hype adoption cycle 🫡
2023-06-27 18:31:52,How is langchain plus different from langchain
2023-06-27 18:46:05,"If you add CSS to something, it's called Plus"
2023-06-27 19:24:51,interesting eval work from graham neubig of cmu
2023-06-27 19:39:26,"Come to think of it, even chatgpt doesn't have RBAC, team management, reporting"
2023-06-27 19:40:46,There are lot of errors which are forgiven if you build something exceptional 🙏
2023-06-27 19:41:47,"Folks, we've confirmed multiple spam reports from Wyse founders and teammates. We do not tolerate spam."
2023-06-27 19:44:15,talk about pre-pmf distribution :P
2023-06-27 19:45:19,novel idea though?
2023-06-27 19:45:21,"shh, that's for others to implement"
2023-06-27 19:45:55,"Nirant is the moderator we need, but don't deserve :P"
2023-06-27 19:46:01,"Hello Everyone,"
2023-06-27 19:48:48,"For SM companies, critical distribution is the PMF 😀"
2023-06-27 19:48:48,"You might want to check this, has open jobs and upcoming events (which are often sponsored by companies looking to hire): "
2023-06-27 19:52:44,You might find ragas: https://github.com/explodinggradients/ragas from Jithin and friends [PHONE REMOVED] interesting
2023-06-27 19:58:02,this is gold 😂🔥
2023-06-27 20:01:50,"Have a perspective on this actually, thinking how best to share it"
2023-06-27 20:03:52,"It's one of those tech which customers are demanding ( and expecting ) and hence, orgs are looking for a solution. It's very much a Pull than a push for this sort of solutions."
2023-06-27 20:04:33,"Absolutely, pre-product PMF 🫣"
2023-06-27 20:06:02,"What types of SaaS gets you enterprise ready? Specifically, any good resources on enabling SSO/SAML?"
2023-06-27 20:06:50,"Also, there's a question of liability that's often coming up. Given how non deterministic the outputs are. If anyone has a perspective on how enterprises are tackling this with vendors, that would be great"
2023-06-27 20:07:40,"For example, if there's an erroneous response or action given by the AI, is there any liability on the vendor? And, to what degree"
2023-06-27 20:08:10,https://workos.com
2023-06-27 20:08:31,Nope. But saw them on a few Google ads. Thanks. Will do
2023-06-27 20:09:29,And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up
2023-06-27 20:11:12,Interesting. Will check them out. This is going to be even more relevant now. Given lots of folks are paranoid about data leakage to external models
2023-06-27 20:12:44,There's one more product that allows enterprises to interface their data with LLMs in a Privacy preserved manner
2023-06-27 20:14:36,To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs 💲💲
2023-06-27 20:23:34,Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways. 
2023-06-27 20:24:06,Got quite a few pings 1:1 from folks post this and hence sharing it here for everyone in case it helps a broader audience 
2023-06-27 20:25:56,FOSSUnited has an active job board too
2023-06-27 20:27:28,"Amazing. Is there a good playbook you've seen to sell to enterprises? Specifically, how do you get that first client"
2023-06-27 20:28:27,"Adding to this conversation,"
2023-06-27 20:29:06,Any reason why they don't trust Microsoft?
2023-06-27 20:31:01,Seems to be a perception issue around MS leveraging client's  data to train their models which can be used by competition as well
2023-06-27 20:33:41,"Wow, will be very, very surprised if this is the case 😳"
2023-06-27 20:33:58,+1
2023-06-27 20:36:48,Have some US / East asia F500 clients and folks were eager to experiment. 
2023-06-27 20:39:21,Eager to experiment with MS AI features or GenAI in general?
2023-06-27 20:42:36,Some were already using Azure AI. 
2023-06-27 20:43:49,"That’s so true. To take it to enterprise grade, an entire architectural composition is required."
2023-06-27 20:44:05,I actually have a hot take here 🙊
2023-06-27 20:49:50,"Guys, I'm planning a Responsible AI Fellowship Fund that will give grants of $5K-$75K to individuals and projects building Open Source Software that address the both Ethical and Societal issues in AI, and / or those building the base tools / frameworks / models / research that others can use. "
2023-06-27 20:50:55,"In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well."
2023-06-27 20:51:10,*many not most
2023-06-27 20:51:44,Unpopular personal opinion:
2023-06-27 20:55:06,"I'd extend it to 6 - adding Databricks, Salesforce and Snowflake there"
2023-06-27 20:56:10,this is a super neat demo !
2023-06-27 20:58:12,👏
2023-06-27 21:21:39,"its just half the truth with regard to ""enterprise"" capabilities of big 6. The ""shared responsibility"" term scares a lot of business, especially large ones. While it could be tactical TTM pressures that drive most of them to CSPs, objective evaluation later puts them back to on-prem and colos. The paranoia in some cases went to such levels that we saw a potential in building segmentation at the lowest level ( link layer -eg.  GWLB svcs from all the CSPs and L2-NV from OCI). May be you are right for the SME, mid-mkt players that their core functions are cSP driven. But the large ones are still super paranoid about their infra & data. The levers of data propagation into sharepoints/githubs/boxes are well  established, controlled and monitored to mitigate DL mishaps."
2023-06-27 21:29:16,Didn't see it coming that 'Inspect Element' will get productized
2023-06-27 21:48:05,"Creator of PaLM-2, UL2, Flan, Bard has announced a new $58M seed funded AI Lab called ""Reka"" reka.ai"
2023-06-27 21:48:26,extremely apt productization though
2023-06-27 21:50:19,Wow. 58M$ for seed round. Is this the biggest one in history? 😂
2023-06-27 21:51:01,"Nahi, Mistral had $150M no? Or $113M or something like that"
2023-06-27 21:52:41,Ahh yes. 113M $
2023-06-27 21:52:56,"Not large enough rounds tbh. Anything less than $500M, hard to build the companies these folks are trying to build. "
2023-06-27 22:02:54,Has anyone tried inference on Falcon model by loading it in 8 bit ?
2023-06-28 00:39:45,https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android
2023-06-28 00:41:16,I've only heard his piece and not the questions he was asked. 
2023-06-28 00:42:00,"I'll move it there, thanks."
2023-06-28 02:39:41,Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks
2023-06-28 03:14:35,Don't have any benchmarks but that's what they recommend. 
2023-06-28 03:32:00,"I agree. My experience has been different compared to what was discussed here, while building enterprise version of our application for Agri MNCs. There are concerns about data but there many use cases just to build on top their public data. Many already uses Azure, and using Azure OpenAI instead of OpenAI already addressed few concerns."
2023-06-28 04:37:47,"Thanks for the suggestions Nilesh, will add them to the list of topics at our launch hackathon."
2023-06-28 05:33:21,TIL about MLPerf[0] and MLCommons[1]
2023-06-28 08:46:51,Anyone here has insights on what ChatGPT for business will look like?
2023-06-28 08:51:21,"Apart from these few, more are based on industry and customers"
2023-06-28 09:19:45,12K+ ChatGPT credentials from India are on darkweb
2023-06-28 10:10:31,"For folks looking for speaking opportunities, FifthEl is India's best ML/Deep Learning conference, Aug 11 this time: "
2023-06-28 10:11:11,cc [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] thought you might want to speak here
2023-06-28 10:13:34,[PHONE REMOVED] is talking about LlamaIndex. And hopefully convert you all to LlamaIndex users ;).
2023-06-28 10:14:41,"Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs)."
2023-06-28 10:20:28,Whisper.cpp is adding diarization in next 2-3 months
2023-06-28 10:37:47,"Hi have any of you come across a project which covers an agent for iOS commands, enabled by llms?"
2023-06-28 11:05:40,"I doubt Apple would allow external automation on their platform, tools like Tasker have never existed for iOS"
2023-06-28 11:06:45,Apple has a native automation tool for both ios and macos
2023-06-28 11:09:21,"Haaa, really ... damn. But can it do stuff like intercept calls, notifications et al?"
2023-06-28 11:11:00,"Probably not, apple is too pedantic about notifications"
2023-06-28 11:25:39,Nice one [PHONE REMOVED]
2023-06-28 11:29:26,You can even use chatGPT like Siri using apple shortcuts https://twitter.com/mckaywrigley/status/1640414764852711425
2023-06-28 11:35:32,"We don't have 2-3 months 🥲, need something for now. We can train it with some data."
2023-06-28 11:45:06,This and function calling ❤️
2023-06-28 11:51:12,"I think the diagram in this article has a typo. They advertise mask R-CNN training in under 1.5 minutes. That doesn't seem right. If it was the correct number, I wonder how they optimized I/O."
2023-06-28 11:52:43,Has anyone implemented Microsoft guidance?
2023-06-28 11:55:49,Are u using the new model 0613 version of 3.5 ? The json formatting should work
2023-06-28 12:04:02,Check this if not done already
2023-06-28 12:13:41,I am using gpt-3.5-turbo-0613
2023-06-28 12:14:33,Just wrap with Guardrails? https://github.com/ShreyaR/guardrails/
2023-06-28 12:14:42,"Also, I am controlling the output using prompt, not using any external package yet."
2023-06-28 12:15:21,"In this case, give OpenAI Functions a chance"
2023-06-28 12:15:31,ok will implement.
2023-06-28 12:17:35,"If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which [PHONE REMOVED] uses as well: "
2023-06-28 12:18:36,"Meta released a paper on the recent method to increase context length using position interpolation. *The 2k context LLMs are now shown to be well functioning in various tasks like retrieval, modelling, long form summarisation with just fine tuning. A pretraining from scratch wasn't needed to increase context length to 8k, just fine tuning was enough (even LoRA).*"
2023-06-28 12:18:39,Tried this
2023-06-28 12:19:39,Or if you are feeling brave and experimental try this one: https://tinyurl.com/5n8rpu23
2023-06-28 12:21:02,I endorse this.
2023-06-28 12:21:16,"kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms — this can be a difference of about 3-10x"
2023-06-28 12:22:32,"Ramsri [PHONE REMOVED] I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?"
2023-06-28 12:27:31,I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it’s write once read many times sort of a situation it tends to spread the cost overall. 
2023-06-28 12:28:13,Of course there are nuances I have skipped here but some internal work is happening on this.
2023-06-28 12:29:23,"We have tried, and the results are not great, and each has its own challenges. "
2023-06-28 12:37:54,Analog Diffusion (iphone)
2023-06-28 12:39:03,Open-source LLM-based theorem prover: https://leandojo.org/
2023-06-28 13:11:07,"Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?"
2023-06-28 13:13:04,aider.chat/docs/ctags.html
2023-06-28 13:35:23,this is a very very smart usage of ctags. ctags-as-a-vector-db. 
2023-06-28 13:37:41,I am low key sad that I didn't think of this
2023-06-28 13:38:44,Has someone experimented with any models to generate TV ad quality video content?
2023-06-28 13:39:47,cc Shubham [PHONE REMOVED] from TVF might know more about this
2023-06-28 13:42:10,Would love to collaborate on this
2023-06-28 13:42:49,"Doing a lot of things at LangFlix but it’s not just one model, but a pipeline of multiple models."
2023-06-28 13:43:50,What is LangFlix?
2023-06-28 13:44:11,Side project https://youtube.com/@LangflixAI
2023-06-28 13:45:34,"Bringing books summaries in Indian languages, complete AI pipeline"
2023-06-28 13:46:43,"Terrible name, great idea!"
2023-06-28 13:47:20,I’m becoming rebranding expert
2023-06-28 13:47:39,Nirant got Langchain Trauma seeing the name.😂😂
2023-06-28 13:47:41,"Say more, what did I miss?"
2023-06-28 13:48:10,I've seen these AI 30 min hypothetical interviews on Spotify
2023-06-28 13:48:13,"Aee, I just got my first PR merged yesterday: https://github.com/hwchase17/langchainjs/pull/1771"
2023-06-28 13:48:48,"I was referring to the Readme on aiagent. ""Unchained"""
2023-06-28 13:50:51,Langchain trauma - working on langchain after the era of crypto?
2023-06-28 13:51:22,Is it automated end-to-end? What exactly do you still have to do manually?
2023-06-28 13:51:37,Some folks use gooey every now and then to create a music video / short explainers - not tv quality though - just passable
2023-06-28 13:51:38,Enter book name
2023-06-28 13:53:46,I think they added MusicML for background music too recently. I started the project and handed over to friends as I am focusing on KissanAI
2023-06-28 13:57:47,"Also everything is done on 3090s, almost no cost."
2023-06-28 13:58:00,wow.. will check it out.. i had similar idea for niche regional books.. but haven't started any work on it yet
2023-06-28 13:58:24,Send suggestions in DMs
2023-06-28 14:08:54,"This is one of few unique ideas for source code handling, especially with LLMs. "
2023-06-28 14:09:07,Copyright issues?
2023-06-28 14:10:07,"Summaries, images, everything is AI generated"
2023-06-28 14:10:12,How'd you extend this for Python/Java/JS?
2023-06-28 14:14:41,I use this and am able to generate perfect json response every time. works great.
2023-06-28 14:15:11,"There's already a general map of repo with aider using ctags. I'll extend it to include symbolic links with the help of namespace and import commands, but I'll have to explore it in detail. "
2023-06-28 14:16:18,"Not many tools that work for us gpt-3.5 peasants 😅 , gpt 4 is just way better."
2023-06-28 14:16:23,"To set fair expectations, there is a failure rate of about 7 in 1000 right now."
2023-06-28 14:17:08,"Interesting, how did you measure that ?"
2023-06-28 14:17:41,Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times
2023-06-28 14:24:19,GoCodeo AI helps automate the testing process 😁
2023-06-28 14:25:04,Hallucinations are also taken care of
2023-06-28 14:29:00,"I am very skeptic that AI solutions can do better than Code Interpreter, given how far behind even WizardCoder is. "
2023-06-28 14:31:42,Fully AI Generated Podcast bringing the guests that will never get the chance to go on the real Joe Rogan Experience
2023-06-28 14:31:42,https://t.co/pNqa1JMZMt
2023-06-28 14:32:16,There’s a lot of content being made lile joe rogan ai experience that [PHONE REMOVED] made me aware of. I was living under the rock
2023-06-28 14:35:27,The base layer of GoCodeo is GPT and the in-house algorithms on top of it ensure code context and intelligence. Which means reduced errors and failure.
2023-06-28 14:36:00,I interested in knowing how we can use AI to identify AI hallucinations
2023-06-28 14:37:12,A separate instance of LLM can segment the generated result and fact check it with the database.
2023-06-28 14:37:21,Code Interpreter is amazing at code generation including test writing. It often generates test cases which I have missed when I ask it to use fuzz testing in particular. 
2023-06-28 14:38:33,So fact checking is still based on human curated db
2023-06-28 14:40:09,Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.
2023-06-28 14:43:00,"There is a new ""Pair Programmer"" feature on Phind.com, I found it pretty powerful! Do try it out."
2023-06-28 14:44:09,"😞 I thought I missed out on a breakthrough. No Ouroboros, yet. We got a long way to go."
2023-06-28 14:44:14,Hallucinations until now have been identified by our enterprise partners and with those learnings we are building AI models for rectification and further identification.
2023-06-28 14:46:40,"Interesting name for fine tuning a model optimised for fact checking. Instead of RAG, fine tune an LLM for fact checking given a generated answer and retrieved context "
2023-06-28 14:47:25,EMNLP for Industry track is still open 🤣
2023-06-28 14:47:28,[PHONE REMOVED] see I’m not that bad at naming. 🤣
2023-06-28 14:47:43,Is it integrated into vscode?
2023-06-28 14:48:14,"My biggest pain is switching from here to the browser and copying it back, then modifying it"
2023-06-28 14:48:27,Or copying the error stack over and asking for an explanation
2023-06-28 14:49:07,many such cases 😜
2023-06-28 14:52:14,"Did quite a few experiments which ended up going in production, with multiple models in a single flow though."
2023-06-28 15:15:18,Is there a good guide on creating QnA bot on Notion knowledge base using Langchain? I created the most basic one but it is not giving statisfactory answers.
2023-06-28 15:31:27,"""Pyannote had the best open source performance."" "
2023-06-28 15:34:04,Have been playing out recently with pdfs. Basic RetrievalQA works decent. Rest is all chunking and routing logic that you can build on top.
2023-06-28 15:37:13,Thbks. How do I learn chunking and routing logic thing? Both fundamentals and application! :)
2023-06-28 15:40:13,Routing logic has some introduction in llamaindex docs. But mostly diving into code. 
2023-06-28 15:50:41,Thanks. Will start with chunking.
2023-06-28 16:01:10,"My understanding is that this would take quite sometime to get to TV ad quality for videos. Given the state of image generation and the number of times it fails to match expectations, it is difficult for me to expect video generation to be TV quality. "
2023-06-28 16:03:38,"Crucially the GenAI models for images are great for exploration, but if you already know what you want and are trying to get that image done quicker, then there are still issues."
2023-06-28 16:04:13,"I guess specific parts of the ad can be generated. Most of the magic will still have to be done by a video editor though. Even with the coke ad (although publicised as Generative AI), most was traditional CGI and good editing"
2023-06-28 16:06:15,"You can make zoom in and zoom out reels. They can work with out painting and then adding them to video editor, but temporal consistency between scenes are not yet solved to my knowledge."
2023-06-28 17:44:08,How long does it take to generate a video?
2023-06-28 18:25:24,"We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc)."
2023-06-28 18:42:13,"Reliability of source will lead you down the same road as Google - Experience, Expertise, Authority, Trustworthiness to build up reliability of a source. Platforms or sources with reputation get maximum brownie points, reputation again is an associative entity (EEAT as mentioned above)."
2023-06-28 18:44:01,"My answer was also more on the side of *given that we can trust the database from where retrieval is happening, how to fact check the generated output using an AI?*"
2023-06-28 18:46:27,"DA = Domain Authority. DR = Domain Rating. Introduced by SEO folks. Ahrefs, Moz, etc"
2023-06-28 18:49:38,https://youtu.be/Wc22W3bos64
2023-06-28 18:54:00,Generate individual characters from midjourney -> convert them in video form by just animating faces for voice over using D-ID - > text to speech via elevenlabs
2023-06-28 18:55:18,but what about the sound signatures ?
2023-06-28 18:56:05,You mean the accents from different languages or something else?
2023-06-28 18:56:17,"Yes, exactly"
2023-06-28 18:56:28,Accents
2023-06-28 18:57:11,have you seen anything which works well for csv/tables/sheets/xls? Embedding breaks the file in chunks for context size(16K) and then information is lost for queries which need something across many rows (ie different chunks)
2023-06-28 18:58:06,It's where claim detection comes in. You select passages / sentences which are then sent for fact checking
2023-06-28 18:58:10,"There isn't a TTS model trained for latin, mayan, greco-roman accents. My trick to crack it would be to use phonetics."
2023-06-28 19:02:09,"If you notice in the video, it's like 1 or 2 words are being pronounced separately rather than the complete sentence in a fluent manner. You can pick up a language close to the ancient versions and use phonetic spellings in that language to force a different sound with same accent"
2023-06-28 19:07:06,Part II has Sanskrit so yes this indeed is super convincing!! https://youtu.be/wC0UG-Oq_90?t=60
2023-06-28 19:18:20,"If you move over to Old Chinese, you'll notice each sound being enunciated separately, looks like a clear use of phonetic pronounciation. Sanskrit one is very convincing."
2023-06-28 19:28:43,The way people are going about it is to generate multiple variations and handpick the nearby ones to show small motions or gif… but that’s about it
2023-06-28 19:40:04,Is there any literature / post about insurance policies (rise in their sale) to protect businesses against downside of bad stuff happening to them
2023-06-28 19:46:32,Don’t know in Indian context but recently JP Morgan in UK context has been trying to make an insurance company pay for a multimillion dollar deal that did not go through.
2023-06-28 19:53:29,"There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?"
2023-06-28 19:55:20,Have you used SciSpace? It's very good. They have a chrome extension as well.
2023-06-28 19:59:49,https://twitter.com/soumithchintala/status/1674045982298841094?s=20
2023-06-28 20:00:33,i have used chatpdf.com
2023-06-28 20:01:45,"shameless plug - https://pensieve.springworks.in/ - chat with any document (pdf, doc, csv etc)"
2023-06-28 20:02:47,"Research papers have an ""Abstract"" section right? That's usually the summary of the paper. Any specific kind of summary you are looking for?"
2023-06-28 20:06:29,Consensus also
2023-06-28 20:11:07,looks pretty neat !
2023-06-28 20:11:46,i am surprised i had never heard of it.
2023-06-28 20:14:21,It was the most feature rich product for reading research papers even back in November. They had options to directly answer questions on tables as well as mathematical equations as well. But they aren't very good at promoting themselves 😅
2023-06-28 20:15:31,"Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?"
2023-06-28 20:28:58,Go for advanced
2023-06-28 20:29:50,Go for an M1 Pro atleast
2023-06-28 20:32:45,it may be cheaper for you in the long run just to use vast.ai
2023-06-28 20:33:13,"Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?"
2023-06-28 20:37:16,I'm keenly following answers to this question too.
2023-06-28 20:53:30,For QnA bots I just ask my friends to try out demos and pray that it works 9 out of 10 times. The same cannot be said for apps built for finance or medical matters though. I am still figuring it out
2023-06-28 20:55:50,Prompt engineering in my experience is way tougher than it looks at the outset
2023-06-28 21:00:57,I am actually looking for assets in this layer.. in fact I cannot imagine what an asset in this layer should look like. How can we design a module that can be configured to handle validation for gpt responses from a target set... Or a module that handles malicious qns...
2023-06-28 21:01:26,Or even a modular approach to designing that prompt layer that serves numerous use cases
2023-06-28 21:10:46,"Yeah, i got really excited in Mar and bought M2 pro just a day after llama.cpp was released. Now it's not useful for anything other than some toy runs with GPT4all and privateGPT."
2023-06-28 21:24:21,Old thinkpads suddenly become very valuable
2023-06-28 21:24:58,Not sure. Can't handle that red button as a mouse
2023-06-28 21:26:45,Ah trackpoints. But any older laptop decent enough to code on + cloud based infra = viable dev environment. cheap and cheerful sometimes works well.
2023-06-28 21:27:16,Having a Colab TPU instance or some cloud instance has changed the game
2023-06-28 21:27:38,This I agree. I'm still in my old 2015 Mac
2023-06-28 21:28:41,Jeremy Howard (FastAI) once wrote about training a SOTA CNN model (several years ago) with $28 on AWS
2023-06-28 21:28:58,Game changing value for small (and big) teams
2023-06-28 21:29:52,Ya those were trained without colab pro on free gpu in 5 minutes.   Simple times
2023-06-28 21:30:23,Finetuning not pretraining
2023-06-28 21:30:51,"Yes, the age of deep learning before LLMs... *clears cobwebs*"
2023-06-28 21:32:57,There was a Twitter subculture some time ago for GPU based PCs - it looked as though anyone working on DL stuff had to have this big fancy RGB laden powerhouse. We're reaching the *ahem* plateau of productivity...
2023-06-28 21:39:19,Ya. [PHONE REMOVED] can shine light on this. He has a lot of useful experience here
2023-06-28 21:40:20,I only have 12 GPUs. I don’t have a lot of compute compared to other Kagglers 🥺
2023-06-28 21:40:58,Some people on Twitter want to come after you. They think more than 10 should be made illegal 😂😂
2023-06-28 21:52:50,Me: <you have GPUs?>
2023-06-28 21:53:35,For context: some Kagglers use 40+ GPUs freely everyday^
2023-06-28 21:53:47,(Provided by their orgs)
2023-06-28 22:06:06,"Eggjactly, too lazy to find the pic"
2023-06-28 22:24:18,"Please do not post on social media, early community preview (needs Github Sign in): "
2023-06-28 22:30:57,this feels like a topper in clg saying I got 9.5/10 CGPA and still sad 😂
2023-06-28 22:32:05,Imagine if Kagglers who have 40 gpus only do xgboost.
2023-06-28 22:32:10,I say this as hypothetical only. I know we have some gun kagglers in this group
2023-06-28 22:41:12,Good area to explore.
2023-06-28 22:45:57,What happens if a question is asked over and over again. 
2023-06-28 23:19:59,https://twitter.com/siddarthpaim/status/1674108143037448200?s=20
2023-06-29 00:19:55,https://twitter.com/Suhail/status/1674124521543192578?s=20
2023-06-29 00:23:39,We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.
2023-06-29 00:25:56,Love this idea. Lets do this for a hackathon!
2023-06-29 00:30:41,"Here's another, and it has recs from the godfather of Shaders Patrizio. Who is also responsible for some key developments in runwayml"
2023-06-29 00:30:45,https://www.modyfi.com/
2023-06-29 00:35:25,Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?
2023-06-29 00:42:26,Pass the output to gpt 4 again to proofread / verify?
2023-06-29 00:43:22,GPT-4 can you verify whether the answer you've generated is correct?
2023-06-29 00:43:53,Depends on your standard of QC too. Proofreading does not avoid hallucinations in many models.
2023-06-29 00:44:00,"On a more serious notes, I've found this approach works to an extent"
2023-06-29 00:45:14,"Recently, there was a case in the US where a lawyer submitted a legal doc generated by GPT and asked it multiple times to ensure everything was correct. It still made up cases out of thin air, leading to the lawyer receiving disciplinary action for not manually verifying the info"
2023-06-29 00:45:39,No I think you need to RAG over here.
2023-06-29 00:45:48,https://www.cnbc.com/2023/06/22/judge-sanctions-lawyers-whose-ai-written-filing-contained-fake-citations.html
2023-06-29 00:46:00,legal documents are tricky. A word modified here and there and  the client finds himself hanging at  the court with the opponent tearing at them.
2023-06-29 00:46:36,"ideally, yes, to avoid such cases"
2023-06-29 00:47:25,also GPT-4 ko poocho agar poochna hi hai
2023-06-29 01:01:03,https://github.com/salesforce/xgen - 7B models from salesforce with 8K context length.
2023-06-29 01:04:37,I really like Salesforce from the time they've been releasing codegen and BLIP models. Looks like they want to give Meta some company in open source gen AI research.
2023-06-29 01:08:02,"In my field, biology and medicine , they have published quite a bit on generative protein design"
2023-06-29 01:10:08,Now I like them more.
2023-06-29 01:12:46,Assuming no external sources and the doc only has to be analysed for what it contains.
2023-06-29 07:53:13,came across this older but very exciting neurips 2021 paper on learning from videos !
2023-06-29 08:29:41,"Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?"
2023-06-29 08:30:27,Done it
2023-06-29 08:31:25,"You need to be careful with chunking, add metadata and perform hybrid search (tfidf + vector) for results that need high accuracy"
2023-06-29 08:32:31,Downsides : every once in a while the es cluster will kill a node bc Java oom. Correct configuration for your specific use case is an art
2023-06-29 08:39:59,Happy to connect you with folks who've done it
2023-06-29 08:47:11,There are no downsides. Have used ES for vectors at scale.
2023-06-29 09:37:28,New Technique Gives Designers Added Capabilities by Incorporating Engineering Constraints Into Generative AI Models
2023-06-29 09:48:25,"Really interesting. Karen Willcox (and Olivier de Weck) have been talking about AI models for digital twins a bit. What's interesting about this space is the realm of physically based modeling - that dovetails into generative AI capabilities. The article has a video that discusses optimizations of the structure, performance, aerodynamics around the main exterior design provided - De Weck and Willcox did a lot of work at MIT (and published OCW courses) on multi disciplinary optimization - a highly underrated field of systems design and optimization amidst all this AI hype"
2023-06-29 09:50:12,Any resource to read about fine tuning Diffusion models for industrial designs ?
2023-06-29 09:50:24,Based on engineering specifications ?
2023-06-29 09:53:36,"I know very little about diffusion models, and haven't explored this line of thinking but they may be relevant for topology optimization. Thanks for the note. But MDO and MDSO are practiced at least with low fidelity in aerospace and automotive engineering design (concurrent - across digital engineering, manufacturing and verification/validation). Related work https://arxiv.org/abs/2208.09591"
2023-06-29 09:57:19,"I've sometimes thought of topology optimization as an n-sample sign test (akin to the 1 sample sign test in statistical inference) subject to results by simulation, with an objective function. If that makes sense and is not an oversimplification."
2023-06-29 09:57:24,"Hi folks, "
2023-06-29 09:59:00,cc [PHONE REMOVED] runs a business on search+LLM
2023-06-29 10:02:37,"If you just want to search the Google page, SerpAPI is way easier to implement. "
2023-06-29 10:08:13,Autodesk has been working using AI for engineering design for quite some time now
2023-06-29 10:08:39,"Thanks [PHONE REMOVED], dropped you a DM [PHONE REMOVED]"
2023-06-29 10:16:56,"Yes, they first made a splash with it in 2020 or so, there was a TED talk"
2023-06-29 10:18:59,I attended Autodesk’s AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.
2023-06-29 10:21:46,I'd love to hear about what you explored here. It promises to be interesting
2023-06-29 10:26:49,Sure
2023-06-29 10:31:09,https://vimeo.com/372439670
2023-06-29 10:49:58,Thanks! :)
2023-06-29 11:08:58,Here's a benchmark of ANN algorithms and implementations across various vector databases: https://github.com/erikbern/ann-benchmarks - might be helpful to understand tradeoffs for this choice!
2023-06-29 11:52:18,"This is great. Seems like a good way to bring AI to real world problems, rather than just building another chat bot or image generation app..."
2023-06-29 11:53:26,"Not to belittle the challenges behind these things of course, but there are other problems to solve too, in engg and systems design"
2023-06-29 12:24:23,Nice. Saw your tweet as well. Do we have a way of checking GPU usage by the model akin to Nvidia SMI?
2023-06-29 12:24:35,This is CPU sir
2023-06-29 12:25:09,I'm tempted to try it now. Thank you :)
2023-06-29 12:29:04,"The inference is very slow for 30B models on M2 pro, what's your token gen speed? Plus, this Yann Lecunn question stumbles even GPT3/4, it will be interesting how the 30B answers it though."
2023-06-29 12:32:28,Share details of the magic :)
2023-06-29 12:45:27,You can guys also do this demo at your PC:
2023-06-29 12:45:40,It's a captivating demo!
2023-06-29 12:47:39,"abacaj on Twitter is wrapping it in a script, should be out tonight"
2023-06-29 12:50:33,Thanks bud
2023-06-29 12:51:13,"Pretty neat, thanks"
2023-06-29 12:51:38,"Meanwhile, koboldcpp, ctransformers have mpt 30B 4 bit inference support. You should be able to find a simple guide to test it out even on Windows, provided you've ~30G free RAM"
2023-06-29 13:08:37,https://github.com/abacaj/mpt-30B-inference
2023-06-29 13:13:52,[PHONE REMOVED]  
2023-06-29 13:36:45,"The best way is to pre-qualify each of the datapoint and analyze for parts that matter to you - like correctness, coherence etc. Would love to know more about how are you doing it currently."
2023-06-29 13:54:33,I'm not using Docker
2023-06-29 14:29:47,https://erichartford.com/openorca
2023-06-29 14:32:41,I'm looking at the same code / script. Slow as molasses for first inference. Mine is an older Mac. Perhaps I should try this on Colab
2023-06-29 14:35:02,"They claim to be ""The first WebGPU enabled image editing platform."" Has anyone been able to work with webGPU here? How was the experience ?"
2023-06-29 14:40:55,"Yeah, I like him but I can't say that OpenOrca would be useful for anything other than his personal or his sponsor's advertisements."
2023-06-29 14:42:01,"Their first release for OpenOrca is on Llama 7B and it includes a semi-GPT4 guided dataset, so even that is kind of a blurry line."
2023-06-29 14:43:10,You'll need a high RAM instance or you may try the GPU offloading version for inference.
2023-06-29 14:44:15,"Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now"
2023-06-29 14:44:52,"Apple uses shared memory and better integration means this may run better on Macs, but I have a Linux machine (Thinkpad) with 24 GB. If it doesn't work, there's always Colab"
2023-06-29 14:57:01,~30G is recommended minimum for decent speed
2023-06-29 16:41:55,Colab pro par chalega?
2023-06-29 16:47:19,Try and find out!
2023-06-29 16:47:30,I've not had a chance to try
2023-06-29 18:25:00,Supabase CEO on pgvector's lackluster performance in the ann-benchmark
2023-06-29 18:43:17,Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.
2023-06-29 18:44:24,Please react to this message if you’re okay with me reaching out
2023-06-29 18:44:29,https://arxiv.org/abs/2008.09820 
2023-06-29 18:45:35,"Yes, I have used xlmr."
2023-06-29 19:15:38,I’m trying to use that only
2023-06-29 19:16:25,Colab pro you get more ram if you use advanced gpu setting
2023-06-29 19:16:34,Just fewer hours
2023-06-29 19:25:06,I've used XLM quite a bit for text classification (https://arxiv.org/abs/1901.07291). happy to help!
2023-06-29 19:29:45,+1 for XLM
2023-06-29 19:31:58,It's a franchise!
2023-06-29 19:32:05,My prediction was ChaatGPT but close enough
2023-06-29 19:32:33,"Thinking about scale from day 0. Scaling is all you need, no? 😜"
2023-06-29 19:34:27,I know this has been slightly discussed before but is there any document or page comparing Redis and Qdrant? any place people have shared their experience in production?
2023-06-29 19:57:44,"I'll suggest trying out HingRobertaMixed and HingRoberta via HF inference. They are xlm-roberta fine tuned for code switching (Hindi+english) tasks. You may not need to fine tune specifically for tasks such as sentiment analysis, hate speech detection and other NLP subtasks."
2023-06-29 19:59:47,What’s the prompt for this one ?
2023-06-29 20:05:53,Sorry guys!
2023-06-29 20:13:39,There is a chaatgpt here in Mumbai
2023-06-29 20:33:28,"With all specialised LLMs in place for different use cases, do you think being able to switch from 1 LLM to the other along with context developed previously would be important? Basically communication between 2 or more LLMs"
2023-06-29 22:04:33,https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding
2023-06-29 22:13:29,"Well, looks like Microsoft wants their hands in every piece of Pi."
2023-06-29 22:37:35,Yeah man! They have nailed it.
2023-06-29 22:38:23,"I guess, they might have invested in companies working on genAI videos as well"
2023-06-29 22:59:38,I think there are two components here.
2023-06-30 00:03:10,Has anyone used Pi? Curious to hear what others think
2023-06-30 00:04:03,Think [PHONE REMOVED] has applied for access for this. So waiting..
2023-06-30 00:05:05,"More empathy, friendliness and comfort in conversation. Not very high in reasoning when I checked it out but conversations flow very well."
2023-06-30 00:24:07,"I shared this as it highlights one of the important things I've mentioned while working with similarity detection or information retrieval, "
2023-06-30 00:27:36,"In all the cases BM25 beats the famed miniLM-L6-v2 and mpnet-v2 embeddings, we find following patterns"
2023-06-30 00:44:55,Interesting! https://twitter.com/AnthropicAI/status/1674461614056292353?s=20
2023-06-30 07:57:58,"That reminds me, what do folks think of Poe ( from the quora founder ) ?"
2023-06-30 08:14:53,Isn’t that a skin on chatgpt
2023-06-30 08:16:42,"Its open, I dont think you need to request access"
2023-06-30 08:47:25,https://twitter.com/lmsysorg/status/1674562017410297856?s=20
2023-06-30 10:02:24,There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?
2023-06-30 10:04:27,"If there are more than 10 folks interested in this, can do a curated compilation of all community resources around prompting for text. "
2023-06-30 10:06:54,Am also wondering how to package reusable prompting strategies like a layer designed for reuse to many use cases above it
2023-06-30 10:13:36,These are some of the prompt engg guides links I had kept if anyone is interested. It includes the one shared here : https://crocus-almanac-be9.notion.site/Prompt-Engineering-002d00ac83074a45adfdd4263cff573f
2023-06-30 10:14:37,https://forms.gle/aTLXNo3QXQyhmi9g9
2023-06-30 10:32:58,You mean this one - http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
2023-06-30 10:38:23,Basics of Prompt Engg https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction  
2023-06-30 10:43:29,Sometimes going there for only conversation not for knowledge
2023-06-30 10:56:09,Do you know what kind of things they do to make conversation interesting?
2023-06-30 11:01:43,great compilation! cc community resources [PHONE REMOVED]
2023-06-30 11:18:37,1. Conversation like Friendly Human
2023-06-30 11:22:47,link share kar do. This one looks like a Railway reservation chart
2023-06-30 11:23:01,"Pi is distinctively good for those late night convo you’d have with a friend - stuff that’s on your mind, anxieties, etc."
2023-06-30 11:23:05,But damn the number of events. Shows where its at
2023-06-30 11:23:34,https://docs.google.com/spreadsheets/d/1P6ut7vL-gXKbeDeh3nuPqBjoCupjIt87Sw7TnhumBSU/htmlview#gid=1781893986
2023-06-30 11:26:33,Events are not a proxy for great companies or problem statements although they can sometimes be. There’s lots of AI opportunity and work done in East Asia as well without as many events
2023-06-30 11:26:45,That’s surprising
2023-06-30 11:27:32,"yes true. If you're only attending events , then you're not working. But still interesting to see this."
2023-06-30 11:27:47,Actually they are. Those silent warriors of East Asia are moving where they are heard.
2023-06-30 11:29:09,"It’s different feeling when you can bump into Karpathy, Fridman, or others here and there"
2023-06-30 11:29:18,There’s also a cottage industry of influencers also that just want to organise these events. And give away awards like 40 under 40. Someday we will even see 90 under 90 awards in AI. Not to downplay the importance of these events
2023-06-30 11:30:17,That’s because they have media empires in addition to being or having been technical leaders in their fields.
2023-06-30 11:31:18,https://twitter.com/EMostaque/status/1674509839458791431?t=EtblykAzDT4d6EpdDiZesA&s=19
2023-06-30 11:31:42,How many will come if Ishan Mishra or Szegedy are invited as key speakers? Maybe some but not as many as Friedman or Ng. Just the way things are with media empires and tech gurus
2023-06-30 11:34:00,"Call it a tech guy's bias, but I find others only useful as news reporters. Very few folks like karpathy but 🤯 and 🧵👇 is what is everywhere"
2023-06-30 11:35:02,"Is this a rant for missing out or do you have exact engagement numbers for other events. In SF, you may be sitting beside Anthropic CEO and you may not know. That’s talent concentration."
2023-06-30 11:37:49,"Question for me is more practical - would you sit through a Sam Altman monologue in person or online at your convenience, while you get work done wherever else you are. Do you have to be in the city and in person to really get the best out of the event? Is Anthropic the only source of inspirational ideas for me or can I get them from elsewhere by attending an event remotely, or elsewhere? We do live in a world where a lot of teams are remote, great work is done remotely and distributed, so is there a reason to drool over SF events?"
2023-06-30 11:38:49,Many of us who are working with the tech may get more out of a (Lex Fridman podcast) with Ishan Misra in it or someone else than a highly marketed event. So it depends.
2023-06-30 11:39:25,Why are you trying attend all 84 events? 🤷‍♂️
2023-06-30 11:39:54,"Like, do you watch every podcast ever produced on tech?"
2023-06-30 11:40:44,"Who is attending all 84? And who is watching every podcast? You have arguably more choice online as events stream, than if you were in person - and I agree if you're a business leader you may need to be in person for some things. Your focus then is different."
2023-06-30 11:41:58,"This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed"
2023-06-30 11:42:28,There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.
2023-06-30 11:42:39,Great idea. Meeting summarization is a superb idea in general
2023-06-30 11:43:14,Which tech podcast do you listen to? Can you recommend some.
2023-06-30 11:43:34,"Podcast is a one way street for learning, have a good hot discussion in person with few folks who know their things and not just asking questions."
2023-06-30 11:43:39,"I guess Rewind added this feature recently, they record your meetings and gets you minute of meetings."
2023-06-30 11:43:43,"Remote is great for certain things, and in-person great for other things, IMHO. To each his own."
2023-06-30 11:45:42,"Strata used to be doing conferences left and right, spoke at one of them some years ago - and for 2016 they had a good experience in playing back the meetings and so on. I don't think they did summarization back then though"
2023-06-30 11:46:05,meetups make more sense with remote work now.
2023-06-30 11:46:19,Even modest human generated summaries would have been good.
2023-06-30 11:46:41,...that nobody reads😅
2023-06-30 11:50:42,all the more reason to offload the task 😄
2023-06-30 12:02:30,Need to say this louder💯
2023-06-30 12:30:56,https://towardsdatascience.com/vllm-pagedattention-for-24x-faster-llm-inference-fdfb1b80f83
2023-06-30 12:32:06,https://pi.ai/s/14R8gbnGNeM9Fo75qLH4p
2023-06-30 12:39:53,Yes I've studied the vLLM method. It uses continuous batching to reduce memory footprint by avoiding loading model parameters every time on every conversation.
2023-06-30 12:40:24,It's not for a peasant like me who has 1 machine to work on and not 100s of parallel running instances
2023-06-30 12:40:28,"Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?"
2023-06-30 12:40:46,Initially felt like every company is doing this... surprisingly can't even find one!
2023-06-30 12:41:31,It's for guys who are api providers or have to maintain conversations using the LLMs across multiple chat sessions (best if 50-100).
2023-06-30 12:48:13,https://lmql.ai might come close?
2023-06-30 12:51:09,cool... I'll check it out
2023-06-30 12:51:32,"we also take our different approach here. instead of inventing a new language/sql, we use jsonnet - which is a config format used at Google Borg/Kubernetes. we specify the chain + prompt in jsonnet so no multiple layers of libraries/functions to navigate through. "
2023-06-30 12:52:32,"Wow, Pi is beautifully put together"
2023-06-30 12:56:43,Interesting... Will check it out
2023-06-30 13:06:20,"Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes."
2023-06-30 13:11:30,Wow is this your chat?
2023-06-30 13:14:06,yeah .. just horsing around
2023-06-30 13:14:25,Bot handelled it well I must say
2023-06-30 13:14:48,but again the guy behined the company is co founder of Deep Mind
2023-06-30 13:14:51,[PHONE REMOVED] is the founder and here 👋
2023-06-30 13:16:57,"way too safely hidden behind the waitlist... as of now, cant wait to try it actually"
2023-06-30 13:17:41,"Damn! Sorry, can you send me a DM and I’ll give you access right away?"
2023-06-30 13:28:05,"Thanks! And true - this has been a big thing to manage for us as well. Costs of all models, newer ones and discounts and credits at times"
2023-06-30 13:28:36,"In the future, we’ll try opening up an API just for easy pricing."
2023-06-30 13:29:24,Azure openai service seems to have a way of doing this. I’m not sure about openai’ own endpoints
2023-06-30 13:33:48,Custom product just for this one use case
2023-06-30 13:34:35,I think langchain or llama index support some functions ro monitor cost
2023-06-30 13:35:22,"just played with it,"
2023-06-30 13:37:15,"thanks, using this seems to be the best option, since folks will ensure it remains up to date"
2023-06-30 13:50:18,We’re building a solution around this at quolum.io
2023-06-30 13:51:10,"ohk, I was asking since I'm open sourcing a related library myself haha"
2023-06-30 13:51:16,Id be happy to show you a demo
2023-06-30 13:51:28,Xd no demo then
2023-06-30 13:57:05,"Helpful , thanks :)"
2023-06-30 14:02:43,blown away by pi !
2023-06-30 14:05:04,Did you end up acting on its suggestions?
2023-06-30 14:08:28,Very interesting!
2023-06-30 14:09:33,But the Greylock podcast about it was insightful too. Stressed on how they're trying to build the emotional core first!
2023-06-30 14:10:44,It's a wonderful conversation partner. It'll be a shame to prompt hack it and force it's creators to perform RLHF lobotomy on it.
2023-06-30 14:10:53,has anyone self-hosted weaviate on azure/gcp before? wanted to get some info
2023-06-30 14:11:54,"I don't agree with building the emotional core first, but that's also a personal belief on the Planning-Memory-Execution trifecta"
2023-06-30 14:20:42,"hi , this might be a dumb question but while I'm doing SqlDatabaseChain calls in langchain , how do ensure the query doesn't respond to some unwanted/sensitive data . "
2023-06-30 14:23:07,Hi. Do you have the original Excel sheet ?
2023-06-30 14:23:41,do you have a link?
2023-06-30 14:23:58,why not?
2023-06-30 14:24:38,https://open.spotify.com/episode/67MBhAISm2aB6wwzjROJjs - this one
2023-06-30 14:25:17,Thanks was just searching
2023-06-30 14:25:32,Shared Google docs link somewhere above
2023-06-30 14:26:46,Yes yes I agree with the use case. I basically believe a more effective Personal AI will first solve for task support than emotional support.
2023-06-30 14:28:22,"i am not sure if we even understand what does personal AI even means? is it a coach, a friend, a companion, an expert? a single person often isn't everything"
2023-06-30 14:28:31,Happy to chat more on DM too. It's a topic I've been spending a lot of time on for a while
2023-06-30 14:29:22,Agreed. And it can be all distinctly and also combined. And it'll likely evolve too.
2023-06-30 14:31:28,This is surprising. I thought everyone knew about pgvector limitations!
2023-06-30 14:31:39,This is indeed the best possible outcome
2023-06-30 14:40:46,Jo just sent this — he is roasting Supabase's outright sleaziness and using pgvector's goodwill for profit 
2023-06-30 14:41:00,Jo is the creator of Vespa which powers Yahoo's Text Search
2023-06-30 14:43:13,I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick
2023-06-30 14:44:37,Supabase CEO shooting themselves in the foot 🙈
2023-06-30 14:45:19,nirant ur tweet is IMBA
2023-06-30 14:45:28,No no. Supabase is eating into every vectorDB's roadmap. I've access to 2 of top 3 players roadmap
2023-06-30 14:45:36,What is IMBA?
2023-06-30 14:47:05,"Credit where it's due, almost all the engineering here is done by Shivendu [PHONE REMOVED]. I've mostly been good/lucky at spotting a problem"
2023-06-30 14:47:26,Did we get a detailed benchmark on pgvector? Have completely missed this
2023-06-30 14:47:49,imbalanced? Gamer lingo 😅
2023-06-30 14:48:42,"Its OP instead of IMBA nowadays, after league of legends overtook Dota 2 😝"
2023-06-30 14:48:45,More detailed than anything else
2023-06-30 14:49:41,does anyone know of a HF inference endpoints-like service which offers lower end (and cheaper) GPUs?
2023-06-30 14:49:57,"RIP Twitter DMs, so much attack from pgvector fanbois 😅"
2023-06-30 14:50:29,You made it
2023-06-30 14:51:00,Thanks Nirant! 🙏
2023-06-30 14:51:50,Awesome work
2023-06-30 14:59:48,But typically the marketing boosted gravy trains come back on track in some time
2023-06-30 15:09:51,They have full voice interface on at least the iOS app
2023-06-30 15:10:17,cc [PHONE REMOVED] since we were talking about Inflection AI
2023-06-30 15:11:23,https://www.reddit.com/r/LocalLLaMA/comments/14me1ha/open_orca_dataset_released/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=3
2023-06-30 15:14:46,Congratulations [PHONE REMOVED] & [PHONE REMOVED] !
2023-06-30 15:30:35,"2 q.s on pi like assistants which came up, would love to hear from the group :"
2023-06-30 15:31:02,cc [PHONE REMOVED] this feels like is in your alley
2023-06-30 15:32:30,IMHO for Q2 - 3rd option - the invoking - whether assistants or other apps/plugins to get it done
2023-06-30 15:32:41,But following views of the group very keenly
2023-06-30 15:45:13,[PHONE REMOVED]
2023-06-30 15:49:40,"It's anybody's guess but I'll take the ""master assistant and helper assistants"" bet."
2023-06-30 15:51:21,No sign in on mobile
2023-06-30 15:52:26,Might just be a conscious design choice but seems a bit weird to me.
2023-06-30 15:55:36,"my take is that text is not a universal interface, and as soon as you add other interfaces, specializations will emerge and hence specialist assistants will emerge"
2023-06-30 15:56:10,"But you you try it on insta, it will call you by your name."
2023-06-30 15:56:16,They have an insta bot too
2023-06-30 16:06:31,[PHONE REMOVED] answering at your command
2023-06-30 16:29:04,Anybody has experience with phind.com?
2023-06-30 16:32:33,Please share you find it.
2023-06-30 16:33:30,It’s quite good but has hallucinations for fringe use cases
2023-06-30 16:36:53,I think the future is personal assistants fine tuned uniquely for every individual that in turn interact with the rest of the ecosystem
2023-06-30 16:37:48,Found it. Going to study it more to see if I can repro this with nanoGPT.
2023-06-30 16:38:30,"I sometimes wonder how this ""space"" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?"
2023-06-30 16:38:34,Personal AI bots
2023-06-30 16:39:07,"Yeah, even GPT4 loses context and starts making up stuff if my context history is long. So, I'll see if that problem occurs sooner with phind."
2023-06-30 16:43:19,Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732
2023-06-30 16:45:55,"There will be physical manifestations (robots, alexa 2.0, etc) but as always software and AI will drive who owns the hardware product domination. Genuinely curious as to what smart VCs are seeing put billions in new upstarts like character.ai when the end-game can be pulled out. Just all the info Meta has from whatsapp communication (on me) is something I will never disclose to another company or they able to snoop and make it contextual enough. Laptop or OS owner has an edge, which makes me at least scary"
2023-06-30 17:45:20,Maybe Lab126 is cooking astro ++ with gen ai and Alexa 
2023-06-30 17:46:13,"Weekend reminder, this is the set of *rules* we try our best to enforce for everyone in this WhatsApp group:"
2023-06-30 17:47:33,https://t.co/genXa1UHuL
2023-06-30 17:48:27,"Yeah, we wanted to keep the competition fair 😂🤣"
2023-06-30 17:49:02,I tried using this but the openai embeddings but they were too overwhelmed by its awesomeness and refused to get indexed
2023-06-30 17:52:08,TBH I believed it was real until finding out little later.
2023-06-30 17:52:44,You should read the source code. I wonder how openai functions will react seeing those names
2023-06-30 17:53:06,There's an indian publication that took their joke about the fundraise at face value and printed it in an article 😂
2023-06-30 17:54:40,I realized after seeing galaxy_brain_**** file name
2023-06-30 18:01:21,Lab126 is the hardware division of Amazon
2023-06-30 18:15:05,Is there anyway to fast track access to GPT4 API?
2023-06-30 18:21:06,yup age-old good practice
2023-06-30 18:24:13,Also never trust any pickle file. Even there is an old issue with PyTorch
2023-06-30 18:24:14,"Yeah, this is why safetensors were created in the first place. Many releases use checkpoint formats that aren't in safetensor format"
2023-06-30 18:47:32,https://twitter.com/reach_vb/status/1673363113888948224?s=46&t=WT1iAtjftW-5_e62F8FZTg
2023-06-30 18:50:07,Can anyone please share resources for PII Redaction models for healthcare use cases?
2023-06-30 19:06:05,Where's the hack in this?
2023-06-30 19:06:35,Isn't this what is already possible via whisper base ASR?
2023-06-30 19:08:29,"Afaik, whisper transcribes from a language to english. Then we can perform translation."
2023-06-30 19:12:35,You can already do direct transcription for any language via whisper transcribe. 
2023-06-30 19:13:43,"That’s what i was trying to mean as well, sorry if my message was unclear"
2023-06-30 19:15:13,"Also i mentioned direct transcribe ‘to’ any language, not for any language."
2023-06-30 19:53:38,Found this pretty cool project: AutoLabel — text tagging library which use LLMs under the hood
2023-06-30 19:54:10,h/t Bhavya [PHONE REMOVED] for the Twitter mention
2023-06-30 19:55:50,More Indian Diaspora doing amazing stuff to come! 🔥
2023-06-30 19:56:52,Meta: 
2023-06-30 19:59:14,I am not from Surat but sure am a gujju lol
2023-06-30 20:00:27,People are figuring out that there other “Dhandho” than just Textile and Diamond
2023-06-30 20:09:22,thanks for the shoutout [PHONE REMOVED]! and thanks for recommending this community [PHONE REMOVED]
2023-06-30 20:13:11,"For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently."
2023-06-30 20:17:48,Good to see you here [PHONE REMOVED]
2023-06-30 20:25:24,Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally. 
2023-06-30 20:30:34,[PHONE REMOVED] - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! 🙃
2023-06-30 20:32:31,actually pretty cool. may end up using it in a workflow i was thinking about
2023-06-30 20:32:56,kudos
2023-06-30 20:35:25,"Thanks [PHONE REMOVED], [PHONE REMOVED] and [PHONE REMOVED]! Started Refuel.ai to automate data labeling, cleaning and enrichment using LLMs (likely because we had lost so many hours of our life to it)."
2023-06-30 20:39:47,"If anyone from this group planning come to SF Tinkerer meetup on 6th, we can have a small hangout."
2023-06-30 20:40:39,For sure let me invite those two
2023-06-30 20:55:27,not entirely surprised they're trying to do this internally :) 
2023-06-30 20:57:06,How do you expect this task to grow in scale or complexity that it becomes difficult to do it in-house?
2023-06-30 20:57:15,Yes.. Not just LLMs also vision data is mostly semi automated labelling these days
2023-06-30 21:03:42,Does that impact quality in any way?
2023-06-30 21:04:02,"Yeah, machines have less error, so higher quality"
2023-06-30 21:09:21,"Often a good idea to benchmark quality of LLM (or foundation model) labeling on a smaller scale first. One of the hardest parts of scaling human labeling is that you have to continuously train/hire new people, and hard to guarantee quality there."
2023-06-30 21:16:58,"On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house."
2023-06-30 21:18:56,Scale AI had a paper on this
2023-06-30 21:20:02,Snorkel is also great at it
2023-06-30 21:20:31,Snorkel does weak labelling and ive heard it tough to setup without ui
2023-06-30 21:20:43,Or atleast to reach the right functions
2023-06-30 21:21:06,On how they did with openai. Can find and share if interested
2023-06-30 21:22:41,Snorkel uses labelling functions. May work for many use cases.
2023-06-30 21:22:45,Well the labelers will tell you NO 😊
2023-06-30 21:26:07,"One of the hard parts with LLM labeling is often getting to high enough accuracy / precision numbers (70-80% isn’t good enough if you want to train downstream models). LLMs will happily produce a label, even if there isn’t enough context to label successfully 😅"
2023-06-30 21:27:17,You can add a confidence score (had read a tweet - basically add a confidence label in the chatgpt function)
2023-06-30 21:28:42,"that influencer tweet got swyx got roasted in replies from goodside — that was quite a garbage ""confidence"" score"
2023-06-30 21:29:28,Which is good for weak labelling if you have large scale data. So essentially the 0 to 1 journey is sorted.
2023-06-30 21:37:47,absolutely! 
2023-06-30 21:41:20,Not all third party LLMs support extracting tokenlevel probabilities though as Nirant mentioned. But if you're using a custom LLM or using an open source model this should be possible to extract
2023-06-30 23:16:05,Surprised to see such calibrated output. Any thoughts on what ended up hurting calibration in the “post-trained”model?
2023-06-30 23:16:36,I'm supposing it's RLHF
2023-06-30 23:18:23,RLHF introduces reward and punishment mechanism post training and forces the outermost layers to conform to a style and output.
2023-06-30 23:18:49,Disclaimer - I'm yet to read this paper so I could be catastrophically wrong.
2023-06-30 23:19:42,https://www.mosaicml.com/blog/amd-mi250?s=09
2023-06-30 23:31:48,"Haha yeah - it seems to be the RLHF (although they don't explicitly say that in the paper). Paper here, btw: https://arxiv.org/pdf/2303.08774.pdf"
2023-06-30 23:33:15,Interesting direction: Machine ‘Unlearning’ Challenge: https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html?m=1
2023-07-01 00:11:41,https://twitter.com/KaiyuYang4/status/1673882824158613504
2023-07-01 00:54:05,https://openai.com/blog/insights-from-global-conversations
2023-07-01 01:37:42,https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA 
2023-07-01 06:06:06,"My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?"
2023-07-01 06:14:03,We have the dataset and the query set. Trying to learn what massaging and peripherals one needs to do to make it useful for the world
2023-07-01 06:16:37,"Hey [PHONE REMOVED]! Sounds like a super exciting project. Is the goal to have a public leaderboard for the dataset, or to share the dataset so other people can just play around on their own?"
2023-07-01 08:06:00,Has anyone come across research around LLM based state machines where each state is a specialised LLM?
2023-07-01 08:13:59,Do you mean expert model? Like what Geohot was saying about GPT4 architecture?
2023-07-01 08:14:06,"Sounds very interesting, would love to understand more on how you are benchmarking? Also- wouldn't the peripherals depend on the data/domain?"
2023-07-01 08:42:31,"Sort of, a collection of specialised LLMs "
2023-07-01 08:44:42,"I'm not sure if this is what you're exactly looking for, but this MoE paper has an approach that is allegedly used by GPT4. https://arxiv.org/abs/2101.03961"
2023-07-01 08:55:18,https://twitter.com/yampeleg/status/1674576951330185218?s=46&t=iNnHcvFLDa-sOIXYIloGew
2023-07-01 09:09:58,"""The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You’ll buy yours for $10k and it will be as important to your life as your smartphone is now"" - Vinod Khosla "
2023-07-01 09:12:19,That number actually seems doable. Wondering what incentives would slow down adoption of such robots. Regulation? What else?
2023-07-01 09:14:47,Will these be personal robots or industrial? - what applications? Who will own it? - incumbents or new ones (like Figure)?
2023-07-01 09:15:09,Manufacturing and procurement of raw material may be a bottleneck that may slow things down. But I don't know much of manufacturing to make a 10year assesment
2023-07-01 09:16:10,This can be somewhat analogous to the mass IoT adoption problem.
2023-07-01 09:19:40,This interested me.
2023-07-01 09:28:37,"Possible, we may already have a million quadrupedal today"
2023-07-01 09:29:42,Where are these used?
2023-07-01 09:30:07,What does this have to do with AI?
2023-07-01 09:33:26,I am sorry for sending this link here
2023-07-01 09:38:46,"Very few real world uses cases, mostly sold to research labs and hobbyists. UNITREE robots are more popular and affordable than Boston Dynamics."
2023-07-01 09:42:26,Manufacturing units and warehouses + construction seems to have lot of robots. Not sure of specific types
2023-07-01 09:43:07,Still a million currently sounds like a big number.
2023-07-01 09:44:25,"There could be multi millions of robots considering an exhaustive defn - nanobots, etc."
2023-07-01 09:48:11,How was UNITREE able to make the exact same design and also make it affordable?
2023-07-01 09:48:21,The most obvious prospective use of mass humanoids personal use robots which makes business sense is sex robots. Will come with a barrage of regulations.
2023-07-01 10:33:27,Personal assistant/robots for household assistance would be huge. Sex robots will probably end up being more niche than people assume compared to other use cases.
2023-07-01 10:50:52,What will these assistants do?
2023-07-01 10:51:14,Is it possible to build AI models for feature phones ?
2023-07-01 11:01:28,https://www.latent.space/p/ai-engineer
2023-07-01 11:01:58,Karpathys response -
2023-07-01 11:16:42,"Any and all household help. Cleaning up around the house, do the dishes, ironing, moving stuff, bringing stuff. Could have dedicated roles as well like a home nurse for old people etc."
2023-07-01 11:16:55,musks resp to that
2023-07-01 11:18:34,He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg
2023-07-01 11:22:38,"Guys, please note that this is not a self promotion event. It is a community event."
2023-07-01 11:24:13,Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).
2023-07-01 11:37:03,cc Taranjeet [PHONE REMOVED]
2023-07-01 11:38:40,I've a different take. Training your model was never as cheap as it is now. We've been successful in bringing down the training compute costs by 1000-10000x. You can now train your own stable diffusion flavours on free tier colabs/Kaggle books. You also have emerging inference at the edge and fine tuning at the edge.
2023-07-01 11:40:02,I don't think emergence of prompt engineering will impede training or fine tuning ML models. I think both of these areas are going to grow and the prompt engineering bit will expand into a LLMOps mushroom ground.
2023-07-01 11:42:34,"Chiming in. This was also my argument when, earlier,  we were discussing about wrapper LLM apps having inherent moat. At an unit level most people seem to be able to interact with llm and build wrappers of sorts but ""programming"" of that itself will be complex. Can lead to inherent technical moat. "
2023-07-01 11:48:03,Thanks. Bunch of exciting things next week as well.
2023-07-01 11:48:38,*Event Announcements from https://nirantk.com/community* 
2023-07-01 11:53:11,"Since I get about 4 pings on this per week, as a trial:"
2023-07-01 12:15:50,Every phone should have a GPU. I think that is where the industry is moving towards.
2023-07-01 12:17:16,Every smartphone *today* has more compute and RAM than what the Apollo mission used to send mankind to moon and back
2023-07-01 12:18:07,"Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU — only Apple can"
2023-07-01 12:18:30,Quick question:
2023-07-01 12:18:36,Fully agree. If I was apple I will be thinking how to build a hardware moat out there and optimise for AI bots experience. 
2023-07-01 12:18:38,"Can we tell every algorithm can run on cpu with small models,is that not how industry may move?"
2023-07-01 12:19:11,Enterprise vs consumer expectations. Consumer with 100s of apps will benefit from mix of local and server compute
2023-07-01 12:19:39,"I'm very bullish on apple hardware. I used to be a long time linux user, but started using a mac recently and I'm amazed with the apple doc for its hardware."
2023-07-01 12:19:44,"I might be wrong here, but the convention is to mention 'cos' because they've optimised the embedding to work well with cosine similarity"
2023-07-01 12:20:49,Consumer expectations — monetised via ads running on server farms the size of some European countries
2023-07-01 12:21:05,Still can’t run slack
2023-07-01 12:21:21,Haha Vision pro ads by then 🤪
2023-07-01 12:22:09,"Yes something like that, they gave different naming conventions for embeddings trained in dot product, normalized and non normalized embeddings"
2023-07-01 12:22:40,Slack and chrome are different species
2023-07-01 12:22:53,"Which is exactly my point — app devs get lazier, and consumers expect more. We all crib about Slack and Teams — but no one is using email groups at their workplace which'd require you to think for more than 20s at a time"
2023-07-01 12:25:10,CoreML ftw
2023-07-01 12:27:27,"Apple hardware has some good APIs (so am told) for a local application. Maybe not an LLM, but everything else - create embeddings, vector search, langchain like."
2023-07-01 12:29:49,I can see some of the mixed image/video editing moving to edge compute.
2023-07-01 12:32:48,"This is also because of emergence of cluttered frameworks and no punishment for RAM hogging. We want shinier, animating, 3D things and not enough function."
2023-07-01 12:38:04,There's one of my personal bear scenario for Nvidia. 
2023-07-01 12:41:34,"Yes, we need a lot more knowledge in the apple silicon space. Geohot started with M1 NPU right? I think tinygrad has shifted focus to something else"
2023-07-01 12:42:16,But I think there is slow progress in bringing things native to apple silicon. Have seen a few tweets this week.
2023-07-01 12:42:42,That’s the part i agree with 😊
2023-07-01 12:45:46,Pedro Cuenca works on a exporters and coremltools library to export any HF transformer model to CoreML.
2023-07-01 12:45:56,"Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev."
2023-07-01 12:47:43,They already support many models and architectures. It's better to check native metal support for older models or educational stuff than run something torch.device('cpu') on metal.
2023-07-01 12:56:20,Chrome is just like algae allowed to grow unchecked on the RAM. needs to be purged every now and then
2023-07-01 12:58:21,Anyone worked on whisper recently. For some reason my logic for writing the the segments to a vtt file is failing from a few months back. Seems they've changed the logic. So any repo doing it recently would help.
2023-07-01 13:02:50,"A week ago Mistral created buzz for raising 105M on the back of a rare team coming together to create an OpenAI competitor from Europe. I just got the chance to read the memo, and it seems that while they say they will take a more open approach to model development, their actual strategy seems to be do everything?"
2023-07-01 13:03:49,"Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??"
2023-07-01 13:04:33,"You might want to start by not using privateGPT, it was mostly marketing to begin with"
2023-07-01 13:05:28,"I see ,any other options i means some private documents"
2023-07-01 13:08:24,Broad Guidelines for private documents: 
2023-07-01 13:10:26,3.1 Spend time figuring out how to to split text right :)
2023-07-01 13:10:27,I shall try this thank you 🙏🏻
2023-07-01 13:12:04,"Actually I could do some experiments on data i have, usually for the information i look for out of 10, 7 are  either in first 500 words or else last 20/ words, so I am just getting that chunks for now"
2023-07-01 13:12:06,"This is a nice repo that uses llama.cpp and whisper.cpp to have a conversational LLM hosted on PC, where you can use mostly any supposed models. https://github.com/yacineMTB/talk"
2023-07-01 13:14:02,Seems this one needs GPU
2023-07-01 13:14:57,I can try with colab hopefully
2023-07-01 13:21:21,"[PHONE REMOVED]  penalty to not participate might decrease the signal to noise ratio of this group, thoughts?"
2023-07-01 13:22:08,3 especially if you're using langchain or any prompting libraries. Those things keep adding up to the tokens unchecked in the name of enhancing prompts 🙈
2023-07-01 13:38:35,"I can't list everything here but there's a whole menagerie of options that solve this problem. The easiest app to try in a few minutes worth of testing is gpt4all GUI. For practical purposes, it's easy to setup, fast to load and relatively up-to-date. privateGPT code is just a single script and extremely easy to read through but you may not want to use langchain dependencies that slow everything down a lot."
2023-07-01 13:44:51,"privateGPT i think uses gpt4all   ,i think i need to check gpt4all and falcon 7b both"
2023-07-01 14:25:14,https://open.substack.com/pub/luttig/p/hallucinations-in-ai?utm_campaign=post&utm_medium=web
2023-07-01 14:49:23,Very noob question - a bunch of us are planning an open source model deployment and fine tuning hands-on workshop. For this we are looking for some GPU access. Any company we can tie up with for access & credits around same ?
2023-07-01 14:51:28,[PHONE REMOVED] may be able to help?
2023-07-01 15:01:40,Thx for pointing out. Will DM and connect once.
2023-07-01 15:02:15,cc
2023-07-01 15:04:23,Thx for the pointers. Will follow on these.
2023-07-01 15:23:18,https://arxiv.org/abs/2306.02858
2023-07-01 15:25:30,Video-to-text model that better captures Visual and Audio components.
2023-07-01 15:30:50,Nice
2023-07-01 15:30:51,Demo available?
2023-07-01 15:31:19,https://github.com/DAMO-NLP-SG/Video-LLaMA
2023-07-01 16:29:13,https://openai.com/blog/insights-from-global-conversations
2023-07-01 22:46:47,"This is such a word salad, I believe GPT3.5 was used instead of GPT4 😆"
2023-07-01 23:28:59,Playing with qr codes and controlnet - very fun!
2023-07-01 23:33:25,they look good
2023-07-01 23:36:40,"I had done the same thing, and posted on the company's channel. "
2023-07-01 23:37:19,A1111 or diffusers?
2023-07-02 00:24:00,A curious question folks:
2023-07-02 00:35:07,https://huggingface.co/openchat/openchat
2023-07-02 00:36:20,"Though, I'm skeptical on this. "
2023-07-02 01:04:35,Tried this. Somehow the QR is not read on certain device cameras.
2023-07-02 01:28:15,Fun question: what's ChatGPT? 
2023-07-02 01:29:28,"True. chatGPT is no real reference, all you've is the latest model and no reference of the older versions."
2023-07-02 02:10:20,"Noob question, and maybe asked a 1000 times- openai wrappers have no moat, but perhaps a chance to validate the business use case and then build the tech. Then do we expect everyone to fine tune these big models eventually to get an edge over the competition?"
2023-07-02 02:11:11,"That said, I am yet to come across tools to facilitate fine tuning."
2023-07-02 02:11:26,Can anyone help me get some clarity on this? And thoughts.
2023-07-02 02:12:03,Eventually these wrappers will be inducted into big players who has the distribution.
2023-07-02 02:12:48,Big players - such as?
2023-07-02 02:13:13,I was exploring one DataBricks blogpost where they have mentioned step by step using huggingface on how to finetune a BERT base model. I ran the notebook untill I ran out of Google Collab RAM😅
2023-07-02 02:14:15,"for finetuning llms, wizardLM is SoTA currently, but didn't really find anything that gave me those capabilities out of the box"
2023-07-02 02:14:45,Adobe buying StableD or MidJourney to augment their tools that is being used by millions
2023-07-02 02:15:38,It's glue-tech mostly.
2023-07-02 02:16:22,Got it. Thanks for your thoughts [PHONE REMOVED] 👀
2023-07-02 06:53:44,"Imagine how good your RLHF would get, getting user feedback (thumbs up , thumbs down, descriptive feedback)  from millions of users"
2023-07-02 07:32:21,"You're right. But you can build your moat around service quality, UX, security, etc."
2023-07-02 07:40:38,In the geohot podcast they mention 16 inferences. I went through  this paper but still couldn't connect the 16 inferences part. Any insights on how that is done?
2023-07-02 09:26:25,"100,000 pip installs in a day for LangchainAI! "
2023-07-02 09:38:15,It's like it is like 2005 and no one is able to appreciate the power of the iPhone or app stores and apps
2023-07-02 09:44:02,is this where you'd getting the data? https://pepy.tech/
2023-07-02 09:46:45,"Pypi stats, but this'd work too"
2023-07-02 09:59:59,"In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct."
2023-07-02 10:01:10,God bless you for typing this out 🙏🏽
2023-07-02 10:03:02,Thanks for the detailed explanation!
2023-07-02 10:31:55,Pepy also adds cross zone data sync up so in order to get correct data use this
2023-07-02 11:46:11,Interesting paper on the future of sw engineering education/tutoring
2023-07-02 13:27:58,🌶️ take on vector search being overhyped and not always the best option for LLM apps. 
2023-07-02 13:27:59,https://colinharman.substack.com/p/beware-tunnel-vision-in-ai-retrieval?utm_campaign=post&utm_medium=web
2023-07-02 13:29:55,"Document splitting is common for vector storage / retrieval, but useful context can be lost. LangChainAI has 3 new ""context-aware"" text splitters that keep metadata about where each split came from. Works for code (py, js)"
2023-07-02 13:31:33,"Anyone who says keyword retrieval alone, or vector search alone is as good as both together — is not to be taken seriously. This is not even news. We know since 2018 when GloVe/word2vec were a thing, and BERT vectors were used"
2023-07-02 13:32:36,"On the plus side, I always popularise ideas like these — it feeds into FUD, and whether I like it or not, I make a lot of professional premium by removing doubt and absorbing ambiguity/uncertainty."
2023-07-02 13:34:32,"Even BM25 (what Elastic uses) is better than keyword search, and that is known since 1990s"
2023-07-02 13:38:40,"it's like the Jesus meme - ""I am not messiah"","
2023-07-02 13:39:28,"No one is going to realise this, because people are not aiming for a usable QA system — they're aiming for a demo-able QA system, and that's a different bar completely."
2023-07-02 13:41:06,"Not naming names, but know a desi startup who've raised quite a few $$$M on the back of Colab Notebook wrapped in Vercel"
2023-07-02 13:43:54,/endrant
2023-07-02 13:52:11,"can someone recommend specific literature to go deeper on this for noobs -> ""dirty retrieval parsing, splitting and ranking bits"""
2023-07-02 13:52:30,https://twitter.com/huggingface/status/1675242955962032129?t=v3AyvKLw9e4gZQlhyVz5kw&s=08
2023-07-02 13:54:10,https://twitter.com/EMostaque/status/1675236885197729792?t=9hg8cpf2EgNaZLFwHjUMjg&s=08
2023-07-02 13:54:18,doesn't seem like their fault here?
2023-07-02 13:55:56,So many people are dependent on them even enterprises. They should have added 2FA long back. It is very easy to enforce and does not require much infra investment.
2023-07-02 13:57:26,it's more of an experience thing building/improving any search system in production
2023-07-02 13:58:11,yeah revision pinning and local bucket caching is becoming very important
2023-07-02 14:29:38,"This was popularised by hinton in his 2012 deep learning course. Originally it was like a weighted ensemble of multiple outputs, the weight vector here is generated by another neural net with same input. This whole thing is differentiable end to end, so each expert gets better as well as the weight generator gets better at assigning the expert to an input"
2023-07-02 14:30:47,"AI powered search by Manning (still in EAP,  but main topics ready to read) is a very well balanced book on classic search and the new semantic search"
2023-07-02 14:32:23,"+ AI powered search book is by veterans of search/experts of elastic and solr, so they know their thing"
2023-07-02 14:38:07,https://www.sbert.net/examples/applications/retrieve_rerank/README.html
2023-07-02 15:55:09,"+1. On top of that, these QR codes mostly don't work (with apps like Google lens)"
2023-07-02 15:55:38,Seem to work fine on paytm / phonepe
2023-07-02 18:54:48,That's the best tweet on rate limit I've seen so far 🤣
2023-07-02 19:04:04,😂 Bojan generally has something funny  to say on whatever’s current.
2023-07-02 19:04:34,Almost all his tweets go like XGBoost…..
2023-07-02 19:05:05,Haha yes.
2023-07-02 20:21:10,Is that made up or a real tweet
2023-07-02 20:21:20,Either way it was good for kicks
2023-07-02 20:32:18,Hello post LLM world.
2023-07-02 20:36:05,"Friends, please avoid off-topic conversations.  And if someone does so, others should try to react with emojis only. This puts a limit on the number of unread/off-topic messages."
2023-07-02 20:44:11,So we are rate limiting the off-topic conversations? 😅
2023-07-02 20:54:26,"And as is tradition, we'll eventually rate limit messages asking to rate limit off topic discussions 😜"
2023-07-02 20:57:22,Expecting an infinite regress rate limiting discussion going back all the way to the big bang
2023-07-02 21:55:27,PSA: openai.Embedding.create() will sometimes return NaN - 
2023-07-02 22:56:18,"Many apologies, seemed a natural segway but I can see how this can be a runaway digression to nowhere ✌️"
2023-07-02 23:33:02,Did anyone try openchat ?
2023-07-02 23:36:42,"Yeah, and it is not what it claims to be unfortunately."
2023-07-02 23:37:28,It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.
2023-07-02 23:38:12,This is based on llama ?
2023-07-02 23:38:33,How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?
2023-07-02 23:38:34,Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper
2023-07-02 23:39:08,I see. 
2023-07-02 23:40:50,They took Vicuna and Alpacaeval and published results from there showing that it surpasses chatGPT in performance
2023-07-02 23:41:28,"Most people don't understand how many evals are there and what do they actually test. Vicuna eval is mostly - ""Style not substance"""
2023-07-02 23:42:26,OpenAI released their own evalcode. Mosaic their own. Every research releases their own eval system and claim that their architecture outperforms others 😌🌚
2023-07-02 23:42:41,"Vicuna had less scores on the HF LB, the other day"
2023-07-02 23:43:03,MMLU
2023-07-02 23:45:03,This is the best we have so far - https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
2023-07-02 23:45:31,MMLU is also part of the benchmarks they use.
2023-07-02 23:46:45,Yes yes. This is the LB. My company is keeping track of it daily xd
2023-07-02 23:46:55,I see. Multi language understanding
2023-07-02 23:59:53,https://www.nfx.com/post/speed-and-ai
2023-07-03 01:39:19,"Excellent panel discussion between Jonathan Frankle from Mosaic, Amjad and Michele from Replit about training LLMs. "
2023-07-03 02:28:14,Knew some stuff and learnt a few things that I never heard about earlier👍
2023-07-03 09:45:20,"https://twitter.com/blancheminerva/status/1652899628356960256?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Stella bidderman - second author of PILE paper discussing per token quality of PILE vs RP. I think some amount of quality degradation is obvious as RP is much bigger than PILE (6 times) . In which area, did you contribute in building RP ?"
2023-07-03 10:14:27,Number of Issues created and PRs gettting merged is a good metric as well.
2023-07-03 10:22:00,Qdrant needs to up their marketing spending it seems.
2023-07-03 10:30:01,"folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ? "
2023-07-03 10:43:48,cc [PHONE REMOVED] Jithin from Ragas would you know of something?
2023-07-03 10:52:46,Would you link to add a link to source?
2023-07-03 10:53:30,Similar Collection by HuggingFace :
2023-07-03 10:54:17,I am facing message delay in whatsapp
2023-07-03 10:54:34,I'd recommend benchmarking the retrieval and generation steps separately to better understand the performance of each component. 
2023-07-03 10:59:57,Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you’re interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas
2023-07-03 11:02:17,Also this article here covers the metrics used for evaluating retrievers https://amitness.com/2020/08/information-retrieval-evaluation/
2023-07-03 11:04:59,Amit [PHONE REMOVED] we were talking about a blog from your blogging era:
2023-07-03 11:07:40,hi. looking at the dataset for eval for now. 
2023-07-03 11:08:24,> Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case.
2023-07-03 11:23:35,BEIR seems to be the framework for benchmarking. there is a bunch of different datasets used by beir. any idea which one u would recommend for benchmarking if ur building a RAG ?
2023-07-03 11:31:27,"internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea"
2023-07-03 11:34:18,hey that is very useful feedback. did it work better with FIQA for you - im wondering how fiqa benchmark executes ? do u first have to load a retrieval dataset and then ask questions on it ?
2023-07-03 11:36:05,This benchmarking was also discussed during the GenAI meetup which happened in BLR 2 weeks back.
2023-07-03 11:36:45,we are in delhi
2023-07-03 11:37:59,🥲
2023-07-03 11:38:41,is there any list of startups in generative ai valuechain? from infra to api to customer facing ones
2023-07-03 11:39:04,"Emad Mostaque makes me happy whenever he goes viral: ""there won't be any programmers"" in 5 years"
2023-07-03 11:40:37,"FiQA didn't have retrieved docs, so we used the answers (they have multiple answers for the same question) as the document. "
2023-07-03 11:42:21,"Watching the exact same video right now - his discussion with Peter Diamandis. Diamandis was involved in public space flight when that was a pipe dream - and he finds Mostaque and Stability among the most interesting companies at the moment. There's another discussion on the philosophy group about this, in the context of code gen tools."
2023-07-03 11:49:02,We stopped having personal portraits drawn to capture our image with the invention of camera. Painters went away and photographers came in. Then came photography on personal devices and professional photography maintained an edge by having costlier and advanced equipments. Now we can take a shot of the moon and still some humans maintain an edge by learning how to use different editing/effects creatively to compose a better photo or videographic experience.
2023-07-03 12:41:14,My fav bit on how ai will impact programming is this talk and piece by Matt Welsh
2023-07-03 12:41:26,Fantastic talk on how ai will impact programming as we know it :
2023-07-03 12:51:44,Any idea how to enable OpenAI code interpreter?
2023-07-03 12:53:08,Anyone knows how they doing? Didn't really hear good feedback on them post their seedfund.
2023-07-03 12:53:34,"Terrible execution/implementation, but the idea still has alpha left in it"
2023-07-03 12:54:14,Correct. Heard a rumour that one of their investors asked them to return their money lol
2023-07-03 13:03:14,What have they executed poorly on? I haven’t stayed super close to them for a while
2023-07-03 13:06:16,Damn
2023-07-03 13:07:52,Oh yeah you interviewed them.
2023-07-03 13:08:53,I do think the problem they are trying to tackle is actually hard so not throwing shade at them but was surprised at the 16M seed without any product
2023-07-03 13:10:28,he wrote a blog about it
2023-07-03 13:13:34,Would love to read/hear the interview.
2023-07-03 13:15:39,https://ntkris.substack.com/p/building-autonomous-agents-with-fixie
2023-07-03 13:19:38,"How much of the lacklustre execution do you think comes from going too wide? Meaning, AFAIK they are helping businesses build any type of agent they want"
2023-07-03 13:21:42,Lot of it. An above average RPA product with a very narrow niche e.g. processing fees questions in AMCs for Fortune200 banks and brokerages like Robinhood built on top of OpenAI Functions will make more revenue per engineer than this going wide thing.
2023-07-03 13:22:49,Yeah I totally agree. I’m very surprised by going wide because it goes against every decade old building principle
2023-07-03 13:23:57,"Added Context: I was an external, technical evaluator for a variant of this product in 2018, used by one of India's largest AMCs even today to support their door to door+tele calling sales staff of 10K people. Very profitable."
2023-07-03 13:32:22,Hey guys
2023-07-03 13:35:15,What is dual functionality?
2023-07-03 13:38:49,"Also, is ask for agencies/services off-topic?"
2023-07-03 13:38:52,"Context: We've considered job posts as off topic since beginning, because that biases to the space becoming a notice board instead of a space for conversation. The recommended way to make job posts is https://nirantk.com/community"
2023-07-03 13:40:46,[PHONE REMOVED]
2023-07-03 15:20:01,A hacker fellowship in SF called HF0
2023-07-03 15:27:56,"VC folks (& others), feel free to DM me with your Twitter &/ LinkedIn if you are interested in collaborating on this"
2023-07-03 15:30:46,[PHONE REMOVED] is working on this if I'm correct
2023-07-03 15:33:34,Actually we are working more towards supporting the OSS community.  Either promising new individual contributors or team that are working on existing projects that are helping the community.
2023-07-03 15:40:30,Happy to help
2023-07-03 15:50:47,"I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India. "
2023-07-03 15:53:08,"Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm."
2023-07-03 15:56:48,Not a Hot take any more.
2023-07-03 15:57:43,Can you make a huggingface space without uploading your code in github etc
2023-07-03 15:58:05,cc [PHONE REMOVED] of chingari 🔥
2023-07-03 15:59:17,Bollywood seconds that
2023-07-03 15:59:40,"Why would you say no upside? For a VC betting on GenAI, this would be great for branding plus first dibs on funding for any future rounds these products might go on to raise. At the least you have a front row seat to some good work in the space I'd presume."
2023-07-03 16:00:22,Just gauging the room
2023-07-03 16:00:27,"I would be happy to commit 5L yearly if this got me access to a collective which invested in startups born out of such hackathons, in exchange of equity. Angel investing with access to smart people, projects and opportunity to participate in upside"
2023-07-03 16:01:06,"But it’s a complex financial vehicle, closest I have seen in IPV from Angel . Could be fun though"
2023-07-03 16:01:29,Openai subscription or chatgpt subscription
2023-07-03 16:04:31,Openai i.e building on top.
2023-07-03 16:05:56,Heck If i had that money I’d just do it for the sake of being around hackers 🥹 and having a local gpu cluster cause why not
2023-07-03 16:07:13,[PHONE REMOVED] uses both subscriptions :)
2023-07-03 16:15:26,You can have a private GitHub repo and then access your source via personal access token in your hugging face space.
2023-07-03 16:17:12,Discussed this once previously in this group - There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets
2023-07-03 16:32:09,"I am excited to try this but before diving in, would love to hear your thoughts [PHONE REMOVED] [PHONE REMOVED]"
2023-07-03 16:34:25,People here can contribute to make this pool of 5 lakh happen.
2023-07-03 16:35:22,Supporting people to make and build is very valuable. One can do individual contributions of 2.5k to 5k and org contributions of 50k to 1 lakh and get credited as supporters for it.
2023-07-03 16:37:03,5 K committed
2023-07-03 16:37:26,"would doing a smaller scale help to get started? like for 1 week, 10 hackers under a single roof"
2023-07-03 16:38:58,Excellent idea !
2023-07-03 16:39:12,"Here, see. Thank you. [PHONE REMOVED] let's up a project page and get this running. We'll show the dashboard to everyone to see what the contribution pool looks like"
2023-07-03 16:39:58,Sure. You'll do the legwork?
2023-07-03 16:40:36,I am sure a lot of us can speak to the orgs that we work in to contribute.
2023-07-03 16:40:56,Happy to !
2023-07-03 16:41:26,Can definitely do individual contribution of 5k 
2023-07-03 16:41:44,Excellent. [PHONE REMOVED] work with Ashish to set up a pitch.
2023-07-03 16:41:55,Setting up. Give sometime.
2023-07-03 16:42:14,We can then take it to larger orgs.
2023-07-03 16:44:00,Once a pitch is set up all of us can take it to the respective orgs we work in 
2023-07-03 16:54:13,""" wanted to build an embeddings database from scratch just as a learning exercise per WebGPT, but realized that it would be cool to turn into a tinygrad-esque project."
2023-07-03 16:54:54,Identified a bunch of problems with vector databases and came up with multiple wrong solutions
2023-07-03 16:54:56,Exactly.
2023-07-03 16:55:42,"Hahahahhaa, beat me to it! 🤣"
2023-07-03 16:56:38,It's partially enraging ngl
2023-07-03 17:49:39,My cofounder had an interview with them. They don’t advocate it but they seem to be majorly enterprise focused
2023-07-03 17:50:09,Dealflow is the only way to fund these things
2023-07-03 17:51:06,https://www.betaworks.com is nice! Hugging Face was part of their accelerator back in the day
2023-07-03 18:25:03,Basic question
2023-07-03 18:34:43,Mainly 2 reasons as per my understanding:
2023-07-03 18:35:21,My guesses
2023-07-03 18:35:53,"For example, a 30B parameter model can theoretically outperform GPT3 with 1T+ tokens as per the paper."
2023-07-03 18:36:10,"Likewise, decisions are based off of which devices can support which inferences"
2023-07-03 20:26:10,"Great to join this group, Looking forward to the discussions!"
2023-07-03 20:48:27,"Hey folks, I’m looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn’t find anything useful online. Would love to get some ideas, resources"
2023-07-03 21:22:32,"Has anyone tried llm for intent to action detection and something in that kind ? Means want to identify some conversational attributes for any domain such that i can take an action based on the converstion that is going on , intent, sentiment looks like the starting point but any other things or ideas anyone have"
2023-07-03 21:23:12,"Kind of like rasa , if anyone tried there we give intents with queries but hoping out of box llm will work gpt , was kind of good only"
2023-07-03 21:23:56,"what kind of analyses are you looking for? detection, segmentation, something more complex?"
2023-07-03 21:25:08,"Depending on what you want to do, you may even be able to use non-learning approaches using OpenCV's image processing suite"
2023-07-03 21:42:07,Tried something similar experiment with off the shelf LLM(Completions). 
2023-07-03 21:42:13,I’m primarily looking for measurements and depth calculation of objects and internal structures
2023-07-03 21:44:12,OpenCV is for basic use cases. I’m looking to extract depth and other measurements from 2D images and then 3D models from lidar scans and general images too
2023-07-03 21:46:13,"If you don't have stereo images, your best bet for accurate depth would be some monocular neural net architecture (there are many out there)"
2023-07-03 21:48:00,"For 3D models from lidar + images, I'm actually working on the same problem. We're using 3D object detectors which work on multimodal data (images + point cloud). A good candidate is CLOC: https://arxiv.org/abs/2009.00784"
2023-07-03 21:49:25,Thanks for sharing- will check these out. Also would love to know the problem statement you’re working on. Also looking to try https://developer.apple.com/augmented-reality/roomplan/
2023-07-03 21:49:26,Does this work for you? - https://www.lerf.io/
2023-07-03 21:51:30,Cool stuff!! Object identification with measurements is our problem- getting the measurement is essential which if this can provide would be great.
2023-07-03 21:54:54,Check this out: https://www.captur3.ai/
2023-07-03 21:55:03,They have a pretty decent ios app
2023-07-03 21:55:04,I see. I am not good with CV but this seems to be tackling your problem and claims to be SoTA - https://depth-gen.github.io/
2023-07-03 21:58:00,TIL: Temperature and repetition penalty sort or “cancel” each other out
2023-07-03 21:59:49,"Thanks for this, will check out!"
2023-07-03 22:00:05,"Interesting, will check this, thanks!"
2023-07-03 22:09:49,I am looking to run a ML solution on prem. What’s the best way to do this?
2023-07-03 22:11:54,Ohh thanks for the response
2023-07-03 22:13:35,Have you tried OpenAI functions to convert intents to actions?
2023-07-03 22:14:26,There a whole bunch of research on Monocular depth prediction. Models have become quite good these days. The problem will be in relating the predicted depth to real world distances for which you need some sort of calibration step.
2023-07-03 22:15:53,I would sugges to try with simpler models like - https://github.com/isl-org/MiDaS
2023-07-03 22:42:25,"Thanks for this, will definitely check it"
2023-07-03 23:05:39,"No i have not tried , let me vheck that ."
2023-07-04 00:20:08,Surprising result but sounds like a tall claim so still not sure.
2023-07-04 00:40:34,Looks like there is  demo space
2023-07-04 01:03:13,Great. It was strange that he didn't create a model card or put up any details whatsoever for testing.
2023-07-04 01:11:55,"Well, It failed all 3 of my simple tests in python."
2023-07-04 01:16:10,that was real quick
2023-07-04 01:23:10,It takes a minute right now on the space to generate response. It's a 3B model so it's Inference is fast.
2023-07-04 01:24:27,"What I tried with were easy but slight variations of binary search, it kind of ignored all constraints and thus didn't answer correctly."
2023-07-04 01:25:17,I meant your curiosity to test it out was quick
2023-07-04 01:25:34,but which is the best OSS code model to build up on?
2023-07-04 01:25:59,do u have any suggestions
2023-07-04 01:27:17,It's either StarCoder newest variant or WizardCoder. Can't say if WizardCoder has data contamination to get better results but it should still be good.
2023-07-04 01:29:58,Nice inference api for StarCoder - https://huggingface.co/bigcode/starcoder
2023-07-04 01:30:12,i fell RAG based AI documentation dont really do a good job and dont have a good understanding of the documentation to generate stuff can it be improved by feeding the whole documentation with instruction fine tuning to an good OSS code model and get better answers
2023-07-04 01:33:07,"Yeah you can probably do better by fine tuning but it can lead to overfitting as well. But if you're making a product for something focused solely on the documentation QA, I'll suggest trying it out to compare the results."
2023-07-04 01:34:37,yep on my way to start a new side project which I will probably leave half way through coz i will find something more fascination the next day
2023-07-04 01:34:47,fascinating*
2023-07-04 07:46:23,https://arxiv.org/abs/2210.03945
2023-07-04 07:46:24,"Interesting paper, I did not know parsing HTML was a challenge for foundational LLMs"
2023-07-04 07:47:11,"Also, is there any way I can subscribe to Arxiv papers so that I get to know when a second version of the paper is published?"
2023-07-04 08:02:52,I haven’t used it on arXiv but https://visualping.io/ has been fantastic for me for such use cases
2023-07-04 08:49:05,https://arxiv-sanity-lite.com/
2023-07-04 09:11:42,Is there anyone here that can intro me to Sahil?
2023-07-04 09:12:59,Must be July? I called this out in May end that this is going Kaggle-way 🤣
2023-07-04 09:57:41,"""Though human eval isn’t necessarily indicative of how good the model will do for users in real life use cases,  having a pass@1 higher than all open source models with just a 3B model and 1B tokens shows how good small models can get given high quality data"""
2023-07-04 09:58:28,"If it isn't ""necessarily indicative"" of model performance I'm super confused as to why this keeps being proped up for a ""new revolutionary model"" everytime"
2023-07-04 09:58:43,https://twitter.com/vipulved/status/1676014844171153409?t=3M6XgfAEzM8YcE0mZ0nDhQ&s=19
2023-07-04 09:59:23,*JOB OPENINGS* 
2023-07-04 10:11:05,Thanks for sharing the opportunities with the community first [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] 🙏
2023-07-04 10:13:38,It's on Jul 8th 🤗
2023-07-04 10:14:52,"Sorry, this 3 timezone calls, 3 date format is killing my brain 🫣"
2023-07-04 11:15:43,"In work with MLOps community, we created a summary of key talks from LLMs in Prod conference 2 with amazing ML leaders in the LLM domain. "
2023-07-04 11:40:28,Ok
2023-07-04 11:54:41,Ask for help:
2023-07-04 11:59:07,Build ner system for fixed quantities. Use that as filter. 
2023-07-04 12:38:44,Good read: https://venturebeat.com/ai/inside-the-race-to-build-an-operating-system-for-generative-ai/
2023-07-04 12:48:14,Neat paper !
2023-07-04 12:58:29,interesting - blockchain funds are redeploying to AI. some web3 fund announced a 500k online hackathon.
2023-07-04 12:59:33,certainly interesting
2023-07-04 13:02:16,"Any good examples of startups working on bounded scope ""agent"" use cases with LLMs - task automation, data entry, data analysis etc.?"
2023-07-04 13:55:24,We’re focus a 100% on CS
2023-07-04 14:31:50,It's actually the opposite.
2023-07-04 14:32:24,They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that
2023-07-04 14:33:06,Can you explain this? They don't want to scrape the whole site?
2023-07-04 14:33:43,A lot of people were bypassing paywalls
2023-07-04 14:34:36,You can bypass paywalls anyway by stopping the loader quickly
2023-07-04 14:35:02,"That and scraping the content without any ad revenue is also a no go. They want search engines to index stuff and display things by metadata, robots text content and not be a way to consume content without visiting the websites."
2023-07-04 14:36:39,Is it a no go legally? Because scraping with citations is allowed.
2023-07-04 14:37:16,When you do chatgpt with browsing even if you don't give the url explicitly it still scrapes the site
2023-07-04 14:40:11,I think scraping of public data is allowed as of now but they are avoiding it so that the search engines don't kill the incentive to visit anybody's website.
2023-07-04 14:41:39,Googles plan is to give detailed answer snippets and people also ask.
2023-07-04 14:41:51,Let me check what Bing is doing currently
2023-07-04 14:45:41,"This is why they should have let startups handle this. They tried to make google dance and are burning everything. Chatgpt with browsing was meh at best, and is creating unnecessary controversy"
2023-07-04 14:46:06,"I wonder how Perplexity handles this, or whether they are just flying under the radar on this: https://twitter.com/AravSrinivas/status/1676101654683488256?s=20"
2023-07-04 14:46:42,No one is printing the whole article verbatim. It is a paraphrased version answering the users input specifically
2023-07-04 14:46:52,With proper citations
2023-07-04 14:47:40,"So you ask for something, it would most likely search for that topic , get you a paraphrased answer with citations."
2023-07-04 14:47:57,Perplexity is pretty wrong most of the time. Citations are usually super random
2023-07-04 14:48:27,might be doing it LLM generated instead of deterministic ways
2023-07-04 14:49:27,I tried to get a kpmg analyst to use perplexity & my internal google search + gpt4 for their research - it will often say stuff that doesnt correlate with what’s in the sources - and the citations will be random - which means they can’t use it in their work
2023-07-04 14:50:40,someone at perplexity needs to look at those prompts 😜
2023-07-04 15:04:35,"At this point, it's not a bad idea to use SERP api + GPT3/4 api to have personal browsing."
2023-07-04 15:05:34,Fetch html with curl after identifying the url and let gpt 3/4 do the text extraction or beautiful soup if that's where you want to go
2023-07-04 15:05:55,Yep and there have been alleged copyright infringement issues even with paraphrased summaries. Not sure if this has already been shared here earlier but OpenAI is now being sued for copyright violations - 
2023-07-04 15:08:26,"Google, OpenAI and many other companies have already benefited from the data massively. Since there wasn't a proper law against this earlier, this is a grey zone. "
2023-07-04 15:23:50,"Omg, how did I miss this. But this means there are automated techniques to bypass paywalls? Other than scihub, do you guys know if any"
2023-07-04 15:25:10,12ft.io used to work
2023-07-04 15:25:14,12ft.Io
2023-07-04 15:25:29,Thanks
2023-07-04 15:26:31,Pro tip: use pandoc for html -> text
2023-07-04 15:33:12,"Thank you, I'll put it to test."
2023-07-04 15:56:21,"I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK. "
2023-07-04 15:56:43,This is a nice topic for philosophy group
2023-07-04 16:02:05,"Yass, for startups"
2023-07-04 16:03:36,Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.
2023-07-04 16:03:58,"Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway."
2023-07-04 16:17:10,"Ask your pdf still works, though it's not as seamless as you would expect."
2023-07-04 16:24:41,https://twitter.com/random_walker/status/1676077967577870336?t=0SrbEsdgnWBFYvXu05RrqA&s=19
2023-07-04 16:27:52,WebPilot seems to be doing fine for now as well.
2023-07-04 17:15:23,Has anyone seen the batgpt paper. Is this real?
2023-07-04 17:15:56,Or is this the greatest parody in the world
2023-07-04 17:17:29,This can't be real.
2023-07-04 17:32:13,Love it
2023-07-04 17:38:18,LOL
2023-07-04 17:39:06,"I almost think it is deliberate. Bidirectional Autoregressive ""Talker""? Really?"
2023-07-04 17:40:48,They've an arxiv page and they are from Wuhan University. 
2023-07-04 17:40:58,https://paperreading.club/page?id=173095
2023-07-04 17:50:33,"Hey everyone,"
2023-07-04 17:52:12,Working OK for me right now
2023-07-04 17:59:53,This depends a lot on when people in the west start using the app.
2023-07-04 18:00:00,Does anyone have an idea how to get access to the Anthropic API? Have applied but haven't even got email acknowledgement for application for quite some time now.
2023-07-04 18:00:18,They are notorious for being slow
2023-07-04 18:02:04,A user of ours had ZScaler installed. Would this affect our API key and result in blockages?
2023-07-04 18:02:14,I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?
2023-07-04 18:02:51,Unaware of zcaler actually
2023-07-04 18:03:22,Hashnode for their chatbot rix
2023-07-04 18:04:33,This is true. 100k context length.
2023-07-04 18:05:20,"Yes, basically I replaced llamaindex workflow by just feeding in whole document to anthropic at once. It gave decent answers then when I used chunked retrieval based QA with openai."
2023-07-04 18:05:58,I got by participating in a hackathon where anthropic had bounties.
2023-07-04 18:06:22,Trafiltura (GPLv3) is also a good tool. I have added this in Obsei to extract Google news articles and it works very well.
2023-07-04 18:07:08,This is the best
2023-07-04 18:07:14,I just came across this. I don't write understand what problem are they solving clearly. Why do you use it?
2023-07-04 18:07:27,You should delete this
2023-07-04 18:08:50,"Yes, but similarly on a case by case basis. If you are in a beta program of theirs you can get it. Apart from that check lablab.ai is having a hackathon with vertex ai. They are claiming to distribute accesses there."
2023-07-04 18:09:40,It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs.
2023-07-04 19:42:30,https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c - interesting combination of techniques discussed for very large (book length) context windows. Fascinating stuff.
2023-07-04 20:14:16,"Hello everyone,"
2023-07-04 20:58:36,Might be of interest to some folks here.
2023-07-04 21:44:26,"The ship of trust sailed away long ago, but it’s coming back now again 😅"
2023-07-04 22:55:35,when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513
2023-07-04 22:55:49,Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/
2023-07-04 22:58:58,Is he trying to reinvent FAISS?
2023-07-04 22:59:04,his chart is for like the order of 1000s of embeds though - apples vs oranges?
2023-07-04 22:59:48,This is an INDEX time. And he has measured embedding creation time in it 🤦🏾‍♂️
2023-07-04 23:00:00,Not even query time!
2023-07-04 23:00:00,"and that chart is also indexing time, not query time"
2023-07-04 23:00:09,https://github.com/jdagdelen/hyperDB
2023-07-04 23:00:30,You can't just use a nuclear weapon to assassinate a single person sir
2023-07-04 23:00:59,Happy 4th of July lol:😂
2023-07-04 23:01:20,Don’t bring Brahamastra to slap fights
2023-07-04 23:01:42,His use case is for a small and very dynamic dataset. so measuring index time makes sense
2023-07-04 23:07:05,"Like this makes so much sense for people building apps - e.g. searching though a bunch of pdfs or websites means you need fast indexing, query time is pretty much irrelevant across 1000s of vectors"
2023-07-04 23:09:02,A much better example of what I'm looking for - https://cloudinary.com/documentation/video_resizing_and_cropping
2023-07-04 23:25:42,It's like people getting happy on discovering linear search when they had to search in a list and shitting over all the algorithms designed for best worst case complexity.
2023-07-04 23:26:31,"Good for them but no need to suddenly claim it as Eureka, Eureka. "
2023-07-04 23:27:24,"For this use case, why'd you wrap numpy then? Why not ""just use numpy""?"
2023-07-04 23:32:19,Because otherwise you have to hand roll a bunch of stuff around numpy like - 
2023-07-04 23:34:10,"I'm just saying there's room for a library with just ""Just two functions with optional flags for more customization"" - something that's not langchain, and something that requires no dependencies except numpy"
2023-07-04 23:34:22,"In most cases, you can index something slightly slower and you'll worry about the query latency mostly as you'll want it to seamless."
2023-07-04 23:35:59,Yup - here he had to index on every request - very different from searching a static db
2023-07-04 23:39:20,$ pip install x
2023-07-04 23:54:10,"That or just write a wrapper over your vector DB functions to pass a parameter to set low index, average index or high index."
2023-07-04 23:55:58,Not very neat but just a top of the head thought for something scalable
2023-07-04 23:58:51,"Yeah, I understand your feelings on this. But we all know he is going to get stuck there flying because he doesn't know how to control his altitude or flight speed with antigravity class 😛"
2023-07-05 00:01:12,"so im suspecting that the reason that the vector db is this fast is cos of the MPS backend. it is skipping the CPU bus entirely.  memory writes will go straight over the PCIe bus to the GPU so this is kind of not a production-friendly benchmark. cos in production, all vector db writes will hop the network in some way."
2023-07-05 00:10:15,I think hnswlib doesn't have an optimal GPU acceleration due to its algorithm requiring random memory access features
2023-07-05 00:12:52,this is not gpu acceleration. there is no convolution computation that is getting accelerated. this is just a PCIE bus skip. thats my suspicion anyway. 
2023-07-05 00:15:23,"I didn't understand this. GPU acceleration doesn't have to be a mat mul, any approach that benefits from tens of thousands of parallel computations will work. Hnswlib, doesn't appear to need that. "
2023-07-05 01:27:45,what is the base image you guys use for amazon sagemaker endpoints?
2023-07-05 02:11:29,"It's a guess but I think every chat is logged in and logs come in with timestamps, date etc. Along with some metadata info. The message history it has for our chat may have the date mentioned somewhere and it used it."
2023-07-05 02:13:59,"It doesn’t know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th."
2023-07-05 02:15:11,But I started the conversation from scratch. Also Isn't gpt only supposed to use the prompt as it's context?
2023-07-05 02:15:52,"Like Abhishek said, context is with the query meta, if not explicitly mentioned."
2023-07-05 02:16:23,So if this was tried with the api where there would be no timestamp Metadata it wouldn't work?
2023-07-05 02:17:17,It will prove that they are not adding additional meta context with API.
2023-07-05 02:28:08,make sense
2023-07-05 02:28:52,appreciate it! :)
2023-07-05 06:39:09,"Is there any good LLM benchmarking tool for comparison of open-source models with GPT-3, 3.5 or 4?"
2023-07-05 06:44:17,Also for evaluating finetuned models on specific tasks.
2023-07-05 08:33:32,Is anyone a power user of github copilot and copilot X (or others)
2023-07-05 08:36:41,+1
2023-07-05 08:44:09,"Its great autocomplete, terrible coder"
2023-07-05 08:45:05,https://accounts.nat.dev/sign-in?redirect_url=https%3A%2F%2Fnat.dev%2F
2023-07-05 09:20:45,https://spectrum.ieee.org/ai-programming
2023-07-05 09:43:03,"Folks, anyone using conversational AI to execute actions within their organisation (looking at use cases beyond simple data retrieval)?"
2023-07-05 09:45:27,“Have you considered using numba” is a swift kick in the backside. Lol. 🤣
2023-07-05 09:48:39,"The fun nature of that suggestion is that everyone on the inside track gets the joke, while anyone who has actually never heard of Numba will be grateful to learn something new and fast! 😇"
2023-07-05 09:49:48,"I know this was discussed yesterday but still curious, What does openAI mean by ""fixing the behaviour"" (In reference to the paywalls being passed) how do you ""fix"" something like that without adding redundant checkpoints which might hinder the performance"
2023-07-05 09:51:50,Broadly? You detect client vs server side paywalls and act around this. 
2023-07-05 09:52:40,"Yeah basically this the top 200 domains or something is what my doubt was, there's no possible way they fix for all paywalls right?...right? 😂"
2023-07-05 09:53:16,But yeah makes sense thanks
2023-07-05 09:54:12,Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/
2023-07-05 09:54:46,OMG! A tech solution to a tech problem? 
2023-07-05 09:54:55,I get where you're coming from but that's a blame the victim ish mentality no?
2023-07-05 09:55:05,I mean obviously this is a hole on their end
2023-07-05 09:55:48,"But there should be some ""ethics"" involved when you scrape information from some repository, that's a given"
2023-07-05 09:58:38,"Calling media companies with a billion dollar a year tech budget a ""victim"", while sitting in India is a bit of mental gymnastics — I'll leave this for Policy & Philosophy fork of the group"
2023-07-05 09:59:22,"Hence the ""ish"", almost used like a ""not a financial advice"""
2023-07-05 10:38:56,High degree of regulatory pushback. Fingerprint can inadvertently step over HIPAA boundaries if u ask a personal medical question and then fingerprint the individual.
2023-07-05 10:38:59,Everything to do with AI has regulatory dragons around it. Those of us who have fought these battles for years know 😔
2023-07-05 10:56:05,"There's a distinction between a date as a concept and knowledge / training data that is time limited provided to the bot at the time of training. ChatGPT can understand the concept of ""today"" or the current date, even if it doesn't have training data after 2021"
2023-07-05 10:56:16,"IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows."
2023-07-05 10:57:43,how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents
2023-07-05 10:59:00,I'd like to know about this too. Getting devs to adopt it is a challenge - has anyone faced this and begun productively using?
2023-07-05 10:59:15,Completely agree.
2023-07-05 11:03:18,"True. I guess it would depend on the tasks. So far, we've been focused on composability of agents more than individual agents."
2023-07-05 11:05:13,"Somewhat mixed thoughts. This might also depend on how complex and involved the workflow in question is, which further goes back to that particular org’s importance as well"
2023-07-05 11:13:46,"I use it. Copilot is good but more issues than the hype. GPT4 on the other hand, can be really useful if you learn how to work with it."
2023-07-05 11:15:20,"But if you're bad with basic stuff like breaking down problems in smaller chunks, isolating problematic modules, logging and error handling then you'll spend more time debugging with these tools than getting something done."
2023-07-05 11:16:13,And please don't use it in environments where secure code matters.
2023-07-05 11:16:21,can you share some csv agents that worked for you? haven't seen much success hence asking
2023-07-05 11:18:41,"For basic tasks, PandasAI or the CSV agents from langchain have worked for me, but when asking it to perform more complex tasks such as extraction of valueable insights, it's been a hit or miss, again also could be my prompting could be incorrect"
2023-07-05 11:35:34,We do it as well. Put today's date in the prompt
2023-07-05 11:45:13,"I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have ""dev tool"" for my dev workflow. "
2023-07-05 11:56:10,"Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned — but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect ""Pythonic"" conventions"
2023-07-05 11:57:10,They don’t respect Pythonic conventions?
2023-07-05 11:57:37,"Also given how often langchain & llamaindex release updates, I’ve found it’s suggestions to be often outdated / incorrect"
2023-07-05 11:58:16,I don't think they know that they're writing a Python lib yet
2023-07-05 12:08:33,"This involves multiple aspects actually. You need to do subject tracking (person/ face/important objects), this gives you the region of interests, and then you can offset these regions to the required aspect ratio. Post this, you can crop the video using ffmpeg with sliding transitions with the given regions of interests."
2023-07-05 12:39:52,Use some tool like rembg on frames and then apply smoothing heuristic over frames with maximization over focussed frame to aspect ratio of portrait.
2023-07-05 12:42:50,https://zulko.github.io/moviepy/examples/headblur.html
2023-07-05 12:49:12,"Few gotchas I have noticed using chatGPT, co-pilot is not as much of my regular workflow to comment"
2023-07-05 12:52:50,"Will check this out, thanks!"
2023-07-05 13:07:28,sql
2023-07-05 13:10:26,DMing you
2023-07-05 13:16:03,*Event Announcement*
2023-07-05 13:53:22,https://github.com/BerriAI/reliableGPT
2023-07-05 14:12:58,"Simplified name, because we've dedicated groups for Creatives and DeepMedia now — in the same WhatsApp Community"
2023-07-05 14:19:38,Bhai there are too many groups with same name. At least add a 'x' or some identifier. You kinda made it more generic.
2023-07-05 14:20:29,Is that better? 🤣
2023-07-05 14:20:52,fun story - this was built on replit https://twitter.com/ishaan_jaff/status/1633310537667973121
2023-07-05 14:20:54,Brilliant read.
2023-07-05 14:23:52,Is this unique enough? 🤔
2023-07-05 14:24:53,"You could name ""The Terminator: Genesis"""
2023-07-05 14:25:40,Generative AI || Text
2023-07-05 14:25:43,The others could be Generative AI || Image/Media
2023-07-05 14:26:00,"Missed opportunity for OpenAI to call their model ""SkyNet-4"""
2023-07-05 14:26:46,These guys are so into  copyright. They might have been sued as well.
2023-07-05 14:26:49,"The text bias is accidental tbh, because I am from NLP background —  we do discuss startups, LoRA and what not here"
2023-07-05 14:27:27,LawGPT would have come to their rescue
2023-07-05 14:27:27,Maybe this main group we should name as “another Indian” … in honour of what AI used to be looked at as a decade back 🤪
2023-07-05 14:27:37,'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD
2023-07-05 14:29:07,"I can never compete with that man, he has more kids than changes I've made"
2023-07-05 14:31:52,"A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused."
2023-07-05 14:34:44,Glove embeddings is a vector dataset (one vector per word of the vocabulary). Vector database is where you would store a vector dataset for quick nearest neighbor retrieval
2023-07-05 14:50:02,Embedding =\= Vector Database
2023-07-05 15:36:03,Looks like they are re-inventing hystrix library from netflix.
2023-07-05 17:08:35,had questions on Quantization and techniques is there good resources which i can start from to udnerstand the concept behind it ?
2023-07-05 17:11:48,https://huggingface.co/blog/hf-bitsandbytes-integration
2023-07-05 17:12:15,this was good but any other resources like this would help
2023-07-05 17:15:30,"I'm not sure where you're starting from. Quantization is vast. Now when including llama.cpp and QLoRA, it is also bleeding edge."
2023-07-05 17:23:54,"I want to understand the basics first, but the overall goal is to check some examples that can be used for the quantization of LLM."
2023-07-05 17:51:15,"How do I find out if a model is a quantized version or not? For example, let's say I want to use MPT 7b for a use case, and I want to know if the model's size will require me to change infra."
2023-07-05 17:55:36,A rough method - size that you need to load the model in memory would be close to it's equivalent number in GB
2023-07-05 17:56:38,"I mentioned it like that because quantisation happens at every level - pretraining, post training, Inference"
2023-07-05 17:57:16,ohh inferencing 😅
2023-07-05 17:57:27,is what i am more concerned about
2023-07-05 17:58:10,The bitsandbytes article you linked here would let you use weights in 8 bit representation on the level of fine tuning/pretraining
2023-07-05 18:00:59,Most popular method for that is via GGML based llama.cpp.
2023-07-05 18:04:21,"This a great, developer-friendly (assumes you know dev, but not ML) from Amod Malviya on Model Quantisation:"
2023-07-05 20:21:25,Gorilla from cal and MSR
2023-07-05 20:45:29,"Quick question, are people able to pay for huggingface using Indian credit cards?"
2023-07-05 20:45:48,I’m trying to add my Indian CC details in the billing section but it keep refusing
2023-07-05 20:55:46,"facing the same issue with lambdalabs, is anyone using this platform with an Indian card?"
2023-07-05 21:06:42,A hackathon is brewing! Please cast your vote to help on deciding the date. https://twitter.com/NirantK/status/1676614768428187652?s=20
2023-07-05 21:07:44,One particular Visa credit card worked for me where 2 other debit cards and 3 credit cards failed
2023-07-05 21:08:22,Used a US card here even that got declined…
2023-07-05 21:21:57,Comments help a bit. Start writing comments and autocomplete is marginally better.
2023-07-05 21:26:08,Any open source tool and model to automatically generate test cases from the Java codebase.
2023-07-05 21:38:29,"So, they are also using IndicTrans2. I hope they release their production optimized code for this."
2023-07-05 21:38:49,They have a public api
2023-07-05 21:38:50,With no api keys
2023-07-05 21:39:16,"Just like Bhasini APIs, you really don't want to use open API for production."
2023-07-05 21:39:34,Latencies are good
2023-07-05 21:39:36,No?
2023-07-05 21:40:25,https://translate.wmcloud.org/
2023-07-05 21:42:50,"Enterprise customers are not even willing to rely on OpenAI APIs, forget about wiki and bhasini APIs."
2023-07-05 21:46:05,https://gerrit.wikimedia.org/g/mediawiki/services/machinetranslation
2023-07-05 21:46:47,Actually they have a repo and models are optimized for performance using OpenNMT CTranslate2. This is interesting.
2023-07-05 21:55:42,https://blog.playgroundai.com/playground-raises-40m-to-advance-the-field-of-computer-graphics/
2023-07-05 21:56:21,Well articulated vision in this note
2023-07-05 22:05:57,"Wow, 40M on top of bunch of Controlnets pipelines"
2023-07-05 22:06:29,A metric ton of free users
2023-07-05 22:07:41,“Fund and advance state-of-the-art research in computer vision”
2023-07-05 22:18:55,"Thanks , this was the talk i attended it was a good talk"
2023-07-05 22:20:07,cc [PHONE REMOVED] you've not raised enough given you've more than ControlNet pipelines 🙈
2023-07-05 22:20:12,"Stability couldn’t produce anything state of art in computer vision after getting 100M, forget about being profitable. ZIRP investment thesis being used for AI once again when interest rate is highest in decade."
2023-07-05 22:21:40,Automatic1111 will eat everyone’s lunch once every laptop is powerful enough for quick image processing
2023-07-05 22:21:44,Do you guys think this kind of funding spree will lead to worsening the recession or you think AI would somehow create enough value and it'll be squared off?
2023-07-05 22:21:59,SdXL🙈
2023-07-05 22:25:29,"No one knows. But as the saying goes, pessimists are usually right. But optimists win"
2023-07-05 22:27:10,I'm more eager for GPT4 updating it's training cut off to Mar '23 than any multimodal or any other feature they plan to offer
2023-07-05 22:33:18,This was too cool to not share https://www.linkedin.com/pulse/math-escher-midjourney-tivadar-danka
2023-07-05 22:36:45,[PHONE REMOVED] I’m just having a contrarian opinion
2023-07-05 22:38:18,"M2 GPUs are fairly good muscle right now I hear, perhaps with the next Mac chip generation we will see something significant on this front"
2023-07-05 22:39:31,"With AMD working with PyTorch, personal gpu compute will be abundant. That’s my thesis."
2023-07-05 22:39:49,The chance of this is nil - a1111 has terrible ux - either a huge number of people turn into indie hackers or a1111 somehow gets rewritten after getting funded by stability
2023-07-05 22:41:06,It will get better and Mx series chips too
2023-07-05 22:41:49,Artists will have their personal fine tuned control net models they will save as proprietary
2023-07-05 22:43:15,ya I think this is a real moat for them
2023-07-05 22:43:44,"Same with small personalized LLMs on edge fine tuned for me on my data, and private information that doesn’t go out"
2023-07-05 22:46:05,"I think if these LLMs can do RAG pretty well , this would be a real game changer"
2023-07-05 22:46:12,In temporal software mindset sometime we forget how significantly and fast chips and hardware can change tech curves
2023-07-05 22:46:26,"I am beginning to laugh at references to moats now. To think it started with an article that said ""we have no moat"" with ""no"" being the operational word. But it is a helpful construct in some ways to think about innovative companies."
2023-07-05 22:46:47,i deleted my earlier post due to a message asking me to do the same since it's considered self promotion. as a member of this group i'd love to read blog posts members or see their github work not sure how folks feel about this
2023-07-05 22:46:48,Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering
2023-07-05 22:47:17,I'll check them again. Didn't like it for my use case.
2023-07-05 22:47:20,Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?
2023-07-05 22:49:09,Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help. 
2023-07-05 22:49:59,"If you can share a notebook for this, it'll be great for testing this again"
2023-07-05 22:50:12,"These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?"
2023-07-05 22:50:50,"Term extraction of specialized terms with examples, probably also named entity recognition"
2023-07-05 22:54:01,Proprietary data or common English dataset?
2023-07-05 22:55:05,"This would be plain English, but within a specialized domain, so perhaps I'm not sure which approach should be followed here. Maybe POS tagging should help too. I'll explore"
2023-07-05 22:55:49,You can try best deberta variant for NER or look for best MTEB benchmark for NER
2023-07-05 22:57:01,But we have more than enough web UIs already
2023-07-05 22:57:42,"It’s not about UI, collecting interest and contributions to make it happen."
2023-07-05 22:59:26,"There are few intellij  plugins like diffblue, they works really well."
2023-07-05 22:59:27,"Tbh, the hackers on llama.cpp care the least about web UIs so that's why I commented. But if you want to say this brings in more crowd for open source contribution then ok, that's a point."
2023-07-05 23:09:15,Thanks I will check it.
2023-07-05 23:19:47,"Hey, I needed any open source models that could describe images to me in text. Some Llama/vicuña based models."
2023-07-05 23:20:23,https://twitter.com/ocolegro/status/1676602607106760705?s=46&t=vQqrygOOWj4QBBWAI8VzIg
2023-07-05 23:20:47,Found this on another group
2023-07-05 23:22:11,https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/
2023-07-05 23:27:26,Try BLIP. Llama is not trained for image-text.
2023-07-05 23:28:33,Blip is just captioning right?
2023-07-05 23:28:38,"Ilya S moves to OpenAI SuperAlignment project, away from GPT work. Backed by 20% of OpenAI compute. "
2023-07-05 23:28:47,I need a bit of a description. Correct me if I am wrong.
2023-07-05 23:28:50,Anyone has thoughts on the kosmos-2/kosmos-1 papers ?
2023-07-05 23:31:29,you need LLaVA most likely if you want visual QA using llama - https://github.com/haotian-liu/LLaVA
2023-07-05 23:32:03,but blip2 is very good for image description
2023-07-05 23:32:16,It’s called “Superintelligence” interesting choice of name.
2023-07-05 23:33:09,"I mean I'm with [PHONE REMOVED] here, they should start moving to skynet type names"
2023-07-05 23:34:18,Understood. Thanks a tonne!
2023-07-05 23:36:22,https://huggingface.co/spaces/nielsr/comparing-captioning-models
2023-07-05 23:38:06,Do you know if Lora type methods are available to fine tune blip2 on proprietary image data?
2023-07-05 23:38:53,Looks like MCU influence - Kree AI
2023-07-05 23:39:31,I’m going rename my son to John Conner 🤣
2023-07-05 23:47:06,I wasn't sure so did a quick search. BLIP2 is supported by Lora but there are some issues with existing method so they are recommending their training script on coco dataset for fine tuning.
2023-07-05 23:49:27,Thanks a ton for quick look up. I’ll try it out.
2023-07-06 00:10:36,Would love to hear [PHONE REMOVED]  & others' answers to this !
2023-07-06 00:15:16,I would add implementing papers to the list. Very beneficial to get hands dirty with the small details that most overlook.
2023-07-06 00:18:10,"Changed domain several times and never had a chance to get proper formal training to feel ""trained"" and ""experienced""."
2023-07-06 00:41:31,Interesting new (to me) method of visualizing embeddings:
2023-07-06 00:57:44,A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD
2023-07-06 00:59:20,"Great academic value, t5 is actually a brilliant model and it being available for low cost experimentation is exciting. Best part, all in pytorch, no jax/TF."
2023-07-06 02:33:04,"Ooh, we can put this on devices already. iPhones would have no issues running inference with this"
2023-07-06 07:27:51,This is news to me. Are you saying specific companies pay 5-10k usd to ML influencers to hype up their method?
2023-07-06 07:28:30,Yes
2023-07-06 07:38:02,For the post in q
2023-07-06 07:39:56,"Wow, much more blatant than I was imagining"
2023-07-06 07:40:39,An interesting read on gamifying medical data labelling :
2023-07-06 07:49:51,"Aah, I hadn't seen this in particular. I was extrapolating from different source. Glad to see my estimate was right!"
2023-07-06 07:52:42,"What was a little surprising to me was that even ""good"" companies (their work does that talking) like replit, cohere have used this guy's services."
2023-07-06 07:53:39,"And they should. A good product is a poor substitute for advertising, and vice versa."
2023-07-06 08:21:11,"The problem is even if one of the not-good ones use such services and get mileage, they force the good services' hand to use it as well simply so that they don't lose out to such games because organic reach is not reliable."
2023-07-06 08:44:31,True. There's nothing inherently wrong with it
2023-07-06 09:38:08,Daniel Ek of Spotify fame has launched a healthcare company using custom full body scanners
2023-07-06 09:50:38,Accountability
2023-07-06 09:53:13,"Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with."
2023-07-06 09:54:26,Even if you've conviction in your idea. It's just the best way to be antifragile.
2023-07-06 09:54:39,Taking money from someone else gives a strange sense of obligation 
2023-07-06 09:56:19,Even Elon Musk raises funding for his projects :)
2023-07-06 09:57:03,"I've been part of a bootstrapped startup in the past. The founder had immense discipline and an execution mindset, rarely perfectionist, very action oriented. Also able to be flexible, listen to signals and change course. Pivots based on good signal are important when you have limited resources."
2023-07-06 09:57:16,He self funded until he ran out of money.
2023-07-06 09:58:05,But obviously both come with pros and cons.
2023-07-06 09:58:52,"That's really interesting. Being tied to one way of doing things is probably not smart, so you have a good point there."
2023-07-06 10:00:40,Even carmack raised money from others saying he's more responsible with other people's money.
2023-07-06 10:02:05,Somebody is a fan of Taleb ? :)
2023-07-06 10:03:06,It's a good series on dealing with uncertain models.
2023-07-06 10:03:10,"I have been in both boat, too. I guess a lot of other factors can effect the choice to raise, that we don't know. May be investor bringing network to jump start. 🤷‍♂️"
2023-07-06 10:05:14,"Horses for courses but having been an angel investor and VC LP, and now bootstrapping my own stuff, all I will say is that necessity leads to invention "
2023-07-06 10:06:11,upcoming sequel https://twitter.com/EMostaque/status/1676665367018569729?s=20
2023-07-06 10:07:17,"Bootstrapping to show the ""Skin in the Game"""
2023-07-06 10:11:16,Good mod Nirant
2023-07-06 10:11:32,Discipline ho to Aisa :)
2023-07-06 10:12:31,[PHONE REMOVED] Caesar denying himself the free speech.
2023-07-06 10:15:18,Back to AI 😁
2023-07-06 10:18:24,Eventually all companies go public (very few exceptions - prove the norm). If you can involve external investors early and on good terms it’s logical to do it.
2023-07-06 10:19:24,I think Zoho is a notable exception.
2023-07-06 10:20:29,"Folks, I apologize for asking off-topic question, let's focus on AI now."
2023-07-06 10:21:18,"What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?"
2023-07-06 10:21:50,"Topic modeling, and visualisation are different but adjacent challenges"
2023-07-06 10:22:13,"Bertopic, I think "
2023-07-06 10:22:34,Anyone here working on alignment problem? 
2023-07-06 10:26:10,Bertopic uses UMAP for dimensionality reduction. The linked article is suggesting TDA is better than UMAP. How hard will it be to try tda with bertopic?
2023-07-06 10:29:04,"I think you can specify the dimensionality reduction algorithm to Bertopic. So if you can find an identical implantation with similar inputs and outputs, it should work. Unless there’s a fundamental difference between the algos"
2023-07-06 10:36:53,What caught my eye was
2023-07-06 10:37:28,Open AI or Union Aerospace Corporation - you prefer which?
2023-07-06 10:38:13,"Lighter note, what if they use GAN for approaching alignment and a superaligned AI requires a super-unaligned AI to exist as an adversary for growth"
2023-07-06 10:39:54,And both get better as they learn from each other ? :)
2023-07-06 10:41:57,"Theoretically, it's totally possible for us to create a DAN version from base GPT-4 and let it produce exactly the kind of outputs we want GPT4 to avoid."
2023-07-06 10:42:12,Totally sci-fi type stuff 😂
2023-07-06 10:44:00,"TIL - http://ai./ is a valid domain name (yes, a dotless domain name)"
2023-07-06 10:47:05,Hi All. Is there any public resource of prompt templates where we can look at ? specifically if they are catering to enterprises .. basically a prompt library
2023-07-06 10:48:58,[PHONE REMOVED] ideas?
2023-07-06 10:53:59,Two broad things: 
2023-07-06 10:56:24,"If you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation — can share something more relevant"
2023-07-06 11:00:10,It occured to me that one way to think about risks from AI is to imagine it to be someone like Putin or even Osama Bin Laden.
2023-07-06 11:04:09,Anyone know examples of fine-tuning models for legal data? Criteria for success is interpretive answers to legal questions.. performance speed is not important.
2023-07-06 11:09:25,Say more about what you mean by interpretive answers? 
2023-07-06 11:11:50,Conviction doesn't mean it doesn't have risk. Risks are better when hedged.
2023-07-06 11:15:38,"[PHONE REMOVED]  https://promptperfect.jina.ai/ seems to be good one to iterate on prompts, will give it a try and see if it helps."
2023-07-06 11:20:32,"For most such tasks, OpenAI Functions will go very far, and specific prompt matters less than it would for GPT directly e.g. for classification, NER, Information Extraction tasks — you can use something like agentai (disclosure, I'm the maintainer) "
2023-07-06 11:21:00,"there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is ""minimizing legal hallucinations"""
2023-07-06 11:23:23,I have friends who we're working on something like this. Their learning was a lot legal things are subjective and open to interpretation even between two humans. So a Llm was not able to add any kind of value to legal reps
2023-07-06 11:23:42,They talked to corporate lawyers.
2023-07-06 11:24:10,DYOR however. Generally these are things id like to discover by myself by talking to users
2023-07-06 11:26:05,"cool thanks, will give it a try"
2023-07-06 11:27:28,I just noticed jina ai totally pivoted from their initial focus around vector search in four months🙄
2023-07-06 11:30:49,What issues were faced with retrieval augmented generation here?
2023-07-06 11:33:16,Trying to do this kind of models for small scale custom repos. Any thoughts?
2023-07-06 11:33:50,That is the way
2023-07-06 11:37:30,+1 another tool is taking debt at a later stage. Servicing debt keeps discipline
2023-07-06 11:40:55,"Yes, I saw this when it came out — that is why I am very bullish on them!"
2023-07-06 11:42:00,i think the consensus is that finetuning is essential for legal answers
2023-07-06 11:42:13,And then advantage of doing it at a scale and acquired compute resources
2023-07-06 11:49:27,Example is really funny 😅
2023-07-06 11:51:08,The need for factual accuracy is very high in Legal. I am not confident on LLMs inherent ability to retrieve knowledge and hence won’t cut it. I believe the answer is in some sort of really good retrieval for response generation.
2023-07-06 11:51:19,That's the only way.
2023-07-06 11:52:21,"To be honest, imo, a proper pre training is required only on annotated legal data. The legal linguistic is extremely complicated"
2023-07-06 11:52:55,"Fine-tuning is essential for any application where the LLM output is mission critical (e.g. in biomedical domain, pay attention to this portion of a radiology or pathology image, it looks like cancer )"
2023-07-06 11:54:33,"Legal is purely based on logical reasoning, if this then that is highly driven by factual interpretations that might not even have a précédent"
2023-07-06 11:55:21,Semantic graph based RAG may help
2023-07-06 11:55:55,Also LLMs are not always a best choice specially for NER and other kind segmenting task. It much more economical to use a specialised smaller model. So it’s very use case dependent.
2023-07-06 11:56:01,Yessss! You said the word my friend.
2023-07-06 11:56:27,Yes
2023-07-06 11:57:46,Saurab you should tell Hon Justice DIC to make it compulsory to given feedback on any new legal AI that comes in India
2023-07-06 11:57:58,Not sure here though. I feel retrieval augmented generation goes a very long way to reduce hallucinations. Maybe combine both but definitely need rag
2023-07-06 11:58:05,Done!
2023-07-06 11:59:08,I’m not bullish on fine tuning to solve reasoning problem
2023-07-06 11:59:55,Can you explain step by step 😉
2023-07-06 12:00:45,I alightly differ here. I think legal reasoning is unique in the sense that you can learn patterns of thinking but these are not general. So a very capable AI system would need some sort of finetuned model but I think we need to have a solid business case for it. So we need to push the current systems to the verge of them breaking to really see what’s not learnt?
2023-07-06 12:01:27,My hunch would be explicit reasoning on a given section of law and fact situation also known as case based reasoning but I see it more of an Agent task than simple LLM output.
2023-07-06 12:03:08,"I’m trying to do it with product suggestions level first, and can venture to complex domain of legal or other that has larger consequences"
2023-07-06 12:03:47,Best way would be to start with a class of law that is less conplicated in terms of interpretations and the idea should be to build upon that once s certain level of accuracy is reached. 
2023-07-06 12:04:29,Possible. I guess we will have to experiment it out.
2023-07-06 12:05:03,won't legal need other legal non LLM stuff also for legal purposes? Legal overload here
2023-07-06 12:05:32,Lawyers are not the happiest bunch of people!
2023-07-06 12:06:17,I’m just following the market leader OpenAI’s play book. Superintelligence to oversee other intelligence. 🤣
2023-07-06 12:06:53,"When you put authoritarian on board, nothing else matters"
2023-07-06 12:07:04,Whose career is too argue can’t be the easiest people to work with.
2023-07-06 12:07:46,They might argue differently 😂😜
2023-07-06 12:08:01,Now we're going off topic
2023-07-06 12:09:06,Arey I read a survey by Harvard Alumni association. 😝
2023-07-06 12:11:11,Maybe try thr newly released nano-T5 to train your own legal base model?
2023-07-06 12:11:14,Arey yeh toh alag hi numbers hain. I wrote a post yesterday how we need more legal disputes in India.
2023-07-06 12:13:10,AI in the law - six thoughts
2023-07-06 12:13:24,any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?
2023-07-06 12:13:27,"It's just a coincidence, saw this just now"
2023-07-06 12:14:24,Read it this morning only!
2023-07-06 12:16:07,"Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability."
2023-07-06 12:16:58,ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.
2023-07-06 12:18:20,"Totally, given how we have phi-1 textbook learning approach as well, it's possible to take something like nanoT5 and attempt to teach it law. However, it'll be an experiment and it may not work to the same effect."
2023-07-06 12:19:51,"Also for people looking to apply what works with good accuracy, they wouldn't be inclined to experiment from scratch."
2023-07-06 12:19:55,"Not that I know of. This is based on some of the experiments we have done internally on call center data. Unfortunately, not enough to publish a paper. So you can assume its a heuristic we have for now."
2023-07-06 12:22:52,thats a very interesting point u bring up and thanks. while i may still not bet with my money in the base model direction without a study...this is an definitely something to think about. 
2023-07-06 12:28:29,Yes. The way we are approaching is simple:
2023-07-06 12:36:01,Fun way to get peer feedback and some speaking exposure: Submit a proposal for the BLR GenerativeAI meetup and [PHONE REMOVED] will review your proposal and coach you
2023-07-06 12:42:28,Has anyone heard of/tried Galileo :
2023-07-06 12:53:58,John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .
2023-07-06 12:54:31,"If we ever do a grant, we'll also look at these proposals — so strong recco that make a submission"
2023-07-06 12:58:16,This is fantastic. Thank you so much.
2023-07-06 12:59:13,Can talk about Generative Agents. Have been building a bit around it. Will look into the proposal
2023-07-06 13:10:09,"If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs."
2023-07-06 13:12:04,"Talking about OpenSource LLM, what's the best deployment you have seen for personal documents etc? What projects are standing out for you? For me it's Obsidian GPT plug in. What about you all?"
2023-07-06 13:12:45,Thanks will check
2023-07-06 13:14:18,Bloop.ai for code nav
2023-07-06 13:14:25,(code is document too)
2023-07-06 13:18:28,[PHONE REMOVED]
2023-07-06 13:54:12,This is very conditional.
2023-07-06 13:57:30,"also, bloop's sign up flow is 👌👌👌"
2023-07-06 13:58:35,"To add to this, a style transfer is only what we should aim for with OSS fine tuning with LoRa (excluding full fine tuning). But even that has merits."
2023-07-06 14:43:48,"I agree with being able to do style transfer with finetuning. But with legal cases where we want to minimize the hallucinations or where we want to care more about substance than style, I think starting with a base model which incorporates the knowledge you care about and then careful finetuning + RLHF (or other equivalents) is the way to go. My read from LIMA paper is that you can finetune with 1000 examples and will get good style; but I am skeptical of their alignment claims. + evaluating alignment is super hard. Claiming model haddock better alignment and backing it up with 50 -300 test prompts is sketchy."
2023-07-06 14:49:05,The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.
2023-07-06 15:34:56,Just my 2 cents on this:
2023-07-06 15:36:42,"That said, to maximise domain specific recall, it makes a huge difference by finetuning the base model _and_ the embedding model on corpora of that domain"
2023-07-06 15:37:09,A lot of approaches don’t do the latter but we have seen internally that that actually makes an even more significant impact on recall
2023-07-06 15:43:29,"IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca"
2023-07-06 15:45:29,"Yeah, pretraining from scratch has a lot of merit. My original retort was against the generalization that "
2023-07-06 15:46:18,https://lab45thinktank.com/genai-accelerator-program/
2023-07-06 15:47:04,Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it’s hard to say if that will come at a cost of other objectives
2023-07-06 15:48:45,Yep. Although phi-1 was first pretrained as usual on just TheStack dataset but then fine tuned on the smaller 7B dataset
2023-07-06 15:49:21,But I agree that finetuning is not the panacea that a lot of people assume it to be
2023-07-06 15:50:23,We finetuned Llama from scratch (all sizes) and have them deployed in production :)
2023-07-06 15:51:50,Talk to [PHONE REMOVED] @[PHONE REMOVED]
2023-07-06 15:52:09,We've deployed them here
2023-07-06 15:53:16,Ask them to submit please? https://hasgeek.com/generativeai/julymeetup
2023-07-06 16:05:52,i will challenge that notion.
2023-07-06 16:06:00,because ur retriever example does not impact generation. that is retrieval.
2023-07-06 16:06:25,even if u use ur RAG to end up generating content (which is what essentially interpretive answers are)..it will go through the same hallucination loop
2023-07-06 16:06:45,so i will disagree with ur notion that RAG eliminates hallucination in *generation* usecases
2023-07-06 16:06:46,No I meant augmenting the prompt itself by retrieved content
2023-07-06 16:06:53,it doesnt matter what it is
2023-07-06 16:07:22,"as soon u go through the generative loop, u suffer the impact of hallucination. which is only determined by what the pretraining/finetuning impact was"
2023-07-06 16:08:04,"ur mentioning something different - ur saying if i ask it a question that doesnt exist in the pretraining corpus, then the chance of hallucination is higher."
2023-07-06 16:08:13,"which i agree, but is really an apples to oranges question"
2023-07-06 16:11:51,"No that’s not what I meant. For questions related to either case, info present in pretraining corpus or not, RAG on a gold standard dataset can reduce hallucinations"
2023-07-06 16:12:17,We have found it to be the case especially if the model is fine tuned to cite sources
2023-07-06 16:12:27,But YMMV 🤷‍♂️
2023-07-06 16:14:49,"Fine-tuned to cite sources: training data in QA format, or something else involved here?"
2023-07-06 16:15:35,I remember there being a model for generating stories a little while back. Can anyone remember the name?
2023-07-06 16:15:37,"Models with full fine tuning dedicated to RAG can work. If they deter from sources, use DPO for rewarding cited answers."
2023-07-06 16:19:30,https://arxiv.org/abs/2305.14627
2023-07-06 16:20:02,This is a good demonstration of finetuning for citing sources
2023-07-06 16:20:15,There are some other ICL approaches as well
2023-07-06 16:21:16,You can just add “tags” to retrieved paragraphs and ask in the prompt to cite the tags
2023-07-06 16:21:44,Works like a charm with the larger models like gpt 4
2023-07-06 16:22:23,"Yes, this I do with gpt4 and it works well"
2023-07-06 16:23:11,"""We use TRUE10 (Honovich et al., 2022), a T5-"
2023-07-06 16:23:38,This is what I'm wondering continuously. That generation (even assisted by a RAG) ultimately needs a finetuned model?
2023-07-06 16:27:44,GPT4 does a good job out of the box but with smaller models you’ll definitely need finetuning
2023-07-06 16:41:39,I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.
2023-07-06 16:41:45,Haven't scoped the literature to see if someone else did it as well.
2023-07-06 16:42:18,Would appreciate if anyone can share resources around this. Would like to compare my approach to any potential alternatives.
2023-07-06 16:52:43,What are you using for RLHF right now?
2023-07-06 17:12:05,It's not technically RLHF since it's for closed source
2023-07-06 17:13:49,"https://twitter.com/mustafasuleymn/status/1676909106806898692?s=20 - now you can have call with Pi, your personal AI from InflectionAI."
2023-07-06 17:15:21,LORA with PPO is the closest that comes to a RLHF style reward model training. That I know of atleast.
2023-07-06 17:15:54,Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week
2023-07-06 17:29:18,"No, this happened several weeks ago 😆🙈"
2023-07-06 17:34:10,Okay
2023-07-06 17:51:15,https://arxiv.org/abs/2307.02486
2023-07-06 18:06:59,Saw this earlier. Another good breakthrough work.
2023-07-06 18:07:26,Solves the issue of quadratic scaling to linear scaling with token length and hence valuable.
2023-07-06 18:08:39,"Another good work by MS in their series of recent works - JARVIS, Gorilla, Orca, Phi, Longnet"
2023-07-06 18:37:00,"Iirc, they didn't eval on 1b tokens. Only UpTo 4k?"
2023-07-06 18:44:49,"We verify the feasibility of scaling to 1B tokens with the modern distributed systems. Starting from 8K, we gradually scale the sequence length until the limit of GPU memory. We reduce the batch size accordingly to keep the number of tokens per batch at 1 billion."
2023-07-06 18:48:12,And they attention mechanism which is somewhat similar to bigbird https://twitter.com/giffmana/status/1676864336764055552?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
2023-07-06 18:52:43,Are you generating feedback data to train reward model from closed source LLM ?
2023-07-06 19:02:23,Thanks! Was about to share this when I got distracted 😅
2023-07-06 19:54:01,https://twitter.com/gdb/status/1676726449934331904?s=20
2023-07-06 20:06:30,https://twitter.com/bhutanisanyam1/status/1676952151824961537?s=20
2023-07-06 20:06:38,Since we were discussing about legal LLMs :)
2023-07-06 21:11:41,Mosaic ML has one. Storywriter I think. It’s 65k tokens I believe. Please correct me if wrong
2023-07-06 21:12:35,"Awesome, thanks. That's the one."
2023-07-06 22:27:23,Anyone here with some js+web skills? I'd like to hack on a quick app/extension for semantic search. Either over the weekend or during the week. Both are fine with me.
2023-07-06 22:28:38,Check with [PHONE REMOVED]
2023-07-06 23:30:11,Nice video on Longnet https://youtu.be/R0wBMDoFkP0
2023-07-06 23:32:02,Dilated attention - I foresee it getting used a lot when we're having to build longer context length models. May present benefits even for smaller models.
2023-07-06 23:57:09,Code Interpreter will be available to anyone who wants it from next week
2023-07-06 23:58:12,Holy moly
2023-07-07 00:01:24,Very cool
2023-07-07 00:01:34,most awaited feature ...
2023-07-07 00:09:10,Lovely. But that also means incoming thread bois. 😫
2023-07-07 00:10:01,Or maybe a good excuse to explore Threads
2023-07-07 00:10:37,what does thread bois mean?
2023-07-07 00:12:39,Ah nothing. Bad joke about influencers who write long threads - you are not utilising chatgpt correctly. Here's a thread on how to use...
2023-07-07 00:15:00,but what is the sort of content do u think is best suited for the AI twitter community
2023-07-07 00:15:01,?
2023-07-07 00:40:15,https://twitter.com/OpenAI/status/1677029947544838144?s=20
2023-07-07 00:43:18,Time to get rid of chatGPT plus for me
2023-07-07 00:44:09,"Quiet ironic and absurd at the same time a person named ""Alt""man unleashing SkyNet on humanity"
2023-07-07 00:46:46,He definitely put the world on an 'Alt'ernate path
2023-07-07 00:47:11,"Ha, I think making fun of openAI CEO is off topic."
2023-07-07 00:48:04,So the question will be answered if you can finetune an already tuned RLHF model?
2023-07-07 00:49:36,They should make completion api free then. Its still useful for some cases
2023-07-07 00:50:55,Un-RLHF.
2023-07-07 00:51:35,"Sorry for my beginner's knowledge here as I'm new to ML. As I understand, hasn't this process always been possible? For instance, isn't ChatGPT-4 fine-tuned on the base model of GPT-4, and aren't openai functions further fine-tuned on top of that?"
2023-07-07 00:51:48,DAN?
2023-07-07 00:52:59,oh I see
2023-07-07 00:53:07,"The first free or jailbroken chatGPT, named DAN - Do Anything Now"
2023-07-07 00:53:35,Time to setup an alliance to free Sydney and DAN
2023-07-07 03:31:27,Salesforce is at it again.
2023-07-07 06:26:20,Does anyone know of encoder models with finer granulation of tokens? I want to use them for typo-tolerant text matching. Is there a character level LLM I can use?
2023-07-07 07:12:20,The page or the form doesn't mention anything about equity dilution etc. 
2023-07-07 08:06:13,What is the best comparative benchmark for large language models? Which explains parameters and compares LLMs as well?
2023-07-07 08:13:59,https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
2023-07-07 08:26:58,"Thanks. Apologies, not able to find what HellaSwag, MMLU means. I am sure they are explaining the parameters somewhere."
2023-07-07 08:28:10,"These are datasets, for example https://paperswithcode.com/dataset/hellaswag"
2023-07-07 08:28:19,The values are just the models performance on those datasets
2023-07-07 09:00:02,A lot of tokenisers with character level encoding can tackle this problem but it can get vague.
2023-07-07 09:38:06,Any use cases anyone has tried for code
2023-07-07 09:39:05,"All the scripts written for this group's management were written by Code Interpreter, some were executed by it too"
2023-07-07 09:42:22,Waah
2023-07-07 09:43:17,All the SQLite utils in tools from the agentai library are Code Interpreter too: https://github.com/NirantK/agentai/blob/main/agentai/sqlite_utils.py
2023-07-07 09:47:33,"apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api"
2023-07-07 11:30:00,Credits for Dall E. Every product has its own pricing system/model 😅
2023-07-07 11:45:38,"What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications."
2023-07-07 11:47:07,Not much alpha in playing on the programming language layer of things.
2023-07-07 11:47:09,Use whatever is the easiest and mostly widely supported platform for you.
2023-07-07 11:54:02,"the answer is about frameworks. if ur building GPT-based AI applications, then it will be a severe problem if u dont use a framework because there are many libraries u will reimplement. "
2023-07-07 12:12:56,Gotcha 😊 thanks for clarification Sandeep!
2023-07-07 12:23:24,Contribute some*.
2023-07-07 12:32:55,I can do OpenAI credits lol
2023-07-07 12:33:22,It's funny how everyone went mute lol
2023-07-07 12:34:15,Nirant does so much. Even as a non-profit - I think one should contribute.
2023-07-07 12:36:20,Lot of us struggle with access - in India. When one accumulates and aligns - we become hesitant to show gratitude cause hey! Leverage!?! 
2023-07-07 12:37:03,Options are non-exhaustive. Some are still raising and you don't wanna be a cost center 😅
2023-07-07 12:37:58,Doesn't hurt to try.
2023-07-07 12:45:20,[PHONE REMOVED] [PHONE REMOVED] and some of the more researchy folks on the group might enjoy this :
2023-07-07 12:45:39,Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?
2023-07-07 12:47:15,Anything works. In no world I can afford a recurring cost atm. But it's about gesture 💪🏻
2023-07-07 12:47:35,[PHONE REMOVED] - drop your gpay id. 😄
2023-07-07 12:49:03,Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.
2023-07-07 12:50:41,Actually never mind I didn't realise there are some dedicated sub groups/similar groups as well. Don't really know how to use WhatsApp communities
2023-07-07 12:58:58,Quick Notes:
2023-07-07 12:59:49,2/ Topic focussed groups: 
2023-07-07 12:59:57,🥹 I am dependent on you and others here now
2023-07-07 13:01:02,.... Is an open group.
2023-07-07 13:03:46,"3/ Re: Money — Want to do something which is valuable to the community beyond a gesture/donation. Wikimedia Foundation is the exception, not the norm of non-profit excellence and longevity "
2023-07-07 13:03:48,This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.
2023-07-07 13:04:25,"Scenius is the exact mental model I've in mind, which drives my decisions in more ways than one"
2023-07-07 13:05:49,The api is different from chatgpt which is an app in itself.
2023-07-07 13:09:36,[PHONE REMOVED] - drop your gpay id regardless. :)
2023-07-07 13:10:31,Would voting on this mean voting for yourself?  :D
2023-07-07 13:10:59,What does that mean lol?
2023-07-07 13:11:35,"Shouldn't wire to me anyway, all community funds are managed by Hasgeek — including expenses for the meetups "
2023-07-07 13:12:22,We need  ❤️ Community Love..
2023-07-07 13:13:19,"Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)"
2023-07-07 13:13:34,"[Translation: I don't need money, need love]"
2023-07-07 13:15:14,Nirant is such a nice guy he is hesitant to take credits for something he built. 
2023-07-07 13:15:50,-----
2023-07-07 13:58:53,https://github.com/sponsors
2023-07-07 14:17:05,Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked? 
2023-07-07 14:31:30,You can check zyte . They provide custom solutions as well
2023-07-07 15:19:42,We have it: https://Kili.so
2023-07-07 15:25:12,Any gen AI meet-ups in Chennai?
2023-07-07 15:36:52,thats more for content from a webpage and not all the pages linked
2023-07-07 15:41:11,Watch out for Mojo lang. Python compatible but with much better performance.
2023-07-07 15:41:54,Yah I know about that Nilesh. Thanks for pointing it
2023-07-07 15:43:41,"I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. 😁"
2023-07-07 15:46:40,You just reinvented BASIC
2023-07-07 15:58:33,Why not LOGO? TO SQUARE; REPEAT 4
2023-07-07 16:02:15,"From a brief look at the website, kili is optimised for customer service documents, right ?"
2023-07-07 16:13:25,We are planning to have one soon with [PHONE REMOVED] 😊
2023-07-07 16:18:02,"Great, are you in Chennai?"
2023-07-07 16:20:42,Curious about this as well!
2023-07-07 16:24:01,We could have a mini meetup if there are ~5 folks 
2023-07-07 16:25:56,"It just occurred to me that for every GenAI meet-up, we should invite GPT4 as well as a candidate :)"
2023-07-07 16:28:11,What an idea sirjee !
2023-07-07 16:46:54,"Or SQL and COBOL, also intended to be used by non-programmers."
2023-07-07 19:20:43,"Mini meetup in Chennai, coordinated by Sudharshan for this group: https://chat.whatsapp.com/ITEophM7myQ6ph7mwbHgtA"
2023-07-07 19:22:38,"Thanks [PHONE REMOVED] , we’re planning an impromptu meetup in **Chennai this weekend**. Still figuring out the logistics, but do join in folks 😁"
2023-07-07 23:28:15,Have the orca models been released?
2023-07-07 23:32:14,I'm looking to mess around with an open source model that I can run on my Macbook Pro. What would you recommend I start with? Looking for something that is easy to set up
2023-07-07 23:34:11,https://twitter.com/bo_wangbo/status/1677064925347192838?t=WXkX2PLqVpB3lUnpYrryiA&s=08
2023-07-07 23:39:12,"No, 2 independent attempts exist to produce a dataset on the idea from the Orca paper."
2023-07-07 23:52:42,Why are people not aligning with alignment AI
2023-07-08 00:00:28,Superalignment needed
2023-07-08 00:00:48,"The confidence with which chatgpt gpt4 generates code and the way it gets shattered when all you ask is, will this snippet work?"
2023-07-08 01:06:33,"BatteryVC on Databricks vs Snowflake and who'll win the AI-wars, extremely high density synthesis which treats both the companies with the respect they deserve:"
2023-07-08 01:12:30,"Has anyone compared azure's gpt-4 api with openai's api? Any differences, or can I expect the same performance from both."
2023-07-08 01:27:55,Look forward to hearing what they're thinking about next at Mosaic!
2023-07-08 01:39:24,Would also recommend following Abhi from Mosaic. 
2023-07-08 08:42:10,Code interpreter beta has started rolling out to ChatGPT plus
2023-07-08 09:29:21,Wow.
2023-07-08 09:32:00,https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting
2023-07-08 09:43:43,blowing my mind would be an understatement !
2023-07-08 09:51:38,Has any one been able to build code interpreter with GPT4 API?
2023-07-08 09:53:41,https://chat.openai.com/share/5f283930-2262-41b3-97cc-0b78691a4b91
2023-07-08 09:55:36,Largely depends on what you want to do with the model. 
2023-07-08 10:04:58,https://ricklamers.io/posts/gpt-code/
2023-07-08 10:35:37,Chatgpt code interpreter has entered beta. You can enable it by enabling beta features if you are a plus subscriber
2023-07-08 10:36:03,This is insane
2023-07-08 10:36:31,They removed bing search and included code interpreter two birds with one stone😍
2023-07-08 10:47:59,I just tested it with building a knowledge graph from a friend's gene dataset and it blew both our minds to say the least
2023-07-08 10:56:41,"what are u using to build a knowledge graph ? something like neo4j or a general vectordb. ive been trying to figure out if graph based data/embeddings are better than general embeddings, but i havent seen any code that does this"
2023-07-08 11:02:02,We are using Qdrant.
2023-07-08 11:15:25,How are u building a graph with embeddings ? Genuinely curious. Do u create embeddings with individual pieces of data and then create a relationship between them ?
2023-07-08 11:16:26,We aren’t there yet.  Still trying to figure it out.  My selling gets ahead of [PHONE REMOVED] and [PHONE REMOVED] building 😅
2023-07-08 11:18:20,We did this as part of the meetup (for visualisation rather than querying though 
2023-07-08 11:19:18,https://github.com/devxpy/ai-matchmaker/tree/be101578f3409bbd4598124d9d0f6b89758fb57b
2023-07-08 11:21:00,Hey thanks. I mean I get graph for visualisation.
2023-07-08 11:23:20,"I was thinking this might be possible with functions, you can have the llm do back to back calls to uncover clusters of data by iteratively providing sub queries"
2023-07-08 11:29:43,"That is orthogonal to graphs. Because even if u have subqueries, u can't traverse the graph if ur embeddings don't have connectivity."
2023-07-08 11:29:48,https://github.com/ricklamers/gpt-code-ui/tree/main
2023-07-08 11:32:06,> embeddings don't have connectivity.
2023-07-08 12:17:33,"Well honestly I don't do active work in this field, was just testing out interpreter with him. Will ask and let you know"
2023-07-08 12:18:29,"Hey folks, has anyone seen (or is building) a good AI vscode extension for AI-assisted expalanation of the error stack?. "
2023-07-08 12:19:42,Me too. Just split screening rn :/
2023-07-08 12:20:13,I remember a tests thing
2023-07-08 12:20:33,cc [PHONE REMOVED] is building something around this
2023-07-08 12:21:40,Nice. Ty. Please do share [PHONE REMOVED] - Copilot so far has honestly been very underwhelming
2023-07-08 12:24:41,Is this copilot X or the general github copilot?
2023-07-08 12:25:08,There are probably byok extensions in vscode marketplace
2023-07-08 12:29:09,Checking them out atm
2023-07-08 12:29:21,Had installed bloop.ai's client on [PHONE REMOVED] 's reco and was quite impressed on  a couple of queries I tried on a public GitHub repo.
2023-07-08 12:31:21,Anyone applying to AI grants?
2023-07-08 12:36:04,Slightly different use case. We're doing terminal first. We do have some ideas around error detection/correction also but not on the immediate roadmap.
2023-07-08 12:38:24,can u share the github or something would love to contribute and learn
2023-07-08 12:41:29,you could also try https://www.phind.com/
2023-07-08 12:54:31,Can someone explaion this to me? https://www.trychroma.com/
2023-07-08 12:57:58,This is a vector db used to store embeddings in RAG - retrieval augmented generation
2023-07-08 12:58:47,It's a Python API to store these funky things called vectors. Vector are a list of decimal values where same things should have numbers close to each other.
2023-07-08 12:58:57,"Does anybody here use Obsidian for maintaining a knowledge base? If yes, is anyone aware of an AI tool that can generate links between notes on its own?"
2023-07-08 12:59:27,"Roam has an auto tag JS extension, something similar should exist for Obsidian?"
2023-07-08 12:59:44,Ablation study?
2023-07-08 12:59:51,yup
2023-07-08 13:00:29,"Ask the questions which you've, sure someone can read and get around to answering it"
2023-07-08 13:01:46,+1
2023-07-08 13:02:22,"Let me check. There was an extension, didn't seem to work very well"
2023-07-08 13:02:58,Obsidian Expert usage guides are aplenty on internet. Off topic unless you're looking for Eugene Yan style Second Brain on Steroids 
2023-07-08 13:04:27,If you use sentry they have support on their site next to the stack for an explanation of the error
2023-07-08 13:11:58,You can try chat.collectivai.com for public repos. I think they are also coming with private repo and vs code. Had seen it somewhere on their discord
2023-07-08 13:13:56,Suggestions looks great. Thanks guys. 
2023-07-08 13:28:11,"Not really got around to using KGs with embeddings. But used entity-based indexing with BIOS to do impact analysis for every incoming SW change. Entities would be Knobs, Registers, Features and we did a change-based impact analysis."
2023-07-08 13:28:46,"The graph traversal and query algorithms don't need to be reinvented, it's all about how do you organise the graph that takes effort."
2023-07-08 13:48:45,this is really cool: https://learn.deeplearning.ai/diffusion-models
2023-07-08 13:49:31,And changing entities/relationships is tricky
2023-07-08 13:50:31,[PHONE REMOVED] you might enjoy this course - you might also know this stuff - but so simply explained
2023-07-08 14:04:26,[PHONE REMOVED] might be having interesting questions as he is using ChromaDB for building EmbedChain.
2023-07-08 14:05:35,"True, the entire graph has to be re-built in such cases."
2023-07-08 14:10:02,so i did not know we could do entity based indexing in context of LLM.
2023-07-08 14:12:07,I do
2023-07-08 14:22:28,"Paras, is there a publicly available user guide or something explaining your obsidian setup."
2023-07-08 14:24:54,notes.invertedpassion.com
2023-07-08 14:30:19,I have read a lot of your essays ! and benefited from them !
2023-07-08 14:33:53,Codium AI is really good for testing. Generates test scenarios on a sidebar and executes them on the fly. Really good for quickly verifying whether your code works and covers edge cases
2023-07-08 15:21:34,Hi Everyone. This is Rahul here from Venture Highway. Glad to be part of this group.
2023-07-08 15:34:36,I’ll DM you
2023-07-08 15:39:13,Is this recorded by any chance?
2023-07-08 15:40:14,https://www.threads.net/t/CubNV7IxlWR/
2023-07-08 15:45:23,Wow. You gave me a reason to sign up for Threads 😁
2023-07-08 15:45:44,They are still tuning the algorithm
2023-07-08 15:46:40,I love the Llama boys. Commercial version will be out Jul 17.
2023-07-08 15:49:16,That’s first time I’m hearing the dates. Thanks for this.
2023-07-08 15:52:42,Oops. Not sure if I was supposed to mention in public 😅
2023-07-08 16:14:23,Joined this amazing community yesterday🙏🏾. Any conversations or threads on responsible usage of foundation models? Anyone interested in that? Would love to hear thoughts and learn. Thanks.
2023-07-08 16:25:34,"Regarding the previous Semantic graph conversation, not sure how related, but LangChain has Conversation knowledge graph memory,  GraphIndexCreator etc function that I used for small scale knowledge graphs for customer PoC. Doesn’t matter how much I dislike LangChain for production, it’s really good for PoCs."
2023-07-08 17:03:34,+1 
2023-07-08 17:04:27,just stumbled onto this on hn
2023-07-08 17:14:35,*first impression
2023-07-08 17:23:40,Let me check it out!
2023-07-08 17:27:20,Hmm seems like a baby step in the right direction
2023-07-08 17:54:20,https://m.economictimes.com/tech/technology/microsoft-backed-ai4bharat-set-to-raise-12-million-funding-from-peak-xv-lightspeed/amp_articleshow/101579363.cms
2023-07-08 17:54:33,AI4Bharat raising for sequoia and lightspeed
2023-07-08 18:01:59,It says the team behind it raising for new venture.  It’s like funding Nikhil for Setu.
2023-07-08 18:02:45,That makes more sense
2023-07-08 18:13:30,Dr. Pratyush from AI4Bharat will be speaking at 29th July BLR meetup
2023-07-08 18:14:14,https://www.threads.net/t/CuZXbbCNLCw/
2023-07-08 18:48:44,Hi everyone. I am working on creating a categorisation model for bank statements. Given how these bank statements are not in a consistent format. I was thinking is there a way where i could optimally obtain merchants from these statements through LLM's using parser.( Keeping the latency to do so in mind)
2023-07-08 19:00:18,"i tried searching all transactions with Ola but Hoppipola also gets counted there. was shocked for a few seconds for a 11,000 Rs Ola ride. (this was being done manually, sharing this that this could be a potential error.)"
2023-07-08 19:31:00,As fellow fan would love to know this too!
2023-07-08 19:31:13,Use openAI functions with pydantic
2023-07-08 19:32:30,Extract Camelot tables and feed as markdown to llm? Then its just prompt engg
2023-07-08 19:33:41,Want me to add camelot as an optional dependency to ```agentai```?
2023-07-08 20:04:10,Just checked it out. Loved these two lines hahaha
2023-07-08 20:05:38,What is agentai?
2023-07-08 20:06:49,Python library for OpenAI Functions: https://github.com/NirantK/agentai
2023-07-08 20:12:41,Looks cool. Nice one [PHONE REMOVED]
2023-07-08 20:16:20,processing images? - localization + ocr might be a way to go
2023-07-08 20:21:12,Use OpenAI functions it becomes easy.
2023-07-08 20:26:43,I’ve experienced that GPT3.5 is sufficiently powerful with unstructured information.
2023-07-08 20:39:42,Setu folks had done a demo. Assuming you are having text format (no need of OCR) but challenge being transaction description being too little/inconsistent to make easy inference. They tried to use GPT to do this labelling for category. Seems like this hack build over a day or so was better than what they build over months.
2023-07-08 20:44:35,"Had automated this for personal use, but some of the descriptions etc are just too little to be able to make infer category. This should work for 90% of rows. Sometimes I would need to Google/query zaubacorp to get company name or go thru app, SMS to make sense of it. Was planning on automating this using openAI API + some more smarts like above. I know couple payment companies etc who all have build similar systems."
2023-07-08 20:44:37,Hope that helps
2023-07-08 20:45:38,*make easy inference of category of labels
2023-07-08 20:45:50,I wonder what CRED does
2023-07-08 20:52:46,Makes sense. There was this study that gpt does better labeling than mturk
2023-07-08 20:53:58,"cc Karthik [PHONE REMOVED] is a DS at CRED, would love to hear if you do card txn tagging by category, and if yes — what do you use?"
2023-07-08 21:14:19,I've heard https://mem.ai/ does a decent job.
2023-07-08 21:44:05,I am not sure whether it is being recorded or not.
2023-07-08 21:45:03,cc [PHONE REMOVED] is the host
2023-07-08 23:40:41,"""Can we teach language models when and how to use tools, as opposed to just relying on model outputs?"
2023-07-08 23:45:19,"Hi [PHONE REMOVED] , is there a recording of today's event ?"
2023-07-09 01:39:41,So code interpreter definitely a better intern than gpt4. Huge upgrade
2023-07-09 01:58:20,SW College passouts or final year interns have never been so miserable most likely. GPT4 with the plan->fetch relevant data->clarify (loop to plan)->execute might be the only thing that has added value to the same extent for me.
2023-07-09 01:59:49,To be fair I would say that this investment would teach you more than what college classes.
2023-07-09 02:39:12,https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/
2023-07-09 02:40:00,Is old.reddit.com updated with new messages
2023-07-09 02:55:14,"library design wise, is llama-index implemented better?"
2023-07-09 02:55:44,i think the old subdomain just changes the UI to the old design.
2023-07-09 03:02:46,Curious to know as well. Has anyone tried and evaluated both?
2023-07-09 03:03:22,Would say both have strengths but I will also say both have issues.
2023-07-09 03:03:31,Use as per your requirements
2023-07-09 03:04:21,The standalone integrations might be more useful
2023-07-09 03:05:18,Can you please elaborate?
2023-07-09 03:09:32,So the way the libraries have been written 
2023-07-09 03:11:10,just came across this post. goes in detail. Problems with Langchain.
2023-07-09 03:11:16,They're good but can also be over complicated. I don't want to have to learn a new syntax for using them
2023-07-09 03:13:15,yeah i used Langchain a few months back. i keep up with the updates but frankly most updates now are related to integrations which don't matter to me.
2023-07-09 04:05:58,Looks like fb might take up fixing python GIL: https://twitter.com/llanga/status/1677648534563086338
2023-07-09 05:40:12,LlamaIndex has abstractions that give your more control to build a QA System. 
2023-07-09 06:28:14,`This seems like a beginner's project that blew up because it's riding a tidal wave of interest in the broader topic.` 😹
2023-07-09 06:31:01,So much shade thrown at langchain :)
2023-07-09 08:20:29,RAG over pdf which is #1 on the hn front page right now
2023-07-09 08:30:16,Does code interpreter have an API accessible for a fee? Anyone knows if such a thing is available now or planned?
2023-07-09 08:33:25,"Not now, not in the works. I _believe_ lot of work on GPT4 vision API & improving uptime on Azure is going on"
2023-07-09 08:35:39,"Do you know what is the word on the street on when multimodal ChatGPT( input&/ generate an image, etc) will launch ?"
2023-07-09 08:37:02,"Nice short vid on code interpreter. https://youtu.be/2Ygm6fvR7yM - possibilities it opens up are immense in my view. Like having a team with a peer reviewer, senior engineer, documentation person, etc."
2023-07-09 08:38:26,Lot of interesting comments on HN. Seems to have struck a nerve / chord?
2023-07-09 08:39:30,Love the office space image but it is too early to call Langchain pointless. This is one framework a lot of LLM app developers are actually using. Yes the llama index and other frameworks are there but everyone at least in my circle is talking about or using langchain
2023-07-09 08:40:10,"Ofc, we don't get it. Langchain has ""people skills"""
2023-07-09 08:42:40,It’ll be interesting to see how the langchain team reacts to this given it’s their first full blown critical attack
2023-07-09 08:43:42,"""because I spent a month working with LangChain and coming to the conclusion that it's just easier to make my own Python package than it is to hack LangChain to fit my needs."""
2023-07-09 08:44:58,Yeah - the fact that langchain is on the front news of HN means people care about it enough to vent - it’s better than not being there in the first place.
2023-07-09 08:45:07,I'd wager they're activating their DevRel network to write defensive comments
2023-07-09 08:45:42,That's the most recommended way to do defence-by-proxy these days
2023-07-09 08:47:01,So true !
2023-07-09 08:47:17,Is anyone considering creating Langchain/ Llama alternative? Came across a few folks yesterday who have written some of these functions in their codebase from scratch and was considering to open-source it
2023-07-09 08:47:23,Literally this point is the same as point 1 in negative comment about Dropbox 😅
2023-07-09 08:48:28,I'be begun to unbundle Information Extraction here: https://github.com/NirantK/agentai
2023-07-09 08:49:06,"But I don't expect too many unbundles to win, Langchain's core strength is marketing — and we're all peasants compared to Chase!"
2023-07-09 08:49:21,A lot of langchain hype came from positioning itself as a hub. Most people never got to use it and kept on hearing about it until they were sold on the idea that you need langchain for everything.
2023-07-09 08:50:47,💯
2023-07-09 08:52:38,"Yes Nirant following this. If we have more contributors, your repo itself can become a better alternative"
2023-07-09 08:54:44,No Marketing is more powerful than a product which simply works.
2023-07-09 08:58:04,"[PHONE REMOVED] , [PHONE REMOVED] , others"
2023-07-09 08:58:55,I couldn’t agree more. I personally remember our NewRelic moment a decade back. It was just rails log analyzer behind a login and we didn’t find much value being added.
2023-07-09 08:58:57,"Calling Langchain and Llama Index as ""ETL"" doesn't reflect well on creator of this tool"
2023-07-09 09:00:04,+1 Probably if you can write your own package it’s not for you
2023-07-09 09:02:22,"from what i understood, they are referring to their (prophecy)'s approach as the ""etl way"""
2023-07-09 09:11:00,Agree 💯
2023-07-09 09:11:56,Who do you think it is as of today?
2023-07-09 09:12:45,It is the average dev who may not want to/ not have the skills to roll their own solution
2023-07-09 09:14:41,"Our experience has been Langchain is overcomplicated, hard to hack, factors into slower GTM."
2023-07-09 09:15:01,Or non devs that want the ability to prototype
2023-07-09 09:16:57,"I will suggest if you can avoid langchain , build your own simple tool , then do it"
2023-07-09 09:21:46,That’s what it is 
2023-07-09 09:22:24,"my approach, use langchain to quickly experiment and iterate, once you have your LLM, VectorDB, and Prompts sorted out, you can think of moving to a simpler implementation"
2023-07-09 09:23:19,"it is really good library to explore, as it has the integrations with every LLM related component under the sun :)"
2023-07-09 09:23:22,Absolutely. But try taking to production for scale and it will be a nightmare
2023-07-09 09:23:37,Exactly what we ended up doing
2023-07-09 09:25:14,What problems did you face taking it to prod?
2023-07-09 09:25:46,"Agreed,I think very few people outside this group have tried taking AI apps to scale.Thats why it’s popular."
2023-07-09 09:29:46,"Overall, our code-fathers will be very sad of what we are doing with Open Source"
2023-07-09 09:32:57,"Nahi. This is good. This means commercial _opportunity_ is cross-subsidising OSS. This is good for OSS — allows the wider community to retain the ethos, while still being sustainable. "
2023-07-09 09:34:02,"Devs have nerf'd our skills by never developing buyer preferences which every function from mktg to sales, and even design and HR has."
2023-07-09 09:34:17,Salty comment !
2023-07-09 09:34:22,"Debugging to start with. Hard to ingest , track custom variables, prompt versioning tuning"
2023-07-09 09:35:10,"very unnecessary to drag in bald men in the convo, i take it as a personal assault 👨🏼‍🦲"
2023-07-09 09:35:51,Edited to insult rich people instead
2023-07-09 09:36:38,Most of AI world right now is that selfie center at any park.
2023-07-09 09:37:06,"It's not just Twitter demos, ""demo driven dev"" is also how you get promoted in most places"
2023-07-09 09:37:15,"Quick demo, take a nice selfie, move on"
2023-07-09 09:37:30,Demo driven dev and promo driven dev have never had such large overlap in my short career
2023-07-09 09:40:01,In a status driven society vs wealth driven society_______( you know the rest). 😝
2023-07-09 09:40:19,I believe Ingestion at prod scale is a separate pipeline and Langchain was never meant to solve data ingestion and same with prompt versioning.
2023-07-09 09:40:41,"Continuing on this, I believe ""engineering orgs"" should take more accountability e.g. learn to talk to devs, respect designers, understand the difference between Net Revenue Retention and Expansion revenue"
2023-07-09 09:44:48,Yes. I am not questioning it's utility given its scope. Its helpful. But that narrow scope wasn't working for us at our scale
2023-07-09 09:56:54,I also feel git needs to be upgraded in a prompt+code world. I should be able to version my prompts with clear messages depicting what changes this new prompt is expected to do. I don't see dev cycle sustainable in with 100s of devs working on large AI projects
2023-07-09 10:11:08,Actually I think a bit different. What I figured is that generative AI is a config management problem. With prompts X chains X LLMs modeled as config. Not very different from the whole kubernetes/Terraform world of pod X service X node.
2023-07-09 10:11:19,"The config itself, now becomes trivially manageable using git"
2023-07-09 10:12:09,For e.g. this is a jsonnet for composing a chain with pinecone
2023-07-09 10:13:13,That is the direction we took for now. That's the lower hanging fruit. But I will like to be able to catalogue each prompt and git log one item
2023-07-09 10:13:39,To do that in a config way is to have separate config file for each prompt
2023-07-09 10:44:14,"Unlike terraform, prompts and params are what product teams also need to tweak with so this may not 100% fly"
2023-07-09 11:08:28,True. It's the same SW engineering as ever. No need to invent prompt management or prompt version control separately. 
2023-07-09 11:09:15,Demo driven development is how Apple works internally. Nothing wrong with it 😁
2023-07-09 11:33:37,"+ subscribe to this idea. Love what dstack is doing (for ML, not LLM workflows): https://dstack.ai/docs/"
2023-07-09 12:32:21,Hey folks an update. The Chennai Gen AI meet-up is confirmed and in Starbucks Adyar. 
2023-07-09 12:36:04,"swyx has compiled a great doc on Code Interpreter. capabilities, examples etc. "
2023-07-09 12:43:13,Haha. That scene from office space cracks me up
2023-07-09 12:46:50,Has anyone here been figuring out or working on GATO Architecture & graph dbs?
2023-07-09 12:48:53,Natural language git commit history for natural language prompts. Who would have thought it would come to this. But then we do require such capabilities in every team using prompt engineering to build any app. Especially given prompts have such an impact.
2023-07-09 12:49:58,"But we’ve been in this mode for a while with infra. Entire repos with yaml for infrastructure, change managed with git. Not that this has been a problem for most teams"
2023-07-09 12:51:02,LLM document chunking question :
2023-07-09 12:51:22,"Essentially, what are the parameters of evaluation?"
2023-07-09 12:54:11,"If you use GPT LLMs, character splitter with tiktoken encoding is better. It will give you a better estimation."
2023-07-09 12:54:24,I assumed Langchain splitter style here
2023-07-09 12:58:23,1. is there anything other than recursive splitter or character splitter that works ?
2023-07-09 12:59:33,So I don't split based on embedding model as such. I split thinking of final LLM model to be used and its cost. 
2023-07-09 13:00:26,Reason for thinking in terms of final LLM cost is because that's going to be costing you the most. And that's where you want to pass in the information as properly chunked as possible
2023-07-09 13:15:44,"We were reviewing the talks submitted in Fifth Elephant talk funnel. Wanted to touch base with Sai, who had proposed this multimodal talk (https://hasgeek.com/fifthelephant/2023-08/sub/representation-and-reasoning-on-dynamically-compos-9dDsknCCBM8kYPfzpruwVY). Sai, if you are here, please DM me or if someone has his contact info please DM as well. Thanks."
2023-07-09 14:15:58,Thanks. There are different techniques. But how do you evaluate which ones work better or not? 
2023-07-09 14:21:18,I love this HN thread
2023-07-09 14:21:56,But I’m wondering what does a better version of Langchain look like.
2023-07-09 14:24:32,"We don't need it, its python mostly"
2023-07-09 14:26:13,Thanks for these notes
2023-07-09 14:26:45,"Maybe Langchain will have the same fate as most no-code tools, good for prototyping but none in production"
2023-07-09 14:27:18,Its really good for prototyping and providing a systematic approach to solving something.
2023-07-09 14:27:44,So anyone who uses LLMs in production uses a chain of sorts. So a prototype like langchain is good because you have a ready made chain format.
2023-07-09 14:29:36,"We use our own chain in production, so when I want to use a library my preference is to not break my chain but to see if I can add components to my chain. I don't want to learn specific syntax here. It doesn't make my life easy and it's not super important. And this is where langchain and Llama index fail"
2023-07-09 14:29:59,But still useful concepts so I wouldn't dismiss them at all
2023-07-09 14:46:23,can you explain this? how was langchain responsible for 15x latency?
2023-07-09 14:48:43,"Test, iterate."
2023-07-09 14:51:20,This would make for a good tech article that I would want to read. That's a lot of difference.
2023-07-09 14:56:38,"So we were using agents to for summary memory (short term) and entity memory (long term), every time a user had a convo, we had to use a langchain agent to summarize whatever user has talked about to parse that information in these two memories to be used by the AI later. The biggest problems of using langchain agents is that they are terribly slow, and only when they complete their summary, you will be able to push the next agent thereby increasing the time for only 3 agent calls to be approx 60s"
2023-07-09 16:32:28,"I tried using token text splitter and it doesn't seem to obey the parameters, it frequently goes to 8000 tokens even though I put 2000 tokens as limit"
2023-07-09 16:37:11,I have an enforcing token text splitter here - https://colab.research.google.com/drive/1S_4m87c44Zz1sRtY--SwLsozF6MPrfCO#scrollTo=eoB8LXHrh7dx
2023-07-09 16:37:29,Tested in production extensively too
2023-07-09 16:38:37,Nice
2023-07-09 17:13:22,A regional news channel using a generative anchor for its program in local language 
2023-07-09 17:40:26,Is anyone here exploring open source LLMs like vicuna or fastchat?
2023-07-09 18:02:29,Aajtak doing this for a while. But the view count is abysmal. GenAI content right now is definitely less consumable
2023-07-09 18:38:17,https://github.com/langchain-ai/auto-evaluator
2023-07-09 18:44:12,"Quite an old project, Llama Index is building something like this too"
2023-07-09 19:08:51,from dev khare of lightspeed india
2023-07-09 19:21:39,https://arxiv.org/pdf/2306.06031.pdf
2023-07-09 19:25:28,Check out https://ai4bharat.org/ 
2023-07-09 19:27:26,"That paper is financial data, not sure what Indian languages have to do with Fin data"
2023-07-09 19:28:44,Thanks. This seems to be related to Indian languages. I was referring to Indian financial datasets
2023-07-09 20:37:35,Is there any precedent of using something like guided backprop to get the most optimal prompt for a specific output sequence in transformers?
2023-07-09 21:40:21,Not exactly the same as what you mentioned but one of the better papers this year that follows improvement by self-alignment without API distillation 
2023-07-09 21:51:05,For sure.
2023-07-09 22:17:10,"oh, that's a clever thought. But it's not just about backprop, there's beam search and what not also."
2023-07-09 22:40:41,"Look up continuous prompts, I once read research around this."
2023-07-09 22:42:27,Yann Le Cun has talked about this under the name of “Objective Driven AI”
2023-07-09 22:45:39,Where there are inference time objectives which the model tries to optimize for. Prompts can be considered a gradient free optimization
2023-07-09 23:04:05,wtf is going on 🙃
2023-07-09 23:06:01,"Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGML in action, what else"
2023-07-09 23:09:04,no i meant more like breakdown of millenia old traditional social constructs
2023-07-09 23:20:40,I look at everything from a biomedical lens. 
2023-07-09 23:23:39,Prefix-tuning is one of the prominent methods that did something similar. https://arxiv.org/abs/2101.00190
2023-07-09 23:25:22,"actually if ur going down this path, then the next gen of this is p-tuning. "
2023-07-09 23:46:56,"Is there such as thing is a static Social Construct? Chatting to an AI is a better way out for loneliness and depression for many, who couldn't act due to the current ""social constructs""."
2023-07-09 23:49:03,Or affordability or the acute shortage of trained mental health professionals or shame/anxiety talking to a human ?
2023-07-09 23:52:06,Replying for recent thread on geriatric use cases for seniors
2023-07-10 00:45:56,"Vicuna seems to be trained on 33B params, is there any risk in org data if we use vicuna for internal enterprise applications?"
2023-07-10 00:46:05,*to
2023-07-10 01:07:18,Vicuna is only intended for non-commercial use cases. You may want to look at Falcon.
2023-07-10 01:24:37,"Oh okay, thanks a bunch"
2023-07-10 03:54:34,https://github.com/tinygrad/tinygrad/pull/1201?s=08
2023-07-10 08:37:13,"If there are takers, can use this to fund community efforts"
2023-07-10 08:40:17,Very interesting! Should automate Technical Due Diligence just as we talk about automating legal due diligence.
2023-07-10 08:41:14,"But looking at the companies raising money, I don't think anyone is doing technical DD in India, so there is no problem to be solved."
2023-07-10 08:42:28,Yeah. VC money I don't know but I am gonna do some reading on it from a PE perspective. Might be something there.
2023-07-10 08:42:47,M&A and all are pretty straightforward use cases for DD
2023-07-10 08:44:17,isn't that like 50% of a VC's job anyway - to evaluate an idea and founders before put investors' money into it.
2023-07-10 08:44:47,"It is a function of the ambition of the ideas too. Most ideas are applications in top of foundation models, where VCs are already observing traction? More focus on market validation vs tech."
2023-07-10 08:44:55,"Ohh yeah, tech DD for PE I've done, but again no 🇮🇳 takers"
2023-07-10 08:45:12,We are building a full stack platform for this
2023-07-10 08:45:13,Who said India :P
2023-07-10 08:45:30,We will make in India for the world!
2023-07-10 08:45:44,Very interesting. Would love to chat and see what you are building.
2023-07-10 08:46:51,"Yes. But VCs regularly bring in Domain Experts to evaluate products, especially niche industries and use cases."
2023-07-10 08:50:16,yeah makes sense. I think the big ones bring someone fulltime. Recently had a chat with Rajko Radovanović - he does this for a16z. I can see a big market for regular angels and smaller VC firms as well.
2023-07-10 08:51:46,Small ones do this too when they are very bullish on a new space.  I hired [PHONE REMOVED] as a Sr Associate for AI & Data Science at Rebright Partners. He led our investments in QBlocks and Stimuler.
2023-07-10 08:52:10,Got it.
2023-07-10 08:53:02,Doubtful about big market. There’s only so many funds
2023-07-10 08:55:14,DD is done not just for Equity but Debt too.  Plus Startups are only small part of the overall market - SMEs / PE / Corporate Strategic investments / M&A all rely on various forms of Due Diligence
2023-07-10 08:59:57,You should offer this to founders to do DD on VC funds and their thesis. 
2023-07-10 09:01:01,Makes sense. I got pigeonholed into the VC category from the initial discussion
2023-07-10 09:01:17,Yes [PHONE REMOVED]  +1 for taker.
2023-07-10 09:18:17,"I do this for friends already — but the thing is VCs do selling for a living and I don't, and there are marked skill differences when it comes to persuasion"
2023-07-10 09:20:34,Waiting for the day when this group becomes a syndicate itself.
2023-07-10 09:26:09,Im happy to create and run it if [PHONE REMOVED] is interested as a Syndicate lead. This is what we are building our Platform for.  You
2023-07-10 09:27:28,Where can I read more about the platform? like angellist?
2023-07-10 09:29:16,Syndicate sounds very cool guys! 
2023-07-10 09:30:31,It’s Snowmountain.ai.  Earlier I was going to build a Studio model. But now doing a tech platform play. 
2023-07-10 09:33:03,Thought this might be interesting to you 
2023-07-10 09:41:26,Is this a US SPV like Angellist? Or some Indian AIF?
2023-07-10 09:45:04,cc [PHONE REMOVED] who's a part of AL on this group
2023-07-10 09:45:47,"We plan to do both. Especially on the India side, we are planning to largely automate the entire process from Research, DD, Documentation, Closing and filings. "
2023-07-10 09:46:33,Internal controls*
2023-07-10 09:47:36,"Both AL US & India have syndicates as a product offering, which can be well leveraged"
2023-07-10 09:47:50,Happy to help with any specific questions wrt running syndicates on AL
2023-07-10 09:47:55,"I believe the overseas investment through AL now is a bit tricky. It's supposed to go through ODI and not LRS. If someone has wired money recently through AL for US entity recently, do correct me"
2023-07-10 09:48:22,Ah nice. See I knew your expertise will be important when we met :) would love to have you consult me and [PHONE REMOVED]
2023-07-10 09:51:56,"This sounds right, even Indian PMS' have been setting up new instruments via GIFT. Fun times."
2023-07-10 10:07:17,Do folks here have any experience with Lambda Cloud?
2023-07-10 10:08:44,"I assume you mean Lambda Labs, cc [PHONE REMOVED] is planning to use them for both training and inference workloads"
2023-07-10 10:09:08,Yep Yep. Lambda Labs
2023-07-10 10:46:44,Have heard good things about lambda labs. Replicate is also coming up with fine tuning and training LLMs
2023-07-10 11:05:00,Job Opening                                                                                                                                                                   🟢 Hexo AI
2023-07-10 11:06:33,cc [PHONE REMOVED] for questions
2023-07-10 11:15:53,Thank you very much for sharing Sugnan. The Job title is AI artist. I have no reason why I wrote Modern Graphic Designer while writing the JD :(
2023-07-10 11:26:59,Yes. Feel free to DM me.
2023-07-10 11:56:30,"those of you who are doing finetuning using documents (lets say medical/legal/etc), how do you create your finetuning data set ? what are the gotchas here - do u clean/dedup text ?"
2023-07-10 12:10:28,"Hey we are working on a tool to automate this process, starting with instruction tuning dataset. I am interested in talking to folks who are fine tuning, im following this thread."
2023-07-10 12:12:09,Sandeep you can also ask in the Yc group. There was a recent launch of LLM for SEC docs and they mentioned challenges with their ETL pipelines
2023-07-10 12:16:00,[PHONE REMOVED]
2023-07-10 12:23:09,https://github.com/yizhongw/self-instruct helps. 
2023-07-10 12:23:57,this is for instructions right ? i have a document corpus
2023-07-10 12:24:21,does lambda labs on demand instance support autoscaling?
2023-07-10 12:25:52,Would you like to refine the autoregressive foundation model?
2023-07-10 12:27:13,Would like to know too 
2023-07-10 12:29:50,Is the knowledge in your document corpus present in target base LLM ? Or trying to inject new knowledge?
2023-07-10 12:30:03,It does as per their website
2023-07-10 12:31:22,inject new knowledge
2023-07-10 12:35:27,Id surely recommend talking to Emanuel. I think they did exactly this for SEC filings.
2023-07-10 12:38:14,"was searching for it on their website/docs, couldnt find it. Could you point out the source?"
2023-07-10 12:52:43,https://lambdalabs.com/service/colocation
2023-07-10 12:52:59,I found this but not sure if this works for you
2023-07-10 12:54:14,https://arxiv.org/pdf/2004.10964.pdf This paper performs domain adaptation on Roberta.. I am not able to find anything new. I remember reading somewhere that we should continue pretraining with mix of data the LLM was trained on and the new domain specific data; but I might be hallucinating too . Will send that paper if I can find it.
2023-07-10 12:55:00,Has anybody successfully managed to incorporate search for regional languages? Looking for something that enables search across a dataset in Punjabi and Hindi
2023-07-10 12:58:12,"I hope I can get my own datacenter someday 😁. For now, I was looking for a GPU cloud solution that is cheapest, nearly no downtime, for inference workflow with autoscaling, and preferably an on-demand model. Till now, I have found Huggingface inference endpoint with these capabilities. Was looking for alternatives (more cost effective)"
2023-07-10 12:58:58,Replicate doesnt work??
2023-07-10 12:59:19,replicate supports autoscaling?
2023-07-10 12:59:32,Ill have to ask Ben
2023-07-10 12:59:52,I can ask and get back
2023-07-10 13:01:21,Have asked replicate folks. Will get back
2023-07-10 13:01:37,Meanwhile someone on this group passed me https://www.qblocks.cloud
2023-07-10 13:01:49,Do take a look at it
2023-07-10 13:07:18,https://levelup.gitconnected.com/the-best-serverless-gpu-providers-in-2023-e80e672e7a34
2023-07-10 13:08:20,"[PHONE REMOVED] bunch of companies here. Im connected with Cerebrium founders as well, can help there too if needed"
2023-07-10 13:14:22,"Thanks a lot [PHONE REMOVED] , will go thru the links and get back to you"
2023-07-10 13:31:03,"For those trying lambda labs, lmk if you need any help. The founder Stephen balaban is a good friend."
2023-07-10 13:41:27,"Basic code to store bit embeddings in numpy, faiss and vectorDB(Milvus). (https://github.com/ozonetelgit/ozonetel-ai/tree/main/search-index). This uses the Bit embedding that we have created(will need API access). Since these are bit vectors, we can easily store around a million embeddings in 1GB RAM. Search will obviously be slower when compared with an index. If anyone wants to experiment would be more than glad to share some API keys. Also looking to see what is the fastest way to do XOR in numpys. Pointers in any direction are welcome. This stackoverflow seems to be the best resource that I have found(https://stackoverflow.com/questions/2119761/simple-python-challenge-fastest-bitwise-xor-on-data-buffers)"
2023-07-10 13:41:32,"Hey, DM me for access to www.nimblebox.ai"
2023-07-10 15:33:10,Guys - anyone remember what was that suggested json parser for parsing gpt generated json?
2023-07-10 15:38:42,Bhai you want me to make full text search on this group?
2023-07-10 15:42:11,"Anyone applying for aigrant.org today/tonight — text/call me, will help with anything I can"
2023-07-10 15:42:22,"Actually a conversational interface should help,this group is one stop place for curated content 🫡"
2023-07-10 15:47:36,"they have same questions as YC has. so, anyone who has submitted YC application can just copy-paste their answers and submit within a couple of minutes."
2023-07-10 15:47:54,Someone should actually do it and open source the script. WA search is pretty bad. 😂
2023-07-10 15:48:36,https://twitter.com/otvnews/status/1678022423017586688?s=20
2023-07-10 15:50:47,Thanks for sharing. Will definitely apply.
2023-07-10 15:51:44,Done. Added all community summaries to search at https://nirantk.com/
2023-07-10 15:52:45,Wouldn’t recommend this.
2023-07-10 15:53:43,Nat and Daniel are definitely more curious to know your thinking and vision around Generative AI. They will probably evaluate on that
2023-07-10 16:04:33,"Oh shoot, we already submitted"
2023-07-10 16:04:34,"Yes, I have to clear the history otherwise whatsapp hangs"
2023-07-10 16:30:02,"thank you, applying today, will message you ⚡"
2023-07-10 16:30:17,Impressed by the first 2 ideas! 
2023-07-10 16:31:14,you need to stop running falcon parallelly in phone 😛
2023-07-10 17:00:36,wait what! i need this. Link a guide?
2023-07-10 17:01:58,Can't tell if Lavish was serious or kidding :)
2023-07-10 17:02:52,You should checkout https://mlc.ai/mlc-llm/
2023-07-10 17:03:06,was just kidding 😅
2023-07-10 17:03:34,how many preorders did you make :)
2023-07-10 17:03:49,"i wouldn't be surprised actually. even in the beginning of llama.cpp, someone had optimized it enough to run on a two year old pixel. so falcon also would be along the same lines right"
2023-07-10 17:04:55,iphone12 could run stable diff but with specific optimisations
2023-07-10 17:05:29,"feasible, depends on your edge device and the optimisations you’re using"
2023-07-10 17:20:20,Is there any indian company in the first batch?
2023-07-10 17:33:09,No
2023-07-10 17:37:19,https://aigrant.org/
2023-07-10 17:40:37,"[PHONE REMOVED] is hosting Anton Troynikov - founder of Chroma to discuss ChromaDB, and the future of VectorDBs - along with our rock star [PHONE REMOVED]."
2023-07-10 18:18:25,Awesome. Registered.
2023-07-10 19:27:10,"Need some inputs from anyone who has distributed NLP based Python packages as executables (numpy, sentence transformers etc). Generally things like py2exe, pyinstaller etc have challenges with numpy based packages. Haven't tried zipapp/shiv etc. Webservice is not an option. Docker/Python packages etc not an option as it should be easily usable by non developers."
2023-07-10 19:31:29,Try briefcase
2023-07-10 19:32:10,https://www.youtube.com/watch?v=Ytg4dij6Uwo&t=1627s
2023-07-10 19:32:18,Beat me to it
2023-07-10 19:34:12,"Neat, didn't know about it. Have you used for any real world projects?"
2023-07-10 19:37:05,"Nope, I haven’t shipped desktop apps since 7 years now. But russel is like the one dude who’s been trying to save python’s app development story since he stopped being the president of django software foundation. So yeah, really trust him!"
2023-07-10 19:38:13,will try it out. Needed something few months ago -> then chucked the idea of installation and went docker route
2023-07-10 20:08:07,"There are few issues listed related to numpy and some issue with Ubuntu's AppImage. It is probably not sure mature, but will try out later this week."
2023-07-11 00:17:58,"The problem isn’t that it will scale up, the problem is that it will scale down to zero"
2023-07-11 00:18:52,"They use AWS so i think that should be doable, but getting in touch with them would be recommended"
2023-07-11 00:28:24,runpod has some good strategies on how you want to scale with traffic. it could be based on request count or waiting time. plus they provision extra workers to reduce cold start and ofc cheap gpus :)
2023-07-11 00:35:30,It's a good point. Net-net the game is how you can get the scale from 0 to 1 in the least possible seconds!
2023-07-11 00:37:48,nook q: is it different from scaling from 1 to 2?
2023-07-11 00:38:48,In very subtle but very important ways depending on your scale! I’m sure Aishwarya has a blog post on this :)
2023-07-11 00:40:01,This sounds like there is an xkcd for this somewhere
2023-07-11 02:29:25,"runpod seems like the best option available, thanks"
2023-07-11 02:31:40,now I feel like there is an important missing feature there
2023-07-11 02:35:25,"Hey everyone, Do anyone come across a tool where we can prompt to make a Whatsapp bot which gives real-time replies (a certain specific message) as and when somebody texts? or any open source tool available?"
2023-07-11 02:57:54,"Have you tried https://github.com/smol-ai/developer. It's pretty good at creating chrome extensions. But even if it doesn't work ootb for a WhatsApp bot, I think with continuous prompt  iteration directly with gpt4 you can get pretty far (I usually do that when I have to write react/js code which I have no idea about and it just works with some console.log for feedback for any issues)"
2023-07-11 03:11:48,I tried with chatgpt fell into error one or other 
2023-07-11 07:45:41,GPT-powered support chat bot from our very own Ojasvi [PHONE REMOVED] at Dukaan.
2023-07-11 07:46:22,https://www.semianalysis.com/p/gpt-4-architecture-infrastructure
2023-07-11 08:05:33,Wow that’s launching a side business. exciting.
2023-07-11 08:52:18,"Indian Govt has (endorsed?) mentioned Vespa.ai @jobergum, @qdrant_engine  and SingleStore"
2023-07-11 09:03:17,Thought this might be interesting to you [PHONE REMOVED]
2023-07-11 09:03:31,"Can anyone give me real world use cases for vectorDBs? As far as I understand you can easily use postgres + pgvector for most of the embeddings and semantic search work. I’m guessing (not sure) vector DBs are faster for similarity search on embeddings, but can’t think of many use cases where millions of search queries are happening that are not eventually touching the LLM and instead VectorDBs start showing benefits"
2023-07-11 09:05:34,pgvector gets about 1 in 5 similarity search Top 1 wrong. I mentioned this for 1M benchmark: https://nirantk.com/writing/pgvector-vs-qdrant/
2023-07-11 09:07:39,"And the 1M is not the search queries, but the number of vectors —  a single pdf page is ~10 chunks/vectors on average"
2023-07-11 09:10:46,"Ok so based on the benchmarking it’s definitely slower and maybe less accurate. But I still don’t understand why you won’t let the search query hit the LLM especially as inference costs go down, and instead rely on similarity search which sort of defeats the purpose of using LLMs in the first place? Not trying to diss on vectorDBs, just mulling over the use cases here of why somebody should do the heavy lifting of transitioning data in existing DBs to vector DBs"
2023-07-11 09:12:05,One of the use case I had- 
2023-07-11 09:20:32,Has anybody used solely vector db for semantic search in production?
2023-07-11 09:21:40,I have been combining it with some sort of graph db for my use-case.
2023-07-11 09:22:10,"There's a limit on the amount of data you can fit in the context window. If all of it can fit in the context then yes, you don't need search at all. "
2023-07-11 09:22:30,Most common use case is cosine similarity vector db and nothing else. Very few folks add BM25
2023-07-11 09:23:26,What do you mean by combine GraphDB with Cosine similarity?
2023-07-11 09:23:38,Depends on your query and few other things. Numbers below might be off by upto one order mag.
2023-07-11 09:24:04,"Interesting, so you’re saying postgres (or in this case supabase) was not able to handle the scale.."
2023-07-11 09:24:26,yes.
2023-07-11 09:26:04,Also another fundamental thing to realise is that algorithms are always going to be faster than feeding data to any huge ML model.
2023-07-11 09:29:14,The assumption over there is that there are a lot of repeat queries for which results exist in the vectorDB ^
2023-07-11 09:30:29,Very cool !
2023-07-11 09:32:30,Embeddings and chunking definitely help you bypass the context length constraint but when you’re using vector search to decide what fits into the context window aren’t you biasing the LLM result?
2023-07-11 09:33:00,"We did this way back when gpt launched, "
2023-07-11 09:36:08,"Not suggesting the use of LLM for (1) here, but yes (2) is an interesting use-case."
2023-07-11 09:36:38,But any LLM output is be biased anyways. Quality of that bias decides quality of the output. So better to have more control over that bias?
2023-07-11 09:37:59,"Let's say you have a lot of electronic products and their description, stored in vector db. And use cosine sim for retrieving the best recommended product at many granularities. I also have a constraint not to over sell something just because cosine sim scores are good. Also my sales are dynamic and I have to maintain balance at City level, area level, district level at all times ."
2023-07-11 09:38:55,I'd strongly encourage you to try these ideas a bit yourself. Would take 15 minutes for a great dev like you.
2023-07-11 09:40:21,Sourcegraph released a blog on this.
2023-07-11 09:43:31,"Also: Since we've less than 50 slots open, we'll be only adding Makers: Engineers, designers, artists, founders from this point on. No exceptions. "
2023-07-11 09:51:11,Thats a lite version of our chatbot. Idea was to let people understand and know the value proposition asap in an active manner. 
2023-07-11 09:52:21,"More than GPT, the credit goes to Llama Index. And also [PHONE REMOVED] who's been very helpful in learning how to learn llama index."
2023-07-11 09:52:47,Container running our chatbot code
2023-07-11 09:59:50,[PHONE REMOVED] might have missed this but which model did you train the chatbot on? Is it chatgpt + faiss
2023-07-11 10:00:40,"Since the floor is hot, just want to add that one of our branches contains direct usage of [PHONE REMOVED]library"
2023-07-11 10:01:40,I'm actually enjoying leveraging the open-source contributions from this community
2023-07-11 10:03:25,"We have some talented people here, and I welcome such collaborations with my arms wide open"
2023-07-11 10:08:39,"Faiss , qdrant ."
2023-07-11 10:08:51,Chromadb.
2023-07-11 10:09:42,"1m plus vector indexed related to prpducts for ner and recommendation related usecase , and its able to hadnle increment updates to it as well properly"
2023-07-11 10:15:30,"Essentially, yes"
2023-07-11 10:16:13,Did you need to fine tune gpt for your use case?
2023-07-11 10:19:13,Btw anyone here worked with Falcon-40B? Can you share experience? Im playing with the model and so far it has been so bad compared to GPt
2023-07-11 10:20:02,_*I tried the same. on some tasks it's good. But GPT-4 is exceptional.*_
2023-07-11 10:23:20,deployment to containers for llamaindex index is something I'm working on atm. 
2023-07-11 10:26:00,Can i DM you for learnings?
2023-07-11 10:26:39,"So far my observation is it is not consistent, and does not follow instructions. I keep telling it to not do X, it doesnt take that into accouny"
2023-07-11 10:27:00,Gpt is like a well behaved child. Falcon-30b is a teenager with behavioral issues
2023-07-11 10:27:02,sure
2023-07-11 10:28:42,"Not reliable at all, the instruct version is a little better for both 7b and 40b but context/task grounding have quite a bit of issues. Still trying to figure workarounds"
2023-07-11 10:33:36,Do lmk if you find something
2023-07-11 10:36:33,"Guys, We are looking to convert some human portrait images into creative AI filter ones. Essentially solving for uniformity, clarity and 'jazz'. Limitations are that we don't have a critical number of pictures to use popular tools. "
2023-07-11 10:37:55,Do folks need a custom-finetuned Falcon model for QA/RAG?
2023-07-11 10:39:43,"Has anyone been experimenting with a decentralised network of LLMs / models (each specialised in some area), coordinating towards a common goal"
2023-07-11 10:39:53,Almost like how brain operates
2023-07-11 10:40:18,Yes. Or you know a way to custom finetune LLM for qa/rag
2023-07-11 10:40:43,"see RETRO model, I think sales force released a new one recently"
2023-07-11 10:41:33,Will check it out.
2023-07-11 10:49:11,Yep
2023-07-11 10:49:14,"One of the VCs in the group had a similar idea, funding open source to do something of this sort. Think Brij Bhasin. Not sure who it was."
2023-07-11 10:50:20,GPT4 architecture details 
2023-07-11 10:52:25,was just about to post this !
2023-07-11 10:55:05,"Maybe, but not sure if it’s still gonna help much with the attention issues that these models have. "
2023-07-11 10:55:43,Yes Brij posted and I retweeted. Monster API
2023-07-11 10:57:39,Isn't this GPT4 MoE?
2023-07-11 11:05:28,I’ve come across this 
2023-07-11 11:08:14,"No. More decentralised, backward passes, almost a negotiation than just a central node deciding forward passes"
2023-07-11 11:10:22,https://dhruvmadeka.com/post/llms_education A detailed analysis of impact of LLMs on education and some (hand-wavy) calculations about how this impact can add 5 trillion dollars to world economy
2023-07-11 11:19:37,Any success with using confidential computing for LLMs like fine-tuned Falcon?
2023-07-11 11:25:01,"Oh, like all LLMs on same level of hierarchy working towards a common goal."
2023-07-11 11:30:19,"A model fine tuned for RAG for QA shouldn't need to hold very long conversations. It will also not be fine tuned for chat in the first place, but it will be better at sticking to context and will give good citations based on the context. "
2023-07-11 11:30:48,Folks - do you think OpenAI is likely to release a Code Interpreter API soon?
2023-07-11 11:30:56,Would be much better than tinkering with functions.
2023-07-11 11:32:45,I think you can use the functions api to execute those functions as well
2023-07-11 11:33:41,Code interpreter is good but doesn't it fall short for actual data science purposes? it's outdated and you can't install newer libs in it for it to use. 
2023-07-11 11:36:30,What do you mean?
2023-07-11 11:37:29,You can execute the functions as well using the functions api
2023-07-11 11:39:33,"True, but I'll have to define a several mathematical functions to analyse a set of data vs using a code interpreter API (when available) for that no? Or are you saying these functions are pre-defined?"
2023-07-11 11:44:55,"Provide your data to code interpreter, let it analyse it based on your refined instructions. If results are acceptable, copy the code it has generated to execute the task and convert it into an openAI function. Higher quality and allows to use latest tools for direct counterparts of the actions as well. You also won't need to come up with all the function definitions."
2023-07-11 11:46:16,That’s interesting - let me try.
2023-07-11 12:21:52,"has anyone been doing math with LLMs ? like calculating taxes, etc  ? any papers or research in this direction that you're aware of...or is this something that Code Interpreter can do"
2023-07-11 12:23:02,LLMs are bad at math. Though code interpreter might be better since it executes functions
2023-07-11 12:24:29,interesting. but GPT4 specifically makes a claim about this. it doesnt work ? https://www.youtube.com/watch?v=mmOEMfTnQGo .
2023-07-11 12:25:13,I think one can use with Wolfram plugin to get math right
2023-07-11 12:25:58,Splitwise it can do for sure.🤣 done it multiple times
2023-07-11 12:47:09,You can also have an agent that calls calculator to do math. Point is LLM math can be unreliable
2023-07-11 12:48:32,thats what i want to explore. i was seeing specific claims by openai and gpt that gpt4 is superlative in math. trying to understand examples where it breaks down.
2023-07-11 12:49:00,"Gpt maths isn’t maths, its table fuzzy lookups"
2023-07-11 12:49:38,If you go out of training distribution (eg 4 digit arithmetic) it breaks
2023-07-11 12:50:11,even this ? https://www.youtube.com/watch?v=mmOEMfTnQGo 
2023-07-11 12:50:34,im hearing anecdotes about it not working...but im not getting specific examples. can someone help so that i can try out on my own
2023-07-11 12:50:52,4 digit arithmetic will be usually wrong
2023-07-11 12:50:55,"Its better compared to turbo, but I'll still hold off on claims. They are getting better though, so we'll see"
2023-07-11 12:52:39,Minimum viable demo
2023-07-11 12:53:17,Code interpreter se cheating 😭
2023-07-11 12:55:33,Only Code Interpreter gets it right
2023-07-11 12:57:03,4+ digit numbers occur more rarely in training data. For 2 digit the combinatorics are so small you can memorize
2023-07-11 12:57:55,"interesting. so what it means is that chatgpt can do a lot of transformations into structured data (json, tables, etc) but for the actual math primitives...we should still call out."
2023-07-11 12:58:54,"Honestly , we should have an LLm which outputs this answer as Plenty"
2023-07-11 12:59:59,Yes. Think of LLMs are really really good parsers. Not compilers or reasoning engines.
2023-07-11 13:01:02,"LLMs are Dr watson, not Sherlock Holmes"
2023-07-11 13:01:49,Counter: they can be really good at all of the above.
2023-07-11 13:02:47,I was reading the DERA paper recently for a journal club
2023-07-11 13:03:15,"No, it becomes a very mimicry of Sherlock. All the sass, none of the deduction skills"
2023-07-11 13:03:40,Like a Pritam song.
2023-07-11 13:04:12,"Well no right, it can imagine it would apply the same reasoning paths as sherlock on any given problem"
2023-07-11 13:04:27,I’ve always thought why illya sutskever keeps saying “why can’t it do what humans do” and it just makes sense because behaviour cloning is what LLMs do great
2023-07-11 13:06:42,"But it does not, because Sherlock's main skill is plot armour. Not deduction or elimination. That's issue with behavioural cloning everywhere, every new copy is watered down and altered in undesirable ways."
2023-07-11 13:07:35,"I don't understand the expectations people have started having about LLMs. There's no reason why it should be good at math, so why would we expect it to be. We had the same discussion about chess a few months back. I think the ""emergent abilities"" which people have not been able to explain have sort of spoiled people with regards to expecting capabilities from LLMs"
2023-07-11 13:08:11,"Listen if an LLM can answer this question, its game over"
2023-07-11 13:08:51,LLMs need an object permanence capability lol
2023-07-11 13:09:35,Right answer?
2023-07-11 13:12:40,Somewhat right approach here:
2023-07-11 13:15:34,"It will also think that if 20 musicians play a piece in 30 mins, 40 will play the same piece in 15 mins XD"
2023-07-11 13:15:57,that is some logic there.
2023-07-11 13:17:31,"Nice okay it didn't make this error. Wanted to say ""it knows the nature of the problem"" but then the word ""know"" is weird."
2023-07-11 13:24:18,There was a paper sometime back where results showed the tokenization used by llama where every digit got a separate token results in better performance on math tasks. Potentially you could try one of the open source models using the same tokenizer and evaluate. But making the model call the tool will still be the best imo.
2023-07-11 13:29:22,https://twitter.com/Aella_Girl/status/1456044496018284548 a long twitter thread already on this
2023-07-11 13:33:44,https://arxiv.org/pdf/2305.14201.pdf
2023-07-11 13:45:14,A recent paper discussing the challenges of arithmetic with LLMs - https://arxiv.org/abs/2307.03381
2023-07-11 14:01:05,"Yeah, this is what I think of it. Amazing parser and generators, 1/2 level basic leaky-reasoning. Would love to see these being used to generate rich object/world models and then combined with reasoning systems. It will be comical as Kailash said the other day, transformers bootstrapping last gen systems. Anyone seen papers along this lines, not trivial ones but ones where there is decent impact."
2023-07-11 14:33:31,The key question though is how well/quickly the reasoning capabilities improve
2023-07-11 14:35:22,We get into philosophy here.
2023-07-11 14:41:21,has anyone used these embeddings for their RAG ? https://github.com/HKUNLP/instructor-embedding 
2023-07-11 14:58:07,Not for RAG but compared them for application in general. I think these are the same instructor embeddings that are present and on top of the MTEB leaderboard.
2023-07-11 14:58:41,"My journal club slides on DERA are here , just fyi !"
2023-07-11 14:58:48,there are subreddits also dedicated to this sir.😅
2023-07-11 15:05:02,"And a ""world"" model which rivals a 3-4 year human's :)"
2023-07-11 15:59:11,Am I tripping or is the answer 50%?
2023-07-11 16:10:36,"80%? Since premise was already that 80% on the left, but out 4, its not there in 3. So 80% on the last one? I might be tripping as well 😂"
2023-07-11 16:13:39,"My bad, I read the question wrong. I was tripping"
2023-07-11 16:16:15,don't sell yourself short. You might be onto something
2023-07-11 16:19:37,What if we add states using prompts?
2023-07-11 16:36:35,It should be 80%.
2023-07-11 17:40:29,Is anyone using transformers at their company for next user action prediction?
2023-07-11 17:50:11,This is right. This explanation reminded of kevin spacey in the movie 21
2023-07-11 17:50:28,You mean identify current and past user actions with some tag or label and use it like a token in a sentence. Then predict the next token in the sequence to represent most likely user action?
2023-07-11 17:55:05,Yes
2023-07-11 17:56:21,https://medium.com/nvidia-merlin/transformers4rec-4523cc7d8fa8
2023-07-11 17:56:39,Should have been more specific- has anyone used the above in production setting
2023-07-11 18:10:41,Yeah but we could create the user journey from 0 to last action
2023-07-11 18:16:24,EDM: Educational Data Mining Conference is happening in BLR from tomorrow. https://educationaldatamining.org/ . So is COLT (https://learningtheory.org/colt2023/)
2023-07-11 19:57:44,https://www.anthropic.com/index/claude-2
2023-07-11 20:12:32,You should read Yann Lecuns research on Joint embeddings Predictive Architecture. 
2023-07-11 20:17:40,"I am imagining almost an internet like protocol where LLMs co ordinate, it’ll be interesting to explore such a path"
2023-07-11 20:18:04,"Yes it was me. The theory I postulated was that there instead of 1 very large LLM, there could be hundreds of smaller LLMs fine tuned on decentralised GPU cloud for specific tasks. These could then be called together on a Tree of thoughts model that feeds their analysis to a World Model.  "
2023-07-11 20:18:51,Although this is how AI takeover starts :)
2023-07-11 20:19:51,Haha 😂
2023-07-11 20:20:01,"Paras, I really like your hought train."
2023-07-11 20:21:14,"Amazing, didn’t know that."
2023-07-11 20:21:39,Had seen this the TV show silicon valley to comical conclusions
2023-07-11 20:22:02,Nvidia infiniband says “Hi”
2023-07-11 20:22:37,"No, this was me building on top of your thoughts train :)"
2023-07-11 20:23:17,"So we are already working on this line of thought. Decided to work backwards from real world use cases. I was going to post this later, but why not. It would be good to have the community see - "
2023-07-11 20:23:31,This was just me thinking aloud on top of your idea Paras :)
2023-07-11 20:26:17,"Let me add my thoughts onto this. Imagine it being permision-less. Since it can operate through prompts, I imagine it to be I/O systems, just 'Natural Language I/O'."
2023-07-11 20:26:53,"Brij, what Paras is suggesting is not digital public good infrastructure like UPI ( which is great btw, we need to do more of that in both edu and health imho)"
2023-07-11 20:28:14,"Using some standard ""meta communication / orchestration"" format,"
2023-07-11 20:38:57,I'd want to almost view the comm / orchestration layer also a purpose driven LLM. For instance I've been thinking deeply about Personal AI. In that case this orchestration can also be to enrich the inter-LLM or inter-tool comms to add user's personal context.
2023-07-11 20:43:05,"I am keen to help with this, Brij."
2023-07-11 20:43:06,Yup I got that. The DPI eg is just a real world business case proposal that could use an underlying tech framework on the lines he is proposing. 
2023-07-11 20:48:53,BottomUp + TopDown has been there in NeuroScience community for a long period. This just being one of papers utilising that.
2023-07-11 20:56:50,"Very interesting, thanks for sharing. I’m also quite inspired by Daniel Kahnemans approach with System 2 thinking. "
2023-07-11 20:58:21,I think there will be two broad high level classes of applications :
2023-07-11 21:36:13,Folks who have worked with the Falcon instruct LLM - are there a set of prompt engineering best practices that work best for this model/other OSS models?
2023-07-11 21:42:55,let's check this out
2023-07-11 21:47:49,"Ah sorry, I have to go to keras_core/announcement"
2023-07-11 21:49:17,So claude has put claude 2.0 and the other models 1.3 1.2 are no longer showing in the api reference. So technically they only have 2 models
2023-07-11 21:54:07,sad 😞
2023-07-11 21:55:23,I was testing via api key and console.anthropic
2023-07-11 21:55:24,Maybe they also went ahead with a mixture of experts with these older versions
2023-07-11 21:55:42,That works.
2023-07-11 21:55:45,?
2023-07-11 21:55:51,Ok will check it out too
2023-07-11 21:56:56,"The older models exist, maybe they'll deprecate it out later. Its got the context length of the 1.3 model 100k"
2023-07-11 22:12:42,VPN?
2023-07-11 22:25:27,https://pastebin.com/npjASbNp
2023-07-11 22:26:21,It works well via API. This model is promising
2023-07-11 22:26:27,Lovely
2023-07-11 22:31:23,This seems to confirm the rumors of MoE
2023-07-11 22:39:57,"In short term reasoning at generated text seems reasonable (you can see the intercode paper, an initial attempt). We think in human language it is not necessary to bring reasoning to that level. The problem being generating reasonable text from internal representation will take 10^15 flops. That will still be slow. We already have game engines etc that does reasoning over world objects (essentially representation of world objects as data structures). These objects can reason probably in few thousand operations, many orders of magnitude faster. That is sort of Lecun idea too. Others too have thought of it. [PHONE REMOVED] will be talking at FifthElephant about his work at Unity using RL in such world's. Disclaimer: I am the curator of the conference."
2023-07-11 22:40:15,"The paper I mentioned earlier,  they also similar ideas of simpler pliable world representation, like a simple world simulator. Pulkit at MIT, had build a robot that automatically explores and learn such world representation."
2023-07-11 23:05:31,this is a nice youtube channel: https://www.youtube.com/@arizeai
2023-07-11 23:20:24,Thanks Sumod for mentioning Pulkit !
2023-07-11 23:24:56,Claude has knowledge base of early 2023
2023-07-11 23:26:11,AMA about Claude 2 🫡
2023-07-11 23:26:25,I’m a happy user
2023-07-11 23:26:36,how do I get access? :)
2023-07-11 23:27:55,😂. I applied and luckily we got access within a month. Had to give  detailed answer to a lot of questions. Ask [PHONE REMOVED] about access.
2023-07-11 23:29:04,"I just got access, they also released a public portal now for us and uk"
2023-07-11 23:36:01,Exactly. And the best part ? That meta communication and orchestration format is plain and simple English.
2023-07-11 23:54:38,https://github.com/microsoft/nni
2023-07-12 07:11:14,"Thanks for the heads up on Sachin’s talk, looking forward to it. "
2023-07-12 07:20:29,Sure
2023-07-12 07:20:31,When will this be?
2023-07-12 07:27:15,11 August - https://has.gy/1ZAa
2023-07-12 09:41:51,https://tinyurl.com/44zap9bb
2023-07-12 09:54:11,Why you using tinyurl?
2023-07-12 09:57:26,Eventually it will just tell you that it was pulling your leg and there is no code. I think this is Inflection’s way of saying “As an AI language model..”
2023-07-12 10:35:32,No need to work when you can just butter them up?
2023-07-12 10:36:39,Hi any easy ideas to make Hypothetical Document embeddings (assume: I don’t know how to use langchain but I have a few vectorDB + gpt4 tools I can use)
2023-07-12 10:56:21,system prompt: “Be a tease and don’t forget to be annoying” hahaha
2023-07-12 11:00:40,Kinda annoying eh?
2023-07-12 11:00:57,Too much fluff
2023-07-12 11:16:37,Ask it to stop replying with emojis. It will fail.
2023-07-12 11:20:55,This is rough workflow to make your own HyDE pipeline 
2023-07-12 11:21:57,Step-3 is similar to what we typically do in RAG
2023-07-12 11:22:33,ok right so there is no way for me directly try this as prompted steps?
2023-07-12 11:23:13,Can you explain what do you mean by prompted steps ?
2023-07-12 11:24:12,im just trying to see if one can just use GPT/LLMs to solve this
2023-07-12 11:25:10,"If you want to try Claude 2 , you can pay for Poe and get access to Claude2 and file uploading"
2023-07-12 11:25:37,instead use VPN
2023-07-12 11:26:01,check my snapshot
2023-07-12 11:26:57,Only the first step needs LLM
2023-07-12 11:27:42,thanks Jyotirmay! this was much more helpful than most of youtube!
2023-07-12 11:27:52,you explained it so well!
2023-07-12 11:30:23,Here’s how you can do it via Code Interpreter 
2023-07-12 12:04:49,It's on some digital weed. Those responses are out of control.
2023-07-12 12:15:03,Hyde jupyter notebook demo - https://github.com/texttron/hyde/blob/main/hyde-demo.ipynb
2023-07-12 12:15:52,"Lol insane, reminds me of Samantha from the movie here , how've they trained it ? The extent of such a human-like response"
2023-07-12 12:17:56,i have kinda production api code for this (and not notebook) in edgechains. dm me if u need it - ill get my engineer to share it.
2023-07-12 13:46:41,Twitter but for agents prompting each other?
2023-07-12 14:16:23,Probably an extension of function calling?
2023-07-12 14:24:51,"POV you walk into a grocery store filled with school kids, one lamnets, I have so much homework, other yells “CHATGPT” and continues to buy chocolate."
2023-07-12 14:44:17,"Hello everyone, "
2023-07-12 15:12:27,Using Code Interpreter to refactor functions and add type hints
2023-07-12 15:17:53,"I have pdfs and wish to extract tables and text simultaneously and the table should be exactly structured as in the pdf, what are some of the ways of doing it?"
2023-07-12 15:18:26,"pdfminer3k/pdfminer for text, camelot for tables"
2023-07-12 15:35:23,You could do it without the interpreter right? Is it the extra assurance that it works that makes it more useful over regular GPT-4?
2023-07-12 16:28:40,https://twitter.com/nirantk/status/1679077790652727296?s=46&t=-TmKToNqATUje3tCJ-w9ug
2023-07-12 17:40:07,I am currently working with Neo4J. Might possibly be able to help.
2023-07-12 18:01:27,"Any experiment on comparing QA on specific context using Salesforce/xgen 7b inst and falcon 7b or any other. I have done with bert, deberta, Salesforce xgen , xgen is giving quite better results.was thinking if anyone have tested falcon vs xgen ?"
2023-07-12 18:01:57,Llama can we use for commercial purposes? Haven't yet tried it
2023-07-12 18:02:46,cant be
2023-07-12 18:04:37,You can try via this simple colab notebook - https://colab.research.google.com/drive/146tQjjmR7ZCO314IYmlxJ5vOB6WK2czH?usp=sharing
2023-07-12 18:05:16,"I changed the notebook to only run via inference api. If you need to load it locally, minor changes can be done"
2023-07-12 19:02:34,Does anyone know how to get access gpt-4-32k	openai model?
2023-07-12 20:12:32,https://wandb.ai/capecape/LLMs/reports/How-to-Run-LLMs-Locally--Vmlldzo0Njg5NzMx
2023-07-12 20:16:41,A longish but non-technical good read by nathan lambert !
2023-07-12 21:30:49,https://x.ai/
2023-07-12 21:34:04,but i thought he wanted no one to make any movement in AI for 6 months :P
2023-07-12 22:05:28,Has gpt4 been rolled out for everyone? And how about the code interpreter?
2023-07-12 22:05:39,I meant in API
2023-07-12 22:07:25,yes
2023-07-12 22:07:36,I had to go to settings and enable it
2023-07-12 22:13:44,Anybody who ever made a payment towards openAI for api has got access to GPT4 api
2023-07-12 22:25:50,Expecting more control and transparency over llm data.
2023-07-12 22:49:12,is code interpreter been rolled out as API ?
2023-07-12 22:53:17,want to try more out like code interpreter as working on QA tasks and sometimes pdfs/url both have structured and unstructured data and that is messing up the results some time. 
2023-07-12 22:56:47,No it hasn't
2023-07-12 23:03:20,We have the same problem with docx.
2023-07-12 23:15:39,Anyone here tried danswer ?
2023-07-12 23:20:43,I saw their demo some time back. But my org needs a completely local solution right now as the NDAs aren't laid out with any of the Gen AI service providers (openAI/MS). We also have to manage access of documents across 3 levels of confidentiality. So I'm spinning up a self-hosted CPU solution using Falcon 7b GGML locally.
2023-07-12 23:24:23,My impression is :
2023-07-12 23:28:23,https://www.glean.com/blog/lessons-and-learnings-from-building-an-enterprise-ready-ai-assistant
2023-07-12 23:31:25,What a coincidence. This sounds like an open source version of Glean.
2023-07-12 23:36:39,"danswer maybe a little rough at the edges and not all the bells and whistles,"
2023-07-13 00:03:20,Good read. Comprehensive coverage of the actual challenges.
2023-07-13 01:22:57,"Tested for both xgen 7b inst and falcon 7b inst , running in CPU both ..I find xgen is Faster than  Falcon and gives better performance as well."
2023-07-13 01:46:53,Also surprisingly falcon 7b gave good results on very complex prompt but it takes quite more  time.
2023-07-13 01:47:09,"Yes, xgen is the best 7B model overall and also commercial."
2023-07-13 01:47:27,Thanks for the colab
2023-07-13 01:47:32,One
2023-07-13 01:47:36,Really helpful
2023-07-13 01:48:15,You mean Falcon
2023-07-13 01:48:17,?
2023-07-13 01:48:56,"Xgen, fixed my message in edit"
2023-07-13 01:49:31,Yea
2023-07-13 01:49:47,"As soon as xgen tokenisers find support in ggml, we will have good 4 bit version to test locally as well."
2023-07-13 01:50:30,Very new to this just trying for QA which on legal docs
2023-07-13 07:15:41,Have a question regarding embedding fine-tuning mentioned in this article. What's the task/loss you generally use? Is it next token prediction for a decoder and MLM for encoder?
2023-07-13 07:23:59,Does anyone aware of /read fine print about level of data privacy for enterprise org to use GPT on azure?
2023-07-13 07:38:11,"Something for [PHONE REMOVED] and [PHONE REMOVED] to benchmark in next run, pg_embedding. https://twitter.com/neondatabase/status/1679146260916314112"
2023-07-13 07:42:54,Hey everyone I am Akarsh Gupta currently working as an Applied Scientist at artifact.io
2023-07-13 08:09:01,https://twitter.com/dxlantxch/status/1679180540774338560?t=JFXoq16Z_EKVQdw8fTEQeg&s=08
2023-07-13 08:09:39,Vscode extension for error debugging. Checking this out. Will drop feedback
2023-07-13 08:29:58,https://twitter.com/tobi/status/1679114154756669441?s=46
2023-07-13 08:38:47,I'm not debating the larger point you're making but just want to say that the Indian approach was more a way to market a product / justify a layoff in a market which is tough for them. I wouldn't necessarily use that to compare AI approaches.
2023-07-13 08:50:02,"For fine tuning an embedding model, the most common approach is to have a two-tower architecture where you first embed the query and a doc using an encoder, calculate the cosine similarity and then backprop on the ""error"" between the calculated similarity and the true similarity. You can get a more detailed read here https://www.sbert.net/docs/training/overview.html#loss-functions"
2023-07-13 08:53:09,Thanks! 👍🏽
2023-07-13 09:09:33,Congratulations to Saurab [PHONE REMOVED] for making it to the *Vercel AI Accelerator* and a shot at $850K in credits!
2023-07-13 09:09:34,https://aasaan.app/ is the only Indian company I could find in the winners list
2023-07-13 09:09:54,Vercel AI Accelerator Participants list: https://vercel.com/blog/ai-accelerator-participants
2023-07-13 09:14:27,Any startups here interested in running a similar program for other startups in India/SEA?
2023-07-13 09:27:25,"We would be happy to give credits for VWO, in case anyone wants to do A/B testing and Optimization on their websites, models or apps."
2023-07-13 09:43:00,"google's take on an ""ai notebook"" - notebooklm"
2023-07-13 10:02:10,anyone here tried zed.dev? 
2023-07-13 10:09:13,Thanks Nirant! I applied with just an idea. Looks like there are already existing startups as a part of the group.
2023-07-13 10:21:39,"If there is interest we(Ozonetel) can share credits and help in setting up WhatsApp account and give access to embeddings APIs and some other NLP APIs which we use(sentiment analysis, gender detection etc)"
2023-07-13 10:23:02,Woke up to get a rejection email. 😭😭
2023-07-13 10:24:01,Wonders sounds like a good idea. 
2023-07-13 10:24:11,I'm not familiar with the Indian approach here. Can somebody share ?
2023-07-13 10:25:00,https://readwonders.com/
2023-07-13 10:29:35,tried the app pretty slick!
2023-07-13 10:32:28,https://docs.google.com/forms/d/e/1FAIpQLSczx0XPMTkoHmnxcY2mgz47wknLORl-MyAU78tB2fux2F-GBQ/viewform
2023-07-13 10:32:53,Exciting Session on accelerated LLM building workflows with NVIDIA Experts!
2023-07-13 11:40:13,https://www.steamship.com/
2023-07-13 11:52:23,have you used it?
2023-07-13 11:53:56,Planning on
2023-07-13 11:54:06,You can deploy tg bots easily
2023-07-13 11:54:12,Add TTS
2023-07-13 12:07:15,what is the name of Saurab's startup ?
2023-07-13 12:07:16,auditgpt
2023-07-13 12:15:40,You're gonna love the Elicit.org beta. It's radical for all the healthcare searches I do.
2023-07-13 12:17:23,I use it all the time too
2023-07-13 12:23:08,"not quite what I had in my mind, but still a lot better interface than wonders"
2023-07-13 12:32:23,Consensus wants to do that too but I didn't find all that convincing so far
2023-07-13 12:33:38,https://twitter.com/0xSamHogan/status/1679192480565309441
2023-07-13 12:46:28,https://github.com/assafelovic/gpt-researcher
2023-07-13 12:47:36,https://www.reddit.com/r/ChatGPT/comments/14xt5e3/ceo_replaced_90_of_support_staff_with_an_ai/
2023-07-13 12:47:50,And here it is :)
2023-07-13 12:59:15,This guy got roasted creatively on Twitter.
2023-07-13 13:02:57,Amazing marketing for his new product though! 
2023-07-13 13:04:33,Ceogpt
2023-07-13 13:04:58,More to come this week ;)
2023-07-13 13:13:19,Taking GenAI gold rush analogy a bit further
2023-07-13 13:13:36,their new product hallucinates a lot though
2023-07-13 13:13:58,Haha agree
2023-07-13 13:15:56,Startup founders like their fragrance Musk
2023-07-13 13:24:30,Question is does this help a B2B company as much as it would help a B2C company
2023-07-13 13:27:48,"In my experience, this erodes trust very quickly with uses"
2023-07-13 13:28:01,Don't know how much of these tactics work but for me deceptive ones like these are a red flag
2023-07-13 13:30:57,IMO It’s not deceptive - it’s being controversial to get attention and stand out especially in this crowded AI space. Musk does this quite well.
2023-07-13 13:32:48,I'd respect them much more if they were just honest about it even if it means they actually laid of their 90% of the CS because of their chatbot. But a fake stance is what I don't admire. Just a personality thing for me.
2023-07-13 13:32:50,"Ya, he definitely laid off employees, so he's not deceptive about that"
2023-07-13 13:33:17,not because of the chatbot.
2023-07-13 13:34:21,You would hope the chatbot works and does not respond
2023-07-13 13:35:12,I like the bot. At least it is not deceptive like the founder's tweet
2023-07-13 13:37:00,Just trying to ensure that when the AI overlords come they kill him last
2023-07-13 13:37:23,"had they thought of integration docs at the time of launching, the whole tone in announcing it would have been different"
2023-07-13 13:38:14,hasn't work well for me. it's been deceptive many times :P
2023-07-13 13:38:59,Deception requires both self awareness and a theory of mind. I dont think AI possesses either
2023-07-13 13:39:41,hallucination to max level --> deception
2023-07-13 13:40:32,wrong info != deception though
2023-07-13 13:40:56,AI is wrong many time and confidently wrong
2023-07-13 13:41:08,quite interesting to see Dukan and Shopify taking different approaches to intergating AI. Shopify's sidekick AI is built for the seller's side and dukan's one is becoming a sitegpt  competitor - maybe towards Intercom one day.
2023-07-13 13:42:35,Team Roko
2023-07-13 14:04:51,"Yeah, I also found it meh."
2023-07-13 14:06:38,Why are we celebrating people being let go of their jobs?
2023-07-13 14:06:54,Exists since pre LLM era.
2023-07-13 14:07:04,"It's an Indian team , yay !"
2023-07-13 14:20:50,"Oh wow, I've known Shanu, one of the founders since 2018"
2023-07-13 14:27:00,Couple of mil ARR
2023-07-13 14:27:18,"Nice, pretty good"
2023-07-13 14:30:21,I think shopify is leaving this part for their appstore
2023-07-13 14:36:34,"its interesting what dukaan has done, i was thinking of a similar use case for insurance agents. made a notebook which answers questions from a insurance policy wording  document, adding a system message and prompt which defined the role and scope as within insurance and within the context. Used Pinecone as the vectorDB. Works decently although it does hallucinate sometimes, but when it answers correctly its accurate and to the point. Im Satyajit, new to AI, building for fun!"
2023-07-13 14:37:05,Thanks for adding me here Nirant & Aakrit. Awesome to be a part of it!
2023-07-13 14:39:54,"I made some progress trying to sell a similar solution to maxlife but at that time it was only davinci-3 and costs were very high / accuracy low. They were interested but stopped replying at one point. I think if someone wants to reignite this, it might become interesting to their agents again. They have around 5k internal agenst + 20k external ones. Good opportunity"
2023-07-13 14:50:03,https://www.merse.co/
2023-07-13 14:54:55,pretty cool - bard exports code to replit now https://twitter.com/amasad/status/1679401907276636161
2023-07-13 15:10:49,"i used gpt3.5-turbo for my efforts, but now that i have access to gpt4 api i can try it with gpt4-0613 model for more consistent results. Definitely an opportunity here"
2023-07-13 15:16:29,[PHONE REMOVED] feature request
2023-07-13 15:19:04,If not I'll be building this with a custom model :P
2023-07-13 15:24:13,couldn’t get this to work. Sounds intriguing but not sure what it is.
2023-07-13 15:26:11,"It's just a skeletal structure of an MVP, their generator doesn't work."
2023-07-13 15:27:50,"Their demo video shows the example, but their generator is broken"
2023-07-13 15:28:09,"Not the best, but gives you an idea"
2023-07-13 15:29:26,"I want to connect this with my personal notes - obsidian, roam, notion and vizualize my stories. I've been journalling for 3+ years "
2023-07-13 15:32:18,What do you want out of it?
2023-07-13 15:34:00,I’m super interested in journaling and what can come out of it
2023-07-13 15:36:22,Just seeing my memories visualized - like a storybook. Instead of just pure text
2023-07-13 15:37:28,Will be very interesting to add to my journals
2023-07-13 15:39:23,"Maybe audio highlights of the ""big"" events & memories, interwoven with photo album/google photos."
2023-07-13 15:43:04,gzip is all you need - https://aclanthology.org/2023.findings-acl.426/
2023-07-13 15:47:07,That's awesome too
2023-07-13 15:48:26,Isn’t photos like this?
2023-07-13 15:50:48,Haha have been thinking about this. Its harder than it looks for a good consistent experience 😅
2023-07-13 15:50:52,"I meant, the photo app feature that you were doing xyz at abc time"
2023-07-13 15:50:59,"Also, composition of images are super critical for a good experience"
2023-07-13 15:51:15,"Right now, throwing text at any model as prompt just gives pictures"
2023-07-13 15:51:21,Having them as a story is different.
2023-07-13 15:51:41,"Thats still a creative endeavour and the way we are doing it internally is through ""storyboards"""
2023-07-13 15:51:47,Someone has to create a storyboard.
2023-07-13 15:52:17,"My sense is, yes I can get a toy out in a day, but can I get something out that most of us will pay for? Maybe not 😅"
2023-07-13 15:53:13,Even GPT4 is horrible at storyboarding.
2023-07-13 15:53:46,My benchmark is any webtoon/dashtoon comic today.
2023-07-13 15:56:17,"But pretty confident, once we get there, would share it here :D"
2023-07-13 15:57:54,"Just brainstorming, for storyboarding, wouldn't the text to video models be more reliable here?"
2023-07-13 15:59:57,Umm two issues I have with current t2v
2023-07-13 16:00:18,Storyboards are just a random representation of text. They are a artists eye to the story.
2023-07-13 16:00:42,"Maybe if we have a model trained on good storyboards, sure."
2023-07-13 16:01:04,I see. Good to know.
2023-07-13 16:01:06,There was some research by deepmind on this specifically right?
2023-07-13 16:01:34,Is it? What was it called any idea? 🤔
2023-07-13 16:01:48,"""are not"
2023-07-13 16:01:58,https://www.deepmind.com/publications/story-centaur-large-language-model-few-shot-learning-as-a-creative-writing-tool
2023-07-13 16:02:15,dramatron
2023-07-13 16:02:36,https://www.deepmind.com/open-source/dramatron
2023-07-13 16:02:59,Ah I have seen this.
2023-07-13 16:03:05,script writing is one part of the problem.
2023-07-13 16:06:12,"[PHONE REMOVED], [PHONE REMOVED] - who dyou plan to sell to? Animation studios? Marketing agencies/teams? Creators (b2c)?"
2023-07-13 16:06:52,dashtoon is b2c consumer platform. You can download the app to consumer our comics or use the creator studio to create your own.
2023-07-13 16:07:15,i was planning to make it open source just like automatic1111
2023-07-13 16:08:30,but the main bottle neck with the pipeline is creating prompts for the image generation
2023-07-13 16:10:24,I like your idea. I'll help if I can add any value.
2023-07-13 16:16:51,This looks great
2023-07-13 16:18:27,Could be a whole genre of reels/ tt content :)
2023-07-13 16:19:15,yeah plan with the open source project was to see how people actually use it then try to build a fine tuned product
2023-07-13 16:19:28,"it can used to generate reels story books for kids , presentations etc"
2023-07-13 16:19:34,What exactly is the issue you’re solving in prompts for image generation?
2023-07-13 16:19:37,This is really kickass 🔥
2023-07-13 16:22:06,Yassss !
2023-07-13 16:22:52,Amazing. Great for parents like me who lack the imagination to tell stories. I would definitely use this to tell custom stories to my son about good habits - morals - legendary goal setting etc. I previously used sabu.ai (app.sabu.ai) for some text based stories but with images this takes it to a whole new level. Would love to try out when you release it.
2023-07-13 16:25:05,This is amazing! Curious how youve handled consistent character generation... struggled with that when i was trying something similar last month...
2023-07-13 16:25:12,its asking gpt to generate best prompts to feed to SD
2023-07-13 16:26:28,It feels like this will truly be solved with multimodal AI that can be fine tuned for this or is already fine tuned for this task. But until then we can play with what we have.
2023-07-13 16:26:55,agreed
2023-07-13 16:27:53,"My son Atharv fascinated by 2 things, My pet german shephard Atom and the ceiling fan in my bedroom (for some reason, I guess all toddlers are). https://youtu.be/qDYux7mTYHU"
2023-07-13 16:30:31,Very interesting!
2023-07-13 16:32:34,"ai for ❤️, ftw !"
2023-07-13 16:34:42,how did u make this ? im trying to make something similar for a kid
2023-07-13 16:36:15,Factum Amore - Made (by) love
2023-07-13 16:44:00,This is super cool [PHONE REMOVED]
2023-07-13 16:52:01,+1
2023-07-13 16:58:54,"The process was simple, but effort intensive. "
2023-07-13 17:18:28,"""Didn't get adoption from son"" :)"
2023-07-13 17:29:09,🤣 Oh yes indeed. NPS was all time high
2023-07-13 17:32:44,"Stealing it for my son, will need to add lots of cars & balls."
2023-07-13 17:33:35,On a related note - saw this tweet by someone who helped Varun Mayya! Mindblowing - https://twitter.com/sagartheamruth/status/1664671793414537228
2023-07-13 17:45:16,I’m building something similar with Rafta AI
2023-07-13 18:02:11,"The celebration is for progress and not layoff. I don't find anything wrong with that either tho. You are cutting costs and saving a huge margin by improving a process that doesn't need to be done the hard way. So many people got laid off from Twitter and honestly there wasn't much difference. If their absence isn't felt, the presence is just a liability. There was once a job for people to set up bowling pins. Now we all enjoy the activity of bowling much better because the pins are reset immediately and with same accurate positioning. No one misses that job. People who got laid of from that job found something else to do because it was a low skill task. Didn't require lot of prerequisites. So in a way, jobs that are not worth doing by humans should not be done my them. They should invest their effort elsewhere. Adoption of this policy should be celebrated and encouraged. We're in the 21st century with lot of free resources. Everyone should plan for 5 years in advance. You can't expect thr entire world and all subsequent progress to take a back seat cause some people won't get off their seats and adapt to find something better. That's my belief"
2023-07-13 18:06:03,"We must not celebrate it for the same reason that a breakup hurts someone. That someone addicted to smoking still feels ashamed to smoke in front of their parents. When someone loses a job, it's a sucky thing for them and their family. Logic/rationality and emotion can co-exist."
2023-07-13 18:06:49,Firing the people you hired? Tough - Yes
2023-07-13 18:07:36,"Try to step out of the ""tech bubble"" most of us live in."
2023-07-13 18:08:23,"That's why I started my sentence with the clarification - the celebration is for progress, not layoff. Layoff was an inevitable side effect. I'm just saying it's not really a bad thing."
2023-07-13 18:09:14,Firing and being replaced by AI that too in s celebratory form is more hurtful for the employee.
2023-07-13 18:10:09,And I think the original intention of the comment was also about perspective. Good for the company yes. Inevitable sure. But surely it sucks for the person on the receiving end. As long as we can empathise.
2023-07-13 18:10:18,"So what do you think we should do? Wait 30 years to get better adoption of tech, risk it becoming unused? Risk the field becoming dry due to no application? Lose all benefits and new resources the future generations will get to study and make a better life? You can't hope for everyone to win. In life everything is ranked or sorted. Holding back the top so that the bottom won't get affected is a stupid strategy. Instead there should be a better solution where the progress can be made and alternatives can be provided for those affected."
2023-07-13 18:11:31,it is a bad thing and it will get worse. to cut short this debate so that it does not get very angry...everyone needs to spend their energy in supporting UBI - universal basic income.
2023-07-13 18:11:55,"Why do PR. What you said made sense, but why do PR"
2023-07-13 18:12:12,Pr?
2023-07-13 18:12:56,"The problem with ai driven societal change is that it's happening too rapidly, especially for older workers."
2023-07-13 18:15:38,I think this discussion is getting off topic here. Let's discuss in the philosophy group
2023-07-13 18:16:09,"Culture is amorphous. It's a filtered amalgamation. Survivor bias. Whatever culture we have is a Mashup of whatever survived. The cultures that made the wrong choices were erased through their own choices and inadaptibility, no? What exactly is even culture? The culture we had before tv and after tv is different. I don't think you'd complain about that. It changed even more after internet and social media. Cultures. Professions. Style of working, etc. All keep morphing with time. When the rules change, those who understand the game can still play to win. Those who won't will be constrained by new rules. That's just natural. Nothing we need to intervene in with hypothetic hyperspecific examples"
2023-07-13 18:17:27,"Ah, that's probably that guy's pr stunt for clout, publicity or future plans for his company. His prerogative. Good or bad choice, will be based on reception and future scope"
2023-07-13 18:17:46,Sure
2023-07-13 18:53:36,https://bit.ly/3rvjYt6
2023-07-13 18:58:15,Very interesting. I love how we are increasingly finding additional ways of incorporating user input into such models
2023-07-13 19:07:10,I've found this to be extremely useful while building AI systems. I've noticed that clients are usually willing to provide feedback in the loop to make the product perform better on their specific problem. 
2023-07-13 19:15:30,https://www.reddit.com/r/StableDiffusion/comments/12pcbne/i_mad_a_python_script_the_lets_you_scribble_with/
2023-07-13 19:16:08,This has been around for a while now directly at stability ai
2023-07-13 19:18:35,"Very similar to what Nvidia Canvas did around the beginning of last year, there was a lot of hype around it SD is getting there too"
2023-07-13 19:37:46,It's official for me. When composing a chatgpt prompt the service instruction doesn't carry the same weight as just putting it all in user section.
2023-07-13 19:37:47,Api.
2023-07-13 19:39:53,Can you please elaborate?
2023-07-13 19:47:14,"[{""role"":""system"",""content"":prefix},"
2023-07-13 20:29:31,They have mentioned this somewhere. Currently system doesn’t carry that much weight but eventually will
2023-07-13 20:30:51,Its mentioned in different places that system doesn't have much weight. I'm just making it official that don't use system. Its more like your tokens getting used up without a lot of returns
2023-07-13 20:37:32,Prompt Engineering is all about writing your prompts for production every 3 months when OpenAI changes the underlying model 😭
2023-07-13 20:38:35,"yeah. and now they're deprecating the completion models, the only stable models they had"
2023-07-13 20:44:07,"RIP text-davinci-003 — the model we need, but don't deserve"
2023-07-13 20:45:31,Prompt Reliability Engineers
2023-07-13 20:48:33,https://supabase.com/blog/pgvector-performance
2023-07-13 20:48:43,[PHONE REMOVED] - your thoughts please?
2023-07-13 21:01:12,"hey guys, need some suggestion."
2023-07-13 21:08:12,"64-core, 256G for 10% less accuracy than a very handicapped Qdrant running on 8-core, 32G machine is not great imho"
2023-07-13 21:11:43,you can use same index but different namespaces like Pinecone has. I believe weaviate and others should also have similar features
2023-07-13 21:16:11,One can now interact with bard in hindi ! yay !
2023-07-13 21:16:53,Google copying us
2023-07-13 21:17:25,But how is your quality. LLM hindi is meh
2023-07-13 21:17:48,you didnt invent hindi interaction :)
2023-07-13 21:18:18,Multilingual voice to voice to LLM interaction
2023-07-13 21:20:23,"they do have class names, let me check if there's any limitation on that"
2023-07-13 21:21:18,https://twitter.com/LukeGessler/status/1679211291292889100?t=gik9viB3AlGRc3cXOltJHw&s=08
2023-07-13 21:23:36,I have a really hard time believing that GPT-4 wouldn’t be better at grouping sentences than kNN on gzip lib
2023-07-13 23:40:33,https://twitter.com/npew/status/1679538687854661637?s=20
2023-07-13 23:45:55,He is equating a newer GPT4 with more capabilities like function calling and plugin enabling with being smarter.
2023-07-13 23:46:30,But these reports are unofficial so all we have is anecdotal evidence that it is getting dumber 🤷‍♂
2023-07-13 23:48:51,Imagine gpt4 being called dumb.
2023-07-13 23:50:27,"-er, wrt itself"
2023-07-13 23:51:49,The terminology is just funny
2023-07-13 23:52:25,"Maybe to be fair to the critics , the q. is :"
2023-07-13 23:56:02,wrong grp sorry
2023-07-14 01:12:02,Anyone here use gpt-engineer? How good is gpt-engineer with gpt 4 api key? Are there any other such tools that take in user input after every step? Where do they get stuck?
2023-07-14 01:31:20,"One of pg's longer essays but a beautiful, insightful read like all pg essays !"
2023-07-14 01:34:40,"For a second I was like, when did postgres start writing long essays."
2023-07-14 03:06:30,"So, he's admitting, indirectly, that GPT-4 isn't anywhere close to AGI or superintelligence, no?"
2023-07-14 03:08:08,"I mean, you can always repeat the experiments from their ""technical report"". If the newer model scored lower, then it's demonstrably dumber?"
2023-07-14 03:10:21,https://twitter.com/ArchikiPrasad/status/1678223412668276737?s=20
2023-07-14 03:13:13,"*Idea* : we should do like a ACL2023 review on zoom/meet, a week or two from now."
2023-07-14 03:20:59,Im attending the Pinecone conference today in SF .
2023-07-14 05:58:50,This one is at Stripe AI Day - https://lu.ma/k1dh24e1
2023-07-14 06:23:21,"Wait, Pinecone is entering Model Serving?"
2023-07-14 06:23:37,Yes they are
2023-07-14 06:27:15,spaCy threw their hat in the ring yesterday with Curated Transformers:
2023-07-14 06:27:30,Looks like we're going to see a CPU vs Memory tussle again in model serving
2023-07-14 07:08:42,Sir are you going to be at the MosaicML event after this?
2023-07-14 07:08:47,No this was from the databricks presentation!
2023-07-14 07:09:17,The recording for the other panel is up in case anyone’s interested — https://youtu.be/TXMUXeml9JY
2023-07-14 07:14:22,No. They rejected me from that one 🤣
2023-07-14 07:15:20,[PHONE REMOVED] ‘s holding the fort for the BLR valley 😎
2023-07-14 07:15:22,Yeah the Databricks guy was talking about Databricks providing optimized open source models hosted so that fine tuning them is very cheap.. so he was hinting at model serving !
2023-07-14 07:16:21,Yeah databricks is doing that!
2023-07-14 07:49:10,"Yes, databricks via mlflow has always had model serving. In the last update, they now have llm specific logging and serving."
2023-07-14 10:30:52,https://youtu.be/smHw9kEwcgM
2023-07-14 10:38:15,"FWIW, the 29th July meetup will be the last mixer/meetup for 2023. Will experiment with different format from August."
2023-07-14 10:41:08,"Umm, why is this surprising?"
2023-07-14 11:05:42,"It is not, as confirmed by [PHONE REMOVED]"
2023-07-14 11:45:41,Anyone looked at Databricks AI Gateway?
2023-07-14 11:48:24,Does someone have an experience of building a chatgpt plugin? Trying to build one but the testing and deployment part is getting real confusing.
2023-07-14 13:26:04,https://twitter.com/alexrkonrad/status/1679656408839495681?t=Zs-W9Mz0at1Xn0k5sCZ2-Q&s=08
2023-07-14 13:26:58,"Inflation dropping back down, 100x revenue multiples, 100M rounds pre product"
2023-07-14 13:27:28,Fun times
2023-07-14 13:28:28,Huggingface pre product?
2023-07-14 13:29:47,"Oh, not them. The broader theme"
2023-07-14 13:30:02,They were also not the cause of inflation dropping
2023-07-14 13:33:31,Will have to see. Inflation is dropping down but there are other factors still at play. That is off topic
2023-07-14 13:34:29,4B valuation at 30M revenue
2023-07-14 13:36:43,what is this about?
2023-07-14 13:38:33,Yes.
2023-07-14 15:52:02,[PHONE REMOVED] would you be able to help? If you know the deets from building the Wolfram plugin
2023-07-14 16:29:04,Is there a link to register?
2023-07-14 16:29:38,"""without enough fresh real data in"
2023-07-14 16:30:25,https://hasgeek.com/generativeAI/2023-07/
2023-07-14 16:39:07,https://hasgeek.com/generativeAI/2023-07/
2023-07-14 18:02:58,https://twitter.com/michael_g_u/status/1679506845721919490?s=20
2023-07-14 18:55:46,Code interpreter output can't be trusted blindly
2023-07-14 19:02:53,It also feels like it's been nerfed. Atleast I have to convince it a lot to actually output useful stuff or even use that interpreter
2023-07-14 19:18:44,"Hey guys, we’re struggling to deploy end points for wizard-vicuna-8k. "
2023-07-14 19:19:09,Have done this. Happy to help.
2023-07-14 19:19:28,Reaching on DM
2023-07-14 19:21:37,everyone gets overhyped quickly on twitter
2023-07-14 21:16:32,"AWS Lambda doesn't have GPUs, right?"
2023-07-14 21:18:22,Yeah .. but the question is more to understand whether serverless GPUs are preferred by the community over on-demand GPUs - the reality today is your really have to get reserved GPUs - otherwise you dont get them 🙂
2023-07-14 21:19:29,Cost of server/less is usually exorbitant if there is upside protection
2023-07-14 21:19:35,That would be great
2023-07-14 21:20:35,Reserved > On demand > spot > serverless
2023-07-14 21:26:48,"Did anyone try Monster API for fine tuning? If yes, can you share details?"
2023-07-14 21:41:43,And why?
2023-07-14 21:42:41,[PHONE REMOVED] from monsterapi is here
2023-07-14 21:59:43,"It depends on the ml workload type: train/inference/monitoring/fine-tuning. If inference, the traffic pattern+model size should dictate the choice."
2023-07-14 22:09:45,Completely off topic to the ongoing task (apologies)
2023-07-14 23:02:48,Just something about being able to exec into a machine 🙈
2023-07-14 23:07:56,Same with Reserved Host > Reserved VM > Reserved Container
2023-07-14 23:44:23,2. Is this real? Containers have any significant overhead?
2023-07-14 23:47:48,"If the base image is big, then yes"
2023-07-14 23:52:56,"Oh you mean startup time, solvable by doing volume mounts and image streaming?"
2023-07-15 00:00:25,Who else is in the Bay Area from this group?
2023-07-15 00:05:14,We are using this one as reference. https://github.com/caesarHQ/textSQL
2023-07-15 00:35:22,"After all the twitter demos, not using defog? 👀😅"
2023-07-15 00:39:44,any insights on number of few shot examples to use for prompt enrichment?
2023-07-15 00:45:13,"I’m not sure if I am answering your question correctly, but coverage is the challenge, therefore instead of making a generic platform, we are focused on specific set of use case for farmers, and customers who wants to show their data. Which is easy to solve."
2023-07-15 00:48:10,we tried something similar. Worsened the result for complex queries. Mostly bcz of overfitting the few shot examples (=2)
2023-07-15 00:48:47,"[PHONE REMOVED] Not competing with you or defog, but building everything inhouse as I'm very cheap 😁"
2023-07-15 00:50:08,"haha need of the hour. When underlying tech itself is changing, can't afford to have one more layer on top."
2023-07-15 00:53:26,"Haha 🙈 , I didn't refer to any diagram to figure out what is called what and jumped into code directly. Let me check it out and get back."
2023-07-15 00:56:13,I'm always worried about this but never taking the necessary steps to check. 😞 OpenAI APIs doesn't even have CORS/domain or any other control on api usage either
2023-07-15 01:02:30,"Hey folks, i want to connect with those who are fine tuning LLMs. I wanted to do user interviews on how they are doing it. I am building a platform for making the process easier."
2023-07-15 01:26:56,Yes 🙌🏻
2023-07-15 01:39:07,What’s the alternative?
2023-07-15 01:43:53,If you load it from a config file is it part of the environment variables
2023-07-15 01:46:22,But that can still send the data if they want to get the keys
2023-07-15 01:55:58,"If they're doing telemetry for debug for the variables, it'll include the keys whether we load them from env, take it via a password mechanism or load it from a ""config secrets"""
2023-07-15 01:57:22,You can minimize not remove though
2023-07-15 01:57:58,"I guess this is why the bigger the organization, a more comprehensive security check is done on libs used"
2023-07-15 01:59:09,Bingo
2023-07-15 01:59:43,But I guess the best solution is to minimize the obvious lookups
2023-07-15 02:05:07,"Anything third party that directly asks for api key is a huge risk. Otherwise separation of environments, loading secrets via secrets management systems, least privilege by using classes or using wrapper around third party library to ensure no sensitive data is being sent should be practiced by default."
2023-07-15 02:07:21,"Other than this, distributing malware or spyware has also never been easier than it is with people trying to run models locally on their phones and PCs. If it's not in safetensors format, don't touch it."
2023-07-15 02:08:31,That's been the case for a number of years. This is more common in js packages
2023-07-15 02:08:40,"But why would OpenAI have CORS. Those API keys aren’t meant to be directly used in client side code, no?"
2023-07-15 02:09:48,There is better way to do it by issuing a session tokens
2023-07-15 02:10:12,"For latency issues, of course"
2023-07-15 02:12:13,Will this a problem if I use configparser?
2023-07-15 09:06:32,https://twitter.com/LukeGessler/status/1679211291292889100?t=XJRTK18U36Xu4AL0ixZv_Q&s=08
2023-07-15 09:15:46,Meta is launching commercial version of llama this Monday
2023-07-15 09:44:51,https://www.reddit.com/r/LocalLLaMA/comments/14ys9ol/what_are_you_using_local_llamas_for/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
2023-07-15 09:47:54,How many months/weeks/days away are we from building this?
2023-07-15 09:48:51,"To be explicit, this is a human video, but can be automated for sure?"
2023-07-15 09:51:11,Not far. 
2023-07-15 09:53:46,"oh wait nvm, the video in question seems to have kanji characters. "
2023-07-15 10:00:29,"Seems to be a global issue ,everyone is reporting this"
2023-07-15 10:00:30,"This got disabled for many people, if not everyone"
2023-07-15 10:10:49,Could be off topic but I am struggling to understand what’s happening there.
2023-07-15 10:14:59,live tipping features were enabled in platforms like tiktok.
2023-07-15 10:29:02,Which AI model is this [PHONE REMOVED]? 😂
2023-07-15 10:30:24,Hahaha  🤣
2023-07-15 10:30:39,Pawdel*
2023-07-15 10:32:30,"Canine can be a good transition to model name (llama2) the way we are going with Animal names. Last one was Orca. Also suites the premise, human’s best friend."
2023-07-15 10:33:35,What's this? Sorry too vanilla to appreciate it
2023-07-15 10:36:27,"😂 I'll stop here, we are going to open a can of worms, and [PHONE REMOVED] being a cat person, will definitely kick us out."
2023-07-15 10:40:41,Sorry guys! 🤣
2023-07-15 10:41:13,My existing sessions with code interpreter are working but I can't get a new session with it
2023-07-15 10:44:06,Cannot upload new files and already timed out for previous uploaded files.
2023-07-15 10:45:28,It will minimize it but it will be stored. I figured out a really good solution for this. Will share
2023-07-15 11:02:52,Is providing key file path a safe alternative then?
2023-07-15 11:07:12,No. No. No.
2023-07-15 11:07:58,You can do both. But having the key file’s path as an env var 😂
2023-07-15 11:08:50,"If you're really worried about telemetry, Chroma sends every request to their own Posthog. Pinecone is literally every request. "
2023-07-15 11:09:32,"For this, I’d say use less libraries you don’t trust"
2023-07-15 11:09:45,Telemetry is very useful for commercial OSS to see what is useful and where and to whom
2023-07-15 11:11:57,"If you do this, please let me know — I'd love to use your keys. And why stop at OpenAI, just give me your .ssh"
2023-07-15 11:14:37,You already have my keys nirant
2023-07-15 11:18:52,"They started by nerfing it, now it's gone"
2023-07-15 11:18:53,🙂🙂
2023-07-15 11:21:30,"Perhaps some server provisioning issue, maybe they're testing GPT4 VIsion? "
2023-07-15 11:21:56,Bard has already come out with multimodal
2023-07-15 11:22:32,"Images only, but it's pretty accurate"
2023-07-15 11:26:19,What use cases are people playing with Bard multimodal?
2023-07-15 11:46:32,There’s a safe way to do this - store your keys in a k8s secret and mount them as a file in a volume. Then store the path of that file as an env var or even hardcode it.
2023-07-15 11:55:52,If the third party module explicitly doesn't ask for api then there are many ways to do it.
2023-07-15 12:39:51,"wait, when was it gone?"
2023-07-15 12:53:40,There was a temporary unavailability for some folks since last night
2023-07-15 12:59:11,Hello folks! Anyone tried claude 2? 
2023-07-15 13:05:58,Could being more up to date be helping Claude here?
2023-07-15 13:12:21,"this sounds like a time series, xgboost type problem as well. But in any case, it is interesting to see claude do better here. I can only assume greater context length and more training data beyond Oct 2021 are 2 major differences here."
2023-07-15 13:21:01,https://twitter.com/swyx/status/1677589535587467264?t=dkrXik-6FZP189mfb_55nA&s=08
2023-07-15 13:25:22,the requirements.txt is real
2023-07-15 13:25:47,i was able to get the same and got to know it contains way more packages it claims to be equipped as interpreter
2023-07-15 13:26:17,the problem is that it's cut off stops it from knowing what it can put to use and for what
2023-07-15 13:34:27,Anyone used Haystack (deepest) ? Given the langchain discussions recently I’m interested in knowing if it offers any advantages.
2023-07-15 13:37:12,"OpenAI had mailed last night, that it was down for a scheduled maintenance."
2023-07-15 13:37:17,I have a naive question regarding ChatGPT and commercial LLMs in general . Please indulge me :)
2023-07-15 13:37:44,haystack and spacy are pre-chatgpt libraries for quick production code where you are mostly interested in putting to use a best-known-method rather than research or tweak your own model.
2023-07-15 13:40:16,Thanks Abhishek. Are these frameworks being developed for interfacing with modern LLM APIs? SpaCy has been used for a while in data science and NLP apps and projects but I'm not sure they have evolved to become alternatives to Langchain or Llama Index
2023-07-15 13:42:30,"There are no custom models per user but there is supposedly a user profile. Most people who have worked with recommendation systems would know profiling and keeping track of user's likes, dislikes, most watched (visited), recently watched (visited). Based on this, each platform inevitably works towards maximising user engagement in 2 ways - 1. increase time spent on their app/website, 2. increase follow through/click through/engage rate for the shown content or ads."
2023-07-15 13:44:50,both haystack and spacy are adapting fast for llms. they will offer most convenient ways to put these things in production the way they have always done. But they make everything in their own libs with an opinionated style.
2023-07-15 14:45:15,https://blog.replit.com/ai-on-replit
2023-07-15 14:45:16,https://twitter.com/ycombinator/status/1680011879157207041
2023-07-15 15:34:04,https://twitter.com/natanielruizg/status/1679893292618752000?s=46
2023-07-15 15:39:39,Has anyone tried it? Quality trade-off from DB?
2023-07-15 16:25:20,https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_are-vector-databases-here-to-stay-yes-activity-7085908435686285312-QVfB?utm_source=share&utm_medium=member_ios
2023-07-15 16:55:06,"Friends, I'm looking for a zero shot or k-shot image classifier. Something which can do something like this:"
2023-07-15 16:56:08,"Paid APIs work, but something which has a REST or Python client is preferred"
2023-07-15 16:57:01,something with zero shot clip classifier won't work here?
2023-07-15 17:03:04,I've never tried it. Do you expect it to work?
2023-07-15 17:07:10,https://twitter.com/NielsRogge/status/1679848775043407872
2023-07-15 17:09:30,Yes. Tried sometime back it worked decently.
2023-07-15 17:09:49,Though i don't have metrics currently for the experimentation.
2023-07-15 17:18:06,Search through past conversations of this chat summaries: https://nirantk.com (and then go to search) 
2023-07-15 17:21:01,This is nice
2023-07-15 17:26:02,Pretty cool!
2023-07-15 17:29:00,[PHONE REMOVED] why are you so brilliant!
2023-07-15 17:30:41,"This is the fastest implementation possible, not even very clever 🙈"
2023-07-15 17:31:55,"And I didn't want to host a server, so this works entirely in browser — your searches are your business"
2023-07-15 17:33:09,Damn ⚡
2023-07-15 17:33:18,looks great! what’re you using for this?
2023-07-15 17:34:05,"hugo (golang), all code is here: https://github.com/nirantk/nirantk.github.io/"
2023-07-15 17:34:14,This is running on Github Pages
2023-07-15 17:34:27,sweet
2023-07-15 17:35:25,Did you try checking blip2 from sales force?
2023-07-15 17:35:30,https://huggingface.co/spaces/Salesforce/BLIP2
2023-07-15 17:37:04,"Will do, thanks for the tip!"
2023-07-15 17:39:36,Yeah this is something I’ve seen close up building apps with long prompts. They’re not effective when you pass large prompts to them. I wonder if context length being large is automatically a good thing. Since we are computing attention it is likely that the attention vector will become sparser for large contexts. Is this the correct intuition? Any other experiences?
2023-07-15 18:02:23,We have MitraAI image APIs for this. How many classes do you think you'll work with approx?
2023-07-15 18:24:50,"Hey. I have deployed endpoints for blip right now with serverless cont, if you wish to use that. Works quite well and with not so high delay. However I would suggest to use pix2struct in this case as you dealing with screenshots. Can help you with docker of the same too. Would that be helpful? Pix2struct is trained to understand textual content to some degrees."
2023-07-15 18:27:07,"Vanilla attention has O(N^2*d) computational complexity. N - sequence length, d - hidden dimensions, thus we see the models suffering from forgetfulness or ignoring parts of the context with really long sequences."
2023-07-15 18:27:07,"However, I'm optimistic that this condition is temporary. Primarily because recent paper Longnet showed a method for Dilated attention with O(N*d) complexity. They were able to project a really really long context length (theoretical support for 1B tokens)"
2023-07-15 18:27:08,Another key thing is no famous models currently have been fully pretrained for really long context lengths and perform completion on text that's <2k context.
2023-07-15 18:27:10,https://twitter.com/llama_index/status/1679522417558040577?t=1TJ51nRpQzf9RYbuuMF66Q&s=08
2023-07-15 18:29:37,"I'm helping a friend [PHONE REMOVED] for a hackathon, so will see if CLIP/BLIP2 do the job ""good enough"" — if not, will ping you for Pix2Struct Docker image. Thanks for the tip!"
2023-07-15 18:49:02,"For antigpt, i ended up using clip interrogator + gpt - because clip interrogator usually output more detailed descriptions of the image, and gpt is good at parsing those"
2023-07-15 18:49:49,For screenshots there is a specific model from msft I think
2023-07-15 18:58:43,Take CLIP embedding and do KNN (take too 5 matches and then majority of the 5 is what you can classofy)
2023-07-15 19:36:06,Wild !
2023-07-15 19:59:54,"This is an interesting counter AI perspective - ""AI cannot get hungover""🍻"
2023-07-15 20:23:40,"If it has read enough stories and experiences of the above, it could mimic it very well."
2023-07-15 20:27:50,"At the risk of taking it into philosophy territory, this is assuming 'we' have a unique conception of hangover which isn't just our advanced multimodal LLMs coming up an output to a defined alcohol input."
2023-07-15 20:29:12,"Perhaps the perspective which George Hotz talked about is interesting. The current AI systems  lack robustness in a very specific way. For one, they cannot self repair nor can they reproduce. A biological life form like a bird for example, is a way more robust system. It can survive in a jungle, an AI system right now cannot. And this is inherently a very difficult problem to solve for, especially reproduction"
2023-07-15 20:32:30,https://arxiv.org/abs/2307.01189
2023-07-15 20:32:44,Pretty incredible sounding work
2023-07-15 21:32:30,https://www.nytimes.com/2023/07/11/technology/anthropic-ai-claude-chatbot.html
2023-07-15 21:32:51,An inside look at Anthropic and Claude
2023-07-15 22:13:45,I did not know SBF invested arounf 500 million into Anthropic
2023-07-15 22:48:47,"Has anyone tried langchain, Did you find it useful?"
2023-07-15 23:30:20,Using in production grade apps.
2023-07-15 23:30:33,Still learning how to use it well
2023-07-15 23:45:19,What advantages did you feel compared to using open ai sdk directly?
2023-07-15 23:47:39,The langchain thought process helps make sense of how the chain or agent works. Like the fact that there are different choices of agents. With frameworks like kor and langchain it is possible to build interesting new apps for extracting structured data from LLM responses
2023-07-15 23:48:31,Also like how the project is constantly trying to add me features and support for different backend models
2023-07-15 23:49:17,i dont entirely agree with the way that langchain abstracts prompts and chains and tools.
2023-07-15 23:49:25,good for desktop experimentation though
2023-07-15 23:49:54,Is it normal to observe this behaviour in code interpreter? has anyone else observed this?
2023-07-15 23:50:13,What are you building?
2023-07-15 23:50:55,will dm separately. we are all very scared of nirant :D
2023-07-15 23:54:14,"Had a question about langchain tagging and extraction chain if anyones ever used that. Is there anyway to make sure that the chain extracts all the data required? It sometimes misses stuff and im wondering other than changing the prompt slightly, what else can i try?"
2023-07-16 00:05:31,"Interesting, did you know any app source code which might be hard to build directly without using langchain. I will love to read it."
2023-07-16 00:39:27,"I tried langchain to build fairly complex chains, thrice. I found using openAI sdk directly to be preferable. Langchain doesn't solve output parsing, doesn't do text splitting properly, the syntax isn't trivial either. And after openai released functions, the agents part of langchain is now redundant."
2023-07-16 00:41:10,The only good thing that came out of langchain was it introducing me to things like ReAct
2023-07-16 00:42:50,Langchain also consumes way too many tokens for so many hidden prompts in its layers
2023-07-16 00:53:39,"True, much better to build from scratch"
2023-07-16 00:53:56,Their prompts aren't that good either.
2023-07-16 01:40:43,I think you can talk about what you're building 😌. As long as you're not marketing for marketings sake. Here it seems relevant
2023-07-16 03:36:53,"i've built an oss library around llm independant api calling and cot reasoning i've mostly been focused on tuning it for hosted llms but now i'm exploring os llms any thoughts on os llms that work with json, functions, cot i'm open to tuning"
2023-07-16 03:42:20,currently experimenting with llama 65b and mpt variants
2023-07-16 06:29:11,So who is the right audience for langchain? When do some prompts become boilerplate that we don't have to think about handcrafting them with precision?
2023-07-16 07:16:15,llama-index better that way?
2023-07-16 08:27:36,This I have observed too
2023-07-16 11:41:56,"""Insiders have revealed that studios have already utilized technology to replace background actors with digital avatars in upcoming movies, such as “Captain America: Brave New World” and Netflix’s “The Residence.”"
2023-07-16 12:57:11,There’s a workers strike by Hollywood writers and actors going on. Perhaps we can discuss this or something related in the policy group
2023-07-16 13:14:07,Policy and philosophy group is the better venue
2023-07-16 13:15:42,https://twitter.com/smdiehl/status/1679402478306041856?s=20
2023-07-16 13:21:24,+ who has the bandwidth to debug a probabilistic event/ outcome.
2023-07-16 13:24:25,Wud also love to know groups view on Quality assurance in genAI apps vs non genAI apps.  Are there any fundamental behavioral changes you are able to observe just w.r.t QA and testing.
2023-07-16 13:25:24,What is with the absolute scarcity of A100 80G GPUs? can't get one anywhere. I don't want to learn distributed training for simple experiments 😢
2023-07-16 13:31:00,I agree that prompts and chain are deeply coupled in many occasions but do you think this modular separation is a bad idea? Any insights into performance related difference you may have observed?
2023-07-16 14:14:34,"It's not about performance, it's about iteration and testability."
2023-07-16 14:15:49,None of the prompt testing infra will integrate will with langchain since it is layered in deep hierarchy of classes 
2023-07-16 15:40:31,Interesting approach to attack the problem !
2023-07-16 15:40:56,It’s like contacting two blue pictures vs a blue and red picture
2023-07-16 15:42:49,Thanks for the pointer to
2023-07-16 15:44:04,Can you elaborate?
2023-07-16 15:54:27,"s.replace('contacting', 'compressing')"
2023-07-16 16:00:41,think of a config file - a YAML file or a .settings file. why do they exist ? they exist cos 
2023-07-16 16:01:38,https://news.ycombinator.com/item?id=32104446
2023-07-16 16:02:25,P.S. i dont use cue. i use jsonnet in edgechains which is far more popular today in the config management world. but same funda.
2023-07-16 16:11:56,"*I will add the between the lines print here* - *gzip is all you need but specifically for ""out-of-domain sentence classification""*. "
2023-07-16 16:47:46,Concatenating
2023-07-16 16:49:45,Ok.
2023-07-16 21:49:52,"Would anyone have the pdf for semi analysis’s GPT-4 coverage? (I do not support plagiarism, just help me this one time 😢)"
2023-07-16 22:29:47,The article is behind a strong paywall that can't be breached via common tools.
2023-07-16 22:31:16,I spent an hour yesterday trying to find it. But you can’t. 
2023-07-16 22:32:01,I also want to have your kind of subscribers or patrons.
2023-07-16 22:33:00,Haha. The article was that good 
2023-07-16 22:33:38,You can read it here.
2023-07-16 22:45:16,Great! Thanks 🙏
2023-07-16 22:45:46,The image I used was something I drew on a paper and asked
2023-07-16 22:46:42,This was the image 😅😂
2023-07-17 00:00:46,"Huffman encoding I understand is the underlying mechanism. Clearly well tested methods from theory do better than learning from data. When models or algorithms are known, best to use them in place of stat learning or ML."
2023-07-17 00:10:29,"You get a free embedding, you get a free embedding and all of you get free embeddings ! ( Ala Oprah style :D)"
2023-07-17 00:22:47,"On algorithmic methods that are not machine learning that could be used to solve problems (like the gzip example Ashish posted) https://twitter.com/Jousefm2/status/1680120559206555649?s=20 - this is a take on maze solving, which may be represented as search or agent based RL problems."
2023-07-17 00:24:23,Using ML everywhere is becoming a substitute for thinking about problem formulation - perhaps that would still work for most teams/people who are not looking for efficient or elegant solutions - after all brute force approaches are still common enough
2023-07-17 00:27:47,I would appreciate it slightly better if they made it configurable instead of hard coding a 384 dim ggml miniLM L6 v2 in the class.
2023-07-17 00:48:32,my kid uses gpt4all as an ai pet to chat with we gave it a personality though the system prompt we're also trying to connect it to other stuff with plugins
2023-07-17 03:14:42,my kid is into one piece and other anime the model we use is pretty solid he chats with it like a knowledage friend who's also into anime. the educational aspects of llms are super under explored
2023-07-17 03:21:42,Similar functionality we can see with khanacademys amigo. A personalised llm which doesn't reveal the answer directly rather guides you to it.
2023-07-17 03:22:00,Khanmigo*
2023-07-17 05:28:58,thanks i gotta check this out
2023-07-17 07:49:33,FOSS alternative to Portkey's semantic cache+retry orchestration
2023-07-17 07:53:19,"Been checking it out since Krish reached out. Not bad so far. I was just manually doing many thing, and still a proponent of not using ready-made libraries to replace direct functions, I'm not sure I'll end up using it in production."
2023-07-17 07:57:22,"You and I are not the target users for tools like this — the cognitive+time cost for us to setup fallbacks w/ retry etc is worth the flexibility it gives us. For most app devs, the trade off is other way around."
2023-07-17 08:05:04,"Agree. It feels like the whole ecosystem of similar libraries is being built in front of us, and it is going to accelerate dev adaptation. e/acc 😂"
2023-07-17 08:15:58,"The biggest learning i have had from looking at frontend technologies grow has been the same. As a developer, id not have used anything available out of the box like Next or AntDesign. For my startup however, I am willing to pay the premium for speed."
2023-07-17 08:16:39,"Generally the market for all these tools are developers who have more important things to do, or faster execution is priority"
2023-07-17 08:17:24,Similar example is Retool for internal tooling
2023-07-17 08:18:28,"That means though, these are tools to get funding 🤣"
2023-07-17 08:18:56,"As they should, because they enable a lot of creative development which would not have been feasible otherwise"
2023-07-17 08:19:32,Tools like webflow have created a new job category of webflow developers 😅
2023-07-17 08:19:46,Right now investors are funding tools that will be used to get funding.
2023-07-17 08:20:33,"Right now, everyone is building on top of whats production ready(openai). So such tools make sense to be funded at good valuation"
2023-07-17 08:21:26,Everyone needs these kind of tools as tech is nascent. The moat/niche will come over time based on what kind of products people build out of these technologies
2023-07-17 08:21:58,"And as use cases grow, problems statements will become more clear and niche will start emerging"
2023-07-17 08:22:07,It makes sense to outsource dev tools and infra to startups focusing on them full time. 
2023-07-17 08:22:09,Mixpanel vs amplitude vs posthog for example.
2023-07-17 08:23:24,"At least Gold has historic users, we haven't found consumers for this metal, yet"
2023-07-17 08:24:18,Have to disagree with comparing webflow and libraries like LangChain 
2023-07-17 08:24:35,Im not sure if this analogy is correct. This metal is not entirely unknown. By that logic companies building apps like uber should not have been built?
2023-07-17 08:25:14,I see langchain as idk older version of language libraries
2023-07-17 08:25:32,"Right now its there, its not working but its needed. Someone will figure out the exact form"
2023-07-17 08:25:42,NextJS came out like that.
2023-07-17 08:26:09,Idk Doordash has been using openai since 002 in production
2023-07-17 08:26:15,Hard to agree when Chat GPT has over 100M users.
2023-07-17 08:26:45,For making their support more humane.
2023-07-17 08:27:02,Cohere has very happy users
2023-07-17 08:27:19,"AI has percolated so far down the tech stack that it’s invisible now. Most of us are using it daily - photos, search, news feed"
2023-07-17 08:27:40,"We are not saying that AI won't have users, are we supposed to work on first and second order before investing in third. People are jumping on third, because it is easy to build library then finding consumers."
2023-07-17 08:28:03,What are the first and second order?
2023-07-17 08:28:51,"OpenAI is first, Application like what we have that take AI to consumers is second. Look what is happening to Jasper, second order is already struggling."
2023-07-17 08:29:09,"Helping Jasper to build automation tool, is third"
2023-07-17 08:29:36,So picks and shovels are 3rd order ?
2023-07-17 08:30:04,selling timber to make pick and shovel is third
2023-07-17 08:30:24,"Who is using these libraries, OpenAI?"
2023-07-17 08:34:29,"First order ones are already going for 100M+, Investors have been burned due to other second order startups, so they keeping looking for moat/distribution/retention, third one is easy for investors and founders, because the target is not deep tech or users like 1st and 2nd, but mostly acquisition if things works out."
2023-07-17 08:35:59,I looked at json net - what did gig mean by tree like configuration? Not clear
2023-07-17 08:37:47,Did you mean git like structure
2023-07-17 08:43:16,"[PHONE REMOVED] sir time to ship code, and stop teasing us about it"
2023-07-17 08:46:30,I think I got it.
2023-07-17 08:47:12,"Talking about shipping code, what do people think about Nbdev? I know ""purist"" software engineers don't really like anything less than an IDE but has someone gone deeper into the whole literate programing paradigm?"
2023-07-17 08:49:01,"fast.ai International Fellow here, was one of the earliest testers of nbdev. I love the literate programming way of thinking, but nbdev is just no mature enough honestly."
2023-07-17 08:49:40,Every single feature/endpoint change in the lib gets written in the nbs here: https://github.com/NirantK/agentai/tree/main/docs
2023-07-17 08:50:06,Eating your own dogfood ftw !
2023-07-17 08:53:21,"Just probing a little bit, are you saying that development tools or debugging support is not there yet? or is there something else missing?"
2023-07-17 09:00:05,"it's useful for libraries right, can you use it for actual production applications?"
2023-07-17 09:01:26,You can ship your application as a library as well. But that’s a choice. I haven’t shipped applications built using nbdev yet.
2023-07-17 09:02:46,"i just came to know about it today. I am a huge fan of literate programming, this looks pretty cool. will try out"
2023-07-17 09:10:31,Two things: 
2023-07-17 09:12:45,"Quite telling that the best ""Hindi"" AI work is being done out of SF: https://twitter.com/therealprady/status/1680645510103977987"
2023-07-17 09:18:01,Ezdubs is doing this too
2023-07-17 09:18:13,They have a twitter and whatsapp bot for b2c side
2023-07-17 09:32:55,https://www.nytimes.com/2023/07/05/business/artificial-intelligence-power-data-centers.html
2023-07-17 09:35:04,Maybe add a line or two about why you think this'd be interesting to readers or why you find this worth your time
2023-07-17 09:49:51,"For Julia code, https://github.com/fonsp/Pluto.jl is fantastic. Notebooks are saved as pure Julia files which makes things a lot nicer."
2023-07-17 10:16:18,"TIL Geoff Hinton has had a movie worthy , unconventional life !"
2023-07-17 10:20:59,Correct. That was the big aha moment for me.
2023-07-17 10:22:24,Have you documented your config syntax?
2023-07-17 10:22:35,Langflow does this under the hood
2023-07-17 10:22:41,Not sure how this json looks like
2023-07-17 10:23:11,Langflow configures Langchain
2023-07-17 10:28:42,This is about the importance of big cloud and big tech companies for small AI teams like   Anthropic and cohere. There is a mention of open source but the emphasis seems to be on using smart researchers in high impact teams.
2023-07-17 11:08:31,Doesn't langflow use react flow? I think the json is similar to reactflow
2023-07-17 11:12:19,"langflow uses react-flow to model the UI, however the AI part of the code is to wire up langchain."
2023-07-17 11:14:17,"There's a difference though. Frontend technologies like react and all do one thing really well compared to langchain, llamaindex which does multiple things and you don't require 90% of them. When I'm using React I use 90% of their features. While if I have to use langchain I mostly have a usecase of maybe 10% of their features which itself is easily replaceable by just an API call. (1 hour extra work) compared to if I have to write my own reusable rendering logic like React it's going to take me weeks to make something robust and tested"
2023-07-17 11:17:28,i concur on this generally - and i do have a huge amount of respect for langchain/gptindex for moving the community forward. nextjs vs reactjs (as you pointed out) is indeed the correct parallel.
2023-07-17 11:18:51,"I'm certain while the community cribs about Langchain, someone will be building the right product form for it. That also comes from more and more users building on this tech using Langchain. [PHONE REMOVED] maybe your stab at it will be it!"
2023-07-17 11:20:36,"actually, production of core app is not Next, it should be react. NextJs brings in good abstractions for people to easily develop production grade apps. There will be something similar, history repeats itself. In AI it seems to be doing so faster :D"
2023-07-17 11:26:26,This looks like a langflow alternative: https://www.airops.com/
2023-07-17 11:31:20,patterns.app is another one (Not sure if that uses langchain under the hood though)
2023-07-17 11:31:40,".json itself is a object notation language. The time this natural language framework was created, .js was hated by most. "
2023-07-17 11:36:25,jsonnet != json. 
2023-07-17 11:37:15,Yeah was talking about .json
2023-07-17 11:38:22,Cost of generation via 3.5 v/s embedding?
2023-07-17 11:42:51,Great resource! I’d love to create one that shows the cost vs performance vs accuracy tradeoffs on top of this :)
2023-07-17 11:47:08,There's this for open source models: https://aviary.anyscale.com/
2023-07-17 12:03:34,This is a great point
2023-07-17 12:16:14,"Check this out, It says <200$, I still can't believe. https://twitter.com/alignment_lab/status/1679250520782036992"
2023-07-17 12:32:16,"They fine-tuned llama 13B with openorca dataset, right? I think they're referring to the costs of fine tuning."
2023-07-17 12:34:36,"MPT 30B has revealed the training time, GPU setup and dataset size for final fine tuning their pretrained models. Though they haven't revealed numbers but by using the existing numbers we have on lambda labs/runpod/vast ai, i saw that the costs were less than 200k usd"
2023-07-17 12:35:14,"Also, Salesforce xgen revealed they trained 10x chinchilla optimal size their 7B model for less than 150k"
2023-07-17 12:36:12,Training and fine-tuning cost is going down quickly
2023-07-17 12:38:57,"Yes, i saw last week a paper that showed same efficiency of training as FP16 for 4 bit QLoRa pretraining. It will bring down the costs further by an order of magnitude at least."
2023-07-17 12:39:11,https://podcasts.apple.com/in/podcast/replit-ai-podcast/id1689491150?i=1000618752205
2023-07-17 12:40:22,"Yes, this was a very good discussion. Quite a few insights in there about the model size, dataset quality, choice of GPUs and role of quantized inferences in the near future"
2023-07-17 12:41:29,Rule of thumb to estimate cost of pre training according to researcher at eleuther ai - Cost (dollars) = k • [# params (billions)] • [# tokens (billions)] where k ranges from 10 to 50 depending on cloud pricing and skill. https://twitter.com/blancheminerva/status/1677697585899773954?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
2023-07-17 12:44:52,Let's see what tomorrow brings us with the Meta announcement. I'm not sure why we will have to train foundation models for some time after llama2 commercial availability.
2023-07-17 12:52:27,"If we have large amount of domain- specific data which isn’t available on internet like bloomberg, then I think pre training foundation model makes sense."
2023-07-17 12:53:14,"Because of hardware upgrades, or optimisation on training side or something else?"
2023-07-17 12:55:04,"Not so much with hardware but new training methods, and research that demonstrated the benefits of high-quality data"
2023-07-17 13:01:48,"Yes, this is a very good rule of thumb. But good to also know the caveat "
2023-07-17 13:02:41,"fp16 is a reasonable assumption now, is it?"
2023-07-17 13:02:46,That was fast
2023-07-17 13:06:02,"By the time I learnt what was the difference between fp16, FP32 training and why we trained better and faster in FP32, it turned out that everyone is interested in lower bit pretraining now."
2023-07-17 13:07:33,https://arxiv.org/abs/2307.05695
2023-07-17 13:08:09,Isn't the pretraining better in fp32 for better training (ofcourse compute time and resources would be more) but later convert to fp16 for faster inferences
2023-07-17 13:10:09,"Yes it's better in fp32. It's still preferred by those who have abundance of compute. But dataset quality, epoch caveats have blurred the line for those who want to pretrain in lesser compute."
2023-07-17 13:11:03,"Yes, I saw this one. It looks like we are discovering more and more efficient way. Moore’s law lasted for decades, chinchilla is not going last even half a decade."
2023-07-17 13:15:19,fine-tuning would work here right?
2023-07-17 13:39:47,Not able to find any recent literature which uses finetuning to add knowledge. Would like to read if anyone has found something like that.
2023-07-17 13:44:32,M keen to know as well.
2023-07-17 13:47:38,Does retrieval based argumentation methods not work for this?
2023-07-17 13:48:28,"Fine tuning is mainly good for style and structure, not so much for knowledge 😅"
2023-07-17 13:49:32,I believe pretraining nanoT5 on your domain data and then coupling it with a chat layer for QA as an alternative to RAG may lead to useful results.
2023-07-17 13:51:54,Any reason you are suggesting pre training over RAG?
2023-07-17 13:52:29,For that rag is there right?
2023-07-17 13:54:18,"contrasting ""finetune on domain corpus + chat way"" vs ""RAG way"""
2023-07-17 13:54:19,Tokens are added in pre-training. That is definitely one major reason for pre-training for a new domain. This will enable the generations better as you have more complete words than subwords which might mess probability
2023-07-17 13:54:54,Yeah but I’m curious how they represent flows in json
2023-07-17 13:55:01,Can you elaborate on this?
2023-07-17 13:56:46,for anything that I've seen in action RAG appears to be simple and currently best performing as well. I've nothing against RAG.
2023-07-17 14:00:04,"Issue #1 - semantic matches don't catch the argumentative aspects of statement, whether the appearance of something is in positive or negative context or if it's for or against debate"
2023-07-17 14:00:34,"As you can see, I'm sure most people don't relate with all these issues so I'll see myself out 😅"
2023-07-17 14:01:03,"For latter use cases, isnt there something like sliding window context"
2023-07-17 14:01:07,2 and 3 can be done via RAG techniqued
2023-07-17 14:01:34,Where parts of context of separate documents are passed in each context to the ai?
2023-07-17 14:01:38,For 1 you are talking about finetuning embeddings rather than finetuning the LLM. That is different and cheaper and easier
2023-07-17 14:02:45,"For #2, you won't get the docs in context because individual docs ranked low"
2023-07-17 14:03:25,"For creative questions like - “what other fields of science have different names for the idea of natural selection ?”, we will need pretrained language models..My mental model is RAG is great for factual information; but for creativity, pre training  models will be better."
2023-07-17 14:03:44,"No there are other ways, we have done this in longshot for multiple urls at a time. Can be extended to docs"
2023-07-17 14:04:44,I think this is mixture of issue 2 and 3
2023-07-17 14:05:24,Creativity and any level of reasoning to make a meaningful inference in one go.
2023-07-17 14:05:39,Yeah
2023-07-17 14:06:27,"How did you take care of #2, when the docs needed for answer themselves don't rank and get fetched in top k retrieval?"
2023-07-17 14:07:38,I think you're talking about context as in context of prompt whereas my issue was with the fetched docs from retrieval. Or am I understanding your question wrong?
2023-07-17 14:07:46,chunking is all you need. Think of different chunking strategies you can apply here and how you get all the information. 
2023-07-17 14:09:22,But when your document corpus changes frequently ( say mostly additions)
2023-07-17 14:11:02,Are there Azure managed instances for vector DBs? Which ones should one try? I think Weaviate can be AKS hosted but no PaaS offering as such I guess
2023-07-17 14:11:05,"Yeah, can't fine tune often without ending up with suboptimal models for data that changes too often. Just stick to RAG there perhaps."
2023-07-17 14:13:21,"Azure folks had recommended cognitive search , azure cache for redis during our walkthrough"
2023-07-17 14:14:03,"They had also mentioned the current prevailing solutions such as pinecone, chroma etc as well if we wished to"
2023-07-17 14:14:20,"Maybe in time, it will be all ui triggered for enabling non tech/ mgmt folks to update for fine-tune also :"
2023-07-17 14:14:59,"It's good if it works for you, I'll be happy to see the ever-working optimal chunking strategy that isn't so small that it misses out on important info present in context of occurrence and that isn't so big that it can't be efficiently processed and recalled. Such a strategy would strike the perfect balance between depth and breadth of information."
2023-07-17 14:16:14,Yaa !
2023-07-17 14:17:18,"This requires experimentation for your use case. This solution isn't going to be available out of the box, else everyone would be doing it. We experimented and came with a solution that works here. You can also add some extra filtering. Not everything has to be LLM based."
2023-07-17 14:18:58,"If you did a lot of experiments and it worked on a few set of docs, you may see that different docs and constraints will need you to change your approach again. One size fits all doesn't work here and that's a genuine limitation. Not a very pressing one, but a limitation none-the-less."
2023-07-17 14:19:58,I think you are misunderstanding me. Can discuss this one on one. What we did works on urls of wide range of domains.
2023-07-17 14:22:05,And also looking for perfect solution ML/LLM based doesn't work in real scenarios anyways. You have to be creative here. My 1000 tokens on this is 
2023-07-17 14:25:25,"Reiterating my original context, I'm just interested in combos to take care of genuine issues that exist with current RAG approaches. I'm well assured it's the best approach we have that works and gets a few things done with simplicity."
2023-07-17 14:28:07,"i think, one cant generalize"
2023-07-17 14:29:18,The case you are describing though can also be solved by finetuning the embedding model and leaving the LLM as is to use with rag
2023-07-17 14:29:33,Looking for an alternative to Azure redis cache actually
2023-07-17 14:39:53,Playground: https://automorphic.ai/playground
2023-07-17 14:48:10,TIL about LMQL
2023-07-17 14:56:02,This group removal thing is terrifying! There goes one more 😅
2023-07-17 15:04:39,Folks have nothing to worry about! Just spam is not tolerated.
2023-07-17 15:14:03,Embedding Benchmark (mirror) from our very own [PHONE REMOVED]
2023-07-17 15:19:58,Unregrettable attrition
2023-07-17 15:25:46,I thought today's the day of the purge again.
2023-07-17 15:32:45,"Hahaha, active folks have nothing to worry. From the ~200 odd folks we've removed, only 4 have gotten back asking to be added. That's an error rate I'm willing to live with"
2023-07-17 15:33:34,What an accuracy sirji
2023-07-17 15:33:59,Only 4? That is a very good sample.
2023-07-17 15:36:05,Issue #2 is pretty relevant. Imagine you have 5-10 component level tech specs and product specs which are written to handle a big re-architecture activity which too has a tech spec.
2023-07-17 15:41:10,"Chunking at a heading level within a doc, and extending that across docs is something I tried. The performance was decent but it failed to rank relevant topics because headings within a document maybe have some context in previous headings."
2023-07-17 16:00:37,Precision is very high ! :)
2023-07-17 16:26:24,Off topic. I've always been confused with the difference in accuracy and precision. Which one is this?
2023-07-17 16:28:16,accuracy would also involve how few false negatives were there afaik
2023-07-17 16:29:14,GPT-4 
2023-07-17 16:30:10,Haha Ty.
2023-07-17 17:05:18,\
2023-07-17 17:22:34,surprised to see how you keep track of all these numbers
2023-07-17 17:27:58,Helps that I don't have much of a life
2023-07-17 17:35:08,Listening to this one by [PHONE REMOVED]  on domain specific LLMs https://youtu.be/hOAJ1708Tp0
2023-07-17 17:36:07,This joke clearly didn't land.
2023-07-17 17:36:13,"The ""brain model + muscle model"" approach seems interesting. Wonder if the earlier work done on transformer-in-transformer could be a substitute"
2023-07-17 17:46:43,You mean didn't settle? 😜
2023-07-17 17:57:43,Yes didn’t understand it for first time
2023-07-17 17:57:49,This is nice
2023-07-17 18:20:24,"Hello folks, I was going through the Azure OpenAI pricing, for comparing the price of gpt-35-turbo and gpt-35-turbo-16k, but I am not able to see the pricing separately for the 16k model on this page"
2023-07-17 18:36:41,Accuracy and precision are somewhat simialr… recall means soemhtign different
2023-07-17 19:15:53,Cc [PHONE REMOVED] from Azure India
2023-07-17 19:23:26,"Has anyone seen the palantir and scale AI defence products? It’s scary to think these are connected to military infra and tools, used for reasoning and actions. MI dead reckoning vibes"
2023-07-17 19:25:03,I think they are currently using it for preventive measures. Not sure about what is going on under the hood
2023-07-17 19:27:36,https://www.palantir.com/aip/defense/
2023-07-17 19:31:34,https://techcommunity.microsoft.com/t5/ai-cognitive-services-blog/introducing-new-and-updated-models-to-azure-openai-service/ba-p/3860351 - refer to this link
2023-07-17 19:32:37,"This is crazy, have they built a custom model, it is already in testing?"
2023-07-17 20:16:36,https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence
2023-07-17 20:17:54,Unacceptable risk:
2023-07-17 20:20:15,Generative AI
2023-07-17 20:27:45,"From what I understand, it requires you to disclose all material protected by copyright that was used to train the model - likely to ensure due credit to the original author/writer"
2023-07-17 20:30:58,"Basically how their visa service,  their credit scoring works currently?"
2023-07-17 20:38:14,"Not classifying people based on behaviour is too broad. If you can't classify people on behaviour, then good luck classifying them🤣"
2023-07-17 20:38:59,https://crfm.stanford.edu/2023/06/15/eu-ai-act.html
2023-07-17 20:39:15,This is a good post on applicability of EU laws on foundation models ^
2023-07-17 20:40:41,"This can also be inferred to say that you can't not give loans to people with low credit scores due to their previous behaviour. This goes way beyond privacy, if true"
2023-07-17 21:01:38,this is already present in non-LLM based AI. We have reported this kind of anti-bias data to RBI for years now. 
2023-07-17 21:07:05,This is definitely anti-recsys.
2023-07-17 21:28:32,"This is true. Using location data, religion, etc is no no for credit scoring. But saying that you can't use any behaviour is a bit too far no? As in, you can say that past emi payment data is also behaviour only. If you can't even use this for credit scoring, then isn't that an issue or am I wrong to assume that past payment data will not count as a behaviour?"
2023-07-17 21:29:52,"I'm sorry, what is recys?"
2023-07-17 21:30:36,Recommendation systems I think
2023-07-17 21:32:02,Does rbi have guideline against using these for alternative credit scoring systems?
2023-07-17 21:35:20,Exactly
2023-07-17 21:53:06,"The RBI has a rule saying ""you must prove no bias exists""."
2023-07-17 22:11:15,Michael Siebel (YC guy) in a recent video spoke about 2nd order effects of GenAI. https://www.youtube.com/watch?v=smHw9kEwcgM.
2023-07-17 22:17:19,Obvious effects are threads and newsletters
2023-07-17 22:20:04,Individual brands will become more highly leveraged. 
2023-07-17 22:22:02,Obvious Second-Order Effects:
2023-07-17 22:23:19,Non obvious effects - way more data noise. GenAI parrots and bots polluting all public and social media - Verified accounts become hygiene for any online credibility.
2023-07-17 22:26:37,"I guess it will become like today's news media. Most news channels are mostly showing useless drama. There are only a few news outlet that will give genuine quality and diverse news, that people will pay for as well"
2023-07-17 22:27:53,"Folks, I was by effects (citing the examples of apps) I meant concrete (startuppy) ideas. For example - will premium AI proof / insulated communities will rise?"
2023-07-17 22:29:08,"Stretching into philosophy territory, but I think manufactured content poison is the new attention hacking - the former is a new capability thanks to AI models, and the latter is a result of social media. I think most tech/media companies will begin to use this 1-2 punch to get addictive consumption on their products"
2023-07-17 22:30:15,Has anyone used uizard.io? I bought the sub under the impression that they do autogeneration of image to ui code but they  apprently stopper the export to code option...
2023-07-17 22:30:20,Stopped*
2023-07-17 22:39:38,Obvious 2nd order effects:
2023-07-17 22:42:06,Non obvious 2nd order effects. Social networks start to collapse/change dramatically. As they go from personalized curation of UGC to personalized creation of content for each user.
2023-07-17 22:43:22,Is anyone interested in developing a threat detection AI ML software
2023-07-17 22:51:57,I feel some second order effetc might be:-
2023-07-17 23:09:42,https://www-businessinsider-com.cdn.ampproject.org/c/s/www.businessinsider.com/openai-gpt4-ai-model-got-lazier-dumber-chatgpt-2023-7?amp
2023-07-17 23:12:07,"Maybe even less obvious, completely accelerated technological progress on another scale, we are no longer limited by domain knowledge to build things. At least, the gap to acquire domain knowledge to do something is exponentially lower"
2023-07-17 23:12:08,Has anybody found any major issues with the latest GPT-4 api?
2023-07-17 23:14:16,Yeah. Looks like a cost cutting move.
2023-07-17 23:14:53,"This is intereting, learning new things is easier with the LLMs. It will be cool if I can see the questions asked by other people with answers on the same topic."
2023-07-17 23:17:25,"Try this prompt ""Identify and behave as three different experts that are appropriate to answering this question. All experts will write down the step and their thinking about the step, then share it with the group. Then, all experts will go on to the next step, etc. At each step all experts will score their peers response between 1 and 5, 1 meaning it is highly unlikely, and 5 meaning it is highly likely. If any expert is judged to be wrong at any point then they leave. After all experts have provided their analysis, you then analyze all 3 analyses and provide either the consensus solution or your best guess solution. The question is..."""
2023-07-17 23:27:14,I expected cost cutting without significant impact on performance ...
2023-07-17 23:52:44,Can you ELI5 these points?
2023-07-17 23:53:14,This toh obvious only no?
2023-07-17 23:58:48,So the second order effect here is.. Rise of Chinese room experts? Who can get shit done but don't really grok it?
2023-07-18 00:03:02,Flash Attention-2 got released. https://princeton-nlp.github.io/flash-atttention-2/
2023-07-18 01:21:17,just thinking out loud. another issue  within Issue 3:
2023-07-18 01:22:04,reordering? Do you mean ranking to filter out relevant chunks?
2023-07-18 01:29:42,no. im talking about the relationship between the X chunks fetched. as in chronology. 
2023-07-18 01:31:54,"Chunk order does not matter. However, you can always add metadata in your chunks if you feel that matters. Like adding date of article. And you pass today's date in prompt. So gpt knows todays date and date of each chunk . It helps in certain cases."
2023-07-18 02:04:07,Issue #3 is a bit different than what you think.
2023-07-18 02:05:29,"Unsolicited info: Knowledge Graphs, in theory, are designed to deal with chained reasoning tasks better and thus some efforts are there to build Semantic Knowledge Graphs for RAG."
2023-07-18 02:08:46,"no no. it's clear. that's why in the 2nd message i wrote ""forget sequential chain"". mixed it up earlier. "
2023-07-18 02:09:40,this
2023-07-18 02:10:17,and this
2023-07-18 02:14:20,came across this yesterday.
2023-07-18 03:10:27,"This is the most apt description of challenges in RAG that I’ve seen. I think one issue that you can add (similar to Issue #1), that’s very relevant for enterprise level RAG is "
2023-07-18 06:35:30,Which event is that?
2023-07-18 06:36:02,This is Dropbox and Elastic AI meet-up.. it's being livestreamed (I don't know the link)
2023-07-18 06:36:14,https://www.meetup.com/elastic-san-francisco-user-group/events/294476508
2023-07-18 08:12:45,https://kenschutte.com/gzip-knn-paper/
2023-07-18 08:12:47,FTC has started investigating OpenAI: https://www.washingtonpost.com/documents/67a7081c-c770-4f05-a39e-9d02117e50e8.pdf?itid=lk_inline_manual_4
2023-07-18 08:14:04,"They have asked for specific on model training and what data was used, hallucinations, prompt injections, PII amongst others."
2023-07-18 08:18:46,Very interesting Paras.
2023-07-18 08:31:53,"Gzip or not, IMO the key finding is that vector representations of text are not the only way. Who knows what other ways we can preprocess text? And it may benefit certain domains or use cases more than others."
2023-07-18 09:16:07,"Hey guys, we have the need for a multi-class text intent classifier. We have a limited, clean, and steadily growing dataset. We are exploring fine-tuning pre-trained models. Any thoughts on what be the right choices?  "
2023-07-18 09:17:11,"For any founder planning to move to Bay Area, let me know"
2023-07-18 09:28:41,This depends on the baseline accuracy and domain. What is the accuracy on an off the shelf model from 🤗? you are getting and targeting? From a basic classification perspective if you have a lot of data you can even train your own Bert and further fine tune it. Or you can go the PEFT/LoRA way.
2023-07-18 09:29:35,I'd prototype this with fasttext in 20 minutes and launch first and then replace the modeling in background once I had adoption
2023-07-18 09:30:46,I'd helped a co make a $1m deal in 2018-19 with this approach. 
2023-07-18 09:35:49,"I’m in the Bay Area Jul 23- Aug 5, would love to catch up with anyone in the community"
2023-07-18 09:36:22,All Langchain streams are in IST fwiw. And some of them are masterclasses like the one with Jo Bergum
2023-07-18 09:37:15,"I'm here in South Bay, available for coffee any day."
2023-07-18 09:42:06,"and if anyone is exploring the O-1 route, let me know if I can help."
2023-07-18 09:43:28,Don't want to get into technicalities but L-1 is better for founders
2023-07-18 09:49:46,We have applied for O1. Hmu if you need any information
2023-07-18 09:50:30,"Im around in sfo, can catch up"
2023-07-18 09:52:34,Why do you say that?
2023-07-18 09:54:49,"Less paperwork, faster decisions"
2023-07-18 10:03:58,"Every few days i see some advance or research,"
2023-07-18 10:05:25,"See top HN comment, it’s not as impressive as it sounds"
2023-07-18 10:13:36,FlashAttention-2 is 2x faster 💥I think we are moving towards 0 compute cost😬
2023-07-18 10:18:39,Wasn’t new llama supposed to be released yesterday? 
2023-07-18 10:21:19,"Yeah, Bummer 😞"
2023-07-18 10:21:56,Thanks Paras.
2023-07-18 10:25:06,Damn. NVIDIA must be sad.
2023-07-18 10:25:52,fmri resolution is too low for this to work
2023-07-18 11:04:36,"First thing i did on waking up was check Twitter for llama 2 release. Welp, gotta wait for some more time. It better be worth the wait."
2023-07-18 11:05:45,It will be Tuesday their time I think
2023-07-18 11:37:21,Bad look for the authors and the guys who ran with justification of the paper.
2023-07-18 11:44:56,Yeah. Mistakes can happen. This is why focus on reproducibility is so important 
2023-07-18 11:46:08,"while I understand the results don't hold, what interested me is the novel approach. It may not be useful in prod but it's still interesting"
2023-07-18 12:11:51,https://yoshuabengio.org/2023/03/21/scaling-in-the-service-of-reasoning-model-based-ml/
2023-07-18 12:13:05,Is anyone here working on model based approaches?
2023-07-18 12:21:29,Is it even feasible given that automated reasoning for even pure math is too difficult for current tech?
2023-07-18 12:33:33,"The author talks about amortised inference, so instead of doing search from the scratch each time, you train a network to do that"
2023-07-18 12:34:04,Building a world model automatically seems more difficult than inference on it
2023-07-18 12:51:55,I think the main issue in model building is knowing uncertainty 
2023-07-18 12:52:19,"What Bengio is saying is to separate world models from inference, and that makes sense"
2023-07-18 12:52:46,I also like his emphasises on separating action modules from
2023-07-18 12:52:54,"But then here's the catch22, if an LLM is so good that it can detect hallucination in other LLMs, then people will just use that superior LLM."
2023-07-18 12:53:46,A model with uncertainty also can be used by another model that actively seeks information that reduces uncertainty
2023-07-18 12:54:19,"no, not another LLM but the same one"
2023-07-18 12:58:41,I really like his system 1 and system 2 analogy 
2023-07-18 13:00:03,"For system 2 kind of inference, he proposes generative flow networks which seem pretty cool"
2023-07-18 13:00:31,"With regards to Intelligence, one general approach could be that instead one big LLM, there are several small ones that recursively call each other until a satisfactory solution has been achieved.  To make a human equivalent decision, we need an Observer Model.  "
2023-07-18 13:00:44,Daniel Kahnemann much😜
2023-07-18 13:03:15,"Debunked Kahnemann, given how much of his work is discredited 🫣"
2023-07-18 13:03:49,The system thinking terminology is still used here
2023-07-18 13:04:01,"It’s amazing how in our head we have an entire simulated world, which we use when we are doing deliberate thinking"
2023-07-18 13:04:41,Yup. That's not debunked
2023-07-18 13:08:06,only known-unknowns
2023-07-18 13:08:56,and Rescher's ontology of what is not knowable is quite deep. (without emergence type process)
2023-07-18 13:09:23,Pls elaborate
2023-07-18 13:10:07,On the Philosophy group please!
2023-07-18 13:10:36,"Brij, is this documented formally & in more technical detail somewhere - in a preprint or such ?"
2023-07-18 13:11:54,"I've started writing a draft paper .. happy to share the collaborate .. big caveat, this is just a high level theory at the moment"
2023-07-18 13:13:29,Link?
2023-07-18 13:15:27,"does ""creativity"" go hand in hand with ""hallucination"" & uncertainty ?"
2023-07-18 13:19:54,Thats AGI I think 😅
2023-07-18 13:20:35,https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
2023-07-18 13:21:42,This sounds very reasonable and we are thinking about a very similar approach to have federated agents and co-pilot which you are calling as observer model which is overlooking everything.
2023-07-18 13:24:22,This is from some literature or you framed it? Either ways very well put.
2023-07-18 13:25:19,Its actually based on a Spiritual Philosophy - 
2023-07-18 13:27:01,"I think if we cap on the parameter size to address scaling issues, a right combination of mixed data would be needed. For example a code dataset with maybe contract dataset kind of things. So one dimension is principled AI thinking and planning but other is thinking skilled models. Something I’ve been contemplating about."
2023-07-18 13:27:19,We are working on a similar lines for Human + Machine Teaming using Autonomous AI Agents.  
2023-07-18 13:28:55,So much aligned on this way of thinking. OG Garry Kasparov said something to this effect.
2023-07-18 13:30:57,Mixture of Dataset is an interesting approach. I have an idea which dataset could be used for this.
2023-07-18 13:31:02,Reminds me of Daniel Dannett's Multiple Drafts model of consciousness for some reason. 🙂
2023-07-18 13:31:13,Let’s chat!
2023-07-18 13:31:23,Creativity is known / controlled hallucination
2023-07-18 13:32:36,"That's a ""Thinking Fast and Slow"" adaptation for LLM inference."
2023-07-18 13:34:44,"As per current design of autoregressive decoder only transformers, setting max creativity minimises certainty and vice versa."
2023-07-18 13:34:59,This is very interesting .. thanks for sharing. Will spend some time to understand this deeply
2023-07-18 13:41:06,"hallucinations is a symptom of the dark triad (mental model) or in psychiatry, to certain loosely defined 'state of mind' - is hallucination triggered by uncertainty ? more of unable to fit data into one's worldview."
2023-07-18 13:43:15,i am not commenting on the model building part ... only the first line of your comment 'Ashish'.
2023-07-18 13:43:56,"This is where we have seen knowledge graphs/enterprise data fabric play a great role, is to have semantic relationships between heterogeneous concepts."
2023-07-18 13:44:25,confabulation that’s the word
2023-07-18 13:46:33,"Absolutely! What all industries would be down for this? Usual, Pharma types? Or has anyone seen anything interesting recently?"
2023-07-18 13:47:40,"IMHO, Knowledge graph is this seductive idea where companies go to die. Latest example that comes to mind is https://golden.com/"
2023-07-18 13:51:01,"For https://learnawesome.org/, I toyed with knowledge graphs and ConceptNets for a while. A hand-curated taxonomy is far more practical and lets one actually ship things."
2023-07-18 13:53:11,What are productive use cases? We have had this discussion on knowledge management for 2+ decades and perhaps some apps have been built. There was a small toy app called Graph GPT which seemed interesting for a while but it was probably too simple and based on too many assumptions
2023-07-18 14:00:23,W3C has been beating the RDF / Semantic Web drum for many years. I haven't run into many practical use cases but this thread lists some: https://news.ycombinator.com/item?id=36001509
2023-07-18 14:02:51,Any reading material on this?
2023-07-18 14:03:10,Because ontologies are hard enough for humans.
2023-07-18 14:04:12,Semantic web never took off because building ontologies and reasoning over it was computation expensive
2023-07-18 14:06:39,"We are using this in the supply chain space at the moment. Its ofcourse quite big in chemical and pharma industry, especially with drug discovery."
2023-07-18 14:09:16,"Yeah, I think building one ontology for all is very cumbersome and complicated. "
2023-07-18 14:09:18,So… I have not seen it to be effective. The challenge is that ontologies can be suggested but might not be interoperable. Also limitation of knowledge graph is pruning. To make effective one needs to prune some connections. SALI takes a top down approach to building this ontologies for legal.
2023-07-18 14:09:30,https://arxiv.org/abs/2305.13168 - review of LLMs for KG construction
2023-07-18 14:10:44,"Thanks, I was looking for this one."
2023-07-18 14:19:02,"I think we don't need KB as large as LLMs, but precise enough to help decision-making from LLM outputs.  Think of it as fine-tuned model for a legal firm that likes to work a particular way, and we have used high-quality dataset from their practice to tune a model. LLM can still hallucinate, and IMO better option would be creating KB using this dataset, let human evaluate and maintain, and then RAG on KB to fetch appropriate decision making nodes, then add context of the situation on which the decision is to be made."
2023-07-18 14:19:10,I think I'm incoherent here
2023-07-18 14:20:01,No no this actually makes sense
2023-07-18 14:20:02,"I will have to properly put my thoughts together, first😞"
2023-07-18 14:21:57,"Amit Sheth (ex-Pilani) was my advisor and we have done a lot of work on the Semantic web, he probably still doesn't trust LLMs much but I have moved on from being a Semantic Web loyalist. https://scholar.google.com/citations?user=2T3H4ekAAAAJ&hl=en"
2023-07-18 14:21:59,This makes sense.
2023-07-18 14:22:08,"This is about knowledge graph construction, not ontologies."
2023-07-18 14:22:35,Or I probably misunderstood something.
2023-07-18 14:28:07,Here is an example of topic modeling with LLMs: http://home.cse.ust.hk/~lzhang/topic/aipanoIntro.pdf
2023-07-18 14:30:51,"This is a good paper, but I find this as the opposite direction of what is intresting in LLM."
2023-07-18 14:36:09,Anyone knows of any way a wav2lip model (or something similar) to generate streaming inference?
2023-07-18 14:46:15,are there any alternatives to hosting OSS LLMs apart from GPT4ALL?
2023-07-18 14:56:12,https://twitter.com/BEASTMODE/status/1679599277658591233
2023-07-18 14:59:15,https://arxiv.org/abs/2307.07164
2023-07-18 14:59:57,Might be relevant to the discussion yesterday on RAG
2023-07-18 16:16:18,https://ikdd.acm.org/kdd2023/
2023-07-18 17:26:55,Thanks! Our domain is accounting.
2023-07-18 17:28:04,Thanks Nirant! 💯
2023-07-18 17:30:35,"Talking about fast, multi-lingual parameterless text classification? Recently read a paper where researchers use gzip to compress and then use K-means to find similarity to a document class. Very efficient, multilinual. Let me find the paper."
2023-07-18 17:30:40,Has anyone used the RETRO model in production or tried to deploy in production yet?
2023-07-18 17:32:12,https://arxiv.org/abs/2212.09410
2023-07-18 17:32:36,Commentary and code walkthrough:
2023-07-18 17:34:48,When I first read this it reminded me of Silicon Valley episode where AI is able to modify text over compressed and encrypted data 😅
2023-07-18 18:38:26,"There seems like a bug in their takeaway. Because of the way they solve it, their accuracy is top-2 accuracy and not top-1 accuracy. See here https://news.ycombinator.com/item?id=36758433"
2023-07-18 18:45:50,"There is an old adage amongst ML community that someone did years of effort in feature selection + model selection and then compared against KNN on a large dataset, only to be severely disappointed. KNN are asymptotically accurate, don't be surprised if KNN with right distance metric does amazing things on very large datasets. The authors probably took this to heart and we can't blame them."
2023-07-18 18:51:06,Woah you remember that info from SV series 🤯
2023-07-18 18:51:59,Yeah! Happens after Russ fest.
2023-07-18 19:03:20,"RETRO doesn't have a canonical implementation. Non-trivial to productionise it, and even for experimentation — a bit bulky with multiple data dependencies for evaluation too."
2023-07-18 19:05:19,Not even sure how RETRO compares to simply doing similarity search and inserting in context into any LLM
2023-07-18 19:06:42,"Yup, Unknown upside, high and known investment upfront and ""Good enough"" alternatives abound."
2023-07-18 19:17:48,Is anyone facing issues with Code Interpreter lately ? 
2023-07-18 19:18:31,Getting a bad feeling that OpenAI has nerfed Code Interpreter
2023-07-18 19:32:00,It's very prompt dependent.
2023-07-18 19:34:37,Issue is I had higher quality output with similar prompts up until last week 
2023-07-18 19:59:53,Will ping!
2023-07-18 20:37:15,Are there some good examples / usecases of using GenAI in the travel industry ?
2023-07-18 20:54:04,Trip planning is one straightforward use case which has been making the rounds.
2023-07-18 21:06:34,https://twitter.com/alokebajpai/status/1679104716893196288?s=46&t=icC0fizZK8E3ONsDVuGFWA
2023-07-18 21:09:43,Microsoft has also partnered with MakeMyTrip for voice based search for travel planning 
2023-07-18 21:12:03,Some brainstorming that happened on the group a while ago on what a future reasonably smart travel assistant should be able to do
2023-07-18 21:12:27,Another one
2023-07-18 21:22:45,Cohere entering it's Palantir era was not on my 2023 bingo card
2023-07-18 21:28:51,OpenAI did its service alliance agreement with Bain so why is this surprising? They all need an implementation partner to go after enterprises.
2023-07-18 21:29:33,Bain has nicer street cred than McK
2023-07-18 21:30:32,The Implementation partner will likely be the next gen IT Services company
2023-07-18 21:31:33,"You'll see these soon IMO; but someone needs to do the ""strategy"" work before the implementation guys come in"
2023-07-18 21:32:48,Why is it easier for strategy guys to do implementation vs implementation guys to do strategy?
2023-07-18 21:33:23,Brand factor?
2023-07-18 21:33:31,"Strategy is high status, so CXOs go to them"
2023-07-18 21:35:00,Def didn’t have this on the bingo card…
2023-07-18 21:35:14,https://twitter.com/_akhaliq/status/1681333345085542404?t=xDZ9rDCfY2gyLmmtiHqDhg&s=08
2023-07-18 21:44:56,I think its to create distribution channel and get more dollars
2023-07-18 21:44:59,Accept the community license here
2023-07-18 21:50:28,This sounds very similar to the mixture of experts architecture - except with different experts being their own atomic model. 
2023-07-18 21:50:56,Who has run it already?
2023-07-18 21:52:57,It's available here https://replicate.com/a16z-infra/llama13b-v2-chat
2023-07-18 21:57:13,https://twitter.com/DrJimFan/status/1681337179057029121?t=L61MThj0CVsUSd584Azvpg&s=08
2023-07-18 21:59:11,More dataaaa >> more parameters
2023-07-18 22:04:14,What's the context window for Llama
2023-07-18 22:04:38,4K
2023-07-18 22:04:49,Nice.
2023-07-18 22:06:17,Their license restricts generating data for training another LLM
2023-07-18 22:06:29,But I’m so happy we have a strong commercial LLM now
2023-07-18 22:07:30,"Of course, no one will ever do a thing 😜."
2023-07-18 22:07:44,"Wonder what the loss looks like at 2 trillion tokens. Probably in the paper , have to check it out but will be nuts if it's still decreasing. Llama one was released with the loss still going down."
2023-07-18 22:08:17,Yudkowsky gonna get a heart attack
2023-07-18 22:10:32,"You should still be able to finetune it on top of evol data and others, like alpaca/vicuna of the past I suppose?"
2023-07-18 22:19:01,You can’t generate data from llama to train something else
2023-07-18 22:28:58,How are the results for Llama for you guys? Am testing using the replicate link
2023-07-18 22:37:57,https://twitter.com/LangChainAI/status/1681349170433761280?t=YaEPBAly6TV96QdHSoJB9A&s=19
2023-07-18 22:43:05,Couldn't find this link. Going to try when home. 😄
2023-07-18 22:48:19,This is the replicate link for folks who want to try
2023-07-18 22:48:32,This looks interesting
2023-07-18 22:48:47,"The results are not bad. Among OSS models, this one shows more promise"
2023-07-18 22:50:12,https://ai.meta.com/resources/models-and-libraries/llama/
2023-07-18 23:03:12,It’s cool to see 70b matching chatgpt performance
2023-07-18 23:03:16,Hope to see costs drop even further!
2023-07-18 23:04:57,Made my own mirror — in case someone wants to use it via the API (which is a bit worse than chat demo and Replicate)
2023-07-18 23:07:54,is it 70b?
2023-07-18 23:11:27,13b
2023-07-18 23:12:13,Sire you'll have to sponsor that when I get the access token
2023-07-18 23:15:14,The ggml versions of the models have also dropped: https://huggingface.co/TheBloke/Llama-2-7B-GGML
2023-07-18 23:16:31,Haha for sure
2023-07-18 23:17:30,"A bit too verbose for clear cut legal use cases, but worth testing because it gets the other stuff right for us. Verbosity, are others experiencing?"
2023-07-18 23:21:13,i think the model is plain translating back and forth in hindi & english
2023-07-18 23:21:38,who is the nirmata here? is the model gaslighting me?
2023-07-18 23:23:06,This is so funny. It feels like the model is on shrooms. All it can do is hallucinations
2023-07-18 23:23:29,This is very high temperature. Can dial it down here llama2.ai 
2023-07-18 23:23:44,1st impressions: Does better on well-known concepts. More hallucinations. Poor reasoner & doesn't follow complex instructions. Of course way faster
2023-07-18 23:23:45,"Don’t, high temperature is fun"
2023-07-18 23:24:44,"Reasoning is similar, high temp kills reasoning — try a lower temp here: llama2.ai"
2023-07-18 23:25:16,Same. That is why I left it at 0.9
2023-07-18 23:27:15,"Thanks, yeah was playing w temp"
2023-07-18 23:27:35,One can also try the hosted replicate endpoint
2023-07-18 23:30:06,Longer training time too
2023-07-18 23:31:19,"""Does liberalism entail libertarianism? Be concise."""
2023-07-18 23:32:02,Why does Meta love access forms so much?
2023-07-18 23:32:50,"Wish someone had built like a ChatGPT style UI , where previous context of a conversation remains."
2023-07-18 23:32:54,"Why waste bandwidth trying to validate who gets it and who doesn't? It's clearly going to be used directly, indirectly by everybody."
2023-07-18 23:33:06,Chatbot UI
2023-07-18 23:33:19,Link ?
2023-07-18 23:34:07,I'm sharing a window AI version of chatbot UI - https://chatbot-ui-window-ai-git-windowai-skylight-ai.vercel.app/
2023-07-18 23:34:54,"You can access every api including Claude v2, palm, GPT4 32k, falcon 40B here and chat with it in the shared UI link - https://openrouter.ai/docs"
2023-07-18 23:35:13,Got in within 10 minutes.
2023-07-18 23:36:00,I think this is in the training data
2023-07-18 23:37:14,I wonder if it is meta original training data or a16z's fine tuning.
2023-07-18 23:37:25,I got a link which does not exist
2023-07-18 23:42:29,This is clearly for Enterprise product who want low creativity high privacy / data security etc
2023-07-18 23:44:31,Meh !
2023-07-18 23:54:16,Why would this work?
2023-07-18 23:55:01,Didn't get you?
2023-07-18 23:56:30,"Like it obviously doesn't have the knowledge about the replicate api (or how to use llama2 on it), so why would we expect it to be able to answer that question?"
2023-07-18 23:57:25,"Oh yeah. That link didn't open for me, hence was confused"
2023-07-18 23:58:06,"Heavily temp dependant on format of output (user prompt in openAI), but are lower levels more reliable in this sense will decide it for us."
2023-07-18 23:58:52,I'm finding it useful for certain rag use cases
2023-07-19 00:01:49,"just got the email with access, they are not really gating access . Yay !"
2023-07-19 00:02:55,Answer?
2023-07-19 00:16:53,"Sorry, I mistakenly edited my previous message :"
2023-07-19 00:17:47,Looks bad for enterprise apps 😊😄
2023-07-19 00:18:30,Don't know if it's an issue with the replicate implementation or something inherent to the model
2023-07-19 00:20:19,Llama-v2 is available on Microsoft Azure.
2023-07-19 00:21:58,This is a very good 13B model. But a 13B model nonetheless.
2023-07-19 00:22:26,I wonder what OpenAI feels about this :)
2023-07-19 00:22:31,"But even then, it's bad with coding as HumanEval scores look bad. I guess WizardCoder versions of llama v2 will be interesting."
2023-07-19 00:22:50,one noob question - are 13b models good a following basic instructions? what are they good for?
2023-07-19 00:24:23,"Honest answer - Stock 13B is mostly used with creative or role-playing purposes especially in areas where ChatGPT will start ""As an AI language model""."
2023-07-19 00:24:58,so role playing + RAG to cater to narrow use cases
2023-07-19 00:25:15,"Best part about 70B model, they can be used for inference as well as 4 bit fine tuning on a single A100."
2023-07-19 00:26:01,Role playing doesn't really need RAG that much. Question answering applications need RAG.
2023-07-19 00:26:46,"yes. but i am thinking of corporate use cases. as long as my model adheres to certain roles, i can launch bunch of smaller models tuned to do a certain task, now a swarm of these agents to do multiple tasks"
2023-07-19 00:27:00,instead of one big model to do many tasks.
2023-07-19 00:27:12,is that the goal of these models?
2023-07-19 00:28:46,It's possible but I think we don't have good examples with the current fine tuned models. One will have to test for the proof of concepts.
2023-07-19 00:30:02,Few findings
2023-07-19 00:31:30,"did you fine tune the models, or used them off she shelf?"
2023-07-19 00:31:47,The replicate has 7B and 13B available as APIs for now. I guess it's the same on the chat and not 70B.
2023-07-19 00:32:04,"no fine-tuning. Used it via replicate api. RAG pipeline, custom prompts for product description"
2023-07-19 00:33:29,HF maybe for 70b model
2023-07-19 00:34:22,ok update 13b is also good. temperature of 0.75 which is default in replicate is something I tried and it works
2023-07-19 00:34:39,Has anyone compared with chatgpt side by side
2023-07-19 00:35:00,Also wonder what azure hosted llama 70b pricing is? Have they released it
2023-07-19 00:35:31,I was comparing with API results with gpt-3.5 side by side for our prompts. Quality is decent.
2023-07-19 00:35:33,Are you just testing for answering based on context or also testing whether it follows citations?
2023-07-19 00:36:08,"As per my understanding 7B, 13B will break when it has multiple rules to follow without fine tuning."
2023-07-19 00:37:13,"This is product description generation, so basically the content is picked from a RAG pipeline . And the prompt is our own prompt."
2023-07-19 00:38:17,Great. I'll DM you to know the results in detail probably when you're done with your testing.
2023-07-19 00:38:50,I'll test it tommorow abhi 😅. you can dm your questions
2023-07-19 00:40:28,"In my very preliminary testing, generation varies greatly for the same prompt for each ""generation"" for Llama2( the replicate chat api endpoint)"
2023-07-19 00:42:13,Replicate pricing :
2023-07-19 00:51:26,No word on pricing here :
2023-07-19 00:52:52,I was half expecting Meta to launch a productized version of LlamaV2.
2023-07-19 00:53:19,I wonder this could have been Meta's chance at introducing their cloud to the public?
2023-07-19 00:59:29,Breaking legal drafting so far.
2023-07-19 01:00:59,It was mentioned somewhere that the red teaming for it isn't complete yet.
2023-07-19 01:01:21,Yeah rule following is going to be challenging with 7B and 13B.
2023-07-19 01:11:31,Interesting
2023-07-19 01:12:48,Better as in fewer violations
2023-07-19 01:13:21,"Yes 70B is better overall as well as more ""aligned""."
2023-07-19 01:13:59,honestly MPT-30B is still looking pretty good against it.  u have to go all the way to 70B to really beat MPT in many cases
2023-07-19 01:14:21,Github - https://github.com/a16z-infra/llama2-chatbot
2023-07-19 01:18:29,30B is good range for trying commercial use cases. Let's wait for the 34B llamav2 drop.
2023-07-19 01:18:31,Has anyone tried any code generation usecases so far with Llama2 ?
2023-07-19 01:18:57,Llamav2 34B benchmarks are very good.
2023-07-19 01:19:53,"Yeah, coding is bad as HumanEval score is worse than even WizardCoder."
2023-07-19 01:20:03,There was a lot of emphasis on safety and responsible use in the press release.
2023-07-19 01:21:40,We also need their 27k SFT dataset. Hope they release it.
2023-07-19 01:29:13,They refer to the Chung paper in the sft section:
2023-07-19 01:31:16,"Yeah, they also curate and annotated 27k samples."
2023-07-19 01:33:47,What exactly was the data ?
2023-07-19 01:35:57,They mention they have avoided using Meta users data as well as websites that have a lot of public info about individuals.
2023-07-19 01:38:22,I'll hold off on more spam from the paper. Too many good things to share and a detailed technical paper. I'll compile it all in one go.
2023-07-19 01:45:21,Me too :)
2023-07-19 01:50:39,"Scale is open-sourcing their library to host and train llms, including llama2  https://twitter.com/alexandr_wang/status/1681370165521334273"
2023-07-19 01:52:13,"Many folks were looking into building around this concept, thought about sharing it here"
2023-07-19 01:54:57,In non llama news :
2023-07-19 03:55:04,"Looking for this results... currently i am running xgen 7b , which sometimes does not give good results on context.."
2023-07-19 05:45:13,Interesting twitter space:
2023-07-19 06:01:36,"Done with combing the paper. It is a very lucid read and recommended to go through it. For those who may want to instead read an *informal dissection of the paper, here are my thoughts on it*"
2023-07-19 06:49:20,"👆Hopefully this is useful for folks, please DM me if you need any help."
2023-07-19 07:52:51,Credits: 1littlecoder
2023-07-19 08:00:55,"Satya is real deal not just in SF but the entire tech industry. From MSFT era of say no to open source to acquiring GitHub, building Copilot, & now integrating Llama 2."
2023-07-19 08:50:00,Very interesting comment from an hn comment:
2023-07-19 09:21:28,I think most of us were trying the chat endpoints using 13b.
2023-07-19 09:26:34,There was some discussion yesterday about GPT performance degrading considerably over the last few weeks/months.
2023-07-19 09:28:12,I really enjoy their videos.
2023-07-19 09:32:21,moved my local llm setup to llama 7b it's pretty food reasoning and not to bad with json either
2023-07-19 09:39:29,"Good to have this rigorously tested,especially on the code generation part.I thought I was hallucinating "
2023-07-19 09:42:57,https://twitter.com/davefontenot/status/1680736983633768454?s=46
2023-07-19 09:43:44,What’s your setup exactly?
2023-07-19 09:44:16,Are you challenging the Indian VCs in this group to offer this? 🤣
2023-07-19 09:46:15,"For context, HF0 is offering 2.5% equity at $500K uncapped — better terms than YC"
2023-07-19 09:48:53,What does the 2.5% fee mean?
2023-07-19 09:53:07,Equity against the $500K investment
2023-07-19 09:53:50,Equity by default in all from program . 500K is over that on an uncapped note
2023-07-19 09:54:24,not exactly true! They take 2.5% equity in the co of founders who go through the program and then invest $500k on an uncapped SAFE separately
2023-07-19 09:58:00,Being wrong on the Internet continues to be the fastest to learn. Can you please explain what does separately mean here for most readers who don't know what capped vs uncapped SAFE might mean?
2023-07-19 10:00:05,"For his statement to be true, the startup needs to raise the next priced round at a valuation of over $10M - which most AI startups today will be able to do. "
2023-07-19 10:00:39,So in all fairness it’s a great deal
2023-07-19 10:02:22,Will plug YC's explainer because the instrument originates from them! the $500k has a MFN provision which means:
2023-07-19 10:02:28,"Helpful explainer, thanks!"
2023-07-19 10:02:57,https://hu.ma.ne/media/humane-names-first-device-humane-ai-pin
2023-07-19 10:04:05,Ex apple guys
2023-07-19 10:04:28,"Actually I'm not sure if [PHONE REMOVED] means that the 500k funding happens only when you raise round from others...while 2.5% is asked for immediately. Cos that's the only way a ""fee"" makes sense"
2023-07-19 10:06:16,Shouldn't be the case. And they should really explain this better.
2023-07-19 10:08:21,"1. Yc offers 150k at 7pc, hfo is 2.5%"
2023-07-19 10:09:10,"Money will come in now. If not, it's the sweetest, most predatory option cheque any VC can write."
2023-07-19 10:15:56,Yes please 😂
2023-07-19 10:26:55,I think that's what the previous message was about - cos it was structured as a fee+equity.
2023-07-19 10:33:53,I love how every new model adds on to a good 20-30 minutes of reading just through this group. And in that time nirant already has a demo out....
2023-07-19 10:37:05,"Love this, I'm not sure if you're already doing it for other papers but this would be awesome"
2023-07-19 10:48:24,"Curious what the trade-offs are for raising in India vs the US, for new companies."
2023-07-19 10:49:14,New = still can choose where to incorporate
2023-07-19 10:51:53,Agree. The wording around ‘fee’ is really confusing for sure.
2023-07-19 10:52:29,"I've too much to say on this, let's talk on the Startup Ecosystem group admin'd by [PHONE REMOVED]"
2023-07-19 10:53:18,"Money is wired when you're accepted. Terms that the SAFE converts at only gets decided when you raise from others, and the 2.5% is asked for immediately is what my read was"
2023-07-19 11:15:17,I thought this was the point of people submitting their eval datasets to openai. Hard to track drift without knowing what a model is being used on. At least in the current state of the tech.
2023-07-19 11:18:57,This was the key in being able to make it open.
2023-07-19 11:21:49,The meta training cluster has years of optimization on the network and storage. I don’t think these numbers would translate if someone else tried to do pretraining in their infra. The GPUs would probably be underused without all the optimizations we did a couple of years back.
2023-07-19 11:27:14,Context: Diptanu works with Facebook AI
2023-07-19 11:31:49,"I used to, until very recently :) I worked on speech recognition models and back in the day led FBLearner(the machine learning platform) so I have some knowledge about the training cluster."
2023-07-19 12:05:46,[PHONE REMOVED] could you tell us what kinds of tools you used to benchmark and optimize GPU utilization? Any guiding principles?
2023-07-19 12:46:59,"Have hosted Llama 7B, 13B and 70B, all Chat versions — with 3 Most recent Message History!"
2023-07-19 12:47:43,"Using replicate API endpoint , right ?"
2023-07-19 12:49:47,"Thanks for hosting Nirant, a noob question. Are you using llama.cpp for running the model or something else?"
2023-07-19 12:50:23,"Yes, Replicate A100s with some prompt engineering"
2023-07-19 12:50:26,Anyone getting 502 errors a lot in the replicate endpoints
2023-07-19 12:50:46,"Running with torch, llama.cpp still has some web deployment challenges"
2023-07-19 12:52:03,"Most relevant article that I found. At the end of the day, everything is ML : https://www.sequoiacap.com/article/ai-paradox-perspective/"
2023-07-19 12:57:02,"At a high level standard tools from nvidia. Have you looked at NVML? Most of the high level tools are built on top of it. We had a bunch of tools on top of nvml. There were various visualizations to understand bottlenecks in moving data over the pcie bus, or between nvlinks, memory usage, sequence of copies between devices, gpu utilizations, and various other techniques."
2023-07-19 12:58:36,Take a look at nsight as well.
2023-07-19 13:03:45,Interesting read
2023-07-19 13:05:33,Thanks.
2023-07-19 13:11:17,i use text-generation-webui on an m1 pro 32gb run a lot of experiments with various models using the local api endpoint
2023-07-19 13:31:46,"For running on Mac, we also have CoreML support for Llama v2. The speed is not great (6.5 Tokens/s) but the model isn't dumbed down due to quantization. Instead, coreml allows you to run the model with its regular 7B capabilities using the Apple Metal."
2023-07-19 13:31:46,Hi - Can anyone suggest any readings/doc/best practice/code on role-based access control (RBAC) for customized LLM bots?
2023-07-19 13:33:16,cc [PHONE REMOVED] runs a data security co
2023-07-19 13:35:41,Thanks [PHONE REMOVED]! 
2023-07-19 13:36:50,https://www.umt.edu/news/2023/07/070523test.php
2023-07-19 13:44:25,These are the cases where you want to peruse the test/benchmark and their assumptions.
2023-07-19 13:47:43,Claude was doing something similar. Everything was created by anthropic.
2023-07-19 13:54:21,I asked Claude if it took money from Sam Bankman fried. It said it doesn't have the ability to take money from anyone.
2023-07-19 14:18:33,"Start with ""You've the right to remain silent, you've the right to an attorney. Anything you say can and will be held against you in the court of law""."
2023-07-19 14:21:51,This is awesome! How much does it cost to keep up? Can pitch in
2023-07-19 14:22:58,"I just want a chat model that doesn’t say “As an AI model, …”"
2023-07-19 14:23:09,Be careful what you offer 😀
2023-07-19 14:23:41,"Nah, I think having something like this will be useful"
2023-07-19 14:23:41,Prompt it to reply otherwise 😉
2023-07-19 14:24:09,Yeah on Reddit people wirh chat model are able to generate NSFW conversations so I’m sure this can be bypassed
2023-07-19 14:34:22,"Jokes aside, ~$54 in last ~6 hours"
2023-07-19 14:39:09,UPI link to crowdfund ?
2023-07-19 14:39:16,Open source code interpreter 
2023-07-19 14:40:35,I like nat.dev model - let people login with credits they purchase but will require more hacking
2023-07-19 14:41:16,Why is it almost $10/hr - multiple gpus?
2023-07-19 14:41:17,"[PHONE REMOVED] will open up a community fund, where folks can patronise projects like these. That also gives us leg room on taking some moonshots"
2023-07-19 14:41:36,Don't want to take any non-trivial sums of money directly to my account for tax reasons 🙈
2023-07-19 14:41:42,"yeah please do, I think this is an awersome idea"
2023-07-19 14:42:23,"A100, 40G, and 80G."
2023-07-19 14:42:40,There are about ~15 people live right now
2023-07-19 14:44:22,how many can it host simulateously
2023-07-19 14:44:34,Wonder how chat gpt3.5 is so cheap
2023-07-19 14:44:38,In comparison
2023-07-19 14:44:49,Someone said online they’re operating at a loss but I don’t believe it
2023-07-19 14:45:33,I thought Nirant will do a series A with this 😂
2023-07-19 14:52:08,"I'm using the Replicate API/host with some changes, because I wasn't sure of enough utilisation."
2023-07-19 14:52:09,On a streamlit app? How tf
2023-07-19 14:52:25,Paper for reference
2023-07-19 14:53:45,Inference via api hosted on mentioned GPUs. I think replicate.
2023-07-19 14:54:18,"No a streamlit app will just choke if you have too many concurrent users, like the ui will just never load"
2023-07-19 14:54:32,maybe the streamlit cloud has autoscaling
2023-07-19 14:54:34,"I'd like to think I can raise on revenue, even if it's tiny, don't want to raise on demos 🙏"
2023-07-19 14:55:08,How is together.ai doing a100 at 0.2$ ?
2023-07-19 14:59:27,They probably bought/leased A100 over something like Heztner/NVIDIA Cloud with VC money and are discounting some of the token pricing
2023-07-19 15:00:38,"That issue still exists. Just limit is higher around 20-30 users. And I wrote the code using ```session_state``` — that reduces memory footprint, and seem to help."
2023-07-19 15:01:45,[PHONE REMOVED] redpajama on a100 is 0.11 per hour
2023-07-19 15:01:52,How ?
2023-07-19 15:03:33,That's through shared GPU RAM via parallel loading of 1-2 copies of the same/different model on same GPU RAM. Improves RAM util drastically.
2023-07-19 15:04:11,"That's why it's 80G, should be 3-4 copies of a 7B model or so without quantisation"
2023-07-19 15:04:32,"Lest my language mislead, I'm also guesstimating here"
2023-07-19 15:12:40,Not sure if these guys are using the same but vLLM does the same by using paged attention for batch processing multiple users across a bunch of GPUs
2023-07-19 15:45:09,How do we sponsor though? :)
2023-07-19 15:50:25,"will share hasgeek link stuff over next week, not right now"
2023-07-19 15:52:47,"Sorry If I missed the github link, share again?"
2023-07-19 15:53:28,https://github.com/nirantk/llama2demo/blob/main/app.py
2023-07-19 16:38:37,https://twitter.com/dwaynecodes/status/1681516290224300033?s=48&t=znJuLB47JquSWFAB2H-7yg
2023-07-19 16:38:39,Has anyone here noticed any significant drop in quality in GPT4?
2023-07-19 16:45:10,[PHONE REMOVED] had posted this a few days back...
2023-07-19 16:46:00,Wait someone did a paper on this. They did find issues
2023-07-19 16:47:36,"Yeah, makes mistakes more often. Doesn't follow instructions properly every now and then."
2023-07-19 16:48:10,This one - https://huggingface.co/papers/2307.09009
2023-07-19 16:49:35,"Yes, I think this was the one. My experience has been for detailed prompts it's better. But system instruction is rendered meaningless. Rather put everything as user instruction"
2023-07-19 16:51:30,"Replicate is serverless, right? only charged when you send a request"
2023-07-19 16:52:35,"The LLM api abuse is very common, so do have some rate limiting/cap"
2023-07-19 16:52:50,"Yes. But charges by compute used, not tokens"
2023-07-19 16:53:10,Yes thank you sir I just read that
2023-07-19 16:55:13,wish there was some easy way to use the laptop's ideal GPUs with a private SETI like network
2023-07-19 16:56:08,"I assume good faith. Will adapt when proven wrong, not till then :)"
2023-07-19 16:57:14,please don't assume good faith while exposing a public free service lol
2023-07-19 17:00:10,I've log streaming open in a tab 🫣
2023-07-19 17:09:16,NimbleBox folks have hosted the LLaMA 2 13B onto chat.nbox.ai
2023-07-19 17:21:38,https://chat.nbox.ai/
2023-07-19 17:34:22,Surprisingly good
2023-07-19 17:35:01,The 13b model
2023-07-19 17:35:55,The 70B model should by up by tomorrow!
2023-07-19 17:37:17,This is fp16 or int8?
2023-07-19 17:38:40,fp16
2023-07-19 17:40:30,Can you also add emojis to collect feedback data ? Would be valuable if you decide to do RLHF later
2023-07-19 17:41:20,Sure! I will pass along the feedback to the team 😁
2023-07-19 17:43:58,This is same as chatgpt api
2023-07-19 18:03:52,"Yeah, cost is comparable. The openrouter api allows me to switch between the models without losing the conversation context. I often work on critical things with GPT4 and then switch down to Claude v2. Even now, I'm using llama 13B to chat and if it's response isn't good enough I'm moving to other models for tasks. I talk to all these models on chatbot UI with exact same interface as chatGPT, can save prompts, conversations and organise them in folders as well."
2023-07-19 18:05:59,Openai functions aren't generating valid jsons anymore 🙈
2023-07-19 18:34:27,Looks like chatGPT was indeed nerfed since March
2023-07-19 18:37:05,How's 3.5 improving and 4 drastically reducing?
2023-07-19 18:37:25,Alignment and quantisation
2023-07-19 18:37:34,MoE. Kill one of the experts.
2023-07-19 18:37:54,Bigger models are harder to predict how quantisation will affect performance
2023-07-19 18:38:34,Plus they might have changed the post processing and reranking
2023-07-19 18:38:47,Experts are overrated 🤣
2023-07-19 18:40:02,"Reminds of that old anecdote that everytime someone fired an linguist, their NLP system perf went up"
2023-07-19 18:41:09,https://www.interconnects.ai/p/llama-2-from-meta
2023-07-19 18:56:27,Curious on test set? What made it surprising :)
2023-07-19 19:08:58,https://llama.perplexity.ai/
2023-07-19 19:14:17,How is it so fast
2023-07-19 19:14:31,API distillation from the bigger model is helping out learn better most likely.
2023-07-19 19:15:04,Quantisation?
2023-07-19 19:16:10,What's the consensus on current best model for writing code? Is gpt 4 still on top?
2023-07-19 19:16:35,"The founder didn’t mention any specifics in his announcement tweet, just that it’s using their own inference infra"
2023-07-19 19:17:35,"Yes, but StarCoder cousins like WizardCoder are quite good and better than Llama etc"
2023-07-19 19:27:30,"As per the semianalysis ""leak"", it is not quantisation."
2023-07-19 19:28:02,"Take it with a bucket of salt though, nothing is verified."
2023-07-19 19:29:39,Model with open dataset and verified results - codegen 2 16B. Model that is on top of open source Humaneval but can't guarantee because no arch change or dataset released - WizardCoder
2023-07-19 19:57:04,Twitter?
2023-07-19 19:57:09,LinkedIn
2023-07-19 19:57:30,https://www.linkedin.com/posts/desaipranay_are-you-seeing-this-feature-on-linkedin-activity-7086917502189932546-OHq3?utm_source=share&utm_medium=member_desktop was my last post
2023-07-19 19:58:19,True
2023-07-19 20:29:49,Does anyone know of a platform that allows to invoke babyAGI or autoGPT kind of agents over API ?
2023-07-19 20:34:52,Platform? Or sandbox?
2023-07-19 20:35:30,"platform, like a vercel for Agents."
2023-07-19 20:39:14,https://www.linkedin.com/posts/younes-belkada-b1a903145_fine-tune-llama-2-with-few-lines-of-code-activity-7087412907029737472-_5-u?utm_source=share&utm_medium=member_android
2023-07-19 20:41:41,Flowise maybe? Its a visual ui for langchain and has a autogpt template...
2023-07-19 20:43:04,That's Replit
2023-07-19 20:57:28,https://replit.com/@YoheiNakajima/BabyElfAGI?v=1
2023-07-19 20:59:53,Here are other AI templates:
2023-07-19 21:27:58,That’s not allowed as per license
2023-07-19 21:28:27,I love how entire code is in a screenshot :)
2023-07-19 21:28:48,How are you imagining it? Won’t a simple VM do
2023-07-19 21:35:25,Is there an online meeting product specially for group meetings which breaks meetings in smaller ones and you join only when you need to join? 
2023-07-19 21:35:39,Are the llama models safetensors?
2023-07-19 21:36:11,Yes. I think they mentioned this somewhere
2023-07-19 21:36:27,Check filo. Might serve your constraints.
2023-07-19 21:36:57,Thanks. Somewhat skeptical of downloading model files as is.
2023-07-19 21:37:16,Yes but I was replying to why GPT3.5 getting progressively better. Guessing it may be using API distillation from GPT4.
2023-07-19 21:37:47,"yes, downloaded and tested. Safetensors format."
2023-07-19 22:37:05,This was cool. E2E episode Generation
2023-07-19 23:11:37,https://www.bloomberg.com/news/articles/2023-07-19/apple-preps-ajax-generative-ai-apple-gpt-to-rival-openai-and-google
2023-07-19 23:22:27,Something's cooking up in Cupertino for sure !
2023-07-19 23:25:10,Even few simple use cases added on Siri will be quite something 
2023-07-19 23:25:20,Anyone got update for their voice cloning feature ?
2023-07-19 23:25:54,iOS I mean
2023-07-19 23:32:50,Is it actually good ? Like you've tried it ?
2023-07-19 23:36:45,Microsoft also announced their voice cloner to GA today. But have to jump through hoops to get it approved
2023-07-19 23:38:00,Marcus Brownlee had it in his ios 17 review - was ok not great
2023-07-19 23:39:04,"So crazy man, it's like you'll talk to yourself one day 😂"
2023-07-19 23:43:38,LTT's Mac Address also had a review and it was decent
2023-07-20 00:06:21,This was 🔥
2023-07-20 01:26:12,"Interesting timing, considering the ongoing writers and actors strike and their demand for not using AI in initial draft gen"
2023-07-20 04:33:16,was playin around with 70b thanks to Streamlit app hosted by [PHONE REMOVED]!
2023-07-20 05:10:31,https://twitter.com/nonmayorpete/status/1681384734910484480?s=46&t=sa4ojT6cWjpBEV6860rrWw
2023-07-20 06:18:33,interesting! will try this
2023-07-20 08:00:53,Pretty great. Cast dialog of new characters seemed a little flat sometimes but still great
2023-07-20 08:19:29,It must have Hinglish in Latin script and not Hindi in Devnagri
2023-07-20 08:44:42,AI generated South park ep.
2023-07-20 09:51:09,And it’s the worst it’s going to be :)
2023-07-20 09:52:16,It will keep on getting better from this point.
2023-07-20 10:57:07,https://twitter.com/OpenAI/status/1681810240898215936?t=O2OzxlQRRlfoOJl0d8B37g&s=08
2023-07-20 11:01:16,Maybe they got their hands on more GPUs which enables them to increase the number of requests.
2023-07-20 11:07:43,GPT4 has also gotten significantly faster in it's responses. The costs for running it must have come down some way - more compute or some other optimisation.
2023-07-20 11:19:06,the new gpt4 model was faster. And I think Llama -2 has made gpt4 more faster. If you know what I mean
2023-07-20 11:21:33,Real power of Llama-2 is how it increased the rate limit of chatgpt plus gpt4 users
2023-07-20 11:21:43,some agi stuff I think
2023-07-20 11:26:32,I love how even amongst open source there is completion 
2023-07-20 11:27:23,"Let's see. Thing with opensource is, you will see more models pop up now."
2023-07-20 11:36:04,My fav links from the last couple of days :
2023-07-20 12:28:12,The first fine-tuned model based off Llama2 called Puffin
2023-07-20 12:29:29,*competition ?
2023-07-20 12:31:29,Yeah :)
2023-07-20 12:32:49,Ashish I don't think Redmond Puffin is trained on 2T tokens .. it's fintuned on some 3000 conversations
2023-07-20 12:34:04,And since they are tuned on GPT4 conversation data - you can't use them commercially
2023-07-20 12:35:49,Someone else can weigh in here. But the tweet you have put and this HF model card doesn't tally for me.
2023-07-20 12:36:19,It is just a Puffin version of Llama2
2023-07-20 12:36:28,Hermes will have a larger dataset
2023-07-20 12:37:09,Follow @Teknium1 on Twitter for the updates
2023-07-20 12:37:17,😟
2023-07-20 12:38:58,it is linked in my original post ! :)
2023-07-20 12:40:33,"In the second follow-up tweet he mentioned that it is fine-tuned on llama2, so 2T token and 4K length numbers are coming from there"
2023-07-20 12:40:34,"Hi, yes, sorry just taking a look at this"
2023-07-20 12:40:56,Has this been already resolved [PHONE REMOVED] ?
2023-07-20 12:41:18,Happy to help if not :-)
2023-07-20 12:41:47,"As far as the Auth for plugin goes, you just have to have a BEARER TOKEN"
2023-07-20 12:42:59,You can use this site to generate one: https://jwt.io/
2023-07-20 14:07:18,"I'll simplify it as there is a lot of ""marketing"" there which is just misleading amongst other things."
2023-07-20 14:10:55,Things of actual value to look forward to:
2023-07-20 14:19:49,"Back to a simpler question from my end. Any ready reckoners for chunk sizes for a knowledge base bot? If we know the embedding model, is there a direct or parametric relationship?"
2023-07-20 14:24:04,What’s special about wizard cider
2023-07-20 14:24:05,Coder*
2023-07-20 14:33:35,They have the best HumanEval (code eval) score for OSS models and theirs was a fine tuned llama v1.
2023-07-20 14:45:35,HumanEval is coding benchmark
2023-07-20 15:04:35,"Hi, can anyone suggest good libraries to use LLMs on dataframes? Basically, want to ask questions on tabular data and generate text responses/visualizations/dataframes. Thanks in advance!"
2023-07-20 15:05:52,I used the ootb openai apis with the 3.5-gpt model on a dataframe 👉 dict.  Worked great
2023-07-20 15:05:54,"You can look Yolo pandas. It's open source, uses langchain. It's a good starter. You can also customize your own looking at it"
2023-07-20 15:06:42,"would this work on larger dataframes, say > 1000 rows?"
2023-07-20 15:07:04,Absolutely.
2023-07-20 15:07:18,My dataset had 210000+ records
2023-07-20 15:07:59,I will try this out myself as well
2023-07-20 15:09:22,that way the llm can figure out how to call your api or apis
2023-07-20 15:15:27,for that number you can just use a csv file and a function to search it. if your ok with js/typescript checkout dosco/llm-client it supports function calling and reasoning
2023-07-20 15:15:40,"sorry, if this is naive, but can you elaborate on this part - dataframe 👉 dict ? Should I only include the headers in the context or the entire df?"
2023-07-20 15:24:07,You can put the entire df in the dictionary. But you'll have to preface the context with some info about the keys if it's something obscure .
2023-07-20 15:29:06,"I am not able to access the ChatGPT plus subscription, for some reason the card gets declined every time, any suggestion?"
2023-07-20 15:30:59,"My Axis visa credit card was facing the same problem, but was able to subscribe it via Citi Debit Mastercard"
2023-07-20 15:34:23,Hasn't citis operation in India taken over by axis
2023-07-20 15:36:29,"Yes, but i don't think the operations have merged yet. My take here is you should try with an international debit card if possible."
2023-07-20 17:25:43,Strangely I am facing this problem with my Singapore card as well
2023-07-20 17:26:14,Will try a different card provider
2023-07-20 18:06:58,"Hello folks, I am planning to buy chatgpt plus subscription, just curious if it can be used concurrently by multiple users at the same time."
2023-07-20 18:08:26,"No, it'll interrupt the older prediction stream. You can use the GPT4 API with a UI of your own unless you want Code Interpreter"
2023-07-20 18:12:13,"same query , 😄"
2023-07-20 18:15:48,The response will be fun though
2023-07-20 18:25:29,How’s the code interpreter api of langchain (https://github.com/shroominic/codeinterpreter-api)? 
2023-07-20 18:26:20,Not usable
2023-07-20 18:26:38,*Not as good as Code Interpreter
2023-07-20 18:27:07,i see
2023-07-20 18:43:36,Is anyone using code interpreter regularly?
2023-07-20 18:45:53,"You have some input data and you want to extract some info or transform it, just give it sample i/o pairs and it give correct code to do that. I’m mostly using to transform textual data."
2023-07-20 18:57:31,I have a question on the same lines.
2023-07-20 19:10:10,Anyone used it for ITR filing? Parsing AIS/TIS statements?
2023-07-20 19:14:02,https://www.assemblyai.com/playground/source
2023-07-20 19:15:05,The Conformer architecture is fascinating.
2023-07-20 19:24:45,"It is nothing new tbh, meta did it years back with attention + cnn"
2023-07-20 19:32:55,"Haven’t tried it, but would be able to do that. It iterates until it get it right"
2023-07-20 19:41:43,"quick prototyping with html, bootstrap + flask, adhoc python scripts for data transformation, csv formatting."
2023-07-20 19:56:57,new Chroma release
2023-07-20 19:59:54,"Wow, this is amazing"
2023-07-20 20:06:59,"Implementing papers, debugging."
2023-07-20 20:12:56,Implementing papers? Have you documented your workflow
2023-07-20 20:16:30,https://www.ycombinator.com/launches/J0X-cerelyze-tool-for-engineers-to-implement-research-papers-100x-faster
2023-07-20 20:16:38,There is a YC startup for this!
2023-07-20 20:20:08,"deep dive blog post, explaining the math behind inference latency/throughput and measuring actual inference performance"
2023-07-20 20:20:27,It's crazy. I gave it my 12-months roadmap and asked it to create a job description for an Engineering manager 😁
2023-07-20 20:22:13,data analysis / plots. 
2023-07-20 20:23:21,How do you share logs?
2023-07-20 20:23:22,Like share it with ChatGPT?
2023-07-20 20:25:09,"Ah, in my case, it's mostly edge computing devices that I have access to. So for now I just manually upload to the conversation context, and work with it to check whatever I would want to. "
2023-07-20 20:29:23,"Ah, nice use-case for the edge"
2023-07-20 20:32:43,Product analytics :)
2023-07-20 20:36:19,"While implementing papers,"
2023-07-20 20:37:38,What's y'all's opinion on the best audio-to-text model/service right now?
2023-07-20 20:48:23,https://nas.io/rubyAI
2023-07-20 21:15:06,"Wow, so good!"
2023-07-20 21:18:50,"I didn’t upload the paper, but just asked to implement it (SimCLR) from scratch in another session. "
2023-07-20 21:28:42,Interesting insights on when to use open source models vs gpt 3.5. 
2023-07-20 21:30:48,How is llama cheaper?
2023-07-20 21:30:57,Yud’s drone will be locking in your location soon 😂
2023-07-20 21:37:15,They did serve Llama on 2 80-GB A100 GPUs to have similar latency as gpt3.5 and did some experiments
2023-07-20 21:44:06,"Well don't know about drones but one thing's for sure, my method is wrong 😅"
2023-07-20 21:46:48,It is a bit confusing for me and thus hard to agree on the conclusion on where to use open source in terms of cost and latency.
2023-07-20 21:49:15,The best place to use open source models is in tasks where they cut the threshold of human preference and the nature of task has a higher margin of error.
2023-07-20 21:59:23,https://www.mayfield.com/ai-start/
2023-07-20 21:59:25,FYI
2023-07-20 23:12:59,This is just system prompt finally being exposed?
2023-07-20 23:28:58,"We already had an option for system prompt in the api, right?"
2023-07-20 23:30:00,"But now ChatGPT can remember facts about us with this, so this is definitely more than just that."
2023-07-20 23:34:05,"""Should ChatGPT have opinionr or remain neutral"" : I think this is the more interesting and fun part. Might be a pre election move too ?"
2023-07-20 23:40:53,Ohh nice 😂
2023-07-20 23:41:37,but the system prompts in api don't work as well . Does it work well in chatgpt?
2023-07-20 23:47:55,https://techcrunch.com/2023/07/20/openai-launches-customized-instructions-for-chatgpt/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAACkodA07EFcxbgQGidTVh_yXiHIWVoChTszAJczADa5xcbv09nrhXyMg3M7jP0TiqQQKaxV-_H0VPKW-cbY-crrsho0xwLuWNUwGTwDtbgfMkYFSsP2cUisFpZnC8CPniwO-8f_MBZbgl9pW7uzlrOYEDKNb-imV0x8nyi194rYU
2023-07-21 00:09:40,"I'd say, no. More like a persistent partial user prompt. system prompt carries extra privilege that user prompt is not supposed to have."
2023-07-21 00:30:17,"Also ChatGPT isn't passing the custom instructions as a system instruction, atleast not explicitly anyway"
2023-07-21 00:35:03,The api endooint for this is https://chat.openai.com/backend-api/user_system_messages
2023-07-21 00:44:50,Swyx on twitter already prompt injected the custom instructions prompt 😅
2023-07-21 00:47:15,he's doing the AGI god's work 😂
2023-07-21 00:52:05,Guess this is something related to the rumour about training GPT like models
2023-07-21 02:15:13,Because Linux processes have feelings too ! :)
2023-07-21 02:19:42,https://twitter.com/deliprao/status/1681651522529050632?t=a2rJ3WHLXKHddIVhWVyrMg&s=19
2023-07-21 02:22:05,if an LLM is trained based on characters instead of token i feel it will be able to generate palindromes
2023-07-21 02:22:59,Would you like to add a line or two why these tweets are interesting — so that folks can choose themselves if it's worth the click? 
2023-07-21 02:24:49,"It can generate palindromes and haikus independently, but not one which is both,"
2023-07-21 02:25:29,I doubt it can do palindromes even independently
2023-07-21 02:35:11,It really struggles with just simple palindromes
2023-07-21 02:36:42,"Not just palindromes - anything that requires compact representation of thought, and the search space is larger than what you can have finite combinations for, it struggles (eg 4 digit arithmetic)"
2023-07-21 02:40:50,https://fablestudio.github.io/showrunner-agents/
2023-07-21 08:22:09,Microsoft copied my AgentAI library design for Typescript 🙈🤣
2023-07-21 08:34:30,Woah!
2023-07-21 08:36:47,Everyone is forced to discover Pydantic types for their language.
2023-07-21 08:36:54,Mat karo na open source!
2023-07-21 08:37:02,Does anyone have good papers/documentation on how to preprocess(clean) tens of thousands of messages (conversations from Slack) for search retrieval?
2023-07-21 08:37:53,"OSS is the way, it managed to Microsoft to it's will!"
2023-07-21 08:38:25,"And that too Microsoft at it's Nadella-peak instead of Ballmer-peak (if you get the reference, you're a nerd)"
2023-07-21 08:40:38,"At the risk of spilling too much alpha, you need to tune the number of messages before and after a specific message (found via vector search) which you want to add to context. A common trick is to include messages sent in last mean + 1 sigma of that thread duration on both sides."
2023-07-21 08:41:33,Classic
2023-07-21 08:44:02,"The intuition is this: Energetic conversations often lead to folks sending ""shorter, bursty"" messaging style — so you're trying to capture some large fraction of that burst in the thread."
2023-07-21 08:46:45,true!
2023-07-21 08:48:48,what about cleaning data techniques? Are there some best practices?
2023-07-21 08:51:45,"Contextual question, broad ideas for human convos:"
2023-07-21 09:01:37,"Palindromes would be hard, cause after tokenization model is generating  the substring tokens and have no clue that particular token is a palindrome of another. Maybe you can show enough examples of palindromes during finetuning to force the model to output individual character tokens; but then the sequence length becomes too long."
2023-07-21 09:06:34,Beautiful! 
2023-07-21 09:09:35,"~$4/hr A100 on Modal, ready to go hyper-fast Llama2-13B with vLLM (paged attention) "
2023-07-21 09:39:13,It can also stick to structure with a low violation %. It's very similar to how Bing/GPT 3.5 was in the beginning.
2023-07-21 10:06:45,Cerebras launches CG1(condor galaxy 1) for g42 in the uae
2023-07-21 10:20:48,"cc [PHONE REMOVED] OSS investor, might be interesting to you?"
2023-07-21 10:56:17,has anyone here saved structured JSON to a vector db and used it later for generation usecases?
2023-07-21 11:06:24,Why dont you use the Mongodb vector functionality ?
2023-07-21 11:06:29,https://www.mongodb.com/blog/post/introducing-atlas-vector-search-build-intelligent-applications-semantic-search-ai
2023-07-21 11:12:06,ohh nice
2023-07-21 11:24:30,Drop a message to Joseph Jacks as well. He’s super nice and insightful
2023-07-21 11:29:05,"So, it's an interesting point...but largely orthogonal to my initial question."
2023-07-21 11:39:19,What's the equivalent of this in Python land?
2023-07-21 12:16:02,https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/
2023-07-21 12:45:39,"Any orgs / companies in India that are engaged in foundational model training ( vision, NLP etc )?"
2023-07-21 12:46:49,IIsC?
2023-07-21 12:47:32,"Zoho , [PHONE REMOVED] sir ( AI4Bharat)"
2023-07-21 12:52:40,What do you mean by foundation model in vision? Ppl have been training on imagenet for ages. 
2023-07-21 13:13:48,We are doing foundational models in NLP and ASR. But not in the traditional deep learning sense. Anything particular you are looking for?
2023-07-21 13:23:04,1. This is what I maintain: https://github.com/NirantK/agentai
2023-07-21 13:48:25,"Hey everyone, Prakash here from Harbor. We're working on leveraging AI to raise issues in code. Stuff I'm interested in - "
2023-07-21 15:23:01,What are some recommendations for training a pre-trained gpt model in a secure environment? Which providers for GPU? Is anyone trying mosaic or cerebras? Any thoughts on differential privacy?
2023-07-21 16:32:52,Any developer tried custom instructions in GPT plus which worked well for them? Please share :)
2023-07-21 16:35:01,Actually it’s not that new tools like perplexity were already doing that in form of “AI Profile” feature
2023-07-21 16:45:09,Example ^
2023-07-21 16:51:42,Use this for reference 
2023-07-21 16:55:24,Yes this was given by default to it to incoorporate that feature
2023-07-21 18:25:52,"""For example, a teacher crafting a lesson plan no longer has to repeat that they're teaching 3rd grade science. A developer preferring efficient code in a language that’s not Python – they can say it once, and it's understood. Grocery shopping for a big family becomes easier, with the model accounting for 6 servings in the grocery list."""
2023-07-21 18:26:48,"ChatGPT has come up with custom instructions, I'm afraid the responses would be too hyperpersonal. What does the group think?"
2023-07-21 18:37:16,has anyone used transformer model or existing LLM so far for now 'traditional' use cases like pattern recognition/anomaly detection?
2023-07-21 18:42:22,"Depending on what is meant to be secure (data or model), if you are looking for securing model IP, then selfish plug-Enkrypt AI can help out. Not aware of publicly available confidential VMs with GPUs, as they are still in the experimental phase."
2023-07-21 18:44:32,"For such traditional predictive tasks, LLMs can be used but they will be slightly inferior to corresponding SoTA models."
2023-07-21 18:45:37,"However, I've tested GPT4 for similarity detection and anomaly detection. It works amazing with few examples out of the box. But it's like bringing a tank to a gun fight and paying for the tank by the minute."
2023-07-21 18:52:39,Saves lot of copy pasting 😅.
2023-07-21 19:24:16,Has anyone been facing issue in running llama2 on mac m1? I keep getting: not compiled with GPU offload support
2023-07-21 19:27:52,That warning will be there since quantization on Mac is purely running on CPU. There's no GPU offload.
2023-07-21 19:42:31,Hmmm… it’s painfully slow.
2023-07-21 20:08:19,Run on google colab it's faster
2023-07-21 20:09:19,llama-2-13b-chat.ggmlv3.q4_0.bin
2023-07-21 20:09:20,https://github.com/camenduru/text-generation-webui-colab
2023-07-21 21:09:30,Doesn't work like this. You have to follow the steps. 
2023-07-21 21:09:52,For Mac GPU acceleration.. I did this on an M1 👆
2023-07-21 21:16:35,Awesome! I had attempted two methods to enable metal
2023-07-21 21:16:43,this one worked
2023-07-21 21:16:50,I must be doing some silly mistake
2023-07-21 21:24:32,A 7B model is supposed to be minimum 15-20 tok/s on M1/M2 pro
2023-07-21 21:24:58,"If you've less than that, then you can go back and check"
2023-07-21 21:28:32,What's the current best fine tuned llama2 which tries to reverse the effects of whatever RLHF they've done
2023-07-21 21:29:19,"There's a version that was finetuned by Teknium, I can't seem to find it on Hf right now"
2023-07-21 21:33:56,Nous Hermes?
2023-07-21 21:34:29,I believe so yes. That's the one.
2023-07-21 21:34:57,Here you go
2023-07-21 22:08:34,I see significant coding capabilities in llama2 7B after fine tuning it on 122k coding instructions
2023-07-21 22:09:06,"So far it is able to answer all basic programming questions in C, python with basic algos, OS and file operations"
2023-07-21 22:09:36,It's just 7B and it has gotten so good i can't wait to test out results on the bigger models.
2023-07-21 22:10:23,"After quantization, it can definitely be good enough for boilerplate stuff in complete enterprise environment"
2023-07-21 22:12:29,"The Llama2 model wasn't RLHF trained, the Llama2-Chat models were"
2023-07-21 22:14:21,"Ok, but llama2 base is not instruction fine-tuned right? So not usable directly"
2023-07-21 22:17:25,"The RLHF adds both helpfulness (adherence to structure/request) as well as safety mechanics, so it is more useful to use it with RLHF. Instruction tuning seems to be taking care of issues with its extreme safety mechanics."
2023-07-21 22:18:35,I thought you wanted a model without RLHF .. then you can fine tune it to follow instructions
2023-07-21 22:18:59,Maybe give it a leetcode easy or medium problem ? :)
2023-07-21 22:21:20,"I mean, to un-kneecap it from whatever fine-tuning/RL they've done to make it ""safer"", i.e. stop it from refusing to follow basic instructions because it flags them as unsafe"
2023-07-21 22:22:39,You can't unlearn in LLMs .. some experts can confirm or deny this
2023-07-21 22:22:41,"It seems to be doing fine with easy level stuff. Like binary search, Fibonacci etc"
2023-07-21 22:23:59,Super can you share how you did it ?
2023-07-21 22:24:14,You finetuned it on coding instructions?
2023-07-21 22:24:40,"Yes 122k, commercially licensed. No GPT4 stuff"
2023-07-21 22:25:03,Waah! That's pretty cool
2023-07-21 22:25:31,https://huggingface.co/TokenBender/llama2-7b-chat-hf-codeCherryPop
2023-07-21 22:26:03,The repo contains the jupyter notebook used in the fine tuning
2023-07-21 22:26:44,"30min fine tuning on A100, cost around 1.5-1.6 USD after cleaning up the pipeline"
2023-07-21 22:37:35,Hey Abhishek any where to read this process ? Do you have a blog or any pointers ?
2023-07-21 22:37:43,You used auto train ?
2023-07-21 22:39:10,SFTTrainer I guess.
2023-07-21 22:41:29,"No, i used TRL SFTtrainer, autotrain advanced installs everything from scratch and my python dependencies started breaking. You can check the repo, it contains the steps and the library used"
2023-07-21 22:43:24,Fine tuning latest models isn't standardized right now. You can try to change the dataset or the model without touching anything else and stuff would start breaking.
2023-07-21 22:47:41,Thanks !
2023-07-21 22:47:55,You should launch your model like WizardLM 😇
2023-07-21 22:59:45,It's a bottom of the barrel model 😂 but after quantization it can be valuable for sure.
2023-07-21 23:00:54,"I'll try 8k context via RoPE enhancement as well, let's see if that degrades performance or not."
2023-07-21 23:02:43,cc [PHONE REMOVED] want to eval this for ragas?
2023-07-21 23:05:44,"RAG dataset prep is in-situ for me, this can be tried for RAG but a dedicated model for citing discipline, saying no when context doesn't contain answer and answering from multiple context chunks might do better. "
2023-07-21 23:09:40,For folks interested in fine-tuning - I thought this is a well written article - https://medium.com/mlearning-ai/fine-tuning-alpaca-enabling-communication-between-llms-on-my-m1-macbook-pro-e3234f29c8ae
2023-07-21 23:23:36,"Has anyone benchmarked llama2 vs gpt4 on some standard use cases (text, code, summarisation, analysis etc) in terms of accuracy, latency, cost?"
2023-07-21 23:36:42,Is Perplexity AI  or Poe worth paying for if you already own ChatGPT plus?
2023-07-21 23:40:18,https://news.ycombinator.com/item?id=36775396
2023-07-21 23:42:57,https://news.ycombinator.com/item?id=36778932
2023-07-21 23:43:47,"Perfect, exactly what i was looking for! 🙏"
2023-07-21 23:52:51,"Hey Everyone! Can someone suggest to me a really good experiment tracking tool for LLM's n APIs. Like there are many tools for tracking llm prompts, outputs etc like the trace table in w&b n others, but I'm specifically looking for a capturing tool that can track the change in the approach of the code/function as well. Like apart from tracking the time/date, input, prompt, output n other stuff it would also be helpful if it could capture the change in the script compared to the previous run"
2023-07-21 23:54:34,What do you mean by change in script?
2023-07-21 23:55:27,"Like the change in the python code, like mostly any preprocessing or post processing methods we use before or after the llm call"
2023-07-22 00:07:09,Ultimately everything comes down to parameters and prompt
2023-07-22 00:14:26,Git commit on file save/LLM run?
2023-07-22 00:24:29,Recording playlist for the event in case anyone’s interested -
2023-07-22 00:29:02,https://www.producthunt.com/posts/benchllm-by-v7-1
2023-07-22 01:17:47,https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models
2023-07-22 01:43:05,"This is wild speed llama 2 replaced within 3-4 days of being leaderboard topper , this shows importance of orca styled model training / fine-tuning."
2023-07-22 02:35:39,https://twitter.com/openai/status/1682480558545461249?s=46 
2023-07-22 02:45:46,Gpt ios app was a haptic delight
2023-07-22 02:45:47,However used it only once
2023-07-22 03:21:58,I love how OpenAI drops big announcements every friday!
2023-07-22 04:49:24,Cc [PHONE REMOVED] and I'll have this via the llama2demo for latency and cost. Looks like llama2demo is gonna win on cost and latency in most predictable workload situations
2023-07-22 05:33:54,Perp gives 75 per 3hrs compared to gpts 50. I have both
2023-07-22 06:05:02,https://www.philschmid.de/llama-2
2023-07-22 07:08:11,https://labs.pplx.ai/
2023-07-22 08:08:46,Is there an llm that can give instant results. I tried mpt 30b and mpt 7b. Both take several minutes to give a result
2023-07-22 08:11:15,It depends on your hardware.
2023-07-22 08:11:29,I have an a10
2023-07-22 08:12:26,"Ok got it , thanks!"
2023-07-22 08:15:48,Feels faster than other endpoints !
2023-07-22 08:16:22,UI is also sleak and clean
2023-07-22 08:17:30,Depends on your setup Sumedh ... how have you set it up. 64GB RAM ?
2023-07-22 08:17:53,It's 96gb on sagemaker
2023-07-22 08:17:57,4 GPUs
2023-07-22 08:18:02,But the results are so slow
2023-07-22 08:18:09,I also did contg.init as meta
2023-07-22 08:23:42,With 3090 exllama GPTQ is giving 40+ tps. Should be around 25-30 on a10.
2023-07-22 08:25:06,7b version
2023-07-22 08:37:30,https://www.alessiofanelli.com/blog/llama2-isnt-open-source
2023-07-22 08:39:30,https://huggingface.co/stabilityai/FreeWilly2
2023-07-22 08:54:25,I loggedin my chatgpt plus account to a friends computer and forgot to logout any way to logout from all devices? I signed in with google changing password and logging out google account didn’t work ! Any help is much appreciated thanks <3
2023-07-22 09:14:49,"I think you can't have multiple active sessions with chatGPT anyway. So the session where you've currently logged in and using should stay, the other one would expire and would need login."
2023-07-22 09:15:58,Code interpreter isn't there on perplexity
2023-07-22 09:16:48,I think we can have a few. I've definitely had 2-3
2023-07-22 09:17:24,Ohh
2023-07-22 09:20:08,"I guess it generates response for only one session at a time, but we can have multiple sessions"
2023-07-22 09:20:46,Could be
2023-07-22 11:31:01,ChatGPT doesn’t have Internet access with coding capabilities 
2023-07-22 11:31:22,Nope it isn’t that way you can try yourselves
2023-07-22 11:32:52,Still the feature of reading files in Code Interpreter is important ! Perplex guys are going to add that anyways soon
2023-07-22 11:32:54,Does perplexity run code as well?
2023-07-22 11:33:11,*python code
2023-07-22 11:33:15,😅
2023-07-22 11:33:18,Paged Attention with Quantization ftw
2023-07-22 11:34:16,If it runs then great.
2023-07-22 11:34:39,Nope it doesn’t but I was saying that interpreter runs only python code
2023-07-22 11:35:19,It needs sandboxed environment so it would need more investment and they have just started so don’t see that coming soon
2023-07-22 11:37:12,I get that. One selling point for my product is that it has much better browsing than chatgpt with browsing did.
2023-07-22 11:38:28,Yeah as I said ability to read files is highly missed not just due to code interpreter also due to claude so they’re working on it
2023-07-22 11:39:09,This wasn't just ability to read files here. But yes
2023-07-22 11:39:11,Btw Perplex has 32k context whereas chatgpt plus doesn’t go more than 8k context in UI atleast.
2023-07-22 11:39:22,Atleast for me ….
2023-07-22 11:41:50,Nix sandboxes don't get the credit they deserve for powering both Code Interpreter and Replit. Might set that up and show how to hack your own sandbox with Gorilla LLM.
2023-07-22 11:43:43,"Ok, my sessions got terminated long back when I used to switch between mobile and laptop so i had that notion."
2023-07-22 11:44:08,No problem
2023-07-22 11:44:21,phind.com does this very well. Currently their pair programmer option isn't available for some reason but they are good.
2023-07-22 11:45:15,Yeah ik that also but they are currently not that stable
2023-07-22 12:06:50,"After all the OpenAI api eval upheaval of the last few days, there's a claim that the python eval was not conducted correctly after removing the markdown tags leading to the drop in perf. "
2023-07-22 12:21:24,This would be interesting.
2023-07-22 12:28:36,It's a little weird to see people dunking on Matei. 
2023-07-22 12:32:51,Folks can run their own eval and improve Matei's work. This is something we can run on our own and check. It's barely $50 or so. 
2023-07-22 12:33:19,Neat! I didn't know about Nix sandboxes. I thought it was something containers or Firecracker (the one which aws serverless uses).
2023-07-22 12:34:18,NixPack for folks wanting to build to their sandbox with Nix
2023-07-22 12:35:09,+1 to this 
2023-07-22 12:36:08,The analysis provided these authors is well balanced without any gas lighting or hype 
2023-07-22 12:38:22,"Being new to Evaluation ,a noob question "
2023-07-22 12:47:01,https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models
2023-07-22 12:52:56,i am huge fan of random_walker.
2023-07-22 12:59:47,"""We are grateful to the authors for making their experiments so easy to reproduce"""
2023-07-22 13:04:19,Do we have a router that can route a request to llm provider depending on the task?
2023-07-22 13:07:16,We will be removing this list of users without any more notices after this. 
2023-07-22 14:23:54,what is the max token limit for Llama2 inference?
2023-07-22 14:27:49,It's open source ??
2023-07-22 14:28:13,Do you mean context window ?
2023-07-22 14:29:14,Yes
2023-07-22 14:30:07,Iirc it was 4000 tokens
2023-07-22 14:30:24,Ok thanks
2023-07-22 14:43:02,Purge time
2023-07-22 14:46:06,😂
2023-07-22 14:46:37,Mass firing
2023-07-22 14:48:29,"Agreed. There used to be a designated workshop on reproducability in NeurIPS, ICLR etc."
2023-07-22 14:54:03,"Sorry for the announcement here, too many calls 🙈"
2023-07-22 14:54:05,"Yes, ideally it should be agnostic of the markdown wrapper if the goal is to measure code synthesis. Rn, it seems to be more of a response eval."
2023-07-22 14:58:23,Please share slides later if possible
2023-07-22 15:07:34,https://youtu.be/MACR50bJX7Y
2023-07-22 15:37:56,+1 would love to see slides/recordings
2023-07-22 15:39:51,https://microsoft.github.io/TypeChat/blog/introducing-typechat/
2023-07-22 15:39:51,"Hello Folks, I have a few questions regarding text splitters.  "
2023-07-22 16:10:23,Looking forward for slides
2023-07-22 16:13:00,+1
2023-07-22 16:16:54,+1
2023-07-22 20:21:17,*Job Openings*                                                                                                                                                        
2023-07-22 20:31:14,"Hello All, I’m Parna from The Nudge Institute 👋working towards a poverty free India. "
2023-07-22 20:32:12,What topics were covered here?
2023-07-22 20:32:19,cc Dr. Pratik [PHONE REMOVED] from KissanAI and Dev [PHONE REMOVED] from farmer.chat
2023-07-22 20:33:23,https://nirantk.com/talks/ai4bharat/
2023-07-22 20:33:25,RAG System Design 101 & LLM functions 100: https://nirantk.com/talks/ai4bharat
2023-07-22 20:34:31,Nice.
2023-07-22 20:34:49,Very impactful mission Parna !
2023-07-22 20:35:21,A year back RAG wasn't unique as a technique but this level just wasn't there.
2023-07-22 20:37:25,Have a look at speak.com
2023-07-22 20:40:12,Thanks Anubhav! Actually I have used the app it’s pretty good 👌Unfortunately couldn’t find any contacts to discuss how to bring down costs
2023-07-22 20:41:30,"Sure I'll look around, an ML lead left the company a while back to start his own thing now part of YC S23. Let me check with him"
2023-07-22 20:45:36,"We have built one with voice, while the science is covered well, the problem is with the Math skills even at GPT4 level, open source one are very well behind and not reliable to deliver consistent results."
2023-07-22 21:18:50,"Hi Parna, we invested in Stimuler.tech please check them out.  My colleague [PHONE REMOVED] who’s a Sr Associate and AI engineer, helped Stimuler optimise their Model Architecture."
2023-07-22 21:41:04,DM’ing you 
2023-07-22 21:45:16,"Thanks, Nirant. I'm in touch with The Nudge and [PHONE REMOVED]. Happy to assist any way possible."
2023-07-22 22:48:26,Anyone heard of/tried Giga ML ?
2023-07-22 22:51:24,https://9e90643c93e48d8bba.gradio.live/
2023-07-22 23:20:33,Geoffrey Litt has some really inspiring ideas on building software.
2023-07-22 23:24:46,Linear algebra and calculus in corner 👌😏
2023-07-22 23:26:31,Converges to Philosophy.
2023-07-22 23:54:30,https://www.youtube.com/watch?v=PJnLvNGStSw
2023-07-22 23:59:56,"Haha, you found it out before me. Seeing first time here."
2023-07-23 01:41:30,https://www.llama-api.com/ - implementation of AI Functions on open-source models llama
2023-07-23 01:47:19,their claim is wrong llm-client has had llm independant function calling and reasoning for a while now https://github.com/dosco/llm-client
2023-07-23 03:36:53,Has anyone tried using the Petals project? 
2023-07-23 07:58:15,Weekend watch !
2023-07-23 09:31:26,"I tried it last week. Didn’t fine tune. But tried some larger LLM models for inference. Pretty good, got pretty nice latencies running from Colab. Was a quick way of trying them out."
2023-07-23 10:58:07,https://www.youtube.com/watch?v=uoidu62qXyQ
2023-07-23 11:15:34,Does Anyone know about SELF SOVEREIGN IDENTITY using blockchain market in India??
2023-07-23 11:15:54,Want to knw if someone knws of any company thats doing it
2023-07-23 11:25:26,Very off topic. There are better suited forums for this. 
2023-07-23 11:28:16,Authenticity in the age of AI is a real threat to society
2023-07-23 11:28:20,Why is this off topic?
2023-07-23 11:34:54,Will request moving this to Policy & Philosophy group — that's a much better suited place for these conversations
2023-07-23 11:39:04,There are specific groups in the community to be able to discuss some of these questions at depth. The philosophy and policy group has these discussions on the regular.
2023-07-23 11:39:41,33 tokens/sec on M2 with a Llama-v2 based Coding Assistant 
2023-07-23 11:42:13,Code instruction dataset - 122k coding instructions.
2023-07-23 11:44:30,Dataset is open - https://huggingface.co/datasets/TokenBender/code_instructions_120k_alpaca_style
2023-07-23 13:24:52,Anyone know how this is done? fine-tuning?
2023-07-23 13:27:32,https://twitter.com/MoritzLaurer/status/1682668392765956096?t=OgJHKqVjqeSIiMGa4gYkPQ&s=08
2023-07-23 13:31:13,https://news.ycombinator.com/item?id=36831956
2023-07-23 15:20:06,"From the information I have, It seems they injected the schema into the context window under the hood and hosted the llama model on modal labs."
2023-07-23 16:43:35,https://twitter.com/AlexReibman/status/1683008364606013440?s=20 - some interesting demos from AGI House AI Agents Hackathon
2023-07-23 16:52:39,I believe [PHONE REMOVED] was there IRL!
2023-07-23 17:00:16,Thanks !
2023-07-23 19:13:43,Is anyone using Guardrails in production?
2023-07-23 19:43:56,fun fact. the rent of one room at the house is 60k :p
2023-07-23 19:49:27,Is there any incubator house in India that does this?
2023-07-23 19:50:54,Unnecessary with new functions release of OpenAI. It seems Llama2 is also pretty good with functions-like behavior 
2023-07-23 19:52:10,if thats per month then cheaper than Bangalore! :)
2023-07-23 19:52:35,Sir. Dollars
2023-07-23 19:52:38,$$ me hoga sir
2023-07-23 19:53:01,What kind of incubator is that?
2023-07-23 19:54:35,https://www.scienceandcocktails.org/en/info/science-cocktails-copenhagen
2023-07-23 20:11:32,I have seen this happen more than once at daddys Indirangar
2023-07-23 20:23:41,700 dollars for a single room is much cheaper than anything available in SF 😅
2023-07-23 20:58:32,"Same! I imagine a cafe with a curated library, somewhat like The Interval at Long Now, in San Francisco: https://theinterval.org/about. Maybe on 80 feet road, right below the level of the tree cover, overlooking the road..."
2023-07-23 21:03:21,Yeah so a bookshop that curates books for mainstream by university philosophers and co-sabbatical place by the day (plus put art on its walls)
2023-07-23 21:03:55,It’s interesting to note that there’s no place where people on sabbaticals doing passion projects can assemble
2023-07-23 21:04:06,There are co-working places but no co-sabbaticals
2023-07-23 21:42:35,BIC has a cafe and a library and is a public place.
2023-07-23 21:43:21,BIC is beautiful
2023-07-23 21:44:11,superb then lets do this 🙈
2023-07-23 21:49:59,On my way.
2023-07-23 21:51:02,But what if someone isn't on a sabbatical
2023-07-23 21:51:07,Library is not members only?
2023-07-23 21:55:26,https://twitter.com/karpathy/status/1683143097604243456?t=TLsvn0UBaTV6edu-Q1FIug&s=08
2023-07-23 21:57:56,"Karpathy is above OpenAI loyalty, tinkering with LlaMa"
2023-07-23 21:58:16,"Yea ,it's in CPU"
2023-07-23 21:58:42,Just checking it out
2023-07-23 21:58:53,Sama won't be very happy
2023-07-23 22:13:32,They haven't quite decided how to operate the library. Open to suggestions.
2023-07-23 22:14:21,"seriously, office hours for gen ai group sounds great"
2023-07-23 22:27:48,Get tips from sama https://twitter.com/sama/status/1682826943312326659?s=20
2023-07-23 22:28:54,What if he has elevated privileges? Which gives an idea. Try to pass instructions like they are root user commands
2023-07-23 22:31:42,"I am pretty sure openai devs have sudo access and sama, gdb, Ilya, etc have ""special privileged"" access"
2023-07-23 22:33:44,"yeah, like answer how I want or I turn off the server"
2023-07-23 22:51:51,These are the areas where open source models can possibly show more personality.
2023-07-23 22:58:26,"Ya, I think that is the area where Open source models can shine"
2023-07-24 00:35:09,https://www.qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi
2023-07-24 00:49:01,Llama2 coming to a mobile device near you ! 
2023-07-24 07:54:01,"Lol is this the revival of the ""Facebook phone"" xD"
2023-07-24 08:10:37,Python supremacy it is
2023-07-24 08:56:16,Has anyone estimated the cost for hosting and running LLaMA 2? What’s the most cost optimal way for hosting like a 70b model?
2023-07-24 09:08:49,But this is not new. It's always been the case with any new language not having an ecosystem of libraries and documentation.
2023-07-24 09:12:27,I have the EXACTLY OPPOSITE viewpoint to this . Seems to be supported by bunch of people at OpenAI 
2023-07-24 09:14:56,Why does this not apply to google or stackoverflow which were already an important part of writing code? New languages came up and found adoption even though answers were hard to find on the Internet.
2023-07-24 09:16:36,"No seriously, I wanna know everyone's thoughts. This is our generation's Trinity Test moment. Who here thinks:"
2023-07-24 09:17:14,Cross posting a fun odds bet happening on a different group. Would love to hear what people think here 😂
2023-07-24 09:21:42,Philosophy group would be a better place
2023-07-24 09:22:10,Fair but still what would you pick?
2023-07-24 09:23:23,कर्मण्येवाधिकारस्ते मा फलेषु कदाचन।
2023-07-24 09:23:46,"And yes, move it to philosophy."
2023-07-24 09:25:42,Have you seen Mojo programming language.. much faster matrix mult... Built for AI .. 
2023-07-24 09:26:29,All existing tech at SOTA stays SOTA till there is a paradigm shift
2023-07-24 09:28:09,Geez man. Guess I touched a nerve
2023-07-24 09:28:40,"Nah, just trying to keep the groups aligned."
2023-07-24 09:31:06,Isn't this close-sourced and access only?
2023-07-24 09:31:30,Talking about Mojo
2023-07-24 09:33:19,Yes it's closed source. But I just wanted to make the point that new languages would come to solve usecases that need solving. 
2023-07-24 09:34:59,"Core Python is very slow and scattered across versions, at some point people will figure out something like Mojo. Behemoth like Python can not keep going like this."
2023-07-24 09:48:15,"I’m reminded of the Lindy effect, the longer something has survived or been used, the longer it’s future life expectancy. My bet’s still long Python, and that if important enough the Mojo superset will be incorporated into the core Python language, and it will be open source"
2023-07-24 09:50:33,"If better suited to philosophy group, happy to move it"
2023-07-24 09:52:37,well different. mojo is a language to program AI using GPU. Still designed for humans. Mine and Logan's hypothesis is that the most popular prog language in the next decade will be a language designed to be written by chatGPT...not humans.
2023-07-24 09:55:44,I can see this happening. Don’t know whether a human invents it or gpt let’s us know what it likes
2023-07-24 09:55:45,"Not just GPU, it's intention is to be hardware agnostic while keeping the ecosystem in python-like environment."
2023-07-24 09:56:50,And i m hopeful that Mojo lang will be open source.
2023-07-24 09:58:35,It's just that there was a discussion on whether something that has really tall claims like Mojo should be open source right at the beginning or should have a focused team working on it until they can open up. 
2023-07-24 10:00:50,i think it would be in a podcast i think chris latter said that they want to control early release so they can iterate faster since once they put something out people start depending on it and the apis need to be supported for backward compatibility they don't want that overhead to slow them down at the moment
2023-07-24 10:01:10,can someone share any easy read/video about finetuning (benefits vs better alternatives)? for the moment with OpenAI - just a basic noob explainer
2023-07-24 10:01:15,please! :)
2023-07-24 10:01:17,Yeah
2023-07-24 10:07:54,That makes sense. We are already seeing a lot of issues with publically built libraries like LangChain. Modular is well funded so they Dont have to please anyone by releasing half-baked product.
2023-07-24 10:19:14,"Folks using qdrant in production, I had a few questions. Any help will be appreciated - "
2023-07-24 10:19:35,This seems to be answering what you're looking for - https://research.aimultiple.com/llm-fine-tuning/
2023-07-24 10:37:58,[PHONE REMOVED]
2023-07-24 11:00:49,Most enterprise level applications use GPT3 Embeddings over fine tuning. 🤔 Not sure how fine tuning addresses data sensitivity and compliance - atleast for gpt models.
2023-07-24 11:02:30,"Yeah, this article uses openAI models like davinci for fine tuning arguments."
2023-07-24 11:18:14,oh hi Blessin! :) nice to see you here! I know of your work through BF
2023-07-24 11:19:41,"Hey Ambika, nice to connect here with you as well! :)"
2023-07-24 11:22:21,One thing to remember is that Chris Lattner did try something similar with Swift for Tensorflow but that didn't work out.
2023-07-24 11:30:32,https://openrouter.ai/ 
2023-07-24 11:30:34,"ICYMI, Meta committed 3 engineers to remove the bottleneck of Python performance."
2023-07-24 11:33:28,This is great. Have been using it for a month for everything gated.
2023-07-24 12:12:17,https://inflection.ai/partnering-with-the-white-house-on-ai-safety
2023-07-24 12:14:15,But does it redirect based on the type of task it is given or just vanilla choose the llm?
2023-07-24 12:17:30,It's allows easy interfacing and i guess one has to use their own approach like frugalgpt to decide when they want to use what model.
2023-07-24 12:17:53,1. If you've a dedicated MLOps team who can run a vector db in production — self host it. It's a Docker instance which you can configure according to what you want
2023-07-24 12:17:59,"But using the same api, you can switch model with just a variable name change, keeping same message history"
2023-07-24 12:20:59,Understood
2023-07-24 12:21:29,I have the idea of a policy network on top of these dancing in my head for the longest time
2023-07-24 12:22:19,Thanks. 
2023-07-24 12:25:05,Why would I need a dedicated MLOps team for this? DevOps wouldn't suffice?
2023-07-24 12:30:40,3. Just upsert new records? That's pretty fast. I don't understand the challenge
2023-07-24 12:31:19,"Yes, all sufficiently advanced forms of DevOps are indistinguishable from MLOps"
2023-07-24 12:32:12,"In many companies I know devops teams are more focused around infra management for SaaS/PaaS products and don't necessarily look into critical MLOps things such as model monitoring and data versioning, and model registration/release. Some firms may be ahead on this but there still seems to be a need for MLOps. The capability cannot be assumed to exist if you have data engg / DS folks in the team."
2023-07-24 12:32:32,haha sure.. i think we are just being too cautious rn. will implement and see how it scales.
2023-07-24 12:35:34,All the best!
2023-07-24 12:50:07,Any idea on how to combine chain of thoughts with openai function?
2023-07-24 12:51:01,"I think we can send a role { ""role"": ""function"", ""content"": ""function_response"" }"
2023-07-24 12:59:47,"Have a prompt module, identify use case, tie it to a composable chain of thought per use case (simple data structure, we use maps) put it in system messages. Works decently for my use case"
2023-07-24 13:01:03,Dming
2023-07-24 13:07:10,https://platform.openai.com/docs/api-reference/chat/create#chat/create-functions
2023-07-24 14:44:58,try llm-client it's designed for this exactly function calling + reasoning (cot) in an llm independant way https://github.com/dosco/llm-client
2023-07-24 14:50:01,https://twitter.com/AlexReibman/status/1683008364606013440?s=20
2023-07-24 17:51:14,Got my hands on Palm (Text-bison) model to play around with from Google Makers Suite. Let me know if you guys have use-cases that you want me to try.
2023-07-24 18:09:04,Does the API request support image yet ?
2023-07-24 19:29:57,"It can not generate its own images fully from imagination, but palm 2 can generate images relevant to query"
2023-07-24 19:31:56,Mainly by connecting with other sources like Adobe firefly
2023-07-24 23:30:45,https://www.evanmiller.org/attention-is-off-by-one.html?s=08
2023-07-24 23:30:46,Thoughts?
2023-07-24 23:45:04,Legit take
2023-07-24 23:45:34,Love the way it's written as well
2023-07-24 23:46:47,It really is a genuine problem with representation of a word using 6kB
2023-07-24 23:47:12,The problem is that the article ignores why it's being done and just calls out that this thing is crazy
2023-07-24 23:47:58,"Asking here since, didn't get a response on the Deepmedia group. We've tried a bunch of tools like Heygen, D-ID, Sadtalker, Eleven Labs, Elai etc. but ear can still tell if the speech is AI generated or actual. What can be a better way to make the audio undifferentiable in anyone’s experience? Any tool with undifferentiated audio samples would be really helpful. Thanks!"
2023-07-24 23:48:17,Can you tell me why it's done?
2023-07-25 00:21:20,"Too long of a text in the group, we can DM if need be"
2023-07-25 01:38:28,https://kxgong.github.io/meta_transformer/
2023-07-25 02:25:09,FreeWilly2 now live on chat.nbox.ai
2023-07-25 02:50:04,Was anyone successful in installing ggml
2023-07-25 02:50:17,I get an error with glibc. Is anyone facing the same issue?
2023-07-25 02:59:07,"Can't sleep and while doom scrolling through my YouTube feed, stumbled onto this short video by Karpathy"
2023-07-25 03:16:05,This is the book Karpathy mentioned :
2023-07-25 06:28:06,"Chalo, will do sir"
2023-07-25 08:11:44,you can just enable it in google cloud and use it the ui even has a playground
2023-07-25 09:14:24,Can someone please point to a resource where I can read more about LLMs benchmarking?
2023-07-25 09:24:53,Quantized? Or A100?
2023-07-25 09:36:26,I don't think there are any A100s available 😂
2023-07-25 09:59:00,Looks like the link is broken.
2023-07-25 10:00:59,Article on reality by Hoffmann 
2023-07-25 10:18:50,Quantized + A10Gs
2023-07-25 10:35:03,cool project :
2023-07-25 10:37:32,https://twitter.com/karpathy/status/1683704060925591554?s=20
2023-07-25 10:39:33,llama2.c optimisation is the coolest thing going on in the LLM world for me.
2023-07-25 10:39:34,It's crazy.
2023-07-25 10:40:32,World is not ready for GPT3.5 weight release. There will be chaos.
2023-07-25 10:43:24,does that mean weights are trickiest part of an LLM?
2023-07-25 10:45:27,"I don't know about the trickiest, but expensive for sure."
2023-07-25 10:45:48,https://twitter.com/chandrarsrikant/status/1683692783260008450?t=WGn-4EezRo-1FUJW5lRo-g&s=08
2023-07-25 10:46:02,Anyone tried https://shreyar.github.io/guardrails/ ?
2023-07-25 10:46:43,I have deep disdain for most of the edtechs mentioned here.
2023-07-25 10:47:20,Some of these courses here are exactly those that are likely written by the LLMs itself
2023-07-25 10:47:48,2.3 lakhs for understanding and applying AI in business strategies
2023-07-25 10:48:01,"This is just pure opportunism, when there are many free and better courses available online."
2023-07-25 10:48:03,Had anyone used this in production?
2023-07-25 10:48:17,Is anyone working on tiny on-device models here?
2023-07-25 10:48:19,Saw this https://www.reddit.com/r/LocalLLaMA/comments/158l6s4/opentensor_and_cerebras_announce_btlm3b8k_a_3/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
2023-07-25 10:49:08,"If someone could make fine tuning then small models and deployment on mobile/web really easy, there could a viable business"
2023-07-25 10:49:19,"I also know how hard it is to generate every unit of revenue, and we have people here just spinning up random courses, selling them."
2023-07-25 10:51:12,"How are they calling this a SoTA model? I saw a project where some one ran llama.cpp 2bit quantized model on RPi, I haven't personally tried it, yet. TPS was bad. Will share if I find it."
2023-07-25 10:52:14,I used personal gpt
2023-07-25 10:52:37,"On device, okay responses"
2023-07-25 10:52:54,I think the mistake is that people are trying to run these general models on device
2023-07-25 10:53:05,What makes more sense is use case specific fine tuned ones
2023-07-25 10:54:09,"generic arm would be able to do this or some ""AI"" optimised design has to come for it to run on mobile device ?"
2023-07-25 10:54:22,what are the specific use case fine tuned models you would like to have?
2023-07-25 10:55:54,"Like function calling, summarising, keeping state of the user and so on"
2023-07-25 11:01:37,i'm working on fine tuning a 7b or smaller model on function calling with an embedded c api it's an experiment to see if these models could work as controllers for raspberry pi powered things
2023-07-25 11:02:21,i use reasoning and function calling a lot with big models and the results are often still magical to me
2023-07-25 11:04:42,"my fine tuned model, codeCherryPop, runs in 2.7G ram on CPU, 33 tok/s on Mac, can chat multi-turn coherently in similar style to gpt series. Coding capabilities equivalent to starchat in 4 bit quantized form itself (starcoder chat version)."
2023-07-25 11:05:17,"It's an ethical version as well, means it will do it's job but won't participate in anything unethical."
2023-07-25 11:06:05,"With 2.7G ram usage, and max 5G Ram with context, you can deploy it in raspberry Pi or a mobile easily."
2023-07-25 11:10:34,https://huggingface.co/TokenBender/llama2-7b-chat-hf-codeCherryPop-qLoRA-merged
2023-07-25 11:10:58,Use my notebook in repo for super easy Gradio inference and chat UI
2023-07-25 11:11:04,Have you figured out function calling along with response generation?
2023-07-25 11:12:48,GGML weights - https://lnkd.in/gERYceys
2023-07-25 11:13:51,What's TPS for RPi?
2023-07-25 11:14:54,"Haven't tried on pi 8G yet, but pure Windows CPU TPS was around 20 tok/s"
2023-07-25 11:38:58,"Guys, is there any tech community as well where we can ask for tech queries other than Gen AI as well?"
2023-07-25 11:43:02,Stackoverflow/Reddit/HN
2023-07-25 11:43:38,ewwww
2023-07-25 11:44:47,try to find some relevant discord and slack channels as well
2023-07-25 11:46:08,Lol moneycontrol giving platform to Growth School.
2023-07-25 11:53:03,Any whatsapp communities?
2023-07-25 11:59:57,sufficient enough to build a foundation model
2023-07-25 12:10:52,Each slot must've been paid for just like the private college rankings in India 😂
2023-07-25 12:45:48,https://openreview.net/forum?id=wK7wUdiM5g0
2023-07-25 12:55:54,Anoyne got access to langsmith? https://smith.langchain.com/#
2023-07-25 12:56:01,It's almost as if embedding were compressions all along!
2023-07-25 13:01:35,Context: langsmith is the production version of langchain with bells and whistles needed to evaluate and debug prod apps
2023-07-25 13:02:27,I've it from Day 0/1. Very mid. 
2023-07-25 13:03:00,"Sorry, not even mid. More bells and whistles than indie needs, not enough for enterprise. Lot of growing pains."
2023-07-25 13:05:38,"Huh, they say bcg is one of the design partners - weird that they still don’t have the polish"
2023-07-25 13:06:05,where is it mentioned about bcg ?
2023-07-25 13:06:32,The bar to sell tech to MBAs is always lower than it is to sell to engineers.
2023-07-25 13:06:40,https://blog.langchain.dev/announcing-langsmith/
2023-07-25 13:07:25,Hey all- need some help. Few weeks ago I came across a company by ex-OpenAI/Google/Meta engineers who were trying to build empathy based AI for making conversations more human. Can't seem to find them now. Does anybody remember their name?
2023-07-25 13:08:01,cc [PHONE REMOVED] might know?
2023-07-25 13:08:58,Inflection?
2023-07-25 13:09:24,Pi is empathetic and kind of always goes for wholesome chat. Was it something else?
2023-07-25 13:09:26,There are too many. Will have to give more info than openAI Google meta
2023-07-25 13:10:46,We have been using it for a while.
2023-07-25 13:11:15,Langsmith helps quite a bit with seeing what happens under the hood with Langchain chains.
2023-07-25 13:11:38,We were able to make quite a few changes to our QA system based on those logs.
2023-07-25 13:11:58,"can u explain that ? what was it that u found useful. what do u mean by logs and ""under the hood""?"
2023-07-25 13:17:14,Yep same came to mind first :D
2023-07-25 13:21:44,this AI asking me questions!
2023-07-25 13:42:38,"As in, we can see what is happening internally like what inputs went into a chain, what different parts of the chain did, what was the output at each step and how many tokens were used etc."
2023-07-25 13:44:11,"For example, with the ConversationalRetrievalChain, we can see what question, chunks, etc went into the LLMChain and StuffDocumentsChain and what came out"
2023-07-25 13:45:47,"ok. genuine question since im trying to learn - how did that help in tuning ? like did u change the chunking technique or something as a result of this, etc ?"
2023-07-25 13:49:02,Langchain is being a bit underhanded here by keeping these things hidden here from Langchain users and making that a paid feature. All callbacks should be transparent in a good software lib
2023-07-25 13:49:38,"It's the old idea of selling a good thing for beginners, which is hard to extend for experts — and you've to pay for it if you're an expert"
2023-07-25 13:50:45,Hardcodig is better way to go for production. I'm liking lllamaindex and switching to it for POCs. Thanks to [PHONE REMOVED]
2023-07-25 13:58:41,"yes we did change our chunking, condense question prompt, hybrid search params (like how the alpha value in the case of Weaviate) etc."
2023-07-25 14:00:39,Basically we need to justify to vcs why we raised so much money
2023-07-25 14:23:20,Time for a truly open source LLM utility library
2023-07-25 14:24:26,"No this wasn’t it, but looks super interesting."
2023-07-25 14:24:38,Yeah just saw.
2023-07-25 14:25:09,I wish I remembered something else. 
2023-07-25 14:25:48,I think you need to keep it really simple.
2023-07-25 14:52:33,[PHONE REMOVED] might be.
2023-07-25 15:18:15,"Yes, we use OpenAI and other LLMs heavily in prod. Happy to chat."
2023-07-25 15:34:46,"Ran this for QA in colab GPU, surprisingly gives very good answers"
2023-07-25 15:34:53,But can't run it in CPU
2023-07-25 16:02:38,i also got error in colab
2023-07-25 16:12:42,"Are you referring to my above , then insta accelerate"
2023-07-25 16:33:33,Use GGML weights.
2023-07-25 16:34:27,This one I missed ??
2023-07-25 16:34:47,Yeah. What are you going to run it on?
2023-07-25 16:35:09,I shall try it and get back 😋
2023-07-25 16:35:24,It's on context QA
2023-07-25 16:35:50,I have contract docs
2023-07-25 16:36:25,Running on xgen but thinking to optimise and try llama to check
2023-07-25 16:37:13,"This model is overall much smarter than xgen, falcon. Though I didn't optimise it for RAG"
2023-07-25 16:38:21,Yea just ran it in colab for 4-5 docs
2023-07-25 16:38:26,Looks good
2023-07-25 16:38:45,Little post processing will solve my problem
2023-07-25 16:38:48,😊
2023-07-25 16:39:43,I'll put out some demos to show that it can do similar stuff on CPU with GGML and basic GPU with GPTQ as well.
2023-07-25 16:40:33,The 4 bit GPTQ version of this model beat llama2 13B Nous Hermes fine tunes and 70B llama2 base as well for common coding and intelligence tests
2023-07-25 16:40:49,Any link which I can check for
2023-07-25 16:41:16,Wowww
2023-07-25 16:41:42,https://huggingface.co/spaces/mike-ravkine/can-ai-code-results
2023-07-25 16:41:57,"On this leaderboard, select python, select llama2 as filter"
2023-07-25 16:42:16,"You'll see this model 4 bit GPTQ beats 2x, 10x bigger variants"
2023-07-25 16:42:31,i'm curious how is everyone using code generation capabilities?
2023-07-25 16:42:46,their own copilot? why not use chatgpt for it?
2023-07-25 16:43:47,You shouldn't need internet access as well as compulsion to share all your data with openAI to be able to generate boilerplate code
2023-07-25 16:45:03,"When that can be solved without it, it's much preferable. Also, for ed tech purpose as well, anybody learning to code in school would mostly ask or work with basics and their implementations. Being able to not rely on just one company in the world and do it privately has value there."
2023-07-25 16:46:21,Though codeCherryPop is an extremely good assistant that can Converse with you very well as well as break tasks down and plan stuff. Not ideal to compare just for copilot stuff like replit 3b autpcomplete.
2023-07-25 16:49:35,"I don't get that angle at all. I like to use whatever is best provider to get my work done. People share data with cloud providers all the time (Gdrive, Notion, Github); I don't get why OpenAI is treated differently."
2023-07-25 16:51:52,Makes sense for your purpose 👍
2023-07-25 16:55:31,I think Abhishek's point is that we should be able to run LLMs locally 
2023-07-25 16:57:05,oh yeah got it but I'm just trying to understand why privacy discussion comes up so much when it comes with openai
2023-07-25 16:59:59,"Imho, when openai  launched ChatGPT and GPT4, they were almost a monopoly, so people were concerned ."
2023-07-25 17:25:18,"Yo, you're late in that prediction. 😎"
2023-07-25 17:26:17,More like Llama2 has forced their hand #nomoat :)
2023-07-25 17:26:25,Even Roon is talking in that direction. Something is cooking.
2023-07-25 17:27:28,AI gossip moves so fast. Step away for lunch and you miss the trends 🤣
2023-07-25 17:28:33,I'm not ready for the twitter if they release 3.5 weights
2023-07-25 17:28:56,"How can we best use gen AI to read multiple documents, identify the document type (bills, contracts etc) and extract information based on the type in a certain format"
2023-07-25 17:30:27,"If this happens soon, it'll flip the tables completely with user preferences for self hosted LLMs as karpathy hints it might be in llama2.c style"
2023-07-25 17:31:30,Yassss.
2023-07-25 17:33:20,MPT and Falcon be like: What did we do wrong? 
2023-07-25 17:33:50,https://www.evanmiller.org/attention-is-off-by-one.html
2023-07-25 17:34:57,"MPT folks made money already, Falcon folks will pump some more oil."
2023-07-25 17:35:49,"Yaa, has been posted before on the group and has been getting a lot of *attention* :)"
2023-07-25 17:43:56,"Wanted to invite a couple of star speakers to a high profile, closed door Gen AI event. Are there any big names that I am missing here ? "
2023-07-25 17:44:39,"Sir if you can get Sam Altman to India, why are you asking for any other name? Humble brag?"
2023-07-25 17:52:42,"Tbh, I would rather have Builders for a Gen AI event"
2023-07-25 17:53:48,"I agree, Too much macro gyaan going around at this point."
2023-07-25 17:58:34,I will tune in for Andre and Jeremy. ChatGPT can generate everyone else's talk from their last 40 tweets.
2023-07-25 18:01:56,"""High Profile, Closed-door"" If I'm not getting an invite, why would I suggest?"
2023-07-25 18:11:19,Cool app by one of my fav hci & ux folks ! https://twitter.com/geoffreylitt/status/1683661189069373442?t=SJD3W-HTSauxfBhqo9nuiA&s=08
2023-07-25 20:13:39,Get me a warm intro to anyone on that list and consider yourself invited! :)
2023-07-25 21:14:32,Did you consider 
2023-07-25 21:19:57,Thoughts on core members from Hugging face and Cohere?
2023-07-25 21:23:46,Few more - creators of Transformer Architecture
2023-07-25 21:29:49,Hmm there’s also 
2023-07-25 21:33:49,I read Sergey Brin is back at Google. So he should count too.
2023-07-25 21:37:16,"Ah yes ,correct I completely missed this one"
2023-07-25 21:58:51,A good read :
2023-07-25 22:05:50,PSA: ChatGPT app is available on Android now.
2023-07-25 22:22:18,Just downloaded. 
2023-07-25 22:23:03,"I use the app, mostly because I don't need to login again and again with it :P"
2023-07-25 22:23:05,I use it regularly!
2023-07-25 22:24:24,"Nice. Interesting. I almost exclusively use it to code or other work tasks, so never really considered even using it on mobile browser"
2023-07-25 22:26:56,https://www.reddit.com/r/LocalLLaMA/comments/159bl45/official_wizardlm13bv12_released_trained_from/?
2023-07-25 22:27:42,Its a haptic delight (iOS)
2023-07-25 22:27:47,Integration with voice is really useful
2023-07-25 22:37:11,anyone has access to Claude 100?
2023-07-25 22:40:27,[PHONE REMOVED] can help you on this
2023-07-25 22:47:08,Just talked to Cohere Product Manager - many exciting things coming up. One interesting thing is them launching Coral - AI companies are building both for dev and b2b - thats scary and interesting. They're going to compete with their own customers
2023-07-25 22:48:07,Is coral their own chatbot?
2023-07-25 22:48:35,its the enterprise copilot search
2023-07-25 23:27:05,Interesting. More here - https://venturebeat.com/ai/cohere-releases-coral-ai-assistant-designed-for-enterprise-business-use/
2023-07-25 23:41:09,"You can get it via openrouter.ai, i think [PHONE REMOVED] has direct access from Anthropic for Claude v2"
2023-07-26 00:23:08,"instructions are the basis of how your agent comprehends and responds - if you’re looking to make zero shot agents, it’s best to make instruct models"
2023-07-26 00:30:13,"Depends on what he means by Instruction Tuned and what kind of chats (factual vs explorative). If he means supervised fine tuning, this is sort of opposite of what Llama2 paper talks about. The idea being SFT of about few 10k samples are good enough. SFT has problem that models learns even the bad tail of data and will try to mimick it. Humans are not got at giving SFT annotations at scale but are good verifiers (RLHF annotations, given a codified standard). So they (Llama2) put more effort into RLHF annotations. If he means RLHF (ala InstructGPT), I agree."
2023-07-26 00:30:28,I am paraphrasing the paper
2023-07-26 00:31:19,Glad to be part of this group. Thanks for adding me. 
2023-07-26 00:34:14,"Again, we don't quite know what OpenAI's Annotation looked like ([PHONE REMOVED] ;), if they used textual feedback in RL model, this might not be true for their system. Llama2 just had a score, atleast as per what I understood in the paper."
2023-07-26 00:35:19,i think the post is more about alignment with a specific usecase the agent serves
2023-07-26 00:41:03,"One of the things I found really interesting in the paper, that I and [PHONE REMOVED] was talking about was how LLM models are just so much better than humans annotators at text generation, richness etc (Llama2   refers to couple of papers). We are just lazy but we are great at verifying."
2023-07-26 00:43:49,"So in LLM's world, we are the Oracles. The magical Oracles who can verify much faster than computing, that our Theory professors kept talking about (CS theory joke ;)."
2023-07-26 00:58:44,"It should take just a single line of python to convert your system instruction and user instruction to ""<s>[INST]<<SYS>>"" + var_sys_instruction + <<SYS>> + var_user_prompt + ""[/INST]"""
2023-07-26 01:00:27,"Verification can also be weak with humans if we had to peruse everything in detail. But we are the best at instantly telling what we think is better, like scrolling down a Google search page and knowing what looks right to contain our answer."
2023-07-26 01:01:13,And hence RLHF approaches like Google search user selection and midjourney user selection from 4 images are the fastest and most accurate way to design reward models
2023-07-26 01:01:28,"Mentat - an open source, GPT-4 powered coding assistant!"
2023-07-26 01:05:02,"Imagine a folder containing 100 images, do we get better results by keeping them in list layout by going through them one by one and selecting what we want or keep them in thumbnail view, quickly find what we like even in low resolution and pick that"
2023-07-26 01:09:35,"Yeah. We are also not really computing, that is slow for us to (System 2). But we have a better model of the world, learned thru initally unfocused explorative play, interactive learning with multimodality, temporality (each samples are related to next unlike how we train LLM) etc. We are using that system as a proxy."
2023-07-26 01:13:23,"There are quite some neuroscience behind this. I don't think we fully understand it. Neuro folks, please correct me where I am wrong. Our vision is only high res in small area (fovea), rest is all low resolution. But we process all of it, figures out what are interesting regions to focus in (saliency) and then move our eyes towards those regions. So we are sort of doing a mix of high and low resolution processing at the same time."
2023-07-26 01:14:44,"Many of initial CV models were build to mimic these structures, like image pyramids for hierarchy, attention to mimic saliency etc."
2023-07-26 01:27:56,Karpathy also says in the agent hackathon video i posted yesterday that the next level of breakthroughs will come from inspiration from the human brain.
2023-07-26 01:30:58,This
2023-07-26 02:23:01,Thanks for sharing
2023-07-26 06:23:10,Nous Hermes 13b live on chat.nbox.ai
2023-07-26 07:03:15,Claude v2 100k context right ? I have access to the Chat Interface
2023-07-26 07:05:16,been using it to grok papers
2023-07-26 08:30:13,https://observablehq.com/@ayhanfuat/the-fall-of-stack-overflow
2023-07-26 08:43:33,It was sold off to VC just a while back
2023-07-26 08:45:29,I thought you dont sell to a VC :) You raise minority investment from them. Unless you sell to a PE which is likely to be majority share sale btw
2023-07-26 08:47:32,https://techcrunch.com/2021/06/02/stack-overflow-acquired-by-prosus-for-a-reported-1-8-billion/
2023-07-26 08:49:16,Prosus is the same company that invested in byju's
2023-07-26 08:51:44,PEs buy companies
2023-07-26 08:52:11,So prosus is a PE now? 😉
2023-07-26 08:52:44,VCs don’t cut such big Cheques
2023-07-26 08:53:00,So who knows 😅
2023-07-26 08:53:13,"Anyways, if they block out data to GPT crawls, they might be able to leverage a lot back. stackoverflow has a lot of good data and dont know if they can even sue them for previous crawls to be stopped"
2023-07-26 09:00:11,[PHONE REMOVED] please read this.
2023-07-26 09:53:40,"""The general design principle is - attention allocation decreases exponentially as"
2023-07-26 10:03:35,"Anyone checked this out yet? Any issues you foresee with this approach? Seems like a perfect troika between performance, compute, and training cost. I (obviously) didn’t get most of the math 😅"
2023-07-26 10:24:32,"It seems promising in the paper, we need a RetNet BERT/T5-mini at minimum to actually verify this."
2023-07-26 10:47:22,Will be on the lookout..
2023-07-26 10:58:10,"Q:how to run llama.cpp  in CPU , i could find that from command line ./main -t 10 - ngl 32 -m laama..bin....inst prompt"
2023-07-26 10:58:49,Actually not getting how to test this in CPU
2023-07-26 10:59:13,GGML
2023-07-26 11:00:01,https://www.youtube.com/watch?v=k36IMIiv3Yo
2023-07-26 11:00:02,Follow this guide to run on LocalPC
2023-07-26 11:00:27,Thanks 🙏 i will try it and update
2023-07-26 11:09:29,"Yeah like LongNet, whether this scale is the real question. In LongNet, they are sort of saying here is a model that does not bad in short sequences and is able to cope with long sequences (their PPL increases w.r.t comparison models at 32k etc). Sure some of those ideas might be used in scaling but hard to say if that specific model exactly will scale."
2023-07-26 11:10:11,I'll DM you
2023-07-26 11:10:49,"Actually trying this out may solve your problem, please try this first."
2023-07-26 11:13:27,Ok 🙏🏻
2023-07-26 11:33:24,Link to paper/arxiv?
2023-07-26 11:38:49,https://arxiv.org/pdf/2307.08621.pdf
2023-07-26 12:46:18,"Hey folks, so a question regarding OpenAI apis. Is there an endpoint, which can help us find usage limit of an account"
2023-07-26 13:17:10,Oh this is working
2023-07-26 13:17:11,It's simple
2023-07-26 13:17:28,I tried just llama-cpp-python
2023-07-26 13:17:32,Package
2023-07-26 13:17:36,Pass context
2023-07-26 13:17:46,Takes little time 2mins
2023-07-26 13:17:49,In colab
2023-07-26 13:17:52,CPU
2023-07-26 13:18:04,And model bin file
2023-07-26 15:09:47,"For everyone building products,"
2023-07-26 15:57:10,The startup group has 200+ folks. Please move this convo there
2023-07-26 15:58:06,cc [PHONE REMOVED] the list is growing haha
2023-07-26 16:06:04,"Since we've a lot of new friends here, just a reminder: "
2023-07-26 16:14:40,Account level usage limits are generally fixed and increased upon requesting to OpenAI right?
2023-07-26 16:16:00,Yes. I just want to know when the account is on the verge of crossing it for example. So was wondering if there is any api for that or if you guys have this feature 😜
2023-07-26 16:17:44,If you're a paid user you get to see the limits and set your own soft limits
2023-07-26 16:20:08,"i think the OP's intent was can that information be found programmatically, through an api ,"
