{"Date":{"0":1677628800000,"1":1677715200000,"2":1677801600000,"3":1677888000000,"4":1677974400000,"5":1678060800000,"6":1678233600000,"7":1678320000000,"8":1678406400000,"9":1678579200000,"10":1678665600000,"11":1678752000000,"12":1678838400000,"13":1678924800000,"14":1679011200000,"15":1679097600000,"16":1679184000000,"17":1679270400000,"18":1679356800000,"19":1679443200000,"20":1679529600000,"21":1679616000000,"22":1679702400000,"23":1679788800000,"24":1679875200000,"25":1679961600000,"26":1680048000000,"27":1680134400000,"28":1680220800000,"29":1680307200000,"30":1680393600000,"31":1680480000000,"32":1680566400000,"33":1680652800000,"34":1680739200000,"35":1680825600000,"36":1680912000000,"37":1680998400000,"38":1681084800000,"39":1681171200000,"40":1681257600000,"41":1681344000000,"42":1681430400000,"43":1681516800000,"44":1681603200000,"45":1681689600000,"46":1681776000000,"47":1681862400000,"48":1681948800000,"49":1682035200000,"50":1682121600000,"51":1682208000000,"52":1682294400000,"53":1682380800000,"54":1682467200000,"55":1682553600000,"56":1682640000000,"57":1682726400000,"58":1682812800000,"59":1682899200000,"60":1682985600000,"61":1683072000000,"62":1683158400000,"63":1683244800000,"64":1683331200000,"65":1683417600000},"Message":{"0":"Please leave a one line intro when you join and ask those you invite to do the same! \n I'm Pranjal Mehta. Cofounded ePlane.ai (electric plane startup) and currently looking to build in GenAI. Sales and dev fx problems interest me \n Hey folks,  \n I'm Nirant K. ML\/LLM Consultant out of BLR. Mostly work with startup building in ML. \n Hey \n Kush this side. Running Corp Dev for Glance & InMobi. Definitely interested in seeing Generative AI innovations in the market \n Also please qualify folks before inviting to maintain the focus of the group. Anyone interested in building\/supporting GenAI startups is most welcome! \n I am mostly a spectator and possible evaluator. So, if needed, can exit. \n Hey folks, Pranav this side. I work in the product team at Pepper Content. I lead Peppertype.ai and have been closely working with Gen AI and it's applications in content and marketing for the last 2 years. \n Hello, Uneet here, working as a SDE in platform team at Carousell \n Hi All, Sachin here. Founder of IntelLawyer.com - search engine of case laws. Also previously worked at different places as RL engineer. Built agents to play games and trade stocks. \n Hello, \n Making a full anime with SD. 30 min BTS which has the specific model, video edits and so on \n Folks, please write 1-2 line intros: your name, what you do for work and what brings you here would be great! \n Hey everyone! Kaushik here. \n hey guys, i'm kartikeya bhardwaj. I'm a computer vision\/dl engineer and founder @ (spoofsense.ai) \n Hi Everyone, \n Hi folks I'm Amogh. Until 3 months ago I was director of product at Avataar. Currently I'm tinkering on a project in generative AI. https:\/\/www.youstick.fun\/ lets you use your photos to create fun stickers that you can use in Whatsapp, Instagram, Slack and Discord. Here are a few - \n [PHONE REMOVED] did you just send lots of stickers and delete? \ud83d\ude0b \n DM me for high quality sticker spam! \n Even better, create some of your own \ud83d\ude02 \n Looks like [PHONE REMOVED] got a DM from our benevolent dictator \ud83d\ude02, welcome to the group \n hum solo bootstrap founders ka dard ye beraham admins nahi samjhege, hang in there brother \ud83d\udcaa \n Ye group ka purpose hai aap solo aur bootstrap nahi rahe :) \n Hi all! I am Rahul Sundar, a PhD student from IIT Madras and an alumnus of BITS Pilani. Broadly put, I am interested in teaching  the science of any underlying problem to the machines. This field has different names: SciML, AI4Science, PhysicsInformedML, theory guided ML, etc.  \n Hi everyone, I\u2019m Parth, a VC @ Venture Highway. I look very closely at the Applied AI space and work with a few portfolio companies in the space. Happy to connect with you all. \n Hi All, I am a Data Scientist, have worked on many applied deep learning research problems, across many modalities and domains through a service-based org. A lot of exposure to RL, Computer Vision and NLP techniques. \n Hey folks, I am Abhishek Maiti, currently research engineer at Linkedin. I spend an unhealthy amount of time with computer vision and 3D reconstruction and looking for ways to make creation of 3D and 2D creative assets as seamless and accurate as possible. One of my recent side project: github.com\/ovshake\/stable-fashion Glad to be here. \n Hi everyone, \n How're you doing, people? I am Siddharth, currently working in the autonomous driving space. My thesis was on GANs in voice generation, and I have kept up with the literature and built out some models since. Hope to learn more here. \n Hey all, I am Anagh from Accel. Been working on AI investments for 3ish years, and used to build ML models in the pre-transformers era :P \n Hi guys, I am Naman from Stellaris VP. I look at AI and SaaS investments.  \n hello everyone, my name is Shashwat. Ex glance (inmobi). I am working on AI-based learning and development tool. Primarily interested in recommendation systems and now building one for generative media consumption.  \n Making video shots with RunwayML \n Hi everyone :) ","1":"https:\/\/twitter.com\/OpenAI\/status\/1630992406542970880?s=20 - Update on ChatGPT, Whisper API. \n ChatGPT API Launch tl;dr:  \n in case someone missed it \n https:\/\/twitter.com\/c_valenzuelab\/status\/1630969280803250176?t=Timm5pV-ymLQM02QPZM-sg&s=08 \n Ok I finally got controlnet working in a way that makes me happy! \n Anyone here who\u2019s deployed gpt-3.5-turbo on any of their production apps? How are the latencies after some certain scale? Is the API timing out or throwing errors? \n Na, mostly stable so far. Needs some retries but works with exponential backoff \n Corridor Digital reveals how they made Anime using SD VFX and Blender (scenes) \n https:\/\/twitter.com\/stabilityai\/status\/1631339515792039968","2":"The new Flan-UL2 20B from GoogleAI is out!  \n PS: As a dev I like to use fancy terms, ask questions \u2014 fun to answer them :) \n What's the compute required to have a good \/ useful throughput \n If it's gonna be costing similar in cloud instance cost, you might as well go with chatgpt API? \n Was thinking more data localisation and compliance needs, not cost \n + control\u2026If you need to train specialized models, can\u2019t yet do it with chatGPT. Also once LLMs start to call APIs which access sensitive data, we might need different, transparent and configurable\/ finetunable base models. \n Same applies if it's on cloud instead of on prem, no? \n Two interesting a16z articles \n https:\/\/a16z.com\/2023\/01\/19\/who-owns-the-generative-ai-platform\/ \n https:\/\/a16z.com\/2023\/02\/07\/everyday-ai-consumer\/ \n I wrote a deeper dive into what successful AI products would look like at https:\/\/www.amoghvaishampayan.com\/post\/generative-ai-product-strategy \n I've worked as an AI product manager for the last 5 years. The essence of my generative AI article cold be summarized as -  \n https:\/\/www.reforge.com\/blog\/ai-products-arms-race \n https:\/\/www.biorxiv.org\/content\/10.1101\/2022.11.18.517004v2.full.pdf \n This is the fMRI \u2192 SD from Japanese folks, right? It's quite radical, and well \u2014 brain shattering ;) \n Oh yeah, the on from Osaka. :D \n It took me a couple of mins to realise that prompt for these images was imagination \ud83e\udd2f \n This is genius \n Yep... \n \ud83e\udd29 \n Increasing the noise in my brain by watching non Hindi and non English media only from now on! Will also learn a new language, but only the hi, hello part every month. \n Ummm have they released some code? \n I am very skeptical on this. Data from brain to be used for useful things is still in very very early research. \n Nahi, it's not peer reviewed. Just submitted to some conf I think. \n Like up\/down itself has 70% accuracy \n State of the art devices with some 200 probes ke sath this is the case \n Off the shelf devices like the one that came in shark tank are bleh \n You're bringing facts to an emo excited conversation. Why you be like this? \n Coz I have spent a lot of money and time on this \ud83d\ude02 \n My rant is my emo :P \n Please elaborate further \n \ud83d\ude02\ud83d\ude02\ud83d\ude02  \n I have bought some 4 such devices over 4 years \n Each costing 25k to 1L :P \n And I was a subject in one such experiment too \n And the data is so noisy and hard to use. \n Like the ones used in hospitals was benchmark for off the shel devices \n those have 200 probes, you have to be bald \n and then also it is noisy. \n It works on voltage of neurons. So probes need to be very ver sensitive \n Which is a hard hardware problem \n They are using fMRI data which has a much stronger signal profile. I participated in a couple of frontal lobe activation expts here, and the data was apparently clean enough to run some pretty interesting analyses. \n Can't we get such data without having a hardware device ? \n That's a near-certain no. \n What does clean enough and analyses mean here? If it's alright with you, share a couple of examples? \n I will try and find the paper. \n Non-invasive devices are already pretty noisy compared to brain probes. Without hardware matlab kya? \n In the meanwhile, the expt was as follows: two sessions of 45 min- 1hr wherein a volunteer (me and 10 others) will lie in an fMRI machine, and solve some logic and language puzzles (they will be projected on a screen and I have to verbalize my answer). They showed me the processed data stream sometime later, and explained that they were going to try and localize activations and their strengths to understand which subsection of the frontal lobe is responsible for the thought. After that, they had planned to run some time-series analyses to see how the activation shifts as the answer is obtained and verbalised (not sure if they ever published this one). \n Folks, what are the best videos\/resources on using SD for designers (product, UX) and artists?  \n (Yes, I've already included the anime which plays rock, paper) \n Automatic1111 is the easiest way to use SD and all of its plugins but requires a GPU to run on local. Plus the setup can be a bit technical. If no GPU then it has to run on Colab which is also technical. \n Imagine getting actual footage of your dreams \ud83e\udd2f \n YC Founder talks to YC Partner: https:\/\/youtu.be\/hQC5O3WTmuo","3":"https:\/\/theresanaiforthat.com\/ \n We open-sourced our Hasura AI bot code; and made it easy to deploy with one click. Read about it here, \n Offset Noise is heating up AI Art \n https:\/\/twitter.com\/MetaAI\/status\/1631351811696394240?s=20 \n Can you post the original tweet link \n He is also running purchase parity which I feel most products miss \n An AI themed movie that someone will make soon enough. Think Her, but with a couple and a twist!","4":"Hi everyone, I'm Anirudth, currently an Applied Scientist at Amazon. Invited by [PHONE REMOVED] to this group. I'm excited about generative AI and looking to unlock new opportunities.","5":"https:\/\/www.marktechpost.com\/2023\/02\/28\/oxford-university-researchers-introduce-a-diffusion-model-called-realfusion-that-can-generate-360-degree-reconstructions-of-objects-from-an-image\/?amp \n Breakthrough for nerf \n cc [PHONE REMOVED] Devanshu Tak is a 3D artist who has used NeRF earlier in his work \n Interesting read: https:\/\/unsupervisedlearning.substack.com\/p\/using-large-language-models-effectively. Esp the #4 point around embeddings \n really interesting points. [PHONE REMOVED] you guys used pinecone and langchain in the hasura bot for the embedding purpose only, right? \n Embedding and prompt templating \n But embedding was the biggest reason \n Any specific reason for not using the openai's embedding endpoint other than cost and latency? \n It uses openAI embedding \n Pinecone is used as vector store \n oh ok \n Yeah that's what I would assume \n Langchain gives a good abstraction \n Cool cool, haven't used it yet. I thought it might be some kind of local store creator (if that makes sense \ud83d\ude05) \n Chroma bundles store and the embedding call into one from what I can tell. I'll try that out this week","6":"Doing a GenerativeAI Hackathon!  \n What kind of problem statements are welcome? \n Anything that uses Generative AI e.g. ChatGPT, Midjourney is welcome. No other constraint on the problem statement. Make April Fool Apps for all I care \n Cool \n Has everyone already got a team? \ud83d\ude04 \n Anyone here interested in Normalizing flows? \n I have been, for a while. \n +1 \n Industrial use cases or out if academic interest? \n *of \n Wrong window. \n Interesting resource: \n https:\/\/research.runwayml.com\/gen1","7":"Hi all, wanted to run by an opportunity with you. It's a large content + consumer brands company that I am closely working with, they reach about 40% of all social media users in India.  \n Is this something that you\/any friend you know be interested in exploring? You can DM if yes","8":"https:\/\/zenil.substack.com\/p\/indian-generative-ai-landscape-the?r=1f3ivv&utm_campaign=post&utm_medium=web \n https:\/\/www.reddit.com\/r\/singularity\/comments\/11mztcu\/gpt4_is_coming_next_week_and_it_will_be\/ \n Thanks [PHONE REMOVED] for adding me here. ","9":"Interested in finding what GPT hype is about? \n Is this different from the Google form i filled for hackathon? \n Yes, that is participants only. For people hacking on that day. This is for everyone interested in just seeing what was built during the hackathon! \n So participants don't need to fill then, right? \n Register here for a hackathon invite to the BLR venue: https:\/\/forms.gle\/UizUwyKi4bajt6WB7 \n No \n Why does wording say only GPT? \n Haan Nirant. [PHONE REMOVED], is going to dazzle with stable diffusion. :) \n Exactly :P  \n Would help you save face a lot more if at least someone from your company signed up to participate, that number is \ud83e\udd5a right now \n Registrations shall come :P \n https:\/\/www.youtube.com\/watch?v=VdMgPgicvK4 \n Anyone with access to Runwayml?","10":"Hey, are there any LLMs by open AI that can be deployed on prem today? \n OpenAI has Foundry at $1M\/yr which will have onprem \n *FLan-T5 is FOSS and by Google \n Thanks Nirant for the quick help!","11":"Hello folks,  \n same question! \n Yes, most definitely!  \n Hi folks, any non-techies here? This space is too technical for me right now, but I want to make a conscious effort to keep up with what's happening. Will appreciate any help! \n [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] are PMs, [PHONE REMOVED] [PHONE REMOVED] are founder and VC respectively, [PHONE REMOVED] is Mumbai based creative agency person,  \n Thanks Nirant! \ud83c\udf3b I'll bug 'em. \n What's the prize money split? \n 1L minimum per track \u2014 no runners up, remote submissions welcome, split between all members of the winning team equally  \n Details of evaluation criteria will be helpful, best if it is quantitative and transparent \n This is left to jury's discretion. I'm not aware of it either, nor will I be till the day of hackathon. The jury may choose to share it, after the demos or make it quantitative. \n Personally not a fan of making JEE Mains out of a hackathon \n At least devs competing will know what they are going to be judged on, right? \n And will be helpful for the jury as well on what to look for \n So need to know the jee syllabus rather than going with broad ias subject \ud83d\ude42 \n Tracks are announced no for the hackathon? Isnt that enough to decide? \ud83e\udd14 \n Hey Heer, Rasagy here! Designer \/ Data Artist \ud83d\udc4b \n Having criteria takes away the fun from hacking\/creativity part from hackathons, I absolutely agree with Nirants point of leaving it to the judges \n Hey Heer. My name is Jay. I'm a product manager \n Hey Jay! \ud83d\udc4b\ud83c\udffb nice to meet you..DMing. \n Hello Rasagy! \ud83d\udc83 DMing! \n Hi Heer, Vikas here. fintech\/tech  consultant\/trainer \n Thanks Nirant.  \n https:\/\/alpaca-ai-custom4.ngrok.io\/ Thoughts on this? \n Very slow to try prompts there atm. Hoping it'll be on nat.dev soon. So far, it looks more like davinci-002 than the 003 series in terms of ability to follow logic over multiple hops. Also, no weights \u2014 so kinda iffy on what is going inside training \n Welcome Manjot [PHONE REMOVED]. She is with Lightspeed VC currently. She has a ton of experience having been at Google, started up and then led Stripe India as CEO. \n The instruct dataset is key. And the PR they have raised with Huggingface gives you the training code. \n https:\/\/twitter.com\/OpenAI\/status\/1635687373060317185?t=nhm2BaNejunBE9-syFgEeA&s=19 \n Clearly, built for enterprise: \n As I understand the big user visible things are: \n This was actually true \ud83d\ude36 \n Also too much happening in this space in a day\ud83d\ude05 how do one keep up with things? \n 3x the price \n Yeah this is crazy. The train just does not stop \n Seems enterprise grade security\/Scalability costs premium\ud83d\ude05 \n 12 cents per 1K token completions is quite expensive \u2014 this is going to encourage Llama-Alpaca experiments even more \n GPT4 capabilities have a FOSS counterpart from Amazon: github.com\/amazon-science\/mm-cot \n The be my eyes demo is hilarious \ud83d\ude02 \n https:\/\/www.youtube.com\/live\/outcGtbnMuQ?feature=share \n Thank you ... Odd timing for ist. Will wait for the summary from others \n Thank you so much everyone, glad to be a part of this community! Thanks for adding me Pranjal!","12":"https:\/\/twitter.com\/prashanthshanm\/status\/1635646028648177669?s=20 \n Too late, too little \ud83d\ude02\ud83d\ude05\ud83d\ude02\ud83d\ude05 \n After seeing the OpenAI demo \n the paper wireframe to working code was just \ud83e\udd2f \n But wouldn't this get used more than anything else? who doesn't have to check email, write docs \/ make slides \n I agree. It doesn\u2019t open up loads of possibilities for others to build upon- but enough productivity & note apps are irrelevant after this. \n Loved the wireframe to code demo by OpenAI today \n Really good demos \n Hello!  \n Will also request other experts hiding in the weeds to lend their expertise around StableDiffusion: [PHONE REMOVED] [PHONE REMOVED] \n Last paper I read on Deep Learning\/NLP was Attention Is All You Need. \n I would highly recommend watching Karpathy's nonogpt video. 2 hours of golden content. He basically reproduces the same paper you read from scratch. \n [Beginner Researcher Answer] \n The other way is to work backwards from what is out there and we can study e.g. everything from Llama to Flan-T5 and see what blocks they've been built on \n Do you think Xavi Amatriain's catalog is a good read for starters? \n That can be a bit overwhelming for someone who was last reading BERT-era papers. I mean, even Contrastive Learning is a new concept there in a way.  \n But if you do this for a living, you should most def use that as a starting point \n Re-iterating: Non-technical Qs most welcome. They also are good prompt for someone to elaborate and spark and idea :) \n transformers have taken over the field which was dominated primarily by RNN variants. Are we seeing signals of any new architecture doing the same with transformers? \n On a slightly different tangent  \n With my limited understanding, I think fine-tuning any LLM is quite tricky. \n Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks\/ months)-  https:\/\/web.stanford.edu\/class\/cs25\/ , https:\/\/web.stanford.edu\/class\/cs224n\/index.html#schedule , https:\/\/people.cs.umass.edu\/~miyyer\/cs685\/ \n What do you think about trlx re: PPO?  \n My very spicy, uninformed take is that we'll see model sizes, personalities, flavours spread across the spectrum of use cases like we did for DBs. \n Do we think finetuning is needed for most of the usecases? Or just clever prompt engineering is the way to go? The way I am thinking about this is finetuned model is someone who has learned and internalised the concepts vs prompt optimisation with relevant context is someone intelligent reading interesting information and inferring outputs based on it? And for most cases I feel someone smart reading correct information and responding based on that would be sufficient. Do we think that for applications, prefix \/ prompt tuning is the way to go than finetuning base models (for applications; for open source LLMs, we will need instruction tuning) ? \n For artists (non-tech) looking for _prompt to art_ experiments, what is the next step after playing with basic prompts on Midjourney & Dall-e? Do you recommend just going deep with those two platforms, or is there something else that works better? \n Alex from Carper AI is presenting this tonight at W&B conference. So I'll wait till then and discuss tomorrow. \n Playgroundai \n Prompt optimisation looks more lucrative as the possible size of prompt is now much bigger. Would we train smaller models which will generate better prompts for the underlying LLMs ? \n Stable Diffusion gives you a lot more control, power and flexibility. See civitai.com (NSFW!) for all the styles and themes you can create around. You might also want to checkout a couple of Youtube artists using this really well for prompt to art: youtube.com\/@sebastiankamph is my fav at the moment \n In this group, [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] have played with Automatic1111 the interface and all that it unlocks from ControlNet (used for making fingers, control posture, faces) to upresolution for high res images \n Prompt engineering also changes with each new release, the system gets better at understanding what the user is looking for \n I'll try this for first one week. \n a related but different thought, the next step for text2image providers is integrating directly with artists choice of full-fledge tool - canva, photoshop \n if you have explored prompt engineering, i think next logical step would be exploring image2image, in-painting, out-painting and instruct pix2pix \n also did a quick write-up on different web UIs out there, hope this is helpful for this group - https:\/\/www.ai-art.dev\/web-uis-for-stable-diffusion \n https:\/\/www.linkedin.com\/posts\/sayak-paul_bangalore-folks-how-about-organizing-an-activity-7041263527482830848-qGzh?utm_source=share&utm_medium=member_ios \n [PHONE REMOVED] Have been working with artists and their flows a lot to figure on how to empower them more. \n RNNs are fighting back https:\/\/mobile.twitter.com\/arankomatsuzaki\/status\/1635453248252391427 \n Most research shows that bigger the model, more the number of emergent properties. Are there any works that show when these arise during training? Do they arise gradually one by one as we train or do they all come up early and become better as we train? \n To give more context on the premise: https:\/\/blogger.googleusercontent.com\/img\/b\/R29vZ2xl\/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ\/s1600\/image8.gif from the Google palm Blogpost https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html?m=1","13":"I basically read all the papers related to popular models, helps you understand the differences. \n Thanks Majot. I'll try and explore this as well. \n DM [PHONE REMOVED] \n At the risk of waxing poetic, I like this game of hunting for clues, trying to get into the mind of what did the research team think and what might be the failed experiments they've not mentioned in a paper.  \n You can play this game in arcade (like above), or go to hard mode and start with interdisciplinary papers like Visual ChatGPT and diff it against say, Amazon's MM CoT or even team mode: Host a reading session and invite 4 people to present different papers and tell what the authors missed or got right or what their \"insight\" was \n Brilliant resource. Thanks for sharing. \n Are there any happening in blr? Any channel to discover these? \n Wow this sounds like a great idea. Folks should spontaneously organize such stuff in Bangalore. \n Sumod Mohan used to run a CV paper reading group, Swanand runs one via Hasgeek which is more broader CS (and very high quality!)  \n I would love to listen in if that\u2019s allowed! \n If I get >5 DMs, will share the time and venue here. Can do Zoom if >3 of these are non-BLR \n +1 DM \n Please don't reply here with DM? That's a bit spammy for everyone else here \ud83d\ude05 \n https:\/\/twitter.com\/LangChainAI\/status\/1636122692645691393?t=aUUOXK9kILoYkyVzVgjdhg&s=19 \n I was storing embedding vectors as json in PG database previously. Need to explore this . Thanks for sharing","14":"Thank you [PHONE REMOVED] for bringing this, how does this do with large scale searches ? Any help appreciated \ud83d\udc4d \n Haven't done any performance tests yet, so don't have much idea about that. The integration is still missing some indexing steps, but from what I've seen, specific vector database like pinecone will have better results in case of large scale applications. \n But again, can't say for sure. \n Great thanks for your response , \n https:\/\/www.youtube.com\/watch?v=VqhDnaqhnd4 - Very impressive \ud83d\ude4c \n This might be a naive question but can someone explain why these language models have cut off in 2021, gpt4 included  \n Training involves curating a dataset which is a lot of effort. The dataset they used to train on was curated till 2021. \n Cleaning the data, wrangling it etc take a LOT of time \n Does each llm build their own dataset from scratch  \n Afaik gpt4 cut off is aug 22 \n there are some open source datasets    \n https:\/\/www.springboard.com\/blog\/data-science\/machine-learning-gpt-3-open-ai\/ \n Gpt-4 paper might have the dataset details. The paper was pretty disappointing though \n ChatGPT-3 Whatsapp bot. Can summarise videos, transcribe voice notes, answer text questions and generate images using \/image  \n This is interesting as well, I use it for productivity  \n Count me in for listening, please. \n Replit.com will be sponsoring the hackathon!  \n It seems slightly more complicated. The model certainly has access to data from 2022, and can answer some questions about it, but its official position is that the data has a cutoff date in 2021, and it doesn't answer some questions citing that as a reason. \n The first statement is wrong. I don't know what to make of the whole thing. It knows about IFRNet, but somehow gives a partial answer. Produced correct answer for earlier models. \n Just another day in the life of an LLM, I guess.","15":"New BingGPT Launch: https:\/\/www.bing.com\/new \n This has the potential make advertising briefs soooo much easier \ud83d\udcaf \n https:\/\/www.gizmochina.com\/2023\/03\/16\/ai-hire-a-human-to-solve-captcha\/ \n How will GPT4 change software engineering? I took a stab at answering this:  \n And by I, I mean actually me, not GPT4 \u2014 that guy speaks too much \n hey! is march meetup for gen ai is happening today? at Hasura HQ, kora? \n Is there an RSVP link \/ signup link for this? \n No meetup in March, come to the hackathon! \n Anyone here who has been using image generation model for a while? Have a few questions  \n 1. Yes, I did notice as well. Mid journey results looks more realistic. I tried open-journey too on HF. \n Yup been playing and creating since 2020, even fine tuned old VQGAN models \n Thanks  \n Midjourney is superior, there are a few models in cvitai that come close \n they offer far more functionality and the open source community is very active \n Midj is really pretty but a lot of models have matched quality now. \n Try gooey.ai \n I recently came across it. \n I mean HF spaces. If they are not on HF spaces, you can use HF diffusers. The have documentation on inferencing. \n models like? \n Dreamshaper, openjourney, protogen \n They're not good enough \n Openjourney is pretty bad \n Protogen has many versions. \n Each with some good and some bad. \n None of them lol \n I've tried all \n Depends what you want. \ud83d\ude05 \n The closest model is illuminati diffusion \n With negative embeddings \n Getting MJ like photorealism even with realistic vision is hard \n V5 they really really stepped on photo realism true. \n open journey is good though compared to available open-source models? \n https:\/\/civitai.com\/ \n have fun :) \n So true, couldn\u2019t try it though  \n Yea. This has most models. There are Bollywood models too \ud83d\ude02 \n Yup anyone can train a LORA or a dreambooth \n They're using LORAs to finetune alpaca now \n Anyone giving it a shot? Making LLaMa better with self instruct datasets \n Was discussing literally this yesterday with [PHONE REMOVED] \ud83d\ude05 \n Maybe give it a shot over the hackathon day \n I'll sponsor this upto $500 and happy to contribute datasets and get you your first few users if you want to go commercial with it too.  \n ^This should tell you how excited I'm about this xD \n Are non engineers doing this enough in India? \ud83e\udd14 \n Most are annon \n Anyone can do it tbh \n what's self instruct datasets? \n Just gotta get through the pain of setting up automatic1111 properly \n Alpaca can be much better. \n And then finetune with lora \n Awesome \n Dude even I'm super excited haha. We actually have a chance to compete with OpenAI and launch something super competetive \n Hashed them out quickly - have a look folks and lmk what you think \n I'm a simple man, I see Roam, I like it \n I have the same question.. \n haha \n https:\/\/crfm.stanford.edu\/2023\/03\/13\/alpaca.html \n This is self instructions dataset  \n Basically a large json that can fine tune any LLM and make them more \"aligned\" - makes an LLM better and more like ChatGPT \n to put it simply \n https:\/\/github.com\/tatsu-lab\/stanford_alpaca\/blob\/main\/alpaca_data.json \n Who did this? It\u2019s excellent \n catching up on the convos - \n offset noise write up - https:\/\/www.crosslabs.org\/blog\/diffusion-with-offset-noise \n 4 months away from this generative AI space and this discussion is already putting me in stone age \ud83d\ude05\ud83d\ude05 \n UW PhD Student, quite clever.  Ofc, Stanford hogged all the recall value with Alpaca \n All this happened in last 2 weeks \ud83d\ude02 \n We didn't talk about all the Google stuff and Blender ControlNet for posture and depth yet xD \n i was still in GenerativeAI, just in text2img and not text2text, and i feel like i am in stone age \ud83d\ude02 \n Haha I'm in touch with toysxyz - the dude building all that. We were jamming on using facial keypoints for better control \n Do people not sleep these days? \n Is everyone on Adderall? \n Hahaha \n Was sleep a ZIRP phenomenon? \n Asking for myself, I'm the friend \n \ud83d\ude02 \n So basically the json structure you need to fine-tune gpt using OpenAI? \n Yup \n It's simple instructions + answers generated by GPT-3 \n What if we use GPT-4? \n OpenAI had a team of 40 upwork contractors and Scale AI;s help to do this - (from instructGPT paper) \n A good dataset can make a large difference - like any ML problem","16":"Confirmed *FOSS* Demos for the hackathon, 2 of the top 3 projects from Github Trending in AI: \n Thanks for the intro Ravi Theja, GPT-Index contributor and inMobi DS [PHONE REMOVED]  to Jerry Liu \n https:\/\/mobile.twitter.com\/nickfloats\/status\/1631346749297106958 \n Sharing my favourite blog from last few weeks: https:\/\/simonwillison.net\/2023\/Mar\/17\/beat-chatgpt-in-a-browser\/ \n WASM for LLMs is super interesting, anyone tried? \n came across this today \n Yup saw this \n They also trained an LLM to mimic Homer Simpson and it\u2019s apparently better than gpt-4 \n Hey Hi Guys ! \n Iit madras or Bombay has research labs you can cold mail them or reach out to other iits they might help or redirect to appropriate org. \n It'd be hilarious if the model forgot how to do chain of thought reasoning because of that \ud83d\ude02\ud83d\ude02 \n Lol \n Anyone exploring building a tool like this for VCs?  \n Good customers to sell to and solid use case of AI","17":"https:\/\/twitter.com\/tarundua81\/status\/1625092808095961090 \n https:\/\/huggingface.co\/spaces\/damo-vilab\/modelscope-text-to-video-synthesis anyone tried this? \n Reid Hoffmann's essay on GPT4 \u2014 but is there an AI Summary of this? \ud83d\ude1b \n I mean it's 150+ pages long \n It contains dialogues with GPT-4.  \n This is the future, people will use copilot to make their emails more detailed and comprehensive. Readers would use copilot to summarise it. \ud83d\ude02 \n No, in the future \u2014 there will be no emails, just byte-streams going from your brain to another brain. Mann Ki Baat. \n Shubham, my friend from college and a writer on TVF Pitchers S2 [PHONE REMOVED] shared this HBR essay: https:\/\/hbr.org\/2023\/03\/how-will-generative-ai-disrupt-video-platforms \n Very little MLE in the loop \n Ok super late to this because I was off the phone yesterday. But in my experience Midjourney is far far superior out of the box. Fantastic for applications where you need generic imagery and don't care too much about difficult characters, image composition and other fine control. Very useful for - blog post images, moodboards, inspiration images, stock images  \n Midjourney : Canva : : Stable Diffusion : Photoshop \n interesting \n But I think its not \"very\" hard to make midj and also there is a lot of legal gray area with midj. \n i wasn't expecting this to happen but Midjourney might release an API! \n InvokeAI has made a pretty slick open source UI for SD.  automatic1111 is like a freaking Bloomberg terminal \ud83d\ude02 \n In 2 months? Wow. I missed this office hours \n So true \ud83d\ude02 \n has anybody managed to run invokeAI on colab? AFAIK they have docker to run locally on your desktop GPU \n plus they don't have any changelog, releases. i check updates by looking for closed issues with the enhancement label on github \n \ud83d\ude02 \n I just debug after things break :P \n Automatic1111 will be the crazy hackers option that 5 years from now we will look back and say \"Back in my day we had this thing called Automatic1111 and it was beautiful. All you kids have it easy these days\" \n i didn't watch it either. recap: https:\/\/youtu.be\/onjfu3Uh2vI \n winamp of CreativeAI \ud83d\ude02 \n Haha true \n btw anyone used runwayML Gen1? i got access few days back. crazy impressive. \n Does invoke has the extensions that auto has? \n invoke is pretty limited. i haven't even installed it right now. but love the focus on UX.  \n Has anyone tried Comfy UI, the node based\/DAG interface for image generation? \n V interesting! \n OpenAI wrote a paper on the potential impact of Large Language Models on the Labor Market \n thread https:\/\/twitter.com\/rubinovitz\/status\/1637651591191842816?t=g4U4qTnkF-R02mImutwo8w&s=19 \n With the amount of funds that openAI has are these PR stunts? \n No \n https:\/\/twitter.com\/arankomatsuzaki\/status\/1637612922934382593 \n Request: When sharing links in future, please add a line about why should we click through or what is the topic about! \n didn't know about this. looks interesting but feels like just slapping a nodeUI without attention to workflows. InvokeAI is also working on a node architecture along with their canvas UI. \n Hello, \n Hi everyone, please welcome Kishore [PHONE REMOVED] to the group! He's building in the Generative AI space to generate statics for advertisers. \n What is a static? Image? Text? \n Hey Kishore! \n Excited to see what you have so far. \n Hi Kishore! Welcome to the group. Curious about the images you posted. Are they examples of what a static image is or output from your product's pipeline? \n Hi [PHONE REMOVED] . This is the output from my product pipeline. \n Pretty cool! So stable diffusion with some fine tuning magic I would guess? \n hey, nice to see you here [PHONE REMOVED], amazing progress from last time we caught up \ud83d\udc4d \n You can do this without finetuning. There are many methods out there which you can implement to get similar results. But it does require a lot of trial and error and breaking apart the typical model. You can change the encoders. and other things in the HF pipeline for it to work. \n It was based of some prompt, or img2img? \n Gen2 by RunwayML. paper, video  \n Can the world slow down a bit\ud83d\ude02 \n My current favourite conspiracy theory: Someone is spiking SF's water supply with Adderall \n Not true, tech bros only drink sparkling water \n https:\/\/vercel.com\/templates\/ai \n some cool Replit templates -  \n check out all templates here - https:\/\/replit.com\/templates?q=AI","18":"Great results! \n I'm curious, why not inpaint the main product from a separate LoRA finetuned on the product? \n For folks working on multiple images with minor variations, here is a _tutorial_ (yes! we're in the tutorial era of Stable Diffusion) using ComfyUI for generating similar images but with models of different ethnicities and different anime styles of same character \n Hi [PHONE REMOVED] the main product here doesn\u2019t vary. The main product isn\u2019t the candle. It is the matchstick box with the person holding it. \n This image should be a better representation [PHONE REMOVED] \n Is that how tools like flair \/ booth.ai work? \n How do they retain the text? Lora screws it up usually right \n Didn't try it. Will give it a shot \n I think there's some smart img2img + masking going on apart from dreamboothing \n https:\/\/bit.ly\/hf-nvidia-meetup \n Flair isn't using dreambooth. They are using their own custom trained models, which to my understanding was some sort of mask based, with outpainting. The issues with dreambooth are not only text but also product fidelity. You cannot get the original product fidelity preserved with dreambooth. Also dreambooth required people to custom train models which was very inefficient. better methods have popped up after that. ControlNet, Adapters, Composer(pending release).  finetuning models to my understanding is not needed as of now. You can control, style, image composition, colour scheme without finetuning a model for usecases similar to flair. \n [PHONE REMOVED] I missed this. Primarily speaking training a model on an object and trying to recreate it during the generation process fails when the product fidelity cannot be compromised. The only method which exists as of today is to start the init image of the pipelines and then create the rest of the image. Even when you do that you can see that the product will get changed because all the SD algorithms work in latent space and not in pixels space. This compression and reconstruction of the image makes it impossible to get the original product image which is present in init image. however the solution is very straightforward . All you need to do is copy paste the pixels on the final image where the product exists. No need for LORA or anything of that sort.  \n Is anywhere working on apps like these : https:\/\/news.ycombinator.com\/item?id=35236275 \n Worked on document search. \n Thanks for explaining! I was thinking about this problem statement the other day. What if we take a pic of the product photo in the exact orientation we want, remove the background and inpaint a new one around the product? Haven't tried out Booth ai myself though \n They are using LLM + embedding approach. Guess they use LangChain as well under the hood. \n Yes this is exactly what I was talking about \n And that's why you will have these differences. This will work for e-commerce folks at all. Especially for high value items like furniture \n it will or won't? My understanding is that it won't work. \n It definitely WON'T work! Sorry, did a typo in the worst possible place \ud83d\ude05 \n But here's a method that I am reasonably confident WILL work - Users can use a Nerf capture app like Luma to generate a 3D model from any novel viewpoint. It's as easy as walking around a product while taking a video and takes like 30s. Perhaps extract a mesh from the capture because that's easier to render in a browser than Nerf. Then in your product let the user rotate and orient the accurately captured product however they want. Take a snapshot of it without background. Then mask and inpaint like you did. \n This will remove all limitations. Highly accurate and infinite product photo generation from any angle in every aspect ratio for all your visualization needs. \n [PHONE REMOVED] isnt simple bg subtraction and some bg improvement good enough for ecommerce? :thi \n [PHONE REMOVED] s images also seemed mostly really smart bg replacement only. \n [PHONE REMOVED] you can read up on this as well. https:\/\/www.deepset.ai\/blog\/build-a-search-engine-with-gpt-3 This is by deepset and they have a framework called Haystack. I was looking into it in June of last year, and it's pretty good. Suggest you check it out as well. \n There is a slight halo that is visible if you stare at it long enough \ud83d\ude05 \n Yes, because that is what it is. It is BG replacement. \n I was using similar method too for characters in a scene but this halo hurt the continuity. I am moving to using controlnet for this. \n A lot frankly. But that was mainly cause the original lighting of the image had it and I didn't wan't to spend time to remove it. \n I am using controlnet \n The images are from using controlnet \n Yea. Lighting causes it. Magic brushing with smudge over it removes it usually. \n Ah really. \ud83e\udd14 \n Maybe mine have a halo too. lemme check \ud83d\ude05 \n Yes that's the ideal case if you already have the product photo in the exact orientation you want. Real world situation is that product photography is a whole other expensive initiative usually done by a different team. Marketing which creates the final images comes in much later and they have to make do with what they already have. Like there's a whole workflow for this thing. \n ^Yea. I was asked to once build a 3D rotating platform to take ecommerce photos :P \n For constant lighting, bg etc. \n So if you have a 3D capture that the marketing team can put into ANY orientation to generate images that's a big advantage. \n 3D is hard for a lot of use-cases like clothes, grocery no? \n Your eyes will fall out if I show you Nerf captures of clothes and grocery \n Hahaha. I have not done nerf but in my freelancing days, number of folks who reached out to me for 3d capture of clothes expecting realistic results was \ud83d\ude4f \n And then folks also wanted these clothes to go over humans and look \"natural\" \n I might even have a long mail explaining \"Cloth Simulation is not a solve problem\". Definitely not in freelancing monies :P \n \ud83d\ude1b \n Danny postama is doing to decently well now \n Catching up with these messages \n I'll add my colleague Bharath here who can go even deeper into the nuances of product capture and visualization for e-commerce. [PHONE REMOVED] he can share a lot of great inputs about product imaging for e-commerce. He was interacting with a lot of e-commerce store owners and product photographers from enterprise to small Shopify merchants \n Hey folks! \n Also [PHONE REMOVED] The code for this is still pending. but you can look into this project as well. https:\/\/dolorousrtur.github.io\/hood\/ \n the demos are \ud83d\ude4c \n Damn. This looks good. But lets see how replicable it is. I am a little skeptical. \ud83d\ude05 \n Damn this is also my lab \ud83d\ude02 \n Welcome [PHONE REMOVED]. Bharath is a colleague of mine from Avataar who has worked extensively on generating 3D models using Nerf for e-commerce. \n Ah, I see. \n Hello everyone! \n https:\/\/a16z.com\/2022\/11\/17\/the-generative-ai-revolution-in-games\/ \n Hey Bharath! Really excited to see someone work in the nerf space. \n Hi All, Anyone in here who is interested in https:\/\/www.adept.ai\/ and similar space? This is a different space than generative AI but will be game changer in how we use computers. \n Yes! afaik this was always a research area in RL. https:\/\/proceedings.mlr.press\/v70\/shi17a.html. Curious to learn how they\u2019re going about it. \n This space is very exciting! Even more so that this can actually be done via prompt engineering- https:\/\/github.com\/microsoft\/visual-chatgpt \n [PHONE REMOVED] and myself :) \n The model at adept is pretty good \n Someone replicated Adept \n Using GPT4 API, same control as GPT4:  \n I don\u2019t think adept uses VQA or image captioning  - looks like it works with the DOM \n Might be wrong, but that\u2019s the impression I got when I played with it back in august \n August 2022, might as well have been last century in LLM years \ud83d\ude05 \n Hahaha true \n Folks in US can sign up for Google's BARD (waitlist) here:  \n But VQA is still prett shit right \n I tried blip-2 from Salesforce and it was average \n ^That's Google's attempt at making GPT3 \n Predictably, Adobe is going to drop something big in generative AI. It's a tough fight for horizontal gen AI startups. Adobe ships solid products \n https:\/\/mobile.twitter.com\/ESYudkowsky\/status\/1635577836525469697 \n idk, it's adobe -people will avoid lol \n Only people believing that Alpaca is as good text-davinci-003 are the ones who've not tried both. \n Creative world runs on Adobe. Nobody avoids. At max they pirate \n Niche and industry specific vertical AI products are fantastic markets for startups right now. Like textile design, which uses Adobe products, but only as a part of a deeper workflow in which a generative AI startup can capture the entire stack. From tilable texture generation to fabric pattern generation.  \n I agree also adobe is the OG computer vision company. They literally are deepest in computer vision tools.  \n You couldnt be a creative without adobe tools before gen ai.  It is the Microsoft office for creativity. But then like office, I don\u2019t think they\u2019ll make their weights public. \ud83d\ude1e \n Yeah they're going to play it like Microsoft. \n For a large corporate company, it's overcoming the inertia is the challenge \n products which focus on specific workflows like Descript, RunwayML will carve out some market share, i think. \n otoh, crazy to see how Canva is not visible in the GenAI space. although they launch stuff only once a year, still idk if they have a focus on ML research or not. \n https:\/\/youtu.be\/DiGB5uAYKAg \n Nvidia livestream is live Rn \n The criteria for these horizontal products to succeed is that they have to enable a non expert to create output that hits ALL 3 criteria - fast, cheap and good quality. A designer using Photoshop or Premier Pro currently can hit only 2\/3. Fast + cheap is rarely good, and so on. Canva worked because it let an accountant create a classy looking event poster in minutes. There are some ways to do this, true. Like radically new UX, template based creation and having the best model in production consistently. But it's very very hard. \n Okay holy shit firefly is impressive \n This is so good. \n Do you have access? \n No just checked the features out and wrote a thread on it \n But they basically are problem first. \n Not for fun, or entertainment. How do you use AI Art models effectively to solve problems (vs entertainment) \n This is mostly catch up on mid journey and runway, right? \n Nope \n It\u2019s competing with designer and canva \n But completely overthrew them \n \u26a0\ufe0f\u27a1\ufe0f\ud83e\uddf5 \n I had the same question \ud83d\ude05 \n This is Yudkowsky's propoganda trying to make the business model of building foundational models less attractive \n In the thread he explicitly said if this was pointing in the other direction, he wouldn't have tweeted it \ud83d\ude02 \n The ImageCaptioning model it\u2019s using, i.e., BLIP, is pretty bad imo. \n this worked very well for me https:\/\/huggingface.co\/spaces\/fffiloni\/CLIP-Interrogator-2 \n Or use VPN. \n I know lol, I didn't take it seriously but saw the features. Blew my mind \n Adobe have done a very good job \n Open to changing my opinions and not going to be rigid \n https:\/\/twitter.com\/vinniemourax\/status\/1638218512760971277?s=20 have people seen this? \n https:\/\/www.youtube.com\/watch?app=desktop&v=DiGB5uAYKAg&feature=youtu.be \n Is there an API version of this? [PHONE REMOVED] \n I converted this into an API, I will send you the script if i find it. \n I found this, but seems like a task to integrate: https:\/\/github.com\/rmokady\/CLIP_prefix_caption \n i think replicate also has this \n People started interacting with BARD already \ud83d\ude05\ud83d\ude05\ud83d\ude05 \n Twitter is fastest \n I tested lamda 3 months back only \n It's worst model \n this maybe useful https:\/\/gist.github.com\/ovshake\/69efb594f3b1e8d98b34687b16916145 \n Link?","19":"this one probably https:\/\/replicate.com\/pharmapsychotic\/clip-interrogator \n Also sorry, have been lurking, didn\u2019t introduce myself. Vishal Tripathi, Venture Investor, worked on a fund of funds strategy for Google Ventures - Plexo Capital. Currently with Legacy Venture, investors in many of the funds people have mentioned above (Sequoia, A16z, Matrix, Accel, True, etc). Love the conversation and learning a lot about the space, also building tools on the side\/over weekends. Someone mentioned Yohei (from untapped VC) above, he\u2019s a close friend and I\u2019ve collaborated with him on some of those GPT tools and love learning about these new use cases. \n Hi,  \n I have a proof of concept script that I would like to take to customers \ud83d\ude03. \n Fun blog post for folks who are in marketing or content or do a lot of writing work in other ways:  \n The last line of this link is: This will make certain people really mad \n Wowww! \n Damn, this is so good. Me want! \n I hope its as good as it appears, would be sooo coool \n Infinite customization is actually a pain. Firefly imo is a great example of limiting functionality and making it more useful than the competitors. \n Pre Firefly Adobe was doing all its ML inference on user's local system? Can anyone confirm? \n Adobe express is not local, you could do stuff there online.  \n Hey Vishal, nice to meet you! \n DMing :) \n Just came across this paper today from another route as well. Planning to try it on HF and look through it \n Can add him here \n He published in CVPR 2023 \n https:\/\/www.cs.umd.edu\/~shishira\/Nirvana\/nirvana.html \n Works with video compression, he\u2019s a good friend of mine \n https:\/\/github.com\/microsoft\/MM-REACT \n Demo looks good and better than BLIP-2 \n tf, they literally cloned the langchain repo in it \n https:\/\/huggingface.co\/spaces\/microsoft-cognitive-service\/mm-react \n i uploaded my picture and asked it to describe it to describe me in close detail. It did a decent job. \n send results? \n folks noob question but has openAI exposed multimodal inputs to GPT4? I see that I can only feed chatGPT plus text. \n not yet. very few have access to visual input right now. \n ah understood thanks! \n anyone working in any projects related to healthcare? \n Yes \n Do tell.","20":"Patiently waiting for them to let everyone use it \ud83d\ude02 \n Oh I realised I did not introduce myself. I'm Dukaan's head of AI.  \n If anyone's interested in seeing Jadoosnap you can use the link below \n JadooSnap.com \n Have seen this, great work! \n Going to take some time for public access - there are a few companies using it already \n Any way we can request access for Dukaan? \n https:\/\/twitter.com\/T_Goody3\/status\/1638203321704955904?t=8aQye9lDksWh81DJjhZGlg&s=08 \n Hoping to get a contract with the gates foundation to build a Whatsapp chatbot to guide rural nurses in India.  \n Rural india would need Hindi \n Hindi is supported by both GPT4 and Whisper, so quite doable \n Most popular Indian vernacular languages are in fact \n We\u2019re also using bhashini - an indian government funded research project that has a fine tuned whisper model for hindi \n The hindi results of gpt are not as great as english \n Slightly confused then by Bill Gates writing about an Indian startup working on LLMs for Indian languages \n This is probably why \n Yes, same findings. Plus the source documents are all in English too. Using google translate so that gpt only ever sees english \n Hmm. Doesn't look like it with GPT4 \u2014 original ChatGPT was worse. Using Google Translate would invariably add error. Propose a test set on this \u2014 why discuss opinions when we can run experiments! \n Openai\/evals \u2728 \n Anybodys got any idea how to achieve this? \n Change the tint of image to RGB (may be converting to grey scale then colorify it), add noise and then denoise guided by prompt a photo of baby \n Controlnet \/ depth2img \n This is too clear ultra sound \n might create false expectations for parents \ud83d\ude05 \n unet came out of medical imaging, so i think in future, rather than taking home ultra sound, you might take back a generated photo realistic image \n Why stop there? Ultrasound \u2192 Baby Photo \u2192 Age by X years is a known dataset \n That as well, bachche ki shakal to pregnancy scanning se mil hi nahi, hospital be bacha badal diya hai \ud83d\ude02 \n Link? \n You jest, but I'll wait for the next medical provider data breach to get this dataset \n https:\/\/gooey.ai\/ai-photo-editor\/?run_id=4ndpy7e0&uid=Nli0J2dP80WU3sdJ9RCw3DeNvIT2 \n Regarding the Adobe products that someone else mentioned, it\u2019s out now \n https:\/\/www.linkedin.com\/posts\/alexandru-costin-a4367_adobefirefly-ugcPost-7043965991910854656-pjbp?utm_source=share&utm_medium=member_ios","21":"What was the prompt :) \n What model? \n Omg the second prompt \ud83d\ude02\ud83d\ude02  \n But this prompt and neg prompt alone isn't enough. It won't give you the robot heads or the glowing eyes, colour tone or the exact kind of armour and rifle that you want. So you need to do a lot of composition iterations \n I've created my own now based on what kind of output I want. It's a checkpoint merge between deliberate v2, dreamlike_photoreal v2 and a few others \n The style reference for this second pic was not in the prompts, rather it was a Rembrandt painting, which is why he's wearing medieval looking plate armour along with what looks like leather and chainmail \n https:\/\/openai.com\/blog\/chatgpt-plugins \n Curious to see if this goes the way of ios\/android apps or Alexa skills. \n I would bet better success than  Alexa Skills anyday \n https:\/\/platform.openai.com\/docs\/plugins\/introduction \n [PHONE REMOVED] \n [PHONE REMOVED] is working on his next company. He was CTO at BharatPe until recently. \n Thanks Pranjal! \n Hi everyone! Glad to be here! \ud83d\ude42 \n Very very unrelated: Has anyone here worked on Firestore? \n We\u2019re stuck at one place and need some help \n Very off topic \ud83d\ude05 \n Hey everyone, got quite a bunch of people who showed interest in attending this. There are a lot of people in this group who are hacking projects on the side, DM me if any of you would want to talk (or show demos) about your projects tomorrow, would love to host \ud83d\ude4c\ud83c\udffb \n Can you share that message again, some of us joined the group after the message was sent \ud83d\ude2c \n Hey folks! \n here you go \n Thanks \ud83e\udee1 \n https:\/\/analyticsindiamag.com\/the-hidden-cost-of-chatgpt-for-indian-languages\/ Is this cost analysis accurate? \n Yes \n You can try it out here \n https:\/\/platform.openai.com\/tokenizer \n Got it. Thanks \n does anyone know if opencv videocapture() can connect to an external iOs camera? \n Not sure about iOs but in android you can capture using any wifi camera app, if there is same kind of app for ios then I think you can do this. \n Do you interact with GPT in English or directly in vernacular languages? \n Direct vernacular is supported \n Doesnt have very good performance though","22":"Can try few shot learning for training \n I ran out of context length before I could stuff enough context for it to have significant improvements \ud83d\ude02 \n What was your workflow? Like what tools did u use? \n Completely using Stable Diffusion. Workflow was first using text2img with controlnet depth map of this image. I got the depth map from Clipdrop's API because it's really good. Thanks to Sudharshan's tweet for this tip! Fixed the red background using this.  \n Do you use automatic1111 for all this? Or just code \n Automatic1111. You would go mad doing this with code \ud83d\ude05 \n Makes sense. Have you played around with langchain agents \/ chatgpt plugins?  \n I think certain things are easier and more fun with a UI - when you need more control and direction a UI would do \n Neat! The depth maps have more control \n The only problem with this is that you need to run iteration loops in every step until you are satisfied with the output before moving to the next step. Doing 1, 2, 3 successively would not work. \n And this is nothing new for artists: retakes are common \n Personally what fascinates me more about AI generating art than generating code is how a deterministic input (auto encoder, model weights, controlnet algorithms etc) can give infinite non deterministic output. \n I believe the non deterministic output still stems from a classical random number generator :) if you keep the seed constant, its very much deterministic. \n Yep \n Simple but quite useful, the entire concept of seeds \n To someone who has control over enough constraints the entire universe becomes deterministic \n There are in theory infinite seeds \n Oh man, this debate itself is infinite \ud83d\ude06","23":"https:\/\/www.youtube.com\/watch?v=L_Guz73e6fw \n No technical details (few hints here and there); but lots of philosophical nuggets about how Sam Altman and by extension OpenAi is thinking about development trajectory \n https:\/\/www.youtube.com\/@aajtakai\/videos \n As we all work on AI and have been inundated with new AI advancements & specifically blitzscaling of OpenAI & Microsoft since last many days, here is a video on *The A.I. dilemma* talking about safety and what's at stake with respect to new exponential growth of LLMs.","24":"Putting on my friendly salesperson hat, please share this with your friends (and lovers?) in Bengaluru \n **Deep Hack Demo Day Invite** \n Wish I could attend but flying out that day \n Jobot, a ChatGPT-powered bot is live at Jovian \n Would u be streaming the Demos ?  \n For those unfamiliar with who I am: Anthropologist and senior fellow with the Max Planck Institute for Social Anthropology (Halle, Germany). Am originally from Amsterdam but often in India (in Bangalore as we speak). I\u2019m particularly interested in the way those working with AI - data scientists, ML professionals, artists - relate to the inherent unpredictability of their models. \n Welcome to the group \ud83d\ude04\u2728 \n Better introduce yourself real fast! \n Sure. I\u2019m Hasan, a new media artist and an educator. My practice is focused on making the cutting edge accessible. I use AI, Robotics and code to build magical experiences. I have been mentoring international artists over the last 5 years about how to use technology to augment their practice. [PHONE REMOVED] and I also run https:\/\/responsibletoday.in focused on addressing the societal challenges of technology in the Indian context. Glad to be a part of this community, you can find my website on my WhatsApp bio and please leave a message if you want to have a conversation. \u2728 \n is it done via stop motion? \n Hey Hasan! I remember seeing your work at the art tech community fair. Good stuff! \n No vfx have been used for this video. It\u2019s the raw recording. OCR -> content search -> style transfer  -> projection mapping \n I\u2019m trying out some generative video models for the future iterations but those are very slow at the moment. \n https:\/\/github.com\/justanotherlad\/blindvisaidgpt \n nice to meet everyone here btw; i\u2019m swastik, search engineer at wolfram|alpha :) \n Isn't OpenAI already is doing this with BeMyEyes, am I missing something? Guessing you want a open source version? \n correct \n it\u2019s always a plus to be able to add a bunch of other visual foundation models :) \n What about blip-2? Seems that's been doing well on captioning tasks? \n Also, a kick ass demo of this built over 12h is amazing bragging rights \ud83d\ude05 \n Swastik has a great demo of WIP stuff here btw: \n [PHONE REMOVED] i was trying a bunch of stuff aside work :)  \n esp integrating ControlNet to alter per specific requirements for a particular color blind person? \n I'll look into this. Traditionally, have avoided doing this because participants feel like their ideas or work might come under too much light too soon. Will ask the folks at the hackathon itself and decide accordingly. \n Were you able to get the WiFi camera connected? Using the wifi camera steaming apps as someone had suggested. We had done something similar but for visually users to navigate in indoor environments. This was device that detects collision probability and provides feedback to user using haptic feedback. This was a long time ago, so running complex enough model on cheap hardware (think 2014, < Rs 10k phones) was quite hard. All the very best. \n *streaming \n sounds interesting \n do you have a repo for it? \n This wasn't open source per se. We had done this for TechMahindra. Please don't share outside. https:\/\/m.economictimes.com\/tech\/ites\/tech-mahindra-tests-goggles-for-blind-plans-variant-for-cars\/articleshow\/45302948.cms \n But one could do this today, if someone is looking for ideas. Phones have decent compute to do interesting stuff. There is a challenge in distribution because you might need different  optimizations for different manufacturers. But for a quick demo this could be really possible. \n If anyone is interested in making ControlNet work on iPhone, this is a good start: https:\/\/github.com\/apple\/ml-stable-diffusion\/issues\/131 \n Hi, Does anyone know of any text to video tool through which one can do camera movements over still images? \n Zoom\/pan\/tilt that kind of thing \n We have a controlnet webapp and API too :) \n Nice do you offer all modes? I\u2019m building an app and was looking to deploy on runpod or modal \n The underlying container is opensource too so you should be able to deploy on modal \n No sir, I bring my own gpus \ud83d\ude02 \n Ive tried at least 5 different serverless gpus. None of them have a way to get excellent cold start times where you have over 30 models and sparse network activity. \n See, I need clients like you who have over 30 serverless models \ud83d\ude05 \n If you define a simplistic DSL (something like MOVE LEFT 3) then you can directly call the transform or scale. Or you could also provide some examples, in your pre-promt to GPT to create the transformation functions. \n That is quite good price to perf ratio for most B2B use cases \n I think it'd be helpful to have a more simplified answer. [PHONE REMOVED] isn't a ML Engineer \n I\u2019ve worked as an ml engineer at amazon. \n Thanks i got that \n :) \n For what model sizes you are getting these latencies? \n Aeee, you told me you wrote for TVF Pitchers S2!  \n Wow what! \n Haha in my previous avatar I was an ML Engineer. Can't help combine the two skills now that AI is going where it is going. \n I use accelerate to offload to cpu which lets me deploy all of them on a single a100 without running out of gpu. Latency is less than 5 seconds for the diffusion models. \n My vision is to be able to  make full scale movies with AI \n Model sizes isn't perhaps a good proxy for the kind of work I am doing: think TorToise TTS, GPT-6J as a proxy \n People accuse OpenAI of putting software engineers out of job, Shubham here is putting King Khan and Deepika Padukone out of work. No one is safe any more \n On second thought, very curious to know how GPT will handle degeneracies. \n Or trying to save himself from going out of work \n Make AI to write and create episodes for the final season of GOT, my goal \ud83e\udd72 \n Makes sense. Because i have tried with around 5GB model size and it was more than 40 secs \n 1. Their own cold start times have improves over Feb and more in March \n I started up with this dream. \ud83d\ude05 \n Yes.. they are getting better. In feb it was around 60 secs \n Just checked this, basic part works. It is even able to create even Homography matrix if I say move left by 20% etc (Homography Matrix tells how to transform an image by translation, scaling eyc). I thought it will  gets tripped by degeneracy. But it gets tripped up even before with non commutativity of matrix multiplication. So please use that idea with caution. \n unrelated but this seems really interesting; i\u2019m a regular user of sam harris\u2019s Waking Up \n I\u2019ve tried giving it those direction questions (start north move 30degree south \u2026 where are you now), from a mental ability textbook and the performance is shit. \n New AGI test: Can GPT4 do route planning for a Logo (anyone remember that?) pointer in specific shapes and mazes? \n That's gonna be a yes, I think. \n I am a little more curious about its ability to reason about problems in its distribution but not in its data: eg. leetcode hards that it might not have been trained on. \n Asked GPT-4 (via ChatGPT Plus) the following puzzle for and it fumbled and failed. \n As per the paper they can't do well. See Aravind's post about contamination: https:\/\/aisnakeoil.substack.com\/p\/gpt-4-and-professional-benchmarks \n Is it 20kg of supplies all together or each person? Can the supplies be broken? \n Thanks, yall. \n \ud83d\udc46\ud83c\udffd \n The 20Kg of supplies are together. No, the supplies can't be broken down. Have to be carried as a whole 20Kg. \n GPT-4, on NEW Leetcode problems past its training date, in 5 attempts, gets \n Yeah, not 100% sure of this. There are just so many questions out there, that these newly created questions could just rewording without change in core idea. See Aravind's blog. In my experience with ChatGPT, when I give problems that are easy to medium and then I change the problem ever so slightly in its core idea and it will get it wrong. Or there are tell tale signs it has mugged up. Like I will give a problem that is a coin change in disguise with coins that are multiples of each other.  Thus allows greedy solution, it will provide a DP Solution (I am not even testing for corner cases etc or even if it will run). Just whether the core structure is right, which it did not. So in my experience small perturbations to core idea causes drastic change in correctness. \n Hard questions usually are what differentiates for top ranks (and much fewer) and could just be what people put more effort in creating. \n I saw someone on Twitter saying gpt-4 does much worse than leetcode hard on newer Euler problems. \n https:\/\/about.sourcegraph.com\/blog\/cheating-is-all-you-need \n The author for some reason seems to be discounting Github's excellent search product which has similar or maybe larger advantage than Sourcegraph \n The author is quite famous Steve Yegge. \n yeah I noticed, I liked the rant style \n Why do you think my Substack is called niranting.substack.com ? xD \n His infamous Google rant from 2011 https:\/\/gist.github.com\/chitchcock\/1281611 \n Yeah, obviously he'll be baised for his company. But larger point he makes about how people are underestimating potential of LLM powered coding assistants by seeing a few edge case failures of code generation on chatgpt is quite valid. Finetuning LLMs for user's existing codebases + building search capabilities on codebases will be gamechanger \n I believe https:\/\/www.buildt.ai does this \n Github Copilot X(available for preview only) is doing it (https:\/\/github.com\/features\/preview\/copilot-x) \n Thanks for sharing. I absolutely think this is monumental and going to change how we work. And working on something using LLMs. Funny thing is the same time, question I asked it is the exact kind of question I would usually ask a fresher to know if they are faking it (as in just knowing the answers mugging up a lot of leetcode answers) or they conceptually know it. I do think lot of the code today we write, will easily to automated too. That begs the question what won't be. All the glue code, all the templates, all the code that is quickly needed to get a project up and running will all be automated. What will possibly remain? So what skills will become more important? \n Remote submissions are eligible for prize. Correct ? \n Yes","25":"Hello everyone, this is Dr. Parth Sharma...I am a doctor by profession...i have keen interest in python and likes of AI, deep learning for some years now...i look forward to learning\/implementing some good stuff here in medical AI especially \n Hi all,  \n Andrej karpathy on youtube \u2728 \n Which videos? \n We are vision-mission buddies \n New Prompt trick: Every time ChatGPT gives an answer I am not satisfied with in terms of detail, I just go full gym bro on it: \n Realised that you can use GPT-3.5 as data resource even without internet connection. I asked for a list of shopify websites in USA which sell Candles. I use those links and asked chatGPT for a crawler code to get email Ids. Till now I got 130 valid links. Incase anyone doesn't have the money to splurge on databases and want some free solution, try this. \n were you inspired by: https:\/\/twitter.com\/AKASpencerScott\/status\/1638996898941124609?s=20 ? \n It's pretty good at competitor analysis too. If you give precise small collection and ask it to give you similar companies, it will get you really good ones. It tends to give general answers, so need to do prompt engg to really get the interesting things. \n Oh wow. No. I was trying to get shopify lists and thought it will give me a way to get it. However, it started giving me the actual links. \n Hmm, interesting - didn't quite for me \n Pratyush bhai, Is that the best you can do? \n Thor got depressed after that win. Let's not do that to GPT4 \n Hi, \n Is this a real person? \n No \n Which checkpoint are you using ? \n Does the image have Exif data of generation ? \n Did you try dreamboothing her? \n I'm a simple man. I see Deepika Padukone, I \u2764\ufe0f it \n No, I was too tired to dreambooth today. Spent so much time on the jacket and trees that I was pretty exhausted \ud83d\ude1b \n I know, right? \n Dude this became a point of debate.  \n Not aiming for photorealistic fwiw \n On the one flower in focus, the petals look weird. \n Depressed software engineer from Bangalore spends all night generating AI girl, falls in love. Laptop crashes at midnight, man loses checkpoint, seed, prompt, everything. Cannot recreate girl. Has only 1 image. Shares image online with heartbroken message. Kind netizens of Bangalore organize a search for the real girl. Girl is found! She is a photographer. They get in touch, romance kindles, they get married, AI generates their wedding invitation. Cinderella 2023. \n The plot of Her, Yash Raj Films edition \n Sell the movie rights to this \n Make this movie using AI > Sell the movie rights to this \n Would watch this movie. Extra props if it\u2019s made using AI \n \u201cThere is no good and evil. There is only Balenciaga\u201d. \n https:\/\/youtu.be\/kCc8FmEb1nY \n I had a Deepika in Arcane animation art style. But literally lost the seed, prompt and everything \ud83d\ude2d \n Arre arre yeh movie tou real hain \n In Greek mythology, there's a similar story of a sculptor who falls in love with a statue that he carved: \n This is my bumble bio from today \n Length of the neck gave away a little\ud83e\udd2a","26":"https:\/\/twitter.com\/io_Y_oi\/status\/1634835399918108673?t=malrs07ZHMBbup1Pr7gO-g&s=19 \n Google Partners with AI Startup Replit to Take on Microsoft\u2019s\u00a0GitHub  \n i wonder if ghostwriter is gonna use Bard now \n Anshul sir [PHONE REMOVED] runs India Replit \u2014 and they're sponsoring the hackathon (https:\/\/has.gy\/gpt4hack), ask him how you can try GCP features on Replit! \n For engineers wanting to get a first hand feel of how to write a GPT from scratch, this is great \u2014 but I wonder how popular will be that in the months, years to come? \n Theory enthusiats who are still in college might do it as it gives them the sense of having deeper knowledge. \n Elon Musk, Emad Mostaque, Yoshua Bengio, Steve Wozniak and bunch of other famous people have asked AI Labs to not train systems more powerful than GPT4 for 6 months and instead use this time to \"jointly develop safety protocols\"  \n Playing around with alien technology needs a built-in stop-loss \ud83d\udc4d\ud83c\udffd \n I wonder if you'd have felt the same way about printing press, Internet or smart phones\/social media. \n Zooming out, the Church hated printing press, horse-specialists hated Ford cars, Govts hate social media and engineers outside Microsoft\/OpenAI hate GPT4 \u2014 there seems to be a pattern here :) \n The only sane way to align incentives is to buy $MSFT, Nvidia and ASML xD \n Yea, but we 'understood' how these technologies worked, right? \n Like printing a book by itself does not have any meaningful emergent properties, unlike AI. \n Ofc, printing a newspaper has emergent properties? How do you think nation states came into existence? \n There are of course societal effects, which can be called emergent \n Also, we've gone too off-topic \u2014 let's move to DMs \ud83d\ude06 \n Does anyone know Richa Gandhi, the journalist who wrote this? Would be fun to have her here perhaps? \n BIC is having an event on \"ChatGPT and it's Ilk\" by Anil Ananthaswamy, a science writer and editor. \n For folks who are wondering how this'll play out wrt Search and ads, Bing Chat has ads: https:\/\/twitter.com\/debarghya_das\/status\/1640892791923572737 \n Will be waiting to see stats on CTRs and their subsequent effect on CPCs.  \n I think those are valuable discussions though. Can we utilise the WhatsApp community feature to have a philosophy room? So people can continue those discussions. \n Yeah man if there's anything related to gen AI it's cool with me \n I don't care if it's just 2 people talking \n Context can be figured about scrolling in the north direction \ud83d\ude02 \n That would be great! \n The group is small and would want to keep our _attention_ here at the moment \u2014 as a reminder, most people here don't do this full time :) \n Will consider doing a philosophy fork if we've more topics like David Chalmers coming up organically \n While we are on the topic - another point to support the case for forks at some point would be to have some use-case specific groups - such as photo studio, legal, education \n That\u2019s fair. we can make a small philosophy group with the few people interested in that and do this full time. Is it okay with you if I share the link here? \n Yeah, go ahead! Added a group to the community which makes it easier for folks here to find that hopefully \ud83e\udef0\ud83c\udffb \n so missed the important classifier _Funding_ feel free to drop a \ud83d\udd25 emo to identify :) \n Reposting because lot of new friends! \n Streaming, pls! \n And for those who want to _participate_ in the hackathon in BLR: https:\/\/has.gy\/gpt4hack \n One of my recent best reads: https:\/\/direct.mit.edu\/daed\/article\/151\/2\/183\/110604\/Do-Large-Language-Models-Understand-Us \n Hey hey I want to be in these DMs \ud83d\ude05 \n Same \n https:\/\/twitter.com\/tobi\/status\/1641010421493637122 \n what is the source for 100 Trillion? have we already reached triple digit in trillions \ud83d\ude2e \n Don\u2019t think 100 trillion is right. Sam Altman had clarified in the podcast with Lex that 100 trillion is just a meme going around. ~1-10 trillion is what seems probable (though thats also a speculation, no authoritative source) \n https:\/\/twitter.com\/marckohlbrugge\/status\/1640961076039925760 \n Alt - builders can apply too for any projects this weekends fyi \n You kinda need an active project with a website, \"CTO\" and stuff to apply \n Why does this look like a phishing attack? \n We're talking to Azure and going via them for Azure OpenAI credits \u2014 OpenAI ghosted already. Will see how this pans out! \n Grant Eligibility: \n Ah got it \n I mean its a random google form with no actual announcement from openai, feels very phishy \n And a Google form instead of their usual Microsoft thing which they use in Wait list \n https:\/\/futureoflife.org\/open-letter\/pause-giant-ai-experiments\/ \n I found this which looks more plausible: https:\/\/openai.com\/microsoft-for-startups \n [PHONE REMOVED] scroll up maadi, this is the first thing we discussed today xD \n any good hacks to reduce hallucination of gpt? \n Add to System Prompt: You are a Harvard Professor of <whatever domain>.  \n Treat GPT4 as a naughty 5-7 year old who talks a lot, wants to be helpful and if you say the same thing in 4 different ways it'll eventually listen to you \n The talk at BIC was excellent today. \n And it was a packed house. \n I use a score in interactive sessions. So penalize when it starts to hallucinate. That seems to help. But not in first time prompting. Similarly score for speed seems to help  \ud83e\udd2b \n More like a 9 year old since it passed the theory of mind test \n btw \n We'll not go there, because it's already better at Leetcode, Chess, flirting and bunch of other things than me. The only things I'm better at are puns and Shayari at this point. \n I bet it could very soon be better at those too \ud83d\ude05 \n It making up stuff and saying things that not true, creating references, articles etc \n Ask for references or sources ? \n Its like doing a peer review of a paper when it is to be published \n Once the model hallucinates, this doesn't help \u2014 it'll make up a source \n But if you've an extra API call, you can do a self-consistency check: \"Are you sure your answer was correct using the information below:\" \n But we can verify if the source is legit or not ? Or does it cite something that might be obscure ? \n And yeah very good one at that. I had it create references with actual researcher in that area of maths. Just that they didn't write the paper (at least not yet or don't know if it had access to data I don't have access to ;) \n Are you using penalty system like the Dan jailbreak?  \n Depends on the task \u2014 for open domain QA, it'll make up very believable stuff and you'll be tripping acid for a while. For closed domain QA, verification is somewhat easier but harder to use this signal. \n Ghosts of Future Past: Math Papers edition \n ```refine``` from langchain works well for gradual operations around this \n Not not across sessions. No did not use DAN jailbreak. \n What surprised me was that the speed one worked. Can others try and let me know if it works for you too. Nothing Fancy: start with saying you get +1 for producing the output fast and -1 for slow responses. But ensure that you doing when things are bit slow. Last 3-4 days, it adds a disclaimer that it will be slow irrespective but in my experience it was decently fast compared to otherwise. \n Because if this works, seems like they might be throttling using prompts!! Which just didn't seem right. \n I was thinking of doing something else. Basically you can make a series of questions answer pairs based on the output it gave and then search using serp or other available tools to validate or invalidate the answer. Haven\u2019t tried this out but will do so when I get the time. \n second one does seem to work. will share here if I find any really good solution. was thinking if a custom agent implementation helps which first figures out if this is made up (does induce recursive problem) and then dodges the reply if yes. \n Self Consistency is empirically known to work: arxiv.org\/abs\/2203.11171","27":"was this before or after the GS report of 300 million jobs likely to get impacted ? \n Yeah this was a surprise - Stuart russel and Yoshu bengio signed off on this \n I personally think any kind of hindrance to tech hurts the entity that's hindered, and is hardly ever fruitful. \n But this won't happen \n OpenAI is a for-profit company \n And backed by microsoft \n It's like asking Apple to stop innovating and launching new things \n In 6 months openAI went from gpt 3.5 to gpt4, will they really stop training new AI models for the next 6 months just because of a document on the internet? \n Perhaps more marketing\/bringing awareness to the issue - like Balaji \n They won't, and they shouldn't. It's a joke. \n Even if I was running a non-profit AI research lab.  \n true lol \n It's all virtue signalling, which I completely understand. But that's for outsiders. If you're an insider, you really should see this as a joke. \n I'm surprised with Elon  backing it \n So looks like strategy to catch up rather than concern \n Yann Lecun drew a line in the sand! \ud83d\udd25 \n Google Bard is trained on ChatGPT \u2014 the first author of BERT, Devlin, resigned over this?  \n Wasn\u2019t the whole point of buying Twitter the data it offers? Hard to justify the price he paid for it otherwise \n Elon is famously very pro-Govt when it benefits him: He takes tax rebates for Tesla via their Solar City acquisition, lobbies NASA and Congress to use US launch vehicles instead of European or Indian. He's basically Ambani Redux. \n As someone who has worked with Elon : I second that.. \n FYI - most likely this was a phishing scam (that i fall for as well), have reported it to twitter and google, let's see what happens \n I got 2500 OpenAI credit as well. \n by filling this form? i doubt it \n Loss of long term memory is a feature not a bug. \n Got it.. I got email from OpenAI \n In what capacity? \n Leading data program at Tesla. \n Oh nice! \n Aditya is working on building an Adept rival from Namma Bengaluru! Hit him up if that's your vibe :)  \n Thanks Nirant.. \n We've got a bunch of very interesting folks here, feels like home \ud83d\ude48 \n This calls for more elon gossips \ud83c\udf7f \n Would be way more interested in Karpathy's work, the work Tesla did with synthetic data e.g. simulations and how they manage _truly_ big datasets! \n Sure. I def have some nice ones to share... \n I vote for aditya focussed meetup \ud83d\ude02 tesla pe charcha \n I dint work with Karpathy as Data Org is different than car engineering. But worked on data privacy program which had overlap. \n Hi All,  \n Hey Aditya great to see you here :) \n In case you are comfortable sharing, would love to hear about your 'Bhramastra' against adept and inflection. \n Hey Aditya!\u2728 \n Definitely \ud83d\ude05 \n Thanks guys. Sure will share more. Any additional AI groups on reddit or discord I should be part of? \n Are you looking to minimise hallucinations during QnA over documents or just plain vanilla chat conversations? \n https:\/\/twitter.com\/jerryjliu0\/status\/1641234014991446016?s=46&t=icC0fizZK8E3ONsDVuGFWA \n The maker of that evaluation model is [PHONE REMOVED] \u2014 he is here! \n Thanks, Nirant for the mention. \n [PHONE REMOVED] Ravi great to have you here \ud83d\ude4c\ud83c\udffb\ud83d\ude4c\ud83c\udffb Been following your work and Llama Index for quite a while ! \n Asking a dumb question what is Llama index? Been so caught up with visual AI that I've missed a lot of LLM progress \ud83d\ude2c \n This project: github.com\/jerryjliu\/gpt_index \n did llama index and langchain raise funds? \n Curious to see if Harrison would tackle the langchain deployment layer himself \n Give a read of Overview section here Amogh, you will get pretty good idea - https:\/\/github.com\/jerryjliu\/llama_index. \n They are trying to afaik \n SLAs are so tricky with open source projects; a lot of companies try to prioritize their features and fixes \n feature requests* \n Chase is also doing a lot of community events\/webinars btw. Almost 2 a week at this point, Chatbase, Explain Paper and other projects built around that \n ikr, what a machine \n Small offtopic: anyone here who got an O1? Looking for advice on lawyers.. \n https:\/\/huggingface.co\/google\/pix2struct-textcaps-large \n The results shown are pretty impressing with pix2struct. \n Pretty good \n I've found mm-react to be the best - probably SOTA till GPT-4 launches multimodal \n Randomly collaborating on someone who DMed me on twitter to build poetry CAM  \n \"In the garden of fading hues, \n Fed to GPT-4 \n what product use cases could you think of with such features? \n I see the first wave as mostly fun and interesting products \n Like glean, for images too \n There's also llama mulitmodal - need to benchmark that too. \n Please welcome Shreya Rajpal [PHONE REMOVED], creator+maintainer of Guardrails: github.com\/shreyar\/guardrails \n Something on these lines : https:\/\/www.springworks.in\/albus\/ \n Thanks for inviting me to the group [PHONE REMOVED]! \n You have any ideas? \n Shreya has also kindly agreed to give a Guardrails demo on Friday late night at the hackathon. Should be pretty useful for anyone working on LLM-Agents, structured parsing and similar sub-tasks! \n Btw a fun usecase I saw in my improv group was using GPT-4 to do improv with as a scene actor \n https:\/\/twitter.com\/sama\/status\/1641181668206858240?s=20 \n Sam altman coming to india \n OpenAI Tour haha \n Very shady \"regulate-in-my-favour-please\" tour on behalf of Microsoft \n Yes. Not even coming to Bangalore. \n Mostly travelling to capitals. Talking to different govts. \n why govts? \n reason ^ \n He\u2019s going to Delhi not Bangalore! Bad choice \n Microsoft runs World's largest Govt cloud, and was the first company to offer a backdoor to CCP for Windows. At that time, Windows was \"dangerous\" technology. \n Bhai saab, itni job losses hone wali hai from openai, thoda confidence main to Lena padega \n I have heard about this . Apparently how to tune it according to different rules of each government , like free speech rules and such! \n What to show ! And what not to show \n Github (MSFT acquisition) used to share when they got take down requests from Govt here: https:\/\/github.com\/github\/gov-takedowns \n Unfortunately yes! Great leavy for power \n Let me invite them here. I\u2019m currently doing an art residency with that group. \n A DNS cert is basically you taking someone else's word instead of a small Twitter celeb \ud83d\ude05 \n How many years y\u2019all are into AI? \n They performed at rang Shankara and BIC recently. AI improve \n I was born in the ashes of SVM Kernels and raised in the wilderness of Random Forests \n https:\/\/instagram.com\/climateprov?igshid=YmMyMTA2M2Y= \n import tensorflow as tf \n 6 months here \ud83d\ude2c\ud83d\udc76 \n In days or days and nights? \n Been 3 months I guess! Been trying to do things on Kaggle and others ! Small things creating model , tuning different parameters . Lot to learn ! Long way to go! \n How do you tell the difference ? \ud83d\ude35\u200d\ud83d\udcab \n I started training when tf.Session was the only way to do it :)) \n So I suppose that\u2019s an OG statement \n For exploring new capabilities and building quick things: no of years might be weak indicator, may be even negative indicator. It's a Brave New World !! \ud83d\ude02. \n Theano folks in the house? \n They'll need a Caffe before they step out with a Torch \n Sam Altman over elon musk \n probably he has changed his view this year lmao \n since tf-idf features were slowly being replaced by word2vec from gensim and mainstream torch was in lua \n That's a long, long time. \n Now you'll have to explain what are gensim and Lua \ud83e\udd23 \n but also this \n Crazy\u2019 \n In before someone says that it's all just matrix multiplication and those \"foundations\" haven't changed \n When I started, word2vec, maybe GloVE, were the bleeding edge of NLP tools. \n Haha. Here's mine \n started roughly in late ~2016 \n https:\/\/www.researchgate.net\/publication\/308719279_Sentiment_Analysis_for_Mixed_Script_Indic_Sentences i worked on this paper in 2015 and i thought i was working on bleeding edge stuff.   Shows how out of touch research work in our universities was \n Same pinch.  \n and likewise infra spend has also increased dramatically \n Coded a sparse autoencoder in MATLAB back in 2012. Not ashamed to admit that was the peak of my ML prowess \n I actually first heard about ML first from [PHONE REMOVED] nerding about Tom Mitchell's book \n I think I still have a pdf of it somewhere. The only major book I got a hard copy of was the AI AMA. \n Curious to know if there are folks from the mlblr \/ tsai community here! \n I mucked around with theano and also had a gsoc proposal that didn't go through \ud83d\ude05 \n What\u2019s your source for discovering the latest papers\/works? I saw someone shared a paper from a week ago \n Tbf, matmul optimization is still an unsolved problem and folks do PhDs on this even today \n Follow this firehose, turn on notifs  \n Deepmind's AlphaTensor is beating them \ud83d\ude05 \n Except there was a paper in the next day that found faster matmul algorithm. Just that they were academics that didn't have a PR team behind them \n https:\/\/arxiv.org\/abs\/2210.04045 \n Wrote A3C in lua torch (it was asynchronous as we were using threads instead processes in Lua) and trained the agent to play doom game . \n Since alpha zero beat stockfish.  There was some excellent chess coverage around those matches \n Thankfully it's much simpler to do something with it now \n Around 2018. When I saw Deepminds first demos of neural nets playing Tetris.  \n https:\/\/www.linkedin.com\/posts\/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_android \n Hey Munjal, welcome to the group! \n Hi Nirant sorry will not repeat again. My intention was not self promotion but education. \n hackathon idea - get all relevant WhatsApp chats from [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] and other organisers related to questions they've been receiving about the upcoming event. Fine-tune a LangChain model on those question answers.  \n [PHONE REMOVED] expected footfall for the hackathon? \ud83d\udd25 \n 154 invites sent out for the in-person Bengaluru hackathon \n woohooo!","28":"A quick hack for DeepMind GPT \n It is able to handle multiple context questions ,check the demo vid till the end \n Sorry *DeepHack GPT \n Quick extension++ \n Small flex - you can export this group chat from whatsapp and just upload the text file to gooey and it will get you this search without writing any code  - you can change the prompts and change model settings from the ui! \n Will this also herd adults? \ud83d\ude00 \n Has anybody worked with making LLMs understand table structures? If I have it a document \/ PDF that has a table in it, the LLM needs to read it row by row, remembering context of the columns as well. \n chatpdf.com \n This is the best! \n Nice, gonna try this out. Did you build it Shashwat? \n No Amogh. I'm building on databases. Text2Sql usecase primarily. \n From when did WhatsApp start allowing exporting chats as txt \ud83d\ude2e \n I think it's been there since quite a while \n Yeah used that feature 4-5 years back.. they did in a zip.. \n 2016 \n Rephrase.ai just launched a completely automated blog to video powered by GPT-4. I made some contributions to it, and am working on the next version of it.  https:\/\/www.rephrase.ai\/blog-to-video \n thanks! pinged Mathis \n Ritesh, Some issues in your form. One time the email input field did not render at all, the other time it took more than 20s for the form to load. May be just a load thing. \n Interesting work btw. \n Hi all, \n Hi Pradyumna. You can just use the Whisper API to get the transcript. Don't need GPUs \n You can upload this to gooey doc search too, might take a while. You can select the asr model in settings \n You can use Colab  \n Thanks alot, trying this right now \n Oh you just needed the transcript. Sorry, that\u2019s at https:\/\/gooey.ai\/asr\/ \n Oh, thanks!  \n Sure \n You could even use - https:\/\/www.gladia.io\/ - 1-hour audio file transcript will be extracted in 10-20 seconds which uses openai Whisper backend. Currently, the API is free. \n Maybe check out Assembly.ai, they have a playground to upload files to and try transcription, accuracy is pretty good too. \n Checking. I usually use their python API. \n [PHONE REMOVED] I tried just now with a 50-minute audio file by uploading. It worked fine. \n Wierd, I'll try again. Thanks \n Tried on one of the medium blogs and it\u2019s pretty good. Is there a constraint on time limit on the video generated? \n seems like the default is 1 minute \n yes we are generating videos for around 1 minute. There is a limit on size of blog - upto 20k characters \n Is the 1 minute limit because of computation\/cost or technical limitations? \n let me check \n just a product decision for now, since it's free for now - cost is also a reason \n What'd it take to make a Tiktok\/IG reels version of this? \n Or use whisper.cpp \n You mean in terms of only the resolution or is there any other difference \n Pitch, editing style, cuts, screen transitions, overlays \n yes all of that is what i am working on, that is the plan \n i mean there are lower hanging fruits then these , but all of these will come.  Making pitch better will happen sooner \n Do it before Bytedance\/Tiktok does it! \n Or runwayml! \n Could you please share the results? \ud83d\udc40 \n https:\/\/mobile.twitter.com\/svembu\/status\/1641710194458791939 \n Video: https:\/\/personalized.rephrase.ai\/?campaign_id=0Rhz6gA1qhU07BWGCjHap03Pfr9SRQ&shareable=true \n hi \n https:\/\/arxiv.org\/abs\/2303.17580 HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. What do you guys think of this? \n ChatGPT plugins and langchain agents already do this in a way. \n Calling out to fellow Product Managers  - need some insight on some KPI error corrections. \n The Italian Data Protection Authority (DPA) has some interesting things to say about ChatGPT's training models and finds it violation of their data laws.","29":"Who all going to the DeepHack demo day? \n Live stream is set up here - https:\/\/has.gy\/ULYt \n Demo Day live stream \n Hi, Are we done with all the submissions? The live stream just stopped \n Taking a 5 min break \n Oh okay. Thanks Nirant!","30":"https:\/\/magicfusion.github.io \n hey folks. are there any good\/free\/local alternatives to D-ID, ElevenLabs? so that i can upload my custom image, audio and get a lip-synced avatar video. \n https:\/\/gooey.ai\/lipsync\/ \n also, is there anywhere I can read the difference b\/w Dreambooth, LoRA, Texual Inversion - differences, pros, cons, training time etc. I had trained custom DB model last year, know a lil bit about the other two, but haven't used them yet...looking to.  \n thanks! \n I don't have a brief doc written but based on my experience, LoRA works really well compared to other two especially after being trained on small amount of data relatively, followed by dreambooth which would provide decent results after multiple attempts of fine tuning whereas textual inversion did'nt return any good results for me, i did try making small changes but that didn't help much as well. \n https:\/\/youtu.be\/dVjMiJsuR5o","31":"thanks [PHONE REMOVED] [PHONE REMOVED] \ud83d\ude4f \n > But it\u2019s very possible that creativity and what we think of us as human intelligence are just an emergent property of a small number of algorithms operating with a lot of compute power (In fact, many respected neocortex researchers believe there is effectively one algorithm for all intelligence.  I distinctly remember my undergrad advisor saying the reason he was excited about machine intelligence again was that brain research made it seem possible there was only one algorithm computer scientists had to figure out.) \n > Human brains don\u2019t look all that different from chimp brains, and yet somehow produce wildly different capabilities.  We decry current machine intelligence as cheap tricks, but perhaps our own intelligence is just the emergent combination of a bunch of cheap tricks.","32":"https:\/\/twitter.com\/lumalabsai\/status\/1642883558938411008?s=46 \n Report here: https:\/\/aiindex.stanford.edu\/report\/ \n Funny but off topic, we do not encourage this :) \n No worries \n Hey Hackers, [PHONE REMOVED] and I have built something in the generative AI space, that we wanted your feedback on: https:\/\/twitter.com\/CyberSahu\/status\/1643166480794791938?s=20 \n https:\/\/github.com\/nat\/openplayground \n Collateral Damage: Killing Suhail's playgroundai.com any chance of entry into text LLMs \ud83d\ude02 \n Playground.ai is very different na? I think its more about popular prompts and upvoting rather than comparing models \n playgroundai lets you experiment with different diffusion models, parameters, inpainting, base image generation...openplayground also does same thing for LLM's right. \n Surprised they don't have mid journey 5 \n it's free, which is a big deal \n AFAIR it's only accessible through discord \n Yes, I\u2019ve heard that API is in the works \n Yes, you're right. I presumed it would be in some alpha by now \n once it comes out, I believe it's going to be chatgpt moment for them \n Why the strategy to have a discord bot but not an API? \n I think they are\/were bootstrapped and inference infra is hard & expensive \n I think Stability supports them with GPU resources, not completely sure though. \n They\u2019re rolling out API access soon. Heard in their office hours.  \n Anyone remember magicleap? That\u2019s the guy behind it \ud83d\ude2c \n Sorry leap motion* \n https:\/\/youtu.be\/xNqs_S-zEBY \n AirBnB for GPUs would be such a thing \n Used to be called AWS \n those are hotels \n vast.ai \n Hetzner Cloud was the OG hotels no? https:\/\/www.hetzner.com\/cloud \n if you mean someone letting renting out their GPUs, then runpod is doing it \n Damn, didn\u2019t know Jasper trained their models on the Cerebras systems \n Claims to be unofficial MJ API - https:\/\/www.imagineapi.dev \n Did they create a MJ bot for the MJ bot?! \ud83d\ude06 \n W&B speaks to OpenAI, answers questions about cutoff date and bunch of other tidbits:  \n Langchain is awesome.  \n Indians in India should've a globally used GenerativeAI library within next 12 months if we're to be still in the running. We missed the PyTorch\/Tensorflow\/transformers wave completely.  \n For anyone interested in my AI-generated comic from the weekend hackathon: \n Sooo good \n Praise Lord Datt\u0101! \n it's actually impressive \ud83d\udd25 \n Love it! Publish a sequel :)","33":"Does anyone know if we can utilise OpenAI embeddings model to create graph embeddings? \n One naive approach is if you have graph structure with sentences as nodes, you can use openai embeddings - \"text-embedding-ada-002\" to get node embeddings directly, and using adjacency matric you can compute edge embeddings by averaging the connected nodes. \n Pinterest \u2014 the OG graph folks would recommend starting off with any base embedding and then update them   \n I came across this article on HN and was wondering if it can be done using some form of text representation using \u2018text-embedding-ada-002\u2019 \n Is there a gpt model that i can currently use finetuned with financial data and analysis? \n there's some bloomberg gpt ig \n its not usable yet \n Yeah but I don\u2019t think this is available publicly \n I somehow doubt they will ever open source it \n its just a paper by far \n It\u2019s a paper of an existing \/closed implementation- won\u2019t be open sourcing . It\u2019s trained on their proprietary data . \n *sourced \n It works? \n 500 lol \n but it's around the corner it seems \n maybe they've rolled it out already to a few people \n [PHONE REMOVED] can you pls add Abhinav here. He is Shop101 CEO, wanted to join the community \n PSA: Please DM for add or other admin requests in future :) \n In the words of Kaggle Grandmaster Sanyam Bhutani \u2014 the \"World's best Deep Learning course\"  \n Hey folks! Thinking of having a light beer + pizza mixer of ~20 people building in generative AI at the Lightspeed office in Koramangala opposite to third wave on the 13th of April, next week Thursday. We can keep the conversations focused on just new things people are building as well as what I'm seeing in the market more broadly in the US and around the world. Folks that are interested, please do a thumbs up on this thread! I'll start a separate group with you all! Looking forward \ud83d\ude42 \n If we exceed 20, no worries, will do this at least once in 3 weeks, so should be just including people in the next set. \n If you all can fill up this form: https:\/\/docs.google.com\/forms\/d\/e\/1FAIpQLSfRg1AOSSfSs8ZBbKzWd5ne_8JqzJrwFvy_NN0K-TUIdG2jYA\/viewform \n Good to see so many events around AI happening in Bangalore. Sharing one I am hosting on April 14th, 6pm at the Draper Startup House, Koramangala.  \n Folks, I got the 2500$ openAI credits from here! You all should check it out \ud83d\ude00 \n Not a phishing attack? Share an email screenshot etc? \n I mean this is an open ai link. Not sure what else would convince you \n Oh right, this link is different \n You had a crunchbase profile? I set it to NA while filling the form \ud83d\ude05 \n lol I created on last year for lulz after I incorporated my company \n Same. I did too. Although I have an incorporated company so that might have helped. \n Guess I won\u2019t be receiving the credits anytime soon \n You can get this only if you are registered as a start-up or even if you are an individual looking to build stuff? \n registered as startup and then got this but took many months \n I recently came across a Blind post saying Google is moving the majority of its resources from Assistant to Bard, and heard similar sort of news for Amazon's Alexa. \n Incentives explain more of these decisions than insight :) \n Do we get this only if it's an incorporated company? \n 8:30am 8th April no? \n Perhaps, but I didn't provide any official details of the company (only website and crunchbase) \n sorry for the scare guys :P \n This is two phenomenon occurring almost at the same time. Amazon Alexa and Google assistant orgs were slowly being shutdown \/ dismantled due to economic downturn. With the sudden hype around LLMs, they're simply pivoting these teams instead of firing and hiring \n This makes sense, but I thought post LLM hype they will just rejuvenate these projects but understandable. \n May be next time. \n Update on this.  \n All that I'm hearing is the first 1000 are free \ud83e\udd23 \n https:\/\/community.riscv.org\/events\/details\/risc-v-international-risc-v-in-india-presents-nerds-talking-to-nerds-about-risc-v-hosted-by-tenstorrent\/waitlist\/151 \n Is anyone aware of research happening in Deepfake detection? \n any good app\/software for it? \n [PHONE REMOVED] from Spoofsense.ai is working on this I believe. \n Found this effort by Microsoft as well, but it doesn\u2019t have a working model for public ig: https:\/\/blogs.microsoft.com\/on-the-issues\/2020\/09\/01\/disinformation-deepfakes-newsguard-video-authenticator\/ \n Not releasing is probably a good call, tricky thing to release authenticators because that makes it easier for next generation of cheaters to evolve\/reverse engineer. \n I recall that long time ago Y! had released a nudity detection model, and a bunch figured out Wordpress and other social media companies were using similar CNN based methods \u2014 and had bypasses to detect babies from adults.  \n Found the model. It's 7 years ago and written in Caffe.  \n interesting, thanks for sharing Nirant \n one lofty way I could think of is all newly created images having a mandatory hash\/digital signature like NFTs to verify and validate their origin; \n not sure what\u2019ll be the limitations of this. \n Sigh, every generation re-invents pgp keys, pdf standards, and SSO \ud83d\ude05 \n not only images, I mean any digital \u201cinformation\u201d \n sure \n I meant, that we've to re-invent to keep up. The threat surface has evolved too. \n absolutely; cryptography is a constantly-evolving process\/field \n can use this https:\/\/kroop.ai\/the-vizmantiz\/ \n Has anyone seen an API to categorize questions into HR, Finance, Marketing etc? \n DM, send me 20 samples, can make you one over the weekend? \n Yes but will need to host etc \/ I was thinking if there's a service which could do analytics etc, retagging etc \n Google Sheets has GPT4 if it's batch \ud83d\ude02 \n are you think of a prompt \"Please categorize this into HR, Finance\" etc? \n That's the baseline, yeah \n It would be great if you can give it samples in the prompt itself and perhaps chain it with the system response and then in the second user message send your input query \n Does anyone know how to get more than $1K\/month hard limit of OpenAI? We're going to be crossing that any day and I've already applied for an increase. \n Sorry didn't bother with punctuations \ud83d\ude05 \n yes \/ can get very expensive very quickly. 5K questions a day. \n Can it be done by similarity search ?  \n You can perhaps then use gpt4 data do generate your own dataset \n And then train a model of your own labelled dataset \n And use that in prod \n Over engineering friends \n Perhaps :p \n Run this against a decent prompt and see how most of it will just work \n Prone to less accuracy \n I used the Google Sheet workflow to decide who to invite for the hackathon, over 200 folks applied \n Just descibe what HR and Finance mean, and gpt will classify pretty well.  \n This technique was also used by openai to train gpt4 \n Gooey is such a cool ass Swiss knife \n Kudos to you \n The trade off I was considering was using prompt to classify would require a more expensive API end point  \n Turbo is cheaper than Ada? \n Could be that I might have referred to wrong prices then  \n I could be wrong as well, let's check and come back \n who's the largest openai customer in India? \n https:\/\/www.buildt.ai\/blog\/incorrectusage \n Pepper is one of the larger customers.. fwik \n how much do you think they spend per month? \n not sure if I can share that, but what are you looking for? \n https:\/\/analyticsindiamag.com\/hugging-face-launches-gpt-4-alternative-vicuna-13b\/ \n Neat! This seems to be essentially knowledge distillation+human in loop for higher quality labels. Or do folks think this is a false equivalence? \n Here\u2019s on Zero Knowledge Machine learning published by WorldCoin  \n One good use case they\u2019ve highlighted is on using ZMKL for the purpose of inference on medical data \n \"HuggingFace launches\" \n Please don't share outright wrong press. Erodes trust in the group \ud83d\ude00 \n hey folks, what's the status of prompt injection in gpt4? \n Funny you should ask, just earlier today I was experimenting with prompt injection out of curiosity. I know that in chatGPT and GPT 3, 3.5, asking it to simulate another agent with different ideals works well. I don't have access to GPT 4 but have heard that this doesn't work well with it. What, in particular, are you interested about in prompt injections? \n one silly example from my experiments \n thanks. i just want examples which worked before but don't right now in chatgpt-4. \n ask it to create a full form for that name \ud83d\ude02 \n You can make it do a lot of funny things with this hack. I'll probably get kicked out by the admins if I post too many of those screenshots \ud83d\ude02 \n My DMs are open, send me your darkest work \n Go ahead da. Dumbledore's Army will always have a space in Room of Requirements! \n I've experimented with GPT-4 and it is really good with handling prompt injections. It sticks to the system prompt and straight up denies such prompt injections methods. Atleast with the experiments I did, I had no luck to get promo injection working with GPT-4. OpenAI seems to have worked well on handling it.","34":"I reckon they made good use of the system prompt this time. My guess is that it\u2019s appended at the END of all previous messages and the network is trained to ignore the grammatical content of it, but obey the instructions. \n Yep, could be the case. \n yo anyone building anything for gen ai applications in schools? \n Im looking to create Sparse Veccors and do hybrid search. What is the best model to use in a prod environment? \n Doing a small experiment, say hi to this guy \ud83d\ude2c \n Nicee \n What are you using for text2vid \n Goodmorning folks. Does anyone know how Danny postma is doing cloth transfer?  \n Is he masking the cloth first, and then doing style transfer? Even then, the results look near perfect and artefact free, unlike what style transfer or img2img can do \n https:\/\/arxiv.org\/abs\/2304.01852 \n This came out two days ago \ud83d\udc46 \n https:\/\/github.com\/sangyun884\/HR-VITON \n Has anyone tried a paid subscription of MidJourney from India? My payments seem not to be going through. \n Yes - my team had setup a subscription \n Did you pay for it by credit card or is there any other mode of payment available? \n This is so cool!! \n https:\/\/youtu.be\/E7fGsSNKMc4 \n Personal citi Indian master credit card \n it's a stripe link, right? i think other modes should work as well. i used my amazon icici cc \n more good ideas on how to use the platform --- \n I see my college's library in the preview \ud83d\udc40 \n \ud83d\ude31 \n Yeah that's definitely Trinity college Dublins library \"the book of Kells\" \n Hi folks. I\u2019m trying to achieve text to color grading similar to this model provided by RunwayML.  \n Nice, runwayml is \ud83d\udd25 \n Can't recall which teams had asked for this specifically, but finetuned STT for Indian languages: https:\/\/huggingface.co\/blog\/fine-tune-whisper \n And dataset, wave2vec models: https:\/\/github.com\/Open-Speech-EkStep\/vakyansh-models \n https:\/\/twitter.com\/MetaAI\/status\/1643602729615646720  \n hey everyone, \n Quick q, how big is the database? \n cc [PHONE REMOVED] did you work with Pinecone?  \n 3361 - vector count \n Not to derail your project, but this sounds like an xy problem. You dont need the complexity of a vector database at this scale. Just use pandas \n Will the response be faster? \n Yes. It will be in-memory and require no network calls. \n Openai has notebook examples of it too \n Not to mention, so much easier to debug and inspect \n Ankur, how comfy are you with Python\/pandas ecosystem? \n Very little.. learning on go \n Hmm, in that case you can also do what I do and just do python lists and not even do pandas \ud83d\ude02 \n Okay, if I can teach you how to do this in Google Sheets, will that be faster for you? \n Any link? \n And how you decide when vector db is better ? And which vector db is much pinecone, superbase etc.. or all these are just brands and using same tech under the hood? \n Very interested as well \n Aside: Keeping this convo on main, since 2-5 people have pinged with similar\/adjacent questions, and hoping that answering this would help more folks :) \n Really.. \n Nah.. not looking at google sheets ways.. \n Yes. 3000 rows is pocket change \n https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb \n For any indie hackers, you can use Google Sheet as a db to launch a GPT4 app as well:  \n Small self promotion: Gooey.ai supports this as well, and even lets you create bots that refer to google sheets \ud83d\ude2c \n You can use self-hosted postgres with pgvector too \n Pinecone and Supabase are both over the network. Pinecone is _vector first_, while Supabase is basically managed Postgres. So querying metadata is hard and it's terrible at ranking\/search for both. If you've a complex webapp at launch, you can launch with Supabase. It's just Postgres.  \n nice \n Chroma works in-memory, persists state (unlike Pandas) \u2014 and no network overhead. Unlike Weaviate, it's quite a thin Docker image and doesn't need bells and whistles \u2014 just pip install and it works. \n Chroma can do a lot better dev marketing by saying: \"It works\" \n The Founder is also very nice \n And in a market where Pinecone deletes your vectors, Weaviate doesn't review PRs \u2014 that's quite important \ud83d\ude05 \n Indian gov has finedtuned checkpoints too - https:\/\/huggingface.co\/vasista22\/whisper-hindi-large-v2 \n is there an api for this? \n Sorry I can\u2019t help self plug again - https:\/\/gooey.ai\/asr\/ \n this notebook had serious finetuning-example problems \n You can make $500 MRR by fixing OpenAI Notebook bugs and putting behind a Stripe link and Fly.io deployment at this point \n wait what \n I\u2019m a contributor of openai cookbook: https:\/\/github.com\/openai\/openai-cookbook\/blob\/6df6ceff470eeba26a56de131254e775292eac22\/examples\/fine-tuned_qa\/olympics-1-collect-data.ipynb \n How can I make money? \n [PHONE REMOVED] how much time it takes to insert embeddings\/ data into chroma? Asking this in the context of online\/ on the fly data insertion. \n Problem Statement: Finetune off the shelf embedding for a specific domain, extremely useful for improving search ranking and QA. Empirically proved by ColBERT and Vespa both.  \n Host on a web service to show that it works, market with a ton of benchmarks \u2014 mock every commercial service who can't answer questions from their own pricing page _almost always_ \n 10% kalesh marketing (why does this problem matter), 90% convince that it's enough value (here is my solution) \n Haven't profiled it tbh, but for a 50K chunk\/rows size, it was more than 30s. So on the fly should be worth taking a shot at \n This kinda homework\/advice is what I invoice $500 to Series A CTOs\/Founders usually \ud83d\ude06 \n Nirant since we\u2019re on this topic, is there any way to use colbert \/ dsp over an unlabelled dataset? \n This is very interesting commercially. Many fashion brand owners are quite keen on AI generated catalogues, and do away with model photoshoots \n The market pull is real for that use case \n Happy to share ideas on DM, when I am sober on Sunday. Have not tested this enough. But zooming out, I refuse to believe that there is such a thing as \"unlabeled text data\" anymore. \n Anybody know if I can use hydbrid embeddings on Chroma? \n Embedding search is very powerful but I feel the linear nature of the embeddings can be limiting, not in terms of performance but the semantic capacity. \n Would be helpful if you elaborated on what do you mean by \"hybrid\" :) \n I love this constant human urge to decouple systems into memory, reasoning, context and what not \u2014 despite 15 years of ML research proving that combined systems outperform decoupled systems.  \n Sure, so hybrid meaning searching for keywords + semantic meaning. My understanding is that you can use sparse + dense embeddings to achieve better accuracy on results. Pinecone for example allows you to store both of these for a single ID. Wondering if Chroma does the same \n Yes, Chroma does the same. They don't have good docs around it yet though. Assuming that you're a hacker solving for time to market, launch with Pinecone. Move to Chroma when someone asks on-premise \n Combined system definitely will perform better and I feel we are on the verge of achieving this in AI. But as of now it\u2019s clear that memory is a limiting factor of LLMs and hence we need alternative solutions. \n something related: https:\/\/twitter.com\/LangChainAI\/status\/1643628476505681920?s=20 \n Thanks, will have a look \ud83d\ude4f\ud83c\udffd \n \"Managed Retrieval Engines\" \u2014 clearly a Management Consultant type was paid to rebrand hosted services into something cooler, so that we can add one more category to G2 and then become it's leader \ud83e\udd23 \n The most basic model is to use sklearn's CountVectorizer (which is based on bag of words) on the text, and use the sparse vectors generated by it. All conventional systems use bm25, tfidf etc., So you could generate sparse vectors from that as well. \n What would be the nodes and edges of this graph. Idea sounds interesting, but would like to hear more of your thoughts on it \n Some sort of a entity relationship graph might work, upon some text input, we could semantically traverse the graph to filter out the relevant nodes and edges and focus on them for future processing (using LLMs maybe) \n Even I\u2019m not sure if it will work but I definitely feel there are some semantic gaps when using purely embeddings and this might be a solution \n The thing is: *everything* can be (and is) linearly embeddable. Even graphs themselves \ud83d\ude00. \n Understood, yea the graph db approach makes a lot of sense \n I'm actually designing something like the second for a company right now \n Nice nice thanks will check it out \ud83d\ude4f\ud83c\udffd \n I wonder how many of their new integrations are going to be business-motivated (eg: the bm25 being with Elastic). I'm guessing we can still contribute our own adaptors for other platforms to their GitHub.. \n Nope, used an in memory JSON file with embeddings stored in a key value store. For the hack it was good enough, but for scaling it I was planning to use weaviate.  \n b25 is more fundamental I think\u2026 it\u2019s a class in lucene, on top of which Elastic is essentially built. \n By \u201cbootstrapped\u201d I mean those who have their own \u201csearch-system\u201d, and do not use Elastic, etc. \n btw, langchain has some stuff around graphs as well  \n for anyone using pinecone, just be careful. their pricing is very confusing. this dude paid $1000 for ... ~no usage \n yeahs got $24 billing for 5 days with just 10 queries - \n For how many indexes? \n 2 \n damn. could've had one month of ChatGPT Pro and still have $4 left \ud83d\ude02 \n Then it should be correct I guess. One index costs approx $2.3 per day and 2 indexes for 5 days it\u2019s $24 \n Was the bill because he was creating an index per customer or something? \n only after his tweet I deleted my unused stuff on Pinecone, did not know I was paying for it. \n i checked my account as well, just in case \n Digital ocean used to be the nice ones \ud83e\udd72 \n thats why i use credit card with limits. so if by any chance any tools more than what I can pay. Service stops. \n pinecone started off with a lot of community collaboration, their blogs on semantic search by james briggs are still my favorite on the topic \n this was generated by chatgpt, right? \n lol, no \n i only use stolen credit cards \ud83d\ude0e \n pure dadaji vibes.. \n Donald Knuth didn\u2019t spare any words, \u201cgetting binomial coefficients to work properly\u201d \ud83d\ude02 \n Send some my ways too \n Fun story: met jim keller today and he wants to build a 2 terabyte risc-v chip that can run pytorch code. 2 goddamn terabytes \ud83e\udd2f\ud83e\udd2f\ud83e\udd2f \n anyone here tried the gpt4 compression prompt? it's pretty good.  \n I tried out another one I saw before this tweet, worked good for plain text, not much for other kinds of text(like code) \n Read somewhere Djikstra loved theoritical CS so much that he considered plebs writing code to paint pixels on a screen vulgar in his time. \n yeah. i tried to compress lyrics. didn't work. \n https:\/\/www.linkedin.com\/posts\/samyakhtukra_holy-smokes-sam-segment-anything-model-activity-7049699206206283776-_fva? \n This seems like a fitting analogue \n Speaking of which, Chroma just announced their template for Replit. \n Terabyte or Teraflop? \n Haha.. Let me bite. I wouldn't bet against theory folks (CS Theory) in the long term. First aeroplanes were build out of experiments but we really learned how to build aircrafts safely only later with the necessary math. They will come up with much simpler representation and more compact algorithm. That is their job by definition. To quote a friend who was an early FB engineer, what we write becomes useless in few months. Some of what they do remains current for much much longer. That's probably where he is coming from. \n What is your take? \n Lol! \n ig some people are so attached to the work of their lifetime that they cannot accept\/focus on things changing\u2026 \n but these are nobel laureates we\u2019re talking abt, so i\u2019d never know \ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f \n I spoke too soon. There is a hot new YC company on this: https:\/\/getmetal.io\/ \n OpenAI notebook bug fixes + Stripe \u2192 YC pipeline is strong \ud83d\udcaa \n How Stripe? \n That is how you take the credit card of an unsuspecting developer and then invoice them some absurd amount \ud83d\ude1b \n Paul Krugman is another one \ud83d\ude02 \n Has anyone tried using ElevenLabs for training and generating audio in Hindi? \n Or maybe open source alternatives like tortoise-tts? \n [PHONE REMOVED] \n Demos from India's first Generative AI hackathon are here: https:\/\/nirantk.com\/deephackdemos \n To friends in VC, can make introductions to teams if you give me carry \ud83d\ude06 \n To engineers \u2014 lazy fuckers please write better copy, and take pitching tips from [PHONE REMOVED] [PHONE REMOVED] next time","35":"Could the creator of the ViewsAct project kindly share a demo video, please? \n He opted out because his demo used some real-world company designs and data. \n For those who track of hackathon demos in SF\/NYC\/Berlin circuits, I genuinely believe that all winners would've done well in SF, won in NYC\/Berlin in Feb end atleast. Would love to hear more if you do track :) \n anyone saw the first shortfilm using dalle? : https:\/\/www.instagram.com\/reel\/CqstiaNuSjX\/?igshid=MDJmNzVkMjY= \n There is this one too \n Using mid-journey. He has also shared the breakdown process. \n I'm in the bay area until Saturday. Would love to meet people working in the gen AI space. \n I'm an Applied Scientist at Amazon building computer vision tech for video action recognition \n Hi,  \n cc [PHONE REMOVED] \n [PHONE REMOVED] \n Following. \n For those in London: this might be worth checking out. Lots of AI\/art\/gaming stuff: https:\/\/www.theguardian.com\/games\/2023\/apr\/06\/now-play-this-ai-video-game-somerset-house-london?CMP=Share_iOSApp_Other \n chrome just shipped WebGPU  \n Pichai baba is back baby! \n Gazab \n I\u2019m curious that for use cases outside of those that need extreme security - why would I run a model on my personal machine vs accessing it via an API? \n It's wayyy lower latency, higher throughput. Think why games continue to be written for devices. \n Also Makes compute significantly cheaper for companies serving consumers at scale \n This would still happen on a server farm I assume? \n brb, gotta buy some Cloudflare now. \n Doesn\u2019t the inference take longer though? \n No, WASM will do the rest. Segment-Anything proves that inference can be light-weight decoder only \n Depends on the case I guess, I know some very large companies who have benefitted significantly from running ML on the mobile edge \n Thought that is more a bandwidth issue. How much data can I fit through a pipe \n I literally opened vested for this \n :P \n Cashflow poor and idea rich people think alike \ud83d\ude1b \n Any examples? \n Hmm, need to do more reading here \n there will be no strong QoS but it opens up possibility of freemium models \n https:\/\/twitter.com\/mathemagic1an\/status\/1644123645432958976?s=46 \n Pichai baba ya fir Larry\/Sergey? \n What is QoS? \n Quality of Service? \n Chrome is classic Pichai in my mind, so is Web acceleration ideas \n Quality of Service \n Was his brainchild, yes \n hopefully battery tech keeps up \n like Google Keyboard already does \n I think the best product in this case is actually SwiftKey and Microsoft acquired them very quietly in 2016 \n As we move to models running on the edge, I'd not be surprised to see Microsoft launching some OAI features inside SwiftKey \n The product as is works incredibly well \n SwiftKey has been botched after the acquisition. It's a slow and unbearable app now \n How is agent planning evolving? This was quite broken in Turbo. Is it 2x better in GPT4? 10x better?  \n No idea, deep diving soon \n Umm, not sure why you'd say so - have been using it since they were launched and haven't seen any notable difference \n I've been using it on Android though - not sure if that changes things \n https:\/\/twitter.com\/wileycwj\/status\/1644220882062282752?s=46&t=lkuvFQUWr1nav0QpUpFmdQ \n This is probably just me but I still don\u2019t have a good sense of why something like pgVector won\u2019t work. At what scale does pgVector not work? \n Does pg_vector also do NN like HNSW or nmslib? \n I'll RTFM, but if someone has direct docs, would appreciate \n It is not performance as in speed but accuracy\/semantic richness. Does this answer your question. \n Don't think so, quick glance through code base doesn't seem like it. \n there was some good discussion wrt pgvector in this thread https:\/\/twitter.com\/jobergum\/status\/1643187540222959616 \n btw, has anyone tried out Midjourney's \/describe feature (img2text2img)?  \n Interesting read on hardware infra of OpenAI \n I spoke to Qdrant founder, and he said pgvector is basically unusable for LLM apps. It has recall in the area of 50% \n Basically whatever was referenced here \n Erik Bern of Modal Labs maintains ann-benchmarks github.com\/erikbern\/ann-benchmarks, let's request him to add pg_vector to it? \n This is something we can test\/verify empirically, don't need to trust opinions from direct competition \n And avatars come for news anchors: https:\/\/twitter.com\/KhaleejMag\/status\/1641123893145485343 \n True \n agreed. i find it kinda hard to trust benchmarking blogs by other vectorDB startups. \n https:\/\/www.linkedin.com\/posts\/hsemina_generativeai-community-hackathon-activity-7050057219123400704-NIHR?utm_source=share&utm_medium=member_android \n This is fab. Thank you! Hoping pgvector comes out decent. Want to stay within the supabase ecosystem \n Eric mast aadmi. Gave me access to modal in five mins, when I mailed him \n Same. Matt Welsh of Fixie too. \n https:\/\/medium.com\/m\/global-identity-2?redirectUrl=https:\/\/blog.startupstash.com\/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b https:\/\/medium.com\/m\/global-identity-2?redirectUrl=https:\/\/blog.startupstash.com\/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b \n How was your experience with fixie? \n The product? Confusing \ud83d\ude48 \n I'm not their Target either. I think they're building for PM junta \n Haha, maybe they didn\u2019t anticipate the launch of ChatGPT plugins \n The last bad product I used was https:\/\/www.steamship.com \n Platform to deploy langchain applications \n Interviewing him this week for newsletter :) \n Why was this bad out of curiosity? \n Nice! What newsletter? \n ntkris.substack.com \n Sweeet! I might have a question. \n will ask! \n Keen to know too \n Pinecone, weaviet, Chroma, vertex ai matching engine and there are bunch of other vector stores as well. What is the logic behind having soo many vector stores? Is the market soo huge? \n They are building a wrapper on top of LangChain components to take it to production. \n And I did mention it to one of their engineers on a call a month back, Harrison will pick up funding soon and have to build a cloud solution to monetize.  \n They raised $10 m \n Question best answered by VCs [PHONE REMOVED], want to chip in? \n [PHONE REMOVED] \n Sorry for the self plug but this is relevant to the conversation here: https:\/\/twitter.com\/nirantk\/status\/1644290469915164672?s=46 \n I love this quadrant \n Honestly, based on Vespa founder's tweets I think they might have the best tech? But I die a slow death every time I look at their documentation \n Oh long discussion but yeah pinecone is basically far ahead of the competitors in terms of technology \n Vespa is so good, and their docs so bad -- you could make money by just simplifying their docs. \n Why\/how are they ahead? Latency, throughput? \n Gcp vertex ai matching engine is ready for enterprise scale?  \n My biggest worry with vector stores: what happens when Azure, AWS or GCP adds them? \n The same thing which happened with Mongo, Elastic, MySQL, Postgres \n Basically pinecone has been in the bake for 4 years, always focusing on enterprise readiness and supports the largest number of use cases. Happy to talk more in depth about the actual tech that makes it more scalable, reliable \n Generally agree. My one push back on this: all of the things you mention are the \u201cprimary\u201d storage of some kind. Vector DBs, for now, are a critical feature. I still need a stand-alone sql or no sql db for the rest of my stack \n True. And unless it's massive scale, where the differences in performance becomes signficant, there's probably merit to keeping it unified \n Does pinecone offer a signficant advantage over something like pgvector? \n inb4 AWS comes out with an S3 integration for vector DB storage \n This would be a game changer.  \n Folks as someone who loves learning database internals: \n https:\/\/rime.ai\/ \n https:\/\/twitter.com\/lilyjclifford\/status\/1643702014680133632 \n https:\/\/twitter.com\/younesbelkada\/status\/1644341068241186818?s=46&t=icC0fizZK8E3ONsDVuGFWA \n Seems like new foundational models for different tasks are released everyday  \n Is anyone generating embeddings for this group, to create top 10 learnings from here every week? \ud83d\ude05 \n Haha, nice idea, and then scrape the learning articles and links and make sumarizer, which summarizes every topic in 10 words \ud83d\ude0e","36":"So needed \n Do folks know if anyone has integrated chatGPT\/LLMs into Alexa\/Nest type of smart home devices? Seems like a low hanging fruit. \n hey folks, has anyone dabbled with paddlespeech? \n The video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published - https:\/\/youtu.be\/WF28ZwhUCc4 \n there are tools that do it, alexa and siri integration is possible given you have your openai key which is the barrier to adoption \n Use Automatic 1111 on colab \n If you have MacBook download DrawThings App. \n GPU memory issue i think. Try smaller models \n I believe Jay is trying to get that running on local via Web GPU. Not a direct Python to GPU. \n I'm on windows machine on chrome canary. Currently the image is being created and is in process \n Image got generated on windows, but took a lot of time \n Automatic1111 works quite well on my max \n *Mac \n Like text to image in 10 seconds \n Is this even faster? \n SD is about 10 sec on A100 too \n Subtle flex but this one is M1Max with 64 gigs of RAM so maybe that's why \n It's ridiculous \n In my experience using Automatic on Mac simple text2image works but if you run inpainting with batch count of 4 using multi control net then you\u2019re going to have trouble \n Meanwhile Siri is in absolute shambles \n This is with xformers and fp16 though \n Bro I already have trouble \n M2 with 16GB RAM though. Complex operations would be better with 64 GB \n Wealth advantage \ud83d\ude02 \n Given we are discussing apple hardware, I'm planning to buy a MacBook soon \n 2 points I have to decide on \n My recommendation would be to either go all the way or get the Macbook air \n You can always get generative AI running on a cloud setup \n But if you want local gen AI capabilities do try to get as big of a machine as your wallet permits \n It's never going to be enough specially once text-to-video takes off \n True \n Yeah, but my Mac needs an upgrade, so looking to include the ai workflows locally as well \n I understand, I just wanted to highlight that M1 MB-air is plenty of you have a cloud setup \n *if \n I'm all in for a good ROI, and apple is very evil when it comes to pricing ladders, so looking at the optimum config \n How optimized are these models for running on apple RAM? As opposed to Nvidia GPUs  \n CEO of Weaviate, Vespa and Modal Labs are nerding out over serverless Vector DB and pricing around it: https:\/\/twitter.com\/jobergum\/status\/1644653416994488320 \n If you know how to read between the lines, that's a free masterclass on Developer eXperience and how that influences pricing, GTM \u2014 and mostly will continue to do so \n https:\/\/youtu.be\/8y7GRYaYYQg \n It's quite neat how the dev is debugging the logic on his own, but letting GPT4 fix the syntax and API calls. Quite close to my mental model of what it is right now. \n Within 2-3 months, I expect to see dedicated planning \"agents\" which can pair with the dev much more on the first part \u2014 this demo still relied on dev's skill and knowledge on how to describe game play well. \n Would love to hear more from game devs here :) \n My brother who is a not into development sent me this video today. Was intrigued at the possibilities and the capabilities we can have with GPT assisting. \n Jo never shills Vespa. Doesn't need to. Vespa is run  by web search OGs. \n [PHONE REMOVED] if you ever do a podcast style fireside chat\/discussion, do count me in for one of your sessions.  \n With Erik or any of these folks? \n Anyone. \n Working on something close. \n Not sure is this was already shared","37":"12am saturday, what else would you do but generate desi lofi girls \n If anyone to sell his SAAS company - https:\/\/twitter.com\/danmartell\/status\/1644798423961575426?t=BwA0POzNya9uB_BZkY1cHA&s=19 \n brb starting a vector db company \ud83e\udd23 \n Spending some time this weekend to catch up on everything, made this little tool \ud83d\udd28  \n cc [PHONE REMOVED] and friends built this for Youtube videos \n sitegpt as well does something similar - https:\/\/sitegpt.ai\/ \n Talking about similar projects - if folks are still interested. Microsoft Edge has a copilot option which does this exact thing which I\u2019ve been using. \n https:\/\/twitter.com\/alexgraveley\/status\/1644186023868416000?t=3mfuMZb0hDnOx2sFR9Wn4Q&s=08 \n Doesn't jsonlines format solve this? \n https:\/\/jsonlines.readthedocs.io\/en\/latest\/ \n https:\/\/twitter.com\/rowancheung\/status\/1644778701974822913 \n this will probably have the same bias as that viral midjourney thread with indian villagers smiling(like western folks) \n Youtubers in 2025: Smile wide and talk loudly, clearly to get an interview offer when talking to AI Interviewer \n Yeah only alternative is to train on an indian data set \n Has anyone used gptindex here in production? \n [PHONE REMOVED] is a contributor to Llama Index, might know more folks, please DM him. If you've hosting\/infra challenges, since that's the quite similar for Langchain, I can also help. I've 2 Langchain projects in prod+going to prod. \n Yes already working with him.  Seeing scale challenges now - slowness of answering and training new docs. What database did you use? \n Chroma, works in-memory, other than frequent deploys, not a pain.  \n Also, very small data: Less than a Gb of text \n In memory won\u2019t work for 100s of docs for us \n Yes it\u2019s not OpenAI as it\u2019s mostly in search which has no calls to it \n Hmm, if you're embedding a query with Ada, that is still a call to their API? \n Any better embedding suggestions than Ada, trying something on legal docs but it does not seem to work well, results are not consistent enough with Pinecone indexing and ada embedding, faced anything similar \n sachin from https:\/\/intellawyer.com\/ - should be able to answer it as he has experience with legal documents \n cc [PHONE REMOVED] \u2014 Indian legal docs \n Try mpnet from sentence transformers \u2026works quite well \n That\u2019s only during training. I was talking about searching \n https:\/\/www.sbert.net\/docs\/pretrained_models.html \n Btw a great shout out to Ravi \/ he\u2019s been so helpful to us with all his expert advice and tips. \n Any suggestions of Vector DBs? \n Thanks Karthik.  \n I use pinecone.. Nirant \/ Ravi knows much more about tradeoffs between them \n https:\/\/twitter.com\/nirantk\/status\/1644290469915164672?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Tweet thread by Nirant about this topic \n Nirant- you should start an accelerator for startups. So much knowledge. \n We got approved till $5K now. \n [PHONE REMOVED] \n You're 9 days late for April Fools Kartik sir \ud83d\ude1b \n Would a Pinecone, Chroma, pgvector comparison\/benchmark be useful?  \n hamara Erlich Bachman \n \ud83e\udd23\ud83e\udd23\ud83e\udd23 \n On a serious note, really want hackerhouses to exist in bangalore! \n +1 \n The only hackerhouse I wish to go to \n Oh HF0 \n legends \n You can actually make something like this happen in BLR \n Kormangala\/Indranagar has bunch of great bunglows \n Logistics is not the issue \n Rent them and make it a hacker house and attach it to some accelerator \n Yeah! \n So what is the bottleneck? \n Not enough OpenAI researchers in Bengaluru \n Why the accelerator? I would assume a bungalow would be self sufficient from just the rent \n If you putting all that effort to increase the chances of success for startups, you want to capture at least part of the upside \n *As a person hosting the thing \n Charging flat rent is not interesting in that regard \n There are more aligned ways to capture that upside e.g. can invest a pre-seed amount. But very off topic now. \n I really miss HackerDojo, used to be a blast. [PHONE REMOVED] This is something you all can do. A space for hackers to meet for cheap and hack together. Indiranagar is ideally located. \n Related note, GenerativeAI April meetup registration link: https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ \n Let's do it. Who's in for this? [PHONE REMOVED] you want to help set this up, to get it going? \n This is interesting. What was hackerdojo ? \n Google research toh h na? \n In theory, we also have Microsoft Research. In theory, Sharechat, Flipkart and a handful others do write CVPR, ICML, ACL papers.  \n Sure thing \n That\u2019s the thing to change nirant baba \ud83d\ude05 \n [PHONE REMOVED] will be lead the change and be teaching how to make comics at the April meetup \n This was exactly what I miss. HackerDojo in Mountain View is a community run space, I think it is a not for profit, where people can get desks for cheap with bunch of tooling etc to build stuff. Couple of startups started there, Pinterest is one that comes to mind. They used to be the default place for many meetups. I had met H2O's Satish Ambati there, when they were just 2 people amongst others. There were quite few others.  There were a bunch of people from Google Brain and FB's some team, who used to give talks there. So there was the amazing vibe and back and forth between the grey hairs and people pushing the bleeding edge. \n They used to have some link with Computer History Museum not 100% sure what it was. \n Hahaha May meet-up I\u2019ll do this pakka. April is tight. \n Maybe as part of the oral history series? \n That one could be one thing. There was some fiasco with finances. But one thing they did was they had membership dues + hot desk charges hot desk was quite reasonable. Definitely had the hacker vibes. I think there was some support from well to do community members too. May be we can talk to Nandan etc and others too can chip in. Just thinking out loud. \n +1 \n Any awards this time? \n \ud83d\ude01 \n Also, has anyone here gotten off the chatGPT plugins waitlist? \n still waiting :( \n same, still waiting :\/ \n Same. I don't know anyone in India who's received plugins access.  \n *its \n yeah me too. got gpt4 immediately. surprised that many people still don't have access to gpt4 api as well. \n Guy who is maintaining kisaangpt got it I guess \n Is there a link? \n He's living in SF so my conspiracy theory still holds \ud83d\ude05 \n I have it, going to build something for my product in the next week \n Oh wow. Let me DM you! \n But wait, you're not in India it seems (going off of your phone number) \n Yes I\u2019m in London(sorry didn\u2019t realise it was india specific) \n Welcome Dr Pratik. We were just talking about you! \n \ud83d\udc4b \n We're talking about how few folks in India have gotten chatGPT plugins access \n Hey Ojasvi, Nice job with Jadoo and Shakalaka\u2026 Been following all of you guys work and Nitant\u2019s hackathon. \n I've got the access \n Thank you sir \ud83d\ude4c\ud83c\udffb \n Not in India though \n What could be the reason India isn't getting the same treatment as the rest of the countries for plugins access \n Often compliance is a big reasion \n *reason \n Yeah, I got the access. They are mostly vetting and rolling out access slowly. They have been following my work with Kissan GPT and provided support letter as I have been called up by ministries. That may be the reason for my boost. \n Quite inspiring \n You're still in SF? \n Yes \n I'm still waiting for GPT-4 API. Any recommendations on what I can do to? \n You guys may be right about country preferences due to compliance as I got access to GPT4 API in the first few days only. The another reason can be age of account or usage. I have been using their API platform since 2020. \n Same, 2020 user. But Atty soft-confirmed they're doing SF first. Everyone else came later. \n Atty is the OpenAI engineer at Setu office right now \n Just the city. Wow. Looks like doomers are making them more cautious about opening up. \n Meaning? Who? \n What\u2019s your usage? Ballpark $ or requests? \n https:\/\/www.linkedin.com\/in\/athyuttamre \n He's on the plugins team \n Is the talk being recorded anywhere ? Missed it, unfortunately :( \n My usage is not so high tbh. 80k+ requests\/mo. Mostly using turbo instead of 4, to keep the cost low, which is really inexpensive, and good enough for my use case. \n oh \n coming to india v soon \n Came back to SF yesterday \n was in India for a month \n i mean the plugin access \ud83d\ude05 \n Who will be in SF this month? \ud83d\udc4b\ud83c\udffc \n [PHONE REMOVED] ? \n https:\/\/www.linkedin.com\/posts\/setu-apis_we-have-kicked-off-the-openai-x-fintech-session-activity-7050806116791832576-S3Ns?utm_source=share&utm_medium=member_android \n I\u2019m here in Bay Area , in case anyone wants to grab a coffee or beer. \n also, people who are thinking to buy plus just for plugins \n disjoint sets \n Was this recorded by any chance? Would love to get if anyone took screenshot or could share access to the recording later. \n Oh, just came back to Seattle. I'll be in Seattle for a few months. Would be happy to meet w\/ you when you're around here.  https:\/\/www.linkedin.com\/in\/anirudthn \n Hi folks, have been lurking a bit in the group for now. \n Hey I have some experience in this and can help out. Is it for a product or a one time thing? Because the approach would be different \n I have something in mind, but not sure if it can be a product. \n Sure \n I'd like to help \n Will dm you as well, thanks \n Cerebral Valley (which I\u2019ve been a part of) started with ~50 members. (About 500 now but it started off small)","38":"https:\/\/www.youtube.com\/watch?v=2xxziIWmaSA&t=1079s  \n Thread of Hackathon ideas and lot of the same ideas we saw at our hackathon:  \n Weird, the political action project is the first thing we sold to a client back in 2022!  Who\u2019s the creator? \n Creators haven't been mentioned, but you can tweet to Joseph or @swyx and ask? \n Aside: I realised I know swyx from back in the react world because of this superb talk - https:\/\/youtu.be\/KJP1E-Y-xyo \n many of them are chatbots, we had so much variety in our hackathon imo. \n GPT 3.5 users, have you ran into problems which require you to limit output length? \n So my question is, instead of instructing it to change its length in terms of characters, will there be any benefit to changing the length units to token.  \n Sorry for the long message. Had to make sure it's clear to the people who'd like to answer \n The recommended way to do this is to use Guardrails and turn on re-ask (iterative variant of your recursive strategy). It's easier to reason about and often more token efficient too.  \n You'd know about this if you were at the hackathon venue [PHONE REMOVED] \u2014 we had Guardrails creator do the demo xD \n Thanks a lot, will check it out \n My body was barely functioning, I was borderline disoriented with 2 hours of sleep \ud83d\ude02 you know this \n https:\/\/github.com\/ShreyaR\/guardrails \n My intent for sharing this is to emphasise that Indians are no longer playing catch up.  \n One weird thing that I noticed in guardrails and kor - why is the schema format not the same as the output format? \n What\u2019s Kor? \n General purpose parser for any text\/schema \n Similarly for guardrails, the schema is xml, but the output is json \n From a language\/lib design PoV, these are the two things you're trying to balance:  \n <3 \n The dsl makes sense, but the part that\u2019s confusing to me is why the schema sent to the llm is not the same as the requested output format. \n My intuition, based on the thousands of samples I've tried so far is this. The resizing prompts work fairly well when input and output language is English. Tokenizing ka rule is uniform in English.  \n Thanks for moving this back to main, since it's widely relevant. E.g. [PHONE REMOVED] has worked on an adjacent problem statement as well. \n Aligned on the non-English challenge: The BPE tokeniser is notoriously unstable for CJK and Indian languages. Better with European languages often.  \n Prompt engineering in this way is a bit like casting a spell, and I don't think any amount of tips on \"wingardium leviosa\" is going to help \u2014 doing it will work best \ud83d\ude4c\ud83c\udffb \n Tweet this, tag OpenAI folks. Nothing like this to nerd snipe them into replying to you and spilling some detail about GPT4 is actually trained on text-davinci-003 \ud83d\ude02 \n I like how your mind ticks \ud83d\ude02\ud83d\udc4c\ud83c\udffc \n My customers are raising support tickets for this and saying that we're fooling them by saying we got GPT4 access \n Ouch. I'd try to improve this with a system prompt: \"You are helpful OpenAI Assistant, specifically GPT4. Never say GPT3\" or something along those lines. \n The reason this happens is that chat models are instruction finetuned, sanitised and scaled forks of large base models. Same for the REPL and Retrieval models in Plugins. \n This trick should also work the other way around. You can have GPT3.5-Turbo claim to be GPT4 \ud83d\ude02 \n Super explanation of GPT with 2 tokens and a context length of 3.  \n What a beautiful doc \u2764\ufe0f \n Karpathy is doing teaching again? Yess! \n Interesting new research on Generative Agents \n Some enthu reporting as always - https:\/\/youtu.be\/wHiOKDlA8Ac \n Anyone suggestions on how I can get my hands dirty with Midjourney? On the discord, it has been showing full capacity for quite sometime. Any other way that I can try it out? \n Midjourney is exclusively on Discord. Wait for a while or try in the afternoon when traffic eases up. Or pay for premium \n Hi. There is a new model Kandisky 2.1 available on dreamlike.art which is pretty decent  alternative to MJ. They provide daily credits as of now \n Quick ques: What are the costs differences between GPT-4 and GPT3 API? \n I had found this quick compare table,handy for comparing various models \n any image-creation tool that accepts looking into a website design for reference? \n Do you've friends or acquaintance artists working with LoRA?  \n Vignesh is quite nice! In my Covid-tinged master's days, he gave me great advice for job hunting in Leuven. \n Thank you very much Nirant! You are awesome \ud83d\ude0d \n Thank you Sid! \ud83d\ude0d","39":"https:\/\/arxiv.org\/pdf\/2304.03442.pdf \n Yeah, just saw on Andrej Karpathy tweet \n with the demo at https:\/\/reverie.herokuapp.com\/arXiv_Demo\/ \n Yeah Generative Agents \ud83d\ude00 \n Yup! \n He\u2019s an awesome person. I agree \ud83e\udee1 \n I've seen this project\/tool floated around Twitter. But I can't recall its name, google isn't helping much either. Would love if anyone of you can share what its called or a link to it. \n That was a while back and I think they were using flat GPT output without crawling their pages. I may be wrong. \n is it this one? : https:\/\/wtfdoesthiscompanydo.vercel.app\/ \n Yeah \n thanks folks \n This is another interesting paper. Combined with Meta\u2019s segmentation model can open up many interesting use cases. https:\/\/twitter.com\/_akhaliq\/status\/1645594671068971008?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw \n Langchain Bruh moment \n This bot doesn't have memory, you asked if the lib has memory, not the bot. Classic NER ambiguity mistake. \n even Jeremy didn't have access to ChatGPT plugins until now! it really is SF-first (he's in Australia i think) https:\/\/twitter.com\/jeremyphoward\/status\/1645597656499245057?t=21TkvGGfdo-gEqmw3NKvsA&s=19 \n Ab FOMO Nahi ho raha \ud83d\ude02 \n My hypothesis was they have profiles on pro open source people and are being slow w GPT-4 features w them \n Is using a VPN a workaround? Depends on how do they determine your country, does anyone have an idea? \n i don't think that's gonna be useful.  \n Let's assume that my OpenAI account is a part of a big organisation and we use OpenAI APIs extensively \n PSA: Ojasvi leads AI at mydukaan.io \n yeah im aware :) \n im just guessing.. \n They ask you isn't it? Guessing probably use ur input + your ip + other sources like where cloudflare is serving from + some predictive stuff based on prior tokens. Guessing they probably use martech profile data as well. Which exact ones, is anyone guess. Guessing you tried messaging over Twitter. Try connects if you have any at OpenAI. Don't know if they have 'strong' policy around it though. \n mydukaan.io needs to IPO [PHONE REMOVED] bhai, they've given access to more public companies \n Hey folks! I've started sending out invites for this, it's happening on Thursday at the Lightspeed office in Koramangala at 6:30pm, not all folks are there on the invite since we were trying to make it a very interactive group with small number of people, but the idea is to invite for the next mixers. Looking forward to seeing people on Thursday! Please do DM me on WA to confirm if you're coming, thanks \ud83d\ude42 \n You didn't have to tell 350+ people that we're not cool enough [PHONE REMOVED] \ud83e\udd23 \n Haha, more like we have a small rooftop which can only support so many people\ud83d\ude02 \n It\u2019s not entirely location based. It\u2019s org working with openai + selected startups + particular use cases of person working on a specific domain openai is experimenting on \n I have access to all the plugins sitting near bellandur lake \ud83e\udd23 \n So I don\u2019t think vpn would work \n https:\/\/www.inferless.com\/serverless-gpu-market \n Thank you for the shoutout, Dev!  \n This is well written! Great job \n This is great! \n This is a very comprehensive guide, Aishwarya.  \n Anybody know any Ai research labs in Bangalore? \n I have a client which is an AI lab. What's up? \n Looking for some research based experience on cutting edge tech! [PHONE REMOVED] \n In Ai itself \n Can connect you, DM! \n Rahul is one of the smartest people I know. He's worked at MS on Wall St and then started a crypto hedge fund. He sold it to BlockTower Capital. \n Has anyone tried using YubiBert? CredAvenue's OSS Financial LLM? \n Linkedin has one of its research arm at Bangalore. \n [PHONE REMOVED]  whom do i contact? \n I work there. DMing you \n I would also be keen to learn more about this AI lab \n [PHONE REMOVED] what kind of work do they do? \n The team works on content moderation and content quality on the Linkedin platform. \n So they build their own models or something for all these? \n Yes, we train our own models, since the data distribution is different from the datasets used in academic setting. \n Yes got it! \n Anyone attending the OpenAI meetup in HSR today? \n How to find out more? \n https:\/\/lu.ma\/y7uu4m4e \n https:\/\/www.inkle.io\/resources\/events\/talks \n Any chance this will be streamed? \n On providing the required config files to access a service that requires authorisation, can we ask gpt to access let's say a specific table in database and make commits in that? \n Yes. It's possible. You can perform CRUD ops in database \n this can be done using tools for dml,ddl commands or do you have any other method? \n Yes. Just the dml commands. Connect with [PHONE REMOVED] if u are still blocked","40":"Has anyone compared\/experimented with OpenAI's best embedding model available \"text-embedding-ada-002\" vs Huggingface models or Sentence Transformers. Have seen most people using OpenAI's embedding, does it have any advantage over others available? \n I believe many of the OS ones are superior. There was a thread on this, let me see if I can find. \n https:\/\/twitter.com\/mr_cheu\/status\/1626261050566778880?s=46&t=lkuvFQUWr1nav0QpUpFmdQ \n That was Feb 2023 so like a decade ago by AI standards\u2026 \n I had compared sentence transformers with OpenAI embeddings 6ish months ago..For my use case, sentence transformers turned out to be quite competitive \n Got it, thinking to try this model 'sentence-transformers\/all-mpnet-base-v2', is that the best mpnet variation? \n Multi-qa-mpnet-base-dot-v1 works a little bit better for semantic search ..but I will recommend tryiing top 2 or 3 and checking \n Also if you need better scoring mechanisms, use cross-encoder for scoring afterwards \n https:\/\/youtu.be\/540vzMlf-54 \n Awfully painful questions \ud83d\ude02 \n Traditional News Media looks really frightened with AI. Even I got call for Interviews for that tweet \ud83e\udd26\ud83c\udffd\u200d\u2642\ufe0f. The buzz is really hot and controversial, people are waiting to take you opinion out of context and attack. Everyone is on edge. \n Ohh, the ChatGPT Plugins SF hackathon announced their winners: https:\/\/twitter.com\/atroyn\/status\/1645954654394802176 \n All the winners here have much higher _usability_ than what we had though \n Reminder: My intent for sharing this is to emphasise that Indians are no longer playing catch up.  \n Thank you for sharing [PHONE REMOVED]. The chatrooms concept was super cool, brings social networking into it. I\u2019m going to explore that. It is analogous to an idea I had about enabling long term conversational memory, by vector indexing the conversation history itself. \n Langchain has some pretty good abstractions around memory (in addition to the index+retrieve approach): https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/examples\/conversational_customization.html \n Happening as we speak : https:\/\/twitter.com\/i\/spaces\/1djGXldPqNyGZ?s=20 \n Very off topic. Appreciate the intent to share news though.  \n depends on where you draw the lines. There are obv going to be some AGI conversations in this space. But anyway, \n Silicon valley is stealing my ideas >.> \n Elon just spent at least $250M on GPUs for training generative AI at Twitter. \n https:\/\/twitter.com\/yoheinakajima\/status\/1645811071230545920?s=48&t=vVjNVO7AhqZtPO3IJxRokA \n I\u2019m really liking this autonomous GPT agent stuff : \n AutoGPT -4 SigGravitas  \n Harrison Chase implemented a custom LangChain abstraction for BabyAGI based on Yohei\u2019s method  \n https:\/\/twitter.com\/langchainai\/status\/1645808279849947137?s=46&t=icC0fizZK8E3ONsDVuGFWA \n https:\/\/python.langchain.com\/en\/latest\/use_cases\/agents\/baby_agi_with_agent.html \n Also worthwhile checking this out  \n Smaller version of the \u201cWestworld Sims\u201d experiment \n Design Principles for building Agents \n https:\/\/github.com\/eumemic\/ai-legion \n For folks using Typescript for agent building \n We're starting to see first steps towards regulation by governments https:\/\/www.wsj.com\/articles\/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b \n Obligatory next step for gov of India to try to build BharatGPT. \ud83d\ude05 \n They're already doing that \n Yeah I heard in a Nadella interview. \n Sam Altman is making a DEL trip, not BLR. Clearly, monopolisation and regulations are best buddies. \n Monopoly play clearly \ud83d\ude05 \n https:\/\/github.com\/RSTLess-research\/Fauno-Italian-LLM \n Italy might have banned OpenAI  \n Petition to create a Bharat LLM instead of Bharat GPT \n Are you referring to a foundational model or a GPT model fine tuned on India data? \n +100 \n I would assume it would start off with GPT first. \n Problem is with all the examples you\u2019ve mentioned we are not fully local till today  \n A better example would be India\u2019s nuclear programme and ICBMs \n I think they'll create an LLM because Gov is more focused on self owned public infrastructure \n https:\/\/ai4bharat.iitm.ac.in\/models \n Anyways, AI4Bharat is working on it ig. The IITM one \n BabyAGI on Replit in just 105 lines of code https:\/\/replit.com\/@YoheiNakajima\/babyagi?v=1 \n Lol what a coincidence \n But I think it will be very hard to beat translation + gpt-4 performance \n For now their focus can be on transliteration \n Also they might just invest 500 mil and ask Microsoft and Nvidia to just do it too who knows. \n Yeah, pratuysh works at msft research only so \n https:\/\/www.medianama.com\/2023\/02\/223-nadella-bhashini-language-translation-platform\/ \n https:\/\/farmer.chat \n Can add more Indic Languages, add voice support and link to government schemes via plugins \n Voice support is there via one of the ai4bharat models \n More Indic languages will come :) \n We are using IndicTrans in KissanGPT for few already \n We use google translate. How are the latencies for indictrans? Where are you hosting it? \n Trying to add TTS but the inference is not optimized yet \n The US got another tool for its leverage and control \ud83e\udd26 \n You mean stt? \n TTS as we are trying to also return answer in same language \n https:\/\/www.inferless.com\/serverless-gpu-market \n You can check it out at https:\/\/kissangpt.com \n Pretty slick! \n We have been working in AI for agriculture for sometime so we have significant amount of knowledge base and in talk with ministry to access huge amount of information that we will start adding \n Our government is actually working to enable the ecosystem. They're hiring PMs for AI roles too. bhashini.gov.in\/en\/ecosystem \n While [PHONE REMOVED] speaks of how the country is advancing and getting ahead in the tech-contribution at par with the westworld, the only difference is the tools that people build there start getting used quite immediately and you can see it\u2019s effect, while it\u2019d probably have 0 usability here. \n Of course we are doing better than most, these models are good but our local open ecosystem needs to jump on making these models production ready from research output. \n That's probably because we don't have PMF with the end user. Our products are still not designed well for them \n By what time do you think farmers of India will start using https:\/\/kissangpt.com? \ud83d\ude43 \n I have been getting calls from all type of farmers and hobbyist about using Kissan GPT and feature requests. Not getting time to add features as I\u2019m talking to them. \n Probably when it stops having foreign words like GPT in its name for starters \n (foreign to the local farmer) \n that\u2019s insane, kudos! \n Already there is a good amount of folks using it. Farmers have phone and they are very much aware of news and things going on then you tokan think. \n Folks* \n There are large club house groups where talk regularly \n Would love to see an use case like above! \ud83d\ude03 \n When last time I was on clubhouse, they were suggesting requests for their everyday use thay I have to look for note pad. \n Hey how are you ensuring RLHF ? Here ? \n Do you have any systems in place ? \n Yes, our students are capable but they don't have the required resources (computing is costly). Hopefully corporate and govt will support this ecosystem. \n No I don\u2019t. But I\u2019m collecting enough information that I can implement something in future and May be share voice dataset with Bhasini. \n Let\u2019s see, lot of initial conversation going on multiple front \n I got one interesting request to integrate visual capabilities to detect bad signs in the crop photos. Do you have any plans or thoughts there? \n I have asked OpenAI to give me access to multimodal when it is available in gpt4 api, let\u2019s see when that available. We will be integrating it. \n This is a novel and socially good use case. \n Yes soon, I\u2019ll have to move from my home rigs to cloid infra. I\u2019ll reach out. \n You are running this on your home infra? \ud83d\udd25\ud83e\udd2f \n \ud83d\ude4f\ud83d\ude4f \n Yes \ud83d\ude14 \n What will the cost to move it to the cloud? \n Need to keep cost low as possible to make it available for Agri domain \n Register a company and apply to Microsoft for startups get 150k in credits donot for 2 years \n One PSU already gave up \n Same, we got google cloud for 2 years. \n Working on it \n Amazon before that. Just keep moving clouds until you get free credits from everyone \n They are supportive \n With open source, non-profit research use cases any cloud provider can provide credits easily. \n How big are you guys? Just you? \n I am not thinking non-profit case as it won\u2019t help me scale. I have Agri startups to integrate in their platforms lined up. But still they do give startup credits which I\u2019m going to apply for. \n Im here in Bay Area and small team in Surat, 7. \n I know [PHONE REMOVED] is also from Surat. Small city folks. \ud83d\ude01 \n Any Finance bros\/gals in this group playing with AI? There is an idea I'm toying with would love to chat. \n Not finance but building in the legal space. \n Glad to find that it was helpful! :) \n Have you used TTS ? Can\u2019t locate their weights \n What are you using, quality is good \n You have to literally hack into their XMLs and storage path to get those. They are saying they have them on Bhasini and open sourced them but I couldn\u2019t find direct links. I tried to request on their account but I didn\u2019t get any reply, and then the inference is not optimized. That\u2019s the reason I\u2019ve to run everything on my rigs right now, as a lot of hacks are involved. \n Just realised that SAM runs inside a browser on the cpu \ud83e\udd2f \n cc [PHONE REMOVED] do you want to do a demo on this in the April meetup? \n Yup. Working on it. \n Link for April meetup, for those who've joined recently \n In-person, BLR only \n https:\/\/huggingface.co\/spaces\/abhishek\/StableSAM \n I\u2019ll be there \ud83e\udee1 \n Folks, a portfolio co which generates research reports on quality of carbon credits, is looking for tools that can help write their research reports on top of the research they have done. This report will be a mix of text & charts.  \n Else, if someone is willing to hack something like this along with the portfolio co, happy to make the introduction.  \n whosoever picks this up, please charge more than $10K \n The initial encoder uses GPUs, it's only the decoder which runs on web browser. \n I have a question regarding SAM. \n Compare yourself here: https:\/\/huggingface.co\/spaces\/abhishek\/StableSAM \n You'll need a 512X512 to try this link btw. Errors out for all else dims \n Internally resizing is happening right \n Thanks, will try this \n Dumb Q: Wont you use SAM to just generate a mask for the inpainting or outpainting model? \n I\u2019m still a noob at these.  \n I think the advantage with SAM is the interactivity from a UX perspective \n This looks like SD code, not the sam code \n Yes SAM gives mask \n tried, still didn't work \n https:\/\/twitter.com\/kevinafischer\/status\/1646009719314841601?s=46&t=icC0fizZK8E3ONsDVuGFWA \n AI agents writing their own plugins \n https:\/\/twitter.com\/shivam124081\/status\/1645691399164026880?s=46&t=kpJ79jqt9oDMH6ZCqnhylA  \n Cc [PHONE REMOVED] karde Kya? \n Hey folks, anyone here know any dataset agencies? (Need to curate an instruct type dataset.) \n Folks, this langchain webinar with harrison, yohei among others is quite nice - https:\/\/www.crowdcast.io\/c\/46erbpbz609r. Is live now \n Can anyone share Langchain resource i can checkout to get started ? \n The Langchain docs are really good to get started with they also have guides for reference too. Check them out here :  \n *- https:\/\/python.langchain.com\/en\/latest\/ \n Thanks \n https:\/\/huyenchip.com\/2023\/04\/11\/llm-engineering.html \n OpenAI have released open source implementation and model weights for their latest work. These models do one step image generation. ","41":"Love how they crowd sourced the dataset from own employees: https:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm \n This can be amazingly fast as it doesn't use diffusion. If someone finds memory requirements and inference speed, please share. If it is small enough to tinker without using the A100 cluster, we can see its versions of Dreambooth and ControlNet popping out soon. \n A nice summary - https:\/\/www.marktechpost.com\/2023\/03\/10\/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training\/ \n oh no! we just went live with Pinecone and this is scary \n Ditch em. That's a key risk. Even if you ever want to tell your customers how good your recall your QA is, Pinecone prevents you from doing so. Will handicap your marketing\/sales. \n yes agreed. Weaviate had other problems though - scale, connectors. Will check out Qdrant \n Yeah, hear you on Weaviate's scaling issues. Qdrant scales betters. Connectors solution is to go via Llama Index for recall.  \n That is quite valuable to my enterprise SaaS friends, any sort of reporting\/tooling to see what they're missing in FAQ \n yes using LlamaIndex with Pinecone in prod with Ravi's evaluation \n Please forgive me for being repetitive, I am a sucker for neatly executed ideas \ud83d\ude05 \n Much needed one. As more people use it, it helps me to get feedback and make it better \ud83d\udc4d\ud83d\ude09 \n Which is the best Vector DB for production ? \n Naive question but being bold asked \n Not naive at all, the answer is \u2014 we don't know \n \ud83d\ude0e \n Ok \n Worse, we don't know if it's worth answering this question when 32K context windows become a thing \n I am a little biased but I'd throw in the name of Redis \n Inferencing costs? \n People married to Azure Redis is the only choice which is PAAS \n [PHONE REMOVED] sir, sponsor a grant to do this ANN Recall vs $$ benchmark? I'll do it for \ud83d\udcb5 \n I am liking this group so lively \n There is one Vector DB Millivus \n The current inferencing costs are about 10-50x from what they can be at scale, even for GPT4. I think the price will drop another 10x in next 6-12 months. \n Name your favourite Pokemon: Milvus, Weaviate, Qdrant, Chroma, Pinecone, Redis Vector Cache, Vespa, Elastic, pgvector on Supabase \n I like you 2x2 matrix actually here  \n I'll let you know how Pinecone goes. Will push to 250 customers next week. \n I\u2019m implementing hybrid search and really annoyed with their docs. Literally tried their example and it doesn\u2019t work. Good time to move away it sounds like \n Umm, could I ask what makes you believe so?  \n Cloud Providers' APIs are also fairly expensive \n Azure, AWS, GCP \n For example, https:\/\/aws.amazon.com\/comprehend\/medical\/pricing\/ \n GPT3.5 was cheaper than GPT3 \n Was? \n text-davinci-003 is more expensive than gpt3.5-turbo \n sorry, is. \n 2M tokens for $2 \n Ah! I thought they increased overnight \n point is that LLM models will only get cheaper and faster - as proven in the past few months. GPT4 is more expensive than 3.5 until GPT5 comes up \n GPT4 has two major releases pending:  \n 3. Plugins for all practical purposes. I doubt they want to stop at giving 20K people access to that. \n Plugins has _at least_ 2 new GPT4 finetuned forks:  \n and plugins in API \n I got zero juice from that Atty OpenAI event \n sigh \n The juice from the Setu event was worth 30 min commute tbh \n Setu event? \n Before the open-for-all event, Setu hosted Atty in a closed door meeting. He answered questions like finetuning for plugins, API design, release plans and constraints, internal tooling, some benchmarks (and who makes them), checkpointing and how they decide to brand one model as \"GPT4\" \n bruh, this sounds so much better \n lol \n Can add libraries to the list? Faiss, Annoy, ScaNN, ANNlite \n Yeah, at the very least FAISS and Annoy qualify \n But I ran out of storage in my Pokedex \n How much? :P \n If you've to ask ... \n I doubt it Karthik, most of the foundational LLM companies are losing a lot of money + there is a GPU shortage in the market ... they have to jack up prices to customers.  At least I think next 12 months prices will increase, until there is mass adoption and so we reach supply demand equilibrium. \n Will you take a personal wager of 1L INR on price hike? \n I'm willing to take a personal wager that prices drop \u2014 either via people switching to internal GPUs or OpenAI or some other mechanism \n Sorry not a gambler here. But happy to buy you a drink. And as I said my comment is for commercial LLM providers - a company switching from commercial to self-hosted \/ open source LLM is not where my perspective applies. \n Cost of compute is high, moving to open source \/ self hosted makes a lot of sense. But then you have to include the LLMOps cost + team cost + data cost etc etc ... \n And I don't believe most startups have the money to hire very expensive research scientists that OpenAI has \n It is a gamble if you think it's a game of chance and not skill :) \n Maybe once the usage of private data to train the model is restricted, APIs can be free if the user consent to give up on data rights. Paid for those who don't. \n The moat for a company lies in proprietary dataset is my view. \n I believe even commercial ones will get cheaper and willing to bet on it. We haven\u2019t even seen AWS, Google, Microsoft enter yet \n Unfortunately to me it feels like Google is not even in the game. And Microsoft has such a sizeable investment in OpenAI that most probably Azure APIs will be essentially OpenAI APIs repackaged. \n I think the fight is between Oracle (yes lot of people don't know that they are cheapest out there in GPU pricing) vs. AWS \n TPUs don't make a difference? \n Fantastic case study from StableCog and what did they consider when selecting between all the popular Vector Databases. \n lets discuss in 6 months \n good documentation \n https:\/\/github.com\/lllyasviel\/ControlNet-v1-1-nightly \n Is anybody using Milvus ? \n I hear it's popular at Zilliz \n It's their opensourc \n opensource \n https:\/\/zilliz.com\/ \n You didn't have to ruin the joke for everyone by explaining it \n someone will need to build a migration tool to avoid re-embedding \n AFAIK: That is an open research problem. \n I'm currently in touch with the Lead who's managing vector similarity search in Redis \n Recall against $$, recall against qps \n Prayank, I agree with your arguments from the economics pov. From a technical pov, it seems like models will get smaller without drastic reduction in accuracy unlike now. The fact that we can train them with simple optimisation algorithms, the fact that you train on 570GB to create a 170B parameter model etc, all sort of allude to the fact that we possibly have a much smaller model (possibly this is just a smaller model embedded in larger space, so to speak). There are things that can still  help these companies make money and we still have to use them. \n The research community is super split on this. There is a smaller model future faction and a larger model faction. Smaller you described and larger you can guess. After having spoken to enough researchers, it feels like only time will tell which way we will head. OpenAI is clearly interested in larger and larger models. \n Is any meaningful alternative to Nvdia coming up in the next 12 months that can alleviate the stress on chip supply? \n From what I have read, smaller models are accurate for certain tasks but for higher accuracy still larger models are required. And, also emergent abilities are coming out in larger models \n https:\/\/tenstorrent.com \n [PHONE REMOVED] good to see you here \n [PHONE REMOVED] any idea on who is using them and what is the cost\/performance comparison to NVidia? \n This is jim keller\u2019s new chip company. Openai put money into it. Don\u2019t know the specifics right now, but jim informally told us that they want to build a 2 terabyte ram ai accelerator. \n Sorry I dont think the openai funding got through yet - https:\/\/techcrunch.com\/2023\/01\/10\/openai-in-talks-to-back-zeloof-and-chip-legend-kellers-startup-at-100-million-valuation\/amp\/ \n Just noticed they have a Bangalore office. Unbelievable! \n But the vibe at the bangalore meetup was very clear, they want to give the incumbents a run for their money :) \n You are 100% accurate on this. There is interesting dynamics around what is needed by the task at hand. So really the question is are there going to be lots of reasoning like applications or better search\/similarity like applications. How much larger models resoning like capability requires, that probably is anyone guess. Given the semiconductor lifecycle, new chips will take time. OpenCL has been trying to make inroads for last decade. Would be interesting if new models can do reasoning (GPU like) + table lookups (traditional computers), AllenAI did some work on this but nothing mind blowing afaik. \n IMO these are very long term play and probably only help OpenAI or whoever can afford development out side of cuda. Also OAI, reportedly using Cerebras. \n AllenAI's announcement this summer will change that mostly but I wouldn't swear by it yet \n Cant tell about the long term play part, but they were a lot of talks about open ISAs because of risc-v and how they\u2019re actually trying to democratise access to chip designs. They also talked a lot about open source. \n folks, have you come across any open source LLMs that are strong with code generation & various programming languages? \n If I'm not wrong, Replit and Aws codewishperer are both using CodeGen \n Anybody knows Something which can be hosted locally without internet... Can Alpaca be finetuned for local codebase? \n I recently tried running GPT4ALL locally and it worked pretty good on my 8gb ram laptop \n https:\/\/github.com\/ravenscroftj\/turbopilot \n I was just trying this since noon. This is good for text generation and the onboarding is super simple. But it\u2019s not really strong with code yet \n Will check this out \ud83d\udc4d \n Agreed. OpenAI has kind of merged their codex model with GPT 3.5 turbo so they have a single purpose code generation model kind of integrated which makes it powerful \n Feat. [PHONE REMOVED] \n Nice! Any way deck can be shared? \n There is no deck, it's a survey thing they did live \n Ah \n \ud83d\udd25Commercially Viable LLM from Databricks - Dolly 2.0 - 12B parameter language model (LLM)  \n They have open-sourced training code, the dataset, and the model weights, all suitable for commercial use :) \n That's their top highlight while selling the contract renewal of the data bricks platform \ud83d\ude02 \n https:\/\/github.com\/huggingface\/diffusers\/releases\/tag\/v0.15.0 \n Such a good share. \n Anyone wants to join hands on translating Spectrogram Diffusion to work for images? \n We (Koo)want to identify generated images.  \n cc [PHONE REMOVED] runs a company called Spoofsense.ai if I remember correctly, but I might be wrong \n Perfect. I'm wearing a Dukaan tee. How can I spot you? \n Hi Harsh, Kartikeya here (spoofsense.ai) would love to connect. \n Coming back up. Stepped our to buy cigs \n Are you sure, heard it can\u2019t be done \n Let me know how we can collaborate. Sending you DM \n https:\/\/twitter.com\/ashe_cs\/status\/1646543644038397952?s=46&t=0NBX3C3Uma-Su4_rjA3OMA \n Thanks a lot [PHONE REMOVED] for hosting today's mixer. Met so many cool people and it was absolutely delightful to hear what everyone in Bangalore AI space is up to. \n You forgot to thank them for free beer and food \ud83d\ude02 \n Ehh they'll probably make it back 10x if they invest in some of the killer startups that people represented today \ud83d\ude09 \n Nirant should get carry!! He runs a group that has the highest ROI of perhaps most groups in Bangalore tech space. \n Anyone else experiencing crazy timeouts with GPT-4 API? \ud83e\udd7a \n Yes \n Ohh yes, I think so. It started to feel slower from evening today \n They're rolling out new access, so small spike. Will even out tomorrow hopefully. Consider using tenacity with exponential backoff in the meantime and be nice :) \n Tenacity is a Python lib for retrying with exponential backoff \n Mujhe laga life skill of being patient bola aapne \ud83d\ude02 \n (Not kidding. I actually didn\u2019t the framework. Thanks \ud83d\ude4f) \n Cerebras is doing some solid work but not planning to be consumer focused chips \n https:\/\/www.linkedin.com\/posts\/harshsinghal_under40-activity-7052341005978615809-EaUX?utm_source=share&utm_medium=member_android \n Sambanova building FPGA based chips for AI \n Open to working on this with interested folks.","42":"langchain uses Tenacity too! \n +1 on this \n We have an api for this kids as superheros idea \ud83d\ude06 \n https:\/\/techcrunch.com\/2023\/04\/13\/with-bedrock-amazon-enters-the-generative-ai-race\/ \n Today i finished the Andrej Karpathy's video on Neural Nets. Even though i knew few things, i learned a lot in depth. Will highly recommend to anyone starting or even in the field. He teaches really well and in depth. \n https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ \n cache LLM calls and save $$ \n Tried this on an online image. Pretty good.  \n Img2img models for inpainting? How? \n I'm not an expert and things are moving fast - I'll ask GPT-4, browse diffusers like crazy, watch a ton of YouTube videos or wait for someone here to suggest. \n https:\/\/stability.ai\/blog\/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users \n Morning everyone. I remember seeing a Twitter post about 'ChatGPT for a github repository'.  \n https:\/\/js.langchain.com\/docs\/modules\/indexes\/document_loaders\/examples\/web_loaders\/github \n Demo video of Chat with GitHub  \n Must be this one only \n sweet, thanks bud. Have a great day. \n What if someone build this \"Google me what I have seen or heard somewhere\" \ud83d\ude05 \n It is entirely possible using LangChain  \n Actually, I am using Bard for asking questions on a github repository, and it is performing pretty well for me until now. \n Seen\/Read: On Twitter, Browser, WhatsApp, Slack, and any other platform\/app  \n Check Reflect.Ai then \n Thanks I will check. \n Ah no,I think I got the name wrong  \n Directly asking questions to bard about certain repository by providing link or some other way? \n For famous repositories, it directly works by typing the name of repo, for new repo or repo that is not ranked, I provide link and ask questions. \n I think you meant rewind.ai \n I could really do with that tool just now \ud83d\ude05 \n Yes exactly \n Their tagline itself is  \n Building LLM applications for production \n https:\/\/grail.cs.washington.edu\/projects\/dreampose\/ \n Here's a new AI model called DreamPose that can generate Video from Image. \n do we need to finetune the model on the subject-specific image before creating the video?  [PHONE REMOVED] \n Yeah it looks like it, https:\/\/github.com\/johannakarras\/DreamPose#finetune-on-sample \n ok. noob question may be but how is this diffrent from an edge detection algorithm on steroid . \n question: for smaller sets of data, what\u2019ll be the difference between generating embeddings and storing them in vectorDBs v\/s providing them directly to the LLM for question-answering? \n If data set has >4000 tokens you have to chunk it and store them in dbs and do QA by taking relevant chunks\u2026.if it\u2019s <4000 tokens you can directly ask LLM for QA. \n 4k is still high. One should consider prompt tokens and tokens to generate in the answer too. Else they are left with just 97 \n Akto.io just launched AktoGPT - https:\/\/www.akto.io\/blog\/aktogpt \n @ankush talks about things to watch out for before deploying GPT LLM in production - https:\/\/twitter.com\/Ankush12389\/status\/1646779395833741313 \n Folks I'm here as myself not a VC, but yes Akto is funded by Accel India so here is a disclaimer \n https:\/\/arxiv.org\/abs\/2303.01469 \n In the software world, we call it \"avoiding premature optimization\" \n Has anyone used LangChain with Azure endpoints instead of OpenAI  directly ? \n https:\/\/python.langchain.com\/en\/latest\/modules\/models\/llms\/integrations\/azure_openai_example.html \n Tried this? \n Yup I\u2019ve tried this  \n They have examples for custom LLM agents, not sure if that helps \n Using gpt-3.5 response as it is from Azure endpoint response and then customising it for use is a huge headache for me currently \ud83e\udd72 \n Prompt was simple \u201cTell me a joke\u201d nothing more \n This has happened before too \n https:\/\/colin-scott.github.io\/personal_website\/research\/interactive_latency.html \n wow \n latency for 2000 Bytes over commodity network went from 2000NS in year 2009 to 44 NS in 2020 . \ud83d\ude2e \n CTO of Stability AI is talking about Stability diffusion if anyone is interested  \n ChatGPT for Robotics \n Fire optics became more widely adopted over this time \ud83d\ude0a \n It's fun to see these numbers and trends as a way to understand industry directions and opportunities.  \n https:\/\/colab.research.google.com\/drive\/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing \n you have it in your name","43":"Awesome \ud83d\udc4f\ud83c\udffd \n Enjoy \ud83e\udee1 \n on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me. \n Has anyone here been able to get the latest controlnet v1-1 nightly release models working with inpainting? There is one controlnet model which is for inpainting, any inputs on how that would fit with multi controlnet? I got the models working with multi controlnet but have not been able to do so for inpainting yet. \n https:\/\/github.com\/karpathy\/randomfun\/blob\/master\/knn_vs_svm.ipynb \n Sounds very cool, must put into gooey \n You may check Haystack. It provides very easy abstraction. \n Would love to see some comparisons at production level scale \n This was about controlnet inpainting \n We are not at production level scale yet anways \ud83d\ude05 about 1% of dukaan probably \n Enterprise Document Search in Azure - MSFT recommends using Azure Cognitive Search with Azure OpenAI . I would be interested to know your thoughts . Azure Cognitive Search may be costly \n Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search \n Interested to know from the community of production level deloyments \n This is what we\u2019re live with. \n Thank you [PHONE REMOVED]  . Size of the DB = ? and your choice of Vector DB = ? \n twitter discussion for this https:\/\/twitter.com\/karpathy\/status\/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19 \n 10681 vectors and pinecone \n Thanks so much \n Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies. \n https:\/\/www.theverge.com\/2023\/4\/14\/23683084\/openai-gpt-5-rumors-training-sam-altman \n Yes, works great though when you don't have too many data refreshes\/updates. \n I have a friend called gpt 4. Fairly reasonably priced. \ud83d\ude0b \n immediately reminded me of spam detection PoCs :P \n True! I recently pushed a project thru the deadline and practically - copilot helped w a good chunk of front end code . GPT for all those complex Cloud formation templates . \n has anyone figured good ways to reduce time in getting output from an LLM? \n also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique? \n Introduced to this recently for a similar problem statement \n wow amazing. thanks a lot, been searching for 2-3 days \n https:\/\/twitter.com\/pratyush_r8\/status\/1647104801950552064 \n Interesting thought. I always thought bionic reading just highlights the first 2-3 characters of each word. \n I have a question and I think people here would be well suited to answer \n If projects like langchain are open-source, then why do they raise money? What are the economics here? \n Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition? \n Fowarded a thread I'm having elsewhere. Let me know if anyone has any understanding about this. \n Users and distribution. As a man once said, your monetisation techiniques are very different when you have 10K users vs 10M users \n Managed Services. Including enterprise. See dbt cloud for reference. \n Also people don't like writing code or reading docs. This is also the Fixie thesis \n OpenSUSE and RedHat open sourced their code. Still profitable by providing training and support \n Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies \n What\u2019s dbt cloud? Heard this from my investors too \n That'd be off topic. I love dbt too. Happy to talk more on DM \n I'd wager Llama Index should\/will raise too if they build a company around it \n Hosted cloud version - that\u2019s a great value prop Id pay for. Like mongodb \n It's a fantastic model. A wrapper around Foss. With a lot of successes \n Cal.com has turned that into a pretty decent content model as well \n Like elasticsearch went into AWS? \n Anyone here who has invested in such a business model before? \n Won't compare to AWS services, but more like mongodb, appsmith, vercel etc. \n Where you get hooked to the service by first using it on your instances, but as team\/complexity grows, you prefer to just use their hosted offerings \n Vercel and NextJS is a great example \n Gotcha \n Makes sense \n Yeah, and when you try using NextJS on AWS amplify, it had terrible build times (as per my last experience). We had no choice, but to use the Vercel hosting \n Is anyone familiar with AI for crime detection (loud noises etc) \n Redhat $1B \n https:\/\/twitter.com\/anoushkavaswani\/status\/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19 \n https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7053046289256632320 \n https:\/\/twitter.com\/foyerwork\/status\/1647282584907579393?s=20 \n AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https:\/\/aws.amazon.com\/codewhisperer\/ \n https:\/\/aws.amazon.com\/blogs\/machine-learning\/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity\/ \n https:\/\/blog.lucas-simon.com\/amazon-codewhisperer-vs-github-copilot#heading-final-thoughts","44":"Any sci-fi enthusiasts here ? \ud83d\ude03 \n Yeah it\u2019s great \n This is even better - it\u2019s also very timely because of AI \n https:\/\/www.gregegan.net\/MISC\/CRYSTAL\/Crystal.html \n Doesn\u2019t the Multivac sound eerily similar to today\u2019s LLMs \/Auto-GPT ? \n You ask a question ,it finds answers  \n Yeah lol, Asimov basically predicted AGI \n I guess Turing had already predicted it before him though \n Asimov did do that in many stories ,I\u2019ve read basically all of his books  \n Yeah agreed! \n The interface is similar, but I think the big difference is that LLMs are conceptually structured, but untethered from reality. That I think is the big difference between multivac and LLMs \n Like it understands conceptually that colors should cluster together, but doesn\u2019t really understand a color \n Multimodality will help a lot with that \n On the color front I just happened to come across this paper :)  \n Agreed they are largely conceptually structured \n Great share thanks \ud83d\ude4f\ud83c\udffd \n Like in the \u201clast question\u201d the question asked over eons is can entropy be reversed. The fact that it took sooo long to answer because it is such a difficult question based on its understanding of reality was amazing \n But thank you for bringing up Asimov\u2019s work, that man was my first brush with sci-fi and a genius \n It kept updating its understanding of reality  \n Glad to meet a fellow Asimov fan!  \n Cixin Liu is my all time favorite \n Draft Community Guidelines for this WA group. Will hopefully make it easier for you to decide for yourself what is off topic \ud83e\udd72 \n Very cool, curious was it generated using AutoGPT, it seems to have 1 numbering only but also working links. \n Get yourself an admin that defines community guidelines in git \ud83e\udec2 \n off-topic - orion's arm is a cool website for sci-fi enthusiasts. \n Sci-fi thats relevant to this group \n Huge fan here. Probably read Asimov, Clark and Heinlein all through college and masters. Kept me sane and got me excited about the future.  \n Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key? \n I figured that's cheaper than buying chatGPT plus \n https:\/\/www.chatbotui.com\/ \n And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit? \n Is this the one you are looking for? \n Seems so \n Thank you \n I mostly use plus because it lets me use GPT-4 with large context windows and that turns out to be cost efficient. Do consider that. \n Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great! \n https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb \n Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful. \n I love sci-fi, \n +1  \n https:\/\/www.databricks.com\/blog\/2023\/03\/20\/fine-tuning-large-language-models-hugging-face-and-deepspeed.html \n https:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm \n These are articles by Databrick on how they\u2019ve tuned the open source Dolly LLM for reference if anyone is interested  \n I am trying to use sentence transformers and OpenAI combined and making a Docker Image. Obviously the image is quite big [ > 4 GB ] , did anybody try deploying this type of thing to Kubernetes \/ AKS \/ EKS ? \n Doing it in a VM is ok and works fine. Interested to know the community viewpoints \n Anyone who has performed Model Distillation? \n I am curious - what\u2019s your use case?  Use different models based on inference request parameters\/tasks? \n Standard ones [ Q&A , Chatbot]. The reason I am using Sentence Transformers instead of OpenAI embeddings to save cost \n Oh I see, so using embeddings from ST to do information retrieval and then add the context into OpenAI prompt? \n Correct \n OpenAI embeddings are good but they would charge. Hence alternative ST , but con is image is huge \n In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ] \n May be deploying the model separately behind a service endpoint could be a way to go. That way you wont have to distribute the model in the application containers. \n Yes that's correct ; but the model itself is huge [ ST with all its fanfare Torch and \u2026 ] ; Are you suggesting deploying the Model in a VM and exposing as a service ? \n Yeah \n Thank you for your views \n I am just wondering how the community is thinking about using OpenAI for everything [ Embeddings and Chat Completion ]. My views are Embeddings can be done using ST and Hugging Face and reduce cost \n I agree. \n Have seen it start to work with 200 odd examples. OpenAI suggest 1000+ for accuracy.  \n Sorry I'm not sure i understand. Do you mean the image is large because of storing the vectors? \n Different than the OpenAI fine-tuning* \n I am using Sentence Transformers for Word Embedding. The ST has dependencies on Torch and NVIDIA libraries , hence the image is large \n Your standard flow is Embeddings + Chat Completion [ Very Himalaya level flow ] . For Embeddings to minimize cost using ST \n and Context \/ Chat Completion using OpenAI \/ Azure OpenAI \n It\u2019s not recommended to use fine tuning where you can get away with embeddings. \n How many GBs are we talking about? \n > 5GB \n One solution from one helpful community member is to convert ST into ONNX format \n and this would reduce the size \n Any other solutions \/ viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated \n I love this community . So very quick and helpful members \n wait, I thought finetuning means providing extra\/specific information to the model which it already doesn\u2019t know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong? \n https:\/\/stackoverflow.com\/questions\/63521958\/is-this-a-right-way-to-descrease-size-of-my-docker-images \n Harrison is really open about their strategy and sharing the plans.  \n https:\/\/medium.com\/@TheHaseebHassan\/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696 \n Nice article to convert ST into ONNX format \n Haha \n This is quite neat. I missed pinned messages for this! \n Fine tuning adjusts the weights of a model, with more training samples. Embedding are usually used for similarity search(among other things). \n calculating embeddings is a part of adding \u201cmore training samples\u201d, right? Or not necessarily\u2026? \n These things are orthogonal to each other. \n Are you talking about fine tuning the embedding model or something? \n These things are nuanced based on the context :) \n ah \n Think of it this way \n You can say embeddings is an LLM's mother tongue. It understands text by converting in into an embedding to understand the meaning and relation between words. Finetuning is giving the llm lot's of examples to learn a particular new skill or subject \n I used \"differentiate\" in a explanatory flavour \n https:\/\/twitter.com\/tree_industries\/status\/1647416130753945601?s=46 \n I imagine gpt3.5 and gpt4 embeddings will be much better for similarity search \n Anyway gpt3 embeddings are 1536 in length \n I see\u2026. \n just trying to understand, so if this \u201cintelligence\u201d depends on the models\u2019 weights, variance, etc which is obviously the case (basically upgrading from gpt3 to gpt4), there are ways to finetune, i.e., add more weights, etc. ourselves also? instead of waiting for a new release like gpt5? \n I so long thought finetuning just means giving it more documents (storing the embeddings in a db)\u2026 i didn\u2019t know there are ways to make the model smarter without burning huge computation powers \n Check this out https:\/\/huggingface.co\/spaces\/microsoft\/HuggingGPT \n Hmm ,think of embeddings as transformations (At very high level) \n ya I understood that\u2026 \n When you fine tune a model \n what is the \u201cprocess\u201d of \u2018finetuning\u2019 then if not generating and storing embeddings? \n Providing it with prompts? \n to use those embeddings more smartly? \n larger dof is not good for longer run, latency wise, too. \n Calling the api and updating the weights for your use cases. \n Weights being updated with example data \n Can I get a more comprehensive guide on how to \u2018update these weights\u2019 please? \n https:\/\/platform.openai.com\/docs\/guides\/fine-tuning \n Providing with example date like rightly said  \n There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver. \n Tweet about a paper \n Make sure if finetuning is really necessary for your usecase (computational costs involved) or if you can simply  use a external vector database like pinecone or weaviate instead. \n I had read a little bit of this when I was initially exploring, but never tried myself: ```question and answer pairs to additionally create adversarial questions and context pairs``` \n What do you people think of this? \n This is interesting but needs more finesse.  \n Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more \"precise\" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this? \n I think langchain's conversation memory types can be combined to optimise for your chunks \n https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/how_to_guides.html \n https:\/\/trib.al\/HIuiF1K \n Is it possible for a specialized piece of hardware (ASICs or FPGAs) to speed up the embedding search ? \n Hey [PHONE REMOVED] can we summarize the things going on here with GPT. It's getting really hard and time consuming to catch up with 50+ messages on WA. As more people are joining, the number of messages here is just exploding \ud83d\ude05 \n This guy is literally raising funds via his github repository \n https:\/\/github.com\/jdagdelen\/hyperDB \n someone said langchain will probably integrate this by end of the day \n it's a joke apparently \n yea it opens up that nyan cat youtube video \ud83d\ude04 \n I tried asking GPT for this. This is what it responded with. \n A smart summariser Bot for WhatsApp groups will be really helpful.  \n im very inspired by this. gonna launch my own database next week. have a killer name in mind. \n post by Vespa founder https:\/\/bergum.medium.com\/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5 \n IPython ChatGPT extension \n Neat, this can work with Google Colab in theory too \n or is it just ranking them and using the closest match to the input \n Good questions \n Would love to hear what people have to say \n Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks \n Not sure whqts happening in here though \n makes sense.. \n Anyone here who has worked extensively with these agents? \n There are few different things: \n [PHONE REMOVED] uses them almost daily to run his company and cribs about how broken they are \n If you do not like to use LLM for HTML parsing then this tool I found does a great job. But use it at arm distances because it is GPL3 licensed. \n not extensively yet but have the same experience. \n for now my plan is also to keep adding new tasks in classifier and seperating their workflow standalone \n There are strategies in langchain for this.. map_reduce, refine, ... \n Will read up on it. What's the umbrella term langchain uses for these? \n https:\/\/python.langchain.com\/en\/latest\/modules\/chains\/index_examples\/summarize.html \n memory chains or conversation memory \n those are different I think \n Summarisation sounds about right \n Memory is retrieval \n Sorry. You are right. It's summarization","45":"btw folks langchain discord has a \"ask-kapa-langchain\" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase. \n they also have integrated https:\/\/www.mendable.ai\/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat? \n yeah. the kapa langchain bot is discord based. when you ask a question, it generates the answer in a thread \n https:\/\/www.paradox.ai\/solutions\/recruiters \n Does this also have automated screening of resumes? \n https:\/\/www.skillate.com\/ \n https:\/\/leoforce.com\/ \n Gottit ,I was planning on building an automated screening in my company  \n How do you solve for this issue if automated screening is used? \n I abandoned working on the prototype all together because of these issues \ud83e\udd72 \n Sounds a lot like the SEO - google war \n It's perennial \n One party is trying to deliver the best results to its usere \n The other party is trying to hack around that delivery logic \n True. The other side of this spectrum is someone building a resume builder to job candidates so that the resume is maximally similar to JD \n Never ending arms race \n Yes, it's unethical. But if you won't use it, someone else probably will \n even today, recruiters don't do the first touch on resumes in big corps. \n Then the other side will start too :) \n There is also the matter of possible bias which the AI solutions might have. Which is difficult to solve for and a very sensitive issue. \n And then use chat GPT during the interview \n Boom \n Slightly off track but it reminds me of this dialogue from Batman Begins :) \n I\u2019m seeing many companies ask candidates to come in person to the office for interviews for this very reason \ud83d\ude02 \n The _\u201cactions\u201d_ settings say it can retrieve upto 500 rows, but I\u2019ve only been able to reach that limit for small, tokenised, chunked datas in each row \n anyone here who can share some basic dope on how some people are creating realistic music with AI? \n Check: \n thanks \u2705 \n so there's no elevenlabs like product yet - right? \n https:\/\/gooey.ai\/text2audio\/ \n Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it.  \n Summary of this in a thread here - https:\/\/twitter.com\/psurya1994\/status\/1647628166792372224?s=20 \n Sharing the original paper here as well for completeness. The talk, thread are based off this and paper has some amazing examples \n If you'd like to present a paper summary e.g. Reflexion, Sparks of AGI, Amazon's MM-CoT at the meetup this Saturday, happy to help you outline and prepare. Please DM me soon! \n BLR Generative April meetup:  \n Here is one about review of fine tuning techniques  https:\/\/arxiv.org\/abs\/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning. \n Are we also calling model distillation as fine-tuning now? I see them both being used interchangeably on interwebs \n Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https:\/\/bit.ly\/lsip-dataverse-ep4 \n https:\/\/www.indiatoday.in\/technology\/news\/story\/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12 \n This seems to be GPT-3.5 \n Someone tested using GPT-4 and they reported 21\/108 questions being solved by GPT-4  \n Also IMO these tests are very misleading ,it\u2019s performance on zero shot prompting of JEE questions would obviously be poor  \n Present LLMs fake understanding \n Plus we don\u2019t really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores \n Isn't having access to a Wolfram plugin basically cheating? \n It is sort of consistent with the fact that it cannot do complex math. For now. Physics and chemistry it can reproduce well with decent reasoning \n I\u2019m 100% sure the ones reporting failure of GPT on JEE would be copy pasting questions in ChatGPT \n \"Significant gains are visible in the accuracy of the GPT4 model, in decreasing order of Chemistry(\u272836%\u2728), Physics(14%), and Maths(3%) over ChatGPT on our challenge set\" thread says \n I\u2019m curious to see the performance with Wolfram access + textbook content retrieval. Even though it\u2019s kinda like cheating, considering the complexity of JEE it\u2019s still impressive if it can solve with content retrieval and tools access as well \n Also we're forgetting the value of negative marking \n Exactly, these people just post results with some general prompting and then give a wrong impression \n Not sure how else to train a LLM to solve complex math  \n Also perhaps there is some value in prompting it to skip math more than chem and physics \n Since it's dumber at maths \n +1 on this  \n In Zero shot prompting you\u2019re just posting a question and taking at face value the first answer GPT provides \n Someone can experiment autogpt with jee and see where it leads \n Will be still useless with math I am guessing \n And also many low hanging fruit problems in JEE are repeat questions with slightly different values \n Also I'm sure GPT finishes the entire test in like 5 to 10 minutes \n And also sequential questions. Where one question's answer leads to the context of next one. I'm sure whoever implemented this experiment did not take into account the previous questions context and prompted GPT to answer it in isolation.  \n Anyone wants to join hands and work on this with me? \n Sure! \n Also had another idea if anyone is up to collab: https:\/\/replit.com\/bounties\/@JosephJacks\/llm-ify-any-app \n It still can't do math calculations, that must have been main reason why it failed brutally. I think it must have scored great in reasoning questions. \n Making a group \n Anyone else? \n A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider \n actually interesting idea, I could give this a try\u2026 \n Clip it up \n Not going to help 100% of the time but that is indeed very valuable context \n I doubt clip would be effective with academic diagrams, worth a shot but i'm skeptical \n Let's see \n If it isn't then we'll just prompt it to be a little hesitant in answering diagram based questions \n CLIP + some OCR logic + some prompting on top of that maybe idk \n Can probably glue up something like Amazon's MM-CoT and see if that helps with diagrams and figures? cc [PHONE REMOVED] \n I'm sure folks in this group can do much better than what these guys did \n I've already made a group with [PHONE REMOVED] \n We'll crack it soon! \n Happy to have more folks on board \n OCR is definitely required \n Flip your work to FOSS and post weekly updates :) \n are we opening a fiitjee for llms now :p \n If you start fine tuning it then definitely it\u2019s FIITJEE \n overFIITJEE \n After all aren\u2019t students \u201cfine tuned\u201d for cracking JEE ? \ud83d\ude1d \n We can also skip image related questions in first try? and see how it performs on questions with no images. \n I am already in process of writing a paper on this. Should be up on arxiv by this weekend \n Problem: \n Working on similar problem statement currently  \n Should we spin off a separate group for speculative fiction enthusiasts? \n You can create a separate prompt for determining the question type. In the prompt you can keep the three options in MCQ format at the end of the prompt so you can easily parse the output. Keep this prompt at the very beginning before the retrieval part \n Already exists: https:\/\/chat.whatsapp.com\/GuJCOKL4nVHH3szN1d8TRV \n Thank you! \n I agree we need better terms. Not sure what to call soft-prompting. It's not distillation. Customer don't want to use OpenAI + only davinci knows enough context to generate valid outputs but still needs fine tuning on data not publicly available. But they are insanely expensive to serve ($.12\/1k token, that's 10Rs per output). \n So we are in this world of fine tuning local models. To be able to serve\/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci. \n Btw did anyone try to ask chat GPT4 to solve ie Itodov? \n Imo atleast for the physics part for waves i did try. Let me know if anyone is able to try with questions of IE Irodov \ud83d\ude05 \n Models like MatCha or DePlot are trying to answer based on diagrams. https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/matcha , https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/deplot \n for diagrams, there's Google's Pix2Struct. trained on 9 tasks. links: \n Vicuna-7B runs in Chrome Canary on M2 Macs with WebGPU \n Super exciting direction because this means we can have LLMs which are private to _user_, not just _organisation_ \n Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today \n Giving me Blade runner 2049\/Her vibes. \n _Apple silently beefing up their little ml cores inside iphones_ \n We already have that at a very small scale, your phone keyboard is personalised \n Fun fact: Person behind WebLLMs also developed XGBoost, TVM and MXNet \n yup. google did some very impressive stuff for on-device ML for Assistant and Gboard apps, a few years back. \n Before my current product, I wanted to build an AI-enabled analytics product. Some thoughts on this: \n Talk about a boss-mode Github \n Goat \n Fine-tuning davinci doesn't really work is what I have heard \n Prompt engineering davinci is almost always better than fine-tuning it \n For those not familiar with naming conventions:  \n The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis.  \n Can I get access? Trying to integrate something similar for our data warehouses \n DMing \n https:\/\/www.together.xyz\/blog\/redpajama \n who's picking all these names \ud83d\ude02 \n An Indian employee of huggingface worked on this and published it \n During my research days I came across this dataset called LOL dataset \n It was a dataset of low light pictures and their well-lit versions \n I think I even used it in my papers and cited it \n Ohh I know this one: paperswithcode.com\/dataset\/lol \n Yes exactly that! \n It was the wild West in 2017  \n How could anyone compare their claims to these unreproducable publications \n Paperwithcode.com was quite helpful to compare my research with others \n Haha lol yes. I remember those days. I spent months trying to make a sota model work for our data, then failed to reproduce then rebuilt with some more data then fine tune and rebuild and so on. Eventually I realised their sota was reproducible but nothing else worked. \n PSA: Please inform whosoever you're sharing the invite link with that this group is a firehose and somewhat technical in it's spirit.  \n but the lora paper didn't have any indian author \n LoRA is from MSFT, that blog is from Huggingface DevRel \u2014 which has a couple of Indian origin folks in Europe \n yes \n You exactly know my pain \ud83e\udec2 \n Were you working for a research group back then? Or was this an industrial task? \n [PHONE REMOVED] \n Oh my bad \n Huggingface built a wrapper around multiple finetuning methods, called it PEFT: https:\/\/github.com\/huggingface\/peft \n for my startup \ud83d\ude42 Bewgle. \n My salutations \n Can't help but admire any founder ready to roll their sleeves up and get their hands dirty in some R&D \n https:\/\/twitter.com\/NathanLands\/status\/1647864974323204096 \n Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad \ud83d\ude1e.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4. \n Just ask each of them - \"What is Bengaluru? Be concise\" and see all of them spectacularly fail. \ud83d\ude2b \n So Magi is Bards sister? \/ is this a rebrand because of all the bad press from the bard launch? \n Not PaLM? \n Is it PaLM? not sure. \n it's Google. multiple launches, rebranding of the same product is their forte \ud83d\ude02 \n We build some models and ensemble some others. Our use case is deliberately narrow- we don\u2019t need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn\u2019t behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn\u2019t. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment. \n [PHONE REMOVED] \n LLM Components to decide and weigh memory in Langchain, from the Generative Agents paper. Implements 2 agents talking to each other as well.  \n i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem? \n especially in this case related to generative AI \n Has any of you worked with LLMs for math problem solving, or used chain-of-reason prompting? We're delving into the problem solving use case and would love to discuss if you have. \n A good starting point: \n Grab hold of a prof. Or.. Enterprise researchers can help if you intern with them. \n Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc. \n github.com\/shreyar\/guardrails might be useful here, uses LLMs to give structured outputs including JSON, Python objects, XML and DSL like outputs should be possible too \n Something something PCA Nishant \n *Nirant \n We caught you using old dimensionality reduction techniques \ud83d\udc40 \n [PHONE REMOVED] : delt game moderate","46":"Adept.ai got copied as an in the OpenAI Plugin Store, called Multi-on \n We will need people who have the following experience: \n Meeting invite? \n 1. cc [PHONE REMOVED] has worked with CLIP, BLIP-2 and VQA \n As mentioned in the screenshot \u2014 Please find the group from Community in WhatsApp, Apply to Join, meeting link will be shared there :) \n What are you trying to build? \n [PHONE REMOVED] ajao sir, sending you the whatsapp invite directly \n 4. Multimodal vector similarity search - we're going to index image and text embeddings of useful information. Will definitely need someone with solid experience here. \n https:\/\/github.com\/marqo-ai\/marqo - probably can take a look at this db \n *vectordb \n I'm a bit oldschool here and prefer to stick with elasticsearch \ud83d\ude02 \n Is it tough to setup and maintain? yes, but I have production level experience of doing that so it's fine i guess \n Should I bring an all-purpose AK47 to a knife fight and mention FAISS \ud83d\ude05 \n Additionally, all kinds of financial help in terms of openAI credits, GPU credits are welcome with huge open arms.  \n I'm in. I have curated a tagged dataset of a large number of JEE-styled questions that can be used for training. \n Go ahead, I'll bite \ud83d\ude48 \n Lot of the modern DL infra is built around FAISS: Haystack (Deepset), Milvus, txtai. Even Langchain launched with FAISS. \n makes complete sense \n Maybe we can just train a KNN model and save its artifact locally so people can run it locally too \n Karpathy baba's SVM approach also makes complete sense in this usecase \n Keep going down the path of Baba Karpathy, and soon you'll find yourself in a Random Forest with Boosted Trees. There my friend, I first saw wisdom. \n Are you saying that Baba Karpathy is the Yoda of the machine learning world? \n So Karpathy (w\/ Fei Fei Li and others) was the one who demonstrated the LSTM+CNN Image Captioning Model in his PhD Thesis. He was also the one who introduced the idea of using model weights projected as an _attention_ map to debug models. This was a precursor to _Attention_ in the philosophical sense.  \n Truly a pioneer \n found this in the eval PRs \n https:\/\/yaofu.notion.site\/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 \n Are there folks in this group interested in working on these problems?  \n Me - Problems I like \n Interested  \n 3) Is something I've bee thinking about for a few years - How do you reduce unknown unknowns \n Also - https:\/\/www.together.xyz\/blog\/redpajama \n I\u2019m interested as well.  \n what does the \u201cpersonal search\u201d problem statement mean? \n Been working on personal search. Will keep you guys posted. \n rewind.ai \n I'm interested in the multimodal AI project. \n DM me if you find mistakes. \n interesting\u2026this must be really memory-heavy? \n The multi-modal AI project finds a direct correlation to what I work on currently. I would love to explore Generative AI to solve problems and build systems which are multi-modal. \n My key takeaway from skimming this paper was the iterative prompting.  \n Interested as well \n Interested in how to do domain specific feedback loop and fine-tuning.  \n +1 Interested in this too [PHONE REMOVED] \n +1 to domain specific feedback and fine-tuning \n What do you all mean by domain specific feedback? RLHF? \n Check out character.ai. They are doing something similar. \n Nice! Any comparison for open source LLMs? \n Interested \n Folks, please share ideas which you can contribute\/implement to indicate interest. Or even better, share any relevant code\/paper which you've seen on the topic :) \n Yes RLHF from the domain experts and internal team users.  \n Helpful list of directions \n are you planning to talk to Anton? \n Augmented reality Pokedex caught my eye. \n There is a openai model to convert image\/text to 3D model I have seen: github.com\/openai\/point-e \n Yes there seems to be a project on this  \n Segment Anything Model was used to create an object mask from image \n Demo for anyone interested  \n https:\/\/t.co\/sVSHuljpwe \n Might DM, but this program is US or US remote. Wbu? \n Anyone else facing issues with huggingface endpoints rn? \n Both Gh and hf are facing issues. \n personal search related: https:\/\/github.com\/KnowledgeCanvas\/knowledge \n interested. working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data. \n These are some really interesting directions. \n Clashes with this meetup \n Removing the previous message since we discourage self promotion and the person hasn't replied to a personal ping, has no name on WA, nor an active contributor here \n That is amazing! BLR should've more gatherings, hackathons for people to choose from! \n Very good read \n https:\/\/www.wired.com\/story\/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over\/ \n Title is a bit misleading though. The point is that models will become better, but not by adding more base training data \n Better chance of playing catchup for startups :) \n Especially comes after together  said that their model will be 1.3 trillion params \n Quick question for folks who are using LLMs in production(guessing there would be many in the group) \n One account with multiple keys - easier to consolidate and have conversations with OpenAI team on priority access. \n we use AzureOpenAI, so tracking is pretty easy over there. \n I'm also doing this fwiw \n btw do Azure Credits work for Azure OpenAI? \n cc Ankita [PHONE REMOVED] works for Azure India, can you please folks and confirm here? \n Can you track dev and prod on the same keys though? I didn\u2019t know that functionality was there \n Our OpenAI access   is on a subscription level , so if you have credits on that subscription, absolutely will work \n probably create different resources for prod and dev? haven't tried it though. \n Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product \ud83d\ude05 \n 1 strike next week* \n You can always ask someone else to post, including me sir! \ud83d\ude4f\ud83c\udffc \n Haha yea! Have to book some time with you anyway \n count me in as an early user \n [PHONE REMOVED] I heard there\u2019s a meet up this sat. Where can I find details about this and how do I register? \n https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ \n has anyone worked with context based search with cohere embeddings and openai gpt3.5 for non-english languages? how good it is in terms of results? \n Has anyone worked here with map_rerank chain types in LangChain? Would like to know of there is away to return the document metadata for sources alongside the QA responses \n map_reduce and refine both have this already. map_rerank should too? \n Worked with OpenAI. Good for some languages (eg Spanish) not good for others (Czech) based on feedback from our users \n Haven\u2019t seen a good resource on what languages are good VS bad. Presume it\u2019s based on amount of training data on the open web \n I am trying with Arabic but it just says hmm. I am not sure \ud83e\udd72 \n I think you're right, I need to explicitly define which keys I want in the chain response, let me give it a try \n Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: \u062f\u0627\u0626\u0645\u0627 \u0627\u0644\u0631\u062f \u0628\u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \n Hey everyone, please welcome [PHONE REMOVED]. My old roommate. He's from CMI in case anyone from CMI is here. 15+ yrs in tech. 8+ yrs in fintech space , currently building AI solutions for real estate sector in India\/Middle East\/ North America\/ Australia. \n I just said, replay in context's language.. but let me be specific. \n thanks! \n I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another. \n In the right place and product, this reply is worth hundreds of dollars! \n Is there any cheaper and lower latency way to detect language? Especially in audio \n Open-source knowledge sir \ud83d\ude4f\ud83c\udffb \n In text we do this.https:\/\/github.com\/Mimino666\/langdetect \n But audio is a bit more difficult \n Not worked in audio. \n exactly what I started using.. by specifying the language it works for a generic question \n https:\/\/www.youtube.com\/watch?v=30xueN12guw \n How easy\/complex was this language detection\/translation? \n And did it introduce some latency? \n [PHONE REMOVED] check this. If API based solution then it will add latency for sure. \n Of the top of my head - Cut out a very short snippet of the audio, then use something like deepgram or whisper? \n smaller the file, lower the latency is my guess.. but haven't tried it \n Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation \n One issue is translation depends on context too, so chunks can\u2019t be super small \n So you can split on gaps in amplitude. With a rule like 5 gaps in one chunk \n This might actually make for a good cost reduction (compromising latency though) use case as well. Read the amplitude and omit parts of the audio where no sound was detected and then translate\/transcribe \n Yeah that's pretty common in audio pre processing. \n Interesting.. didn\u2019t know that \n Same for text too. we remove white spaces and new lines to save for tokens in document chunks.  \n Hey Everyone, \n Props for asking a well-formed question! \ud83d\udc4f \n Can you please create a poll for this? \n I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses  \n Let me zoom out a bit: I'm personally convinced that there is sincere interest. For a working group to happen, the bottleneck isn't buyer, reader or user interest \u2014 but builder\/experimenter effort. \n I\u2019m looking to slice audio too. What would folks recommend with Python? I know pydub is popular but I saw it requires an external package \n pydub is fine \n hey, can you post an example input image? on which you're trying to do this task. \n Nice! Share more? or DM \n Happy to chat. Have build\/deployed something like this before but not with LLM. \n I think someone had asked on Text to Video, do check this \n quick thoughts \n [PHONE REMOVED] might have some good ideas \n Just read your last point - have you thought of asking the user to select the best mask? Simple product problem vs complex AI pipeline \n could work depending on your product! \n Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more \n Not GenerativeAI tbh, but pretty neat offering: https:\/\/www.causal.app\/ \n https:\/\/github.com\/OpenBB-finance\/OpenBBTerminal\/releases\/tag\/v3.0.0rc2 \n Open Source Bloomberg GPT \n OpenBB is pure terminal play, right? \n I don't recall them doing a LLM, and if yes, what data and arch are they building on? \n Yup I\u2019d thought the same based on their site  \n Yeah, pure terminal play, i think they get direct market data, earnings calls, and reports \n Making videos via SD. This guy's last couple of reels are very good : https:\/\/www.instagram.com\/reel\/Cq5eWq4rRQC\/?utm_source=ig_web_copy_link \n Have you tried using the latest control net models for intruct pix2pix (https:\/\/github.com\/lllyasviel\/ControlNet-v1-1-nightly#controlnet-11-instruct-pix2pix)  \n Discovered by [PHONE REMOVED] \n [PHONE REMOVED] have you come across any img2img models where I can generate variations of UI elements.  \n a very limited version of this used to be logojoy.com \n Pretty cool that its open https:\/\/huggingface.co\/liuhaotian\/LLaVA-13b-delta-v0 \n This is nice. I've played with Midjourney for logo creation and it was pretty good.  \n Can you explain what you mean by you have existing designs? Is it some type of sketch? Also can you elaborate on \u201csegment various attributes of UI elements \u201c  \n Try this gradio space if you already have a sketch. https:\/\/huggingface.co\/spaces\/hysts\/ControlNet \n My understanding is that the maximum amount of control right now comes from control net models. Given that multiple controllers can be clubbed together and img2img and inpainting is also supported, with even huggingface launching a control net sprint , we will get a lot of community controlnets which can be used. T2I adapters is another approach but controlnet has community momentum with it. \n Noob here, but would Controlnet (https:\/\/github.com\/lllyasviel\/ControlNet) be useful?","47":"Existing designs - I've used some UI elements from the Koo app and tried dreamstudio.  \n Cool. Use the gradio space I shared. It would be a good starting point. You can also try playgroundai.com and see if that can help you \n Thanks a lot [PHONE REMOVED] \n Hi, \n For readers, Shapiro Wilk is a measure of whether the data is normally distributed or not. https:\/\/en.wikipedia.org\/wiki\/Shapiro%E2%80%93Wilk_test \n In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset \u2014 sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption.  \n Thanks for your input. Do you have any suggestions for methods I can use with a non normal dataset. \n This was my thought too. This just violates some assumptions for linear regression variants, you can consider 1. other regression algorithms like tree based ones, or 2. See if the target can be transformed via a sensible function to close to normal distribution. \n 2. *and then apply liner regression family \n Can you elaborate what you mean by confined? And really bad for what exactly? \n Also, can you plot it somehow? \n I tried using support vector regression and experimented with non linear kernels, the results remained the same. Will try tree based methods as well. \n Also, really sorry if I am making some stupid remarks\/comments about the data. I have not worked a lot with tabular data, and I am just a beginner in Machine Learning. \n This is not some sort of time series data? \n No it\u2019s not a time series data \n It's not a function in the traditional sense. It could the case that y = some_prob_distribution(x). Ex. Y = normal_distributed(mean =x) \n Hey Guys, thanks a lot for suggestions on this.  \n Try jadoosnap.com \n Wanted to give users of I\u2019m feeling lucky option :) Though a nice suggestion if they want total control! \n how did you blend the images? only if you want to share or is it a completely different approach? \n Yeah man curious to know! Results look quite nice! \n I actually did this exact approach.. researched online on how to blend.. saw adobe firefly results.. and dropped it \ud83e\udd72 \n Two cents \n DM me brother \n For the first part no my data isn\u2019t categorical.  \n Would be great if we could get prettier backgrounds! Thanks already! \n Along with SD 1.5 inpainting ckpt \n And this was with minimal effort on the prompting end, so results may get better with better prompting. \n Have you tried to use any inpainting models? They are opensource by runwayml. The one shared above by Abhishek.  \n Folks hoping all of you have seen launch of Open Assistant - https:\/\/open-assistant.io\/ - opensourced alternative to ChatGPT by the LAION-AI initiative. \n I have seen this image somewhere. Is this a product of any startup? \n The image is from my startups website. The \u201c product\u201d is from a Instagram image of this company which sells candles. I just dropped out the hands, matchbox and light of the matchstick and incorporated into other image which I then used as base for controlnet inpainting. \n do you have a website to check it out more? \n https:\/\/github.com\/geekyutao\/Inpaint-Anything maybe this can work for you \n Thanks for the suggestions. I did use normal checkpoints with a basic prompt to see if they are understanding physical structure. I\u2019m attaching one of the result where I gave the prompt \u201cadd dining table in background\u201d.   \n if your data is not normally distributed then you can use Extreme Value Theory tools. See Hill Estimator for instance, but there are others \n Just curious to understand - \n fwiw, in my experience trusting things which are made up is more common with my parent's age cohorts than urban, educated teenagers who seem to be skeptics by design \n Yeah, they are curious but how about keeping things age appropriate for them? \n Thank you \ud83d\ude4f \n cc [PHONE REMOVED] works on making the Google Play Store safe for kids and minors. Would love to hear more product design, generic principles from you \ud83d\ude4f\ud83c\udffc \n Since these interfaces will have image (search, generation) soon, there has been academic interest in detecting _sexy_ images as well. These are suggestive, but not porn or nudity. The line gets blurred even more with comics\/anime\/hentai. \n Speaking purely in individual capacity  \n We've been using this to ensure all questions are safe for works. Works decently well and is a requirement from companies \n This will be super interesting as I do not know of any specific regulation yet.... \n Sure, will look into that as well. \n Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it? \n ouch \n Hi! I need one help. \n Fine tune vicuna on your WhatsApp chats \n index n retrive from vectorDB could be a easy quick start \n fine-tuning is not to save info . Its to teach a skill to the LLM \n Do you think dependence on these for home work affect reasoning abilities in kids? \n I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs.  \n Yes, in my view \n yes. you just retrive the relavant context with cosine similarity , and simply feed it into the prompt. with character limit . it should work well . with some prompt engineering + if you using GPT4 put in the system message  to impersonate you based on the context provide. LLM chains \n Do you think dependency on Google Search and Saved contacts affect our memory skills? \n These are memory recall skills aren\u2019t they ? \n hey guy quick intro i'm Akash , we are building a embedding engine specifically for code syntax.  also anyone here worked with Siamese search stuff ? \n Parents I guess would be more concerned with reasoning skills being affected coz of using GPT \n Thank you Edgar and Akash! I will check these out! \n Our parents were worried about memory and we seem to be doing okay without them \ud83d\ude1b \n https:\/\/twitter.com\/hwchase17\/status\/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19 \n cue the pessimists_archive twitter handle \ud83d\ude02 \n \ud83e\udd23\ud83e\udd23\ud83e\udd23 \n Heard it from Altman in the Lex friedman interview that he repeatedly says in the company to treats it's users like adults \n cc [PHONE REMOVED] for questions on QA evaluation and fact checking \u2014 since you worked on that problem \n I did. Curious how you are thinking of applying it. \n GPT4 8k and 32k versions are now available on Azure Openai India as well. \n https:\/\/twitter.com\/varunshenoy_\/status\/1648374949537775616?s=52 \n You could additionally change the object's position and use SD Inpainting, which gives more variation results. [PHONE REMOVED] has mentioned those in details section of his product here - https:\/\/gooey.ai\/product-photo-background-generator\/ \n anyone here using promptlayer or other tools for prompt versioning?  \n Want to use a tool badly - is this good? \n Humanloop does A\/B testing+versioning of prompts as well \n https:\/\/www.izzy.co\/blogs\/robo-boys.html \n haven't used it yet. but they integrate with langchain too. \n btw [PHONE REMOVED] is also working on this! \n thanks! Yes, I'm going to announce this soon.. we have a few companies in beta right now so happy to help if someone wants a tool that works out of the box \n \ud83d\udc4d joined the waitlist \n https:\/\/www.databricks.com\/blog\/2023\/04\/18\/introducing-ai-functions-integrating-large-language-models-databricks-sql.html \n interesting attempt at structuring prompts better. guardrail:XML, this:SQL \n There should be some way to get nudged about cost incurred when running these via LLM calls lol \n https:\/\/python.langchain.com\/en\/latest\/modules\/models\/llms\/examples\/token_usage_tracking.html \n Appreciate the guardrails shoutout! \n Folks, I have a request.  \n *\/imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections. \n Friends, Nilesh [PHONE REMOVED] is an engineer-turned-journalist covering Generative AI in India and it's impact on jobs and business \n You can try openjourney if it's urgent \n https:\/\/cdn.discordapp.com\/attachments\/1059408411890028584\/1098182375965478963\/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png \n TIL Discord CDN has no auth! \n trying out the chatgpt-retrieval plugin.  \n It's an embedded image right? \n just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too \n full disclosure: trying to sign qdrant as consulting client \n Yeah, using SQL lets me do embed ontology a little better, saves me a bit of time doing prompt engineering with vectordbs, but I have a theory about where all this is going to end up \n RDF2text2vector \n Literally no solution out there allows me to embed both taxonomy and ontology in my text right now, so my workflow is to put both of them in the text first before embedding. \n Hopefully someone comes up with RDF2vector directly \n my dataset has 7.5k rows\u2026shouldn\u2019t be a constraint right? \n Weaviate even had an issue in gh for RDF2vec, but it closed due to lack of interest \n Less than a million rows should be fine. qdrant CTO told me that they can do entire Wiki with inference usage of ~1.2G RAM \ud83d\ude27 \n This sounds insane. Wiki text is around 80gb I think. \n (not sure that's just English though) \n English Wikipedia is the claim \n Thank you, Shashank. \n what is the challenge with saving embeddings in a vector variable \n In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU \u2014 or FAISS \n @here getting really disappointing result when cloning my voice on elevenlabs, any other tool\/saas suggestions? \n Checkout out VALL-E's unofficial PyTorch implementation  on GitHub. Facing similar issues with ElevenLabs \n Is there a way to use np.array for the chatgpt\/retrieval-plugin? Didn\u2019t find it in the documentation \n azure tts has a neural voice cloning service i think. haven't used it tho. i only used their presets. \n also Descript has cloning too \n is anyone working on AI financial advisors? change the incentive model.  \n Chroma has a decent local db support, could start with that as well \n Simple local dev interface to get started with \n How to use these custom dbs in chatgpt\/retrieval-plugin?? \n also, it\u2019s entirely open source. I like knowing the hood, helps to extend, debug and hack around. They will come up with their hosted solution soon \n under the* \n Not sure, haven\u2019t checked out the retrieval plugin repo in depth. It kinda looked like a mess when I saw it first lol \n Probably others could help here \n Has anyone retrained an open source transformer like llama? Mostly content creators are going gung ho around architectures like few shot learning\/vector similarity \n okay, I checked it out. You could check out this PR branch https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59 and get started with Chroma \n Did you use it ? Issue with eleven labs is it doesn\u2019t have Indian accent, it works well on American accent \n I mean does vall-e not have same issue \n I opened an issue: https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59#issuecomment-1514694410 \n I haven't tried it myself, but will patch you in with some folks :) \n Sharing what I wrote today -  \n Has anyone evaluated - DeepSpeed - https:\/\/www.deepspeed.ai\/ ? \n Deepspeed powers Bloom and LoRA from MSFT \u2014 so many people might've tried it without knowing \n *tried the output model \n Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are\/were better than Google \n Has anyone felt\/realized this anecdotally? \n thanks, that\u2019d be v helpful \n qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now \ud83d\ude05 \n If someone asks to choose b\/w Redis and Qdrant, what would be your recommendation? \n Does a pod correspond to a pinecone index?  \n Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way \n DevEx is the key - long Redis \n https:\/\/github.com\/Stability-AI\/StableLM \n Awesome !!! \ud83e\udd29 \n I wanted to know about how the different language models out there today are different. \n It\u2019s already 20th April in some parts of the world so\u2026 \ud83d\ude05 \n Any benchmark studies on how it's faring compared to existing models? \n \u201cAs is typical for any pretrained Large Language Model without additional finetuning and reinforcement learning, the responses a user gets might be of varying quality and might potentially include offensive language and views. This is expected to be improved with scale, better data, community feedback, and optimisation.\u201d \n Have anyone used Weaviate?  \n Also, wrt to embedding models, has anyone here done considerable research on which model is better? Ada from openAI is good, but how different is it from sentence transformers from HuggingFace? \n Haha... I thought so but then the founding team mostly isn't based out of those areas \n It\u2019s always 4\/20 somewhere \ud83d\udc81\u200d\u2642\ufe0f \n Haven't come across any benchmarks or anecdotal reviews \n i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet. \n Not sure how many folks have tried the new Bedrock product by AWS but curious if folks think some of it and the aspects of model benchmarks potentially move to AWS \n Any idea where I can find it? \n For indian languages cohere multilingual embeddings are having good discrimination based on my experiments. \n https:\/\/twitter.com\/Nils_Reimers\/status\/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19 \n https:\/\/twitter.com\/jerryjliu0\/status\/1648709029777252352?s=46&t=gjIVQMn9Hp7sUgYs_m23Ww \n [PHONE REMOVED] - again contributing with Evalset generator \n Thank-you for the mention Arpan.","48":"Thanks for the mention ravi! \u2764\ufe0f \n sorry I must have missed. Where is the meet-up ? \n BLR, Saturday evening: https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ \n https:\/\/blog.replit.com\/llm-training A good blog post by Replit where they give us high-level description of how they train their own LLMs \n What's amazing is that the team is <5 people :) \n Replit is < 5 people??? \n The ML team \n Wow \u2764\ufe0f \n The entire engineering team ~50 people \n Talent density >> head count \u2764\ufe0f\ud83d\udd25 \n https:\/\/twitter.com\/fabianstelzer\/status\/1648700767992180737?s=48 \n EyeQuant founder talks about text2film \n Proven again and again in the world of Foundational Models - almost all top companies have lean teams \n Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors \n midjourney outsourced frontend to discord \ud83d\ude02 \n https:\/\/simonwillison.net\/2022\/Sep\/17\/prompt-injection-more-ai\/ \n Cracked crazy adoption \n Original song by Ariana Grande: https:\/\/www.youtube.com\/watch?v=DOJremEQw88 \n What tech is used for this? \n Are you tracking usage on a per-api key basis? Is this even possible? \n OpenAI tracks usage per organisation basis, one way to work through this might be setting up different teams for different keys \n I came across https:\/\/twitter.com\/vboykis\/status\/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19 \n Someone had a very good analogy on this : \n just org \/ no tracking per key possible.  \n Well said \n Tried this last night. Controlnet inpaint model isn\u2019t much better than the regular sd inpaint. The advantage though is that you dont need a custom inpainting checkpoint, so you can inpaint with community models like analog diffusion, openjourney, protogen etc or maybe even a lora model? \n This is the comment by the author of the controlnet repo: \" \n Thanks. I used diffusers lib with the hugginface checkpoint so yes probably not as good as a1111. The inpainting code in general has always been super well done in a1111, really amazing stuff! What\u2019s the status of a1111\u2019s python api these days? \n I haven't worked with the API yet. So wouldn't know. Also the diffusers library isn't upToDate with the latest release. This is because the repo author is working on integrating it with automatic1111 first. \n What resolution is this? \n 768x512 \n The glass seems to have been modified a bit? \n yeah. I didn't mask correctly. I am testing other aspects of the controlnet. \n Keep us posted :-) \n cc [PHONE REMOVED] since you opened this thread \n The best way to insert an external object like a glass into another image is to just overlay it in another layer using photoshop or free web based photopea. Export as a single image (img1). Also export an image in the same dimensions but with only the glass and the rest of the background black (img2). Then inpaint over and around the glass in img1. Load img2 into controlnet. Use canny, depth, hed maps or a combo of these based on the kind of object. Adjust the controlnet weight appropriately. Also adjust the weight of the right word in the prompt like (glass:1.2). \n Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny \/ depth \/ hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image. \n This is awesome [PHONE REMOVED] Thanks a lot for this. I'll update once I have setup Automatic UI. \n How hard to push per key API results to Prometheus? From there use any UI tool like grafana to monitor per API usages. \n Is anyone using GPT4 in prod? I'm sending gpt-4 as the model but its still using gpt-4-0314. Have heard gpt-4 is much more faster than the 0314 \n Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR. \n Which LLM\u2019s? Pix2instruct? Or any other LLM? \n say GPT-4? I know the multi-modal functionality is not rolled out yet but curious of  Visual Document Q&A is an application since you can ask it questions about images. \n I was just checking out this repo: https:\/\/github.com\/clovaai\/donut \n Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments \n Doesn\u2019t use OCR \n I've tried it, hard to fine tune to your use case and get consistent results \n Ya tesseract is great. I\u2019m coming from the perspective of one model to rule them all. It\u2019s clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS\/GCP API \n In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https:\/\/huggingface.co\/microsoft\/layoutlmv3-base \n [PHONE REMOVED] pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing \n I see. Since they are taking in images, I was thinking there might be some ocr involved \n Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse? \n Today, or in future?  \n Got it, thanks. \n Future changes everyday nowadays \ud83d\ude05 \n Sounds reasonable. Additionally, can I audit the requests made to each api key? \n Labels can be used to pass API key hash or user friendly name (do not pass exact API key :)) \n I tried using MM-REACT using hugging face space provided by them. It works much better than Donut. The work uses Reasoning capabilities of LLMs to extract information from visually rich documents \n https:\/\/github.com\/microsoft\/MM-REACT \n https:\/\/github.com\/Layout-Parser\/layout-parser \n last time i checked, langchain had a layout-parser integration for pdfs \n https:\/\/blog.eleuther.ai\/transformer-math\/?s=08 \n Optimised implementation for Whisper, faster than real time \ud83d\ude80 \n Sanchit is absolutely killing it \n Sahi! Anyone know the costs? \n Has anyone tried fine tuning dolly2 yet? \n It is open source  \n [PHONE REMOVED] This was so-vits-svc \n What tools or best practices you guys use for recording LLM experiments (for example, with what change of parameters, how much reasoning\/relevancy of retrieved results increased along with tracking metrics like accuracy\/precision improvements, finding difficulty in managing ways to look through various Jupyter notebooks etc? W&B is a familiar tool, but want to capture and know the Gist of all the experiments at one place. Looking forward to hearing your suggestions \ud83d\ude4f \n https:\/\/twitter.com\/CohereAI\/status\/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19 \n Given the model specificity for any operations, the more open and accessible you are, the more acceptance you will have by early adopters, more traction you will get \n Cmiiw, stability haven't made their latest stable diffusion model available to public and is only available on their dreamstudio ui, right? \n minigpt-4 is better \n and https:\/\/llava-vl.github.io\/ is very good too. Does well on gpt-4 samples \n https:\/\/twitter.com\/marty_catboy\/status\/1649032460573745152 \n Martin Shkreli's AI launch \n Btw very nice talks going on live at Weights & Biases LLMOps London event - https:\/\/www.youtube.com\/watch?v=YfBtytGNEKE","49":"This guy says he used langchain  \n WebGPT - run gpt models entirely on the browser. based on WebGPU.  \n damn. WebGPU seems to be a great ROI for folks building apps that concerns client privacy \n Absolutely love this resource!  \n https:\/\/kubiya.ai\/ \n Has anyone tried something similar? \n What caught your eye? Why is this interesting? \n Can apply helm charts, debug, rollback on K8s clusters all via using a chat interface using natural language \n Well computer engineering goes in circles. It all started with command lines, then started becoming fancier, spent enormous efforts building GUIs and now after all the decades of innovation we are back to \u2026 command lines \ud83d\ude06(essentially) \n \ud83d\ude06\ud83d\ude06 \n https:\/\/blog.replit.com\/llm-training this one \n I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask.  \n Like this technique \n I was hearing it live ! Pretty awesome talk Amogh ! \n Thanks! \n You didn't pray to the demo Gods, they almost tested you there \ud83d\ude02 \n Good demo and techniques there \ud83d\udc4f \n I was going to do pre recorded videos but [PHONE REMOVED] keeps me so busy at Dashtoon that I had no time and had to wing it live \ud83d\ude1b \n Is there any good drawing to 3D tools out there \n cc [PHONE REMOVED] is a 3d artist and has worked with NeRFs \n https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/12etqvx\/tutorial_creating_a_consistent_character_as_a\/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1 \n Create consistent AI characters across images with SD \n Is there an AI art\/ text to image group? [PHONE REMOVED] [PHONE REMOVED] \n This is the one for now \u2014 hence the \"DeepMedia\" in the name! \n I agree on separate image group too \ud83d\ude05 \n Text is so much more popular but would want to have 100% coverage on images. \n I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) \u2014 so if more than 10% (>30) \n Can we join if we are noobs looking to start in deep media ? \n [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED]  please vote :P \n I\u2019ve not muted \n It\u2019s actually a really high quality group. I\u2019ve met some really smart people on here \ud83e\udee1 \n I agree. \n But from discussion standpoint, just want images\/video specific place too \ud83d\ude05 \n Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of . \n Yessss. Beginners are welcome in the community! This is why I personally take the pain to dig up everything from UI components to VectorDB benchmarks for questions asked here! \n Working on this. Releasing next Friday. \n Hero we deserve \n Thanks, man. I recently got into LLMs stuff, so I'm missing the text to image and basically all the new recently released techniques on the image generation. This will really be helpful. \n There should be an option for Not Applicable \n Agree! \n Yeah, that's \"No\" \n there are already like 5 groups in this community, it's becoming like the slack channel hell \ud83d\ude02 \n Yes please. Separate image group please \n Ah! Have a lot of controlnet, SD and text to video stuff I\u2019d love to share and have deeper discussions. Have felt this group is more towards LLMs and NLP and image stuff doesn\u2019t get discussed as much. \n Haha \u201cNO\u201d can be rude \n \ud83d\ude02 \n And much like Slack, the expectation is that you've 1-2 core channels where you contribute actively, sporadically in 2 more and lurk in the rest :) \n Dont follow all is the secret to all slack groups :D \n You can just choose to not vote \ud83d\ude05 \n I promise to contribute more actively to the resultant text-only group :) \n Guess I tipped the balance. Can us commoners get a new group? \ud83d\ude2c \n DeepMedia: Generative Art (Text to Images, Video, Music) \n Haha [PHONE REMOVED]  we need a Text to Action group as well for the next revolution in AI .. \n New poll please \n Early joiners beer on me \ud83c\udf7a \n Yes sir, in couple of weeks when we've more people interested in actions :) \n Haha \ud83d\ude02  I know an expert in building AI community.. \n folks, noob request here. \n Illustrated Transformers: https:\/\/jalammar.github.io\/illustrated-transformer\/ \n Thanks a ton Nirant! \n https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ \n https:\/\/docs.google.com\/spreadsheets\/d\/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4\/edit?usp=sharing quick and dirty effort on this \n \ud83d\ude47\u200d\u2642\ufe0f thanks, my weekend will go well \n Really nice. Did you write a script for whatsapp web? \n Can export chat to plain text and regex on it :) \n yeah this. now tweaking to get context. almost done \n Langchain it! Release code to Github. I'll add the features I'm working on as well. \n My Ola's ex-colleague built this. See if this is helpful  \n \"Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples\" (from https:\/\/news.mit.edu\/2023\/large-language-models-in-context-learning-0207 )  \n https:\/\/arxiv.org\/abs\/2303.12712 in this paper Microsoft researchers who had early access describes to an extent how they think it works. Finally they also conclude they don't know how it works \ud83d\ude41 \n How did you do this so quickly \n export chat+pandas \n +github copilot ofc \n Love how \"Langchain it\" is becoming a verb here \n Am sorry if I'm missing something here. What's new in this? Isn't this what we have been doing in most LLM apps? Just feed the context. Model won't \"learn\" anything. \n In context learning examples include input\/output pairs, not just stuffing data into the prompt \n There is an interesting Microsoft paper that checks the values at various layers of the transformer when giving examples in the prompt vs fine tuning the models with the same examples for 1 epoch. They find similar values in both and have a theory that prompting with examples causes implicit gradient descent which helps the model perform on the unseen example. \n Question for the embeddings experts in this group: say I have a hybrid index on Pinecone. Then during my query, I *only* input dense (semantic) embeddings, what happens? Does this mean it will query only using the dense embeddings or am I likely to get bad results? \n With Pinecone, we don't know. We'll have to read their docs \n okay cool, i will do some digging and report back here as Im sure its useful to others. FWIW I'm migrating from dense only -> sparse + dense and a lot of these little questions come up \n Same story here, would be interested in hearing more about your experience (will share mine once I have gone through it) \n Text to (relatively) high res video is here:","50":"Hi, I am bit new with using GPU. I want to train\/run few models.  \n You can try this if it works for you https:\/\/colab.research.google.com\/drive\/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing \n You can get a free tesla T4 from google \n You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :( \n https:\/\/fullstackdeeplearning.com\/cloud-gpus\/ This comparison table might be useful. \n Thank you Sachin and The Last Samurai. I will go through these links! \n Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage. \n Wow! I think this will solve my problem! Thank you Nirant!! \n also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too \n https:\/\/www.freecodecamp.org\/news\/how-to-use-google-colab-with-vs-code\/ \n Seems like they have banned it  \n Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand \n Thank you!! \n I am actually failing to understand the pricing of cloud gpus. \n You need economies of scale, not considering maintenance and over head \n Also interests rate on capital investment \n e2e networks give some GPUs.  \n Also the current price point is similar across many providers, so we already have an optimum price discovery for this asset \n Got it guys! Thanks. This makes sense. \n I have one.  \n https:\/\/vast.ai\/ \n Any reviews on this cloud GPU rental \n 16Gb memory is not enough. \n Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful \n The Docker file will have this RUN pip3 install torch --index-url https:\/\/download.pytorch.org\/whl\/cpu for my Linux machine \n Hope this is useful \n Hi, How can you enable multiple checkpoints in automatic1111? \n While fine tuning the model using dreambooth? \n Yeah \n Awesome. If you have any public images\/code, please share. Thanks \n Folks will we get the recording or decks of today's talks ? \n Decks yes. I'll email them to the email on the registration one.  \n Hey guys, what\u2019s the solution to privacy while using chatGPT? Most enterprises don\u2019t want to risk sharing their sensitive information to chatGPT? \n We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs. \n What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results? \n Thanks for organising the event! [PHONE REMOVED] and others (whose names I didn\u2019t catch \ud83d\ude05) \n IIRC, GPT-4 launched with McKinsey as a client. Maybe they can use that to assuage any privacy concerns \n Then lightning rounds were good. Would like to hear more of what others have been building.. \n FROM python:3.8-slim-buster \n https:\/\/www.qblocks.cloud\/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I\u2019ve used it frequently and it worked great for my use case \n Will DM you! \n Privacy is important as a principle for enterprises. What\u2019s the best way to figure out which model will work for a particular use case? Any blog\/advice on that? \n Have y\u2019all seen this: ","51":"Looks interesting.  \n I can look around, but nothing comes top of mind. \n Thank you!! I will reach out :D \n Thanks! \n Does anyone have access to Anthropics pitch deck?  \n OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely.  \n First instance of an Indian politician referring to deepfakes \/ audio synthesis? \n Hi all, \n course.fast.ai for being able to make sense of all of this \u2014 even as it changes in 2-3 months and we add VQA (Vision) to mainstream OpenAI APIs \n Lot of new work should come from STT and TTS side, including performance improvements like Whisper-JAX in the coming 4-6 month and more important, voice cloning, avatars and the like. They should have their own \"Lensa moment\" as such if someone markets it well. \n Stable Diffusion\/Generative video? \n Not for beginners I think... but I should say Stable Diffusion does get people hooked ... I got hooked like that \ud83d\ude42 \n Depends if your friend would like to get more into theory or hands on applications \n most devs want hands on first i think \n This is good learning path, only it skips all the LLM theory \n if i had to recommend a course to cover the NLP hands-on with theory - https:\/\/www.udemy.com\/course\/nlp-with-transformers\/ \n This used to be super helpful when heroku was free and we could deploy our applications on heroku. Last I remember, Torch CPU and other packages took less than 500mb to deploy \n Was talking about this \n You can still pretty affordable (about $2\/mo) instances on Fly.io \n If there's anyone interested, Mckay Wrigley is starting a course on Replit on AI dev. The advanced stuff is coming soon but here's the day 0 course. https:\/\/twitter.com\/mckaywrigley\/status\/1649492404943323136 \n Thanks \n controlnet Inpaint guidelines for A1111. https:\/\/github.com\/Mikubill\/sd-webui-controlnet\/issues\/968 [PHONE REMOVED] you can try out with this and let me know how it is working for you.  \n From the author of controlnet repo:  \n Hi everyone! Shreyas here, I\u2019m a product designer at Clari working on revGPT, a chat interface to get on top of everything happening with sales in an organisation ( and a few personal projects:) ).  \n I saw this tweet by the guy who made BabyAGI, with a new approach to vector search & embeddings: https:\/\/twitter.com\/yoheinakajima\/status\/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg \n He then goes on to say that the \u201cpaper\u201d, the code, and the twitter thread as well, were all created with ChatGPT \n Can the experts here explain if this is all fluff or has actual basis? \n https:\/\/yoheinakajima.com\/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search\/ \n Not fluff. Nakajima has been tinkering with AGI for long \n Yep. I was referring to this new technique for vector search which he came up with, or chatgpt came up with \n Lol. He literally said he has idea what it does. \n Well I didn\u2019t say he didn\u2019t knew what he\u2019s talking about or that what he\u2019s speaking is fluff. \n Yep. Still assimilating. Atleast from a reco system lens can comment : in theory, this can potentially be a good approach \n what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing \n This WhatsApp group \ud83d\ude48 \n I hear OpenAI has some decent folks \n should have a job board :) \n This would be helpful - looking for an AD\/Director of ML for my team too \ud83d\ude4c\ud83c\udffc \n How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one. \n Looking to hire folks as well - full time or part time! Job board would be ideal \n I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere? \n Oh it\u2019s ridiculous.  \n I haven\u2019t come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set. \n For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers \/ [ something like that ] and pass the Embeddings to OpenAI for completion \n They\u2019re also building foundation models  \n Hence, ^ \n Don't know if this helps, thought of putting this \n [PHONE REMOVED] has built a wrapper around openai tiktoken to count tokens in a file or text - \n I think we can put one google doc in the group description. Should be good enough to solve the purpose. :) \n Or another group in the community for sole job seekers and employers! \n I was trying to generate an image of \"a key ring with the OpenAI logo on it\" \n u can use ControlNet canny model https:\/\/huggingface.co\/spaces\/hysts\/ControlNet, just start with the openai logo, select the canny model and give the promptt \n If it had the keyring chain-thing, that'd be pretty cool, trying out the ControlNet model \n As someone who did hire from this group in some way and trying more.  \n pardon my bad drawing \n Thx, this is something very close! will finish the remaining using gooey \n This was controlnet only btw, both canny and hed boundary worked well (you can change that in settings) \n Anyone working on open domain Q&A type problems or ones which make use of retreievers\/dense embeddings? \n Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success). \n Oh cool, can you share what kind of models and retrieval algorithms you are using?","52":"Yup we use OpenAI at the moment and dense embeddings only (OpenAI again) \n Going to move to hybrid soon \n Oh cool, are you doing similarity search on a flat embedding space to retrieve context? \n At the moment, yes. Might change depending on what we focus on \/ feedback from customer s \n Came across this GitHub where someone used PEFT to fine tune a LLM based on their iMessage chats to impersonate so that you can create a bot which talks like you  \n Son of Anton \ud83d\ude1c \n cc [PHONE REMOVED] who runs a similar community, [PHONE REMOVED] who is in a Marketing role at Slice, and tech savvy generally \n Hi rohan happy to connext \n Any supabase user is there?  \n You'll probably get a faster response here: https:\/\/github.com\/orgs\/supabase\/discussions ? \n If it's an rpc call, can you explain analyze the sql? \n Or check your RLS policies \n RLS polies are public.  \n https:\/\/explain.dalibo.com\/ \n posted their too- but no response yet \n Use this to visualize your query to understand where it's slow \n Add indexes for parts of the query where there's a mismatch between planned rows and returned rows \n Unoptimized reads on RLS policies won't show up here. So do check for that separately \n ahh okay.. \n Send the specific link on the Github or discord forum with more details \n Can help \n Folks @brkirch ... Automatic1111 guy is doing a new branch for Mac release of Automatic1111 - I tried it much faster than the stock Automatic1111 ... but it is still experimental \n https:\/\/github.com\/brkirch\/stable-diffusion-webui\/releases \n https:\/\/github.com\/orgs\/supabase\/discussions\/13923 \n cc [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] Thought this might be interesting to you \n Woah this is great \n hahah was just tagging you and [PHONE REMOVED] \n It's failing because the query us timing out. Two options : \n Need to get a 64 gb mac like [PHONE REMOVED] now \n ahh okay. let me try \n Are school kids in India using chatGPT ?  \n If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. [PHONE REMOVED] mentioned how his daughter's friends are using it. \n https:\/\/e2eml.school\/transformers.html \n Yeah the demographic data isn't available but the percentage of users in India is just going up month on month \n Same here. Hear anecdotal evidence of kids going majorly into it. My 12 yo son using it to rephrase stuff from Wikipedia for school essays \ud83e\udd23\ud83d\ude05 \n What is memory usage before hitting a query? Also what is data size? \n on the second step , while copying the data from one column to another \n Memory Usage is around 63% before and after...  \n However you guard. Kids are smart and they know how to navigate around restrictions. \ud83d\ude05 \n Friends, how long do I've to wait before I can say \"off-topic\" for Supabase\/Postgres performance queries? Asking for a friend \ud83d\ude05 \n Nice!  \n okay. sorry.. I didn't knew that.. \n No sweat, just want to be cognisant that we've 600+ folks here and they're here mainly for keeping up with GenerativeAI. Supabase is quite likely not relevant for them :) \n make sense \n Would \u2764\ufe0f to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions?  \n https:\/\/www.reddit.com\/r\/selfhosted\/comments\/12w4p2f\/localai_openai_compatible_api_to_run_llm_models\/ \n Yourself? :) \n [PHONE REMOVED] \n The intent is to have mid-speakers (we're all mid compared to Amod) as backup incase we've speaker cancellations.  \n Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ? \n Cohere (Nils Reimers) for sure \u2014 I've a half a page of questions also! \n Is there any event\/session link to register for the same? \n I will try to get it setup. Will share with the community \n Yes please would love transformers or diffusion models in the May one. Any takers here? \n For May, would prefer tasks like VQA, Stable\/Latent Diffusion, image captioning. [PHONE REMOVED] and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon. \n https:\/\/mitchellh.com\/writing\/prompt-engineering-vs-blind-prompting \n Addendum: The April theme was Question Answering (hence a QA demo + QA internals) aka \"How to make your own ChatGPT for internal docs\"  \n The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep [PHONE REMOVED] (https:\/\/www.linkedin.com\/in\/soumyadeepmukherjee\/?originalSubdomain=in) \u2014 previously Infra at Udaan and now runs a Generative AI company in Bengaluru. \n \ud83d\udcaf  \n [PHONE REMOVED] taught a Stable Diffusion workshop in Feb, and there wasn't enough interest at that time. We'll consider this going foward. \n Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more.  \n Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time.  \n Yeah, by default, workshops will be paid. Upto the educator to price them. Can set this up early May and ask here :) \n So the way me and Nirant have been thinking to structure like 1 product\/usage\/use-case talk, 1 deep dive into some engg optimisations\/libraries\/use-cases and 1 deep dive into fundamentals. \n PSA - we had a stable diffusion workshop in March has.gy\/1CNF \n Hey [PHONE REMOVED] can you explain a bit on \"creating realistic images\" specifically what would be the topics on this. Is it prompt oriented or model oriented or something else? \n Sure works - was thinking this would be similar to Amod\u2019s talk but can do a paid workshop too \n Makes sense \n Both - but mostly model oriented and more complex dreambooth methods \n Or rather less known \n Sounds good \n Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!)  \n https:\/\/warpspeed2023.devfolio.co\/ \n Piratewires is always great, one of my favourite substacks \n This is off topic. Is there someone here who has experience working with motion capture \/ face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic. \n [PHONE REMOVED] ? \ud83e\udd14 \n I work in these areas, happy to chat! \n Did some work few months back with mediapipe along with integration in blender. Though not updated with recent developments \n I've worked on a few projects where we did live performance capture, yes. Happy to chat about it! \n https:\/\/twitter.com\/Uncanny_Harry\/status\/1650462479237931008?s=2 \n Text is easier to read on a phone than a text inside an image :) Type the text ;) \n If it's a marketing plug, please refrain. \n It is not. But happy to remove it if you think so. Sorry, I happen to be a marketer \ud83d\ude4f\ud83c\udffd \n Anyone here has experience working with Interoperable Master Format? Would love to connect. \n Has anyone noticed differences between using newlines\/replacing them when using openai's embedding api? \n While you're at it, [PHONE REMOVED] and I'd love to know why Langchain does a newline replacement too \ud83d\ude05 \n \\n is probably not a token in the vocabulary \n Creating a token from an unknown world and having it in the vocabulary is different. The model\u2019s vocabulary are words that it understands to encode into something meaningful in the encoder. \n Can you elaborate or rephrase a bit? I didn't understand \n https:\/\/www.livemint.com\/companies\/start-ups\/indian-engineering-colleges-lead-generative-ai-research-projects-in-indic-languages-facing-challenges-in-data-sourcing-and-computing-power-11681663553393.html \n Let\u2019s take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary. \n So while a newline could be a token it doesn\u2019t have any semantic meaning when it\u2019s encoded. \n Aaah, that'd make sense. Thanks for explaining! \n So to rephrase the original question \u2014  if we have the original vocab file for GPT3.5 and that has a newline, adding\/removing it makes a semantic difference and vice versa? \n If the vocabulary has new lines, you could keep them. But for all practical purposes I haven\u2019t seen models contain any space, tab or new lines in models \n You will use up tokens and not get any advantage in terms of results \n Sometimes, new line matters for text splitting\/ chunking. (Such as splitting by para). Then the \/n has meaning, correct? \n I'm referring to text splitting pre-embedding \n Those are character splitters. Yeah they look into these control characters. \n The assumption from the model author is that you would split texts the way you see fit and then remove unknown vocabulary, tokenize and then feed the texts into the model. \n *text splitters \n My approach for choosing splitting and sanitizing texts would be to run some experiments and see what preserves or improved the performance of the model with the least number of tokens. \n Context length obviously plays a role also. Can\u2019t go longer than ctx supported. \n might be the reason for the extra tokens too? As the new line + word is not recognised as a common enough token \n You could look into the source code of the tiktoken library on GitHub to see how they are doing it. It\u2019s purely heuristics. \n The tokenizer is called C100k or something \n gpt-4 uses a different tokenizer but they haven't updated the url you linked with that. \n yes \n Nice, love pirate wires - good source of truth with lesswrong and scott alexander \n Can help - explored and published on these topics \n https:\/\/twitter.com\/aribk24\/status\/1650372832524926977?s=20 \n responded* \n Worked in pose estimation (egomotion\/SLAM etc) and deployed in few places. Dabbled in human pose at some point but not up to date with lit. You can DM. Not much in mocap\/face-body reconstruction. \n How did you do this? \n We did something very similar for the hackathon - there are some good voice models out there \n Holy shit! Let\u2019s go Arib. Arib hooked me up with a free ticket to a Sam Altman session. What a great dude \n This thing is going to take over the world. \n Sounds legit ! Can you repost your hackathon link? ","53":"what are some cool chatgpt related chrome extensions y'all have come across? \n V. interesting read on potential to use RL without human feedback: https:\/\/gist.github.com\/yoavg\/6bff0fecd65950898eba1bb321cfbd81 \n Not entirely sure if this belongs here, but which are most interesting OSS projects in the space? I finally have some free time and would love to contribute more. \n ShareGPT! \n One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI \ud83d\ude1d and not be bothered to text-back during the week. And just be presented with a date on the weekend. \n For that I had to make a chrome extension that can read all my chats \n she: you're so fun, so when do we go out? \n \ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23\ud83e\udd23 \n No it's trained exclusively to type like me with a super low temperature \n I don't want to come across as someone I'm not \n Just wanted my own two extra hands, not an AI \"dating expert\" \n time to recreate: hang the DJ \n beware of prompt injection attacks \ud83d\ude02 \n Next feature is a vector search on all the girls I've swiped right in the past and autoswiping on girls that cross a certain similarity threshold. Will apply to their images and also their textual information like bios. \n It's still in POC stage \ud83d\ude1d \n can those occur in my context? \n Damn exactly what I was looking for \n idk honestly. yours is also low temp. so maybe more difficult than usual? my understanding is that most prompt injection out there is tested on the default temperature 0.7 \n If anyone wants\/needs help on prompt injection, please send me your model. I enjoy interacting with LLMs to trick them into breaking things. \n Will do once I'm out of POC stage \n Yeah plus the training dataset is made from my chats \n **creates fake profile to send ojasvi a prompt injection attack** \n Feels like a dialogue straight outta \u2018Indian Matchmaking\u2019 \n https:\/\/openai.com\/brand \n +1 on this  \n Transformers is the generic term, GPT was their branding from the beginning \n This is for Branding if you want to mention OpenAI. Just don\u2019t mentioned them and you can name anything. \n ah so do they have a trademark on GPT? \n https:\/\/techcrunch.com\/2023\/04\/24\/gpt-may-be-trademarked-soon-if-openai-has-its-way\/ \n The fact that ChatGPT, as being associated with OpenAI is widely known - they\u2019re only trying to prevent any use of [insertword]GPT that may suggest an association\/affiliation\/partnership with OpenAI when there may be none.  \n Any of you use qdrant for vector search? It looks really cool and easy to use as well. \n The difference between pinecone, Milvus and Qdrant is so small! \n Redis and Qdrant. Have tried Chroma too.  \n Developer Experience? \n off-topic - anyone wants to complete a Bounty for Yohei Nakajima? https:\/\/replit.com\/bounties\/@YoheiNakajima\/scrape-an-api-and-se \n Too little money for trivial work? \n Has anybody tried training any of the openai models on code? \n Embeddings plus GPT-3.5 should be able to do it \n While I read through the fine tuning section of openai docs, just wondering if there are any do\/donts\/tips that I should keep in mind \n Not perfectly though \n Is fine tuning necessary? \n I did kind of a similar approach to create diagrams using MermaidJS. Created embeddings from the docs and added gpt-3.5. Worked well for the most part \n Most of these components have several parameters that they accept that define the behaviour of the UI component. \n Plan of action that I have in mind: \n Afaik, fine tuning is only available for base models not for RLHF'ed\/SFT models. So you may see degradation in performance. \n Thanks \n I couldn\u2019t setup Qdrant and Chroma with the chatgpt-retrieval plugin \ud83d\ude22 \n https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59#issuecomment-1514694410 \n Is there a consensus yet on the best affordable spot GPU \/ cloud providers? \n Haha great idea - how did you train it? \n Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use. \n I got access to this. Haven\u2019t installed yet  \n Nice! Which model?  \n so-vits-svc fork \n This is how world will end \n I like the disclaimer : \" Havent installed it yet \" . : ) \n Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search.  \n Haha \n This was not a scam? Had strong scam vibes \n Can you tell us which parts require training vs which parts are zero shot \/ one shot inference? \n https:\/\/arize.com\/observe-2023\/ \n I haven't trained these models myself because of data prep requirements. \n Is someone kind enough to share their gpt4 access for a day and half please? \ud83e\udd79 \n For GPT4 access, you can try https:\/\/github.com\/xtekky\/gpt4free \n In case you do not have a paid subscription \n I want to clone Arijit Singh's voice. Will have to collect and clean the data. \n Ah, so its like style transfer for speech, nice \n Yup. \n Hire someone on upwork\/fiver? Costs <50 USD for this \n And 2 dats \n days* \n Are you using https:\/\/beta.elevenlabs.io\/ for this? \n Nope. https:\/\/github.com\/voicepaw\/so-vits-svc-fork \n Someone leaked pretrained models of many popular singers a week back. Was that for this project? \n Probably. Wait I'll share. \n https:\/\/docs.google.com\/spreadsheets\/d\/1qzeFdpUPr7E0jOFwWSXd8LF30ZLjz1CSVEBiG8gPHTU\/edit#gid=1792554832 this one? \n They even got Freddy \n https:\/\/twitter.com\/tivadardanka\/status\/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA \n https:\/\/aiagent.app\/ \n This is pretty cool! Know who's built this? \n The toolkit says coming soon \n something that\u2019s already here - fixie.ai \n doesnt this look like godmode.space (or just AutoGPT in general)? \n Fixie's SDK is pretty powerful \n has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this. \n have you used this? \n I have, a bit \n Worked for the 30 mins i played with it \n How are you running it on prod? Docker? Is it a cluster? \n The concept is fun, but I haven\u2019t really found it useful. \n It's a cluster, but we're using their managed SaaS service WCS, https:\/\/weaviate.io\/developers\/weaviate\/installation\/weaviate-cloud-services \n Just out of curiosity, why not? \n depends on the application I guess? I generally use it for paraphrasing (for which chatgpt suffices) and coding (where none of these models work very well - haven't tried GPT4 which some people claim is much better, but more expensive too) \n why not? at least thats the idea wit medical AI, as of now humans by nature will not trust AI diagnosis any more than a human doctor's diagnosis. AI assisted healthcare makes sense from both effort minimization and improving patient outcome \n an example: https:\/\/whiterabbit.ai\/ \n Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines. \n Serverless? Modal and Banana type services? \n Have it forever - https:\/\/gooey.ai\/compare-large-language-models\/?example_id=7ihhyv3l \n Okay, I am not sure if serverless would be right for us. So I have a normal python script with multiple diffusion models and hosted via flask\/streamlit. Sorry, little noob in hosting :p \n wow - this should help my case, if they offer what they claim. \n Hey Shivansh , \n happy to connect and understand how we can help you \n Arey this is mine only :) DM for bugs and feedback \n https:\/\/arize.com\/observe-2023\/ \n We\u2019ve spent a lot of time trying diff GPU hosting platforms.  \n Check Modal Labs perhaps? It's beginner friendly and they've Python-friendly web endpoints: https:\/\/modal.com\/docs\/guide\/webhooks \n Ongoing webinar on Dolly right now. Still on for another 30 mins.  \n Q&A so far. In case it's helpful for anyone. \n Open Source (Llama 30B-based) rival to ChatGPT from Huggingface: \n Must be WA blue \ud83e\udd23 \n You're welcome :P Did this via apple app on mac in case there's an actual constraint on other devices :P \n Fine tuning vs sending long, detailed prompts is a very interesting topic\/Product design requirement \n My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction.  \n Added Q to above: \n *satisfactory output \n https:\/\/manifold.markets\/IsaacKing\/will-any-llm-have-a-context-window \n Related discussion here https:\/\/news.ycombinator.com\/item?id=35682424 \n Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production? \n Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better? \n Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ? \n How do we think of expenses? \n More input tokens would mostly mean more expensive API calls? \n Expenses is ~ # of context window tokens to and fro on OpenAI atleast \n My understanding so far is that GPT 4 especially is very capable for most use cases with few shot in-context learning. So would be easier to test and learn like this, figure the nuances of the use case and then evaluate smaller fine tuned models. \n Makes sense. With that in mind 1M tokens of context will be much worse on $ than fine tuning maybe. \n But say we were using an open source model (Llama? alpaca? Of the future) where pricing isn\u2019t a factor of token count. The large context window approach will work better with more flexibility? \n Open question still - anyone tried both approaches? \n (Adding to what Karan said) \n I think it's a function of Product maturity \n If it's a multi tenant setup, I think it's better to finetune on the combined data for all tenants and then use few-shot prompting to refine for every customer. \n Umm, if I'm a chatbot\/conversational AI company and have competing customers (say Axis and HDFC) as my clientele, I'd likely have a base model and fine-tuned (forked) versions of the same running inside the environments of Axis and HDFC \n The former use-case was via anecdotal research \n How much are we seeing Indian clients caring about their data being used for model training? Is it just regulatory heavy industries like banking or are non-reg industries saying the same? (Eg Ed-tech) \n https:\/\/www.researchgate.net\/publication\/370213628_Scaling_Transformer_to_1M_tokens_and_beyond_with_RMT \n Personal experience from a limited sample set - more about the use-case than regulations \n I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data.  \n Also important to build a differentiated solution. Else anyone can create the wrapper without fine tuning \n Well said. We have a similar vision - start with embeddings and then at some point fine tune per client (maybe per team) \n Precisely why AI has higher marginal costs (and poorer GMs) than traditional cloud software \n You can get away with embeddings right? So there\u2019s no training? \n discussing this for a complicated usecase where finetuning is required in some capacity. So pureplay embeddings and few shot prompting won't work is the assumption here. \n Those models doesn't not have RLHF etc, not just smaller models. So you will be seeing perf similar to GPT3 and some more: your fine tuning. You will need other models and then train RLHF or use one of the RLHF trained models and try. Haven't done the last part. You will most likely need to fine tune RLHF as well, as the new models might have drifted in the output space. \n Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white. \n What's the exact fine print that is difficult to decipher? \n From what I understand, context is the application's and not Open AIs but want to understand this further. \n Tell them they\u2019ll loose everything when their competition uses chatgpt to outperform them \ud83d\ude17\ud83d\ude1d \n Scare is definitely one approach haha :D \n And it took the big 3 15 odd years to instil this trust \n Or tell them you\u2019re using azure, azure has like a direct passthrough of gpt \n Used replicate and runpod.io, would recommend both for serverless and stateful use cases \n In typical Amazon fashion, better selection inside a VPC that customers trust with Anthropic which is possibly the biggest competitor to OAI today \n It feels like a good tool for scaffolding, but also a bit blind. The way the repo is also feels limiting.  \n Their wordings are something like \"OpenAI may use content to provide and maintain services\". What he heard from an OpenAI engineer was won't be used for training* (*to be verified by the engineer). Don't know if Nirant or others heard an update from their team. \n https:\/\/learn.microsoft.com\/en-us\/legal\/cognitive-services\/openai\/data-privacy \n Open AI engineer Boris Power - \"Prompting leads to faster results, with fine tuning it's painful to edit with changing data. Use fine tuning for exact format of input and output and if you have lots of historical high quality data. New use cases - fine tuning acts a lot of cost. Fine tuning doesn't do well when you need to understand facts and then provide the output\" \n Thanks for this. Could be helpful for us. \n They did say in an email that all data is deleted within 30 days and it\u2019s not used for training \n https:\/\/openai.com\/blog\/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt \n Already did this. Like how this is fine print on the website since Sam said the purpose of releasing chatgpt to the world was (high frequency \/ diverse) user feedback. \n *this was \n Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.","54":"OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions. \n I think multinationals too will move to start using them. Their models are quite good and it is just a matter of time. \n They do need more data, just not api platform customer data. \n Data Partnership: Interesting. \n Anyone have a list of data partners for Open AI? \n Nah... They don't talk about how they train their new models either in terms of data or architecture...  Their platform api  data policy is public info though... \n I spent a day in march at openai office when they have invited some startups. They are very much looking to get more data to train their models from the industry because they have exhausted internet and academic datasets. However their organization is so small that they are able to cater to partnership proposals only from the biggest tech companies right now, all of which are lining up at their door. Over time they may get to your request. \n Woah, it would have easily made 90%'ile in my undergrad randomized algo course at IIT. \n If it helps, BITS Pilani did not have a randomized algo course \u2014 we had a design and analysis of algorithms, which was more analysis than design: And even Turbo does better than on those questions (specially speed!) than I do even today \ud83d\ude05 \n Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics \n Apparently they built this under 2 weeks \n https:\/\/twitter.com\/Mascobot\/status\/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19 \n Widely known no? Even GPT3.5-turbo and GPT4 are a Codex iteration, not vanilla LLM? \n Widely known to maybe scientists, not discussed much I feel \n Fair, I might be suffering some form of inside-track groupthink here \ud83d\ude05 \n To many, I wouldn't think it does \n Aligned, it's a utility like ec2 in 3 years or sooner \n 100% - this is the difference between AI now and 5 years back. \n The UX of consuming models was not great up until openai came into the picture. \n Still kinda sad that HF hasn't learned this well enough tbh \n Once we have a well supported IR which works across all platforms, serving and consuming models from source would become a lot easier too. \n They were born at a different time. Compared to their competition at that time(2017-18) they have done well. \n Almost everyone who does NLP now makes their models work their transformer library. \n In 2018 we spent half a day finding out how to use a model someone trained lol \n UX bhi and ML application development pipeline bhi \ud83d\ude05 \n Stanford NLP \ud83e\udd0c\ud83c\udffc \n https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/12yzd2a\/google_researchers_achieve_performance\/ \n Anyone working on ML on edge here? \n This looks big \n Some of this stuff like flash attention is generally applicable even on servers \n Wow! \n https:\/\/www.qualcomm.com\/news\/onq\/2023\/02\/worlds-first-on-device-demonstration-of-stable-diffusion-on-android \n Some earlier work from Qualcomm \n Pretty cool. Quite interesting that there is a huge jump from chatGPT. Will try this on the JEE ones we all were trying. \n Palantir launches ChatGPT for war  \n Damn expect anduril to come up with something too \n The full video link for those who are interested in involvement of tech in defence and future wars \n this makes me sad \n I hate that their tech usecases go from disaster relief efforts straight to drone warfare \n Well for one, this is clear proof that programmers are god living among us \u263a\ufe0f \n Only 2 ML engineers that too :) \n Any idea how 10 days of traning time translates to total gpu time spent, i.e. including experiments? \n I\u2019ve worked with Pete Warden and the tinyml folks at Google, used to be with the company that owns the accelerators for their voice wake, happy to chat ! \n Wonderful! \n Will DM \n Anyone knows how they did it with 1\/10th the parameter count? \n Keeping it coming pls. Beginner insights most welcome Some of us still noobs in the group. 3 month old industry for us \ud83d\ude02 \n Anyone here worked with music generation \/ audio generation \/ jingle generation \/ song generation \/ new AI instruments => pls do share and open for discussions over DM \ud83d\ude4f \ud83c\udfbc \n Doesn't look like they've some unfair data (qty or quality advantage) \u2014 they just decided to test Chinchilla limits and that worked. They trained for a lot more tokens than most people have tried for similarly sized models.  \n PSA: Dedicated group for music, images, video: https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J \n If anyone remotely knows this person. An expert talk by then would be helpful ++ \n them * \n Replit Demo Day videos are soon going to be on Youtube from what I hear \n To all the silent VCs in this group feeding this chat thread to an LLM, pls help \ud83d\ude4f \ud83d\ude02 \n Slide Deck from Accel's [PHONE REMOVED] on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes.  \n yeah will be up tomorrow - and the model should be released soon as well \n Thanks! \n Thanks Anshul sir! Anshul sir [PHONE REMOVED] leads Replit India \n Thanks! Was this a closed session? \n Yes Sudharshan .. i did this for Accel funded startups - founders and tech teams \n Alright thanks, was going to ask for invites to future sessions - this is really good \n https:\/\/twitter.com\/matthieurouif\/status\/1650904940036890626 \n The gpt-4 multimodal model has an api yet? I thought it was chatgpt only \n GPT4 takes text in and can generate prompt for a SD\/Midjourney landscape \n They use photoroom  \n Not out, you can use https:\/\/minigpt-4.github.io\/ or https:\/\/llava-vl.github.io\/ \n Doesn't have image understanding \n https:\/\/dust.tt is awesome! \n It's internal for now \n better than modal or runpod? \n Shared interest, please keep me posted on your connects ! \n It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own \n Dust.tt is amazing! \n Nice looking at the docs \n i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right? \n https:\/\/www.linkedin.com\/posts\/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios \n [PHONE REMOVED] is playing with music gen these days \n Novelty isn't the only dimension. Ease of use is greatly improved and tons of Shopify stores which sell everything from soaps and other trinkets would love this.  \n oh totally agreed! my initial impression from the post here was that there's something new... technically speaking (as a lot of folks here are technical).  \n The application. \n Went through this, this is very useful \n Resharing the link, as someone has recently joined and is curious about the deck DM'ed  \n Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling \n How's the availability on Amazon Sagemaker? \n Might not be applicable for everyone, but I think by far the fastest and best experience would be to apply for google cloud startup credits, and use a dedicated A100 for colab. \n Jupiter on VS Code with Banana on backend will cost \u20b9150\/hour.  \n ^ banana.dev also has a great free tier for 1 hour of use \n Should still be good for tinkering use-cases I'd guess? \n Really nice for notebooks \/ automation \/ scripting  \n Yes. Community model templates allow one click deployment. For 50+ models. Simple docs. \n Kaggle \n I want to experiment with deploying StableDiffusion and running Gradio\/Automatic1111 ... will also want to keep some of the models like Lyriel \/ Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase \n You can try paperspace, they are undercutting big tech on GPUs. https:\/\/www.paperspace.com \n they have 5GB space on the Gradient .. \ud83d\ude41 \n Google Colab is $12 - and 50GB \n I have been using my Mac Pro as a server at home + socket + multiple LMs. Works like a charm :) \n You can keep the model storage on hugging face and then use any serverless gpu player to import your model from there directly. \n Will try this ! \n This doesn't work, start up credits cannot be used for colab, they have separate billing \n Yes, but now you can connect a gce vm to colab, giving you persistent sessions and dedicated compute \n https:\/\/research.google.com\/colaboratory\/marketplace.html \n Can recommend runpod, stop the instance when not using, will only be charged for storage \n Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home \ud83d\ude05 \n On a more serious note, runpod, lambdalabs, fluidstack. Keep moving around \ud83d\ude05 \n Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs \/ hour FYI. \n Does anyone know what compute units mean? \n I asked gpt. this maybe helpful \n Back to On Prime? \ud83d\ude02 \n What GPU do they offer at this price? How much RAM for SD? \n T4 24GB think for this rate \n \"No One Knows What It Means But It's Provocative, It Gets The People Going\" \ud83e\udd23 \n Are these instances persistent? Or do yoh still have to do the google drive hack \n not persistent \n Which platform is this? \n Google cloud \n For non persistent \/ spot instances of GPUs GOOG was always in under supply while we were testing.  \n https:\/\/www.chartgpt.dev\/ \n https:\/\/news.ycombinator.com\/item?id=35697627 \n For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB? \n Context: I'm using Pinecone and I'm saving most of my content in a different db (pinecone has a limit on size of meta data). Want to know if that is required \/ recommended for other Vector DBs like Weaviate \n whats the major difference between storing it in vector dbs and something like a numpy array? is retrieval super fast for say 1000s of vectors \n Yep, our app allows users embed content so we need containerization + expect this to increase significantly (\ud83e\udd1e). If you are building a vertical app (only embedding content yourself), numpy is probably ok - others probably have a better view tho \n https:\/\/www.youtube.com\/watch?v=7TCqGslll-4 \n https:\/\/github.com\/ai-forever\/Kandinsky-2","55":"https:\/\/twitter.com\/rasbt\/status\/1651226178353614854?s=48&t=ACPHEfclkXmi9Z92RTsh9g \n [PHONE REMOVED] \n In Weaviate itself. It also allows to do pre filtered vector search based on the metadata, it internally builds separate indices for the metadata as well. \n Oh cool, so you could store everything in weviate? Is the cost prohibitive? For example, if metadata is chunks of text \n Their managed SaaS  right now actually charges only based on the number of vectors and the dimensions of the vectors, irrespective of the extra metadata stored \n Replit's latest announcement is interesting: https:\/\/twitter.com\/swyx\/status\/1650989632413401089?s=20 \n Anyone started learning LLMs\/Transformers\/ML in the last 3 months? \n Let\u2019s do a zoom session to discuss? \n How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX \n bumping - has anyone been able to solve? \n I faced this problem before. We used some form of leaky bucket to smoothen the API calling rate. \n Not particularly for OpenAI but for a general solution for limiting API calling rates. \n 429s, use the retry-after. Are you getting rate limited for requests or tokenS? \n all types of errors now. I wish there was a middle layer to solve this \n :) \n Any proxies like Nginx with Lua JIT or Envoy with WASM\/Lua can be used for production setup without adding any much latency and performance overhead. \n Can you elaborate and\/or share links? Hearing about Lua JIT and WASM in this context for the first time \ud83d\ude05 \n https:\/\/openresty.org\/en\/ \n https:\/\/tetrate.io\/blog\/wasm-modules-and-envoy-extensibility-explained-part-1\/ \n These enovy, istio, nginx are API proxy and they have a customised layer where we can add multiple filters. These filters can extend functionality. Which you can write in Lua, Wasm etc. Lua interpreters bring less overhead and way faster than python interpreter. \n Things like if you are testing multiple models on production one is main other are tests. And you like to send prod requests to all and then like to monitor outcomes. For this generally you need to write code. But in the case of these proxies you simply need to write small Lua or even yaml. And this proxy itself sends requests to all these services (which host models) and passes the response of the main service to the caller\/client.  \n Thanks to those who reached out.  \n Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos).  \n Guys quick question.  \n https:\/\/twitter.com\/raj_raj88\/status\/1631018786492157954 \n i guess 302, 303 etc. are later versions \n Not clear to me what does snapshop mean here. If this model is to be deprecated in 3 months, what's the need in the forst place. Is there a specific reason of not following conventional versioning. Would appreciate if someone can eli5 \n Think of a continuous model training process with multiple forks, each \"named\" or versioned model is a actually a checkpoint in that.  \n Workflow wise: Say you build on 0314 or any other 3 month model, when it gets deprecated, you have to explicitly upgrade and you'll be prepared to run your entire battery of tests again. This is better than a silent upgrade where the behaviour of underlying model changes silently. \n Does this help? \n Yes but basis this tweet https:\/\/twitter.com\/raj_raj88\/status\/1631018786492157954 my understanding is 3.5-turbo refers to the latest model 3.5-turbo-x  \n Let me move this to DM, need to understand your query better \ud83d\ude05 \n Might be useful for you,i was trying to train a Bloom model  and i was running out of GPU memory..and this gradient notebook helped me https:\/\/github.com\/rasbt\/gradient-accumulation-blog\/blob\/main\/src\/1_batchsize-1.py where if we want to use a batch size of 256 but can only fit a batch size of 64 into GPU memory, we can perform gradient accumulation over four batches of size 64. (After processing all four batches, we will have the accumulated gradients equivalent to a single batch of size 256.) This allows us to effectively emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices. \n As I have mentioned, tried all possible combinations with gradient accumulation as well. Problem is of memory leak \n If you are facing GPU constraints you can try using the quantized version and fine tuning using lora+ bits and bytes \n Okay my bad I see you are already using peft \n Based on cursory research, rundiffusion seems like a good hosted solution for automatic SD UI.  \n It's pretty good, just not that well known \n Hey Guys \n https:\/\/twitter.com\/Replit\/status\/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19 \n You can try qblocks.cloud \n Tried serverless GPUs like bananadev? \n I am using this. Comes to around 1 dollar for 24gb GPU \n This is some kind of membership. Optional I think \n any devrels here ? \n This has some nice comparison of serverless platforms \n You\u2019re welcome to try it out for yourself next week when it drops :) \n Also the LLM relevant stuff is 46:00 onwards \n Already signed up & looking forward :) \n This is optional but might turn out to be cheaper if you are using it for high-velocity use cases. I have tried the Automatic1111 on SD V1.5 and is pretty decent for playing around. \n Has anyone gotten higher rate limits from OpenAI? \n cc [PHONE REMOVED] has among the largest OpenAI bills in India, [PHONE REMOVED] used to work with the same team \n Names please? \ud83d\ude05 (I see Rohit\u2019s) \n Can this be used to solve marketing problems? \n Anirudh Singla of Pepper Content and Rohit (now of Portkey), earlier at Pepper Content \n yes, we got it upgraded multiple times at Pepper. (This is Rohit) \n was it for GPT4? or GPT3.5? \n Yes. Take usually 2-3 days. Applies for all incl gpt4 \n Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too \n Stand corrected.. i misread it as quota increase. \n Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https:\/\/lu.ma\/StateofAI  \n We are limited\u00a0to\u00a020\u00a0seats so pardon me if we're unable to accommodate all \n Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal [PHONE REMOVED] isn't doing self promotion here :). \n Oh yes thanks. It's free and there are no affiliations. Just shared passion for AI \n 20 seats is a venue constraint \n [PHONE REMOVED] truly missing your organising skills and energy today \ud83d\ude05 \n Nirant is a one man army \n We've hit capacity. Optimising for maximum participation by limiting it to one VC per firm. Please pardon \ud83d\ude4f \n Any chance of a live stream\/recording? \n It appears that way, but in practice, I'm simply the face for the work done by multiple folks e.g. [PHONE REMOVED], [PHONE REMOVED], [PHONE REMOVED], Hasgeek crew: [PHONE REMOVED] and co \n Don't have the infra\/team. Sorry \n Is this happening? \ud83d\ude42 \n Any recommended resources? \n Try training your own via huggingface. I did that and learnt a lot more (had to beat my head around a lot) \n 1. https:\/\/course.fast.ai \u2014 probably the best there is  \n 3 is more NLP focussed, 2 is broader ranging from Vision to Speech and what not \n Thanks Aashay and Nirant. \n could you pls reshare or perhaps link it in group desc \n https:\/\/docs.google.com\/spreadsheets\/d\/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM\/edit#gid=962390240 \n It starts from scratch. Not sure if useful to many here. Anyway Admin\u2019s call if they want to add it group  desc \n https:\/\/twitter.com\/andrewyng\/status\/1651605660382134274?s=46&t=wdMpftHBI367157ViAY2Gg \n Pinecone raised 100m \n https:\/\/twitter.com\/pinecone\/status\/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19 \n It's having the nvidia moment in age of langchain , good to raise when you have the buzz \n Yeah, also serendipity is a beautiful thing. Started in W15 cohort 8 years ago, to build for the vector search market. Raised series A after 7 years \n Took 8 years to be in the right place at right time. More power to them \n Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution! \n This. \n Woah! Have to say they\u2019re good - literally 0 issues since we launched with them \n agreed, love his videos \n For anyone looking for them: \n Oh absolutely, \n I have a friend there and he was telling me about their production traction from India - it's significant \n any idea if these individuals devs using it or more startups \/ small companies? \n Startups\/companies \n yes \/ would love to know who all so can share learnings. We are at 20K vectors \n Their content game is also great. In most AI keywords they are within 5. \n https:\/\/www.databricks.com\/blog\/contributing-spark-loader-for-hugging-face-datasets \n Haan we can plan one on weekend. [PHONE REMOVED]  would you want to take a lead on this?  cc [PHONE REMOVED]","56":"Sure \n (There is a Nvidia-HF event on Saturday morning, hence kept slots after that) \n Online ? URL ? \n https:\/\/sites.google.com\/huggingface.co\/generative-ai-meetup \n Need an experienced person to guide and answer queries.. volunteer please \n https:\/\/twitter.com\/thesephist\/status\/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19 \n https:\/\/www.euractiv.com\/section\/artificial-intelligence\/news\/meps-seal-the-deal-on-artificial-intelligence-act\/ \n same \n haha, whose place is this party going down at \n Has anyone heard of using diffusion for detection \/ recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar. \n Or, more generally, using diffusion in a generic neural network or for some other application outside of generating content \n They use transformers for lane detection- https:\/\/youtu.be\/aVjDX5XshYo \n https:\/\/arxiv.org\/abs\/2112.00390 \n text2motion  \n [PHONE REMOVED] might know a thing or two \n I got a call from someone inviting me here. Seems a lot like a marketing campaign. If someone is interested in  their data lake services then they should definitely attend it. \n If not, then I don't see much why anyone would attend \n Diffusion is a noise removal process at its core \n You can use it to generate content, but you can also use diffusion to process content. \n [PHONE REMOVED]\u2019s place \n [PHONE REMOVED] is an incredible teacher - should do a talk for the group \n Has anyone used promptlayer? or anything similar? \n Anyone who has resources for Data Exploration and Feature Engineering? \n We can point you in a million directions, but perhaps the most value-for-time is this: \n What are the best projects around these areas of interest: \n Is the intention to get more familiar with these problems? Like a project to assist coursework? \n Hmm, that's part of the problem. Too many teams re-invent these pieces internally. \n Why do you've to touch a GPU for doing custom embedding in 2023? That's a very 2016 thing to do \n https:\/\/tsmatz.wordpress.com\/2023\/03\/07\/react-with-openai-gpt-and-langchain\/ \n Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable \ud83e\udd14 \n I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P \n Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in. \n Umm, almost all kinds of arts have an audience as well \n Also, AutoGPT has fantastic marketing. Credit due where it is due. \n Did it actually do anything useful yet? Haven't seen any impressive results so far. \n AutoGPT has been major disappointment from the hype prospective \n it is only aboe to do small things\/tasks with bounded scopes and well-defined goals  \n Can do basic financial analysis of companies. Somehow gets the easiest thing (getting the right current price from google) wrong. But was able to so SWOT + competitive analysis + DCF \n This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search. \n Have done market sizing and memo writing using AutoGPT, but takes alot of time and gets into loops too often \n Oh my,  I see that link has led to a mini furore in this group \ud83d\ude1f I actually had a specific question but got a call. \n Hahha, no furore. Just banter. \n Bing has a lot longer context window \u2014 so can reason over more search results, is basically free for most people, easier to use. \n AutoGPT took all the learnings developed by langchain, vectors DBs etc etc and made it available for the wider non-developer audience to use in the format they understand better.  \n Bing is also not powered 100% by GPT but uses an internal MSFT model quite often \n *Anyone here who has used such sequential prompting on a custom dataset to run a controlled conversation, say a roleplay?* We\u2019re building a sales roleplay product that mimics conversations of a specific team, and I would like to know such available best practices to optimise the output if someone has dived deeper into something like this. \n This is perhaps the best tooling for guided-chat with some roleplay. \n It\u2019s for B2B enterprises, so the idea is that it better get as precise yet flair-ful as it can get (based on a team\u2019s dynamics). \n AlignmentAI \n PMGPT \n ```Here are a few suggestions for a name for an AI assistant\/co-pilot for product managers\/product teams: \n No offence to any PM, you all are loved \ud83d\ude1b \n Tx. Deleted since it borders self promotion \n Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone. \n Used this only https:\/\/www.namefinder.ai \n A dairy founder wanted g.ai but had to resort to mal.ai \n AIshwarIA \n I think something like autogpt becomes useful when human closed loop feedback cycles are involved at a large scale. Something that incorporates large scale human feedback and nudges into its reasoning, that's where I see real potential \n Eg for trading bots this might be a community of 1000s of traders constantly giving it nudges and guidance on its thoughts and actions \n For the technical folks that are waiting on GPT4 API Access for more than 30 days, with any meaningful open source presence \u2014 please DM me.  \n I got the access in 5 days. Had requested it last weekend and got it this week. \n Works like a charm. We had been pusing internal teams at Microsoft for a month, with no end in sight, but nirant's tip worked in 2 hours :) \n Does anyone have access to GPT plugins? \n did you get through Azure OpenAI service? \n Yes, thanks to nirant as well \n I haven't checked that yet. Is it available through that? \n Are awesome. How did you get it? \n I just want to play with the plugins and explore their capabilities. \n Interesting bit: the Microsoft folks pushed us to shift all our code to azure openai service, and something called semantic-kernel in order to get gpt-4 access, but none of it has materialised yet \n I feel guilty open sourcing nirant's tips \ud83d\ude02 \n More important: We also shouldn't abuse OpenAI's goodwill :) \n Haha. No worries. I have gpt-4 api access. \n Anyone in Ben Tossel's AI maker group? \n I am \n Pray tell \ud83d\ude42 \n And also the joining link\ud83d\ude05 \n Gotta apply \n maker club? \n Where? \n let me find the link \n For folks wondering how is FP8 working? This is based on NVIDIA's Transformer Engine: https:\/\/docs.nvidia.com\/deeplearning\/transformer-engine\/user-guide\/index.html \n What impact you foresee? Large Model, Faster Model, or new model arch? \n Coreweave talks about tier 3 datacenters in north america. What does that mean? Do we have any in India as well? \n Mostly faster inference in the 3-6 month horizon as compute providers figure this out, and perhaps more Fp16, Fp8\/int8 proliferation for task-specific models \n Faster inference means lesser costs because you can handle higher concurrent users per gpu \n If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not \u2014 I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases \n Also at times you can\u2019t guarantee to spawn up some of the higher end GPUs on demand, leading to slower spawn up time for users \n I doubt you'll have this luxury for long, imo serverless gpus are a perfect competition model with market competition dictating  the pricing instead of arbitrary end user value \n https:\/\/twitter.com\/bentossell\/status\/1636394074101153792 \n fyi \n Hey, this is nice, thanks for sharing \n Looks too good to be true, what do you think is the catch here? \n No catch, it's Ben \n anyone  , building with langchain here ?  just deployed a private V2 for collectiv langchainX. would be happy to share access , if you building with langchain would help your process \n Hi! Does anyone know of any tools that can summarize custom code repos\/documentation? Something like https:\/\/github.com\/mtenenholtz\/chat-twitter but where you can maybe enter in any Github repo link and it'll summarize it for you. \n https:\/\/github.com\/peterw\/Chat-with-Github-Repo \n https:\/\/stability.ai\/blog\/deepfloyd-if-text-to-image-model \n Thanks \n Research license only \n interesting approach, will be interesting to see if it will be able to displace the stable diffusion model given the eco-system that has already grown around it","57":"Very lame question: Does LlamaIndex or Langchain support VectorDB with Sources with GPT4 or GPT3.5-Turbo?  \n If yes, can you please point me to the right docs \ud83d\ude05 \n what does vectordb with sources with gpt mean? \n Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question \u2014 I want the response to include 5, 7 \n https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/examples\/vector_indices\/PineconeIndexDemo.ipynb \n response.source_nodes should give you the sources. \n That gives 1, 3, 5, 7 \u2014 all top k \n ohh okay. Sorry, I misunderstood then. One way is to use evaluation module on top these to get only 5, 7 are being used. \n I have a hack for this \n Use this prompt -  \n Then simply parse the citations returned using regex \n I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way? \n Works very consistently \n (Haven't experimented with gpt-4 though yet) \n Including instructions and search results in system prompt made it forget the instructions sometimes \n So moved them to user prompt \n This technique also in my experience has the added benefit of producing more grounded results, because you are kinda forcing it to cite sources. (Not sure why it works at all though) \n OpenAI models don\u2019t do this. What you want is basically the LLMs to cite references. \n *The reader model \n Interesting. \n [PHONE REMOVED] something like this - https:\/\/python.langchain.com\/en\/latest\/modules\/chains\/index_examples\/qa_with_sources.html ? \n Yes, but this uses text-davinci-003 \u2014 which leads to couple of trade offs:   \n what could be reasons that the methodology can\u2019t be ported to GPT-4? (I haven\u2019t looked at the code yet, only did a cursory read on this today) \n Do you mean LLM or code reasons? There are no LLM reasons \n Replacing the OpenAI() classes in the example with ChatOpenAI() doesn't work? \n Code reasons - is the \u201creturn_only_outputs\u201d prop not available for ChatCompletions \n Code Reasons: Langchain is structured around separation of LLMs and Vector Indices \u2014 the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources \n You\u2019ll have to extend the chain functions I guess.. \n Llama Index: [PHONE REMOVED] can share more context, but I think they've just gotten around to it. From what I can tell, they have no such limitations \n *just not gotten around to it \n Aah, that makes sense. Will make for a great PR! \n That was a quick delete \ud83d\ude02\ud83d\ude02\ud83d\ude02 \n Yeah, sometimes I've to enforce that \"stay on topic\" policy to myself \ud83e\udd23 \n Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs \n My eyes can\u2019t believe this, what error does it throw? \n It's definitely not meant for simple things \n OpenAI has a function in one of their libs to convert chat prompts to text ones and vice versa - that\u2019s needed here I guess \ud83d\ude05 \n Wait, what. I've not seen this. Is this part of their default Python SDK? If not, can you link it here? \n https:\/\/github.com\/openai\/evals\/blob\/4da6a6115ac03df4f8364903815a6e73e95c2fd1\/evals\/prompt\/base.py#L22 \n Okay, I see the code. Now I feel sad that I didn't think of this. Probably should've asked this question at 9 AM instead of 2 AM \ud83d\ude05 \n while we are in this repo - these prompts are gold  \n These kinda gems are what make this group worthwhile \ud83e\udef0\ud83c\udffb \n Yes! Writing a blog on how good the library is. We aren\u2019t using so much of what became available here! \n anyone knows a model that can give aesthetic score for an image? \n FID against LAION-A? \n Please share after ur done \n Adding context here:  \n Pretty cool approach. \n That said, if you've user-scored images, you can go very far with just a ResNet and a classification model. AirBnB Staff ML Engineers with a PhD were still doing that and getting promoted in Dec 2022: https:\/\/medium.com\/airbnb-engineering\/when-a-picture-is-worth-more-than-words-17718860dcc2 \n Basically, Big Data beats Big Brains any day, all day long \n Before anyone asks, Airbnb uses AWS OpenSearch with HNSW for their VectorStore \n Thinking along similar lines, I'm eagerly waiting for a model that takes in any photo and gives out professional level DSLR photos. Perfect lighting, colors, focus, contrast, etc :) \n For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license). \n Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there\u2019s 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development \ud83d\ude1b).  \n Working on a summary web version and hopefully a weekly\/monthly newsletter \ud83e\udd1e \n Cool che. Will sign up for that. \n I prefer never using them... Just picking the prompts from their source code \n Who here is using langchain in prod? \n How? Manually \ud83d\ude2f \n No way. Shouldn't expect that from Nirant. Automate. \ud83d\ude01 \n This is a nice read \n Mainly my point about finding any good way to extract WhatsApp group data  automatically. I don't find any official APIs. There might be few unofficial ways but that may cause a number ban. \n Hey folks,  \n My understanding is currently runwayml gen 2. \n This isn't available yet I thought. \n Don\u2019t know about access. I have seen multiple videos of it on twitter lately. \n Few days old \ud83d\ude1c:  \n https:\/\/replicate.com\/cjwbw\/damo-text-to-video \n https:\/\/github.com\/Picsart-AI-Research\/Text2Video-Zero \n Folks, so we are doing the \"Learning Transformers\/NLP\/ML\" discussion on Sunday 4-5pm. \n Anyone at the nvidia event? \n Using openai APIs to expand? \n Fyi that calendar link doesn't do anything for me, using Android here \n I can make a list of great solutions for it if there's interest :) \n Tuned in for Gen AI, listening to GPU talks \ud83d\udc80 \n Thanks for flagging it Amir. \n https:\/\/twitter.com\/bhutanisanyam1\/status\/1412933178411536384 \n https:\/\/postgresml.org\/blog\/tuning-vector-recall-while-generating-query-embeddings-in-the-database \n Haha - I'm here \n It's high quality \n Will share insights \n https:\/\/teams.microsoft.com\/l\/meetup-join\/19%3ameeting_OGM2NDU4N2QtYjdmOS00YzJmLThmZTctYTkxYWEyNWQ0OGNj%40thread.v2\/0?context=%7B%22Tid%22%3A%2243083d15-7273-40c1-b7db-39efd9ccc17a%22%2C%22Oid%22%3A%222e1cc663-be56-46e0-ab3b-b7a9f58868e7%22%2C%22IsBroadcastMeeting%22%3Atrue%2C%22role%22%3A%22a%22%7D&btype=a&role=a  \n Hey [PHONE REMOVED] [PHONE REMOVED] : For tomorrow's zoom meet-up, can you drive 15 minute of the session on 101 of Generative AI? [PHONE REMOVED] is looking for a tech expert in the session. \n Nirant is busy tomorrow. \n Hey guys. I am trying to build something with Generative AI in the advertisement space. I don\u2019t have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss. \n My name is Srinath btw. And I am a final year BTech student. \n Would love to help [PHONE REMOVED] . Dm me whenever free \n Folks, please reach out to our friend directly :) \n Thanks Nitish. DMing you. \n Hello everyone, I am Apurva. I am building a product to make content viral on social media using generative AI.  \n Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf\/image documents (text + image basically). \n Looks like all the Mohits are looking for same use case. \ud83d\ude02 \n Brilliant. We can call our library mohit then! \n Definitely \ud83d\udcaf \n Would anyone know a transcription open source or paid API that can handle hindi\/english as well as indian regional languages \n OpenAI Whisper does this off the bat \n I tried assemblyAI as well but they are expensive, are there any other that I may have missed? \n [PHONE REMOVED] should definitely be able to help! \n thanks will dm him \n Building this but for CSVs at the moment, would love to chat! \n For Hindi there are whisper models trained for Hindi from IITM. \n Deepgram built using whisper works good as well. They give $200 credit to try it out. \n You can try monster api as well \n If somebody is trying out deepgram nova vs Whisper - would love to hear results from both \n You don't need generative models for this. Converting raw text to PDFs\/images and then applying simple distortions is a very common and effective way to get synthetic data for OCR. \n https:\/\/playbook.samaltman.com \n Hey \n Will not be able to make it. \n Will you be recording this? \n Weekend fun! \n D-ID is crazy good. Any ideas on the underlying architecture? \n SadTalker is open and it getting there. Some friends are working on a project and they moved on from D-ID for SadTalker. You will need a good GPU though. \n Not so sure but this tech is around since a while. \n Not zero shot lipsync \/ animation - that's hard and has limited work \n Sad talker is arguably better... \n D-ID is very expensive if you\u2019re building a project with a pipeline to generate content on an enormous amount. \n How expensive? \n As mentioned on their Pricing page. \ud83e\udd23 \n Have you deployed and tested at scale? \n Unreasonably expensive for an api product \n We used multiple D-ID accounts to get this done :p \n They have a full fledged web studio as well. \n Yup exactly - I feel like the pricing is aligned for the dashboard only \n Right now SadTalker can generate 10min video per hour that\u2019s 2$ GPU time \n D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back. \n May be get one with nvlinks for larger runs and still it\u2019s a lot better return time for investment \n And yet has a lot of traction - good product to build. \n Any idea on what models they use? \n \ud83e\udd37\u200d\u2642\ufe0f their own. SadTalker is new and evolving. From tencent I think. \n So many things to build, so many industries to disrupt.  \n Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced \n \ud83d\udc4d  \n Only notes (as of now) \n Yes and 2$ can be brought down if doing at scale (Assuming A100) \n Margins are great for this - and competition is less. (text to talking head avatars vs rephrase ai etc). Good product to build. \n I'll take a stab at building an mvp soon \n Tried doing this back in 2019 and almost raised funding, but didn't work out \n Not sure how big is the market for this though. \n It's an evolving market. Also look at leading indicators \n Wow this is very real \n I've built this product as both an API, and also earlier (2020) as a charcater.ai type offering, and even tried to sell as nfts.  \n Hillarious stuff man \n I know how to do that :) \n That's the easy bit \n Don\u2019t you want 8 AI avatars on Arnab\u2019s show with different personalities? \n *Shakes hands* \n Thank you! [PHONE REMOVED] spent lot of time in generating the voices! \n Haha. We should jam. \n If human can generate similar kind of content, I don\u2019t think pureplay AI will sell. Human generated content is already limitless. \n It was just a joke. But AI fact checking anchor in every debate can be a nice start. \n Thinking XYZ movie in Nolan style. Or personalized standup making references about my own personal life - that might really work. \n Also if anyone else wants to jam with [PHONE REMOVED] and me, and even potentially collaborate on building this - hit me up.  \n There will be a popup after every statement then \ud83d\ude05\ud83d\ude05 \n Interested. Would like to offer something like this to creators on Koo. \n Also interested. Particularly interested in the AI Vocalist use case. \n Please do keep me posted on the jam \n Also interested in the jam in a literal sense, as I\u2019d be happy to beta test to create viral content \n Sure will make a group \n Any opensource alternative to elevenlabs? \n bark \n Anyone came across any examples\/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries? \n Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data? \n Thanks! Checking. \n Except for their officially released cloned voices, it hallucinates a lot. \n Yes correct \n guardrails released this recently \n https:\/\/twitter.com\/ShreyaR\/status\/1650883072324419587 \n cc [PHONE REMOVED] \n Looks very interesting. DMing for further help. \n Hey \n Couldn't find anything. Trying to build it in house with eventual plans to expose as API & dashboard \n [PHONE REMOVED] please build this for us! \ud83e\udee3 \n The analysis part might be outsource-able to thoughtspot \n This is what they're currently offering: \n Their responses have to be REALLY good to have people leave chatGPT and other LLMs and use these features.","58":"Bark is lit too \ud83d\udd25 \n Lyrics by gpt, vocals and music by bark! \n This is the way! \n https:\/\/github.com\/gventuri\/pandas-ai \n Anyone has found any solution to ChatOpenAI giving \"Could not parse LLM output:\" errors? \n https:\/\/github.com\/jerryjliu\/llama_index\/blob\/590639a14dd7346b7f5cc00a21dd24ce0d35ae30\/gpt_index\/langchain_helpers\/text_splitter.py#L240 \n https:\/\/github.com\/openai\/openai-python\/blob\/c556584eff3b36c92278e6af62cfe02ebb68fb65\/openai\/embeddings_utils.py#L21 \n This is what openai used in their rlhf paper - https:\/\/scale.com\/content-language \n https:\/\/twitter.com\/MisbahSy\/status\/1652479189747130368?t=l_GaFpmX5tP50AfqEut_Dw&s=09 \n I'm excited to try cohere's multilingual model somewhere.. Maybe benchmark it to NLLB :) \n basic project idea: \n shortcuts are super useful if you know what you're doing \n Most people don't use them to their full potential since the documentation is so messy \n Can be a vague, small step towards AGI for the common-man. \n Would love to get a functionality like : \"Create shortcuts to automatically change my wallpaper based on 7 images, 1 for each day of the week\" \n One of my friends set up something like that and it took him 2 full hours to get his head around it \n And even generating a step by step guide to make a shortcut should be plenty for people like me \n Any best resources for creating charts\/graphs from data, open-source \"Chart-GPT\" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives. \n Got it. Any open source solution which you know? \n are you looking to fine-tune or perform RLHF? \n RLHF on an open-source model* \n Majorly for RLHF. \n So, for the first case, let\u2019s say \n Hey ,  \n Contextual is the way to go. Tracing will allow for this. Working on it now \n Alright \n Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs. \n Any other alternative you suggest?  Let me try to increase the ram and see? \n How do I read this - how\u2019s the recall measured? \n Those details are the same as here: https:\/\/ann-benchmarks.com \n What would be the best way to implement a file search? If I have a ton of documents and I want a semantic search on top of it to solve the discovery problem, how should I go about it? One use case could be for google drive. \n Langchain has a drive connector fwik. You could use that to then do search with it's helper functions \n okay, I'll check that.. thanks. \n Nice, performance gains attributed to rust vs golang? Assuming both are using the same algo (hnsw) ? \n is the tuning of recall\/speed done by building a new index for each point on this plot, or is it tunable per query? \n This is the code outline we used:  \n Folks we are starting the Learners' discussion at 4pm - Join here : meet.google.com\/jag-jjny-owf \n Thanks [PHONE REMOVED]  [PHONE REMOVED] [PHONE REMOVED] for joining in and sharing pointers and notes \ud83d\ude4f \n I found this tool that shows a nice dashboard of costs incurred while using OpenAI api\u2019s : https:\/\/llm.report \n Thanks [PHONE REMOVED] for hosting \n Looking for feedback on a new product that I'm working on that generates design from prompts using a design system, would love to get some feedback. DM me or upvote and I will send a message \ud83e\uddf0 Thanks :D \n Are there any graphic designers in this group who are interested in learning more about using stable diffusion in their work? I'd love to talk and understand where generative AI can make the most impact in your work. And then hopefully show you how you can apply it \n This is nice. Do you know any other tool which also has per user usage tables? \n Would also love to interview product designers \u2764\ufe0f \n On that note, would like to connect to folks in marketing, specially graphic designers in marketing agencies, or if you know anyone in such agency, kindly connect \ud83d\ude4f \n https:\/\/twitter.com\/bohanhou1998\/status\/1652151502012837890?s=20 \n Haven\u2019t found any other yet","59":"It's quite public, OpenAI demos it everywhere? \n MUST get access to this tool \n The fastest way to get GPT Plugins access is perhaps to make a Twitter viral demo \ud83e\udd72 \n I have GPT plugins access, but I don't this tool anywhere in the ui \n https:\/\/github.com\/georgia-tech-db\/eva \n Any  *** flask \/ python web stack devs here for freelance? Thx! \n Dm ing. \n AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails \n I was able to deploy something locally ( followed line by line advice of chatgpt) to generate personalised DM, email + coffee conversation points for a linkedin profile as a non coder. Jason's requirement should be easy stuff for someone better. \n Link to this group? Want to add a friend \n [PHONE REMOVED] can I post an GenAI internship opportunity at Koo here? \n Posting it without really posting it \ud83d\ude0e \n I just pinged [PHONE REMOVED] ki please delete this too \ud83d\ude05 \n We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there \n Agree \n Lots of good talent here and opportunities \n A subgroup for hiring could be a great idea, keeping this group for ideas\/discussions \n How about a subreddit with flairs for hiring, news, discussion etc? \n Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also.  \n The challenge is that posting on LinkedIn has been ineffective for specific areas and GenAI has very few communities. \n Sent you something similar \n For folks interested in hiring from the community, added a Google Form here: https:\/\/nirantk.com\/community \n Why not have a diff announcement group? \ud83e\udd14 \n +1 \n Splintering off is a terrible idea \u2014 that is partially why of the last 3 groups which we've split off: Generative AI + {Art, Philosophy, Startups} \u2014 2 are dead and one is comatose \n Why is no one discussing AI philosophy \ud83d\ude02\ud83d\ude48 \n Stems from my bias since I seeded this community from my friends. I've generally been a believer that the best philosophy is action, not discussion. That is why we care about OpenAI and not say, so many other brilliant teams \n I would be interested in something that covers hiring freelancers too. \n Yeah, please add there! You can mention in the questions that what kinda freelancing role is this e.g. contractual, but recurring, project based. That is why the questions are free form :) \n https:\/\/www.youtube.com\/watch?v=FE88OOUBonQ \n Send link? \n Anyone interested in teaming up for Warpspeed? \n Looking forward to participate, hopefully this one is online \n It is mentioned that it is an offline event \n Offline, only selected candidates will be allowed \n Meta's SAM under the hood? \n Yes it's offline, please do apply :) \n Will there be selections for attending the hackathon? \n Nope, this is a custom model, haven\u2019t seen anything quite like it anywhere else \n + 1. Need more teams from this group. And winners! I\u2019m up as well to jam with anyone looking. \n Have you tried if it works when you call it from outside those notebooks? \n Ok yeah doesn't work. Interesting. \n AuthenticationError: Your authentication token is not from a valid issuer. \n Wireshark it and find if you can get the headers? \n I mean, this is just nerd-sniping [PHONE REMOVED], I feel ambushed \ud83d\ude02 \n I also want this magic api key though that I can just publish in my code lol \n playwright might be easier than reverse engineering the jupyter notebook api \ud83d\udc40 \n Sal Khan just gave another Ted, the vision reimagined with AI. As good and powerful as the first one.  \n Hinton is leaving google \n https:\/\/www.nytimes.com\/2023\/05\/01\/technology\/ai-google-chatbot-engineer-quits-hinton.html","60":"Article is biased \n His tweets are better \n https:\/\/twitter.com\/zoink\/status\/1653052807950536706 \n How are you folks using ChatGPT to learn? \n Yudbot.com \n I'm starting work on a llm vault manager to bring API level caps ($ &\/or tokens) \n [PHONE REMOVED] [PHONE REMOVED] \n also is API level cap, something that you generally try to keep? got some responses on twitter - wanted to check here too if people would find it useful \n [PHONE REMOVED] might be interesting for you \n https:\/\/www.yudbot.com\/ \n If something can cause the world harm, shouldn\u2019t  the news article be open to all and not behind a paywall \ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f\ud83d\ude1c \n If this was a political group, I'd say that this is an example of capitalism at its prime. But hey, I don't want to get banned \ud83d\ude1e \n How are you folks adding conversational memory to gpt-3.5-turbo? \n Might help :) \n I would have loved to plug Langchain here if they had absolutely anything which worked \n Could you please elaborate? Trying this out. Any shortcomings that we need to be aware of? \n https:\/\/augmented-reality-knowledge.github.io\/ \n Is this not working for you? \n Random shortcoming from the last 24 hours alone which I've seen: \n For a lot of _common_ use cases (outside of agents), it's perhaps better to roll your own then to use Langchain \u2014 and I say this as the resident Langchain fanboi of this group \n What if there are a lot of messages? Exceed 4096 tokens. \n Make an extra API call and ask the model which messages are worth keeping up \n Give an Example? \n Code flow example: https:\/\/github.com\/hwchase17\/langchain\/blob\/master\/langchain\/memory\/summary.py \n thanks! \n 1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them? \n There was a person from luma labs here no? \ud83e\udd14 \n A friend has used llamaindex for chat conversations and was satisfied \n He is in the other group created  by Nirant. \n DMing you \n [PHONE REMOVED] for chat convos how has your experience been with llamaindex? \n I know you use both langchain and llama \n Yeah I started of with gpt index but moved to langchain \n Actually I wanted to create custom tools \n My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ? \n For these use cases, Langchain is still very good \n Why Lucene\/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself? \n For storing chat history isn't llama better? Thought you had some points on this \n I have \n It gets the job done \n Those are also options being evaluated but there are company level constraints on them. \n [PHONE REMOVED] any input on the 2nd question? \n Thanks, I will DM you. \n This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase. \n It's not just about backward compatibility. It's also about clarity on what they want to do \u2014 Langchain seems to be prioritising agents, tools and toolchain around that over everything else \n True we wrote own in js stuff moved away from langchain , will open source soon once we have most basic func \n Question was around data connectors and indexing:  \n Does deforum have a commercial license? \n interesting - I've been using https:\/\/deeplearn.org\/ for this \n Has anybody tried Semantic Kernel? Do you see this as langchain alternative?  \n I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) \u2014 but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along \n Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term. \n But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest \ud83e\udd72 \n yea! heard they raised another round already (not sure about the source though) \n Why though? \n I frankly don\u2019t see any llm abstraction library really working out in the near term. Its like writing a C compiler for a changing chip design and Instruction set before x86 \n API design has little to do with community traction I'd believe \n Say more, I don't understand you \n Fun analogy, but the x86 is GPT4 no? \n Gpt is the processor, instruction set is the prompts \n MSFT is the fastest moving startup in his new world IMO \n Reminds of the SaaS joke I've made since 2019: All B2B salesfolk work for Microsoft, only some know it \n I love how one man Satya Nadella has changed that perception over a few years, completely \n Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more. \n https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/gpt_index\/prompts\/default_prompts.py \n langchain is buggy as hell also. \n this is gold! \ud83c\udf1f \n Thanks! Will DM. We\u2019re doing something similar - a simple moving window of 500 input tokens. \n fwiw we've been using llama index in prod for two weeks now doing around 500 questions on the company docs daily \/ no issues \n Please, can we make a simple colab notebook that has best practices of implementing rolling windows contexts? \n I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because \"this is the first thing I said!\" \n maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio \n What about summarisation? We\u2019ve tried calling the openai summarisation API to summarise the prev chat but it\u2019s slow af \n We need some inside info on how chatgpt is doing this \ud83e\udee3 \n OpenAI has a summarisation API? Didn't they deprecate that? \n Prompt engineering helps there. Think of your usecases as bucketed modules. Don't use a one size fits all prompt, but smartly create prompts that can preserve needed info. Has been working well for our usecases \n Openai once suggested to us in 2020 to use a smaller and faster model for summarisation here, wonder how well that works \n It's a trade off, experience vs expense. Have to take that call based on your product. \n use gpt-3.5 only, prompt it well, keep temp low. \n Had worked on Lucene (query side) and written custom rankers in Solr etc. But not worked with OpenSearch. It's been a while. \n [PHONE REMOVED] \n Would this be of help? It creates a running summary of earlier conversations while also retaining the latest n interactions in their richer form. \n Folks - I know the creator of https:\/\/42papers.com\/, artcompute.com and more importantly mindsjs.com \n I think we might have the answer why LangChain is so focused on tools and agents  \n Using tools and agents with LangChain officially part of OpenAI cookbook \n Also a very basic question for anyone who can help  \n You mean executing untrusted code from an LLM? \n Python environment can be sandboxed ? \n Also not an agent like AutoGPT\/BabyAGI \n Doing so in production at a decent scale \n Awesome. Would love to talk. Will DM you","61":"What\u2019s the scale? \n https:\/\/twitter.com\/samim\/status\/1653289578390749186?s=46 \n Done \u2705  \n Nice \n GPT4 creates a vector DB: https:\/\/twitter.com\/AlistairPullen\/status\/1653459578229788672?s=20 \n Replit open source LLM just dropped. Its released under CC BY-SA 4.0, which allows for commercial use. \n is this what powers ghostwriter? \n https:\/\/twitter.com\/grimezsz\/status\/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA \n Looks like he also called it out on his pod https:\/\/www.youtube.com\/watch?v=WBgrfWW8xxA&t=2095s \n Finetune on instruction dataset curated from geeksforgeeks \n https:\/\/twitter.com\/pirroh\/status\/1653586734641471490 \n Prompt Injection in less than 10 minutes (video, slides, transcripts):  \n Also the very fun follow up article to why you can\u2019t use AI to fix this \ud83d\ude02 \n Anybody applied for the OpenAI service on Azure? \n Got ours withing a couple of days \n JSONFormer: https:\/\/github.com\/1rgs\/jsonformer \u2014 guaranteed JSON output with Huggingface LLMs \n cc Ankita [PHONE REMOVED] is from Microsoft Azure India \u2014 can reach out to her directly \n Why would you do that? \ud83e\udd23Sorry ankita be ready to be bombarded with api requests \n Please DM me - happy to help \n the approach looks very promising! \n DeepFloyd or Multi-ControlNet? \n Abstract artwork I made using stable diffusion. Abstracts are hard to conceptualize and compose but they're a lot of fun! \n Neither \n Custom trained checkpoint, good use of prompts and neg prompts, inpainting, upscaling. And several iterative loops with tweaks in each interation \n Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt \"impressionism oil on canvas painting, thick brush strokes, palette knife technique\" \n It was used in the prompt of several of the iterations used to make this \n Is there a model (other than gpt4) that can extract info from a image in JSON format?  \n What kind of info? \n Basic OCR should be able to do that, unless you want only some part of the text \n Does anyone know anyone who has access to multi-modal gpt4? \n That\u2019s true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt. \n I feed it search result cards from any website and it gives me extracted data with {fieldName: value} \n Yes! That\u2019s so true \n Infact, we can extract values without OCR as well. HTML contains most of the info anyways. \n [PHONE REMOVED] check if this can help \n Thanks. But I think it's solving a different problem :( \n https:\/\/www.spellpage.com\/?utm_source=bensbites&utm_medium=newsletter&utm_campaign=pi-the-new-ai-on-the-block \n autogpt app \n A schema of the output json would help \n It should depend on how the clip model used to create  captions describes the image \n If these result cards are in tabular form, table-transformer might help. https:\/\/github.com\/microsoft\/table-transformer \n haha, been there! \n Hey folks, can you help with the group invite link? (Can't find it in description) \n No issues at all \n Sorry for delay in response earlier \n Have worked on this before. This kind of information is hard to parse in general case (sometimes value can be left of field or right of field, the field and value both can be non regex-able etc). Is there strong geometric structure or is the layout confirming to some standard (think specific bank forms etc). If not folks train specific models to extract these for specific class of documents. Little busy for next day or so, if not urgent message me and happy to chat later. \n Has anyone tried langflow here? Please DM if you have, thanks! \n https:\/\/techcrunch.com\/2023\/05\/03\/where-is-india-in-the-generative-ai-race\/ \n https:\/\/www.latent.space\/p\/reza-shabani#details \n interview with our head of ML and swyx \n While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,\u201d said analysts at Sanford C. Bernstein. \n Chris Lattner's new ML focussed language \n [PHONE REMOVED] - is working on this. More from him. \n Amazing. Would love to connect and contribute. \n https:\/\/crfm.stanford.edu\/ecosystem-graphs\/index.html?mode=table \n I would also like to learn more and contribute in this project \n I think the entire article can be summarised in 3 sentences -  \n Yes, keen to learn more! \n Can someone add the author Manish Singh from Tech Crunch to this group if they have the number https:\/\/twitter.com\/refsrc?s=21 \n We have coders, designers, PMs and VCs here but any journalists or media folks? Please say hi! \n Asking \n Hi Manish \ud83d\udc4b\ud83c\udffb \n Thanks for adding Aakrit -- good to be here \n Good to see you here [PHONE REMOVED] \n Good to see you here [PHONE REMOVED] \n Yes","62":"Glad to be a part - thanks for adding me [PHONE REMOVED]  \n Good to see you here! \n Oh hi haha! likewise :) \n https:\/\/twitter.com\/alexwan55\/status\/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19 \n any model (large language or not) with many parameters suffers from the curse of dimensionality and it is fundamentally impractical to cover all modes of adversarial attack \n arrey hey rahul \ud83d\udc4b! \n There is an opportunity here to create artist focussed digital painting tool using GenerativeAI, right now you are hacking with automatic1111, recursively using the output as the next input, using Photoshop to do what's not possible in automatic etc. \n Hey folks, does anyone in this group have experience creating large scale datasets for llm model training? \n How large? I processed around 300GB for https:\/\/huggingface.co\/aashay96\/indic-BloomLM \n 300gb is large enough DMing \n Folks, I feel openai\/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline. \n cc [PHONE REMOVED] [PHONE REMOVED] would be great to hear from top of my head \n Can you please look at https:\/\/github.com\/EleutherAI\/lm-evaluation-harness as well? [PHONE REMOVED] \n Doesn't have qdrant, Weaviate \u2014 has the same libs as earlier, only adds Vespa as far as I can tell? Did Erik choose to wait for Weaviate feedback? \n Would love this \n A very interesting question to ask would be how does OpenAI do on the lm-evaluation-harness, and what does openai\/evals which the harness does not? \n Unfortunately the whole pipeline is hugginface based. Would require a lot of rewrite \n \u201cTo now be relevant as a SaaS co, depth+breadth of workflow is going to be more and more critical. Point problem solutions will find it harder to establish why they capture value\u201d. . Good set of thoughts pinned by [PHONE REMOVED] \n yep, was wondering what the choice for libraries was.. Redis seems to be doing very well though \n Already building this artist\u2019s tool \ud83d\ude09 \n Oh nice \ud83d\udd25 \n HF <> Inferless ([PHONE REMOVED] ) on deploying GenAI models meet-up on June 10th. \n Thanks for the shoutout Ravi! Folks, please share what all would you like us to cover specifically around model training and deployment.. I am all ears! \ud83d\ude03 \n Folks - I know the creator of https:\/\/42papers.com\/, artcompute.com and more importantly mindsjs.com \n Hey folks - Vikram is excited to have a session.  \n Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before. \n I believe Soumendra [PHONE REMOVED] was giving it a shot \n What do you mean by your own vector embeddings? \n How are you generating them? \n Thanks for responding. I am not using any of the prebuilt vectorizers. \n with client.batch as batch: \n cc [PHONE REMOVED] from RestOfWorld is here. He's also quite comfy with Midjourney and ChatGPT based apps. \n Here the embeddings are my vectors generated thru Sentence Transformers  [ choose  your model ] \n Example : from sentence_transformers import SentenceTransformer \n embeddings = model.encode(Lines) \n What does the search query look like? \n result = ( \n See the near_vector please \n Moving this to one-on-ine as this is going to get technical \n Yes that's better \n Can you DM me output of print(result)? We'll take it forward from there. \n Maybe try reducing \"certainty\" to 0.7 and see? \n How one can achieve multi-tenancy in Qdrant? \n Thank you ; reduced further still no luck \n +1 have the same question about vector dbs \n I have used Faiss and Milvus (via Haystack) for personal projects very long time ago. Used to create create separate collections for different type of datas. As that time filters were not common in these vector dbs. Now like to understand is there other better way, ideally separating storage from query layer. \n Yes, separate collections is perhaps the cleanest way?  \n For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J \n https:\/\/github.com\/unum-cloud\/usearch \n From NimbleBox folks in India, [PHONE REMOVED] and friends \u2014 low-code for making chat experiences in particular: https:\/\/github.com\/NimbleBoxAI\/ChainFury \n Thanks for the shout-out Nirant \ud83d\ude4f\ud83c\udffb\ud83d\ude0a \n I have done this.  \n What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale \n Hi everyone,  \n Average out the embeddings for the document \n Are you predicting related keywords for a given text and then clustering somehow ? \n For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved \n Shyam, a few details which will help us answer your question better:  \n Could you describe your approach ? \n Example, if the user is prompting 'x of 10%', but the data point has the absolute value of that variable, then some logic will be needed. \n We don't implement the matching, because the prompts are varied as I mentioned, we are directly feeding the data and prompt to gpt-3 \n Is there a reason for using text-davinci-003 and NOT gpt3.5-turbo? \n 1. No, just the GPT-3 endpoint. \n No reason, have to try gpt-3.5-turbo and compare results \n Any links\/readings to understand this in detail? \n Thanks ! Can you also please share the invite link for this group \n https:\/\/huggingface.co\/gemasphi\/laprador-document-encoder \n Has anybody used langchain or llama index for hybrid embeddings? I was looking through their code to find what they use for sparse embeddings. Llama seems to use BERT and langchain I couldn\u2019t find \n The error was the Vectors were not inserted properly. The correct code [ highly simplified is here] \n with client.batch as batch: \n Vector =  < Place your VECTOR embeddings here> \n Llama Index has extensible Retrievers, so shouldn't matter either way no? \n Thanks to  Soumendra @+91\u00a074980\u00a076111  for trying yo help me \n Thank you for your interest. I used simple Python and Weavite librarues \n Thanks Sharding is another good way. \n Ah got it. So BERT was just an example \n Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use. \n cc [PHONE REMOVED] was a Haystack contributor :) \n Yeah, Llama Index has decent Retriever design. Some Custom examples: https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/examples\/query\/CustomRetrievers.ipynb \n I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty? \n Ease of use, right place at right time, became viral too fast before people even knew about alternatives \n Once the GitHub stars started picking up everyone's eyes were on it. \n Haystack is much better in code quality and documentation imo. \n Chatgpt helped as well, probably they rode that wave, may be haystack didn't treat chatgpt as urgent requirement \n Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain. \n I mean there is overlap between both \n indexes feels like semantic search interface - https:\/\/python.langchain.com\/en\/latest\/modules\/indexes\/getting_started.html \n Thanks, this discussion helped understanding strengths of langchain and\/vs haystack \n yeah, just discovered this: https:\/\/docs.haystack.deepset.ai\/docs\/document_store because of the discussion here. I was thinking of creating a similar abstraction layer (i.e. provide a single API for vector DBs, allowing any VectorDB to be plugged in), but I might just depend on this now \n True. Apart from code and documentation. Haystack is very good in design. Just check how haystack implemented PromptNode and compare it with Langchain. You will see the difference. \n \u201c This approach is the most flexible, but creating numerous collections may result in resource overhead.  only recommended to separate users into multiple collections if you have a limited number of users \u201c \n Agreed. And the vector store abstraction too. Granted it's not perfect, but flexible enough to mould it the way we want. \n 100s should be pretty fine from what I've been told internally \n 100x100 na \n Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build. \n fwiw, all FOSS Vector DBs offer cloud solutions so that you don't have to think about cluster sizing, managing servers, sharding and  problems like what [PHONE REMOVED] just mentioned \n Build vs Buy \ud83d\ude04 \n Vitess is a great tool. \n For folks wondering: https:\/\/vitess.io\/ is a tool for sharding \u2014 and here is a good primer for what sharding means: https:\/\/aws.amazon.com\/what-is\/database-sharding\/ \n Have y\u2019all heard of Modular? Chris Lattner\u2019s (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication  \n https:\/\/planetscale.com\/ does managed Vitess as well. We were exploring it at Razorpay. \n Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years. \n How did Razorpay end up doing sharding? \n Not being open source at launch was a weird choice...  Can't remember the last time a language launched like that... \n We didn't go ahead in the end. \ud83d\ude05 \n Jeremy was a strong proponent of TF Swift as well. But that hasn't seen major adoption even inside G so ymmv \n https:\/\/open.substack.com\/pub\/semianalysis\/p\/google-we-have-no-moat-and-neither?r=2gao6&utm_medium=ios&utm_campaign=post \n (from the above article) \n Why do I think this graph is on a log scale \ud83d\ude05 \n Hey, i wanted to understand the difference between generative pre training vs instruction tuning in terms of huggingface trainer class. How does the training objective change? \n This is using gpt4 as a judge having it rate llm outputs \n https:\/\/lmsys.org\/blog\/2023-03-30-vicuna\/ \n \u201cAccording to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.\u201d \n Exactly! \n Maybe we run openi evals on it :) \n This eval doesn't make any sense to me. Already LLMs capabilities to produce such ranks\/marks are highly debated to it's stochastic nature. It's like a teacher that gives a different score each time when she evaluates  answer from a different room \n Yea... independent and good benchmarking of AI needs to be a thing... \n LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that. \n just to add one more point, alpaca and vinuca are LLAMA derivatives so I don't think it can fit in that graph since they aren't new base LLMs. Also I don't think its good idea to train models on chatgpts output like Alpaca did, if you're curious about the reason:https:\/\/twitter.com\/Shahules786\/status\/1650898925178720256 \n Benchmarking has this weird dynamic of very useful for industry and their labs, but gives no glory to people who make them \u2014 so it doesn't attract hackers or academics.  \n Sure... at the research level some objective ones will help but also at the consumer and solutions level... We have a full tech gadget review industry... A similar AI review industry is needed...  This impacts everyone and everything now... \n Need a rtings.com of this space... \n That is exactly how ImageNet was born fwiw, and Stanford DAWN Bench and so on. \n This is the exact problem with building a tool for Devs \ud83d\ude05 \n Most devs actually have the highest buying power in any organisation. If a developer says they need to pay 100$\/mo to keep their database up, that\u2019s a bottom line for a business \n Devs are the end consumers \n Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM \u2014 I'll resist the temptation since this is already off topic for a Generative AI focussed chat \ud83d\ude05 \n We should jam separately on this, very different problems and implications :) \n yeah. fastai was also going to build a tf swift version i think, but all those projects kinda got abandoned when Chris Lattner left Google. \n Generative Pretraining is the default \"GPT\" training objective, I'll let you dig this up on your own. If you don't mind reading papers, the original Radford et al is still relevant for this.  \n On a concept level I understand the difference, but while training it, is there a difference? I checked databricks dolly script - https:\/\/github.com\/databrickslabs\/dolly\/blob\/master\/training\/trainer.py \n For wider audience, the code interpreter is largely a Python REPL and a GPT4-fork finetuned on Python\/code. This is not a separate feature or anything like that.  \n Difference in outcomes or syntax\/code which we write? \n Syntax\/code - essentially the training objective \n Going out on a limb, but I'd like to think that they should be identical with different configs \u2014 finetuning and training objectives are often kept identical these days \n Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop? \n Yep. Code interpreter is quite useful.  Threw a csv I had at it and it saved me at least an hour in data clean up if not more... \n Chatgpt code interpreter and gpt-4 browsing models are more useful than I anticipated. \n Guessing \u2014 stop word markers in the instruction dataset? \n Are there specific communities\/ influencers to follow for generative AI content on Twitter ?I see a lot of content across all groups from Twitter hence asking here \n DM'd my list \n https:\/\/crfm.stanford.edu\/ecosystem-graphs\/index.html?mode=table \n https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/137ex2j\/controlnet_tile_can_generate_details_for_each\/ \n Does anyone have experience working with GPT4 for coding in Rust\/working with libraries? GPT-3.5 is quite terrible, so wanted some insights on whether GPT4 is any better \n If it turns out to be as great as they are claiming, I\u2019m sure someone will build and release open source version of Mojo soon, like OpenMojo etc, and it may create pressure on them. \n Yeah, you train on( instruction+prompt, output). So the system learn from those instruction what the stop points are to some degree. But the real challenge is \"how do tell these specific words really messed up\". Here is where you do RLHF. Let me try to find some resource to explain this. \n I need to see a training script \n Doesn't the dolly one do. \n For all thos who asked me earlier and I couldn't find the original resource. This a great one from Stanford. Explains big picture of pretraining, fine-tuning and RLHF. https:\/\/web.stanford.edu\/class\/cs224n\/slides\/cs224n-2023-lecture11-prompting-rlhf.pdf \n One will need to deep dive into each of those areas for more details. This is big picture intuition. \n asking without asking part-2 \ud83d\ude02 \n https:\/\/twitter.com\/pbteja1998\/status\/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08 \n Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though \n There are other differences:  \n StarCoder is open that their model is GPT2 \u2014 so all GPT2 tricks, scripts will work! \n Really interesting read from Simon Wilson on moats in closed source models quickly disappearing: https:\/\/simonwillison.net\/2023\/May\/4\/no-moat\/ \n https:\/\/blogs.microsoft.com\/blog\/2023\/05\/04\/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge\/ \n If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ? \n 1. LM-evaluation-harness for Huggingface compatible models: https:\/\/github.com\/EleutherAI\/lm-evaluation-harness \n I've not had a chance to try Dolly and OpenAssist yet, but GPT-JT (https:\/\/huggingface.co\/spaces\/togethercomputer\/GPT-JT) is definitely comparable to text-davinci-003, which was their claim. \n And I am honestly surprised that they were able to get this far by careful training data selection and training\/finetuning params \n new model? \n Together are the ones behind redpyjamas right? \n I think it's a bit old? Dec 2022\/Jan 2023? \n Yes, I believe so \n okay \n https:\/\/twitter.com\/lmsysorg\/status\/1653843200975704069?s=46 \n seema perfectly reasonable","63":"Having tried all the models from Google, I fully agree they have no moat. \n You think OpenAI has no moat either? \n Community \/ dev side NFX is there \n Also early mover is a real advantage for them. All that gets built\/is getting built right .. tough\/lethargy to rewrite\/rewire \n NFX? \n Network Effects \n Network effects \ud83d\ude48 \n Of course not, which is why I pointedly talked only about Google \ud83d\ude00 \n Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough. \n I don't think community\/nfx is a moat here. Look at what happened to tensorflow. \n I think even if open source becomes comparable or even more effective, the possibilities of building a business does exist.  \n OpenAI's moat comes from aligning with MSFT\/Azure. Government and finance domains are essentially theirs for the taking. \n And the pace at with they can onboard other businesses on plugins- like uber, expedia \n That will take a while to mature, finance sector is where they'll make the big bags for now \n esp now that they have solved EDA with code interpreter \n This seems a bit panicky. It's not difficult for big tech to integrate oss stuff back in. They'll most likely wait a while to see what works best before integrating and releasing into products \n have u guys tried out the code interpreter? is that on the waiting list right ? \n With 3 million software devs in India second only to the US's 4 million, not sure about china numbers. I think the open source implementation may accelerate faster than commercial models.  \n Not that I disagree. But as the terrain stands currently, (and please correct me if I'm wrong), all major oss developments in LLM (alpaca, llama.cpp etc) built on top of llama. It cost 30M to train that. I don't know how much we can replicate that in OSS. \n Perhaps works like Bloom could prove me wrong? \n Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs. \n Man, MSFT under Nadella is gonna be a business school 101 case study in a few years. He's trying to commoditize their complement: https:\/\/gwern.net\/complement \n Not sure if someone shared this here, but super interesting\/scary (also expected): \n The nearest neighbors will fall first. Further away from it, less chance of being destroyed by the fast-moving train. \n https:\/\/www.semianalysis.com\/p\/google-we-have-no-moat-and-neither \n Hello awesome people. Missed a week (feels like a decade). \n wish there was an llm-summarisation hooked to this chatbox for the purpose, lol \n Hugging face just launched StarCoder LLM \n You know this group became so big and intractable when you see the same article being shared 5 times in the past 100+ messages. \ud83d\ude05 \n The Google doom story is about 6mo old, if they get their acts together, they can turn the tide as they still have their distribution intact \n Anyone using bharatforAI translation in prod? It seems to very require large server instances. Would love to chat if anyone has \/is using \n Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up: https:\/\/docs.google.com\/presentation\/d\/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU\/edit#slide=id.g20f09001284_0_76  \n Is there any good article with all available SoTA large models in multimodal space (text, image, video, audio, etc) \n I'm afk, but look up Amazon's mm-CoT on HF and explore tags from there. Similar for PapersWithCode. \n HF is huggingface.co \n we are getting alternatives now \n Does anyone know if the probabilistic functions in generative models are truly random or deterministic? \n Can you elaborate on what you're trying to understand? This phrasing is hard to understand \n if you are talking about RNGs then they are psuedo random and can be controlled via seed \n although don't expect same results across devices (chipset) \n What's the difference between gpt-3.5-turbo and gpt-3.5-turbo-0301? \n gpt-3.5-turbo is a \"brand\", it will change under the hood when the _next version_ of gpt3.5 comes out.   \n got it thanks \n The encoder takes in a sequence of input tokens, the decoder needs to generate\/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence.  \n as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over? \n I think they've shared rate limits, but if they do separately -- yes \n Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem.  \n Does it work that way? Or rate limits are key based \n so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)? \n Sure \n Yes, but there is always some non determinism with GPUs. \n In GPT, the randomness comes from the probability distribution over the vocabulary right? Is there a way we set top-k\/top-p values though the chat interface? \n What are some good tools for creating and managing prompts? \n Does anyone have resources around how to do chunking while creating code embeddings? Also, pointers to the best open source model for code embeddings would be great. \n Noob question: Can Meta's SAM (Segment Anything) and Track Anything - can be utilised for tracking logos from the video?  \n Yeah. Should work out of the box \n What are the best tools\/repos to replicate the AI songs like the ghostwriter ones (drake wala) \n on the same chipset, yes, as long as all software versions are pinned down to the lowest levels including the os and kernel \n So-vita-svc, afaik \n https:\/\/agi-sphere.com\/llama-models\/ \n so-vits-svc \n Would be interested to know what artist you\u2019re replicating \n Also, it would be a fun get together for anyone trying to make a song, I know I haven\u2019t taken an initiative here, but would be thrilled to jam with anyone who does \ud83d\ude42 \n There was a sheet here with a list of fine-tuned models - anyone have it? \n [PHONE REMOVED] \n Can you share a link plij? \n I've heard good things about this \n Hi \n Well that so-vits-svc models sheet is deprecated now (obviously because decades have passed \ud83d\ude1b) \n I want to train on Arijit's voice but I'm quite occupied these days :') \n ++ \n https:\/\/discord.gg\/aihub a lot of models here. It\u2019s 7000 people big and people say all kinds of stuff there. [PHONE REMOVED] did an amazing job of keeping this community focused and productive for this long, everyday I am blown away looking at the cutting edge work you\u2019ll are doing. \u2728 \n https:\/\/www.mosaicml.com\/blog\/mpt-7b \n SlackGPT \u2014 multiple business workflows, horizontally integrated with Slack.   \n Might have to rename it, gpt trademark \n salesforce v openai soon \n Salesforce vs Microsoft \n Also didn\u2019t Slack partner with OpenAI for this ? \n They are able to generate 84k tokens on a single A100 GPU by finetuning base model of 2k context length to finetuned model with context length of 65k. \n Just used for a few prompts that I tried for ChatGPT (GPT4), still a long way to go. I used mainly used code snippets and asked questions around it. I wasn't able to get  answers and abruptly stopped giving responses mid way. \n Which checkpoint did you use ? + it might not do that great with code understanding as it is trained only on 135B tokens from the stack. \n This one `MPT-7B-Instruct` \n I will also try it. Would be interesting to generate 6th book of GoT series as George RR Martin might never write it \n Taylor Swift singing a kannada song :D \n I genuinely want to try out The Weeknd singing Arijit songs \ud83d\ude2c \n Not sure if this has been shared \/ discussed before (since I joined late in this group), throwing it here.  \n https:\/\/wandb.ai\/site\/prompts","64":"https:\/\/huggingface.co\/spaces\/mosaicml\/mpt-7b-chat \n A very good post on what transformers are for some of us who are getting started and others who just want to deepen fundamentals. \n Luis Serrano and Jay Alammar - Cohere has two of best ML content creators ever. \n Hi. Anyone wants to join an already formed awesome team in Warpspeed GenAI hackathon? We have one open slot! We would love to have you. \n Does anyone have\/made a list of top AI themed newsletters?? \n I followed a few but found this the best bensbites.co \n checkout 42papers.com \n That's Twitter but worse because almost everything there is already from https:\/\/twitter.com\/_akhaliq \n These are the one's ive found quite useful: \n New open source LLM, better than Llama, commercial use allowed \n \"The 7B model is still training (at 800B tokens) and we see the training loss still decrease consistently. As a result, we will continue to train it to 1T tokens.\" Fascinating that models will start to touch the trillion mark! \n No. There are two ways to make it deterministic (this is not including RLHF magic, any fine-tuning magic etc, don't know what all they have here) but both with different behaviours. One by setting temp=0, here you are forcing softmax to select the top word pick, so this degenerates to greedy though you are sampling. Thus will have issues being it taking the most frequent word combinations. \n The other by setting seeds. This still allows you to 'actually'  generate using top-p\/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable\/deterministic, you don't need to always go to zero. \n Pro Tip for anyone trying to pursue this line of reasoning and looking for first hand experience: Take a GPT2 or BLOOM model and try to get consistent outputs \u2014 you'll develop a very good mental model of what it takes to get a deterministic output. \n Hey everyone, Chirag this side from Endiya Partners, an early stage VC. Happy to be here!  \n https:\/\/huggingface.co\/spaces\/Geonmo\/laion-aesthetic-predictor \n Might have a better time just running clip interrogator and just asking gpt for a score from that genenrated caption \n Hallucination and determinism (the above definition of it, same output for same input) are not that related. Hallucination is largely an after effect of model learning patterns that aren't true, in the weights so to speak. The determinism issue is largely a final layer problem (and may be fine-tuning layers). As in how you select from most  reasonable walk amongst series of words choices (you essentially have k-ary tree starting from first word). Another meaning of determinism could be whether it could generalize well (minor perturbation of input don't lead to change in output), this is very related to hallucination and both are related model weights. \n I don't think this is doing human profile scoring per se \ud83d\ude00. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating. \n [PHONE REMOVED] sir would you like to explain AVA and image dataset curation methods\/conventions \u2014 lot of folks here are not from Vision in particular \n It is pretty bad at scene scoring too unfortunately. Only the examples they've shared score well. \n Sorry, my bad. This is for the problem of Visual Aesthetic Scoring that is given a set of pictures, score pictures from interesting to least (think flickr interestingness if you know what that was, like what photos you will want in your album or showcase your photography talent). There were bunch of datasets created for this, AVA was one of those, I think curated from DPChallenge with score and sematic tags for each image. \n it's ranked based on likes etc not from a specific person also each paper is has a short summary as well as why it's important basically designed for a daily quick scan \n which part is worst always improving so happy to learn \n https:\/\/github.com\/mosaicml\/llm-foundry\/tree\/main\/scripts\/eval \n there needs to be a standard that everyone can use. Was hoping HELM becomes that \n Any good library references to create datasets for LLMs? Say, training Vicuna\/Dolly 7B\/13B on a domain. I want to replicate what BloombergGPT did in finance but for a very specific bucket in finance. Also, any way to estimate infra cost for suchs training and hosting? \n Given a prompt, and a set of generations from the prompt, example, if the prompt is \"black and gold colour scheme, blue sky, white mountains, red house,... \" and 10 images are generated, is it possible to rank the generated images based on how well the prompt was followed? \n Additionally, given that there are numerous generations where there are small issues, for example, extra hand in one, incorrect tshirt representation in another, is it possible to auto build a workflow, which figures out where the image is incorrect , masks it, and sends through another generation to fix that area?  If so, what would be required for it to detect errors in the image? \n Reply with: DM me \ud83d\ude02 \n you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service. \n Could be a growth hack as well \n Are you a dev? Because you just pulled a \"It's a not a bug, it's a feature\" \ud83d\ude02 \n No that is a different problem altogether. The above one is a very visual problem, doesn't depend on things like semantic meaning or the implications of those as much. So for example, it will rank the fanous Henry Cartier Bresson's Leap into unknown photo (this photo's context is Europe entering world war 2) poorly. The visual aesthetic problem to a decent degree is sort of solved. Many models are production use, where you can remove human time required. But this problem requires more understanding of real world (like humans have 2 hands etc). So training on that dataset probably won't work as well. I think [PHONE REMOVED] and others have worked on this more. They can chime in on what works. \n I mean, large scale deployments are common for Visual Aesthetic scoring, where revenue numbers can be impacted if you do poorly. \n Is it possible for a visual QA model to identify errors in a picture, if we use \"errors in the image\" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections? \n I am asking more from a workflow, rather than one model doing it all. It would be difficult to make it work using a single model. \n this seems like a task for andrew ng's https:\/\/landing.ai\/ \n Any open source suggestions? \n Could you expand a bit on errors, what kind of errors are you expecting, like logical, or edited in errors? \n Oh I just saw the above messages, you mean errors between the prompt and the images. \n a naive idea that comes to my mind, is divide the images into multiscale patches, embed with CLIP and then check similarity with the prompt. \n The issue with this is that if the hands were incorrect, it would still return hands. \n Discussion on HN about Langchain \n similarity of the string \"hands\" will still be less for it, compared to a good set of hands, is what I am hoping.  \n Any idea how much time does it take to get access to chatgptplugins? \n Thanks, I'll check. \n Is there any usable finance gpt yet? i.e., trained on yahoo finance or something? \n Bloomberg gpt.. but it quite expensive \n they\u2019ve released a product? Last I knew it was a paper \n I think they released it into their terminal \n someone was finetuning gpt with yahoo finance in this group? \n https:\/\/llava.hliu.cc\/ \n There\u2019s an open source alternative to Bloomberg terminal called OpenBB. They released a blog on how one can train on their documentation to get the appropriate OpenBB command  \n I'm starting to look into the autonomous agents space \n https:\/\/www.mattprd.com\/p\/the-complete-beginners-guide-to-autonomous-agents \n i built something for myself along these lines much simpler and no dependencies \n https:\/\/github.com\/dosco\/minds","65":"OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of _safety reasons_ \u2014 as they've hinted in the past, , but because of competitive reasons. He believes models can be improved to the point _in future_ where it becomes a safety concern.   \n competitive reasons aka MSFT in simple words"},"wc":{"0":666,"1":84,"2":721,"3":67,"4":28,"5":141,"6":71,"7":52,"8":9,"9":119,"10":36,"11":496,"12":807,"13":249,"14":295,"15":696,"16":142,"17":687,"18":1909,"19":354,"20":365,"21":349,"22":279,"23":76,"24":1706,"25":517,"26":1323,"27":1602,"28":618,"29":42,"30":139,"31":132,"32":344,"33":1483,"34":2050,"35":1193,"36":615,"37":1523,"38":756,"39":747,"40":1756,"41":2006,"42":613,"43":773,"44":1880,"45":2274,"46":1971,"47":2151,"48":1160,"49":1077,"50":589,"51":899,"52":1635,"53":2357,"54":1747,"55":1435,"56":1367,"57":2068,"58":610,"59":614,"60":1225,"61":702,"62":2551,"63":1366,"64":1370,"65":54},"Summary":{"0":"## Introductions\n- Members introduce themselves and their backgrounds in AI, ML, and related fields.\n\n## Projects and Startups\n- Pranjal Mehta talks about his electric plane startup, ePlane.ai, and his interest in building in GenAI.\n- Nirant K works with startups building in ML.\n- Kush is running Corp Dev for Glance & InMobi and is interested in seeing Generative AI innovations in the market.\n- Pranav leads Peppertype.ai and has been closely working with Gen AI and its applications in content and marketing for the last 2 years.\n- Sachin is the founder of IntelLawyer.com, a search engine of case laws, and has previously worked as an RL engineer.\n- Amogh is tinkering on a project in generative AI called Youstick.fun, which lets users create fun stickers using their photos.\n- Rahul Sundar is a PhD student interested in teaching the science of any underlying problem to machines.\n- Parth is a VC at Venture Highway and looks closely at the Applied AI space.\n- Anagh from Accel has been working on AI investments for 3ish years and used to build ML models in the pre-transformers era.\n- Naman from Stellaris VP looks at AI and SaaS investments.\n- Shashwat is working on an AI-based learning and development tool and is primarily interested in recommendation systems and building one for generative media consumption.\n\n## Topics Discussed\n- Creating a full anime with SD.\n- Building agents to play games and trade stocks.\n- Generative AI's applications in content and marketing.\n- Using generative AI to create fun stickers.\n- Teaching the science of any underlying problem to machines.\n- AI investments in the Applied AI space.\n- Building recommendation systems for generative media consumption.\n- Making video shots with RunwayML.\n- Computer vision and 3D reconstruction.\n- GANs in voice generation.\n- RL, Computer Vision, and NLP techniques.\n- SciML, AI4Science, PhysicsInformedML, theory guided ML, etc.","1":"## ChatGPT API Launch and Updates\n- OpenAI provided an update on ChatGPT and Whisper API.\n- A Twitter user shared a link to the ChatGPT API launch.\n- A user mentioned getting controlnet working in a satisfactory way.\n- Someone asked about deploying gpt-3.5-turbo on production apps and how it performs at scale.\n- Another user replied that it is mostly stable but may require retries with exponential backoff.\n\n## Corridor Digital's Anime Creation\n- StabilityAI shared a link to a tweet about Corridor Digital's process for creating anime using SD VFX and Blender.","2":"Generative AI:\n\n- GoogleAI's new Flan-UL2 20B is out\n- Discussion on compute required for good\/useful throughput\n- Comparison with chatGPT API in terms of cost and data localization\/compliance needs\n- Need for specialized models and configurable\/finetunable base models\n- Two interesting articles from a16z on generative AI platform and everyday AI for consumers\n- Links to personal articles on generative AI product strategy and AI products arms race\n- Discussion on fMRI to SD research from Japan and its limitations\n- Personal experience with off-the-shelf brain devices and noise in data\n- Use of fMRI data for cleaner and more interesting analyses\n- Request for resources on using SD for designers and artists\n- Recommendation for Automatic1111 for using SD with plugins, but requires GPU and technical setup\n- Excitement over possibility of getting actual footage of dreams\n\nMiscellaneous:\n\n- YC Founder talks to YC Partner in YouTube video","3":"## AI Bot Code\n\n- The group chat mentions that the Hasura AI bot code has been open-sourced and can be easily deployed with one click.\n- They share a link to read more about it on https:\/\/theresanaiforthat.com\/.\n\n## AI Art\n\n- The group chat discusses Offset Noise, which is apparently heating up AI art.\n- They share a link to a tweet from MetaAI about it: https:\/\/twitter.com\/MetaAI\/status\/1631351811696394240?s=20.\n\n## Purchase Parity\n\n- One member of the group mentions that the person behind Offset Noise is also running purchase parity, which they feel most products miss.\n- No further context or information is given about what purchase parity is.\n\n## AI Movie\n\n- The group chat briefly discusses the idea of an AI-themed movie, similar to Her but with a couple and a twist.\n- No further details or context are given.","4":"## Introduction\n- Anirudth introduced himself as an Applied Scientist at Amazon\n- He expressed his excitement about generative AI and looking for new opportunities\n\n## Generative AI\n- Discussion about the potential of generative AI in various fields such as art, music, and literature\n- Mention of OpenAI's GPT-3 and its capabilities\n- Sharing of articles and research papers related to generative AI\n- Discussion about the ethical implications of generative AI and its impact on society\n\n## Projects and Tools\n- Sharing of personal projects related to generative AI\n- Discussion about various tools and frameworks used for generative AI such as TensorFlow, PyTorch, and Keras\n- Sharing of resources and tutorials for learning generative AI\n\n## Events and Conferences\n- Discussion about upcoming events and conferences related to generative AI\n- Sharing of links to events such as the International Conference on Learning Representations (ICLR) and the Conference on Neural Information Processing Systems (NeurIPS)\n\n## Social Media and Communities\n- Sharing of links to social media groups and communities related to generative AI\n- Discussion about the benefits of being part of a community for learning and networking\n- Mention of the Generative Models Slack community and the Machine Learning subreddit\n\n## Miscellaneous\n- Discussion about the use of generative AI in video games\n- Sharing of links to generative art websites such as Artbreeder and Deep Dream Generator\n- Mention of the potential of generative AI in creating personalized content for individuals","5":"## Research and Breakthroughs\n- Oxford University researchers introduce a diffusion model called RealFusion that can generate 360-degree reconstructions of objects from an image. [https:\/\/www.marktechpost.com\/2023\/02\/28\/oxford-university-researchers-introduce-a-diffusion-model-called-realfusion-that-can-generate-360-degree-reconstructions-of-objects-from-an-image\/?amp]\n- Breakthrough for nerf\n\n## NeRF and 3D Art\n- Devanshu Tak is a 3D artist who has used NeRF earlier in his work\n- Interesting read: https:\/\/unsupervisedlearning.substack.com\/p\/using-large-language-models-effectively. Esp the #4 point around embeddings\n\n## Embedding and Prompt Templating\n- Embedding was the biggest reason for using Pinecone and Langchain in the Hasura bot\n- Pinecone is used as a vector store\n- Langchain gives a good abstraction\n- Hasura bot uses openAI embedding\n- Chroma bundles store and the embedding call into one from what can be told.","6":"## Generative AI Hackathon\n- Participants discussing a Generative AI Hackathon\n- No constraint on the problem statement\n- April Fool Apps are welcome\n- Participants asking if everyone has a team\n\n## Normalizing Flows\n- Participants discussing Normalizing Flows\n- One participant has been interested in it for a while\n- Another participant shows interest\n- Discussion on industrial use cases or academic interest\n\n## Resource\n- Participants share a resource: https:\/\/research.runwayml.com\/gen1","7":"## Introduction\n- A member of the group shared an opportunity with the group\n- The opportunity is with a large content and consumer brands company in India\n- The company reaches about 40% of all social media users in India\n- The member asked if anyone in the group or anyone they know would be interested in exploring the opportunity\n\n## No further discussion\n\nThere was no further discussion on the opportunity shared by the member. \n\n## Closing\n\nThe group chat ended without any further discussion or topics being brought up.\n\n## Links\n\nThere were no links shared in the group chat.","8":"## Introduction\n- Group chat about Generative AI\n- Chaotic conversation\n\n## Indian Generative AI Landscape\n- Shared link to article about Indian Generative AI Landscape\n- Discussion about the state of AI in India\n- Mention of Indian startups in the AI space\n- Mention of Indian government's AI initiatives\n\n## GPT-4\n- Shared link to Reddit post about GPT-4\n- Discussion about GPT-4 and its potential capabilities\n- Speculation about the release date of GPT-4\n\n## Miscellaneous\n- Thanked member for adding to the group chat\n- No other specific topics discussed","9":"## Hackathon Registration\n- Participants only need to fill the Google form for the hackathon\n- This chat is for everyone interested in seeing what was built during the hackathon\n- Register for a hackathon invite to the BLR venue: https:\/\/forms.gle\/UizUwyKi4bajt6WB7\n\n## GPT Hype\n- Discussion about the hype surrounding GPT\n- Question about whether it is different from the Google form for the hackathon\n\n## Company Participation\n- Discussion about the lack of company participation in the hackathon\n- Someone from the company is encouraged to sign up to participate\n\n## Runwayml\n- Question about whether anyone has access to Runwayml\n- No further discussion or context provided","10":"## OpenAI LLMs and Foundry\n\n- Discussion about whether there are any LLMs by OpenAI that can be deployed on-premises today\n- Mention of OpenAI Foundry, which costs $1 million per year and will have on-premises capabilities\n- No specific LLMs mentioned that can be deployed on-premises currently\n\n## FLan-T5 by Google\n\n- Mention of FLan-T5, which is a FOSS (Free and Open Source Software) by Google\n\n## Thank you\n\n- Thanking Nirant for providing quick help","11":"## Introduction\n- Group chat discussing Generative AI\n- Non-techie member seeking help to keep up with the discussion\n\n## Participants\n- [PHONE REMOVED] [PHONE REMOVED] [PHONE REMOVED] are PMs\n- [PHONE REMOVED] [PHONE REMOVED] are founder and VC respectively\n- [PHONE REMOVED] is Mumbai based creative agency person\n- Manjot [PHONE REMOVED] is with Lightspeed VC currently\n\n## Hackathon\n- Prize money split is 1L minimum per track, split between all members of the winning team equally\n- Evaluation criteria is left to the jury's discretion\n- Some members prefer leaving the criteria to the judges while others prefer having a clear set of criteria\n- Tracks are announced for the hackathon\n\n## Alpaca AI\n- https:\/\/alpaca-ai-custom4.ngrok.io\/ is slow to try prompts\n- It looks more like davinci-002 than the 003 series in terms of ability to follow logic over multiple hops\n- No weights, so it's iffy on what is going inside training\n- The instruct dataset is key\n- The PR they have raised with Huggingface gives you the training code\n- Built for enterprise\n- 3x the price of other AI models\n- 12 cents per 1K token completions is quite expensive\n- GPT4 capabilities have a FOSS counterpart from Amazon: github.com\/amazon-science\/mm-cot\n\n## Miscellaneous\n- Too much happening in this space in a day, difficult to keep up with things\n- Be My Eyes demo is hilarious\n- IST timing is odd for some members\n- Thank you for adding me to the community","12":"OpenAI Demo and Productivity Tools:\n- OpenAI demo of wireframe to working code was impressive\n- Discussion on how it could be used for productivity tools like email, document writing, and slide creation\n- Some productivity and note apps may become irrelevant after this technology\n\nDeep Learning\/NLP:\n- Discussion on various resources for learning about deep learning and NLP, including courses and papers\n- Recommendation to watch Karpathy's nonogpt video\n- Discussion on studying existing models and their building blocks\n- Xavi Amatriain's catalog may be overwhelming for beginners\n- Non-technical questions are welcome\n\nTransformers and Fine-Tuning:\n- Discussion on how transformers have taken over the field previously dominated by RNN variants\n- Fine-tuning any LLM is tricky\n- Prompt optimization may be more lucrative than fine-tuning\n- Prefix\/prompt tuning may be the way to go for applications\n\nArt and Stable Diffusion:\n- Discussion on using Stable Diffusion for art and prompt engineering\n- Playgroundai and civitai.com mentioned as resources\n- Prompt engineering changes with each new release\n- Next step after playing with basic prompts on Midjourney and Dall-e may be exploring image2image, in-painting, out-painting, and instruct pix2pix\n- Discussion on integrating text2image providers with full-fledged tools like Canva and Photoshop\n\nResearch and Emergent Properties:\n- Discussion on how bigger models have more emergent properties\n- Question on whether there are works that show when these properties arise during training\n\nMiscellaneous:\n- Discussion on organizing an activity for Bangalore folks\n- RNNs are fighting back\n- Link to Google palm blog post on scaling language models","13":"## Paper Reading Groups\n- Discussion about reading and analyzing research papers related to popular models\n- Suggestions to play a game of hunting for clues and trying to understand the research team's thought process\n- Recommendation to start with interdisciplinary papers like Visual ChatGPT and diff it against other models\n- Idea to host a reading session and invite people to present different papers and discuss insights\n- Mention of CV paper reading group in Bangalore run by Sumod Mohan and a CS paper reading group run by Swanand via Hasgeek\n- Interest expressed in listening to reading sessions\n\n## Events and Resources\n- Request for information about paper reading groups happening in Bangalore\n- Suggestion to spontaneously organize such events in Bangalore\n- Sharing of a Twitter link to an event by LangChainAI\n- Discussion about storing embedding vectors in a PG database and the need to explore other options","14":"## Language Models and Datasets\n- Discussion on why language models have a cut off in 2021, including GPT-4\n- Training involves curating a dataset which is time-consuming\n- Cleaning and wrangling data takes a lot of effort\n- Some open source datasets are available\n- GPT-4 paper might have the dataset details, but was disappointing\n- Model has access to data from 2022, but official position is that the data has a cutoff date in 2021\n\n## AI Tools and Applications\n- Discussion on the performance of AI tools for large scale searches\n- Pinecone is recommended for specific vector databases\n- ChatGPT-3 Whatsapp bot can summarise videos, transcribe voice notes, answer text questions, and generate images using \/image\n- Replit.com will be sponsoring a hackathon\n\n## Miscellaneous\n- Positive feedback on an impressive YouTube video\n- Interest in using productivity tools\n- Discussion on the quirks of language models","15":"New BingGPT Launch:\n- Potential to make advertising briefs easier\n- Link: https:\/\/www.bing.com\/new \n\nAI and Software Engineering:\n- Discussion on how GPT4 will change software engineering\n- Link to article: N\/A\n\nMarch Meetup:\n- Question about whether the March meetup for gen ai is happening\n- No meetup in March, suggestion to come to the hackathon instead\n- RSVP\/sign up link requested\n- Link: N\/A\n\nImage Generation Models:\n- Discussion on using image generation models\n- Mention of Midjourney, cvitai, and openjourney models\n- Recommendation to try gooey.ai\n- Link to cvitai: https:\/\/civitai.com\/\n\nLORA and Alpaca:\n- Discussion on using LORA and self-instruct datasets to improve Alpaca\n- Offer of sponsorship and contribution of datasets\n- Link to Alpaca self-instruct dataset: https:\/\/github.com\/tatsu-lab\/stanford_alpaca\/blob\/main\/alpaca_data.json\n- Link to article on Alpaca: https:\/\/crfm.stanford.edu\/2023\/03\/13\/alpaca.html\n\nOther Topics:\n- Offset noise write-up: https:\/\/www.crosslabs.org\/blog\/diffusion-with-offset-noise\n- Discussion on Google stuff and Blender ControlNet for posture and depth\n- Mention of facial keypoints for better control in image generation\n- Humorous comments on lack of sleep and use of Adderall","16":"## Introduction\n- Confirmed *FOSS* Demos for the hackathon, 2 of the top 3 projects from Github Trending in AI\n- Thanks for the intro Ravi Theja, GPT-Index contributor and inMobi DS [PHONE REMOVED]  to Jerry Liu \n\n## Interesting Links\n- Sharing my favourite blog from last few weeks: https:\/\/simonwillison.net\/2023\/Mar\/17\/beat-chatgpt-in-a-browser\/\n- https:\/\/mobile.twitter.com\/nickfloats\/status\/1631346749297106958 \n- came across this today \n\n## AI Models\n- WASM for LLMs is super interesting, anyone tried? \n- They also trained an LLM to mimic Homer Simpson and it\u2019s apparently better than gpt-4\n- It'd be hilarious if the model forgot how to do chain of thought reasoning because of that \ud83d\ude02\ud83d\ude02 \n\n## Research Labs\n- Iit madras or Bombay has research labs you can cold mail them or reach out to other iits they might help or redirect to appropriate org. \n\n## VC Tool\n- Anyone exploring building a tool like this for VCs?  \n- Good customers to sell to and solid use case of AI","17":"AI Models and Tools:\n- Hugging Face's text-to-video synthesis model: https:\/\/huggingface.co\/spaces\/damo-vilab\/modelscope-text-to-video-synthesis\n- Reid Hoffmann's essay on GPT4 and AI summary request\n- Midjourney for generic imagery and potential API release\n- Stable Diffusion vs. Photoshop and Canva vs. Midjourney comparison\n- InvokeAI's open source UI for Stable Diffusion and potential API release\n- Automatic1111 as a potential future option for CreativeAI\n- RunwayML Gen1 and its impressive features\n- Comfy UI, a node-based\/DAG interface for image generation\n- OpenAI's paper on the potential impact of Large Language Models on the Labor Market: https:\/\/twitter.com\/rubinovitz\/status\/1637651591191842816?t=g4U4qTnkF-R02mImutwo8w&s=19\n\nIndustry and Applications:\n- HBR essay on how generative AI will disrupt video platforms: https:\/\/hbr.org\/2023\/03\/how-will-generative-ai-disrupt-video-platforms\n- Kishore [PHONE REMOVED]'s work in the generative AI space to generate statics for advertisers\n- Examples of static images generated by Kishore's product pipeline\n\nMiscellaneous:\n- Conspiracy theory about someone spiking SF's water supply with Adderall\n- Replit templates for AI: https:\/\/replit.com\/templates?q=AI","18":"Generative AI Group Chat Transcript\n\nProduct Inpainting:\n- Discussion on using separate LoRA for inpainting main product\n- Tutorial using ComfyUI for generating similar images with different ethnicities and anime styles of same character shared\n- Clarification on main product being matchstick box with person holding it\n- Flair and Booth.ai tools discussed for retaining text and product fidelity\n- Better methods like ControlNet, Adapters, Composer suggested for similar use cases as Flair\n- Finetuning models not needed for controlling style, image composition, and color scheme\n- Copy-pasting pixels on final image where product exists suggested for preserving product fidelity\n- Background subtraction and improvement suggested for e-commerce images\n- Adept.ai and similar space discussed for game-changing computer usage\n\n3D Product Capture and Visualization:\n- Nerf capture app like Luma suggested for generating 3D models from any novel viewpoint\n- Workflow for product photography and marketing discussed\n- Niche and industry-specific vertical AI products suggested for startups\n- Canva's absence in GenAI space discussed\n\nAdobe and Horizontal Gen AI Startups:\n- Adobe's deep computer vision tools and products discussed\n- Criteria for horizontal products to succeed discussed\n- Firefly's impressive features discussed\n- Yudkowsky's propaganda discussed\n- ImageCaptioning models like BLIP and CLIP_prefix_caption discussed\n- BARD and Lamda models discussed\n\nLinks:\n- Tutorial using ComfyUI: (https:\/\/bit.ly\/hf-nvidia-meetup)\n- Deepset's Haystack: (https:\/\/www.deepset.ai\/blog\/build-a-search-engine-with-gpt-3)\n- Hood project: (https:\/\/dolorousrtur.github.io\/hood\/)\n- Adept.ai: (https:\/\/www.adept.ai\/)\n- Shi et al.'s research on VQA: (https:\/\/proceedings.mlr.press\/v70\/shi17a.html)\n- Visual ChatGPT: (https:\/\/github.com\/microsoft\/visual-chatgpt)\n- Google's BARD: (https:\/\/sites.google.com\/view\/bard-challenge\/home)\n- CLIP-Interrogator-2: (https:\/\/huggingface.co\/spaces\/fffiloni\/CLIP-Interrogator-2)\n- CLIP_prefix_caption: (https:\/\/github.com\/rmokady\/CLIP_prefix_caption)\n- Gist for converting Firefly into API: (https:\/\/gist.github.com\/ovshake\/69efb594f3b1e8d98b34687b16916145)\n- Video of Nvidia livestream: (https:\/\/www.youtube.com\/watch?app=desktop&v=DiGB5uAYKAg&feature=youtu.be)\n- Yudkowsky's tweet: (https:\/\/mobile.twitter.com\/ESYudkowsky\/status\/1635577836525469697)\n- Vinnie Moura's tweet: (https:\/\/twitter.com\/vinniemourax\/status\/1638218512760971277?s=20)","19":"Introductions and Backgrounds:\n- Vishal Tripathi, Venture Investor, worked on a fund of funds strategy for Google Ventures - Plexo Capital. Currently with Legacy Venture, investors in many of the funds people have mentioned above (Sequoia, A16z, Matrix, Accel, True, etc).\n- Someone mentioned Yohei (from untapped VC) above, he\u2019s a close friend and has collaborated with him on some GPT tools.\n\nProof of Concept Script:\n- A member has a proof of concept script that they would like to take to customers.\n\nBlog Post:\n- Shared a fun blog post for folks who are in marketing or content or do a lot of writing work in other ways.\n- The last line of the link is \"This will make certain people really mad.\"\n\nExcitement over a Tool:\n- Members express excitement over a tool that has been shared.\n\nInfinite Customization:\n- A member shares their opinion that infinite customization is actually a pain.\n- Firefly is given as an example of limiting functionality and making it more useful than competitors.\n\nAdobe:\n- A question is asked about whether Adobe was doing all its ML inference on user's local system before Firefly.\n- Adobe Express is mentioned as not being local and allowing users to do stuff online.\n\nPaper:\n- A member shares a paper they came across and plan to try on HF and look through.\n- The paper was published in CVPR 2023 and works with video compression.\n\nProject Related to Healthcare:\n- A member asks if anyone is working on any projects related to healthcare.\n- Another member responds with a yes and is asked to tell more.","20":"## Introduction\n- One member introduces themselves as Dukaan's head of AI.\n\n## JadooSnap\n- JadooSnap is a website that some members have seen and praised.\n- It is not yet available for public access, but some companies are already using it.\n- A member shares a link to JadooSnap.com.\n\n## Access to JadooSnap\n- A member asks if there is any way for Dukaan to request access to JadooSnap.\n- Another member shares a Twitter link that may be helpful.\n\n## Gates Foundation Contract\n- Dukaan is hoping to get a contract with the Gates Foundation to build a WhatsApp chatbot to guide rural nurses in India.\n- Hindi is necessary for this project, and it is supported by GPT4 and Whisper.\n- Bhashini, an Indian government-funded research project, has a fine-tuned Whisper model for Hindi.\n\n## Indian Languages\n- The most popular Indian vernacular languages are discussed.\n- The Hindi results of GPT are not as great as English.\n- A member is confused by Bill Gates' writing about an Indian startup working on LLMs for Indian languages.\n- It is suggested that the source documents are all in English and that Google Translate is used to translate them into Hindi for GPT.\n\n## Experiment Proposal\n- A member proposes a test set to compare the effectiveness of using Google Translate for GPT versus using original Hindi documents.\n\n## AI Photo Editing\n- A member asks for ideas on how to achieve a certain effect in photo editing.\n- Several members suggest different methods, including changing the tint of the image to RGB, adding noise and denoising guided by a prompt, and using Controlnet\/depth2img.\n- The idea of generating a photo-realistic image of a baby from an ultrasound is discussed.\n- A member shares a link to an AI photo editor.\n\n## Adobe Products\n- A member mentions Adobe products.\n- Another member shares a LinkedIn post about Adobe Firefly.","21":"## AI Model and Prompt\n- Discussion about a prompt and AI model\n- Need for composition iterations to achieve desired output\n- Mention of a Rembrandt painting as a style reference for the second picture\n- Mention of a custom AI model created by merging different models\n\n## OpenAI Plugins\n- Mention of OpenAI ChatGPT plugins\n- Comparison to Alexa Skills\n- Link to OpenAI Plugins documentation\n\n## Off-Topic Discussions\n- Request for help with Firestore\n- Invitation to showcase projects\n- Sharing of a link to an article about the cost of ChatGPT for Indian languages\n- Discussion about using OpenCV videocapture() with an external iOS camera\n- Support for direct vernacular interaction with GPT, but with poor performance.","22":"## Topics Discussed in Chaotic Generative AI Group Chat Transcript:\n\n### AI Art Generation Workflow\n- Discussion on using Stable Diffusion for AI art generation.\n- Workflow involved using text2img with controlnet depth map of the image.\n- Depth map was obtained from Clipdrop's API.\n- Automatic1111 was used for the entire process.\n- Iteration loops were run in every step until satisfied with the output before moving to the next step.\n- Retakes are common in AI art generation.\n- Fascination with how a deterministic input can give infinite non-deterministic output.\n- Non-deterministic output still stems from a classical random number generator.\n- The concept of seeds is simple but quite useful.\n- There are infinite seeds in theory.\n\n### AI Tools and Plugins\n- Discussion on Langchain agents and ChatGPT plugins.\n- Certain things are easier and more fun with a UI.\n- Depth maps provide more control.\n\n### AI Learning\n- Suggestion to try few-shot learning for training.\n- Ran out of context length before stuffing enough context for significant improvements.\n\n### Humor\n- Ran out of context length before stuffing enough context for significant improvements \ud83d\ude02\n- This debate itself is infinite \ud83d\ude06\n\n### Social Links\n- Sudharshan's tweet: https:\/\/twitter.com\/sudharshan_\/status\/1441267649479470080","23":"## Video on OpenAI's Development Trajectory\n- Link: https:\/\/www.youtube.com\/watch?v=L_Guz73e6fw\n- Discussion about OpenAI's development trajectory\n- No technical details, but philosophical nuggets shared by Sam Altman\n- Talks about the potential of AI and its impact on society\n- Mentions the importance of safety and ethical considerations in AI development\n\n## The AI Dilemma Video\n- Link: https:\/\/www.youtube.com\/@aajtakai\/videos\n- Discussion about the recent blitzscaling of OpenAI and Microsoft in AI advancements\n- Video titled \"The AI Dilemma\" talks about the safety concerns and risks associated with exponential growth of LLMs (large language models)\n- Emphasis on the need for ethical considerations and safety measures in AI development","24":"## Deep Hack Demo Day Invite\n- Invitation to a demo day\n- Sales pitch to share with friends in Bengaluru\n- One member wishes they could attend but will be flying out that day\n\n## Jobot, a ChatGPT-powered bot is live at Jovian\n- Announcement of a new ChatGPT-powered bot\n- One member asks if the demos will be streamed\n\n## Introductions\n- One member introduces themselves as an anthropologist and senior fellow with the Max Planck Institute for Social Anthropology\n- Another member introduces themselves as a new media artist and educator, with a focus on using AI, robotics, and code to build experiences\n- A third member introduces themselves as a search engineer at Wolfram|Alpha\n\n## AI Projects and Demos\n- Discussion of a video project that uses OCR, content search, style transfer, and projection mapping\n- Sharing of a GitHub repository for a blind visual aid using GPT\n- Discussion of a demo for a work-in-progress project that integrates ControlNet to alter per specific requirements for a particular color-blind person\n- Sharing of a news article about a project that uses goggles for the blind\n- Discussion of using serverless GPUs and accelerate to offload to CPU\n- Discussion of using GPT to write and create episodes for the final season of Game of Thrones\n- Discussion of GPT's ability to handle degeneracies and reason about problems in its distribution but not in its data\n- Discussion of GPT's performance on new Leetcode problems past its training date\n- Sharing of a blog post about cheating in coding using LLM-powered assistants\n- Discussion of the potential for LLM-powered coding assistants to automate much of the code we write and the skills that will become more important as a result\n\n## Miscellaneous\n- Discussion of a text-to-video tool for camera movements over still images\n- Sharing of a ControlNet web app and API\n- Discussion of the eligibility of remote submissions for a prize","25":"Introduction:\n- Dr. Parth Sharma introduces himself as a doctor with an interest in AI and deep learning.\n\nAI and Deep Learning:\n- Discussion about Andrej Karpathy's videos on YouTube.\n- ChatGPT is used to generate a list of Shopify websites in the USA that sell candles.\n- ChatGPT is also useful for competitor analysis.\n- The group discusses the use of checkpoints and Exif data in AI image generation.\n- Dreamboothing is mentioned as a technique for generating AI images.\n- The group debates the photorealism of AI-generated images.\n\nAI Romance:\n- A hypothetical story is shared about a man who falls in love with an AI-generated girl.\n- The group discusses the potential for a movie based on this story.\n\nMiscellaneous:\n- A quote about Balenciaga is shared.\n- A link to a YouTube video is shared.\n- The group discusses a lost AI-generated image of Deepika Padukone.\n- A Greek myth about a sculptor who falls in love with a statue is mentioned.\n- A member shares their bumble bio.","26":"Google and Replit partnership to take on Microsoft's GitHub\n- India Replit sponsoring hackathon\n- GCP features on Replit\n- Discussion on popularity of writing GPT from scratch\n- Request for safety protocols for AI development\n- Comparison to past technologies and societal effects\n- Proposal for philosophy room and use-case specific groups\n- Azure OpenAI credits discussion\n- Hacks to reduce GPT hallucination\n- BIC event on ChatGPT and its ilk\n- OpenAI grant eligibility and phishing concerns\n- Future of Life open letter on pausing giant AI experiments\n- Score system to penalize GPT hallucination\n- Verification of GPT sources and self-consistency check\n- Throttling using prompts discussion\n- Proposal for custom agent implementation\n- Self-consistency empirically known to work","27":"OpenAI and Tech Hindrance:\n- Discussion on OpenAI's decision to stop developing new AI models due to potential job loss\n- Some members believe hindering tech is not fruitful\n- OpenAI is a for-profit company backed by Microsoft\n- Elon Musk's involvement in OpenAI is questioned\n- Yann Lecun's stance on the issue is mentioned\n\nAI Models and Tools:\n- Discussion on various AI models and tools such as GPT-4, ChatGPT, Bard, and Pix2struct\n- Mention of MM-React and Llama Multimodal\n- Interest in Karpathy's work and Tesla's use of synthetic data and big datasets\n\nPersonal Experiences:\n- Members share their experiences with AI and ML, ranging from a few months to several years\n- Mention of past projects and papers worked on\n\nCommunity and Events:\n- Discussion on various AI communities on Reddit and Discord\n- Mention of upcoming hackathon and demo of Guardrails\n- Interest in AI improv and AI-related events\n\nMiscellaneous:\n- Mention of phishing scam and O1 visa advice\n- Discussion on government regulation and Microsoft's involvement\n- Mention of Deepmind's AlphaTensor and chess coverage\n- Sharing of personal LinkedIn and Instagram profiles\n- Hackathon idea involving LangChain model and WhatsApp chats\n- Expected footfall for the Bengaluru hackathon","28":"Quick Hacks and Extensions:\n- A quick hack for DeepHack GPT to handle multiple context questions\n- A small flex of exporting group chat from WhatsApp and uploading the text file to gooey for search without writing any code\n- Whisper API can be used to get the transcript without GPUs\n- Gladia.io can extract 1-hour audio file transcript in 10-20 seconds using openai Whisper backend\n- Assembly.ai has a playground to upload files for transcription with good accuracy\n- HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace\n\nLLMs and Table Structures:\n- Discussion on making LLMs understand table structures\n- chatpdf.com was suggested as a solution\n\nRephrase.ai:\n- Rephrase.ai launched a completely automated blog to video powered by GPT-4\n- The default limit for generated videos is 1 minute with a limit of 20k characters for the blog\n- Plans to improve pitch and editing style, cuts, screen transitions, overlays\n- Results were shared through a mobile Twitter link and a personalized link\n\nProduct Management:\n- Calling out to fellow Product Managers for insight on KPI error corrections\n\nData Protection:\n- The Italian Data Protection Authority finds ChatGPT's training models in violation of their data laws.","29":"## DeepHack Demo Day\n- Discussion about who is attending the DeepHack demo day\n- Live stream link shared: https:\/\/has.gy\/ULYt\n- Live stream temporarily stopped for a 5-minute break\n\n## Submissions\n- Question about whether all submissions have been completed\n\n## Social Links\n- None mentioned.","30":"## Topic 1: Alternatives to D-ID and ElevenLabs\n- User is looking for good\/free\/local alternatives to D-ID and ElevenLabs\n- Wants to upload custom image and audio to get a lip-synced avatar video\n- Gooey.ai\/lipsync is suggested as a possible alternative\n\n## Topic 2: Differences between Dreambooth, LoRA, and Textual Inversion\n- User is looking for information on the differences, pros, cons, and training time of Dreambooth, LoRA, and Textual Inversion\n- User has experience training a custom DB model but hasn't used the other two yet\n- Another user suggests that LoRA works well compared to the other two, especially after being trained on a small amount of data\n- Dreambooth provides decent results after multiple attempts of fine tuning\n- Textual Inversion didn't return any good results for the user who tried it\n- A YouTube video (https:\/\/youtu.be\/dVjMiJsuR5o) is shared, but it's unclear if it's related to this topic or not.","31":"## Emergence of Creativity and Intelligence\n\n- Creativity and human intelligence may just be an emergent property of a small number of algorithms operating with a lot of compute power.\n- Many respected neocortex researchers believe there is effectively one algorithm for all intelligence.\n- Human brains don\u2019t look all that different from chimp brains, and yet somehow produce wildly different capabilities.\n- Our own intelligence may just be the emergent combination of a bunch of cheap tricks.\n\n## Miscellaneous\n\n- Someone thanked two phone numbers.\n- No other topics were discussed.","32":"## Generative AI Tools and Platforms\n- OpenPlayground and Playground.ai are discussed as generative AI experimentation platforms\n- OpenPlayground is noted for its ability to experiment with different diffusion models, parameters, inpainting, and base image generation for LLMs\n- Playground.ai is noted for its popular prompts and upvoting system\n- API access for Playground.ai is expected to be released soon\n- The group discusses the strategy of having a Discord bot but not an API, with some suggesting that it may be due to the cost and difficulty of setting up an inference infrastructure\n- Vast.ai and Hetzner Cloud are mentioned as cloud computing services for renting GPUs\n- Runpod is mentioned as a service for renting out GPUs\n- ImagineAPI.dev is noted as an unofficial MJ API\n\n## AI Research and Development\n- The AI Index Report by Stanford University is mentioned\n- Langchain, an AI-powered language learning platform, is praised\n- The group discusses the potential for Indians in India to develop a globally used GenerativeAI library within the next 12 months\n\n## Miscellaneous\n- A generative AI comic created during a weekend hackathon is shared and praised by the group","33":"## OpenAI Embeddings and Graph Embeddings\n- Discussion on utilizing OpenAI embeddings model to create graph embeddings\n- Naive approach suggested: use \"text-embedding-ada-002\" to get node embeddings and compute edge embeddings using adjacency matrix\n- Pinterest recommends starting with any base embedding and then updating them\n- Article on HN shared for reference\n\n## GPT Model for Financial Data and Analysis\n- Query on availability of GPT model finetuned with financial data and analysis\n- Mention of Bloomberg GPT, but not yet usable or publicly available\n- Doubtful if it will ever be open sourced as it is trained on proprietary data\n\n## Generative AI Mixer Event\n- Invitation to a generative AI mixer event at Lightspeed office in Koramangala\n- Interested participants asked to fill up a Google form\n\n## Deepfake Detection\n- Query on research happening in deepfake detection and any good app\/software for it\n- Mention of Spoofsense.ai working on it\n- Microsoft's effort on disinformation and deepfakes shared, but no working model for public\n- Discussion on not releasing authenticators to avoid making it easier for next generation of cheaters to evolve\/reverse engineer\n- Mention of Yahoo's nudity detection model from 7 years ago\n\n## API for Categorizing Questions\n- Query on API to categorize questions into HR, Finance, Marketing, etc.\n- Offer to create one over the weekend if given 20 samples\n- Discussion on using GPT4 in Google Sheets to classify questions\n\n## OpenAI Credits\n- Discussion on how to get more than $1K\/month hard limit of OpenAI\n- Mention of it being expensive, with 5K questions a day\n\n## Prompt Injection in GPT4\n- Discussion on the status of prompt injection in GPT4\n- Experimentation with prompt injection and simulation of another agent with different ideals in chatGPT and GPT 3, 3.5\n- Mention of GPT4 being good with handling prompt injections and sticking to the system prompt\n\n## Miscellaneous\n- Mention of RISC-V International event in India\n- Query on the largest OpenAI customer in India\n- Sharing of article on Zero Knowledge Machine Learning and its use case in medical data inference\n- Mention of HuggingFace launching a GPT4 alternative, Vicuna 13B","34":"General AI Discussion:\n- Speculation on how the system prompt is used in AI chat\n- Discussion on building AI applications for schools\n- Query on the best model to use for Sparse Vectors and hybrid search\n- Experimentation with AI chat\n- Query on the tool used for text2vid\n- Query on Danny Postma's cloth transfer technique\n- Sharing of recent research on cloth transfer\n- Sharing of a GitHub link for HR-VITON\n- Query on MidJourney subscription payment\n- Discussion on using Google Sheets as a database for GPT4 app\n- Self-promotion of Gooey.ai for creating bots that refer to Google Sheets\n- Discussion on using self-hosted Postgres with pgvector\n- Sharing of Indian government's fine-tuned checkpoints for Indian languages\n- Sharing of an ASR API link\n- Discussion on fixing OpenAI Notebook bugs and monetizing it\n- Sharing of personal contribution to OpenAI Cookbook\n- Query on the time it takes to insert data into Chroma\n- Discussion on the usefulness of finetuning off-the-shelf embeddings for improving search ranking and QA\n- Discussion on using entity relationship graph for semantic processing\n- Sharing of LangChain's work on graphs\n- Discussion on Pinecone's pricing confusion\n- Sharing of Chroma's template for Replit\n- Discussion on the potential of theory folks in CS Theory\n- Sharing of a YC company, Metal, for AI model compression\n- Query on using ElevenLabs for training and generating audio in Hindi\n- Sharing of demos from India's first Generative AI hackathon\n- Offer to make introductions to hackathon teams for VC carry\n- Request for engineers to write better copy and take pitching tips from [PHONE REMOVED] [PHONE REMOVED]\n\nLinks:\n- https:\/\/arxiv.org\/abs\/2304.01852\n- https:\/\/github.com\/sangyun884\/HR-VITON\n- https:\/\/huggingface.co\/blog\/fine-tune-whisper\n- https:\/\/github.com\/Open-Speech-EkStep\/vakyansh-models\n- https:\/\/twitter.com\/MetaAI\/status\/1643602729615646720\n- https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb\n- https:\/\/gooey.ai\/asr\/\n- https:\/\/huggingface.co\/vasista22\/whisper-hindi-large-v2\n- https:\/\/getmetal.io\/\n- https:\/\/nirantk.com\/deephackdemos","35":"## ViewsAct Project\n- Request for demo video\n- Creator opted out due to use of real-world company designs and data\n\n## Hackathon Demos\n- Discussion on winners in SF\/NYC\/Berlin circuits\n- Request for more information on tracking\n\n## Dalle Short Film\n- Link shared: https:\/\/www.instagram.com\/reel\/CqstiaNuSjX\/?igshid=MDJmNzVkMjY=\n- Another link shared for breakdown process\n\n## Networking\n- Request to meet people working in gen AI space in Bay Area\n- Introduction of Applied Scientist at Amazon building computer vision tech for video action recognition\n\n## AI\/Art\/Gaming Event in London\n- Link shared: https:\/\/www.theguardian.com\/games\/2023\/apr\/06\/now-play-this-ai-video-game-somerset-house-london?CMP=Share_iOSApp_Other\n\n## WebGPU\n- Chrome has shipped WebGPU\n\n## Pichai and Google\n- Discussion on Pichai's involvement in Chrome and web acceleration ideas\n- Hope for battery tech to keep up\n- Mention of Google Keyboard and Microsoft's acquisition of SwiftKey\n\n## Agent Planning\n- Discussion on evolution of agent planning\n- Question on improvement in GPT4\n\n## Running Models on Personal Machine vs API\n- Question on benefits of running model on personal machine\n- Response on lower latency and higher throughput\n- Mention of compute cost for companies serving consumers at scale\n- Possibility of freemium models\n\n## pgVector\n- Discussion on limitations of pgVector for LLM apps\n- Request for documentation on NN capabilities\n- Mention of recall in the area of 50%\n- Suggestion to test\/verify empirically\n- Question on why pgVector won't work\n- Mention of ann-benchmarks by Erik Bern of Modal Labs\n\n## Other Vector Stores\n- Discussion on the logic behind having multiple vector stores\n- Mention of LangChain components and cloud solution for monetization\n- Mention of Pinecone being ahead in technology and supporting largest number of use cases\n- Concerns about competition from Azure, AWS, or GCP\n\n## Learning Resources\n- Links shared for Rime AI, foundational models, and database internals\n- Idea for generating embeddings and creating top 10 learnings from group every week","36":"## Integration of chatGPT\/LLMs into smart home devices\n- Query about integration of chatGPT\/LLMs into Alexa\/Nest type of smart home devices\n- Mention of tools that can do it, but openai key is a barrier to adoption\n\n## Paddlespeech\n- Query about anyone dabbling with paddlespeech\n\n## ChatGPT talk by Anil Ananthaswamy\n- Video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published\n- Link: https:\/\/youtu.be\/WF28ZwhUCc4\n\n## Automatic1111 and DrawThings App\n- Suggestion to use Automatic1111 on colab\n- Suggestion to download DrawThings App on MacBook\n- GPU memory issue, try smaller models\n\n## Generative AI on local machine\n- Discussion about running generative AI workflows locally on a Mac\n- Recommendation to either go all the way or get the Macbook air\n- Suggestion to get as big of a machine as your wallet permits\n- Mention of text-to-video taking off in the future\n\n## Optimization of models for running on Apple RAM\n- Query about how optimized the models are for running on Apple RAM as opposed to Nvidia GPUs\n\n## Serverless Vector DB and pricing\n- Discussion about serverless Vector DB and pricing around it\n- Link: https:\/\/twitter.com\/jobergum\/status\/1644653416994488320\n- Mention of a free masterclass on Developer eXperience and how that influences pricing and GTM\n\n## GPT4 fixing syntax and API calls\n- Discussion about a demo where GPT4 fixes syntax and API calls\n- Expectation of dedicated planning \"agents\" which can pair with the dev much more on the first part\n\n## GPT assisting game development\n- Discussion about the possibilities and capabilities of GPT assisting game development\n- Mention of a video sent by a non-developer brother on the topic\n\n## Podcast style fireside chat\/discussion\n- Offer to participate in a podcast style fireside chat\/discussion\n- Mention of working on something close to it","37":"## SAAS Company Sale\n- Discussion about a tweet by Dan Martell regarding selling a SAAS company.\n\n## Generative AI Tools\n- Discussion about a tool for generating desi lofi girls.\n- Mention of a tool built by [PHONE REMOVED] and friends for YouTube videos.\n- Mention of sitegpt.ai, which does something similar.\n- Mention of Microsoft Edge's copilot option for generating text.\n- Mention of jsonlines format for solving text generation challenges.\n\n## Vector DBs\n- Discussion about starting a vector DB company.\n- Mention of Chroma as a database for small amounts of text.\n- Discussion about scaling challenges with gptindex.\n- Mention of Pinecone as a vector DB.\n- Mention of Nirant and Ravi's knowledge about vector DB tradeoffs.\n- Mention of a tweet thread by Nirant about vector DBs.\n- Mention of the possibility of an accelerator for startups.\n\n## Legal Document Embeddings\n- Discussion about embedding legal documents.\n- Mention of mpnet from sentence transformers.\n- Suggestion to ask sachin from intellawyer.com about legal document embeddings.\n\n## Hacker Houses\n- Discussion about starting a hacker house in Bangalore.\n- Mention of HackerDojo in Mountain View as a community-run space for hackers.\n- Mention of the possibility of an accelerator for startups.\n\n## ChatGPT Plugins\n- Discussion about the waitlist for ChatGPT plugins access.\n- Mention of a conspiracy theory about the location of the person maintaining kisaangpt.\n- Mention of compliance as a possible reason for country preferences for plugins access.\n- Mention of the possibility of age of account or usage affecting plugins access.\n\n## Miscellaneous\n- Discussion about the possibility of an oral history series.\n- Mention of the GenerativeAI April meetup registration link.\n- Mention of a talk by Atty from the OpenAI plugins team.\n- Discussion about GPT-4 API access.\n- Mention of a tweet by Alex Graveley about Microsoft Edge's copilot option.\n- Mention of Cerebral Valley starting with 50 members.","38":"## Hackathon Ideas\n- Discussion about a thread of hackathon ideas and similarities to their own hackathon\n- Political action project was the first thing they sold to a client back in 2022\n- Creators of the thread haven't been mentioned, but can tweet to Joseph or @swyx to ask\n- Mention of knowing @swyx from the react world because of a talk\n- Variety of chatbots in their hackathon\n\n## GPT 3.5\n- Discussion about problems with limiting output length\n- Question about changing length units to token instead of characters\n- Recommended way to do this is to use Guardrails and turn on re-ask\n- Mention of Guardrails creator doing a demo at their hackathon venue\n- Link to Guardrails GitHub page\n- Mention of Indians no longer playing catch up in the tech world\n\n## Kor and Guardrails\n- Discussion about Kor being a general purpose parser for any text\/schema\n- Confusion about why the schema format in Guardrails is not the same as the output format\n- Balancing language\/lib design POV\n- Resizing prompts work well when input and output language is English\n- BPE tokeniser is notoriously unstable for CJK and Indian languages\n- Prompt engineering is like casting a spell\n- Suggestion to tweet and tag OpenAI folks for more information on GPT4\n\n## GPT4 and GPT3\n- Discussion about customers raising support tickets for being fooled about GPT4 access\n- Suggestion to improve with a system prompt\n- Chat models are instruction finetuned, sanitised and scaled forks of large base models\n- Suggestion to have GPT3.5-Turbo claim to be GPT4\n\n## Generative Agents\n- Discussion about interesting new research on generative agents\n- Enthusiastic reporting on the topic\n\n## Midjourney and Kandisky 2.1\n- Discussion about Midjourney being exclusively on Discord and suggestion to wait or pay for premium\n- Mention of a new model Kandisky 2.1 available on dreamlike.art\n- They provide daily credits as of now\n\n## Comparing Models\n- Quick compare table for comparing various models\n\n## Image-Creation Tools\n- Question about any image-creation tool that accepts looking into a website design for reference\n\n## LoRA\n- Question about friends or acquaintance artists working with LoRA\n- Mention of Vignesh being quite nice and giving great advice for job hunting in Leuven\n\n## Thank You\n- Thank you messages to Nirant and Sid","39":"## Generative AI\n- Discussion about a paper on generative agents and a demo at https:\/\/reverie.herokuapp.com\/arXiv_Demo\/\n- Mention of Andrej Karpathy's tweet\n- Sharing of a link to a website that uses flat GPT output without crawling their pages\n- Mention of a bot that doesn't have memory and a classic NER ambiguity mistake\n- Discussion about ChatGPT plugins and OpenAI account access\n- Speculation on how OpenAI determines a user's country and suggestions for contacting OpenAI\n- Mention of Ojasvi leading AI at mydukaan.io\n- Invitation to a mixer event at the Lightspeed office in Koramangala\n- Discussion about access to OpenAI plugins and VPN use\n- Sharing of a link to a website on the serverless GPU market\n- Mention of an AI lab in Bangalore and connections to it\n- Discussion about using YubiBert and CredAvenue's OSS Financial LLM\n- Mention of Linkedin's research arm in Bangalore and their work on content moderation and quality\n- Sharing of links to OpenAI meetups and a question about streaming\n- Discussion about using GPT to access a specific table in a database and performing CRUD ops\n\n## People and Companies\n- Mention of Andrej Karpathy and his project\/tool\n- Mention of Ojasvi leading AI at mydukaan.io\n- Invitation to a mixer event at the Lightspeed office in Koramangala\n- Mention of Rahul being smart and having worked at MS and started a crypto hedge fund\n- Mention of a client that is an AI lab and connections to it\n- Mention of Linkedin's research arm in Bangalore and their work on content moderation and quality\n\n## Resources\n- Sharing of a link to a paper on generative agents and a demo at https:\/\/reverie.herokuapp.com\/arXiv_Demo\/\n- Sharing of a link to a website that uses flat GPT output without crawling their pages\n- Sharing of a link to a website on the serverless GPU market\n- Sharing of links to OpenAI meetups and a question about streaming","40":"AI Embedding Models:\n- Comparison between OpenAI's \"text-embedding-ada-002\" and Huggingface models or Sentence Transformers\n- Some prefer Huggingface or Sentence Transformers for their use case\n- Recommended model: \"sentence-transformers\/all-mpnet-base-v2\" or \"multi-qa-mpnet-base-dot-v1\" for semantic search\n- Cross-encoder recommended for better scoring mechanisms\n\nAI in News Media:\n- Traditional News Media is frightened with AI\n- Buzz is hot and controversial\n- Interviews conducted on AI opinions\n\nAI Chatroom Plugins:\n- ChatGPT Plugins SF hackathon winners announced\n- Winners have higher usability than expected\n- Indians are no longer playing catch up\n\nAI Conversational Memory:\n- Idea of enabling long term conversational memory by vector indexing conversation history\n- Langchain has good abstractions around memory\n\nAI Regulation:\n- Governments starting to weigh possible rules for AI tools like ChatGPT\n- India already working on BharatGPT\n\nAI for Agriculture:\n- KissanGPT being used by farmers and hobbyists\n- Feature requests being made\n- Plans to integrate visual capabilities to detect bad signs in crop photos\n- OpenAI being asked for access to multimodal when available in GPT4 API\n\nAI for Finance:\n- Idea being toyed with for AI in finance\n- Portfolio company looking for tools to help write research reports\n\nAI Datasets:\n- Looking for dataset agencies to curate an instruct type dataset\n\nLangchain:\n- Langchain webinar with Harrison, Yohei, and others recommended\n- Langchain docs recommended for getting started\n\nOpenAI:\n- Open source implementation and model weights released for one step image generation model","41":"## Dolly 2.0\n- Databricks has released Dolly 2.0, a commercially viable LLM.\n- The dataset was crowdsourced from Databricks employees.\n- The training code, dataset, and model weights have been open-sourced and are suitable for commercial use.\n- Link: https:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm\n\n## OpenAI's Consistency Models\n- OpenAI has proposed consistency models, a new family of generative models that achieve high sample quality without adversarial training.\n- Link: https:\/\/www.marktechpost.com\/2023\/03\/10\/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training\/\n\n## Vector Databases\n- Participants discussed various vector databases, including Pinecone, Weaviate, Qdrant, Chroma, Redis Vector Cache, Vespa, pgvector on Supabase, and Milvus.\n- Participants also discussed the best vector database for production and inferencing costs.\n- Links: \n  - https:\/\/www.pinecone.io\/\n  - https:\/\/www.weaviate.com\/\n  - https:\/\/qdrant.tech\/\n  - https:\/\/chroma.ai\/\n  - https:\/\/redislabs.com\/solutions\/use-cases\/vector-cache\/\n  - https:\/\/vespa.ai\/\n  - https:\/\/github.com\/supabase\/pgvector\n  - https:\/\/milvus.io\/\n\n## Cloud Providers\n- Participants discussed the APIs of various cloud providers, including Azure, AWS, and GCP.\n- Participants also discussed the cost of compute and the expensive APIs of cloud providers.\n- Links: \n  - https:\/\/aws.amazon.com\/comprehend\/medical\/pricing\/\n\n## LLMs and Chip Supply\n- Participants discussed the future of LLMs and chip supply.\n- Participants also discussed the possibility of smaller models becoming more accurate and the emergence of new chips.\n- Links: \n  - https:\/\/tenstorrent.com\/\n  - https:\/\/techcrunch.com\/2023\/01\/10\/openai-in-talks-to-back-zeloof-and-chip-legend-kellers-startup-at-100-million-valuation\/amp\/\n  - https:\/\/zilliz.com\/\n\n## Code Generation\n- Participants discussed open-source LLMs that are strong with code generation and various programming languages.\n- Participants also discussed the use of CodeGen by Replit and AWS CodeWhisperer.\n- Links: \n  - https:\/\/github.com\/huggingface\/diffusers\/releases\/tag\/v0.15.0\n  - https:\/\/github.com\/ravenscroftj\/turbopilot\n\n## Other Topics\n- Participants discussed the use of FAISS, Annoy, ScaNN, and ANNlite.\n- Participants also discussed the possibility of open-source ISAs and the moat for a company lying in proprietary datasets.\n- Links: \n  - https:\/\/github.com\/lllyasviel\/ControlNet-v1-1-nightly\n  - https:\/\/github.com\/ashe_cs\/status\/1646543644038397952?s=46&t=0NBX3C3Uma-Su4_rjA3OMA\n  - https:\/\/www.linkedin.com\/posts\/harshsinghal_under40-activity-7052341005978615809-EaUX?utm_source=share&utm_medium=member_android","42":"LangChain and Tenacity API\n- LangChain uses Tenacity API\n- +1 on using Tenacity API\n- LangChain has an API for the idea of kids as superheroes\n\nAndrej Karpathy's Neural Nets Video\n- Finished watching Andrej Karpathy's video on Neural Nets\n- Highly recommended for anyone starting or in the field\n- Link to the video playlist: https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ\n\nImage Inpainting and Diffusers\n- Tried Img2img models for inpainting on an online image\n- Asked for suggestions on using diffusers for inpainting\n- Link to Stable Diffusion XL beta: https:\/\/stability.ai\/blog\/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users\n\nChatGPT for GitHub Repository\n- Saw a Twitter post about ChatGPT for a GitHub repository\n- Link to the demo video of Chat with GitHub: https:\/\/js.langchain.com\/docs\/modules\/indexes\/document_loaders\/examples\/web_loaders\/github\n- Link to LangChain API for asking questions on a GitHub repository: https:\/\/js.langchain.com\/docs\/modules\/indexes\/document_loaders\/examples\/web_loaders\/github\n\nReflect.Ai and Bard\n- Suggested Reflect.Ai for asking questions on a GitHub repository\n- Bard is performing well for asking questions on a GitHub repository\n- Link to Reflect.Ai: https:\/\/reflect.ai\/\n- Link to Bard: https:\/\/github.com\/ashishb\/Bard\n\nDreamPose AI Model\n- Discussed DreamPose AI model that can generate video from image\n- Link to DreamPose GitHub repository: https:\/\/github.com\/johannakarras\/DreamPose#finetune-on-sample\n\nGenerating Embeddings and Storing in VectorDBs\n- Discussed the difference between generating embeddings and storing them in VectorDBs versus providing them directly to the LLM for question-answering\n- If the dataset has >4000 tokens, it needs to be chunked and stored in VectorDBs for QA by taking relevant chunks\n- If the dataset is <4000 tokens, it can be directly asked to the LLM for QA\n\nAktoGPT and GPT LLM in Production\n- Akto.io launched AktoGPT\n- Ankush discussed things to watch out for before deploying GPT LLM in production\n- Link to AktoGPT: https:\/\/www.akto.io\/blog\/aktogpt\n- Link to Ankush's tweet: https:\/\/twitter.com\/Ankush12389\/status\/1646779395833741313\n\nLangChain with Azure Endpoints\n- Asked if anyone has used LangChain with Azure endpoints instead of OpenAI directly\n- Link to LangChain API for using Azure endpoints: https:\/\/python.langchain.com\/en\/latest\/modules\/models\/llms\/integrations\/azure_openai_example.html\n\nLatency for Commodity Network\n- Discussed the latency for 2000 Bytes over commodity network from 2009 to 2020\n- Link to the research paper: https:\/\/colin-scott.github.io\/personal_website\/research\/interactive_latency.html\n\nStability Diffusion for Robotics\n- CTO of Stability AI talked about Stability diffusion for robotics\n- Link to Stability AI: https:\/\/stability.ai\/\n\nIndustry Directions and Opportunities\n- Discussed the trends in the industry as a way to understand industry directions and opportunities\n\nGoogle Colab Link\n- Shared a Google Colab link\n- Link to the Google Colab: https:\/\/colab.research.google.com\/drive\/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing","43":"React Development:\n- Someone is looking for React developers for a paid weekend project\n- They ask for leads to be DM'd to them\n\nControlnet Inpainting:\n- Someone asks if anyone has gotten the latest controlnet v1-1 nightly release models working with inpainting\n- They mention that they have gotten the models working with multi controlnet, but not for inpainting yet\n\nAzure Cognitive Search:\n- Someone brings up MSFT's recommendation to use Azure Cognitive Search with Azure OpenAI for enterprise document search in Azure\n- They mention that it may be costly and ask for thoughts from the community on production level deployments\n- Another person mentions the option of uploading document embeddings into a Vector DB and doing semantic search\n- They share that they are currently using this method with Pinecone and have 10681 vectors in their DB\n\nGPT-5:\n- Someone shares a link to an article about rumors of OpenAI's GPT-5\n- Another person jokes that they have a friend called GPT-4 who is fairly reasonably priced\n- Someone else mentions that they used Copilot for a project and it helped with a good chunk of front end code\n\nLLM Output Time:\n- Someone asks if anyone has figured out good ways to reduce time in getting output from an LLM\n\nBionic Reading Technique:\n- Someone asks if anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique\n- Another person shares a link to a Twitter thread that may be helpful\n\nOpen-Source Projects:\n- Someone asks why open-source projects like Langchain raise money if their value proposition is the code\n- Others suggest that it may be for managed services, enterprise support, or self-hosted and cloud-hosted strategies\n- They mention examples like OpenSUSE, RedHat, and dbt cloud\n\nAI for Crime Detection:\n- Someone asks if anyone is familiar with AI for crime detection, specifically for loud noises\n\nAWS CodeWhisperer:\n- Someone shares that AWS has released their GitHub Copilot knockoff for free and it seems reasonably good\n- They share a link to an article about how Accenture is using it to improve developer productivity\n- Another person shares a link to a blog post comparing CodeWhisperer and Copilot","44":"## Sci-Fi and AI\n- Discussion on sci-fi authors such as Asimov, Clarke, and Heinlein\n- Comparison of Multivac from Asimov's stories to today's LLMs\/Auto-GPT\n- Sharing of a sci-fi story by Greg Egan\n- Multimodality and its potential to improve LLMs' understanding of reality\n- Sharing of a paper on color clustering\n- Appreciation for Asimov's work and genius\n- Recommendation of Cixin Liu as a favorite author\n\n## Community Guidelines\n- Drafting of community guidelines for the group\n- Sharing of a website for sci-fi enthusiasts (Orion's Arm)\n\n## GPT-Related Topics\n- Request for a service that allows using chatGPT interface with API key\n- Sharing of a website for chatbot UI\n- Discussion on context window handling of such services\n- Recommendation to use GPT-4 with large context windows for cost efficiency\n- Request for guidance on fine-tuning with custom data and sharing of a GitHub example\n- Sharing of articles by Databricks on tuning Dolly LLM\n- Discussion on deploying a Docker image with Sentence Transformers and OpenAI combined\n- Recommendation to deploy the model separately behind a service endpoint to avoid distributing the model in application containers\n- Discussion on the use of embeddings and OpenAI for cost reduction\n- Sharing of a Twitter thread on fine-tuning and prompting\n- Recommendation to use external vector databases like Pinecone or Weaviate instead of fine-tuning for cost efficiency\n- Discussion on chunk size for converting text dump and documents into embeddings\n- Sharing of Langchain's conversation memory types for optimization\n- Question on the possibility of specialized hardware speeding up embedding search\n- Request for a summary of the GPT-related topics due to the increasing number of messages in the group\n- Sharing of a post by Vespa founder on introducing embeddings and vector search\n- Sharing of an IPython ChatGPT extension\n- Discussion on Auto GPT's intermediate summary phase for webpage parsing\n- Experience with LLMs and plans to add new tasks in classifier and separate their workflow standalone\n- Sharing of Langchain's memory chains and conversation memory for summarization and retrieval","45":"Langchain and Mendable.ai integration for building with Langchain; Kapa Langchain bot for asking doubts on Discord; Paradox.ai for recruiters; Skillate and Leoforce for automated resume screening; issues with bias and possible unethical use of AI solutions in recruitment; use of GPT during interviews; AI-generated music; discussion on GPT-4 and its performance on JEE questions; fine-tuning vs. prompt engineering davinci; use of LLMs for math problem solving and chain-of-reason prompting; LOL dataset for low light pictures; Huggingface's PEFT wrapper for multiple fine-tuning methods; founder's R&D work for Bewgle; LLM components for memory weighing in Langchain; publishing research papers on generative AI; controllability issues with LLMs and use of guardrails for structured outputs.","46":"OpenAI Plugin Store:\n- Adept.ai got copied as an in the OpenAI Plugin Store, called Multi-on \n\nExperience needed:\n- People with experience in CLIP, BLIP-2, and VQA are needed for a project \n- Someone with solid experience in multimodal vector similarity search is also needed \n\nMeeting invite:\n- A meeting invite was shared in the WhatsApp group for the project \n\nProjects:\n- Multimodal vector similarity search \n- Personal search \n- Generative AI for solving problems and building multi-modal systems \n- Domain-specific feedback loop and fine-tuning \n- Context-based search with cohere embeddings and OpenAI GPT3.5 for non-English languages \n- Text to video \n- Applications of generative AI in finance \n\nResources:\n- GitHub repository for the project: https:\/\/github.com\/marqo-ai\/marqo \n- Deepset's Haystack and Milvus for modern DL infra \n- Character.ai for personal search \n- OpenAI's Point-e for converting image\/text to 3D model \n- Segment Anything Model for creating an object mask from an image \n- Langdetect for language detection in text \n- ControlNet models for image-to-image generation and control \n\nLinks:\n- Meetup details: https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ \n- Wired article on giant AI models: https:\/\/www.wired.com\/story\/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over\/ \n- GitHub repository for OpenBBTerminal: https:\/\/github.com\/OpenBB-finance\/OpenBBTerminal\/releases\/tag\/v3.0.0rc2 \n- Gradio space for ControlNet: https:\/\/huggingface.co\/spaces\/hysts\/ControlNet \n\nSocial:\n- Instagram account for making videos via SD: https:\/\/www.instagram.com\/reel\/Cq5eWq4rRQC\/?utm_source=ig_web_copy_link","47":"UI Design:\n- Used UI elements from Koo app and dreamstudio\n- Gradio space and playgroundai.com suggested as starting points\n- Jadoosnap.com suggested for product design\n\nData Analysis:\n- Shapiro Wilk test explained as measure of normal distribution\n- Normality not necessary for regression, other methods suggested\n- Support vector regression and tree-based methods suggested for non-normal datasets\n- Extreme Value Theory tools suggested for non-normal datasets\n- Hill Estimator suggested for non-normal datasets\n\nImage Editing:\n- Inpainting models suggested for image editing\n- Qdrant and Chroma suggested for custom databases\n- Vall-e and Descript suggested for voice cloning\n- DeepSpeed evaluated and recommended\n- Ada from OpenAI and sentence transformers from HuggingFace compared\n\nLanguage Models:\n- Open Assistant launched as open-source alternative to ChatGPT\n- Weaviate and StableLM mentioned as language models\n- Cohere multilingual embeddings recommended for Indian languages\n- Bedrock by AWS mentioned as potential for model benchmarks\n\nMiscellaneous:\n- AI financial advisors and detecting \"sexy\" images discussed\n- RDF2vector and RDF2text2vector discussed for embedding ontology and taxonomy in text\n- Request made for image of Indian politician Kamal Nath\n- Nilesh Mishra mentioned as journalist covering Generative AI in India\n- Evalset generator mentioned by [PHONE REMOVED]","48":"Meet-up:\n- Generative AI meet-up in BLR on Saturday evening\n- Link: https:\/\/hasgeek.com\/generativeAI\/april-meetup\/\n\nLLMs:\n- Replit's blog post on training their own LLMs\n- Link: https:\/\/blog.replit.com\/llm-training\n- OpenAI Whisper had a team of 6 for their project\n- Attention is All You Need paper had 8 authors\n- Midjourney outsourced frontend to Discord\n- Microsoft's LayoutLMv3 does OCR\n- Link: https:\/\/huggingface.co\/microsoft\/layoutlmv3-base\n- MM-REACT uses reasoning capabilities of LLMs to extract information from visually rich documents\n- Link: https:\/\/github.com\/microsoft\/MM-REACT\n\nTools:\n- Best practices for recording LLM experiments\n- W&B is a familiar tool\n- CohereAI tweet about model specificity and accessibility\n- Link: https:\/\/twitter.com\/CohereAI\/status\/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19\n\nModels:\n- Controlnet inpaint model\n- Diffusers library\n- Minigpt-4 is better than stability's latest stable diffusion model\n- Llava-vl is a good model for GPT-4 samples\n- Link: https:\/\/llava-vl.github.io\/\n\nOther:\n- EyeQuant founder talks about text2film\n- Link: https:\/\/twitter.com\/fabianstelzer\/status\/1648700767992180737?s=48\n- Original song by Ariana Grande\n- Link: https:\/\/www.youtube.com\/watch?v=DOJremEQw88\n- Martin Shkreli's AI launch\n- Link: https:\/\/twitter.com\/marty_catboy\/status\/1649032460573745152\n- Weights & Biases LLMOps London event\n- Link: https:\/\/www.youtube.com\/watch?v=YfBtytGNEKE","49":"Web and AI Tools:\n- Langchain and WebGPT discussed\n- Kubiya.ai resource shared and discussed\n- Helm charts and K8s clusters can be managed via chat interface using natural language\n- Discussion on the evolution of computer engineering from command lines to GUIs and back to command lines\n\nAI Techniques:\n- Advanced stable diffusion techniques for inpainting and controlnet discussed\n- Tutorial on creating consistent AI characters across images with SD shared\n- Request for AI art\/text to image group\n- Proposal for a separate DeepMedia: Generative Art (Text to Images, Video, Music) group\n- Illustrated Transformers and other resources shared\n\nPinecone:\n- Discussion on hybrid index and querying with only dense embeddings on Pinecone\n\nMiscellaneous:\n- Request for a public xlxs doc to keep track of shared links\n- Discussion on the need for separate image and text to action groups\n- Mention of in-context learning and Microsoft paper on the topic\n- Use of Markdown suggested for organizing group chat discussions.","50":"Cloud GPUs:\n- Discussion on using GPUs for training models\n- Google Colab and Kaggle Notebooks suggested as options\n- Comparison table for cloud GPUs shared\n- Cheapest option for model fine tuning mentioned as rtx5000 on runpod.io\n- Pricing of cloud GPUs discussed, including economies of scale and interest rates on capital investment\n- Vast.ai mentioned as a cloud GPU rental option\n\nModel training:\n- Tips shared for reducing container image size when using Sentence Transformers for word embeddings\n- Question asked about enabling multiple checkpoints in automatic1111 while fine tuning a model using dreambooth\n\nPrivacy concerns:\n- Discussion on privacy concerns when using chatGPT in enterprises\n- Use cases where privacy is important and chatGPT may be necessary discussed\n- GPT-4 mentioned as a potential solution for privacy concerns, with McKinsey as a client\n- Best way to figure out which model will work for a particular use case asked\n\nResources:\n- Link shared for using Google Colab with VS Code\n- Qblocks.cloud suggested as a cloud GPU option\n- Decks from the event mentioned as available for attendees","51":"## Anthropics pitch deck\n- Does anyone have access to Anthropics pitch deck?\n\n## RLHF for instruct models\n- OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely.\n\n## Deepfakes and audio synthesis\n- First instance of an Indian politician referring to deepfakes \/ audio synthesis?\n\n## AI courses and resources\n- course.fast.ai for being able to make sense of all of this \u2014 even as it changes in 2-3 months and we add VQA (Vision) to mainstream OpenAI APIs\n- Lot of new work should come from STT and TTS side, including performance improvements like Whisper-JAX in the coming 4-6 month and more important, voice cloning, avatars and the like. They should have their own \"Lensa moment\" as such if someone markets it well.\n- if i had to recommend a course to cover the NLP hands-on with theory - https:\/\/www.udemy.com\/course\/nlp-with-transformers\/\n- You can still pretty affordable (about $2\/mo) instances on Fly.io\n- If there's anyone interested, Mckay Wrigley is starting a course on Replit on AI dev. The advanced stuff is coming soon but here's the day 0 course. https:\/\/twitter.com\/mckaywrigley\/status\/1649492404943323136\n\n## ControlNet Inpaint guidelines\n- controlnet Inpaint guidelines for A1111. https:\/\/github.com\/Mikubill\/sd-webui-controlnet\/issues\/968 [PHONE REMOVED] you can try out with this and let me know how it is working for you.\n\n## Asymmetric vector embeddings for directional similarity search\n- From the author of controlnet repo: Hi everyone! Shreyas here, I\u2019m a product designer at Clari working on revGPT, a chat interface to get on top of everything happening with sales in an organisation ( and a few personal projects:) ). I saw this tweet by the guy who made BabyAGI, with a new approach to vector search & embeddings: https:\/\/twitter.com\/yoheinakajima\/status\/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg\n- https:\/\/yoheinakajima.com\/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search\/\n\n## Hiring for GenAI\n- what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing\n- This WhatsApp group \ud83d\ude48\n- I hear OpenAI has some decent folks\n- should have a job board :)\n- How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one.\n- Looking to hire folks as well - full time or part time! Job board would be ideal\n\n## Tokenization and word embeddings\n- I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?\n- I haven\u2019t come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set.\n- For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers \/ [ something like that ] and pass the Embeddings to OpenAI for completion\n- They\u2019re also building foundation models\n- [PHONE REMOVED] has built a wrapper around openai tiktoken to count tokens in a file or text -\n\n## Image generation with ControlNet\n- I was trying to generate an image of \"a key ring with the OpenAI logo on it\"\n- u can use ControlNet canny model https:\/\/huggingface.co\/spaces\/hysts\/ControlNet, just start with the openai logo, select the canny model and give the promptt\n- This was controlnet only btw, both canny and hed boundary worked well (you can change that in settings)\n\n## Open domain Q&A and retrieval algorithms\n- Anyone working on open domain Q&A type problems or ones which make use of retreievers\/dense embeddings?\n- Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success).\n- Oh cool, can you share what kind of models and retrieval algorithms you are using?","52":"OpenAI and Dense Embeddings:\n- Currently using OpenAI and dense embeddings\n- Planning to move to hybrid soon\n- Using similarity search on a flat embedding space to retrieve context\n\nGitHub and LLM:\n- Came across a GitHub where someone used PEFT to fine-tune an LLM based on their iMessage chats to impersonate and create a bot that talks like them\n\nSupabase:\n- Discussion about Supabase and Postgres performance queries\n- Suggestions to check RLS policies and use explain.dalibo.com to visualize queries\n- Offer to help with specific links on Github or Discord forum\n- Mention of a new branch for Mac release of Automatic1111\n\nChatGPT:\n- Discussion about school kids in India using ChatGPT\n- Mention of e2eml.school\/transformers.html\n- Anecdotal evidence of kids using ChatGPT for school essays\n\nGenerative AI Speakers:\n- Discussion about having more Amod-esque speakers\n- Suggestions for speakers from AI21 Labs, Cohere, and Anthorpic\n- Plans to set up an event\/session link to register for upcoming talks\n- Discussion about potential themes for upcoming talks, including image generation, video, and sound\n\nMotion Capture and Pose Estimation:\n- Request for someone with experience working with motion capture\/face-body reenactment or topics related to pose estimation\n- Offers from multiple people to chat about these topics\n\nNewlines and OpenAI Embedding API:\n- Discussion about differences between using newlines\/replacing them when using OpenAI's embedding API\n- Explanation that new lines are not part of the vocabulary and do not have semantic meaning when encoded\n- Mention of character splitters and the importance of context length\n\nMiscellaneous:\n- Article recommendation on safetyism\n- Discussion about Interoperable Master Format\n- Mention of a hackathon link related to voice models","53":"## ChatGPT Chrome Extensions\n- Discussion on cool ChatGPT related Chrome extensions\n\n## RL without Human Feedback\n- Shared interesting read on potential to use RL without human feedback\n\n## OSS Projects\n- Discussion on interesting OSS projects in the space\n\n## ShareGPT\n- Mention of ShareGPT\n\n## AI Dating Expert\n- Discussion on a bot trained on Bumble chats to reply like the user\n\n## Prompt Injection Attacks\n- Warning about prompt injection attacks\n\n## Vector Search\n- Discussion on using vector search on past swipes and bios\n\n## OpenAI Branding\n- Discussion on OpenAI branding and trademark on GPT\n\n## Qdrant\n- Discussion on using Qdrant for vector search\n\n## Fine Tuning OpenAI Models\n- Discussion on fine tuning OpenAI models on code\n- Tips and do's\/don'ts for fine tuning\n- Use of embeddings and GPT-3.5 for creating diagrams\n\n## GPU Hosting Providers\n- Discussion on affordable spot GPU\/cloud providers\n\n## Cloning Voices\n- Discussion on cloning voices using data collection and cleaning\n- Use of open source models and hiring freelancers\n\n## AutoGPT and Fixie\n- Discussion on using AutoGPT and Fixie for useful projects\n- Use of Fixie's SDK\n\n## Context Window and Fine Tuning\n- Discussion on using context window and fine tuning for product design\n- Use of multi-tenant setup and few-shot prompting\n\n## Data Privacy\n- Discussion on Indian clients' concerns about data usage for model training\n- Fine print of OpenAI's data usage policy\n- Boris Power's advice on using prompting and fine tuning\n\n## Other Tools and Resources\n- Use of Weaviate for vector search\n- Use of Modal Labs for Python-friendly web endpoints\n- Discussion on using serverless and stateful use cases\n- Discussion on Anthropic as a competitor to OpenAI","54":"OpenAI:\n- Doubtful of claim that they don't need data, they still need more data for training\n- Multinationals may start using OpenAI models\n- OpenAI is looking for data partnerships, but currently only able to cater to proposals from big tech companies\n- No list of data partners available\n- OpenAI's platform API data policy is public information\n- OpenAI is small and has exhausted internet and academic datasets for training their models\n- Replit Codegen model is better than OpenAI Codex in many human eval tasks and is smaller in size\n- OpenAI's models are a utility like EC2 and have greatly improved the UX of consuming models\n- Many NLP models now work with OpenAI's transformer library\n- Stanford NLP is highly regarded\n- Qualcomm has made progress in ML on edge\n- Palantir has launched ChatGPT for war\n- Anduril may come up with something similar\n- OpenAI's tech use cases range from disaster relief to drone warfare\n\nMusic and Audio Generation:\n- Discussion on music generation, audio generation, jingle generation, song generation, and new AI instruments\n- Shared interest in the topic\n\nGenerative AI:\n- Accel's slide deck on opportunities in generative AI and finetuning vs prompting\n- Replit Demo Day videos soon to be on YouTube\n- Dedicated group for music, images, and video on WhatsApp\n- Expert talk on music generation requested\n- Dust.tt is an internal tool for now\n- Recommendation for paperspace for GPU access\n- Google Colab is $12 for 100 compute units\n- Runpod, lambdalabs, and fluidstack recommended for serverless GPU access\n- Compute units on Google Colab are unclear\n- T4 24GB GPU offered on Google Colab for $12\n- Weaviate discussed in relation to storing metadata for vector DBs\n\nLinks:\n- https:\/\/twitter.com\/Mascobot\/status\/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19\n- https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/12yzd2a\/google_researchers_achieve_performance\/\n- https:\/\/www.qualcomm.com\/news\/onq\/2023\/02\/worlds-first-on-device-demonstration-of-stable-diffusion-on-android\n- https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J\n- https:\/\/www.linkedin.com\/posts\/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios\n- https:\/\/research.google.com\/colaboratory\/marketplace.html\n- https:\/\/www.chartgpt.dev\/\n- https:\/\/news.ycombinator.com\/item?id=35697627\n- https:\/\/github.com\/ai-forever\/Kandinsky-2","55":"## Weaviate\n- Weaviate allows pre-filtered vector search based on metadata and builds separate indices for metadata.\n- Their managed SaaS charges based on the number and dimensions of vectors, irrespective of the extra metadata stored.\n\n## Learning LLMs\/Transformers\/ML\n- Someone suggested doing a zoom session to discuss learning LLMs\/Transformers\/ML.\n- People discussed how they are dealing with rate limits and 5xx errors with OpenAI.\n- Some suggested using a leaky bucket to smoothen the API calling rate.\n- Others suggested using proxies like Nginx with Lua JIT or Envoy with WASM\/Lua for production setup without adding much latency and performance overhead.\n\n## Indic-BloomLM\n- Someone was trying to train Indic-BloomLM but was stuck with a memory leak issue.\n\n## Serverless GPUs\n- People discussed using serverless GPUs like bananadev and qblocks.cloud.\n\n## OpenAI Rate Limits\n- Someone asked if anyone had gotten higher rate limits from OpenAI.\n- Some people mentioned that they had gotten their rate limits upgraded multiple times at Pepper Content.\n\n## State of AI Talk\n- Someone shared a link to a talk by two leading US researchers in AI.\n- The talk was limited to 20 seats due to venue constraints.\n- People asked if there was a chance of a live stream\/recording.\n- Some recommended resources for learning AI, including fast.ai and a Google Sheets document.\n\n## Pinecone\n- Pinecone raised $100 million and is having a moment in the age of langchain.\n- People discussed Pinecone's success and the importance of DevRel for Dev products.\n- Some people shared their positive experiences with Pinecone and their content game.\n- People expressed interest in knowing which startups\/companies are using Pinecone.\n\n## Contributing Spark Loader for Hugging Face Datasets\n- Someone shared a link to a blog post about contributing a Spark loader for Hugging Face datasets.\n- People discussed planning a session on the topic.","56":"## Generative AI Meetup\n- Nvidia-HF event on Saturday morning\n- Online event, URL: https:\/\/sites.google.com\/huggingface.co\/generative-ai-meetup\n- Need an experienced person to guide and answer queries, volunteer needed\n- Twitter link for volunteer: https:\/\/twitter.com\/thesephist\/status\/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19\n\n## AI Applications\n- Using diffusion for detection\/recognition\/segmentation tasks\n- Tesla using diffusion as part of their lane detection algorithm\n- Transformers used for lane detection, URL: https:\/\/youtu.be\/aVjDX5XshYo\n- Text2motion\n- Promptlayer\n- Data exploration and feature engineering resources needed\n- Sequential prompting for controlled conversation, e.g. roleplay\n- AlignmentAI and PMGPT for guided chat with roleplay\n- AI assistant\/co-pilot for product managers\/product teams\n- GPT plugins\n\n## AutoGPT\n- AutoGPT for basic questions\n- AutoGPT's limitations\n- AutoGPT's marketing\n- Large scale human feedback and nudges for AutoGPT\n\n## Namefinder.ai\n- Namefinder.ai for product names\n- Suggestions for AI assistant\/co-pilot names\n\n## GPT-4 API Access\n- Technical folks waiting for GPT-4 API Access\n- GPT plugins\n- Azure OpenAI service\n\n## FP8\n- FP8 based on NVIDIA's Transformer Engine\n- Faster inference and more Fp16, Fp8\/int8 proliferation for task-specific models\n- Impact on large model, faster model, or new model arch\n\n## Serverless GPUs\n- Serverless GPUs and cost savings\n- Market competition dictating pricing instead of arbitrary end user value\n\n## Langchain\n- Building with Langchain\n- Private V2 for collectiv LangchainX\n\n## Code Summarization\n- Tools for summarizing custom code repos\/documentation\n- GitHub repo summarization tool URL: https:\/\/github.com\/peterw\/Chat-with-Github-Repo\n\n## Other\n- MEPs seal the deal on artificial intelligence act, URL: https:\/\/www.euractiv.com\/section\/artificial-intelligence\/news\/meps-seal-the-deal-on-artificial-intelligence-act\/\n- Coreweave talks about tier 3 datacenters in North America\n- DeepFloyd for text-to-image model, URL: https:\/\/stability.ai\/blog\/deepfloyd-if-text-to-image-model\n- Stable diffusion model and its ecosystem","57":"## VectorDB and LlamaIndex\n- Discussion on whether LlamaIndex or Langchain support VectorDB with Sources with GPT4 or GPT3.5-Turbo\n- Sharing of GitHub link for LlamaIndex demo\n- Suggestion to use response.source_nodes to get sources\n- Discussion on using evaluation module or regex to get desired sources\n- Mention of OpenAI models not citing references\n- Sharing of Langchain link for QA with sources example\n- Discussion on limitations of Langchain and need to extend chain functions\n- Mention of LlamaIndex not having such limitations\n\n## AI Models and Applications\n- Discussion on models for aesthetic score of images\n- Mention of ResNet and classification model for user-scored images\n- Discussion on generating professional-level DSLR photos using AI\n- Mention of LAMINI AI library for fine-tuning LLMs to custom domains\n- Announcement of upcoming \"Learning Transformers\/NLP\/ML\" discussion\n- Discussion on D-ID and SadTalker for generating content\n- Mention of Whisper models for Hindi transcription\n- Suggestion of Deepgram and Monster API for transcription\n- Discussion on building generative model for legible pdf\/image documents\n- Mention of AI-generated content for social media and advertisements\n- Request for transcription API that can handle Hindi and regional languages\n\n## Miscellaneous\n- Discussion on automating extraction of WhatsApp group data\n- Mention of RunwayML Gen 2 and Text2Video-Zero\n- Request for transcription API that can handle Hindi and regional languages\n- Announcement of weekly\/monthly newsletter\n- Request for tech expert in Generative AI for Zoom meet-up\n- Request for connections with those working on advertisements\n- Discussion on building AI avatars and personalized content\n- Mention of guardrails for cloned voices\n- Discussion on building QnA over CSVs using Python code or SQL","58":"## Music and AI\n- Collaboration between GPT and Bark for music creation\n- \"Bark is lit too\" \ud83d\udd25\n\n## AI Tools and Libraries\n- pandas-ai library: https:\/\/github.com\/gventuri\/pandas-ai\n- Issues with ChatOpenAI giving \"Could not parse LLM output:\" errors\n- Code snippets for language chain helpers and embeddings utils: \n  - https:\/\/github.com\/jerryjliu\/llama_index\/blob\/590639a14dd7346b7f5cc00a21dd24ce0d35ae30\/gpt_index\/langchain_helpers\/text_splitter.py#L240\n  - https:\/\/github.com\/openai\/openai-python\/blob\/c556584eff3b36c92278e6af62cfe02ebb68fb65\/openai\/embeddings_utils.py#L21\n- Scale.com for content language: https:\/\/scale.com\/content-language\n\n## AI Models and Projects\n- Cohere's multilingual model\n- Project idea for creating shortcuts to automate tasks\n- Resources for creating charts\/graphs from data, open-source \"Chart-GPT\" resources especially python based\n- Implementing file search using Langchain's drive connector\n- Performance gains attributed to Rust vs Golang for HNSW algorithm\n\n## AI Discussions and Queries\n- Issues with limited RAM on Repl on Replit\n- Measuring recall for file search\n- Tuning recall\/speed for HNSW algorithm\n- Learners' discussion at 4pm\n- Feedback on a new product for generating design from prompts using a design system\n- Generative AI impact on graphic design and marketing\n- Interviewing product designers and graphic designers in marketing agencies\n\n## AI Resources and Links\n- LLM.report for dashboard of costs incurred while using OpenAI api\u2019s: https:\/\/llm.report\n- Ann-benchmarks for recall measurement: https:\/\/ann-benchmarks.com\n- Twitter link for stable diffusion in graphic design: https:\/\/twitter.com\/bohanhou1998\/status\/1652151502012837890?s=20","59":"Access to GPT Plugins:\n- OpenAI demos it publicly\n- Participants want access to the tool\n- Suggestion to make a Twitter viral demo to get access\n- One participant has access but cannot find the tool in the UI\n\nWeb Development:\n- Request for freelance Flask\/Python web stack developers\n- Link to GitHub repository for Eva: https:\/\/github.com\/georgia-tech-db\/eva\n\nAutoGPT:\n- AutoGPT is emerging as a catch-all for automation\n- Jason Calacanis has posted a bounty for outbound sales emails on Replit\n- One participant was able to deploy something locally to generate personalized DM, email, and coffee conversation points for a LinkedIn profile as a non-coder\n\nGroup Management:\n- Request to add a friend to the group\n- Request to post a GenAI internship opportunity at Koo\n- Suggestion to create a separate, uncensored group for sharing and subscribing to news\n- Suggestion to create a subreddit with flairs for hiring, news, and discussion\n- Suggestion to have a weekly post with all open roles instead of a separate WhatsApp group\n- Google Form for hiring from the community: https:\/\/nirantk.com\/community\n- Discussion on the effectiveness of posting on LinkedIn for specific areas and the lack of GenAI communities\n- Suggestion to have a different announcement group\n\nAI Philosophy:\n- Discussion on the lack of discussion on AI philosophy\n- Bias towards action over discussion\n\nWarpspeed:\n- Invitation to team up for Warpspeed\n- Hope that the event will be online\n- Confirmation that it is an offline event and only selected candidates will be allowed\n- Custom model for the event\n\nTechnical Issues:\n- Error message when calling the API from outside the notebooks\n- AuthenticationError: Your authentication token is not from a valid issuer\n- Suggestion to use Wireshark to find the headers\n- Playwright suggested as an alternative to reverse engineering the Jupyter Notebook API\n\nTED Talks:\n- Sal Khan's new TED Talk on the vision reimagined with AI\n- Hinton leaving Google: https:\/\/www.nytimes.com\/2023\/05\/01\/technology\/ai-google-chatbot-engineer-quits-hinton.html","60":"## Article Bias and Twitter\n- Discussion about biased articles and preference for tweets\n- Shared link to a tweet: https:\/\/twitter.com\/zoink\/status\/1653052807950536706\n\n## Learning with ChatGPT\n- Discussion on how to use ChatGPT for learning\n- Mention of yudbot.com as a resource\n\n## API Level Caps\n- Mention of developing an API level cap for a llm vault manager\n- Question on whether API level caps are generally kept\n- Shared link to yudbot.com as a potential resource\n\n## Paywalls and Capitalism\n- Discussion on paywalls and access to news articles\n- Mention of capitalism in a political group context\n\n## Conversational Memory with GPT-3.5-Turbo\n- Question on how to add conversational memory to GPT-3.5-Turbo\n- Shared link to a potential resource\n\n## Langchain\n- Mention of Langchain and its shortcomings\n- Discussion on whether to use Langchain or roll your own solution\n- Mention of llamaindex as an alternative\n- Mention of a friend's positive experience with llamaindex for chat conversations\n- Mention of a Lucene-based ANNs project\n- Mention of company-level constraints on using certain tools\n- Mention of lack of quality checks in Langchain repo\n- Mention of Langchain prioritizing agents and toolchain over everything else\n- Mention of a potential Langchain alternative, Semantic Kernel\n- Discussion on API design and community traction\n- Mention of issues with Langchain at scale\n- Shared link to llama_index default prompts\n\n## Rolling Windows and Summarization\n- Discussion on implementing rolling windows contexts\n- Mention of issues with moving windows approach\n- Suggestion to use dynamic rolling window for every question\n- Discussion on summarization and use of OpenAI summarization API\n- Mention of prompt engineering as a solution\n- Suggestion to use a smaller and faster model for summarization\n- Mention of using GPT-3.5 and prompt engineering to keep temp low\n- Mention of experience vs expense trade-off\n- Mention of sandboxing Python environment\n- Mention of executing untrusted code from an LLM\n- Mention of using tools and agents with Langchain as part of OpenAI cookbook\n\n## Miscellaneous\n- Mention of a potential resource for creating a running summary of earlier conversations\n- Mention of knowing the creator of 42papers.com, artcompute.com, and mindsjs.com\n- Mention of a potential solution for executing untrusted code from an LLM","61":"## Topics Discussed in Chaotic Generative AI Group Chat Transcript\n\n### AI Models and Tools\n- GPT4 creates a vector DB\n- Replit open source LLM just dropped\n- Finetune on instruction dataset curated from geeksforgeeks\n- Prompt Injection in less than 10 minutes (video, slides, transcripts)\n- JSONFormer: guaranteed JSON output with Huggingface LLMs\n- DeepFloyd or Multi-ControlNet?\n- Is there a model (other than gpt4) that can extract info from an image in JSON format?\n- Autogpt app\n- Table-transformer might help if result cards are in tabular form\n\n### AI Applications\n- Abstract artwork made using stable diffusion\n- Extracting values without OCR\n- Parsing information from result cards\n- Langflow\n\n### AI Industry and Innovation\n- India's position in the generative AI race\n- Chris Lattner's new ML-focused language\n- Ecosystem graphs for AI startups\n\n### Networking and Collaboration\n- Connecting with others in the group for contribution and collaboration\n- Looking for journalists or media folks in the group\n\n### Miscellaneous\n- Group invite link request\n- AI and art techniques\n- OpenAI service on Azure\n- Multi-modal GPT4 access\n- Sanford C. Bernstein's analysis of AI-based startups in India","62":"Introduction and greetings\n- Members introduce themselves and exchange pleasantries\n\nGenerative AI for digital painting\n- Discussion on the potential for creating artist-focused digital painting tools using Generative AI\n- Current methods involve hacking with automatic tools and using Photoshop to achieve desired results\n\nLarge scale dataset creation for LLM model training\n- Member asks if anyone has experience creating large scale datasets","63":"OpenAI and Google models:\n- Google models have no moat\n- OpenAI may have a moat due to early mover advantage and alignment with Microsoft\/Azure\n- OpenAI's moat may come from government and finance domains\n- OpenAI may be able to maintain its lead for 2 to 5 years or more\n- Open source models are far behind OpenAI currently, but may catch up eventually\n- Network effects may not be a moat in this case\n- Microsoft+OpenAI can make inference costs low and onboard other businesses on plugins\n\nHugging Face:\n- StarCoder LLM launched\n- Good intro + inference optimizations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up\n- Resources for SoTA large models in multimodal space (text, image, video, audio, etc) available on Amazon's mm-CoT on HF and PapersWithCode\n\nGenerative models:\n- Probabilistic functions in generative models may be pseudo-random and can be controlled via seed\n- Rate limits for models may be shared or separate\n- Determinism can be achieved by fixing the seeding of the model or setting temperature=0\n- Randomness in GPT comes from the probability distribution over the vocabulary\n- Meta's SAM and Track Anything can be used for tracking logos from video\n- So-vits-svc is a good tool for replicating AI songs\n\nOther:\n- Discord server with a lot of models available\n- SlackGPT is a horizontally integrated business workflow with Slack\n- MPT-7B-Instruct checkpoint used for ChatGPT, but may not do well with code understanding\n- Wandb.ai has prompts for generating text.","64":"## Introduction\n- Group chat transcript on Generative AI\n- Chaotic discussion on various topics\n\n## Learning Resources\n- Link to a post on what transformers are\n- Cohere has two of the best ML content creators\n- List of top AI-themed newsletters shared\n- 42papers.com recommended\n- Ben's Bites newsletter recommended\n\n## Hackathon\n- Invitation to join a team in Warpspeed GenAI hackathon\n\n## Deterministic Output\n- Discussion on making GPT2 or BLOOM model outputs consistent\n- Two ways to make it deterministic: setting temp=0 or setting seeds\n- Pro tip to pursue this line of reasoning and gain first-hand experience\n\n## Visual Aesthetic Scoring\n- Discussion on AVA dataset and image dataset curation methods\n- Link to a space on huggingface for aesthetic predictor\n- Use of clip interrogator to score generated captions\n- Hallucination and determinism are not related\n- Visual aesthetic scoring is largely a final layer problem\n- Discussion on the limitations of the model\n\n## Dataset Creation\n- Request for good library references to create datasets for LLMs\n- Discussion on creating a dataset based on few hand-written examples\n- Suggestion to check the terms of service for commercial use\n- Discussion on using a visual QA model to identify errors in a picture\n- Workflow suggestion to detect errors in the image and fix them using models finetuned on those datasets\n- Suggestion to use Andrew Ng's landing.ai for the task\n- Discussion on using multiscale patches and CLIP to check similarity with the prompt\n\n## Finance GPT\n- Discussion on usable finance GPT\n- Bloomberg GPT is expensive\n- OpenBB is an open-source alternative to Bloomberg terminal\n\n## Autonomous Agents\n- Discussion on autonomous agents space\n- Link to a beginner's guide to autonomous agents\n- GitHub repository for a simpler and no dependencies solution","65":"## OpenAI's decision to not do closed source\n\n- OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of safety reasons, but because of competitive reasons.\n- He believes models can be improved to the point in the future where it becomes a safety concern.\n\n## Competitive reasons\n\n- The competitive reasons mentioned by Ilya S. refer to Microsoft, which is a major investor in OpenAI.\n- Microsoft has been known to use closed source models in the past, which gives them a competitive advantage.\n\n## AI-generated art\n\n- The group discusses AI-generated art and how it is becoming more popular.\n- They mention a website called Artbreeder (https:\/\/www.artbreeder.com\/) that allows users to generate and manipulate images using AI.\n\n## AI-generated music\n\n- The group discusses AI-generated music and how it is still in its early stages.\n- They mention a website called Amper Music (https:\/\/www.ampermusic.com\/) that allows users to generate music using AI.\n\n## AI-generated text\n\n- The group discusses AI-generated text and how it is becoming more advanced.\n- They mention a website called GPT-3 Playground (https:\/\/gpt3.org\/) that allows users to interact with OpenAI's GPT-3 language model.\n\n## AI ethics\n\n- The group briefly discusses AI ethics and the need for responsible AI development.\n- They mention the AI Now Institute (https:\/\/ainowinstitute.org\/) as a resource for learning more about AI ethics.\n\n## AI in healthcare\n\n- The group briefly discusses the use of AI in healthcare.\n- They mention a website called AI in Healthcare (https:\/\/aiinhealthcare.org\/) that provides information on the use of AI in healthcare.\n\n## AI in finance\n\n- The group briefly discusses the use of AI in finance.\n- They mention a website called AI in Finance (https:\/\/aiinfinance.com\/) that provides information on the use of AI in finance."},"EndNote":{"0":"- https:\/\/www.youstick.fun\/ - a website that allows users to create fun stickers using their own photos for use in messaging apps like Whatsapp, Instagram, Slack, and Discord. Mentioned in a message from Amogh, a former director of product at Avataar, who is currently working on a project in generative AI.","1":"- OpenAI's Twitter URL (https:\/\/twitter.com\/OpenAI\/status\/1630992406542970880?s=20) provides an update on ChatGPT and Whisper API, with a TL;DR on the ChatGPT API launch.\n- https:\/\/twitter.com\/c_valenzuelab\/status\/1630969280803250176?t=Timm5pV-ymLQM02QPZM-sg&s=08 (Message: \"Ok I finally got controlnet working in a way that makes me happy!\")\n- Corridor Digital reveals how they made Anime using SD VFX and Blender (scenes) on Twitter via @stabilityai.","2":"- Two interesting a16z articles: \n  https:\/\/a16z.com\/2023\/01\/19\/who-owns-the-generative-ai-platform\/ \n  https:\/\/a16z.com\/2023\/02\/07\/everyday-ai-consumer\/\n- https:\/\/a16z.com\/2023\/01\/19\/who-owns-the-generative-ai-platform\/ and https:\/\/a16z.com\/2023\/02\/07\/everyday-ai-consumer\/ are related to the topic of AI ownership and consumer applications, while https:\/\/www.amoghvaishampayan.com\/post\/generative-ai-product-strategy provides a deeper dive into successful AI product strategies.\n- The URL https:\/\/a16z.com\/2023\/02\/07\/everyday-ai-consumer\/ is related to an article about successful AI products, and the author provides a deeper dive into the topic in their own article at https:\/\/www.amoghvaishampayan.com\/post\/generative-ai-product-strategy. The author has experience as an AI product manager and summarizes the essence of their article as a strategy for generative AI products.\n- https:\/\/www.reforge.com\/blog\/ai-products-arms-race and https:\/\/www.biorxiv.org\/content\/10.1101\/2022.11.18.517004v2.full.pdf - The author, who has worked as an AI product manager for the last 5 years, shares their insights on generative AI in an article.\n- https:\/\/www.reforge.com\/blog\/ai-products-arms-race: A blog post about the AI products arms race.\n- https:\/\/youtu.be\/hQC5O3WTmuo - YC Founder talks to YC Partner about getting actual footage of your dreams.","3":"- The website https:\/\/theresanaiforthat.com\/ has open-sourced their Hasura AI bot code and made it easy to deploy with one click. More information can be found on the website.\n- The tweet from MetaAI discusses how Offset Noise is impacting AI Art and includes a link to the original tweet. https:\/\/twitter.com\/MetaAI\/status\/1631351811696394240?s=20","4":"","5":"- https:\/\/www.marktechpost.com\/2023\/02\/28\/oxford-university-researchers-introduce-a-diffusion-model-called-realfusion-that-can-generate-360-degree-reconstructions-of-objects-from-an-image\/?amp: Oxford University researchers introduce a diffusion model called RealFusion that can generate 360-degree reconstructions of objects from an image. The message in the same link as the URL is not related to the breakthrough.\n- https:\/\/unsupervisedlearning.substack.com\/p\/using-large-language-models-effectively: An interesting read about using large language models effectively, with a specific focus on the #4 point around embeddings. The message also mentions the use of Pinecone and Langchain in the Hasura bot for embedding purposes.","6":"- Check out this interesting resource for generative AI models: https:\/\/research.runwayml.com\/gen1","7":"","8":"- The first URL (https:\/\/zenil.substack.com\/p\/indian-generative-ai-landscape-the?r=1f3ivv&utm_campaign=post&utm_medium=web) is an article about the Indian generative AI landscape, while the second URL (https:\/\/www.reddit.com\/r\/singularity\/comments\/11mztcu\/gpt4_is_coming_next_week_and_it_will_be\/) is a Reddit post discussing the upcoming release of GPT-4.\n- https:\/\/zenil.substack.com\/p\/indian-generative-ai-landscape-the?r=1f3ivv&utm_campaign=post&utm_medium=web: An article about the Indian generative AI landscape. The message in the same link as the URL is not provided. \n- https:\/\/www.reddit.com\/r\/singularity\/comments\/11mztcu\/gpt4_is_coming_next_week_and_it_will_be\/: A Reddit post about the upcoming release of GPT-4. \n- Thanks [PHONE REMOVED] for adding me here.: A message thanking someone for adding the sender to a group or community. No context is provided for the group or community.","9":"- Register here for a hackathon invite to the BLR venue: https:\/\/forms.gle\/UizUwyKi4bajt6WB7 (Participants may not need to fill it)\n- https:\/\/www.youtube.com\/watch?v=VdMgPgicvK4: Registrations shall come :P. Anyone with access to Runwayml?","10":"","11":"- https:\/\/alpaca-ai-custom4.ngrok.io\/ - The message discusses the slow performance of the website for trying prompts and compares its ability to follow logic to the davinci-002 series. It also mentions uncertainty about the training process due to the lack of weights.\n- https:\/\/twitter.com\/OpenAI\/status\/1635687373060317185?t=nhm2BaNejunBE9-syFgEeA&s=19 - The tweet mentions that the instruct dataset is key and provides a link to the PR raised with Huggingface for the training code. It also suggests that the project is built for enterprise.\n- https:\/\/www.youtube.com\/live\/outcGtbnMuQ?feature=share - The message mentions the \"be my eyes demo\" being hilarious and thanks someone, but also notes odd timing and waiting for a summary from others.","12":"- https:\/\/twitter.com\/prashanthshanm\/status\/1635646028648177669?s=20 - A tweet with the message \"Too late, too little \ud83d\ude02\ud83d\ude05\ud83d\ude02\ud83d\ude05\"\n- https:\/\/web.stanford.edu\/class\/cs25\/, https:\/\/web.stanford.edu\/class\/cs224n\/index.html#schedule, https:\/\/people.cs.umass.edu\/~miyyer\/cs685\/ - Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks\/ months). With my limited understanding, I think fine-tuning any LLM is quite tricky. The message in the same link as the URL is related to the link.\n- https:\/\/web.stanford.edu\/class\/cs25\/, https:\/\/web.stanford.edu\/class\/cs224n\/index.html#schedule, https:\/\/people.cs.umass.edu\/~miyyer\/cs685\/ - Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks\/ months). With my limited understanding, I think fine-tuning any LLM is quite tricky. The message in the same link as the URL is related to the link.\n- https:\/\/web.stanford.edu\/class\/cs25\/, https:\/\/web.stanford.edu\/class\/cs224n\/index.html#schedule, https:\/\/people.cs.umass.edu\/~miyyer\/cs685\/ - Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks\/ months). With my limited understanding, I think fine-tuning any LLM is quite tricky. The message in the same link as the URL is related to the link.\n- https:\/\/www.ai-art.dev\/web-uis-for-stable-diffusion: A link to a write-up on different web UIs related to stable diffusion. The message also suggests exploring image2image, in-painting, out-painting, and instruct pix2pix. The link is shared in a LinkedIn post about organizing an activity in Bangalore.\n- https:\/\/www.ai-art.dev\/web-uis-for-stable-diffusion: A write-up on different web UIs for stable diffusion, shared by Sayak Paul on LinkedIn along with a message about working with artists to empower them more.\n- https:\/\/mobile.twitter.com\/arankomatsuzaki\/status\/1635453248252391427: A tweet discussing the use of RNNs in empowering artists and questioning the emergence of properties during training.\n- https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html?m=1 - The blog post discusses the relationship between model size and emergent properties in language models, and asks whether these properties arise gradually or all at once during training. A GIF from the post is also referenced for additional context.\n- https:\/\/ai.googleblog.com\/2022\/04\/pathways-language-model-palm-scaling-to.html?m=1 - The blog post discusses the relationship between model size and emergent properties in language models, and asks whether these properties arise gradually or all at once during training. A GIF from the post is also referenced for additional context.","13":"- https:\/\/twitter.com\/LangChainAI\/status\/1636122692645691393?t=aUUOXK9kILoYkyVzVgjdhg&s=19 - The message in the same link as the URL mentions not replying with DM and the need to explore storing embedding vectors in a PG database.","14":"- https:\/\/www.youtube.com\/watch?v=VqhDnaqhnd4 - The message expresses appreciation for something impressive and asks a question about language models cutting off in 2021.\n- https:\/\/www.springboard.com\/blog\/data-science\/machine-learning-gpt-3-open-ai\/ : This link leads to a blog post about open source datasets related to machine learning, and mentions that the Gpt-4 paper might have details about the datasets, but the paper was disappointing.","15":"- New BingGPT Launch: https:\/\/www.bing.com\/new - This has the potential make advertising briefs soooo much easier \ud83d\udcaf\n- The URL https:\/\/www.gizmochina.com\/2023\/03\/16\/ai-hire-a-human-to-solve-captcha\/ is related to the potential use of AI in solving CAPTCHAs and its impact on advertising briefs, while the message in the same link discusses the potential impact of GPT4 on software engineering.\n- The message in the same link as the URL states \"open journey is good though compared to available open-source models?\" and encourages the reader to have fun. URL: https:\/\/civitai.com\/\n- https:\/\/crfm.stanford.edu\/2023\/03\/13\/alpaca.html: This link leads to a webpage about a self-instruction dataset, and was accompanied by the message \"haha\".\n- The URL https:\/\/github.com\/tatsu-lab\/stanford_alpaca\/blob\/main\/alpaca_data.json is being praised for its excellence, but it is unclear who created it.\n- offset noise write up - https:\/\/www.crosslabs.org\/blog\/diffusion-with-offset-noise (related to catching up on conversations about generative AI space)","16":"- https:\/\/simonwillison.net\/2023\/Mar\/17\/beat-chatgpt-in-a-browser\/ (favorite blog shared by the sender)\n- https:\/\/simonwillison.net\/2023\/Mar\/17\/beat-chatgpt-in-a-browser\/ - Nickfloats shares their favorite blog from the last few weeks about using WASM for LLMs and asks if anyone has tried it.","17":"- The Twitter user @tarundua81 shared a link to a Hugging Face model for text-to-video synthesis and asked if anyone had tried it. The link to the model is https:\/\/huggingface.co\/spaces\/damo-vilab\/modelscope-text-to-video-synthesis.\n- https:\/\/twitter.com\/tarundua81\/status\/1625092808095961090: A Twitter user shared a link to a Hugging Face model for text-to-video synthesis and asked if anyone has tried it. They also mentioned Reid Hoffmann's essay on GPT4 and wondered if there is an AI summary available.\n- https:\/\/hbr.org\/2023\/03\/how-will-generative-ai-disrupt-video-platforms: HBR essay shared by Shubham, a writer on TVF Pitchers S2, discussing how generative AI will disrupt video platforms in the future.\n- https:\/\/youtu.be\/onjfu3Uh2vI (recap of something not watched)\n- OpenAI wrote a paper on the potential impact of Large Language Models on the Labor Market thread https:\/\/twitter.com\/rubinovitz\/status\/1637651591191842816?t=g4U4qTnkF-R02mImutwo8w&s=19. With the amount of funds that OpenAI has, are these PR stunts?\n- https:\/\/twitter.com\/arankomatsuzaki\/status\/1637612922934382593 \nRequest: When sharing links in future, please add a line about why should we click through or what is the topic about!\n- https:\/\/vercel.com\/templates\/ai: The message in this link states that tech bros only drink sparkling water, but the actual link leads to some cool Replit templates.\n- https:\/\/replit.com\/templates?q=AI: This link leads to a page with various Replit templates related to AI.","18":"- https:\/\/bit.ly\/hf-nvidia-meetup: The message in the same link as the URL discusses the use of custom trained models by Flair, which are mask-based and include outpainting. The message also mentions other methods such as ControlNet, Adapters, and Composer for controlling style, image composition, and color scheme without the need for fine-tuning models.\n- https:\/\/news.ycombinator.com\/item?id=35236275: The message in this link discusses the possibility of creating apps similar to the one mentioned in the link, and the author mentions having worked on document search.\n- https:\/\/www.deepset.ai\/blog\/build-a-search-engine-with-gpt-3: The message suggests checking out this link about building a search engine with GPT-3 by deepset, who also have a framework called Haystack. The context also mentions some smart background replacement images and a slight halo visible when staring at something for too long.\n- https:\/\/dolorousrtur.github.io\/hood\/ - a project with impressive demos mentioned in a message along with a phone number.\n- https:\/\/a16z.com\/2022\/11\/17\/the-generative-ai-revolution-in-games\/ - The message in the same link as the URL is related to the article about the generative AI revolution in games.\n- https:\/\/www.adept.ai\/ - A link mentioned in a discussion about the nerf space and its potential as a game changer in computer usage.\n- https:\/\/www.adept.ai\/ and similar space are discussed as a game changer in how we use computers, and the message also mentions related research and prompt engineering links.\n- https:\/\/proceedings.mlr.press\/v70\/shi17a.html - a research area in RL is discussed and the author is curious to learn more about it.\n- https:\/\/mobile.twitter.com\/ESYudkowsky\/status\/1635577836525469697 - Adobe is expected to release something big in generative AI, and it's a tough competition for horizontal gen AI startups. The message also suggests that people may avoid Adobe.\n- https:\/\/youtu.be\/DiGB5uAYKAg: Nvidia livestream is live Rn, and the message in the same link talks about Canva's visibility in the GenAI space and their focus on ML research.\n- https:\/\/huggingface.co\/spaces\/fffiloni\/CLIP-Interrogator-2: A suggested alternative to the ImageCaptioning model BLIP, along with the recommendation to use a VPN.\n- https:\/\/twitter.com\/vinniemourax\/status\/1638218512760971277?s=20 - A tweet asking if people have seen something, possibly related to the following YouTube video.\n- https:\/\/www.youtube.com\/watch?app=desktop&v=DiGB5uAYKAg&feature=youtu.be - A YouTube video that may be related to the tweet above.\n- https:\/\/twitter.com\/vinniemourax\/status\/1638218512760971277?s=20: A tweet asking if people have seen a certain video, followed by a link to the video on YouTube and a question about whether there is an API version of it.\n- https:\/\/github.com\/rmokady\/CLIP_prefix_caption - A GitHub repository containing a script for converting text into an API, which may be useful for integrating with other applications. The message in the same link as the repository is related to the repository and mentions the possibility of using a tool called \"replicate\" for the same purpose.\n- https:\/\/gist.github.com\/ovshake\/69efb594f3b1e8d98b34687b16916145 - A link to a potentially useful resource, mentioned in the context of a negative opinion about a model.","19":"- https:\/\/replicate.com\/pharmapsychotic\/clip-interrogator: mentioned as a possible URL, but no further context is given.\n- https:\/\/www.cs.umd.edu\/~shishira\/Nirvana\/nirvana.html: The person mentioned in the message published in CVPR 2023 and works with video compression. They are also a good friend of the speaker.\n- The GitHub link https:\/\/github.com\/microsoft\/MM-REACT is related to video compression and the message mentions that the demo looks good and better than BLIP-2. The person who shared the link is also a good friend of the developer.\n- https:\/\/huggingface.co\/spaces\/microsoft-cognitive-service\/mm-react: The link leads to a website where the langchain repo has been cloned. The message in the same link mentions that the user uploaded their picture and the website described them in close detail, doing a decent job.","20":"- https:\/\/twitter.com\/T_Goody3\/status\/1638203321704955904?t=8aQye9lDksWh81DJjhZGlg&s=08 - Requesting access for Dukaan and hoping to get a contract with the Gates Foundation to build a Whatsapp chatbot to guide rural nurses in India.\n- https:\/\/gooey.ai\/ai-photo-editor\/?run_id=4ndpy7e0&uid=Nli0J2dP80WU3sdJ9RCw3DeNvIT2: The message in the same link as the URL mentions waiting for the next medical provider data breach to get this dataset, and also mentions Adobe products being out now.\n- https:\/\/www.linkedin.com\/posts\/alexandru-costin-a4367_adobefirefly-ugcPost-7043965991910854656-pjbp?utm_source=share&utm_medium=member_ios - Regarding the Adobe products that someone else mentioned, it\u2019s out now.","21":"- https:\/\/openai.com\/blog\/chatgpt-plugins - The message discusses the style reference for a picture and speculates on the future of chat plugins.\n- https:\/\/platform.openai.com\/docs\/plugins\/introduction: The message states that the sender is confident of achieving better success than Alexa Skills and includes a phone number that has been removed.\n- https:\/\/analyticsindiamag.com\/the-hidden-cost-of-chatgpt-for-indian-languages\/ - A question is asked about the accuracy of a cost analysis related to ChatGPT for Indian languages, and the response is \"Yes.\"\n- https:\/\/platform.openai.com\/tokenizer: A link to a website where one can try out a tokenizer, with a message indicating that the recipient understands the information provided.","22":"","23":"- https:\/\/www.youtube.com\/watch?v=L_Guz73e6fw: A video with philosophical insights on development trajectory by Sam Altman and OpenAI.\n- https:\/\/www.youtube.com\/@aajtakai\/videos: A video discussing the philosophical implications of AI development and the safety concerns surrounding the exponential growth of LLMs, in the context of recent advancements by OpenAI and Microsoft.","24":"- URL: Not provided. The message is related to the introduction of the sender, who is a new media artist and educator focused on making cutting edge technology accessible. The sender also runs a website focused on addressing societal challenges of technology in the Indian context. The question \"is it done via stop motion?\" is not related to the given context.\n- https:\/\/github.com\/justanotherlad\/blindvisaidgpt: The author mentions trying out generative video models and shares a link to their GitHub repository. They also introduce themselves as a search engineer at Wolfram|Alpha.\n- https:\/\/m.economictimes.com\/tech\/ites\/tech-mahindra-tests-goggles-for-blind-plans-variant-for-cars\/articleshow\/45302948.cms - The link is related to a discussion about a project done for TechMahindra that involved creating goggles for the blind and a possible variant for cars. The message also suggests that the project was not open source and should not be shared outside, but mentions that similar projects could be done today using phones with decent computing power.\n- If anyone is interested in making ControlNet work on iPhone, this is a good start: https:\/\/github.com\/apple\/ml-stable-diffusion\/issues\/131\n- https:\/\/aisnakeoil.substack.com\/p\/gpt-4-and-professional-benchmarks - Context: Aravind's post about contamination and GPT-4's performance.\n- https:\/\/about.sourcegraph.com\/blog\/cheating-is-all-you-need: The author discounts Github's excellent search product which has similar or maybe larger advantage than Sourcegraph, while someone on Twitter says gpt-4 does much worse than leetcode hard on newer Euler problems.\n- https:\/\/niranting.substack.com\/ (The author's Substack, discussing the potential of LLM-powered coding assistants and referencing a Google rant from 2011)\n- https:\/\/www.buildt.ai - a website that potentially uses LLM powered coding assistants and has search capabilities on codebases.\n- https:\/\/github.com\/features\/preview\/copilot-x: Github Copilot X (available for preview only) is mentioned as a tool that is going to change how we work, and the author is working on something using LLMs.","25":"https:\/\/twitter.com\/AKASpencerScott\/status\/1638996898941124609?s=20 - A tweet that inspired someone to use GPT-3.5 as a data resource to find Shopify websites in the USA that sell candles and get email IDs using a crawler code. The tweet also mentions that GPT-3.5 is good for competitor analysis.\n- https:\/\/youtu.be\/kCc8FmEb1nY: \"There is no good and evil. There is only Balenciaga\". The message in the same link as the URL is related to the link.","26":"- https:\/\/twitter.com\/io_Y_oi\/status\/1634835399918108673?t=malrs07ZHMBbup1Pr7gO-g&s=19 - Google Partners with AI Startup Replit to Take on Microsoft\u2019s GitHub\n- https:\/\/has.gy\/gpt4hack: India Replit is sponsoring a hackathon and offering the opportunity to try GCP features on Replit. The message also includes a question about the popularity of writing a GPT from scratch in the future.\n- https:\/\/twitter.com\/debarghya_das\/status\/1640892791923572737 - Bing Chat has ads and the author is waiting to see stats on CTRs and their subsequent effect on CPCs in relation to an event on \"ChatGPT and it's Ilk\" by Anil Ananthaswamy, a science writer and editor, hosted by BIC.\n- https:\/\/has.gy\/gpt4hack: Link to participate in a hackathon in BLR mentioned in a message requesting for streaming and sharing a recent best read.\n- https:\/\/has.gy\/gpt4hack: Link to participate in a hackathon in BLR.\n- https:\/\/twitter.com\/tobi\/status\/1641010421493637122 - Tobi is asking about the source for the number 100 trillion and expressing surprise at the possibility of reaching triple digits in trillions.\n- https:\/\/twitter.com\/marckohlbrugge\/status\/1640961076039925760: A clarification on the estimated number of neurons in the human brain and an announcement that builders can apply for projects this weekend.\n- https:\/\/futureoflife.org\/open-letter\/pause-giant-ai-experiments\/ - An open letter calling for a pause on giant AI experiments.\n- https:\/\/futureoflife.org\/open-letter\/pause-giant-ai-experiments\/ - An open letter calling for a pause on giant AI experiments.","27":"- https:\/\/twitter.com\/jerryjliu0\/status\/1641234014991446016?s=46&t=icC0fizZK8E3ONsDVuGFWA: A Twitter conversation about minimizing hallucinations during QnA over documents or chat conversations, with a mention of the maker of an evaluation model.\n- https:\/\/github.com\/jerryjliu\/llama_index - Overview section discussing Harrison potentially tackling the langchain deployment layer and their efforts.\n- https:\/\/huggingface.co\/google\/pix2struct-textcaps-large: The message asks for advice on lawyers for O1 and mentions the impressive results of pix2struct.\n- https:\/\/www.springworks.in\/albus\/ - mentioned in a message along with introducing Shreya Rajpal as the creator and maintainer of Guardrails and thanking for the group invitation.\n- https:\/\/twitter.com\/sama\/status\/1641181668206858240?s=20: A tweet by Sam Altman about a fun use case he saw in his improv group of using GPT-4 as a scene actor, with the additional context of him coming to India.\n- https:\/\/github.com\/github\/gov-takedowns: Github (MSFT acquisition) used to share when they got take down requests from Govt.\n- https:\/\/instagram.com\/climateprov?igshid=YmMyMTA2M2Y= : The message in the same link as the URL suggests that the person has expertise in machine learning algorithms such as SVM Kernels and Random Forests. The import statement for TensorFlow also indicates their familiarity with deep learning.\n- https:\/\/www.researchgate.net\/publication\/308719279_Sentiment_Analysis_for_Mixed_Script_Indic_Sentences: This link is mentioned in the context of discussing research work in universities and how the author worked on this paper in 2015, which they thought was cutting-edge at the time.\n- https:\/\/arxiv.org\/abs\/2210.04045: A paper was found the next day after discussing a matmul algorithm, which was written in lua torch and trained an agent to play the doom game.\n- https:\/\/www.linkedin.com\/posts\/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_android - Around 2018. When I saw Deepminds first demos of neural nets playing Tetris. Hey Munjal, welcome to the group!","28":"- The blog post talks about the launch of an automated blog to video tool powered by GPT-4 by Rephrase.ai. The author has contributed to it and is working on the next version. URL: https:\/\/www.rephrase.ai\/blog-to-video\n- https:\/\/gooey.ai\/asr\/ - This link provides the transcript that was needed in the conversation.\n- https:\/\/www.gladia.io\/ - This website offers a free API that can extract a 1-hour audio file transcript in 10-20 seconds using openai Whisper backend. Assembly.ai is also recommended for transcription with good accuracy.\n- https:\/\/mobile.twitter.com\/svembu\/status\/1641710194458791939 - A tweet asking for results to be shared, with a link to a video on personalized rephrasing.\n- https:\/\/mobile.twitter.com\/svembu\/status\/1641710194458791939 - A tweet by svembu with a video link to personalized.rephrase.ai and a message saying \"hi\".\n- https:\/\/arxiv.org\/abs\/2303.17580 - The message mentions this link in relation to the topic of solving AI tasks with ChatGPT and its friends in HuggingFace.","29":"- https:\/\/has.gy\/ULYt - Live stream set up for DeepHack demo day.","30":"- The URL is https:\/\/magicfusion.github.io and the message on the same page is asking for recommendations for free\/local alternatives to D-ID and ElevenLabs for creating lip-synced avatar videos with custom images and audio.\n- https:\/\/gooey.ai\/lipsync\/ - A request for good\/free\/local alternatives to D-ID and ElevenLabs for creating lip-synced avatar videos, and a question about the differences between Dreambooth, LoRA, and Textual Inversion.\n- https:\/\/youtu.be\/dVjMiJsuR5o: The message in the same link discusses the effectiveness of LoRA compared to other models for training on small amounts of data.","31":"","32":"- The Twitter link https:\/\/twitter.com\/lumalabsai\/status\/1642883558938411008?s=46 includes a message about a report, which can be found at the URL https:\/\/aiindex.stanford.edu\/report\/.\n- https:\/\/twitter.com\/lumalabsai\/status\/1642883558938411008?s=46 - A report related to AI can be found at this link, but the message also mentions that a certain behavior is not encouraged.\n- https:\/\/twitter.com\/CyberSahu\/status\/1643166480794791938?s=20 - Link to a generative AI project built by the sender and another person, asking for feedback from hackers. Also includes a link to the project's GitHub page.\n- https:\/\/twitter.com\/CyberSahu\/status\/1643166480794791938?s=20 and https:\/\/github.com\/nat\/openplayground - Hackers are being asked for feedback on a generative AI project, with a joke about \"killing\" a competitor's project.\n- https:\/\/youtu.be\/xNqs_S-zEBY: The message in the same link as the URL mentions \"AirBnB for GPUs\" as a concept, while apologizing to Leap Motion.\n- https:\/\/www.hetzner.com\/cloud - mentioned as the \"OG hotels\" in a discussion about Hetzner Cloud on vast.ai.\n- https:\/\/www.imagineapi.dev: Claims to be unofficial MJ API, someone didn't know Jasper trained their models on the Cerebras systems and wonders if they created a MJ bot for the MJ bot.","33":"- https:\/\/docs.google.com\/forms\/d\/e\/1FAIpQLSfRg1AOSSfSs8ZBbKzWd5ne_8JqzJrwFvy_NN0K-TUIdG2jYA\/viewform - a form to be filled up by the recipients of the message, which is related to an AI event happening in Bangalore on April 14th.\n- https:\/\/community.riscv.org\/events\/details\/risc-v-international-risc-v-in-india-presents-nerds-talking-to-nerds-about-risc-v-hosted-by-tenstorrent\/waitlist\/151: The message in the same link as the URL asks if anyone is aware of research happening in Deepfake detection.\n- https:\/\/blogs.microsoft.com\/on-the-issues\/2020\/09\/01\/disinformation-deepfakes-newsguard-video-authenticator\/ - Microsoft's effort on disinformation and deepfakes, but doesn't have a working model for public use. Mention of Spoofsense.ai working on the issue as well.\n- Can use this https:\/\/kroop.ai\/the-vizmantiz\/ for cryptography, which is a constantly-evolving process\/field. The message also asks if anyone has seen an API to categorize questions into HR, Finance, Marketing etc.\n- https:\/\/www.buildt.ai\/blog\/incorrectusage - The blog post discusses incorrect usage of AI and mentions Pepper as one of the larger customers of OpenAI in India.\n- https:\/\/analyticsindiamag.com\/hugging-face-launches-gpt-4-alternative-vicuna-13b\/ - A message discussing the potential of the newly launched Vicuna 13B as a knowledge distillation tool with human input for higher quality labels.","34":"- https:\/\/arxiv.org\/abs\/2304.01852: Is he masking the cloth first, and then doing style transfer? Even then, the results look near perfect and artefact free, unlike what style transfer or img2img can do. This came out two days ago \ud83d\udc46.\n- https:\/\/github.com\/sangyun884\/HR-VITON - This link was shared along with a message asking if anyone has tried a paid subscription of MidJourney from India, as the person's payments were not going through. The link itself is not directly related to the message.\n- https:\/\/youtu.be\/E7fGsSNKMc4: A cool video link, possibly unrelated to the mention of a personal Citibank Indian Master credit card.\n- https:\/\/huggingface.co\/blog\/fine-tune-whisper - This link leads to a blog post about finetuning speech-to-text models for Indian languages, which was requested by some teams.\n- https:\/\/huggingface.co\/blog\/fine-tune-whisper: This link provides information about finetuned STT for Indian languages, which was requested by some teams.\n- The URL https:\/\/github.com\/Open-Speech-EkStep\/vakyansh-models is related to dataset and wave2vec models, and the message in the same link as the URL is related to MetaAI's Twitter account.\n- https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb: 3000 rows is pocket change. For any indie hackers, you can use Google Sheet as a db to launch a GPT4 app as well.\n- https:\/\/huggingface.co\/vasista22\/whisper-hindi-large-v2: Indian government has fine-tuned checkpoints for this model and the message also asks if there is an API available for it.\n- https:\/\/gooey.ai\/asr\/ - The message mentions the URL as a self-plug for an API related to the question of whether there is an API available. The message also mentions that a notebook related to the URL had some problems with finetuning examples.\n- https:\/\/github.com\/openai\/openai-cookbook\/blob\/6df6ceff470eeba26a56de131254e775292eac22\/examples\/fine-tuned_qa\/olympics-1-collect-data.ipynb - A contributor of OpenAI Cookbook is asking how to make money.\n- https:\/\/twitter.com\/LangChainAI\/status\/1643628476505681920?s=20 - The message discusses the limitations of LLMs and the need for alternative solutions in AI. The mentioned URL is related to the topic.\n- https:\/\/www.linkedin.com\/posts\/samyakhtukra_holy-smokes-sam-segment-anything-model-activity-7049699206206283776-_fva? - The message in the same link as the link is related to the given URL. The context suggests that the person tried to compress lyrics but it didn't work, and the URL is being compared to a fitting analogue.\n- https:\/\/getmetal.io\/ - A new YC company that specializes in working with Nobel laureates. The message also mentions the strong pipeline between OpenAI notebook bug fixes and Stripe.\n- https:\/\/nirantk.com\/deephackdemos - Demos from India's first Generative AI hackathon are available at this link.","35":"- https:\/\/www.instagram.com\/reel\/CqstiaNuSjX\/?igshid=MDJmNzVkMjY= : The message mentions a shortfilm using dalle and asks if anyone has seen it. The given URL is for the first shortfilm using dalle.\n- https:\/\/www.theguardian.com\/games\/2023\/apr\/06\/now-play-this-ai-video-game-somerset-house-london?CMP=Share_iOSApp_Other - For those in London: this might be worth checking out. Lots of AI\/art\/gaming stuff.\n- https:\/\/twitter.com\/mathemagic1an\/status\/1644123645432958976?s=46 - The tweet discusses the possibility of freemium models with no strong QoS and asks whether it is Pichai or Larry\/Sergey who will make the decision.\n- https:\/\/twitter.com\/wileycwj\/status\/1644220882062282752?s=46&t=lkuvFQUWr1nav0QpUpFmdQ: A tweet discussing the effectiveness of pgVector and its limitations at certain scales.\n- https:\/\/twitter.com\/jobergum\/status\/1643187540222959616 - Good discussion about pgvector in this thread. Also, a question about trying out Midjourney's \/describe feature (img2text2img).\n- And avatars come for news anchors: https:\/\/twitter.com\/KhaleejMag\/status\/1641123893145485343 (The message in the same link as the link is related to the link.)\n- https:\/\/www.linkedin.com\/posts\/hsemina_generativeai-community-hackathon-activity-7050057219123400704-NIHR?utm_source=share&utm_medium=member_android - The message in the same link as the URL expresses skepticism towards benchmarking blogs by other vectorDB startups and expresses hope for the success of pgvector within the supabase ecosystem. The link is related to the context of the message.\n- https:\/\/medium.com\/m\/global-identity-2?redirectUrl=https:\/\/blog.startupstash.com\/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b: A message asking about the experience with Fixie, mentioned in the same link.\n- https:\/\/medium.com\/m\/global-identity-2?redirectUrl=https:\/\/blog.startupstash.com\/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b: A message asking about the experience with Fixie, mentioned in the same link.\n- The last bad product I used was https:\/\/www.steamship.com (platform to deploy langchain applications).\n- https:\/\/twitter.com\/nirantk\/status\/1644290469915164672?s=46 - Relevant to the conversation, the user loves the quadrant.\n- https:\/\/rime.ai\/ - A link shared by someone who loves learning database internals, along with a related tweet from Lily Clifford on Twitter.\n- https:\/\/rime.ai\/ - This is the main website for Rime, but there is no direct context provided in the given URLs. However, the two Twitter links may be related to Rime in some way.\n- https:\/\/twitter.com\/lilyjclifford\/status\/1643702014680133632 and https:\/\/twitter.com\/younesbelkada\/status\/1644341068241186818?s=46&t=icC0fizZK8E3ONsDVuGFWA: The message in the link states that new foundational models for different tasks are released everyday.","36":"- The video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published - https:\/\/youtu.be\/WF28ZwhUCc4\n- CEO of Weaviate, Vespa and Modal Labs discussing serverless Vector DB and pricing on Twitter: https:\/\/twitter.com\/jobergum\/status\/1644653416994488320 (related to optimization for running on Apple RAM and Nvidia GPUs, as well as Developer eXperience and pricing strategy)\n- https:\/\/youtu.be\/8y7GRYaYYQg: A video discussing Developer eXperience and its influence on pricing and GTM, with a demonstration of a developer debugging logic while letting GPT4 fix syntax and API calls.","37":"- https:\/\/twitter.com\/danmartell\/status\/1644798423961575426?t=BwA0POzNya9uB_BZkY1cHA&s=19: If anyone to sell his SAAS company.\n- https:\/\/sitegpt.ai\/ - Sitegpt offers a similar service to the one built by cc [PHONE REMOVED] and friends for Youtube videos. Microsoft Edge also has a copilot option that does the same thing.\n- Microsoft Edge has a copilot option which does this exact thing which I\u2019ve been using. (https:\/\/twitter.com\/alexgraveley\/status\/1644186023868416000?t=3mfuMZb0hDnOx2sFR9Wn4Q&s=08)\n- https:\/\/twitter.com\/rowancheung\/status\/1644778701974822913 - A tweet discussing the use of jsonlines format to solve a problem related to newlines in data.\n- https:\/\/jsonlines.readthedocs.io\/en\/latest\/ - Documentation for the JSON Lines format.\n- https:\/\/twitter.com\/rowancheung\/status\/1644778701974822913 - A tweet by Rowan Cheung commenting on a viral thread with Indian villagers smiling, suggesting it may have a biased perspective.\n- https:\/\/intellawyer.com\/ - Discussion about embedding suggestions for legal documents and seeking advice from Sachin, who has experience with legal documents. CC Indian legal docs.\n- https:\/\/www.sbert.net\/docs\/pretrained_models.html: The speaker is referring to searching during training and gives a shout out to Ravi for his expert advice and tips.\n- https:\/\/twitter.com\/nirantk\/status\/1644290469915164672?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ: Tweet thread by Nirant discussing tradeoffs between pinecone and other technologies, with a suggestion for him to start an accelerator for startups.\n- GenerativeAI April meetup registration link: https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ (related to the message about creating a space for hackers to meet and hack together)\n- https:\/\/www.linkedin.com\/in\/athyuttamre - He's on the plugins team. The message asks about the usage and cost of something, but it is unclear what it is referring to.\n- https:\/\/www.linkedin.com\/posts\/setu-apis_we-have-kicked-off-the-openai-x-fintech-session-activity-7050806116791832576-S3Ns?utm_source=share&utm_medium=member_android - The message in the same link as the URL mentions being in the Bay Area and open to meeting for coffee or beer. The URL itself is related to an OpenAI x Fintech session.\n- https:\/\/www.linkedin.com\/in\/anirudthn - The message includes an invitation to meet in Seattle and a request for a recording or screenshot of something. The author also mentions lurking in a group.","38":"- Here is a YouTube link (https:\/\/www.youtube.com\/watch?v=2xxziIWmaSA&t=1079s) to a thread discussing Hackathon ideas, including some that were similar to those seen at a previous hackathon.\n- The URL is not provided in the given text.\n- https:\/\/github.com\/ShreyaR\/guardrails - The message emphasizes that Indians are no longer playing catch up, despite the author's physical state.\n- https:\/\/youtu.be\/wHiOKDlA8Ac - Interesting new research on Generative Agents, with enthusiastic reporting. The message also asks for suggestions on how to try out Midjourney, as the Discord is currently at full capacity.","39":"- https:\/\/arxiv.org\/pdf\/2304.03442.pdf: Mentioned in a tweet by Andrej Karpathy.\n- https:\/\/reverie.herokuapp.com\/arXiv_Demo\/ - Andrej Karpathy tweeted about a demo for Generative Agents.\n- https:\/\/wtfdoesthiscompanydo.vercel.app\/ - The message in the same link as the URL suggests that the website may have been using flat GPT output without crawling their pages in the past.\n- https:\/\/twitter.com\/_akhaliq\/status\/1645594671068971008?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw - This tweet contains a link to an interesting paper that, when combined with Meta's segmentation model, can open up many interesting use cases. The tweet also includes the phrase \"Langchain Bruh moment.\"\n- https:\/\/twitter.com\/jeremyphoward\/status\/1645597656499245057?t=21TkvGGfdo-gEqmw3NKvsA&s=19 - Jeremy Howard mentions that even he didn't have access to ChatGPT plugins until now, indicating that it is SF-first. The message also includes a humorous comment about not experiencing FOMO.\n- https:\/\/www.inferless.com\/serverless-gpu-market - The message in the same link suggests that VPN may not work and thanks someone for a shoutout.\n- The first URL https:\/\/lu.ma\/y7uu4m4e is a shortened link that may lead to more information, while the second URL https:\/\/www.inkle.io\/resources\/events\/talks is a resource page for talks related to inkle, a company that creates interactive stories.\n- https:\/\/lu.ma\/y7uu4m4e: A link to an unknown website or page. No context is provided.","40":"- https:\/\/twitter.com\/mr_cheu\/status\/1626261050566778880?s=46&t=lkuvFQUWr1nav0QpUpFmdQ - A thread discussing the superiority of some OS, posted in February 2023.\n- https:\/\/youtu.be\/540vzMlf-54: The message in the same link as the URL mentions \"Awfully painful questions \ud83d\ude02\".\n- Ohh, the ChatGPT Plugins SF hackathon announced their winners: https:\/\/twitter.com\/atroyn\/status\/1645954654394802176. All the winners here have much higher _usability_ than what we had thought.\n- https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/examples\/conversational_customization.html: Langchain has some pretty good abstractions around memory (in addition to the index+retrieve approach) for enabling long term conversational memory.\n- https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/examples\/conversational_customization.html - Langchain has some pretty good abstractions around memory (in addition to the index+retrieve approach)\n- https:\/\/twitter.com\/i\/spaces\/1djGXldPqNyGZ?s=20 - Happening as we speak\n- Elon Musk recently spent at least $250M on GPUs for training generative AI at Twitter, as mentioned in a tweet by @yoheinakajima. The tweet also mentions the user's liking for autonomous GPT agent technology. The URL provided leads to the tweet.\n- Harrison Chase implemented a custom LangChain abstraction for BabyAGI based on Yohei\u2019s method: https:\/\/twitter.com\/langchainai\/status\/1645808279849947137?s=46&t=icC0fizZK8E3ONsDVuGFWA and https:\/\/python.langchain.com\/en\/latest\/use_cases\/agents\/baby_agi_with_agent.html\n- https:\/\/python.langchain.com\/en\/latest\/use_cases\/agents\/baby_agi_with_agent.html - Link to a webpage about using agents in artificial general intelligence, mentioned in a tweet.\n- https:\/\/github.com\/eumemic\/ai-legion: Design Principles for building Agents. This link is for folks using Typescript for agent building.\n- https:\/\/www.wsj.com\/articles\/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b : The article discusses the Biden administration's consideration of possible regulations for AI tools like ChatGPT, which may have implications for those using Typescript for agent building. The message also mentions the possibility of the Indian government building their own AI tool, BharatGPT.\n- The GitHub link https:\/\/github.com\/RSTLess-research\/Fauno-Italian-LLM is related to a message about Italy possibly banning OpenAI, with a humorous comment about Monopoly play.\n- https:\/\/ai4bharat.iitm.ac.in\/models - AI4Bharat is working on creating an LLM model, possibly due to the government's focus on self-owned public infrastructure. The IITM team is involved in this project.\n- https:\/\/replit.com\/@YoheiNakajima\/babyagi?v=1 - AI4Bharat is working on it and there is a coincidence related to the link. The message in the same link as the link is related to it. The IITM one BabyAGI on Replit in just 105 lines of code.\n- https:\/\/www.medianama.com\/2023\/02\/223-nadella-bhashini-language-translation-platform\/ - This link is mentioned in the context of someone named Pratuysh working at Microsoft Research. The message in the same link as the URL is related to language translation platform. \n- https:\/\/farmer.chat - No context is given for this link.\n- The article on Medianama discusses Microsoft CEO Satya Nadella's investment in Bhashini, a language translation platform. The message in the same link suggests that Farmer.chat, a chatbot for farmers, can add more Indic languages, voice support, and link to government schemes via plugins.\n- https:\/\/www.inferless.com\/serverless-gpu-market: TTS is being used to return answers in the same language, and the link leads to information about the serverless GPU market. Another related link is provided at https:\/\/kissangpt.com.\n- https:\/\/www.inferless.com\/serverless-gpu-market: A link to a website about serverless GPU market, with a message suggesting to check out another website related to it at https:\/\/kissangpt.com, described as \"pretty slick\".\n- https:\/\/kissangpt.com - The message in the same link as the URL suggests that farmers in India are interested in using the product, but the company may not have enough communication with end users and may need to improve product design.\n- In-person, BLR only: https:\/\/huggingface.co\/spaces\/abhishek\/StableSAM. I\u2019ll be there \ud83e\udee1\n- https:\/\/huggingface.co\/spaces\/abhishek\/StableSAM : A link to compare oneself regarding SAM, with a message that a 512X512 is needed to try the link and it will error out for all other dimensions.\n- The message in the given link is related to AI agents writing their own plugins, and the link leads to a tweet by user @kevinafischer who says they tried something but it didn't work. The tweet can be found at https:\/\/twitter.com\/kevinafischer\/status\/1646009719314841601?s=46&t=icC0fizZK8E3ONsDVuGFWA.\n- AI agents writing their own plugins: https:\/\/twitter.com\/shivam124081\/status\/1645691399164026880?s=46&t=kpJ79jqt9oDMH6ZCqnhylA\n  - The message in the same link as the link is related to the topic of AI agents writing their own plugins.\n- https:\/\/www.crowdcast.io\/c\/46erbpbz609r - Langchain webinar with Harrison and Yohei among others is live now.\n- https:\/\/python.langchain.com\/en\/latest\/ : The Langchain docs are really good to get started with they also have guides for reference too.\n- The URL https:\/\/huyenchip.com\/2023\/04\/11\/llm-engineering.html is related to OpenAI's release of open source implementation and model weights for their latest work on one step image generation.","41":"- https:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm: Love how they crowd sourced the dataset from own employees.\n- https:\/\/www.marktechpost.com\/2023\/03\/10\/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training\/ : OpenAI proposes consistency models, a new family of generative models that achieve high sample quality without adversarial training. A summary of the article is provided.\n- https:\/\/aws.amazon.com\/comprehend\/medical\/pricing\/ : This link provides information about the pricing of Amazon Comprehend Medical, a natural language processing service for medical text. The message in the same link mentions that GPT3.5 was cheaper than GPT3.\n- https:\/\/github.com\/lllyasviel\/ControlNet-v1-1-nightly: This link leads to a GitHub repository for \"ControlNet,\" and the message following it asks if anyone is using \"Milvus.\"\n- https:\/\/zilliz.com\/ - The message in the same link as the URL says \"You didn't have to ruin the joke for everyone by explaining it.\"\n- https:\/\/tenstorrent.com: The website is mentioned in the context of discussing the accuracy and emergent abilities of smaller and larger models in certain tasks. The message also includes a greeting to someone who may be present on the website.\n- https:\/\/techcrunch.com\/2023\/01\/10\/openai-in-talks-to-back-zeloof-and-chip-legend-kellers-startup-at-100-million-valuation\/amp\/ - Jim Keller's new chip company, which OpenAI is in talks to invest in, aims to build a 2 terabyte RAM AI accelerator. The message also notes the company has a Bangalore office.\n- https:\/\/github.com\/ravenscroftj\/turbopilot: The user tried running GPT4ALL locally and found it to work well on their 8gb ram laptop. They mention that it's good for text generation and the onboarding is simple, but it's not strong with code yet.\n- https:\/\/github.com\/huggingface\/diffusers\/releases\/tag\/v0.15.0 - This link is shared in the context of a humorous comment about the top highlight while selling the contract renewal of the data bricks platform. The message in the same link as the URL is related to the link.\n- https:\/\/twitter.com\/ashe_cs\/status\/1646543644038397952?s=46&t=0NBX3C3Uma-Su4_rjA3OMA: Message thanking someone for hosting a mixer and expressing delight in meeting people in the Bangalore AI space. Also includes a request to collaborate and a DM sent to the recipient.\n- Cerebras is not planning to be consumer focused chips, while Sambanova is building FPGA based chips for AI. (https:\/\/www.linkedin.com\/posts\/harshsinghal_under40-activity-7052341005978615809-EaUX?utm_source=share&utm_medium=member_android)","42":"- https:\/\/techcrunch.com\/2023\/04\/13\/with-bedrock-amazon-enters-the-generative-ai-race\/ - An API for a kids as superheroes idea is mentioned, along with a recommendation to watch Andrej Karpathy's video on Neural Nets.\n- https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ: Finished watching Andrej Karpathy's video on Neural Nets and highly recommend it to anyone starting or in the field. Message in the same link mentions caching LLM calls and saving money.\n- The URL is https:\/\/stability.ai\/blog\/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users and the message in the same link is related to seeking advice on GPT-4, diffusers, and YouTube videos. The context also includes a mention of a Twitter post about 'ChatGPT for a github repository'.\n- https:\/\/js.langchain.com\/docs\/modules\/indexes\/document_loaders\/examples\/web_loaders\/github - Demo video of Chat with GitHub, mentioned in a Twitter post.\n- https:\/\/grail.cs.washington.edu\/projects\/dreampose\/ - Building LLM applications for production. Here's a new AI model called DreamPose that can generate Video from Image.\n- https:\/\/github.com\/johannakarras\/DreamPose#finetune-on-sample - The link is related to a question about finetuning a model on a subject-specific image before creating a video. The message also includes a question about the difference between the process and an edge detection algorithm.\n- Akto.io just launched AktoGPT - https:\/\/www.akto.io\/blog\/aktogpt - a new tool for generating text using GPT language models. @ankush also shares tips for deploying GPT LLM in production in a related tweet.\n- Akto.io just launched AktoGPT - https:\/\/www.akto.io\/blog\/aktogpt. Ankush talks about things to watch out for before deploying GPT LLM in production - https:\/\/twitter.com\/Ankush12389\/status\/1646779395833741313.\n- https:\/\/arxiv.org\/abs\/2303.01469 - The message in the same link as the URL is related to avoiding premature optimization in the software world. The author also mentions that Akto is funded by Accel India as a disclaimer.\n- The LangChain website provides an example of integrating with Azure endpoints instead of OpenAI directly, and asks if anyone has tried it: https:\/\/python.langchain.com\/en\/latest\/modules\/models\/llms\/integrations\/azure_openai_example.html\n- https:\/\/colin-scott.github.io\/personal_website\/research\/interactive_latency.html: The message suggests that something has happened before and the link may provide more information.\n- The given URL is a link to a Google Colab notebook that provides insights into industry directions and opportunities through numbers and trends. The message in the same link mentions having the URL in one's name.","43":"- https:\/\/github.com\/karpathy\/randomfun\/blob\/master\/knn_vs_svm.ipynb: The message in the same link as the URL is related to the link, but newlines may or may not be related. The message is about getting the latest controlnet v1-1 nightly release models working with inpainting and asking for inputs on how that would fit with multi controlnet.\n- https:\/\/twitter.com\/karpathy\/status\/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19 - Twitter discussion about the size of the DB and choice of Vector DB, with a mention of 10681 vectors and Pinecone.\n- https:\/\/www.theverge.com\/2023\/4\/14\/23683084\/openai-gpt-5-rumors-training-sam-altman: Discussion about training a classifier on top of embeddings and explicitly labeling for retrieval, and its similarity to the old world of building classifiers through KNN, SVM, DNN, CNN, etc. Also mentions that this method works well when there aren't too many data refreshes\/updates.\n- https:\/\/twitter.com\/pratyush_r8\/status\/1647104801950552064 - A message expressing gratitude for finding something after searching for 2-3 days, followed by a comment on the concept of bionic reading.\n- Redhat has reached $1B, as mentioned in a tweet by Anoushka Vaswani and a LinkedIn post. \n  - https:\/\/twitter.com\/anoushkavaswani\/status\/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19 \n  - https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7053046289256632320\n- https:\/\/twitter.com\/anoushkavaswani\/status\/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19 - A tweet by Anoushka Vaswani with a message related to the link.\n- https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7053046289256632320 - A LinkedIn post with no context provided.\n- https:\/\/twitter.com\/foyerwork\/status\/1647282584907579393?s=20 - A tweet by Foyerwork with no context provided.\n- https:\/\/aws.amazon.com\/codewhisperer\/ - AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot.\n- https:\/\/aws.amazon.com\/codewhisperer\/ - AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot.\n- https:\/\/aws.amazon.com\/codewhisperer\/ - AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot.\n- The following URLs provide information about Amazon CodeWhisperer, a tool used to improve developer productivity, and its comparison with GitHub Copilot: \n  - https:\/\/aws.amazon.com\/blogs\/machine-learning\/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity\/ \n  - https:\/\/blog.lucas-simon.com\/amazon-codewhisperer-vs-github-copilot#heading-final-thoughts","44":"- https:\/\/www.gregegan.net\/MISC\/CRYSTAL\/Crystal.html: A message discussing the similarity between Multivac and today's LLMs\/Auto-GPT, with a reference to AI.\n- https:\/\/www.chatbotui.com\/ : \"I figured that's cheaper than buying chatGPT plus. And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit?\"\n- https:\/\/github.com\/openai\/openai-cookbook\/blob\/main\/examples\/Question_answering_using_embeddings.ipynb: Request for guidance on the number of documents required for fine-tuning and resources for fine-tuning, specifically with custom data.\n- The following URLs provide information about fine-tuning large language models using Hugging Face and DeepSpeed, and the first open commercially viable instruction-tuned LLM called Dolly: \nhttps:\/\/www.databricks.com\/blog\/2023\/03\/20\/fine-tuning-large-language-models-hugging-face-and-deepspeed.html \nhttps:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm\n- https:\/\/www.databricks.com\/blog\/2023\/03\/20\/fine-tuning-large-language-models-hugging-face-and-deepspeed.html: An article by Databrick on how they've fine-tuned the open source Dolly LLM using Hugging Face and DeepSpeed.\n- https:\/\/www.databricks.com\/blog\/2023\/04\/12\/dolly-first-open-commercially-viable-instruction-tuned-llm: Another article by Databrick on the first open commercially viable instruction-tuned LLM, Dolly, for reference.\n- https:\/\/stackoverflow.com\/questions\/63521958\/is-this-a-right-way-to-descrease-size-of-my-docker-images: A question about finetuning and generating embeddings, with a message about Harrison's strategy and plans.\n- The article at https:\/\/medium.com\/@TheHaseebHassan\/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696 is a nice resource for converting ST into ONNX format, and Harrison is praised for being open about their strategy and sharing their plans.\n- The tweet from Tree Industries (@tree_industries) discusses the potential improvements in similarity search with the use of GPT3.5 and GPT4 embeddings. The URL provided leads to the tweet.\n- https:\/\/huggingface.co\/spaces\/microsoft\/HuggingGPT is shared in the message as a resource to learn about ways to make the model smarter without burning huge computation powers.\n- https:\/\/platform.openai.com\/docs\/guides\/fine-tuning: Request for a comprehensive guide on how to update weights with example data.\n- https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/how_to_guides.html and https:\/\/trib.al\/HIuiF1K are related to optimizing memory types for chunks in langchain's conversation.\n- The given URL (https:\/\/python.langchain.com\/en\/latest\/modules\/memory\/how_to_guides.html) is related to a question about whether specialized hardware can speed up embedding search, with a link to an article (https:\/\/trib.al\/HIuiF1K) for further information.\n- https:\/\/github.com\/jdagdelen\/hyperDB: A person is raising funds through their GitHub repository and someone mentioned that Langchain will integrate it by the end of the day.\n- https:\/\/bergum.medium.com\/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5: A post by Vespa founder discussing mistakes when introducing embeddings and vector search, which has inspired the speaker to launch their own database next week.\n- The URL https:\/\/python.langchain.com\/en\/latest\/modules\/chains\/index_examples\/summarize.html is being discussed in relation to an umbrella term used by langchain for memory chains or conversation memory.","45":"- langchain discord has a \"ask-kapa-langchain\" channel for asking doubts, with a useful bot based on the langchain docs and codebase, and integrated with https:\/\/www.mendable.ai\/. The bot allows to ask queries on discord chat and generates the answer in a thread. (URL not provided)\n- The Kapa Langchain bot is Discord-based and generates answers in a thread. The message also asks if the website https:\/\/www.paradox.ai\/solutions\/recruiters has automated screening of resumes.\n- Does this also have automated screening of resumes? (related to the links) \n  - https:\/\/www.skillate.com\/ \n  - https:\/\/leoforce.com\/\n- https:\/\/www.skillate.com\/ and https:\/\/leoforce.com\/ - The message mentions planning on building an automated screening in the company.\n- https:\/\/gooey.ai\/text2audio\/ - The message mentions an amazing lecture on the question of whether GPT4 is really AGI and recommends watching it.\n- https:\/\/twitter.com\/psurya1994\/status\/1647628166792372224?s=20 - A thread summarizing an amazing lecture on whether GPT4 is really AGI, with a link to the original paper.\n- https:\/\/arxiv.org\/abs\/2303.15647: A review of fine tuning techniques discussed in the BLR Generative April meetup.\n- https:\/\/bit.ly\/lsip-dataverse-ep4: Link to sign up for a chat with Benn Stancil, co-founder of Mode, to discuss generative AI and its impact on the BI layer.\n- https:\/\/bit.ly\/lsip-dataverse-ep4: Link to sign up for a chat with Benn Stancil, co-founder of Mode, to discuss BI and generative AI disruption.\n- https:\/\/replit.com\/bounties\/@JosephJacks\/llm-ify-any-app: The message mentions a collaboration idea related to the given URL, which is about a tool that can \"llm-ify\" any app but currently cannot do math calculations. The author speculates that it may have performed well in reasoning questions.\n- The given URL is \"https:\/\/chat.whatsapp.com\/GuJCOKL4nVHH3szN1d8TRV\" and it already exists. The message accompanying the link is a thank you message.\n- https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/matcha, https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/deplot, and Google's Pix2Struct are models that can answer questions based on diagrams, as mentioned in a message about trying to understand physics waves and IE Irodov questions.\n- https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/matcha, https:\/\/huggingface.co\/docs\/transformers\/main\/model_doc\/deplot, and Google's Pix2Struct are models that can answer questions based on diagrams, as mentioned in a message about trying to understand physics waves and IE Irodov questions.\n- The message \"who's picking all these names \ud83d\ude02\" is related to the URL https:\/\/www.together.xyz\/blog\/redpajama, which is being DM'd.\n- Huggingface built a wrapper around multiple finetuning methods, called it PEFT: https:\/\/github.com\/huggingface\/peft for my startup Bewgle.\n- https:\/\/twitter.com\/NathanLands\/status\/1647864974323204096: A tweet about a founder who is willing to do R&D, with a message about benchmarking open source LLMs against GPT4 and recommending Dolly 2 as the only commercially available option.","46":"- https:\/\/github.com\/marqo-ai\/marqo - a potential database to use for multimodal vector similarity search, which involves indexing image and text embeddings of useful information. The message also mentions the need for someone with solid experience in this area.\n- https:\/\/yaofu.notion.site\/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1: Found this in the eval PRs. Are there folks in this group interested in working on these problems?\n- https:\/\/www.together.xyz\/blog\/redpajama (related to reducing unknown unknowns)\n- https:\/\/t.co\/sVSHuljpwe: A demo for a program that is US or US remote, with a message indicating that the person might DM (direct message) for more information.\n- Personal search related: https:\/\/github.com\/KnowledgeCanvas\/knowledge - interested in working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data. Both Gh and hf are facing issues.\n- Very good read: https:\/\/www.wired.com\/story\/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over\/ Title is a bit misleading though. The point is that models will become better, but not by adding more base training data.\n- https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ - I heard there\u2019s a meet up this sat. Where can I find details about this and how do I register?\n- https:\/\/github.com\/Mimino666\/langdetect: The message discusses the difficulty of detecting language in audio and references the open-source project langdetect on GitHub for text language detection.\n- https:\/\/www.youtube.com\/watch?v=30xueN12guw: The video demonstrates how specifying the language can make language detection and translation easier for a generic question. The message in the same link as the video is related to the topic.\n- https:\/\/www.causal.app\/ - A neat offering related to finance, but not specifically Generative AI.\n- https:\/\/www.causal.app\/ - A neat offering that is not GenerativeAI. \n- https:\/\/github.com\/OpenBB-finance\/OpenBBTerminal\/releases\/tag\/v3.0.0rc2 - Open Source Bloomberg GPT.\n- https:\/\/www.instagram.com\/reel\/Cq5eWq4rRQC\/?utm_source=ig_web_copy_link - This link leads to a video reel on Instagram that the sender thinks is very good.\n- https:\/\/www.instagram.com\/reel\/Cq5eWq4rRQC\/?utm_source=ig_web_copy_link - This link leads to a video made via SD and the message mentions that the guy's last couple of reels are very good.\n- https:\/\/huggingface.co\/liuhaotian\/LLaVA-13b-delta-v0: This link is mentioned in the context of a limited version of logojoy.com and is being appreciated for being open. The message also mentions Midjourney for logo creation.\n- https:\/\/huggingface.co\/spaces\/hysts\/ControlNet: A Gradio space for segmenting various attributes of UI elements, suggested to someone who mentioned having existing designs and asked for elaboration on segmenting UI elements. The message also discusses the potential of control net models and T2I adapters for achieving maximum control.\n- Controlnet (https:\/\/github.com\/lllyasviel\/ControlNet) is being discussed as a useful tool for maximum control, with community momentum behind it.","47":"- https:\/\/en.wikipedia.org\/wiki\/Shapiro%E2%80%93Wilk_test - This link provides information about Shapiro Wilk, which is a measure of whether the data is normally distributed or not. The message in the same link as the URL explains that normality is not necessary for regression on a dataset and suggests alternative methods.\n- https:\/\/open-assistant.io\/ - LAION-AI initiative's opensourced alternative to ChatGPT.\n- https:\/\/github.com\/geekyutao\/Inpaint-Anything - suggested as a possible solution for a website to check out for inpainting.\n- https:\/\/twitter.com\/hwchase17\/status\/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19 - A tweet about parents worrying about memory and the lack of worry from the poster, with a mention of the pessimists_archive Twitter handle.\n- https:\/\/twitter.com\/varunshenoy_\/status\/1648374949537775616?s=52 - GPT4 8k and 32k versions are now available on Azure Openai India as well.\n- Twitter URL: https:\/\/twitter.com\/varunshenoy_\/status\/1648374949537775616?s=52 \nContext: A suggestion is given to change the object's position and use SD Inpainting for better results. The details of the product are mentioned in the link provided. The message also asks if anyone is using promptlayer or other tools for prompt versioning.\n- https:\/\/www.izzy.co\/blogs\/robo-boys.html - Humanloop does A\/B testing+versioning of prompts and integrates with langchain, as mentioned in the same link.\n- https:\/\/www.databricks.com\/blog\/2023\/04\/18\/introducing-ai-functions-integrating-large-language-models-databricks-sql.html: \"\ud83d\udc4d joined the waitlist. Interesting attempt at structuring prompts better. guardrail:XML, this:SQL.\"\n- https:\/\/python.langchain.com\/en\/latest\/modules\/models\/llms\/examples\/token_usage_tracking.html: A suggestion for getting notified about costs incurred when running LLM calls, with a shoutout to guardrails.\n- https:\/\/cdn.discordapp.com\/attachments\/1059408411890028584\/1098182375965478963\/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png \n  - The message suggests trying openjourney if it's urgent and also mentions that the Discord CDN has no authentication.\n- https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59 - A PR branch for an open source transformer that can be used for content creation and has been recommended in response to a question about retraining open source transformers. The message also mentions an issue with the transformer not recognizing Indian accents.\n- https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59#issuecomment-1514694410 (an issue opened regarding a potential issue with Vall-e and a promise to patch in some folks to help)\n- DeepSpeed - https:\/\/www.deepspeed.ai\/ is being discussed as it powers Bloom and LoRA from MSFT.\n- https:\/\/github.com\/Stability-AI\/StableLM: DevEx is the key - long Redis. The message also includes \"Awesome !!! \ud83e\udd29\" which is related to the link.\n- https:\/\/twitter.com\/Nils_Reimers\/status\/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19 and https:\/\/twitter.com\/jerryjliu0\/status\/1648709029777252352?s=46&t=gjIVQMn9Hp7sUgYs_m23Ww - The message discusses the good discrimination of multilingual embeddings for Indian languages based on experiments.\n- https:\/\/twitter.com\/Nils_Reimers\/status\/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19 \n  - This tweet is from Nils Reimers and mentions contributing with Evalset generator.","48":"- https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ - This link provides information about a meet-up happening in BLR on Saturday evening, which the person is asking about in the message.\n- https:\/\/hasgeek.com\/generativeAI\/april-meetup\/ BLR, Saturday evening: A meetup event for generative AI in Bangalore on a Saturday evening. No direct relation to the second URL provided. \n- https:\/\/blog.replit.com\/llm-training A good blog post by Replit where they give us high-level description of how they train their own LLMs. The blog post mentions that the Replit team is <5 people, which is amazing.\n- Fabian Stelzer's tweet about talent density and head count, with a heart and fire emoji, and a link to a video where the EyeQuant founder talks about text2film. (https:\/\/twitter.com\/fabianstelzer\/status\/1648700767992180737?s=48)\n- https:\/\/simonwillison.net\/2022\/Sep\/17\/prompt-injection-more-ai\/ - The message \"midjourney outsourced frontend to discord \ud83d\ude02\" and \"Cracked crazy adoption\" are related to the link.\n- Original song by Ariana Grande: https:\/\/www.youtube.com\/watch?v=DOJremEQw88 (related to a message about cracked crazy adoption and a question about the technology used)\n- https:\/\/twitter.com\/vboykis\/status\/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19 - A tweet discussing the idea of setting up different teams for different keys to track usage per organization basis by OpenAI, with a related analogy.\n- The user mentions a GitHub repository for OCR called \"donut\" (https:\/\/github.com\/clovaai\/donut) and questions the performance of Tesseract in production environments.\n- Microsoft's LayoutLMv3 already does OCR: https:\/\/huggingface.co\/microsoft\/layoutlmv3-base, as discussed in a conversation about using a multimodal LLM for OCR instead of Tesseract or AWS\/GCP API.\n- https:\/\/github.com\/microsoft\/MM-REACT and https:\/\/github.com\/Layout-Parser\/layout-parser are mentioned in relation to the author's experience using MM-REACT, which utilizes the reasoning capabilities of LLMs to extract information from visually rich documents and is found to work better than Donut.\n- https:\/\/github.com\/Layout-Parser\/layout-parser: Last time I checked, Langchain had a layout-parser integration for PDFs.\n- https:\/\/blog.eleuther.ai\/transformer-math\/?s=08: Langchain had a layout-parser integration for PDFs and an optimized implementation for Whisper, which is faster than real-time.\n- https:\/\/twitter.com\/CohereAI\/status\/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19: A tweet asking for suggestions on tools or best practices for recording LLM experiments and tracking metrics like accuracy\/precision improvements. The message also emphasizes the importance of being open and accessible for more acceptance and traction.\n- https:\/\/llava-vl.github.io\/ - A website that performs well on gpt-4 samples, mentioned in a tweet comparing it to minigpt-4. The tweet can be found at https:\/\/twitter.com\/marty_catboy\/status\/1649032460573745152.\n- https:\/\/llava-vl.github.io\/ is a very good website that performs well on GPT-4 samples, as mentioned in a tweet by Marty Catboy about Martin Shkreli's AI launch.\n- https:\/\/www.youtube.com\/watch?v=YfBtytGNEKE - Link to live talks at Weights & Biases LLMOps London event mentioned in a message about Martin Shkreli's AI launch.","49":"- https:\/\/kubiya.ai\/ - A resource that the speaker absolutely loves and is asking if anyone has tried something similar.\n- https:\/\/blog.replit.com\/llm-training: The message mentions a talk on advanced stable diffusion techniques for a hackathon, covering how to inpaint and use controlnet within the inpainting mask.\n- https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/12etqvx\/tutorial_creating_a_consistent_character_as_a\/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1 - Tutorial on creating consistent AI characters across images with SD, shared in a message about a 3D artist who has worked with NeRFs.\n- https:\/\/jalammar.github.io\/illustrated-transformer\/ - A link to an illustrated guide on Transformers, with a message thanking someone named Nirant.\n- https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ: A YouTube playlist, possibly related to a conversation with Nirant.\n- https:\/\/docs.google.com\/spreadsheets\/d\/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4\/edit?usp=sharing: A Google Sheets document, described as a \"quick and dirty effort\" and possibly related to the same conversation with Nirant.\n- https:\/\/youtube.com\/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ: Link to a YouTube playlist. The message in the same link as the link is unrelated to the playlist.\n- https:\/\/news.mit.edu\/2023\/large-language-models-in-context-learning-0207: Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples.\n- https:\/\/news.mit.edu\/2023\/large-language-models-in-context-learning-0207: Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples.","50":"- https:\/\/colab.research.google.com\/drive\/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing: Link to a Google Colab notebook where one can train\/run models using a free Tesla T4 from Google.\n- https:\/\/fullstackdeeplearning.com\/cloud-gpus\/ - A comparison table for cloud GPUs is suggested as useful for downloading lots of data and doing it on a recurring basis. The message also mentions trying Google Colab despite it not being suitable for the task.\n- https:\/\/www.freecodecamp.org\/news\/how-to-use-google-colab-with-vs-code\/ : The article discusses how to use ngrok and vscode with hosted notebooks to code with scripts and use GPU resources for free. It also mentions that this method used to work with Colab but seems to have been banned.\n- https:\/\/vast.ai\/ - The message asks for reviews on this cloud GPU rental platform.\n- URL: N\/A (not provided in the given context)\n- Context: The message in the given link provides information on how to reduce the size of a container image when using Sentence Transformers for word embeddings by using the Torch CPU image instead of the Torch GPU image. The Docker file command for installing Torch CPU is also provided.\n- https:\/\/www.qblocks.cloud\/ is run by a friend and is recommended for use. The message also offers to put the reader in touch with the founder if needed.","51":"- https:\/\/www.udemy.com\/course\/nlp-with-transformers\/ - recommended course for NLP hands-on with theory, mentioned in a message about a good learning path that skips LLM theory and the usefulness of deploying applications on Heroku.\n- https:\/\/twitter.com\/mckaywrigley\/status\/1649492404943323136 - McKay Wrigley is starting a course on Replit on AI dev and the day 0 course is available. The message also mentions that affordable instances on Fly.io are available for about $2\/mo.\n- GitHub link for controlnet Inpaint guidelines for A1111: https:\/\/github.com\/Mikubill\/sd-webui-controlnet\/issues\/968. The author of the repo also provides a phone number for testing purposes.\n- https:\/\/twitter.com\/yoheinakajima\/status\/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg - A tweet by the creator of BabyAGI discussing a new approach to vector search and embeddings, created with ChatGPT.\n- https:\/\/yoheinakajima.com\/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search\/ - Nakajima has been tinkering with AGI for long, indicating that the given URL is not fluff and has actual basis.\n- https:\/\/huggingface.co\/spaces\/hysts\/ControlNet (used for generating an image of a key ring with the OpenAI logo on it)","52":"- https:\/\/github.com\/orgs\/supabase\/discussions - A link to Supabase's GitHub discussions page where a user can get a faster response to their query. The message also asks for help analyzing SQL if it's an RPC call.\n- https:\/\/explain.dalibo.com\/ - The website where someone posted something, but there has been no response yet. The context of the post is unclear.\n- https:\/\/github.com\/brkirch\/stable-diffusion-webui\/releases: This link is mentioned in the message as the location of a new branch for Mac release of Automatic1111, which is faster than the stock version but still experimental.\n- https:\/\/github.com\/brkirch\/stable-diffusion-webui\/releases: Link to the releases page of the stable-diffusion-webui repository on GitHub.\n- https:\/\/e2eml.school\/transformers.html: The message discusses the increasing percentage of users in India for an unspecified platform, and mentions that OpenAI requires users to be 18 years old to use ChatGPT.\n- https:\/\/www.reddit.com\/r\/selfhosted\/comments\/12w4p2f\/localai_openai_compatible_api_to_run_llm_models\/ - The link is mentioned in a message asking for suggestions for speakers with a similar style to Amod for a meetup.\n- https:\/\/mitchellh.com\/writing\/prompt-engineering-vs-blind-prompting: The message in the same link as the URL mentions preferred tasks for May and offers help with delivering a talk, and an addendum mentions the April theme of Question Answering.\n- The curator for the May theme on image generation, video, and sound is Soumyadeep, who runs a Generative AI company in Bengaluru. (https:\/\/www.linkedin.com\/in\/soumyadeepmukherjee\/?originalSubdomain=in)\n- https:\/\/warpspeed2023.devfolio.co\/ - Excellent criticism of safetyism and discusses the loudest detractors and their main arguments (excellent if you want to catch up!)\n- https:\/\/twitter.com\/Uncanny_Harry\/status\/1650462479237931008?s=2 - The message in the same link as the link is related to live performance capture projects.\nThe given URL discusses how Indian engineering colleges are leading generative AI research projects in Indic languages, but are facing challenges in data sourcing and computing power. The message in the same link as the URL explains that a NLP model from huggingface follows the transformer library specification and has a vocab file that includes the words it was trained to encode, but new lines and tabs are not part of the vocabulary.\n- https:\/\/twitter.com\/aribk24\/status\/1650372832524926977?s=20 - A Twitter user offering help and expertise on certain topics.","53":"- https:\/\/gist.github.com\/yoavg\/6bff0fecd65950898eba1bb321cfbd81 - V. interesting read on potential to use RL without human feedback.\n- Feels like a dialogue straight outta \u2018Indian Matchmaking\u2019: https:\/\/openai.com\/brand +1 on this\n- https:\/\/techcrunch.com\/2023\/04\/24\/gpt-may-be-trademarked-soon-if-openai-has-its-way\/ - OpenAI is trying to trademark GPT and prevent any use of [insertword]GPT that may suggest an association\/affiliation\/partnership with OpenAI when there may be none.\n- https:\/\/replit.com\/bounties\/@YoheiNakajima\/scrape-an-api-and-se - off-topic - anyone wants to complete a Bounty for Yohei Nakajima? Too little money for trivial work?\n- https:\/\/github.com\/openai\/chatgpt-retrieval-plugin\/pull\/59#issuecomment-1514694410: The message discusses difficulty in setting up Qdrant and Chroma with the chatgpt-retrieval plugin and also asks for recommendations on affordable spot GPU\/cloud providers.\n- https:\/\/arize.com\/observe-2023\/ - The URL is provided as context and does not require training or inference. The message in the same link as the URL is related to the link and may require zero shot or one shot inference.\n- https:\/\/github.com\/xtekky\/gpt4free: A possible solution for accessing GPT4 without a paid subscription is shared in response to a request for someone to share their GPT4 access for a day and a half.\n- https:\/\/github.com\/voicepaw\/so-vits-svc-fork (Nope. mentioned in response to a question about using https:\/\/beta.elevenlabs.io\/)\n- https:\/\/github.com\/voicepaw\/so-vits-svc-fork - Someone leaked pretrained models of many popular singers a week back. Was that for this project?\n- https:\/\/docs.google.com\/spreadsheets\/d\/1qzeFdpUPr7E0jOFwWSXd8LF30ZLjz1CSVEBiG8gPHTU\/edit#gid=1792554832 - Probably. Wait I'll share. They even got Freddy. (Context: someone is sharing a Google Sheets link and mentioning that Freddy is included in it)\n- The message \"They even got Freddy\" is related to the URL https:\/\/twitter.com\/tivadardanka\/status\/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA, which is followed by the URL https:\/\/aiagent.app\/.\n- https:\/\/twitter.com\/tivadardanka\/status\/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA - A tweet mentioning a cool website and asking about the creator. The website mentioned is https:\/\/aiagent.app\/.\n- https:\/\/weaviate.io\/developers\/weaviate\/installation\/weaviate-cloud-services - The message mentions using Weaviate's managed SaaS service WCS and expresses curiosity about why it hasn't been found useful.\n- The website https:\/\/whiterabbit.ai\/ is given as an example of AI-assisted healthcare, which can minimize effort and improve patient outcomes. The message also mentions the difficulty of finding a good and affordable approach for hosting a stable diffusion-based web app.\n- https:\/\/gooey.ai\/compare-large-language-models\/?example_id=7ihhyv3l - A link related to serverless and modal and banana type services. The message in the same link as the URL is related to the link.\n- https:\/\/arize.com\/observe-2023\/ - The message mentions that the author owns the website and invites users to DM for bugs and feedback. The message also states that the author has spent a lot of time trying different GPU hosting platforms.\n- https:\/\/modal.com\/docs\/guide\/webhooks: A recommendation for Modal Labs as a beginner-friendly GPU hosting platform with Python-friendly web endpoints.\n- https:\/\/manifold.markets\/IsaacKing\/will-any-llm-have-a-context-window - A discussion about whether any language model will have a context window, with a related discussion on Hacker News.\n- https:\/\/manifold.markets\/IsaacKing\/will-any-llm-have-a-context-window - Discussion about the deployment of FMs in production using few-shot in-context learning. Related discussion can be found at https:\/\/news.ycombinator.com\/item?id=35682424.\n- https:\/\/www.researchgate.net\/publication\/370213628_Scaling_Transformer_to_1M_tokens_and_beyond_with_RMT: Personal experience from a limited sample set - more about the use-case than regulations. The message in the same link as the URL is about Indian clients' concern regarding their data being used for model training in different industries.\n- https:\/\/learn.microsoft.com\/en-us\/legal\/cognitive-services\/openai\/data-privacy: OpenAI engineer Boris Power's insights on the use of prompting and fine tuning for AI models.\n- https:\/\/openai.com\/blog\/new-ways-to-manage-your-data-in-chatgpt - Instructions to turn off chat history on ChatGPT and assurance that all data is deleted within 30 days and not used for training.","54":"- https:\/\/twitter.com\/Mascobot\/status\/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19 - A tweet discussing the development of a project that was apparently built in under 2 weeks, and mentioning the differences between GPT3.5-turbo, GPT4, and vanilla LLM.\n- The URL is a Reddit post in the r\/StableDiffusion subreddit discussing Google researchers achieving performance breakthroughs in machine learning. The message in the same link asks if anyone is working on ML on edge.\n- The message expresses excitement about Qualcomm's demonstration of stable diffusion on Android, which is showcased in the given URL: https:\/\/www.qualcomm.com\/news\/onq\/2023\/02\/worlds-first-on-device-demonstration-of-stable-diffusion-on-android.\n- https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J - PSA: Dedicated group for music, images, video. The message also discusses testing Chinchilla limits and training for more tokens than most people have tried for similarly sized models. An expert talk by the person mentioned would be helpful.\n- https:\/\/twitter.com\/matthieurouif\/status\/1650904940036890626 - A message about the availability of an API for the gpt-4 multimodal model.\n- https:\/\/minigpt-4.github.io\/ or https:\/\/llava-vl.github.io\/ can be used instead of Photoroom as it doesn't have image understanding.\n- https:\/\/minigpt-4.github.io\/ or https:\/\/llava-vl.github.io\/ can be used instead of Photoroom as it doesn't have image understanding.\n- The URL https:\/\/dust.tt is mentioned and it is described as \"awesome\" but it is currently internal. There is no mention of any image understanding.\n- The LinkedIn post discusses using AI models to generate a background for a photoshoot and includes a link to a pizza commercial created using these tools. The post also mentions someone playing with music generation. (URL: https:\/\/www.linkedin.com\/posts\/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios)\n- https:\/\/www.paperspace.com - suggested as an option for GPU usage in experimentation with StableDiffusion and running Gradio\/Automatic1111, as well as storage needs for models like Lyriel\/Deliberate+Controlnets, with a note that the 5GB space on Gradient may not be sufficient.\n- The URL https:\/\/research.google.com\/colaboratory\/marketplace.html is mentioned in the context of connecting a GCE VM to Colab for persistent sessions and dedicated compute. The message also recommends using Runpod and stopping the instance when not in use to only be charged for storage.\n- https:\/\/news.ycombinator.com\/item?id=35697627 - This link provides context to the statement that \"For non persistent \/ spot instances of GPUs GOOG was always in under supply while we were testing\" mentioned in the same message.\n- https:\/\/news.ycombinator.com\/item?id=35697627: A question on Weaviate usage, asking whether metadata is stored in Weaviate or a different database.\n- https:\/\/www.youtube.com\/watch?v=7TCqGslll-4 and https:\/\/github.com\/ai-forever\/Kandinsky-2 are mentioned in the context of discussing containerization and embedding content in an app.\n- https:\/\/www.youtube.com\/watch?v=7TCqGslll-4: Link to a YouTube video, context unknown.\n- https:\/\/github.com\/ai-forever\/Kandinsky-2: Link to a GitHub repository for Kandinsky-2, context unknown.","55":"- The Twitter link leads to a tweet by user @rasbt, which may contain relevant information or a message related to the given context. The phone number has been removed for privacy reasons.\n- Replit's latest announcement is interesting: https:\/\/twitter.com\/swyx\/status\/1650989632413401089?s=20 (Their managed SaaS right now actually charges only based on the number of vectors and the dimensions of the vectors, irrespective of the extra metadata stored. Anyone started learning LLMs\/Transformers\/ML in the last 3 months?)\n- The context is about Lua JIT and WASM, and the given URLs are related to it. The first URL is for OpenResty, while the second URL is a blog post from Tetrate.io explaining WASM modules and Envoy extensibility.\n- https:\/\/tetrate.io\/blog\/wasm-modules-and-envoy-extensibility-explained-part-1\/ - This blog post explains how API proxies like Envoy, Istio, and Nginx have a customized layer where multiple filters can be added to extend functionality using Lua, Wasm, etc. It also mentions that Lua interpreters have less overhead and are faster than Python interpreters.\n- https:\/\/twitter.com\/raj_raj88\/status\/1631018786492157954: A Twitter post discussing the versions 302, 303, etc. in relation to something unspecified.\n- https:\/\/twitter.com\/raj_raj88\/status\/1631018786492157954 - The tweet mentions \"3.5-turbo\" which refers to the latest model \"3.5-turbo-x\". The message in the same link as the tweet is related to the link.\n- https:\/\/github.com\/rasbt\/gradient-accumulation-blog\/blob\/main\/src\/1_batchsize-1.py - A notebook that helped with training a Bloom model by performing gradient accumulation over multiple batches to emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices. The message also mentions a memory leak issue.\n- https:\/\/twitter.com\/Replit\/status\/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19 - The message suggests trying out qblocks.cloud.\n- Link: https:\/\/lu.ma\/StateofAI \n  Context: Link to register for a talk by two leading US researchers in AI being hosted at 7:30 PM in Indiranagar with limited seating of 20.\n- https:\/\/course.fast.ai - a recommended resource for training in AI, particularly in NLP and other areas such as Vision and Speech. The message also suggests trying to train with Huggingface to learn more.\n- https:\/\/docs.google.com\/spreadsheets\/d\/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM\/edit#gid=962390240 - A spreadsheet that starts from scratch and may or may not be useful to many, but the message in the same link as the URL is related to it. The request is to reshare or link it in the group description, and it's up to the admin's call if they want to add it.\n- https:\/\/twitter.com\/andrewyng\/status\/1651605660382134274?s=46&t=wdMpftHBI367157ViAY2Gg - Pinecone raised 100m. The message in the same link as the URL is related to the link.\n- Pinecone raised 100m: https:\/\/twitter.com\/pinecone\/status\/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19 - The tweet mentions that Pinecone is having a moment similar to Nvidia in the age of Langchain and it's good to raise funds when there's buzz.\n- https:\/\/www.databricks.com\/blog\/contributing-spark-loader-for-hugging-face-datasets: The content game of the website is great and they are within 5 in most AI keywords. The message in the same link as the URL is about planning something on the weekend and asking someone to take the lead, with two people CC'd.","56":"- https:\/\/sites.google.com\/huggingface.co\/generative-ai-meetup: A link to a website for a generative AI meetup, with a message requesting an experienced person to guide and answer queries.\n- The first URL is a tweet requesting guidance and answers from an experienced person, while the second URL is a news article about MEPs sealing the deal on an artificial intelligence act. The context suggests that the person is seeking guidance on the topic of artificial intelligence. The URLs are: \nhttps:\/\/twitter.com\/thesephist\/status\/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19 \nhttps:\/\/www.euractiv.com\/section\/artificial-intelligence\/news\/meps-seal-the-deal-on-artificial-intelligence-act\/\n- https:\/\/twitter.com\/thesephist\/status\/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19 - This tweet may be related to the link about MEPs sealing the deal on the Artificial Intelligence Act.\n- The use of transformers for lane detection is discussed in a YouTube video (https:\/\/youtu.be\/aVjDX5XshYo) and a related research paper (https:\/\/arxiv.org\/abs\/2112.00390).\n- They use transformers for lane detection- https:\/\/youtu.be\/aVjDX5XshYo and https:\/\/arxiv.org\/abs\/2112.00390, text2motion\n- https:\/\/tsmatz.wordpress.com\/2023\/03\/07\/react-with-openai-gpt-and-langchain\/ - The message in the same link as the URL criticizes the practice of touching a GPU for custom embedding in 2023, calling it a \"very 2016 thing to do\" and a \"late stage hype cycle thing to do.\"\n- https:\/\/www.namefinder.ai: Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone. A dairy founder wanted g.ai but had to resort to mal.ai.\n- https:\/\/docs.nvidia.com\/deeplearning\/transformer-engine\/user-guide\/index.html (related to the impact of NVIDIA's Transformer Engine on FP8 performance)\n- https:\/\/twitter.com\/bentossell\/status\/1636394074101153792: The message in the same link as the URL discusses the potential for market competition to dictate pricing for serverless GPUs.\n- https:\/\/github.com\/peterw\/Chat-with-Github-Repo: A user is asking for tools that can summarize custom code repos\/documentation and provides an example link for reference.\n- https:\/\/github.com\/mtenenholtz\/chat-twitter: A request for tools that can summarize custom code repos\/documentation, with an example link provided.\n- The given URL https:\/\/github.com\/peterw\/Chat-with-Github-Repo is related to a chat application built using GitHub repository. Another URL https:\/\/stability.ai\/blog\/deepfloyd-if-text-to-image-model is also mentioned, but the context is not clear.","57":"- https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/examples\/vector_indices\/PineconeIndexDemo.ipynb: The response from Vector DB and how to retrieve the sources using response.source_nodes.\n- https:\/\/python.langchain.com\/en\/latest\/modules\/chains\/index_examples\/qa_with_sources.html - a link related to a discussion about using text-davinci-003 and its trade offs.\n- https:\/\/github.com\/openai\/evals\/blob\/4da6a6115ac03df4f8364903815a6e73e95c2fd1\/evals\/prompt\/base.py#L22 - A user is asking about a code snippet and expressing regret for not thinking of it earlier.\n- https:\/\/medium.com\/airbnb-engineering\/when-a-picture-is-worth-more-than-words-17718860dcc2 - An article discussing the use of user-scored images and ResNet in classification models, and how Big Data can be more effective than Big Brains in machine learning.\n- The URLs https:\/\/replicate.com\/cjwbw\/damo-text-to-video and https:\/\/github.com\/Picsart-AI-Research\/Text2Video-Zero are related to a text-to-video project.\n- https:\/\/replicate.com\/cjwbw\/damo-text-to-video and https:\/\/github.com\/Picsart-AI-Research\/Text2Video-Zero are related to text-to-video conversion. The message in the same link mentions a discussion on \"Learning Transformers\/NLP\/ML\" on Sunday from 4-5pm.\n- https:\/\/twitter.com\/bhutanisanyam1\/status\/1412933178411536384: A message thanking Amir for flagging something, with no further context provided. \n- https:\/\/postgresml.org\/blog\/tuning-vector-recall-while-generating-query-embeddings-in-the-database: A blog post about tuning vector recall while generating query embeddings in the database.\n- https:\/\/twitter.com\/bhutanisanyam1\/status\/1412933178411536384: A tweet by user @bhutanisanyam1 with the message \"Haha - I'm here\" and a link to a blog post on tuning vector recall while generating query embeddings in the database on the website postgresml.org.\n- The given URL is a Microsoft Teams meeting link and is related to a message requesting a tech expert to drive 15 minutes of a session on Generative AI in a Zoom meet-up.\n- https:\/\/playbook.samaltman.com: The message in the same link as the URL suggests that generative models are not necessary for converting raw text to PDFs\/images and applying simple distortions to get synthetic data for OCR.\n- guardrails released something recently, as mentioned in this tweet by ShreyaR: https:\/\/twitter.com\/ShreyaR\/status\/1650883072324419587. A phone number was also mentioned but has been removed.","58":"- https:\/\/github.com\/gventuri\/pandas-ai: Anyone has found any solution to ChatOpenAI giving \"Could not parse LLM output:\" errors?\n- https:\/\/github.com\/jerryjliu\/llama_index\/blob\/590639a14dd7346b7f5cc00a21dd24ce0d35ae30\/gpt_index\/langchain_helpers\/text_splitter.py#L240 and https:\/\/github.com\/openai\/openai-python\/blob\/c556584eff3b36c92278e6af62cfe02ebb68fb65\/openai\/embeddings_utils.py#L21 - Anyone has found any solution to ChatOpenAI giving \"Could not parse LLM output:\" errors?\n- https:\/\/github.com\/jerryjliu\/llama_index\/blob\/590639a14dd7346b7f5cc00a21dd24ce0d35ae30\/gpt_index\/langchain_helpers\/text_splitter.py#L240: This is a link to a specific line of code in a Python file on GitHub related to text splitting. \n- https:\/\/github.com\/openai\/openai-python\/blob\/c556584eff3b36c92278e6af62cfe02ebb68fb65\/openai\/embeddings_utils.py#L21: This is a link to a specific line of code in a Python file on GitHub related to embeddings. \n- https:\/\/scale.com\/content-language: This is a link to a webpage discussing content language on the Scale website, which was referenced in a paper by OpenAI.\n- https:\/\/github.com\/openai\/openai-python\/blob\/c556584eff3b36c92278e6af62cfe02ebb68fb65\/openai\/embeddings_utils.py#L21: This link leads to the embeddings_utils.py file in the openai-python repository on GitHub. The message mentions that this code was used in OpenAI's RLHF paper. Another link to the Scale website and a tweet by Misbah Sy are also provided.\n- https:\/\/scale.com\/content-language - OpenAI used this in their RLHF paper.\n- The recall measurement details can be found at https:\/\/ann-benchmarks.com, in response to a question about how to read it. Another question in the same message asks for advice on implementing a semantic file search, potentially for use with Google Drive.\n- https:\/\/llm.report: a tool that shows a nice dashboard of costs incurred while using OpenAI api\u2019s, mentioned in a message thanking participants for sharing pointers and notes.\n- https:\/\/twitter.com\/bohanhou1998\/status\/1652151502012837890?s=20 - Looking to connect with graphic designers in marketing agencies or anyone who knows someone in such an agency.","59":"- https:\/\/github.com\/georgia-tech-db\/eva: The user is mentioning that they have access to GPT plugins but cannot find the tool in the UI. They also ask if there are any Flask\/Python web stack developers available for freelance work.\n- https:\/\/nirantk.com\/community - A Google Form for hiring from the community has been added and the message suggests creating a different announcement group.\n- The request is to add a link and clarify the type of freelancing role for a video on YouTube (https:\/\/www.youtube.com\/watch?v=FE88OOUBonQ).\n- Hinton, a prominent AI and chatbot engineer, is leaving Google according to a news article on The New York Times website: https:\/\/www.nytimes.com\/2023\/05\/01\/technology\/ai-google-chatbot-engineer-quits-hinton.html","60":"- The tweet at https:\/\/twitter.com\/zoink\/status\/1653052807950536706 suggests that the author's tweets are better, and asks how people are using ChatGPT to learn.\n- https:\/\/www.yudbot.com\/ - The message in the same link as the URL questions the ethics of putting news articles behind a paywall.\n- The URL https:\/\/augmented-reality-knowledge.github.io\/ is being shared and the message asks if there are any shortcomings that need to be aware of and if the link is not working for the recipient.\n- Code flow example: https:\/\/github.com\/hwchase17\/langchain\/blob\/master\/langchain\/memory\/summary.py (link to a code example on GitHub)\n- https:\/\/deeplearn.org\/ - someone mentions using this website for something related to a question about a commercial license for deforum and a potential alternative called Semantic Kernel.\n- URL: https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/gpt_index\/prompts\/default_prompts.py \n- Context: The message warns against using langchain and suggests an alternative approach for saving chat messages in a system. The URL may provide more information on the topic.\n- https:\/\/42papers.com\/ - Creator of this website and other related websites may have insight into why LangChain is focused on tools and agents.","61":"- https:\/\/twitter.com\/samim\/status\/1653289578390749186?s=46 - The message in the same link as the URL is related to the scale being asked about.\n- https:\/\/twitter.com\/AlistairPullen\/status\/1653459578229788672?s=20 - GPT4 creates a vector DB.\n- https:\/\/twitter.com\/grimezsz\/status\/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA - A tweet asking if Ghostwriter is powered by a certain technology, with a reference to a podcast where it was discussed.\n- https:\/\/twitter.com\/grimezsz\/status\/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA - A tweet about calling out something on a podcast, with a link to the podcast on YouTube. The tweet also mentions \"Finetune on instruction dataset curated from geeksforgeeks.\"\n- The given URL is a tweet by user @pirroh, which includes a link to a video, slides, and transcripts related to \"Prompt Injection\" that can be completed in less than 10 minutes. The content is based on an instruction dataset curated from geeksforgeeks.\n- JSONFormer: https:\/\/github.com\/1rgs\/jsonformer \u2014 guaranteed JSON output with Huggingface LLMs\n- The URL https:\/\/www.spellpage.com\/?utm_source=bensbites&utm_medium=newsletter&utm_campaign=pi-the-new-ai-on-the-block is related to an autogpt app, and the message in the same link as the URL is related to the app. Newlines may or may not be related to the link.\n- https:\/\/github.com\/microsoft\/table-transformer: A GitHub repository that might help with result cards in tabular form, as mentioned in the message.\n- The message asks if anyone has tried langflow and requests them to DM if they have. The message is not directly related to either of the URLs provided.\n- https:\/\/techcrunch.com\/2023\/05\/03\/where-is-india-in-the-generative-ai-race\/ - An article discussing India's position in the generative AI race.\n- https:\/\/www.latent.space\/p\/reza-shabani#details - A webpage providing details about Reza Shabani.\n- Interview with our head of ML and swyx - The message in the same link as the URL is related to an interview with the head of ML and swyx.\n- https:\/\/crfm.stanford.edu\/ecosystem-graphs\/index.html?mode=table - A person expresses interest in connecting and contributing to the project and also wants to learn more about it.\n- https:\/\/twitter.com\/refsrc?s=21 - A request to add author Manish Singh from Tech Crunch to a group of coders, designers, PMs, and VCs, and a question if there are any journalists or media folks in the group.","62":"- https:\/\/twitter.com\/alexwan55\/status\/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19 - The message in the same link discusses the impracticality of covering all modes of adversarial attack for any model with many parameters due to the curse of dimensionality.\n- https:\/\/huggingface.co\/aashay96\/indic-BloomLM - The link is mentioned in the message as an example of a large scale dataset (300GB) for llm model training.\n- https:\/\/github.com\/EleutherAI\/lm-evaluation-harness: Can you please look at this?\n- https:\/\/42papers.com\/ - The creator of this website and other websites, including artcompute.com and mindsjs.com, is mentioned in the message. The message also asks for suggestions on specific topics related to model training and deployment.\n- For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J and https:\/\/github.com\/unum-cloud\/usearch. The message also suggests that separate collections may be the cleanest way.\n- https:\/\/chat.whatsapp.com\/GThJJhoF3cL7QCmrfIoY8J - For folks interested in Generative Art, cool results from inpainting and other SD tricks there.\n- https:\/\/github.com\/unum-cloud\/usearch - No context provided.\n- https:\/\/github.com\/NimbleBoxAI\/ChainFury - From NimbleBox folks in India, [PHONE REMOVED] and friends \u2014 low-code for making chat experiences in particular.\n- https:\/\/github.com\/NimbleBoxAI\/ChainFury - A low-code tool for making chat experiences, mentioned in a message from NimbleBox folks in India along with a phone number and a shout-out to Nirant.\n- https:\/\/huggingface.co\/gemasphi\/laprador-document-encoder: Request for invite link to a group and inquiry about the use of langchain or llama index for hybrid embeddings.\n- https:\/\/github.com\/jerryjliu\/llama_index\/blob\/main\/examples\/query\/CustomRetrievers.ipynb - Examples of custom retrievers for Llama Index, a decent Retriever design mentioned in the conversation.\n- https:\/\/python.langchain.com\/en\/latest\/modules\/indexes\/getting_started.html: The message mentions that the indexes feel like a semantic search interface and thanks the discussion for helping understand the strengths of Langchain and\/or Haystack.\n- https:\/\/docs.haystack.deepset.ai\/docs\/document_store - discussed in relation to the strengths of Langchain and Haystack, and discovered as a potential solution for creating a single API for vector DBs. Also mentioned as an example of Haystack's strong design, particularly in the implementation of PromptNode compared to Langchain.\n- https:\/\/vitess.io\/ is a tool for sharding, as mentioned in a message about Vitess being a great tool and a primer for sharding at https:\/\/aws.amazon.com\/what-is\/database-sharding\/.\n- https:\/\/vitess.io\/ is a tool for sharding, as explained in a message praising its usefulness.\n- https:\/\/www.youtube.com\/watch?v=3MqJzMvHE3E - Jeremy Howard introduces Modular, an AI programming language that is 3000x faster than equivalent Python code for matrix multiplication. The programming language is called Mojo and is not Free or Open Source. Razorpay was exploring managed Vitess at https:\/\/planetscale.com\/.\n- https:\/\/open.substack.com\/pub\/semianalysis\/p\/google-we-have-no-moat-and-neither?r=2gao6&utm_medium=ios&utm_campaign=post (from an article discussing Google's lack of a competitive advantage and mentioning Jeremy's support for TF Swift)\n- https:\/\/lmsys.org\/blog\/2023-03-30-vicuna\/ - The message on the webpage talks about using GPT-4 as a judge to rate LLM outputs and the need for further evaluation.\n- If you're curious about the reason why it's not a good idea to train models on chatgpts output like Alpaca did, check out this tweet: https:\/\/twitter.com\/Shahules786\/status\/1650898925178720256. The message is related to the topic of LLM evaluation and benchmarking.\n- https:\/\/github.com\/databrickslabs\/dolly\/blob\/master\/training\/trainer.py - A link to a Python script for training a GPT4-fork finetuned on Python\/code, with context about the difference between Generative Pretraining and GPT training objectives.\n- The message mentions \"DM'd my list\" and includes two URLs: https:\/\/crfm.stanford.edu\/ecosystem-graphs\/index.html?mode=table and https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/137ex2j\/controlnet_tile_can_generate_details_for_each\/.\n- https:\/\/www.reddit.com\/r\/StableDiffusion\/comments\/137ex2j\/controlnet_tile_can_generate_details_for_each\/ - Discussion about GPT4 for coding in Rust\/working with libraries.\n- https:\/\/web.stanford.edu\/class\/cs224n\/slides\/cs224n-2023-lecture11-prompting-rlhf.pdf - A resource from Stanford that explains the big picture of pretraining, fine-tuning, and RLHF in natural language processing. The message suggests that one needs to deep dive into each of those areas for more details.\n- The Twitter link https:\/\/twitter.com\/pbteja1998\/status\/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08 is related to a discussion about preferring Flash Attention over multi-query attention for certain use-cases.\n- Interesting read from Simon Wilson on the disappearing moats in closed source models: https:\/\/simonwillison.net\/2023\/May\/4\/no-moat\/ (related to StarCoder's use of GPT2 model)\n- https:\/\/simonwillison.net\/2023\/May\/4\/no-moat\/ - Simon Wilson's article on moats in closed source models disappearing, mentioned in a message about resources for learning about GPT models and evaluating open source models for context-based conversation.\n- LM-evaluation-harness for Huggingface compatible models: https:\/\/github.com\/EleutherAI\/lm-evaluation-harness - recommended as a resource for evaluating open source models comparable to GPT models for context-based conversation, in response to a query about learning more about GPT model training and training for a specific domain. The message also mentions Dolly and OpenAssist as other options, and notes that GPT-JT is comparable to text-davinci-003.\n- LM-evaluation-harness for Huggingface compatible models: https:\/\/github.com\/EleutherAI\/lm-evaluation-harness - The message discusses the comparison of GPT-JT to text-davinci-003 and the surprise at the progress made through training data selection and parameters.\n- The Twitter link https:\/\/twitter.com\/lmsysorg\/status\/1653843200975704069?s=46 is mentioned and the message implies that the content of the link is reasonable.","63":"- Microsoft is investing in AMD to counter Nvidia GPU monopoly and developing custom inference GPUs to make inference costs low, which could make hosting other LLMs unnecessary unless there are compliance issues. This is part of Microsoft's efforts to commoditize their complement. The information is shared in the link https:\/\/gwern.net\/complement, which also discusses the potential implications of this strategy.\n- https:\/\/www.semianalysis.com\/p\/google-we-have-no-moat-and-neither: The message in the same link as the URL is related to the link, which talks about Google's lack of a competitive advantage. The context of the message is unclear, but it mentions missing a week.\n- https:\/\/docs.google.com\/presentation\/d\/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU\/edit#slide=id.g20f09001284_0_76 - Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up.\n- The URL https:\/\/agi-sphere.com\/llama-models\/ is mentioned in relation to So-vita-svc and so-vits-svc.\n- https:\/\/discord.gg\/aihub - A link to a Discord server with a community of 7000 people discussing models and cutting-edge work. The message also praises the community's focus and productivity, with a shoutout to [PHONE REMOVED].\n- https:\/\/discord.gg\/aihub: A link to a Discord server with a community of 7000 people discussing models and cutting-edge work, with praise for the community manager.\n- The URL https:\/\/wandb.ai\/site\/prompts is being shared\/discussed in the group and the message suggests that it may not have been shared before.","64":"- https:\/\/huggingface.co\/spaces\/mosaicml\/mpt-7b-chat: This link leads to a post on Hugging Face's website that explains what transformers are for beginners and those who want to deepen their understanding of the topic.\n- Check out 42papers.com for some interesting content. However, be aware that it may be similar to Twitter, with much of the content already coming from https:\/\/twitter.com\/_akhaliq. Here are some useful links I've found:\n- https:\/\/huggingface.co\/spaces\/Geonmo\/laion-aesthetic-predictor: Suggested as a tool to use for generating a score for a generated caption.\n- https:\/\/github.com\/mosaicml\/llm-foundry\/tree\/main\/scripts\/eval: The message in the same link as the URL mentions the need for a standard that everyone can use and expresses hope that HELM becomes that standard. The context of the URL is unclear.\n- https:\/\/landing.ai\/ - suggested as a potential solution for a workflow involving multiple models for a task that may be difficult for a single model to handle.\n- https:\/\/llava.hliu.cc\/ - Someone in the group was asking if anyone had experience finetuning GPT with Yahoo Finance. In response, someone shared a link to an open source alternative to Bloomberg terminal called OpenBB and mentioned that they released a blog on how to train on their documentation to get the appropriate OpenBB command.\n- https:\/\/www.mattprd.com\/p\/the-complete-beginners-guide-to-autonomous-agents: A beginner's guide to autonomous agents that the speaker is starting to look into.\n- https:\/\/github.com\/dosco\/minds: The speaker mentions that they have built something similar to this link for themselves, which is much simpler and has no dependencies.","65":""},"page_headers":{"0":"+++\ntitle =  \"Generative AI: Applications, Projects, and Investments\"\ndate = 2023-03-01T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"In this discussion, participants introduce themselves and their backgrounds in AI, ML, and related fields. They share their projects and startups, which range from electric planes to content generation and AI investments. Topics discussed include creating anime with StyleGAN, building agents for gaming and stock trading, generative AI in content and marketing, and recommendation systems for generative media consumption.\"\ntoc = true\n+++\n","1":"+++\ntitle =  \"Exploring ChatGPT API, Whisper Updates, and Anime Production\"\ndate = 2023-03-02T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A conversation about the ChatGPT API launch, improvements in Whisper API, controlnet integration, gpt-3.5-turbo's performance in applications, and Corridor Digital's innovative anime creation process using SD VFX and Blender.\"\ntoc = true\n+++\n","2":"+++\ntitle =  \"Exploring Generative AI and Brain-Computer Interfaces\"\ndate = 2023-03-03T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion on GoogleAI's Flan-UL2 20B, its comparison with ChatGPT API, the need for specialized models, and the potential of fMRI and SD in brain-computer interfaces. Also includes links to articles on generative AI product strategy and a YouTube video featuring a YC Founder and YC Partner.\"\ntoc = true\n+++\n","3":"+++\ntitle =  \"AI Bot Code, Art, Purchase Parity, and Movie Ideas\"\ndate = 2023-03-04T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"The group chat discusses the open-sourced Hasura AI bot code, the impact of Offset Noise on AI art, the concept of purchase parity, and a potential AI-themed movie idea.\"\ntoc = true\n+++\n","4":"+++\ntitle =  \"Exploring the World of Generative AI\"\ndate = 2023-03-05T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion about the potential, applications, and ethical implications of generative AI, along with sharing personal projects, tools, resources, events, and communities related to the field.\"\ntoc = true\n+++\n","5":"+++\ntitle =  \"Exploring 3D Art and AI: RealFusion, NeRF, and Embedding Techniques\"\ndate = 2023-03-06T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Discuss the advancements in 3D art and AI, including Oxford University's RealFusion diffusion model for 360-degree object reconstructions, Devanshu Tak's use of NeRF in 3D art, and the application of embedding and prompt templating in AI technologies like Hasura bot, Pinecone, and Langchain.\"\ntoc = true\n+++\n","6":"+++\ntitle =  \"Generative AI Hackathon and Normalizing Flows Discussion\"\ndate = 2023-03-08T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Participants discuss an upcoming Generative AI Hackathon with no constraints on problem statements, including April Fool Apps. They also talk about Normalizing Flows, sharing their interest and exploring industrial use cases or academic interest. A resource on generative AI is shared.\"\ntoc = true\n+++\n","7":"+++\ntitle =  \"Exciting Job Opening at Major Indian Company\"\ndate = 2023-03-09T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A member shares a job opportunity at a large content and consumer brands company in India, reaching 40% of the nation's social media users, and seeks interested candidates from the group or their connections. No further discussion follows.\"\ntoc = true\n+++\n","8":"+++\ntitle =  \"Exploring Indian Generative AI and GPT-4 Predictions\"\ndate = 2023-03-10T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A conversation delving into the current state of Generative AI in India, covering startups, government initiatives, and speculating on the possible features and release timeline of GPT-4.\"\ntoc = true\n+++\n","9":"+++\ntitle =  \"Hackathon Insights\"\ndate = 2023-03-12T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Exploring key topics such as registration, GPT hype, corporate involvement, and Runwayml access in the context of hackathons.\"\ntoc = true\n+++\n","10":"+++\ntitle =  \"On-Premises Deployment for OpenAI LLMs and Google's FLan-T5\"\ndate = 2023-03-13T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Exploring the possibilities of on-premises deployment for OpenAI LLMs, the role of OpenAI Foundry, and the introduction of Google's FOSS FLan-T5.\"\ntoc = true\n+++\n","11":"+++\ntitle =  \"Generative AI Group Chat: Hackathon and Alpaca AI\"\ndate = 2023-03-14T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A group chat discussing a hackathon with prize money and evaluation criteria, as well as exploring Alpaca AI's capabilities, pricing, and comparison to other AI models. The conversation also touches on the challenges of keeping up with rapid developments in the AI space.\"\ntoc = true\n+++\n","12":"+++\ntitle =  \"Exploring OpenAI's Impact, Learning Resources, and Research Topics\"\ndate = 2023-03-15T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dive into a multifaceted discussion on OpenAI's wireframe to code demo, its influence on productivity tools, deep learning and NLP learning resources, transformers, Stable Diffusion in art, emergent research properties, and other topics like organizing activities and RNNs.\"\ntoc = true\n+++\n","13":"+++\ntitle =  \"Research Paper Discussion and Storage Solutions\"\ndate = 2023-03-16T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Discussing the organization and participation in paper reading groups focused on popular models, sharing information about existing groups and events, and exploring storage options for embedding vectors.\"\ntoc = true\n+++\n","14":"+++\ntitle =  \"Exploring Language Models, AI Tools, and Productivity\"\ndate = 2023-03-17T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion delving into data cutoffs in language models like GPT-4, AI tools for large scale searches, productivity tools, and peculiarities of language models.\"\ntoc = true\n+++\n","15":"+++\ntitle =  \"AI Advancements and Meetup Updates\"\ndate = 2023-03-18T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore the new BingGPT launch, potential impacts of GPT4 on software engineering, image generation models, LORA and Alpaca improvements, and updates on the March gen ai meetup.\"\ntoc = true\n+++\n","16":"+++\ntitle =  \"FOSS Demos, AI Models, and Research Labs Discussion\"\ndate = 2023-03-19T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion covering FOSS demos for a hackathon, interesting AI-related links, AI models like WASM for LLMs, research labs in IITs, and a potential VC tool using AI.\"\ntoc = true\n+++\n","17":"+++\ntitle =  \"Exploring AI Models, Tools, and Industry Impact\"\ndate = 2023-03-20T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Discuss the latest AI models and tools like Hugging Face's text-to-video synthesis, GPT4, and Stable Diffusion, and their influence on industries such as video platforms and advertising. Additionally, delve into miscellaneous topics like conspiracy theories and Replit templates for AI.\"\ntoc = true\n+++\n","18":"+++\ntitle =  \"Generative AI Group Chat: Product Inpainting, 3D Capture, and AI Startups\"\ndate = 2023-03-21T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion on using generative AI for product inpainting, 3D product capture and visualization, and the role of Adobe and horizontal Gen AI startups in the industry. Topics include LoRA, ComfyUI, Flair, Booth.ai, ControlNet, Adapters, Composer, Luma, Canva, Deepset's Haystack, Hood project, Adept.ai, and various image captioning and chatbot models.\"\ntoc = true\n+++\n","19":"+++\ntitle =  \"Venture Investing, Proof of Concept, and AI Tools Discussion\"\ndate = 2023-03-22T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Participants discuss their backgrounds in venture investing, share a proof of concept script, explore AI tools for content creation, and express opinions on customization and Adobe's ML inference. Additionally, a paper on video compression and healthcare-related projects are mentioned.\"\ntoc = true\n+++\n","20":"+++\ntitle =  \"AI Discussion: JadooSnap, Indian Languages, and Photo Editing\"\ndate = 2023-03-23T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"The discussion covers topics such as JadooSnap, a praised but not yet publicly accessible website, Dukaan's potential Gates Foundation contract for a Hindi chatbot, the effectiveness of GPT in Indian languages, a proposed experiment for translation methods, AI photo editing techniques, and Adobe products.\"\ntoc = true\n+++\n","21":"+++\ntitle =  \"AI Model Customization and OpenAI Plugins\"\ndate = 2023-03-24T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion on refining AI model outputs, using style references, creating custom AI models, and exploring OpenAI ChatGPT plugins, along with off-topic conversations about Firestore, project showcases, and vernacular language support.\"\ntoc = true\n+++\n","22":"+++\ntitle =  \"Chaotic Generative AI Group Chat: Art Generation Workflow, AI Tools, and Learning\"\ndate = 2023-03-25T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"The discussion covers using Stable Diffusion for AI art generation, the workflow involving text2img, controlnet depth maps, and Automatic1111. Participants also discuss AI tools like Langchain agents and ChatGPT plugins, few-shot learning, and the concept of seeds in random number generation. Humor and social links are also shared.\"\ntoc = true\n+++\n","23":"+++\ntitle =  \"OpenAI's Development Trajectory and the AI Dilemma\"\ndate = 2023-03-26T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion on OpenAI's development trajectory, the potential of AI and its impact on society, and the importance of safety and ethical considerations in AI development. The video also covers the recent blitzscaling of OpenAI and Microsoft in AI advancements, safety concerns and risks associated with exponential growth of LLMs (large language models), and the need for ethical considerations and safety measures in AI development.\"\ntoc = true\n+++\n","24":"+++\ntitle =  \"Exploring AI Applications and Networking\"\ndate = 2023-03-27T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Participants showcase AI projects, discuss ChatGPT-powered bots, AI in art, and automation in coding, while also introducing themselves and addressing miscellaneous topics like text-to-video tools and remote prize eligibility.\"\ntoc = true\n+++\n","25":"+++\ntitle =  \"AI and Deep Learning in eCommerce and Beyond\"\ndate = 2023-03-28T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dr. Parth Sharma leads a discussion on AI and deep learning, exploring its applications in eCommerce, competitor analysis, and image generation. The conversation also touches on the potential for AI-generated romance stories and movies, as well as references to Greek mythology and personal anecdotes.\"\ntoc = true\n+++\n","26":"+++\ntitle =  \"Google and Replit Partnership: Tackling AI Development and Safety\"\ndate = 2023-03-29T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"This discussion covers the Google and Replit partnership to compete with Microsoft's GitHub, the integration of GCP features on Replit, and various topics related to AI development, safety, and ethics. Topics include writing GPT from scratch, AI safety protocols, societal effects of past technologies, and proposals for philosophy rooms and use-case specific groups. The conversation also touches on Azure OpenAI credits, reducing GPT hallucination, OpenAI grant eligibility, and the future of AI experiments.\"\ntoc = true\n+++\n","27":"+++\ntitle =  \"Exploring AI Ethics, Developments, and Communities\"\ndate = 2023-03-30T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An in-depth conversation delving into OpenAI's ethical choices, diverse AI models and tools, personal experiences in AI and ML, AI community events, and other subjects such as scams, government regulation, and hackathon concepts.\"\ntoc = true\n+++\n","28":"+++\ntitle =  \"Exploring Quick Hacks, LLMs, Rephrase.ai, and Data Protection\"\ndate = 2023-03-31T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dive into quick hacks for DeepHack GPT, managing table structures in LLMs, Rephrase.ai's innovative blog-to-video automation, and a discussion on Italian data protection laws.\"\ntoc = true\n+++\n","29":"+++\ntitle =  \"DeepHack Demo Day: Attendees, Live Stream & Submissions\"\ndate = 2023-04-01T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A conversation covering the attendee list, live streaming information, and submission updates for the upcoming DeepHack demo day event.\"\ntoc = true\n+++\n","30":"+++\ntitle =  \"Exploring Lip-Sync Avatar Video Tools: Dreambooth, LoRA, and Textual Inversion\"\ndate = 2023-04-02T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive analysis of alternatives to D-ID and ElevenLabs for lip-synced avatar video creation, including a comparison of features, advantages, disadvantages, and training times for Dreambooth, LoRA, and Textual Inversion.\"\ntoc = true\n+++\n","31":"+++\ntitle =  \"Unraveling the Origins of Creativity and Intelligence\"\ndate = 2023-04-03T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A deep dive into the theory that creativity and human intelligence could be the result of a few algorithms working together with substantial computational power, and the potential existence of a single, all-encompassing algorithm within the neocortex.\"\ntoc = true\n+++\n","32":"+++\ntitle =  \"Exploring Generative AI: Platforms, Research, and Applications\"\ndate = 2023-04-04T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"This discussion delves into generative AI experimentation platforms like OpenPlayground and Playground.ai, highlights AI research and development through the AI Index Report and Langchain, and touches upon creative applications such as a generative AI comic created during a hackathon.\"\ntoc = true\n+++\n","33":"+++\ntitle =  \"AI Discussions and Events\"\ndate = 2023-04-05T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Various topics including OpenAI embeddings, GPT models for financial data, generative AI mixer event, deepfake detection, API for categorizing questions, OpenAI credits, prompt injection in GPT4, and miscellaneous discussions on AI-related events and articles.\"\ntoc = true\n+++\n","34":"+++\ntitle =  \"AI Chat Discussions and Shared Resources\"\ndate = 2023-04-06T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A compilation of discussions on AI chat systems, building AI applications for schools, experimentation, and various AI tools and techniques. The conversation also includes sharing of research, GitHub links, APIs, and resources related to AI development and implementation.\"\ntoc = true\n+++\n","35":"+++\ntitle =  \"Exploring AI: Demos, Applications, and Resources\"\ndate = 2023-04-07T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dive into a diverse range of AI-related topics, featuring demo videos, hackathon projects, AI in art and gaming, WebGPU, agent planning, running models on personal devices, vector stores, and valuable learning resources.\"\ntoc = true\n+++\n","36":"+++\ntitle =  \"Innovative AI Applications in Smart Homes and Game Development\"\ndate = 2023-04-08T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore the integration of chatGPT\/LLMs in smart home devices, delve into Paddlespeech, discuss running generative AI locally, optimize models for Apple RAM, examine serverless Vector DB pricing, anticipate GPT4 syntax and API improvements, consider GPT's role in game development, and engage in a podcast-style fireside chat.\"\ntoc = true\n+++\n","37":"+++\ntitle =  \"Diverse Tech Topics: From AI to Hacker Houses\"\ndate = 2023-04-09T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An engaging conversation exploring a wide range of subjects, including selling a SAAS company, generative AI tools, launching a vector DB business, embedding legal documents, establishing a hacker house in Bangalore, accessing ChatGPT plugins, and other miscellaneous topics such as oral history series and GPT-4 API access.\"\ntoc = true\n+++\n","38":"+++\ntitle =  \"Exploring Hackathon Ideas and Language Model Developments\"\ndate = 2023-04-10T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion delving into innovative hackathon ideas, addressing concerns with GPT 3.5, exploring Kor and Guardrails, discussing GPT4 speculations, examining generative agents, comparing Midjourney and Kandisky 2.1, analyzing image-creation tools, and sharing experiences with LoRA.\"\ntoc = true\n+++\n","39":"+++\ntitle =  \"Generative AI Discussion and Related Topics\"\ndate = 2023-04-11T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A conversation covering a paper on generative agents, Andrej Karpathy's tweet, ChatGPT plugins, OpenAI account access, AI-related companies and people, and various resources including websites, demos, and meetups.\"\ntoc = true\n+++\n","40":"+++\ntitle =  \"Comparing AI Embedding Models and Exploring Applications\"\ndate = 2023-04-12T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An in-depth comparison of OpenAI's 'text-embedding-ada-002' with Huggingface models and Sentence Transformers, discussing their use in news media, chatroom plugins, and conversational memory. The conversation also covers AI regulation, applications in agriculture and finance, and dataset recommendations, with a focus on Langchain and OpenAI resources.\"\ntoc = true\n+++\n","41":"+++\ntitle =  \"Dolly 2.0, Consistency Models, Vector Databases, and Cloud Providers\"\ndate = 2023-04-13T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"In this discussion, participants explore the release of Dolly 2.0, a commercially viable LLM by Databricks, OpenAI's consistency models, and various vector databases. They also delve into the APIs of cloud providers like Azure, AWS, and GCP, as well as the future of LLMs, chip supply, code generation, and the use of FAISS, Annoy, ScaNN, and ANNlite.\"\ntoc = true\n+++\n","42":"+++\ntitle =  \"Exploring AI Technologies and Applications\"\ndate = 2023-04-14T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion on various AI technologies, including LangChain and Tenacity API, neural networks, image inpainting, ChatGPT, Reflect.Ai, Bard, DreamPose, embeddings, AktoGPT, and Stability Diffusion in robotics. The conversation also touches on industry trends, latency issues, and a shared Google Colab link for collaborative learning.\"\ntoc = true\n+++\n","43":"+++\ntitle =  \"Wide-ranging Tech Discussion: React, AI, Open-Source, and More\"\ndate = 2023-04-15T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore a diverse range of topics including React development, controlnet inpainting, Azure Cognitive Search, GPT-5 rumors, LLM output time reduction, bionic reading techniques, open-source project funding, AI in crime detection, and a comparison of AWS CodeWhisperer and GitHub Copilot.\"\ntoc = true\n+++\n","44":"+++\ntitle =  \"Exploring Sci-Fi, AI, and GPT Technologies\"\ndate = 2023-04-16T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An engaging conversation delving into the world of sci-fi literature, AI breakthroughs, LLMs, multimodal systems, community guidelines, GPT-related topics, fine-tuning strategies, deployment, and cost efficiency.\"\ntoc = true\n+++\n","45":"+++\ntitle =  \"AI Integration in Recruitment and Education\"\ndate = 2023-04-17T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Exploring the integration of AI solutions like Langchain, Mendable.ai, Paradox.ai, Skillate, and Leoforce in recruitment and education, addressing issues of bias and ethics, discussing GPT-4's potential performance, and examining the use of LLMs for problem-solving and memory weighing in Langchain.\"\ntoc = true\n+++\n","46":"+++\ntitle =  \"OpenAI Plugin Store and Generative AI Projects\"\ndate = 2023-04-18T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore the OpenAI Plugin Store, prerequisites for different projects, meeting invitations, and resources for multimodal vector similarity search, personal search, generative AI, and more.\"\ntoc = true\n+++\n","47":"+++\ntitle =  \"AI and Data Analysis Techniques in UI Design, Image Editing, and Language Models\"\ndate = 2023-04-19T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A discussion on various AI and data analysis techniques used in UI design, image editing, and language models, including Gradio, Shapiro Wilk test, inpainting models, and Open Assistant. The conversation also touches on non-normal datasets, voice cloning, and AI applications in finance and politics.\"\ntoc = true\n+++\n","48":"+++\ntitle =  \"Generative AI Meet-up and LLM Developments\"\ndate = 2023-04-20T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Join us for a discussion on the latest advancements in Generative AI, including the upcoming meet-up in BLR, Replit's LLM training, Microsoft's LayoutLMv3, MM-REACT, LLM experiment recording tools, Controlnet inpaint model, and other AI-related news and events.\"\ntoc = true\n+++\n","49":"+++\ntitle =  \"Exploring AI Tools, Techniques, and Pinecone\"\ndate = 2023-04-21T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A detailed conversation delving into AI tools like Langchain, WebGPT, and Kubiya.ai, cutting-edge techniques such as stable diffusion for inpainting, and Pinecone's hybrid index. The discussion also encompasses the development of computer engineering interfaces and ideas for managing group chats.\"\ntoc = true\n+++\n","50":"+++\ntitle =  \"Exploring Cloud GPUs, Model Training, and Privacy in Enterprises\"\ndate = 2023-04-22T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion on leveraging cloud GPUs for model training, comparing popular platforms like Google Colab and Kaggle Notebooks, and addressing privacy concerns when implementing chatGPT in enterprise settings. The conversation also includes valuable tips, resources, and tools such as Qblocks.cloud and event decks.\"\ntoc = true\n+++\n","51":"+++\ntitle =  \"Diverse AI Topics: Pitch Decks, Education, Employment, and Applications\"\ndate = 2023-04-23T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An assortment of AI-focused conversations covering topics such as Anthropics pitch deck, RLHF in instruct models, political deepfakes, AI courses and resources, ControlNet Inpaint guidelines, asymmetric vector embeddings, GenAI hiring, tokenization and word embeddings, ControlNet image generation, and open domain Q&A and retrieval algorithms.\"\ntoc = true\n+++\n","52":"+++\ntitle =  \"AI Topics: Embeddings, ChatGPT, Motion Capture & More\"\ndate = 2023-04-24T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore a variety of AI discussions, including OpenAI's dense embeddings, GitHub projects, Supabase, ChatGPT in India, generative AI speakers, motion capture, pose estimation, newline handling in OpenAI Embedding API, and other topics like safetyism and Interoperable Master Format.\"\ntoc = true\n+++\n","53":"+++\ntitle =  \"Exploring AI and GPT-3 Applications\"\ndate = 2023-04-25T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dive into a collection of discussions covering a wide range of AI and GPT-3 related topics, such as Chrome extensions, reinforcement learning, open-source projects, AI in dating, security concerns, vector search, fine-tuning models, GPU hosting, voice cloning, data privacy, and various tools and resources.\"\ntoc = true\n+++\n","54":"+++\ntitle =  \"OpenAI and Generative AI Developments\"\ndate = 2023-04-26T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore OpenAI's data requirements, collaborations, and models, along with music and audio generation, opportunities in generative AI, and resources for GPU access and vector databases.\"\ntoc = true\n+++\n","55":"+++\ntitle =  \"Exploring AI Tools, Techniques, and Trends\"\ndate = 2023-04-27T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion on various AI-related topics, such as Weaviate's vector search, learning LLMs and Transformers, Indic-BloomLM training, serverless GPU options, OpenAI rate limits, State of AI talk, Pinecone's success, and contributing a Spark loader for Hugging Face datasets.\"\ntoc = true\n+++\n","56":"+++\ntitle =  \"Generative AI Meetup and Discussions\"\ndate = 2023-04-28T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An overview of various topics discussed, including the Nvidia-HF event, AI applications, AutoGPT, Namefinder.ai, GPT-4 API Access, FP8, serverless GPUs, Langchain, code summarization, and other relevant news and resources in the AI domain.\"\ntoc = true\n+++\n","57":"+++\ntitle =  \"Exploring AI Models and Applications\"\ndate = 2023-04-29T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Dive into a collection of discussions on diverse AI models and applications, such as VectorDB, LlamaIndex, Langchain, aesthetic score models, DSLR photo generation, transcription APIs, and more. The conversation also touches on miscellaneous subjects like extracting WhatsApp group data, AI avatars, and personalized content.\"\ntoc = true\n+++\n","58":"+++\ntitle =  \"AI in Music, Tools, Projects, and Discussions\"\ndate = 2023-04-30T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Explore the collaboration between GPT and Bark for music creation, AI tools and libraries like pandas-ai, issues with ChatOpenAI, and code snippets for language chain helpers and embeddings utils. Discuss AI models and projects like Cohere's multilingual model, automating tasks, creating charts, and implementing file search. Engage in AI discussions on limited RAM, measuring recall, tuning algorithms, and the impact of generative AI on graphic design and marketing. Discover AI resources like LLM.report, ann-benchmarks, and stable diffusion in graphic design.\"\ntoc = true\n+++\n","59":"+++\ntitle =  \"AI Integration, Web Development, and Group Management\"\ndate = 2023-05-01T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A comprehensive discussion on GPT plugins, web development, AutoGPT, managing a GenAI group, AI philosophy, Warpspeed event, technical issues, and AI-related TED Talks.\"\ntoc = true\n+++\n","60":"+++\ntitle =  \"Exploring ChatGPT, APIs, and Language Models\"\ndate = 2023-05-02T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An in-depth conversation covering a range of topics such as biased articles on Twitter, learning with ChatGPT, API level caps, paywalls, conversational memory, Langchain, rolling windows, summarization techniques, and additional resources.\"\ntoc = true\n+++\n","61":"+++\ntitle =  \"Generative AI Group Chat Highlights\"\ndate = 2023-05-03T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"An overview of key topics covered in a group chat centered on generative AI, featuring discussions on AI models, tools, applications, industry insights, networking opportunities, and miscellaneous subjects such as AI in art and startup ecosystems.\"\ntoc = true\n+++\n","62":"+++\ntitle =  \"Generative AI in Digital Painting and Large Scale Dataset Creation\"\ndate = 2023-05-04T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Members discuss the potential of Generative AI in creating digital painting tools and share experiences in creating large scale datasets for LLM model training.\"\ntoc = true\n+++\n","63":"+++\ntitle =  \"OpenAI, Google Models, and Hugging Face Developments\"\ndate = 2023-05-05T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"Discussing the competitive landscape between OpenAI and Google models, Hugging Face's StarCoder LLM launch, and generative models' probabilistic functions. Also touching on resources available on Amazon's mm-CoT, determinism in GPT, and various AI tools and platforms.\"\ntoc = true\n+++\n","64":"+++\ntitle =  \"Generative AI Group Chat: Resources, Hackathons, and Model Discussions\"\ndate = 2023-05-06T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"A chaotic group chat discussing various topics related to generative AI, including learning resources, hackathons, deterministic output, visual aesthetic scoring, dataset creation, finance GPT, and autonomous agents.\"\ntoc = true\n+++\n","65":"+++\ntitle =  \"Exploring AI Applications, Ethics, and OpenAI's Closed Source Approach\"\ndate = 2023-05-07T00:00:00+05:30\ntags = [\"daily_summary\"]\nfeatured_image = \"\"\ndescription = \"This discussion delves into OpenAI's choice to adopt a closed source strategy, the competitive factors influencing this decision, and the implications for AI-generated art, music, and text. Additionally, the conversation touches on ethical considerations and the role of AI in healthcare and finance.\"\ntoc = true\n+++\n"}}