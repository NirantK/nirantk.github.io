Sender|Datetime|Message
The GenerativeAI Group|2023-03-01 14:09:55|‎Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them.
The GenerativeAI Group|2023-03-01 14:09:55|‎You created group “GenerativeAI/DeepMedia”
The GenerativeAI Group|2023-03-01 14:09:55|‎‎‎Disappearing messages were turned on. ‎New messages will disappear from this chat ‎90 days after they're sent, except when kept. ‎Tap to change.
Kaushik Bokka|2023-03-01 14:11:29|‎Kaushik Bokka joined using this group's invite link
Ravi Theja|2023-03-01 14:11:31|‎Ravi Theja joined using this group's invite link
Amogh V|2023-03-01 14:11:55|‎Amogh V joined using this group's invite link
Yash Pandya|2023-03-01 14:12:09|‎Yash Pandya joined using this group's invite link
Abhishek Maiti|2023-03-01 14:12:30|‎Abhishek Maiti joined using this group's invite link
Ayush Deva|2023-03-01 14:18:08|‎Ayush Deva joined using this group's invite link
Soumya Shah Acton Garv's Bae|2023-03-01 14:18:30|‎Soumya Shah Acton Garv's Bae joined using this group's invite link
Pranav Peppertype. ai|2023-03-01 14:18:57|‎Pranav Peppertype. ai joined using this group's invite link
Soumyadeep Mukherjee|2023-03-01 14:20:41|‎Soumyadeep Mukherjee joined using this group's invite link
Devanshu Tak 2015B3A4|2023-03-01 14:21:02|‎Devanshu Tak 2015B3A4 joined using this group's invite link
Preet Singh Khalsa 2015 BPCC Cred Accel|2023-03-01 14:21:39|‎Preet Singh Khalsa 2015 BPCC Cred Accel joined using this group's invite link
Sachin Legaltech|2023-03-01 14:21:41|‎Sachin Legaltech joined using this group's invite link
Karthik CRED|2023-03-01 14:22:58|‎Karthik CRED joined using this group's invite link
Vedant Trivedi Sequoia|2023-03-01 14:25:55|‎Vedant Trivedi Sequoia joined using this group's invite link
~ Uneet|2023-03-01 14:27:33|‎~ Uneet joined using this group's invite link
Karan Ganesan luma.ai|2023-03-01 14:28:12|‎Karan Ganesan luma.ai joined using this group's invite link
Kush Gupta 2014|2023-03-01 14:30:28|‎Kush Gupta 2014 joined using this group's invite link
Kiran Raj S. R|2023-03-01 14:31:20|‎Kiran Raj S. R joined using this group's invite link
Ketan Twitter Intro|2023-03-01 14:32:06|‎Ketan Twitter Intro joined using this group's invite link
Amir Nagri|2023-03-01 14:33:46|‎Amir Nagri joined using this group's invite link
Rahul Bhatnagar|2023-03-01 14:35:06|‎Rahul Bhatnagar joined using this group's invite link
Akarsh Rastogi 2015B5A4|2023-03-01 14:39:06|‎Akarsh Rastogi 2015B5A4 joined using this group's invite link
Saurabh Kumar 2012|2023-03-01 14:40:37|‎Saurabh Kumar 2012 joined using this group's invite link
Manas Jain Wadhwani AI|2023-03-01 14:44:45|‎Manas Jain Wadhwani AI joined using this group's invite link
Harsh V Sharma|2023-03-01 14:48:29|‎Harsh V Sharma joined using this group's invite link
Shubham Sharma 2012C6|2023-03-01 14:51:54|‎Shubham Sharma 2012C6 joined using this group's invite link
Lucky Murari|2023-03-01 14:59:34|‎Lucky Murari joined using this group's invite link
Anurag Singh Amul Twitter Friend|2023-03-01 15:00:05|‎Anurag Singh Amul Twitter Friend joined using this group's invite link
Satyajeet Kanetkar|2023-03-01 15:02:31|‎Satyajeet Kanetkar joined using this group's invite link
Rajeev Singh Naruka|2023-03-01 15:03:45|‎Rajeev Singh Naruka joined using this group's invite link
Bargava|2023-03-01 15:06:35|‎Bargava joined using this group's invite link
Vishal Tripathi NSS 2013|2023-03-01 15:16:23|‎Vishal Tripathi NSS 2013 joined using this group's invite link
Ritesh Invideo Nilenso|2023-03-01 15:24:14|‎Ritesh Invideo Nilenso joined using this group's invite link
~ Praachi Goenka|2023-03-01 15:24:45|‎~ Praachi Goenka joined using this group's invite link
Preet Singh Khalsa 2015 BPCC Cred Accel|2023-03-01 15:25:03|‎Preet Singh Khalsa 2015 BPCC Cred Accel left
~ Tanay|2023-03-01 15:25:10|‎~ Tanay joined using this group's invite link
Jidin Dinesh|2023-03-01 15:26:47|‎Jidin Dinesh joined using this group's invite link
‪+91 98204 09045‬|2023-03-01 15:27:17|‎‪+91 98204 09045‬ joined using this group's invite link
Garv Malik 2012H|2023-03-01 15:31:35|‎Garv Malik 2012H joined using this group's invite link
Vivek Sahil Sorathiya's Friend|2023-03-01 15:41:59|‎Vivek Sahil Sorathiya's Friend joined using this group's invite link
Vandit Gandotra 2014|2023-03-01 15:42:25|‎Vandit Gandotra 2014 joined using this group's invite link
‪+91 76077 14483‬|2023-03-01 15:43:47|‎‪+91 76077 14483‬ joined using this group's invite link
Abhishek Jatram Samsung|2023-03-01 15:44:14|‎Abhishek Jatram Samsung joined using this group's invite link
Soumendra Dhanee|2023-03-01 15:44:33|‎Soumendra Dhanee joined using this group's invite link
Anagh Prasad|2023-03-01 15:46:06|‎Anagh Prasad joined using this group's invite link
‪+91 98882 38811‬|2023-03-01 15:46:37|‎‪+91 98882 38811‬ joined using this group's invite link
Harsh Gupta Felvin|2023-03-01 15:48:13|‎Harsh Gupta Felvin joined using this group's invite link
Kartikeya Bharadwaj|2023-03-01 16:00:37|‎Kartikeya Bharadwaj joined using this group's invite link
~ Karan Sirdesai|2023-03-01 16:00:45|‎~ Karan Sirdesai joined using this group's invite link
Shashwat TDC|2023-03-01 16:07:11|‎Shashwat TDC joined using this group's invite link
~ Aman Rai|2023-03-01 16:12:45|‎~ Aman Rai joined using this group's invite link
Jay Pokarna 2014 BPCC|2023-03-01 16:31:40|‎Jay Pokarna 2014 BPCC joined using this group's invite link
‪+91 97172 74996‬|2023-03-01 16:39:52|‎‪+91 97172 74996‬ joined using this group's invite link
Dhawal Jain Generative AI Group|2023-03-01 16:42:20|‎Dhawal Jain Generative AI Group joined using this group's invite link
~ Tanay|2023-03-01 16:44:12|‎~ Tanay left
Gaurav Arora|2023-03-01 17:06:38|‎Gaurav Arora joined using this group's invite link
Amit Tiwary|2023-03-01 17:11:30|‎Amit Tiwary joined using this group's invite link
Vinayak 2016AB|2023-03-01 17:28:02|‎Vinayak 2016AB joined using this group's invite link
Naman Jain Stellaris|2023-03-01 17:53:20|‎Naman Jain Stellaris joined using this group's invite link
"Arpan Desai | MobileFirst"|2023-03-01 17:57:49|"‎Arpan Desai | MobileFirst joined using this group's invite link"
Khyati Jain Sundial|2023-03-01 18:00:39|‎Khyati Jain Sundial joined using this group's invite link
Rahul Sundar 2013|2023-03-01 18:18:40|‎Rahul Sundar 2013 joined using this group's invite link
Siddharth Agarwal|2023-03-01 18:30:23|‎Siddharth Agarwal joined using this group's invite link
Rishi Bhalodia|2023-03-01 18:34:41|‎Rishi Bhalodia joined using this group's invite link
~ Akul Jindal|2023-03-01 19:04:37|‎~ Akul Jindal joined using this group's invite link
Parth Chhaparwal|2023-03-01 19:05:09|‎Parth Chhaparwal joined using this group's invite link
~ NG|2023-03-01 19:49:21|‎~ NG joined using this group's invite link
Navneet Jha 2012A8|2023-03-01 19:57:32|‎Navneet Jha 2012A8 joined using this group's invite link
~ Arko Cy|2023-03-01 19:57:36|‎~ Arko Cy joined using this group's invite link
~ Ishan|2023-03-01 20:00:56|‎~ Ishan joined using this group's invite link
Chirag Jain|2023-03-01 20:09:26|‎Chirag Jain joined using this group's invite link
Sathvik Napa|2023-03-01 21:12:57|‎Sathvik Napa joined using this group's invite link
Yash Bonde|2023-03-01 21:41:35|‎Yash Bonde joined using this group's invite link
~ Vin|2023-03-01 21:44:50|‎~ Vin joined using this group's invite link
Heer Shingala|2023-03-01 22:38:33|‎Heer Shingala joined using this group's invite link
Hasan Tech Art Guy|2023-03-01 22:43:40|‎Hasan Tech Art Guy joined using this group's invite link
Sharwon Pius|2023-03-01 23:09:28|‎Sharwon Pius joined using this group's invite link
Smit Shah|2023-03-02 00:35:10|‎Smit Shah joined using this group's invite link
Shivendu Kumar|2023-03-02 00:36:30|‎Shivendu Kumar joined using this group's invite link
Karan Ganesan luma.ai|2023-03-02 00:47:05|‎‎Karan Ganesan luma.ai turned off disappearing messages. ‎Tap to change.
Dalan Mendoca|2023-03-02 03:46:39|‎Dalan Mendoca joined using this group's invite link
Nirant|2023-03-02 07:21:36|"ChatGPT API Launch tl;dr:   1. 10x Cheaper 2. Quite a bit faster than the existing davinci-003 series 3. [PHONE] from Hasura + my clients see improvement in quality across QA, Summarisation, Parsing tasks — e.g. ability to say, I don't know, includes specific questions in summary 4. Has a new Chat Markup Language, introduces the concept of _system prompt_. Let's give you give persona like, ""You're a cute doggo"" to ""You're a helpful AI who is good at answering questions"" 5. Whisper has a 25Mb speech to text limit, which is gonna be a pain to use for now, has prompting for error correction here too!"
Pratyush Sinha|2023-03-02 08:40:38|‎Pratyush Sinha joined using this group's invite link
Dhruv Naik|2023-03-02 08:41:29|‎Dhruv Naik joined using this group's invite link
Anirudh Singla Pepper|2023-03-02 08:41:31|‎Anirudh Singla Pepper joined using this group's invite link
Aditya Ankur|2023-03-02 08:54:47|‎Aditya Ankur joined using this group's invite link
~ Rohan|2023-03-02 08:59:53|‎~ Rohan joined using this group's invite link
Yash Sinha 2012C6|2023-03-02 09:07:31|‎Yash Sinha 2012C6 joined using this group's invite link
Ananth Radhakrishnan 2012A7|2023-03-02 09:29:16|‎Ananth Radhakrishnan 2012A7 joined using this group's invite link
Mounik Soroco|2023-03-02 09:30:28|‎Mounik Soroco joined using this group's invite link
Ganesh RoomStayin|2023-03-02 09:38:49|‎Ganesh RoomStayin joined using this group's invite link
Nipun Sadvilkar|2023-03-02 09:42:28|‎Nipun Sadvilkar joined using this group's invite link
Madiha Shumayim|2023-03-02 10:38:52|‎Madiha Shumayim joined using this group's invite link
~ Vinod B|2023-03-02 10:58:54|‎~ Vinod B joined using this group's invite link
Aditya Khsirsagar|2023-03-02 11:03:29|‎Aditya Khsirsagar joined using this group's invite link
Taranjeet Singh Cookup.ai|2023-03-02 12:07:48|‎Taranjeet Singh Cookup.ai joined using this group's invite link
Gaurav Mandlecha 2014B3A4|2023-03-02 12:25:26|‎Gaurav Mandlecha 2014B3A4 joined using this group's invite link
Amir Nagri|2023-03-02 12:32:16|in case someone missed it  https://twitter.com/karenxcheng/status/1627721862565482496?t=cHnO8JUIPlmrjdmTTN9PJQ&s=08  runwayml (from the inventors of stable diffusion models)
Amir Nagri|2023-03-02 12:33:54|https://twitter.com/c_valenzuelab/status/1630969280803250176?t=Timm5pV-ymLQM02QPZM-sg&s=08
Gokul Krishnan|2023-03-02 12:36:30|‎Gokul Krishnan joined using this group's invite link ‎[3/2/23, 12:38:27] Amogh V: ‎image omitted
Amogh V|2023-03-02 12:38:40|Ok I finally got controlnet working in a way that makes me happy!
Yash Sundial Design|2023-03-02 12:43:31|‎Yash Sundial Design joined using this group's invite link
Abhilash|2023-03-02 12:58:49|‎Abhilash joined using this group's invite link
Ramya Swag Shree|2023-03-02 13:23:08|‎Ramya Swag Shree joined using this group's invite link
Ramya Swag Shree|2023-03-02 13:23:39|‎Ramya Swag Shree left
Achal Mall|2023-03-02 13:23:43|‎Achal Mall joined using this group's invite link
~ Prashanth|2023-03-02 14:10:13|‎~ Prashanth joined using this group's invite link
Pranav Peppertype. ai|2023-03-02 14:11:04|Anyone here who’s deployed gpt-3.5-turbo on any of their production apps? How are the latencies after some certain scale? Is the API timing out or throwing errors?
Nirant|2023-03-02 14:11:42|Na, mostly stable so far. Needs some retries but works with exponential backoff
Zainab Bawa|2023-03-02 22:57:53|‎Zainab Bawa joined using this group's invite link
Nirant|2023-03-02 23:14:45|Corridor Digital reveals how they made Anime using SD VFX and Blender (scenes) https://www.youtube.com/watch?v=ljBSmQdL_Ow
Karan Ganesan luma.ai|2023-03-02 23:56:59|https://twitter.com/stabilityai/status/1631339515792039968
~ Aman|2023-03-03 00:07:43|‎~ Aman joined using this group's invite link
Nirant|2023-03-03 01:22:09|The new Flan-UL2 20B from GoogleAI is out!   So what? 1. Industries which want to run models on-premise e.g. healthcare, banking — now have a very good alternative to GPT3 for most things 2. Can be customised to tasks which are domain, company or even department (sales) or role (SDR) specific — I expect Huggingface will update their finetuning scripts within next 4 weeks!  Has a 2048 token window, up from 512 tokens, already instruction fine-tuned (not RLHF) — makes it easier/more predictable, more than Chat API perhaps! https://twitter.com/YiTayML/status/1631359468675166208
Nirant|2023-03-03 01:23:17|PS: As a dev I like to use fancy terms, ask questions — fun to answer them :)
Gokul Krishnan|2023-03-03 03:58:20|What's the compute required to have a good / useful throughput
Gokul Krishnan|2023-03-03 03:59:07|If it's gonna be costing similar in cloud instance cost, you might as well go with chatgpt API?
Nirant|2023-03-03 08:27:13|Was thinking more data localisation and compliance needs, not cost
Sachin Legaltech|2023-03-03 12:15:01|+ control…If you need to train specialized models, can’t yet do it with chatGPT. Also once LLMs start to call APIs which access sensitive data, we might need different, transparent and configurable/ finetunable base models.
Arjun Gandhi NexusVP|2023-03-03 13:40:26|‎Arjun Gandhi NexusVP joined using this group's invite link
Aniket Kamath Nexus IIT B|2023-03-03 13:40:29|‎Aniket Kamath Nexus IIT B joined using this group's invite link
Gokul Krishnan|2023-03-03 14:04:02|Same applies if it's on cloud instead of on prem, no?
Pranjal Mehta|2023-03-03 14:22:44|Two interesting a16z articles
Pranjal Mehta|2023-03-03 14:22:48|https://a16z.com/2023/01/19/who-owns-the-generative-ai-platform/
Pranjal Mehta|2023-03-03 14:22:52|https://a16z.com/2023/02/07/everyday-ai-consumer/
Amogh V|2023-03-03 14:26:51|I wrote a deeper dive into what successful AI products would look like at https://www.amoghvaishampayan.com/post/generative-ai-product-strategy
Amogh V|2023-03-03 14:29:46|I've worked as an AI product manager for the last 5 years. The essence of my generative AI article cold be summarized as -   Vertical AI products are for a specific niche, such as generating fabric prints for the fashion industry or furniture design. Here the moat is not the AI model, but rather the software tooling you build around the model for that industry's problems and workflows. When a new and better model inevitably comes around, your customers will stick with you because you have saved them time and money in their specific workflow. This buys you time to update your model and solves the retention problem mentioned in a16z article.  Horizontal products are for fields such as graphic design that are needed across industries from automobiles to food. Here a state of the art model is certainly helpful but it cannot be the only moat. Supporting moats must be built around whatever gives the user output that is good, fast AND cheap. This is absolutely critical because human designers can offer only 2/3.
~ Anurag|2023-03-03 14:41:50|‎~ Anurag joined using this group's invite link
Kaushik Bokka|2023-03-03 14:42:36|https://www.reforge.com/blog/ai-products-arms-race  I liked this blog as well
Siddharth Agarwal|2023-03-03 14:59:35|https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full.pdf Not sure what, if anything, I can say about this.
Nirant|2023-03-03 15:01:38|This is the fMRI → SD from Japanese folks, right? It's quite radical, and well — brain shattering ;)
Siddharth Agarwal|2023-03-03 15:02:02|Oh yeah, the on from Osaka. :D
~ Anurag|2023-03-03 15:06:45|It took me a couple of mins to realise that prompt for these images was imagination 🤯
Pranjal Mehta|2023-03-03 15:07:57|This is genius
Siddharth Agarwal|2023-03-03 15:10:05|Yep...
Anagh Prasad|2023-03-03 15:10:22|🤩
Nirant|2023-03-03 15:11:23|Increasing the noise in my brain by watching non Hindi and non English media only from now on! Will also learn a new language, but only the hi, hello part every month.
Soumyadeep Mukherjee|2023-03-03 15:11:49|Ummm have they released some code?
Soumyadeep Mukherjee|2023-03-03 15:12:18|I am very skeptical on this. Data from brain to be used for useful things is still in very very early research.
Nirant|2023-03-03 15:12:27|Nahi, it's not peer reviewed. Just submitted to some conf I think.
Soumyadeep Mukherjee|2023-03-03 15:12:32|Like up/down itself has 70% accuracy
Soumyadeep Mukherjee|2023-03-03 15:12:42|State of the art devices with some 200 probes ke sath this is the case
Soumyadeep Mukherjee|2023-03-03 15:12:55|Off the shelf devices like the one that came in shark tank are bleh
Nirant|2023-03-03 15:12:58|You're bringing facts to an emo excited conversation. Why you be like this?
Soumyadeep Mukherjee|2023-03-03 15:13:12|Coz I have spent a lot of money and time on this 😂
Soumyadeep Mukherjee|2023-03-03 15:13:23|My rant is my emo :P
~ NG|2023-03-03 15:13:28|Please elaborate further
~ Anurag|2023-03-03 15:13:51|😂😂😂  My biggest fear is the system will be like wtf are you thinking
Soumyadeep Mukherjee|2023-03-03 15:13:55|I have bought some 4 such devices over 4 years
Soumyadeep Mukherjee|2023-03-03 15:14:01|Each costing 25k to 1L :P
Soumyadeep Mukherjee|2023-03-03 15:14:11|And I was a subject in one such experiment too
Soumyadeep Mukherjee|2023-03-03 15:14:27|And the data is so noisy and hard to use.
Soumyadeep Mukherjee|2023-03-03 15:14:42|Like the ones used in hospitals was benchmark for off the shel devices
Soumyadeep Mukherjee|2023-03-03 15:14:49|those have 200 probes, you have to be bald
Soumyadeep Mukherjee|2023-03-03 15:14:56|and then also it is noisy.
Soumyadeep Mukherjee|2023-03-03 15:15:08|It works on voltage of neurons. So probes need to be very ver sensitive
Soumyadeep Mukherjee|2023-03-03 15:15:13|Which is a hard hardware problem
Siddharth Agarwal|2023-03-03 15:16:29|They are using fMRI data which has a much stronger signal profile. I participated in a couple of frontal lobe activation expts here, and the data was apparently clean enough to run some pretty interesting analyses.
~ NG|2023-03-03 15:18:05|Can't we get such data without having a hardware device ?
Siddharth Agarwal|2023-03-03 15:18:34|That's a near-certain no.
Nirant|2023-03-03 15:19:39|What does clean enough and analyses mean here? If it's alright with you, share a couple of examples?
Siddharth Agarwal|2023-03-03 15:20:03|I will try and find the paper.
‪+91 96194 01031‬|2023-03-03 15:21:25|‎‪+91 96194 01031‬ joined using this group's invite link
Akarsh Rastogi 2015B5A4|2023-03-03 15:24:57|Non-invasive devices are already pretty noisy compared to brain probes. Without hardware matlab kya?
Siddharth Agarwal|2023-03-03 15:25:27|In the meanwhile, the expt was as follows: two sessions of 45 min- 1hr wherein a volunteer (me and 10 others) will lie in an fMRI machine, and solve some logic and language puzzles (they will be projected on a screen and I have to verbalize my answer). They showed me the processed data stream sometime later, and explained that they were going to try and localize activations and their strengths to understand which subsection of the frontal lobe is responsible for the thought. After that, they had planned to run some time-series analyses to see how the activation shifts as the answer is obtained and verbalised (not sure if they ever published this one).
Nirant|2023-03-03 17:06:41|"Folks, what are the best videos/resources on using SD for designers (product, UX) and artists?   Putting together a ""you should check this out"" list for my designer friends who're not in the game yet!"
Nirant|2023-03-03 17:07:01|(Yes, I've already included the anime which plays rock, paper)
Amogh V|2023-03-03 17:15:00|Automatic1111 is the easiest way to use SD and all of its plugins but requires a GPU to run on local. Plus the setup can be a bit technical. If no GPU then it has to run on Colab which is also technical. But if yes GPU then this channel has some great videos starting with this one - https://youtu.be/AZg6vzWHOTA  But the simplest way would be on playgroundai.com IMO. Just login and start using. Although limited functionality
~ Aman|2023-03-03 17:28:28|Imagine getting actual footage of your dreams 🤯
Nirant|2023-03-03 17:40:40|YC Founder talks to YC Partner: https://youtu.be/hQC5O3WTmuo ‎[3/3/23, 18:04:00] Akarsh Rastogi 2015B5A4: ‎image omitted
The GenerativeAI Group|2023-03-03 23:41:46|‎You changed the settings so only admins can edit the group settings
Pranjal Mehta|2023-03-04 09:26:02|https://theresanaiforthat.com/
Smit Shah|2023-03-04 11:29:22|We open-sourced our Hasura AI bot code; and made it easy to deploy with one click. Read about it here, https://twitter.com/SmitShah_11/status/1631743183196676096  You can also read about comparing the new ChatGPT API vs. text-davinci-003.  Finally, we will host a webinar on 14th March on how to build your own AI bot on your docs using an asynchronous, performant, scalable architecture.
Nirant|2023-03-04 15:49:59|Offset Noise is heating up AI Art https://www.youtube.com/watch?v=YjkI5j7ZfY0
Anagh Prasad|2023-03-04 16:35:29|https://twitter.com/MetaAI/status/1631351811696394240?s=20 ‎[3/4/23, 16:51:20] Amir Nagri: ‎image omitted
Achal Mall|2023-03-04 16:54:48|Can you post the original tweet link
~ Anurag|2023-03-04 16:55:35|He is also running purchase parity which I feel most products miss
~ Abhiroop Prasad|2023-03-04 17:22:41|‎You added ~ Abhiroop Prasad
Amogh V|2023-03-04 21:23:02|An AI themed movie that someone will make soon enough. Think Her, but with a couple and a twist! https://twitter.com/amogh42/status/1632045787395002371?s=20
Anirudth N|2023-03-05 23:08:56|‎Anirudth N joined using this group's invite link
Anirudth N|2023-03-05 23:13:08|Hi everyone, I'm Anirudth, currently an Applied Scientist at Amazon. Invited by [PHONE] to this group. I'm excited about generative AI and looking to unlock new opportunities.
Anagh Prasad|2023-03-06 00:59:23|https://www.marktechpost.com/2023/02/28/oxford-university-researchers-introduce-a-diffusion-model-called-realfusion-that-can-generate-360-degree-reconstructions-of-objects-from-an-image/?amp
Anagh Prasad|2023-03-06 00:59:37|Breakthrough for nerf
Madiha Shumayim|2023-03-06 07:56:38|‎Madiha Shumayim left
Nirant|2023-03-06 08:41:34|cc [PHONE] Devanshu Tak is a 3D artist who has used NeRF earlier in his work
Anagh Prasad|2023-03-06 14:44:37|Interesting read: https://unsupervisedlearning.substack.com/p/using-large-language-models-effectively. Esp the #4 point around embeddings
~ Aman|2023-03-06 15:57:01|really interesting points. [PHONE] you guys used pinecone and langchain in the hasura bot for the embedding purpose only, right?
Smit Shah|2023-03-06 15:59:11|Embedding and prompt templating
Smit Shah|2023-03-06 15:59:17|But embedding was the biggest reason
~ Aman|2023-03-06 16:00:40|Any specific reason for not using the openai's embedding endpoint other than cost and latency?
Smit Shah|2023-03-06 16:00:54|It uses openAI embedding
Smit Shah|2023-03-06 16:01:02|Pinecone is used as vector store
~ Aman|2023-03-06 16:01:06|oh ok
Anagh Prasad|2023-03-06 16:01:11|Yeah that's what I would assume
Smit Shah|2023-03-06 16:01:15|Langchain gives a good abstraction
~ Aman|2023-03-06 16:02:09|Cool cool, haven't used it yet. I thought it might be some kind of local store creator (if that makes sense 😅)
Nirant|2023-03-06 16:16:15|Chroma bundles store and the embedding call into one from what I can tell. I'll try that out this week
Shubhi Saxena|2023-03-06 18:52:03|‎Shubhi Saxena joined using this group's invite link
~ Manoj|2023-03-07 16:52:39|‎~ Manoj joined using this group's invite link
Rohit GenerativeAI WhatsApp Group|2023-03-07 16:55:39|‎Rohit GenerativeAI WhatsApp Group joined using this group's invite link
Rounak Datta Hackathon Winner|2023-03-07 16:58:08|‎Rounak Datta Hackathon Winner joined using this group's invite link
~ A Ram Bharadwaj|2023-03-07 17:15:50|‎~ A Ram Bharadwaj joined using this group's invite link
Ishan Sharma|2023-03-07 23:09:18|‎Ishan Sharma joined using this group's invite link
Nirant|2023-03-08 10:37:42|Doing a GenerativeAI Hackathon!   Remote submissions welcome, BLR folks can register here for Venue invite: https://chat.whatsapp.com/LmrYuiASKaqB8E5V34tmlR
Ansh 2017A3|2023-03-08 11:12:02|‎Ansh 2017A3 joined using this group's invite link
The GenerativeAI Group|2023-03-08 11:12:06|‎You added this group and its participants to the community “Generative AI”
The GenerativeAI Group|2023-03-08 11:12:06|‎Anyone in the community “Generative AI” can request to join this group by messaging group admins.
~ Mahalakshmi C|2023-03-08 12:37:49|‎~ Mahalakshmi C joined using this group's invite link
Anshul Bhide Replit|2023-03-08 14:38:44|‎Anshul Bhide Replit joined using this group's invite link
Pranjal Yadav Razorpay|2023-03-08 14:49:28|‎Pranjal Yadav Razorpay joined using this group's invite link
Karishnu Poddar Yellow.ai|2023-03-08 15:17:24|‎Karishnu Poddar Yellow.ai joined using this group's invite link
Rahul Sundar 2013|2023-03-08 17:56:52|What kind of problem statements are welcome?
Nirant|2023-03-08 17:57:56|Anything that uses Generative AI e.g. ChatGPT, Midjourney is welcome. No other constraint on the problem statement. Make April Fool Apps for all I care
Rahul Sundar 2013|2023-03-08 17:58:36|Cool
Rounak Datta Hackathon Winner|2023-03-08 18:11:05|Has everyone already got a team? 😄 Could there be a team/area-of-interest showcase that we can browse?
Rahul Sundar 2013|2023-03-08 18:12:04|Anyone here interested in Normalizing flows?
Siddharth Agarwal|2023-03-08 18:32:07|I have been, for a while.
~ Arko Cy|2023-03-08 18:33:03|+1
Rahul Sundar 2013|2023-03-08 18:48:41|Industrial use cases or out if academic interest?
Rahul Sundar 2013|2023-03-08 18:48:45|*of
Zainab Bawa|2023-03-08 18:52:31|Wrong window.
Siddharth Agarwal|2023-03-08 18:53:03|Interesting resource: https://github.com/janosh/awesome-normalizing-flows
Anurag Singh Amul Twitter Friend|2023-03-08 21:41:50|https://research.runwayml.com/gen1
Anagh Prasad|2023-03-09 15:24:31|Hi all, wanted to run by an opportunity with you. It's a large content + consumer brands company that I am closely working with, they reach about 40% of all social media users in India.   They have a tonne of cross platform data and have done the plumbing piece sorted, now looking to aquihire or hire a team to create the recommendation engine on their platforms.
Anagh Prasad|2023-03-09 15:24:56|Is this something that you/any friend you know be interested in exploring? You can DM if yes
Pranjal Mehta|2023-03-10 08:13:40|https://zenil.substack.com/p/indian-generative-ai-landscape-the?r=1f3ivv&utm_campaign=post&utm_medium=web
Yash Pandya|2023-03-10 08:19:30|https://www.reddit.com/r/singularity/comments/11mztcu/gpt4_is_coming_next_week_and_it_will_be/
Dhruv Anand|2023-03-10 13:28:31|‎You added Dhruv Anand
Harsh Koo|2023-03-10 16:09:00|‎Harsh Koo joined using this group's invite link
Harsh Koo|2023-03-10 16:11:50|Thanks [PHONE] for adding me here.   Hi folks - I'm Harsh Singhal and I lead AI/ML at Koo.  I'm super excited about the current wave catalyzed by Open AI and i see this as the start of the Internet. Albeit a very different proliferation of productivity.  Hope to have learning conversations here.  Harsh https://www.linkedin.com/in/harshsinghal
‪+91 95290 47929‬|2023-03-10 18:53:02|‎‪+91 95290 47929‬ joined using this group's invite link
Satish DeepHack Sponsor|2023-03-10 20:48:04|‎Satish DeepHack Sponsor joined using this group's invite link
‪+91 80783 86131‬|2023-03-10 21:20:41|‎‪+91 80783 86131‬ joined using this group's invite link
~ Nirmal|2023-03-10 22:59:46|‎~ Nirmal joined using this group's invite link
Pranjal Joshi US FINTECH|2023-03-10 23:02:01|‎Pranjal Joshi US FINTECH joined using this group's invite link
~ TheLoneSamurai|2023-03-11 00:20:08|‎~ TheLoneSamurai joined using this group's invite link
~ Khauneesh|2023-03-11 01:06:23|‎~ Khauneesh joined using this group's invite link
~ Arsalaan|2023-03-11 12:56:04|‎~ Arsalaan joined using this group's invite link
Harsh Sharma SRM 2023|2023-03-11 16:24:14|‎Harsh Sharma SRM 2023 joined using this group's invite link
~ Abhinav|2023-03-11 18:42:22|‎~ Abhinav joined using this group's invite link
Nirant|2023-03-12 16:32:26|Interested in finding what GPT hype is about? Opening the post-hackathon demos for everyone in Bengaluru — technical or not!  *Very* limited slots unfortunately First come, first serve!  Forward to office Slack & college WhatsApp groups now!  https://partiful.com/e/sxaGTl08k6NwUfDeazoe
Amir Nagri|2023-03-12 16:39:51|Is this different from the Google form i filled for hackathon?
Nirant|2023-03-12 16:40:42|Yes, that is participants only. For people hacking on that day. This is for everyone interested in just seeing what was built during the hackathon!
Amir Nagri|2023-03-12 16:41:00|So participants don't need to fill then, right?
Nirant|2023-03-12 16:41:02|Register here for a hackathon invite to the BLR venue: https://forms.gle/UizUwyKi4bajt6WB7
Nirant|2023-03-12 16:41:09|No
Soumyadeep Mukherjee|2023-03-12 19:00:13|Why does wording say only GPT?
Rahul Bhatnagar|2023-03-12 19:02:23|Haan Nirant. [PHONE], is going to dazzle with stable diffusion. :)
Soumyadeep Mukherjee|2023-03-12 19:02:44|Exactly :P  Also, I need to save face when I forward. 😂
Nirant|2023-03-12 19:10:34|Would help you save face a lot more if at least someone from your company signed up to participate, that number is 🥚 right now
Soumyadeep Mukherjee|2023-03-12 19:19:47|Registrations shall come :P
Rasagy Sharma|2023-03-12 19:31:57|‎You added Rasagy Sharma
Shubham Sharma 2012C6|2023-03-12 19:39:18|https://www.youtube.com/watch?v=VdMgPgicvK4
Shubham Sharma 2012C6|2023-03-12 19:39:38|Anyone with access to Runwayml?
~ Shalvin|2023-03-12 21:33:26|‎~ Shalvin joined using this group's invite link
Amal David Futuryze|2023-03-13 16:27:47|‎Amal David Futuryze joined using this group's invite link
Anagh Prasad|2023-03-13 22:36:50|Hey, are there any LLMs by open AI that can be deployed on prem today?
Nirant|2023-03-13 22:37:25|OpenAI has Foundry at $1M/yr which will have onprem Flan-T5 XXL by Google
Nirant|2023-03-13 22:37:36|*FLan-T5 is FOSS and by Google
Anagh Prasad|2023-03-13 22:39:22|Thanks Nirant for the quick help!
~ Anubhav Jain|2023-03-14 11:31:34|‎~ Anubhav Jain joined using this group's invite link
~ Anubhav Jain|2023-03-14 11:35:40|Hello folks,  I started working on project idea, the first prototype is ready. I want to add more features to it.  My question is, Can a project that has been started before but worked upon during the hackathon eligible?
Pranjal Joshi US FINTECH|2023-03-14 11:36:23|same question!
Nirant|2023-03-14 11:42:06|Yes, most definitely!   I'd recommend mentioning what you add during the hackathon vs what was there already — this is mainly to prevent startups using this as a pitching venue :)
Heer Shingala|2023-03-14 11:46:52|Hi folks, any non-techies here? This space is too technical for me right now, but I want to make a conscious effort to keep up with what's happening. Will appreciate any help!
Nirant|2023-03-14 11:52:47|[PHONE] [PHONE] [PHONE] are PMs, [PHONE] [PHONE] are founder and VC respectively, [PHONE] is Mumbai based creative agency person,   Happy to intro to them, DM with what you're curious about most or questions
Heer Shingala|2023-03-14 11:53:07|Thanks Nirant! 🌻 I'll bug 'em.
~ A Ram Bharadwaj|2023-03-14 11:55:11|What's the prize money split?
Nirant|2023-03-14 11:56:54|1L minimum per track — no runners up, remote submissions welcome, split between all members of the winning team equally   These are the tracks: 1. Best Prompt Engineering Demo (e.g. LLM apps, browser extensions) 2. Best Storytelling Demo (e.g. video, generated art, music, comics) -- I’d love to have designers and artists win this track 3. Best AI Devtool Demo (e.g. CLIs, VSCode extensions) 4. Best AI Infra Demo (e.g. new cloud services, training tools, libraries) - Co-sponsored by Springworks.in 5. People’s Choice for best overall Open Source project
Amir Nagri|2023-03-14 12:32:13|Details of evaluation criteria will be helpful, best if it is quantitative and transparent
Nirant|2023-03-14 12:36:55|This is left to jury's discretion. I'm not aware of it either, nor will I be till the day of hackathon. The jury may choose to share it, after the demos or make it quantitative.
Nirant|2023-03-14 12:37:15|Personally not a fan of making JEE Mains out of a hackathon
Amir Nagri|2023-03-14 12:38:25|At least devs competing will know what they are going to be judged on, right?
Amir Nagri|2023-03-14 12:38:57|And will be helpful for the jury as well on what to look for
Amir Nagri|2023-03-14 12:40:13|So need to know the jee syllabus rather than going with broad ias subject 🙂
Soumyadeep Mukherjee|2023-03-14 12:46:58|Tracks are announced no for the hackathon? Isnt that enough to decide? 🤔
Rasagy Sharma|2023-03-14 12:48:10|Hey Heer, Rasagy here! Designer / Data Artist 👋
~ Anurag|2023-03-14 12:48:22|Having criteria takes away the fun from hacking/creativity part from hackathons, I absolutely agree with Nirants point of leaving it to the judges
Jay Pokarna 2014 BPCC|2023-03-14 13:03:18|Hey Heer. My name is Jay. I'm a product manager
~ Vikas|2023-03-14 13:33:35|‎~ Vikas joined using this group's invite link
Heer Shingala|2023-03-14 15:38:08|Hey Jay! 👋🏻 nice to meet you..DMing.
Heer Shingala|2023-03-14 15:38:46|Hello Rasagy! 💃 DMing!
~ Vikas|2023-03-14 15:55:23|Hi Heer, Vikas here. fintech/tech  consultant/trainer
Aditya Khsirsagar|2023-03-14 15:57:37|Thanks Nirant.   Hello everyone, I'm ADK, Gifsagar on social. I have a chiller non-agenda group called Cooler Talk. DM if you want to join.
Lucky Murari|2023-03-14 17:22:33|https://alpaca-ai-custom4.ngrok.io/ Thoughts on this?
Nirant|2023-03-14 17:31:13|Very slow to try prompts there atm. Hoping it'll be on nat.dev soon. So far, it looks more like davinci-002 than the 003 series in terms of ability to follow logic over multiple hops. Also, no weights — so kinda iffy on what is going inside training
Aishwarya Goel Inferless 5s for 5G|2023-03-14 17:38:14|‎Aishwarya Goel Inferless 5s for 5G joined using this group's invite link
~ tushar|2023-03-14 18:20:20|‎~ tushar joined using this group's invite link
Manjot Pahwa|2023-03-14 18:25:54|‎Pranjal Mehta added Manjot Pahwa
Pranjal Mehta|2023-03-14 18:29:45|Welcome Manjot [PHONE]. She is with Lightspeed VC currently. She has a ton of experience having been at Google, started up and then led Stripe India as CEO.
Harsh Koo|2023-03-14 18:53:18|The instruct dataset is key. And the PR they have raised with Huggingface gives you the training code.
Ansuman Patnaik|2023-03-14 22:32:45|‎Ansuman Patnaik joined using this group's invite link
~ Aman|2023-03-14 22:41:47|https://twitter.com/OpenAI/status/1635687373060317185?t=nhm2BaNejunBE9-syFgEeA&s=19
Nirant|2023-03-14 22:42:20|Clearly, built for enterprise:  gpt-4 has a context length of 8,192 tokens. We are also providing limited access to our 32,768–context (about 50 pages of text) version, gpt-4-32k, which will also be updated automatically over time (current version gpt-4-32k-0314, also supported until June 14). Pricing is $0.06 per 1K prompt tokens and $0.12 per 1k completion tokens.
Lucky Murari|2023-03-14 22:51:17|As I understand the big user visible things are:  - ability to take image as input - Scalability improvements (ability to process 25k words etc) - Pricing changes   Am I missing anything else here?
Yash Pandya|2023-03-14 22:51:51|This was actually true 😶
Lucky Murari|2023-03-14 22:53:08|Also too much happening in this space in a day😅 how do one keep up with things?
Anshul Bhide Replit|2023-03-14 22:53:39|3x the price
Dhruv Anand|2023-03-14 22:53:58|Yeah this is crazy. The train just does not stop
Lucky Murari|2023-03-14 22:55:29|Seems enterprise grade security/Scalability costs premium😅
Nirant|2023-03-14 22:56:04|12 cents per 1K token completions is quite expensive — this is going to encourage Llama-Alpaca experiments even more
Nirant|2023-03-14 22:56:12|GPT4 capabilities have a FOSS counterpart from Amazon: github.com/amazon-science/mm-cot
Gokul Krishnan|2023-03-14 22:57:05|The be my eyes demo is hilarious 😂
~ Aman|2023-03-14 23:03:37|https://www.youtube.com/live/outcGtbnMuQ?feature=share  There is this stream scheduled for today
Lucky Murari|2023-03-14 23:09:28|Thank you ... Odd timing for ist. Will wait for the summary from others
Manjot Pahwa|2023-03-14 23:18:00|Thank you so much everyone, glad to be a part of this community! Thanks for adding me Pranjal!
Dhawal Jain Generative AI Group|2023-03-15 02:01:35|https://twitter.com/prashanthshanm/status/1635646028648177669?s=20
Nirant|2023-03-15 02:03:12|Too late, too little 😂😅😂😅
Nirant|2023-03-15 02:03:22|After seeing the OpenAI demo
~ tushar|2023-03-15 02:04:21|the paper wireframe to working code was just 🤯
Chirag Jain|2023-03-15 02:05:42|But wouldn't this get used more than anything else? who doesn't have to check email, write docs / make slides
Dhawal Jain Generative AI Group|2023-03-15 02:09:09|I agree. It doesn’t open up loads of possibilities for others to build upon- but enough productivity & note apps are irrelevant after this.
~ Anurag|2023-03-15 02:13:35|Loved the wireframe to code demo by OpenAI today
~ Anurag|2023-03-15 02:14:05|Really good demos
Nirant|2023-03-15 09:41:36|Hello!   Quite a few people have DM'd around wanting to learn more but don't have a good starting point. If you'd be kind enough to ask well-formed questions, can answer them through the day!  All questions — including beginner ones are welcome. Just no speculation or alarmist takes — we've Twitter for that xD
Nirant|2023-03-15 09:42:25|Will also request other experts hiding in the weeds to lend their expertise around StableDiffusion: [PHONE] [PHONE]
Aditya Ankur|2023-03-15 09:59:33|Last paper I read on Deep Learning/NLP was Attention Is All You Need.  With all the recent buzz on LLMs, what should I read/watch to get myself upto speed with the current state of LLMs.  I'm willing to spend a hour daily for a month to reach my goal.
Pranjal Yadav Razorpay|2023-03-15 10:07:04|I would highly recommend watching Karpathy's nonogpt video. 2 hours of golden content. He basically reproduces the same paper you read from scratch.
Nirant|2023-03-15 10:07:16|[Beginner Researcher Answer] There are 2 different directions to structure your reading:  1. What's proven: The underlying op is largely unchanged since GPT2. The core inventions since then are RLHF/PPO (github.com/carperai/trlx) and related Instruction Finetuning (Alpaca's sauce). This is something you can also run in a couple of hundred dollars on commercial GPUs.  2. What's somewhat known: The entire gamut of performance and other tweaks on the OG op: Linear Attention, https://github.com/lucidrains/linear-attention-transformer, Longformer: https://arxiv.org/abs/2004.05150 and their ilk. This is important for working with large context windows. We don't know if OpenAI is using any of these innovations or not.
Azhan Mohammed Generative AI WhatsApp Group|2023-03-15 10:07:50|‎Azhan Mohammed Generative AI WhatsApp Group joined using this group's invite link
Nirant|2023-03-15 10:08:31|The other way is to work backwards from what is out there and we can study e.g. everything from Llama to Flan-T5 and see what blocks they've been built on
Pranjal Yadav Razorpay|2023-03-15 10:10:16|Do you think Xavi Amatriain's catalog is a good read for starters?
Nirant|2023-03-15 10:12:01|That can be a bit overwhelming for someone who was last reading BERT-era papers. I mean, even Contrastive Learning is a new concept there in a way.    For advanced readers, this is the link we're discussing: https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/
Nirant|2023-03-15 10:12:21|But if you do this for a living, you should most def use that as a starting point
Nirant|2023-03-15 10:17:12|Re-iterating: Non-technical Qs most welcome. They also are good prompt for someone to elaborate and spark and idea :)
~ Mayank|2023-03-15 10:19:44|‎~ Mayank joined using this group's invite link
~ tushar|2023-03-15 10:28:49|transformers have taken over the field which was dominated primarily by RNN variants. Are we seeing signals of any new architecture doing the same with transformers?
~ Anurag|2023-03-15 10:32:45|On a slightly different tangent   *Do you think there is compounding/differentiating value in fine tuning in gpt models*  Generative art (stable diffusion) models improve a lot when fine tuned because it helps system understand what the user is looking for  In case gpt models it feels each subsequent model is so powerful there is little advatage in fine tuning - the latest model is way better  Obviously all models gpt,llama are different I am coming more from jasper, copy ai examples  To people who hve used/studied it what are your thoughts?
Pranjal Yadav Razorpay|2023-03-15 10:41:40|With my limited understanding, I think fine-tuning any LLM is quite tricky.  There are three steps, task alignment, reward structuring and reinforcement loop. For example -  Task - QnA Reward structure - top 3 should cover most relevant info Reinforce - RLHF or PPO  I don't know any public code base that explains this in details. Let's not get to distrubuted compute issues due to the scale.  Experts can correct me on this if something is wrong.
Sachin Legaltech|2023-03-15 10:42:13|Few courses which can explain things in details (But most of these courses will be out of date by at least few weeks/ months)-  https://web.stanford.edu/class/cs25/ , https://web.stanford.edu/class/cs224n/index.html#schedule , https://people.cs.umass.edu/~miyyer/cs685/
Nirant|2023-03-15 10:42:29|What do you think about trlx re: PPO?  github.com/carperai/trlx
~ Sachin Govind|2023-03-15 10:49:00|‎~ Sachin Govind joined using this group's invite link
Nirant|2023-03-15 10:51:42|My very spicy, uninformed take is that we'll see model sizes, personalities, flavours spread across the spectrum of use cases like we did for DBs.  This is based on one main beliefs: Instruction tuning is very effective, cheap and on-prem deployment of these models is easier. I don't think RL will be a necessity for finetuning.  tl;dr: There will be a Postgres — but others will have a role to play as well.
Sachin Legaltech|2023-03-15 10:53:20|Do we think finetuning is needed for most of the usecases? Or just clever prompt engineering is the way to go? The way I am thinking about this is finetuned model is someone who has learned and internalised the concepts vs prompt optimisation with relevant context is someone intelligent reading interesting information and inferring outputs based on it? And for most cases I feel someone smart reading correct information and responding based on that would be sufficient. Do we think that for applications, prefix / prompt tuning is the way to go than finetuning base models (for applications; for open source LLMs, we will need instruction tuning) ?
Rasagy Sharma|2023-03-15 10:53:20|For artists (non-tech) looking for _prompt to art_ experiments, what is the next step after playing with basic prompts on Midjourney & Dall-e? Do you recommend just going deep with those two platforms, or is there something else that works better?
Pranjal Yadav Razorpay|2023-03-15 10:53:21|Alex from Carper AI is presenting this tonight at W&B conference. So I'll wait till then and discuss tomorrow.
~ Sachin Govind|2023-03-15 10:54:41|Playgroundai
Sachin Legaltech|2023-03-15 10:55:28|Prompt optimisation looks more lucrative as the possible size of prompt is now much bigger. Would we train smaller models which will generate better prompts for the underlying LLMs ?
Nirant|2023-03-15 10:56:34|Stable Diffusion gives you a lot more control, power and flexibility. See civitai.com (NSFW!) for all the styles and themes you can create around. You might also want to checkout a couple of Youtube artists using this really well for prompt to art: youtube.com/@sebastiankamph is my fav at the moment
Nirant|2023-03-15 10:57:33|In this group, [PHONE] [PHONE] [PHONE] have played with Automatic1111 the interface and all that it unlocks from ControlNet (used for making fingers, control posture, faces) to upresolution for high res images
~ Anurag|2023-03-15 11:05:51|Prompt engineering also changes with each new release, the system gets better at understanding what the user is looking for  My loosely held hypothesis is the companies which will win in applying these models would be the ones who use ai in the background and generate the relevant prompt on their own
Aditya Ankur|2023-03-15 11:07:01|I'll try this for first one week.
Amir Nagri|2023-03-15 11:07:36|a related but different thought, the next step for text2image providers is integrating directly with artists choice of full-fledge tool - canva, photoshop  stability already has a plugin out for photoshop, canva itself have an AI plugin that might get more richer and provide similar/same functionality
Amir Nagri|2023-03-15 11:10:40|if you have explored prompt engineering, i think next logical step would be exploring image2image, in-painting, out-painting and instruct pix2pix  you can try these features on playgroundAI, gives you some ability to edit/control the generated images  given the pace, i think playgroundAI should release Controlnet feature as well, that is going to be absolutely fantastic for artist to control pose, and get better img2img generation
Amir Nagri|2023-03-15 11:30:28|also did a quick write-up on different web UIs out there, hope this is helpful for this group - https://www.ai-art.dev/web-uis-for-stable-diffusion
Karan Ganesan luma.ai|2023-03-15 12:04:37|https://www.linkedin.com/posts/sayak-paul_bangalore-folks-how-about-organizing-an-activity-7041263527482830848-qGzh?utm_source=share&utm_medium=member_ios
Soumyadeep Mukherjee|2023-03-15 12:48:04|"[PHONE] Have been working with artists and their flows a lot to figure on how to empower them more. While my day job is for comic creators, I have been thinking on ageneric level too.  From what I have seen across the world, ""hacker"" artists have setup their own SD and have started tuning it for their own art styles OR usecase. Like spiderverse style, darkish lighting etc. but it is still being heavily used as a mood boarding tool and not as much directly.  Game designers on the other hand are using it far more internally in their workflow now and startups like scenario are building for them.  I checked out figma add ons too which create icons etc but they are bleh. 😅 I am sure we can do better.  SD hacking by artists youtube videos are just crazy. Sometimes I wish I was an artist more than an engg. 😅"
Gokul Krishnan|2023-03-15 12:50:52|RNNs are fighting back https://mobile.twitter.com/arankomatsuzaki/status/1635453248252391427
Gokul Krishnan|2023-03-15 13:14:52|Most research shows that bigger the model, more the number of emergent properties. Are there any works that show when these arise during training? Do they arise gradually one by one as we train or do they all come up early and become better as we train?
Gokul Krishnan|2023-03-15 13:27:07|To give more context on the premise: https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ/s1600/image8.gif from the Google palm Blogpost https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html?m=1
Chaitanya Mehta Goodera Turtlemint|2023-03-15 14:44:20|‎Chaitanya Mehta Goodera Turtlemint joined using this group's invite link
~ Ananya|2023-03-15 17:40:45|‎~ Ananya joined using this group's invite link
~ Rishika Sevlani|2023-03-15 20:44:38|‎~ Rishika Sevlani joined using this group's invite link
Rohan Manchanda|2023-03-15 23:52:57|‎You added Rohan Manchanda
~ Innovator|2023-03-16 01:02:03|‎~ Innovator joined using this group's invite link
~ Srinivasan Selvaraj|2023-03-16 01:03:38|‎~ Srinivasan Selvaraj joined using this group's invite link
~ Venkat Raman Parasuraman|2023-03-16 05:55:25|‎~ Venkat Raman Parasuraman joined using this group's invite link
~ Karthick Rajagopal|2023-03-16 07:55:33|‎~ Karthick Rajagopal joined using this group's invite link
~ Muttu|2023-03-16 09:16:55|‎~ Muttu joined using this group's invite link
Manjot Pahwa|2023-03-16 10:27:52|I basically read all the papers related to popular models, helps you understand the differences.
Aditya Ankur|2023-03-16 10:35:00|Thanks Majot. I'll try and explore this as well.  But it would be difficult for me to read popular model papers if I don't have my prerequisites down :)  Any suggestions for a person who is trying make a come back?
Pranjal Mehta|2023-03-16 10:46:16|DM [PHONE]
Nirant|2023-03-16 10:49:34|At the risk of waxing poetic, I like this game of hunting for clues, trying to get into the mind of what did the research team think and what might be the failed experiments they've not mentioned in a paper.   A great way to learn this is start by following the citation graph of any paper which you think is interesting. For suggestions, [PHONE] (Pranjal Yadav, DS @ Razorpay) mentioned the Transformer Catalog (amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376)
Nirant|2023-03-16 10:51:03|"You can play this game in arcade (like above), or go to hard mode and start with interdisciplinary papers like Visual ChatGPT and diff it against say, Amazon's MM CoT or even team mode: Host a reading session and invite 4 people to present different papers and tell what the authors missed or got right or what their ""insight"" was"
Harsh Koo|2023-03-16 10:51:23|Brilliant resource. Thanks for sharing. ‎[3/16/23, 10:53:13] Nirant: ‎image omitted
Harsh Koo|2023-03-16 10:53:19|Are there any happening in blr? Any channel to discover these?
Amogh V|2023-03-16 10:54:45|"Wow this sounds like a great idea. Folks should spontaneously organize such stuff in Bangalore. I might do such ""art parties"" where we create using stable diffusion"
Nirant|2023-03-16 10:55:39|Sumod Mohan used to run a CV paper reading group, Swanand runs one via Hasgeek which is more broader CS (and very high quality!)   I believe there is one happening in April again around DL (not tfm or GenAI)  But if there is enough people interested in going full nerd, DM with a paper you want to present and I (or a GPT bot on my behalf 🤣) will coordinate a time!
Shubhi Saxena|2023-03-16 10:57:29|I would love to listen in if that’s allowed!
Nirant|2023-03-16 10:58:34|If I get >5 DMs, will share the time and venue here. Can do Zoom if >3 of these are non-BLR
Shashwat TDC|2023-03-16 11:27:57|+1 DM
Nirant|2023-03-16 11:30:19|Please don't reply here with DM? That's a bit spammy for everyone else here 😅  Do DM me with the paper you want to present :)
~ Aman|2023-03-16 12:37:59|https://twitter.com/LangChainAI/status/1636122692645691393?t=aUUOXK9kILoYkyVzVgjdhg&s=19  On a different note, i added PGVector (Postgres's Vector DB) to the Lanchain ecosystem. You can use it now for embeddings if anyone's interested, and DM if you need any help. Can be helpful if you need a simple local setup without too many dependencies.
~ Anand Raj☃️|2023-03-16 13:06:42|‎~ Anand Raj☃️ joined using this group's invite link
Sudharshan GenAI|2023-03-16 13:25:14|‎Sudharshan GenAI joined using this group's invite link
Simran Sachdeva Rephrase|2023-03-16 13:51:44|‎Simran Sachdeva Rephrase joined using this group's invite link
~ Anubhav Jain|2023-03-16 15:41:48|I was storing embedding vectors as json in PG database previously. Need to explore this . Thanks for sharing
~ Rojal Roy|2023-03-16 22:59:05|‎~ Rojal Roy joined using this group's invite link
~ Rojal Roy|2023-03-16 22:59:29|‎~ Rojal Roy left
~ Ashin xavier|2023-03-16 23:00:48|‎~ Ashin xavier joined using this group's invite link
~ rosh|2023-03-16 23:03:03|‎~ rosh joined using this group's invite link
~ All ways 😄Happy|2023-03-16 23:43:58|‎~ All ways 😄Happy joined using this group's invite link
~ Srinivasan Selvaraj|2023-03-17 00:06:14|Thank you [PHONE] for bringing this, how does this do with large scale searches ? Any help appreciated 👍
~ Aman|2023-03-17 00:31:53|Haven't done any performance tests yet, so don't have much idea about that. The integration is still missing some indexing steps, but from what I've seen, specific vector database like pinecone will have better results in case of large scale applications.
~ Aman|2023-03-17 00:32:14|But again, can't say for sure.
~ Srinivasan Selvaraj|2023-03-17 01:05:59|Great thanks for your response ,  I agree ☝️ , challenge I am facing with pinecone is  joining with existing SQL tables to do hybrid searches, I realised a better results with milvus still not sure on the phase of exploration. Thank you 👍
Anirudth N|2023-03-17 02:35:28|https://www.youtube.com/watch?v=VqhDnaqhnd4 - Very impressive 🙌
~ Ameya|2023-03-17 07:55:24|‎~ Ameya joined using this group's invite link
~ Vaibhav|2023-03-17 08:03:03|‎~ Vaibhav joined using this group's invite link
~ Karan ✨|2023-03-17 09:24:11|‎~ Karan ✨ joined using this group's invite link
~ Anurag|2023-03-17 10:34:57|This might be a naive question but can someone explain why these language models have cut off in 2021, gpt4 included   Will there always be a gap of 2year ish in every new model- assuming training, finetuning etc has to be done on top of it  Or is there some other reason?
Sudharshan GenAI|2023-03-17 10:40:02|Training involves curating a dataset which is a lot of effort. The dataset they used to train on was curated till 2021.
Sudharshan GenAI|2023-03-17 10:40:34|Cleaning the data, wrangling it etc take a LOT of time
~ Anurag|2023-03-17 10:57:47|Does each llm build their own dataset from scratch  Or they use same dataset but tune it differently?
Amir Nagri|2023-03-17 11:37:52|Afaik gpt4 cut off is aug 22  Check out the openai YouTube on the past few months of post processing and output tuning they have done after the model was trained
Swastik Banerjee|2023-03-17 11:40:00|‎Swastik Banerjee joined using this group's invite link
~ nilabjo|2023-03-17 11:42:31|‎~ nilabjo joined using this group's invite link
Sudharshan GenAI|2023-03-17 11:43:33|there are some open source datasets     But openai would’ve curated and cleaned their own ‎[3/17/23, 11:44:19] Sudharshan GenAI: ‎image omitted
Sudharshan GenAI|2023-03-17 11:44:26|https://www.springboard.com/blog/data-science/machine-learning-gpt-3-open-ai/
Sudharshan GenAI|2023-03-17 11:44:47|Gpt-4 paper might have the dataset details. The paper was pretty disappointing though
Garv Malik 2012H|2023-03-17 12:30:46|ChatGPT-3 Whatsapp bot. Can summarise videos, transcribe voice notes, answer text questions and generate images using /image   send start to wa.me/16504603230  Product is whatgpt.ai , slightly buggy, but whatsapp makes it really accessible
~ Abhirup|2023-03-17 12:39:04|‎~ Abhirup joined using this group's invite link
Aditya Agrawal SuperU|2023-03-17 13:11:27|‎Aditya Agrawal SuperU joined using this group's invite link
~ Uneet|2023-03-17 13:56:33|This is interesting as well, I use it for productivity  https://usesynth.com
~ ボルツザマク|2023-03-17 17:23:10|‎~ ボルツザマク joined using this group's invite link
~ bhanu.io|2023-03-17 17:49:04|‎~ bhanu.io joined using this group's invite link
Yash Sinha 2012C6|2023-03-17 18:45:24|Count me in for listening, please.
Priyal Mehta|2023-03-17 20:33:03|‎Priyal Mehta joined using this group's invite link
Nirant|2023-03-17 20:35:03|Replit.com will be sponsoring the hackathon!   If any of you need Replit Pro (decent CPU, RAM) for demo'ing GPT4 apps, hackathon sign up: https://has.gy/ULYt — and hit me up at the venue! ‎[3/17/23, 20:37:51] Nirant: ‎image omitted
Soumendra Dhanee|2023-03-17 20:47:53|It seems slightly more complicated. The model certainly has access to data from 2022, and can answer some questions about it, but its official position is that the data has a cutoff date in 2021, and it doesn't answer some questions citing that as a reason. ‎[3/17/23, 23:41:03] Soumendra Dhanee: ‎image omitted ‎[3/17/23, 23:41:04] Soumendra Dhanee: ‎image omitted ‎[3/17/23, 23:41:05] Soumendra Dhanee: ‎image omitted
Soumendra Dhanee|2023-03-17 23:48:31|The first statement is wrong. I don't know what to make of the whole thing. It knows about IFRNet, but somehow gives a partial answer. Produced correct answer for earlier models.
Soumendra Dhanee|2023-03-17 23:48:44|Just another day in the life of an LLM, I guess.
Karan Ganesan luma.ai|2023-03-18 00:49:58|‎Karan Ganesan luma.ai left
~ Karan Gandhi|2023-03-18 04:10:54|‎~ Karan Gandhi joined using this group's invite link
~ Devyani|2023-03-18 05:09:51|‎~ Devyani joined using this group's invite link
Nirant|2023-03-18 05:52:49|New BingGPT Launch: https://www.bing.com/new
Saksham Generative AI WhatsApp Group|2023-03-18 06:31:18|‎Saksham Generative AI WhatsApp Group joined using this group's invite link
Heer Shingala|2023-03-18 09:37:50|This has the potential make advertising briefs soooo much easier 💯  https://bit.ly/3JqMLEm
Shubham Sharma 2012C6|2023-03-18 09:45:33|https://www.gizmochina.com/2023/03/16/ai-hire-a-human-to-solve-captcha/
Nirant|2023-03-18 10:08:04|How will GPT4 change software engineering? I took a stab at answering this:  https://niranting.substack.com/p/gpt4-software-engineerings-iphone
Nirant|2023-03-18 10:10:00|And by I, I mean actually me, not GPT4 — that guy speaks too much
~ Abhishek|2023-03-18 11:30:26|‎~ Abhishek joined using this group's invite link
~ Abhishek|2023-03-18 11:37:37|‎~ Abhishek left
Maneesh 2013|2023-03-18 11:50:26|‎Maneesh 2013 joined using this group's invite link
Rohit GenerativeAI WhatsApp Group|2023-03-18 13:09:16|hey! is march meetup for gen ai is happening today? at Hasura HQ, kora?
Shashank Generative AI Group|2023-03-18 13:12:17|‎Shashank Generative AI Group joined using this group's invite link
Manjot Pahwa|2023-03-18 13:16:18|Is there an RSVP link / signup link for this?
Nirant|2023-03-18 13:17:44|No meetup in March, come to the hackathon!
Yash Sundial Design|2023-03-18 15:36:20|‎‎Yash Sundial Design changed their phone number to a new number. ‎Tap to message or add the new number.
~ Yash|2023-03-18 16:38:45|‎‎~ Yash changed their phone number to a new number. ‎Tap to message or add the new number.
~ AMA|2023-03-18 17:14:28|‎~ AMA joined using this group's invite link
~ AMA|2023-03-18 17:14:57|‎~ AMA left
~ Unni|2023-03-18 17:15:51|‎~ Unni joined using this group's invite link
~ Anurag|2023-03-18 18:40:04|Anyone here who has been using image generation model for a while? Have a few questions   1) Midjourney feels far superior than all the other models, have you also felt the same or is my prompting bad? 2) the best place to play around with stable diffusion seems to be playground.ai or dreambooth is there anything else? 3) Any sites to get better at prompting? I have been using prompt hero 4) is there value in running SD locally?  Feel free to pick and choose the question you want to answer to
Rohit GenerativeAI WhatsApp Group|2023-03-18 18:43:52|1. Yes, I did notice as well. Mid journey results looks more realistic. I tried open-journey too on HF. 2. HF? 3. promptbase (paid), promptperfect (recently saw it on twitter, haven't tried 3. last time I tried on mac, it was super slow
Sudharshan GenAI|2023-03-18 18:46:30|Yup been playing and creating since 2020, even fine tuned old VQGAN models
~ Anurag|2023-03-18 18:46:58|Thanks  Any guide on how to run it via HF?
Sudharshan GenAI|2023-03-18 18:47:32|Midjourney is superior, there are a few models in cvitai that come close  playground ai is good and there's mage.space  But if you want the best experience, you need to use auto1111 or invoke UI (locally)
Sudharshan GenAI|2023-03-18 18:48:03|they offer far more functionality and the open source community is very active
Soumyadeep Mukherjee|2023-03-18 18:48:11|Midj is really pretty but a lot of models have matched quality now.
Soumyadeep Mukherjee|2023-03-18 18:48:18|Try gooey.ai
Soumyadeep Mukherjee|2023-03-18 18:48:22|I recently came across it.
Rohit GenerativeAI WhatsApp Group|2023-03-18 18:48:41|I mean HF spaces. If they are not on HF spaces, you can use HF diffusers. The have documentation on inferencing.  you can also try: https://github.com/AUTOMATIC1111/stable-diffusion-webui if you can run it locally
Sudharshan GenAI|2023-03-18 18:49:01|models like?
Soumyadeep Mukherjee|2023-03-18 18:49:14|Dreamshaper, openjourney, protogen
Sudharshan GenAI|2023-03-18 18:49:24|They're not good enough
Sudharshan GenAI|2023-03-18 18:49:28|Openjourney is pretty bad
Soumyadeep Mukherjee|2023-03-18 18:49:32|Protogen has many versions.
Soumyadeep Mukherjee|2023-03-18 18:49:40|Each with some good and some bad.
Sudharshan GenAI|2023-03-18 18:49:44|None of them lol
Sudharshan GenAI|2023-03-18 18:49:51|I've tried all
Soumyadeep Mukherjee|2023-03-18 18:49:56|Depends what you want. 😅
Sudharshan GenAI|2023-03-18 18:50:00|The closest model is illuminati diffusion
Sudharshan GenAI|2023-03-18 18:50:08|With negative embeddings
Sudharshan GenAI|2023-03-18 18:50:48|Getting MJ like photorealism even with realistic vision is hard
Soumyadeep Mukherjee|2023-03-18 18:51:09|V5 they really really stepped on photo realism true.
Rohit GenerativeAI WhatsApp Group|2023-03-18 18:51:13|open journey is good though compared to available open-source models?  or are there better open-source models available, that I don't know? better than SD 2.1 and open journey?
Sudharshan GenAI|2023-03-18 18:51:23|https://civitai.com/
Sudharshan GenAI|2023-03-18 18:51:28|have fun :)
~ Anurag|2023-03-18 18:51:34|So true, couldn’t try it though  Behind paywall
Soumyadeep Mukherjee|2023-03-18 18:52:10|Yea. This has most models. There are Bollywood models too 😂
Sudharshan GenAI|2023-03-18 18:52:22|Yup anyone can train a LORA or a dreambooth
Sudharshan GenAI|2023-03-18 18:52:38|They're using LORAs to finetune alpaca now
Sudharshan GenAI|2023-03-18 18:53:13|Anyone giving it a shot? Making LLaMa better with self instruct datasets
Soumyadeep Mukherjee|2023-03-18 18:53:41|Was discussing literally this yesterday with [PHONE] 😅
Soumyadeep Mukherjee|2023-03-18 18:54:12|Maybe give it a shot over the hackathon day
Nirant|2023-03-18 18:56:50|I'll sponsor this upto $500 and happy to contribute datasets and get you your first few users if you want to go commercial with it too.   I've experience making datasets, including those which are part of IndicGlue -- the SuperGlue equivalent for Indian languages
Nirant|2023-03-18 18:57:24|^This should tell you how excited I'm about this xD
Soumyadeep Mukherjee|2023-03-18 18:55:33|Are non engineers doing this enough in India? 🤔
Sudharshan GenAI|2023-03-18 18:56:26|Most are annon
Sudharshan GenAI|2023-03-18 18:56:37|Anyone can do it tbh
Rohit GenerativeAI WhatsApp Group|2023-03-18 18:56:46|what's self instruct datasets?
Sudharshan GenAI|2023-03-18 18:56:48|Just gotta get through the pain of setting up automatic1111 properly
Sudharshan GenAI|2023-03-18 18:57:32|Alpaca can be much better.  Was talking to a few friends and thinking of doing these 2  1) Get a better dataset. 52K one alpaca used seems fishy 2) Use llama 30B
Sudharshan GenAI|2023-03-18 18:57:56|And then finetune with lora
Sudharshan GenAI|2023-03-18 18:58:24|Awesome
Sudharshan GenAI|2023-03-18 18:58:43|Dude even I'm super excited haha. We actually have a chance to compete with OpenAI and launch something super competetive ‎[3/18/23, 18:59:54] Sudharshan GenAI: ‎image omitted
Sudharshan GenAI|2023-03-18 19:00:36|Hashed them out quickly - have a look folks and lmk what you think
Nirant|2023-03-18 19:00:41|I'm a simple man, I see Roam, I like it
Abhishek Maiti|2023-03-18 19:00:51|I have the same question..
Sudharshan GenAI|2023-03-18 19:02:23|haha
Sudharshan GenAI|2023-03-18 19:03:14|https://crfm.stanford.edu/2023/03/13/alpaca.html
Nirant|2023-03-18 19:04:44|This is self instructions dataset  https://github.com/yizhongw/self-instruct
Sudharshan GenAI|2023-03-18 19:04:16|"Basically a large json that can fine tune any LLM and make them more ""aligned"" - makes an LLM better and more like ChatGPT"
Sudharshan GenAI|2023-03-18 19:04:22|to put it simply
Sudharshan GenAI|2023-03-18 19:04:46|https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json  The entire dataset
~ Venkat Raman Parasuraman|2023-03-18 19:06:45|Who did this? It’s excellent
Amir Nagri|2023-03-18 19:08:12|catching up on the convos - 1. midjourney feels superior absolutely. hopefully next version of SD with offset noise gives a high contrast images like MJ and pares up the difference MJ's interface is restricted to discord,  as well as not open source, with pace of innovation like LORA, ControlNet, the OS versions looks more appealing 2. automatic1111 using Camederu's colab notebook on a T4 GPU is very effective, productivity as well as cost wise, my go to setup 3. automatic1111 has some extension for generating variation of prompts using GPT-3, but they are just text2text generation making a good assistant for prompt engineering is the idea i am working on for the hackathon 🤞, and looks like i got my first beta user 😊 4. nope, i keep switching between T4 and A100, with a fixed GPU locally, will be restricted to that, and with pace of releases, there is always a risk that your GPU won't support it
Amir Nagri|2023-03-18 19:09:02|offset noise write up - https://www.crosslabs.org/blog/diffusion-with-offset-noise
Pranjal Yadav Razorpay|2023-03-18 19:11:13|4 months away from this generative AI space and this discussion is already putting me in stone age 😅😅
Nirant|2023-03-18 19:11:15|UW PhD Student, quite clever.  Ofc, Stanford hogged all the recall value with Alpaca
Sudharshan GenAI|2023-03-18 19:11:58|All this happened in last 2 weeks 😂
Nirant|2023-03-18 19:12:28|We didn't talk about all the Google stuff and Blender ControlNet for posture and depth yet xD
Amir Nagri|2023-03-18 19:12:29|i was still in GenerativeAI, just in text2img and not text2text, and i feel like i am in stone age 😂
Sudharshan GenAI|2023-03-18 19:14:31|Haha I'm in touch with toysxyz - the dude building all that. We were jamming on using facial keypoints for better control
Nirant|2023-03-18 19:14:52|Do people not sleep these days?
Nirant|2023-03-18 19:14:58|Is everyone on Adderall?
Sudharshan GenAI|2023-03-18 19:15:09|Hahaha
Nirant|2023-03-18 19:15:32|Was sleep a ZIRP phenomenon?
Nirant|2023-03-18 19:15:44|Asking for myself, I'm the friend ‎[3/18/23, 19:15:58] Sudharshan GenAI: ‎image omitted
Yash Pandya|2023-03-18 19:16:01|😂
Rohit GenerativeAI WhatsApp Group|2023-03-18 19:18:39|So basically the json structure you need to fine-tune gpt using OpenAI?
Sudharshan GenAI|2023-03-18 19:18:45|Yup
Sudharshan GenAI|2023-03-18 19:19:00|It's simple instructions + answers generated by GPT-3
Sudharshan GenAI|2023-03-18 19:19:21|What if we use GPT-4?  What if we actually get trained annotators to create the dataset?
Sudharshan GenAI|2023-03-18 19:19:55|OpenAI had a team of 40 upwork contractors and Scale AI;s help to do this - (from instructGPT paper)
Sudharshan GenAI|2023-03-18 19:21:00|A good dataset can make a large difference - like any ML problem
~ 📈|2023-03-18 21:14:22|‎~ 📈 joined using this group's invite link
Vedant Valia|2023-03-18 21:16:31|‎Vedant Valia joined using this group's invite link
Dr. Ashith Generative AI WA Group|2023-03-18 21:49:03|‎Dr. Ashith Generative AI WA Group joined using this group's invite link
Yash Sundial Design|2023-03-19 03:04:15|‎‎Yash Sundial Design changed their phone number to a new number. ‎Tap to message or add the new number.
Nirant|2023-03-19 13:31:16|Confirmed *FOSS* Demos for the hackathon, 2 of the top 3 projects from Github Trending in AI:  1. Guardrails: Shreya R: https://github.com/shreyar/guardrails 2. GPT-Index/Llama Index: Jerry Liu: github.com/jerryjliu/gpt_index  Expecting to convert Weaviate, a vector DB FOSS package too
Nirant|2023-03-19 13:33:42|Thanks for the intro Ravi Theja, GPT-Index contributor and inMobi DS [PHONE]  to Jerry Liu
~ Akshat WorkHack|2023-03-19 14:05:17|‎~ Akshat WorkHack joined using this group's invite link
Shubham Sharma 2012C6|2023-03-19 18:40:21|https://mobile.twitter.com/nickfloats/status/1631346749297106958
~ Akansha|2023-03-19 19:16:44|‎~ Akansha joined using this group's invite link
Anagh Prasad|2023-03-19 21:16:03|Sharing my favourite blog from last few weeks: https://simonwillison.net/2023/Mar/17/beat-chatgpt-in-a-browser/
Anagh Prasad|2023-03-19 21:16:17|WASM for LLMs is super interesting, anyone tried?
Shashank Generative AI Group|2023-03-19 21:18:04|came across this today  https://replicate.com/blog/replicate-alpaca
Rohit Ganapathy|2023-03-19 21:18:36|‎Rohit Ganapathy joined using this group's invite link
Sudharshan GenAI|2023-03-19 21:33:06|Yup saw this
Sudharshan GenAI|2023-03-19 21:33:34|They also trained an LLM to mimic Homer Simpson and it’s apparently better than gpt-4
Harsh Sharma SRM 2023|2023-03-19 21:47:15|Hey Hi Guys ! I have a question which I would like to seek your advice or views upon - I have a few research project / papers Idea which I would like to implement in domain of NLP, but I am looking for GPU-based clusters or GPU-based computing instances in India for Applied research purposes. Does anyone know about any of these resources which one could use?  Any help/advice/information is really appreciated.  Thanks
~ Arsalaan|2023-03-19 21:56:32|Iit madras or Bombay has research labs you can cold mail them or reach out to other iits they might help or redirect to appropriate org.
Dhruv Anand|2023-03-19 22:07:26|It'd be hilarious if the model forgot how to do chain of thought reasoning because of that 😂😂
Sudharshan GenAI|2023-03-19 22:14:56|Lol
Sudharshan GenAI|2023-03-19 22:18:19|Anyone exploring building a tool like this for VCs?   Something to create executive summaries  of startups  Similar to this  https://twitter.com/yoheinakajima/status/1636241201971232768
Sudharshan GenAI|2023-03-19 22:18:44|Good customers to sell to and solid use case of AI
Rounak Datta Hackathon Winner|2023-03-20 00:11:44|https://twitter.com/tarundua81/status/1625092808095961090 There was also this
Shubham Sharma 2012C6|2023-03-20 02:29:00|https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis anyone tried this? ‎[3/20/23, 08:48:21] Harsh Koo: impromptu-rh.pdf • ‎230 pages ‎document omitted
Nirant|2023-03-20 09:27:09|Reid Hoffmann's essay on GPT4 — but is there an AI Summary of this? 😛
Nirant|2023-03-20 09:27:23|I mean it's 150+ pages long
Harsh Koo|2023-03-20 09:27:54|It contains dialogues with GPT-4.   It would be cool if it would be 32k tokens in length.
Yash Pandya|2023-03-20 09:29:00|This is the future, people will use copilot to make their emails more detailed and comprehensive. Readers would use copilot to summarise it. 😂
Nirant|2023-03-20 09:29:38|No, in the future — there will be no emails, just byte-streams going from your brain to another brain. Mann Ki Baat. ‎[3/20/23, 09:31:21] Nirant: ‎GIF omitted
Nirant|2023-03-20 09:34:11|Shubham, my friend from college and a writer on TVF Pitchers S2 [PHONE] shared this HBR essay: https://hbr.org/2023/03/how-will-generative-ai-disrupt-video-platforms  The core idea is that in future the content loop will be complete: machines generate → recommend → see what works and make more  Hit him up if that's something you're interested in talking about!
Harsh Koo|2023-03-20 09:39:59|Very little MLE in the loop
Amogh V|2023-03-20 09:55:41|Ok super late to this because I was off the phone yesterday. But in my experience Midjourney is far far superior out of the box. Fantastic for applications where you need generic imagery and don't care too much about difficult characters, image composition and other fine control. Very useful for - blog post images, moodboards, inspiration images, stock images  I think of Stable Diffusion like a hammer, nails and other tools. Fine tuning is a superpower. When you consistently want a specific product, character, style you need SD. Also if you want greater creative control over composition like specific pose, object arrangement, background  or lighting then you have to use the SD add-ons like ControlNet and inpainting. The tradeoff is that SD is much harder to use and takes longer than Midjourney.  Also unless Midjourney introduces API access, all products will use SD. Even then Midjourney API will be used in something like Canva where the  primary user need is simplicity of use. For everything else, SD will reign
Amogh V|2023-03-20 10:06:52|Midjourney : Canva : : Stable Diffusion : Photoshop
Amir Nagri|2023-03-20 12:47:44|interesting  agree, mid-journey out of the box gives ready-to-use results, but we don't really know what it is doing under the hood, may be it is doing some prompt engineering unknown to user, something similar can be done for Stable Diffusion where based on the limited prompt, the backend injects/expands the prompt to gives a more pleasing and ready-to-use results  so my hunch is the car engine is the same/similar, the dashboard/controls gives you different feeling when you ride  OSS have always been marred by bad/minimalist interface and give a more geeky UI to end user, probably an opportunity to build the SD UI for designers/newbie users
Soumyadeep Mukherjee|2023-03-20 12:53:07|"But I think its not ""very"" hard to make midj and also there is a lot of legal gray area with midj."
Shashank Generative AI Group|2023-03-20 12:57:06|i wasn't expecting this to happen but Midjourney might release an API!  they mentioned this 2-3 days back during their discord office hours (for v5 alpha launch).  also v6 will come in about 2 months.
Shashank Generative AI Group|2023-03-20 12:58:27|InvokeAI has made a pretty slick open source UI for SD.  automatic1111 is like a freaking Bloomberg terminal 😂
Amogh V|2023-03-20 12:58:35|In 2 months? Wow. I missed this office hours
Soumyadeep Mukherjee|2023-03-20 12:58:48|So true 😂 And it keeps breaking. :-/
Amir Nagri|2023-03-20 12:59:47|has anybody managed to run invokeAI on colab? AFAIK they have docker to run locally on your desktop GPU
Shashank Generative AI Group|2023-03-20 12:59:48|plus they don't have any changelog, releases. i check updates by looking for closed issues with the enhancement label on github
Soumyadeep Mukherjee|2023-03-20 13:00:03|😂
Soumyadeep Mukherjee|2023-03-20 13:00:10|I just debug after things break :P
Amogh V|2023-03-20 13:00:19|"Automatic1111 will be the crazy hackers option that 5 years from now we will look back and say ""Back in my day we had this thing called Automatic1111 and it was beautiful. All you kids have it easy these days"""
Shashank Generative AI Group|2023-03-20 13:01:24|i didn't watch it either. recap: https://youtu.be/onjfu3Uh2vI
Shashank Generative AI Group|2023-03-20 13:02:07|winamp of CreativeAI 😂
Sudharshan GenAI|2023-03-20 13:03:39|Haha true
Shashank Generative AI Group|2023-03-20 13:03:39|btw anyone used runwayML Gen1? i got access few days back. crazy impressive.
Sudharshan GenAI|2023-03-20 13:04:20|Does invoke has the extensions that auto has?  There’s a auto extension for modelscope’s text to video already - it’s what I love about it
Shashank Generative AI Group|2023-03-20 13:06:37|invoke is pretty limited. i haven't even installed it right now. but love the focus on UX.  i actually remember that last year in one of the office hours, Emad actually said that they're open to colab with Invoke but i think invoke was reluctant or something.
Nirant|2023-03-20 13:22:52|Has anyone tried Comfy UI, the node based/DAG interface for image generation?
Heer Shingala|2023-03-20 13:32:38|V interesting!
~ Akshi|2023-03-20 13:54:31|‎~ Akshi joined using this group's invite link
~ Raj|2023-03-20 15:20:29|‎~ Raj joined using this group's invite link
~ Joy Mammen|2023-03-20 15:25:16|‎~ Joy Mammen joined using this group's invite link
Yash Pandya|2023-03-20 15:42:21|OpenAI wrote a paper on the potential impact of Large Language Models on the Labor Market  https://arxiv.org/pdf/2303.10130.pdf
Shashank Generative AI Group|2023-03-20 15:44:02|thread https://twitter.com/rubinovitz/status/1637651591191842816?t=g4U4qTnkF-R02mImutwo8w&s=19
Shubham Sharma 2012C6|2023-03-20 16:16:35|With the amount of funds that openAI has are these PR stunts?
Nirant|2023-03-20 16:17:35|No
~ A Ram Bharadwaj|2023-03-20 16:21:30|https://twitter.com/arankomatsuzaki/status/1637612922934382593
Nirant|2023-03-20 16:24:01|Request: When sharing links in future, please add a line about why should we click through or what is the topic about!  Helps folks decide to read/ignore without the FOMO :)
Shashank Generative AI Group|2023-03-20 16:32:16|didn't know about this. looks interesting but feels like just slapping a nodeUI without attention to workflows. InvokeAI is also working on a node architecture along with their canvas UI.  i feel like great, innovative designers haven't jumped into the GenAI field yet.  im collecting examples for a post on this. only 3-5 products have caught my attention in terms of design.
~ Harsh|2023-03-20 17:07:23|‎~ Harsh joined using this group's invite link
Amir Nagri|2023-03-20 17:21:32|Hello,  I have been preparing for a Stable Diffusion hands-on workshop organized by hasgeek. You can check out the details here - http://has.gy/1CNF  To fine-tune the content, delivery and setup, I am conducting FREE hands-on workshops on Controlnet (22nd March, Wednesday 7:00-8:30 pm IST) and Dreambooth (23rd March, Thursday 7:00-8:30 pm IST) in the coming week.  Checkout and sign-up if you are interested - https://forms.gle/ypEXMtf9pgM8QaoFA  For karma, kindly RT/Fwd to your GenAI WhatsApp groups where someone might find it useful  Thanks 🙏
Kishore GenAI|2023-03-20 17:24:34|‎You added Kishore GenAI
Chinmay Shah Arrowhead|2023-03-20 17:26:48|‎Chinmay Shah Arrowhead joined using this group's invite link
Dhruv Anand|2023-03-20 17:36:54|Hi everyone, please welcome Kishore [PHONE] to the group! He's building in the Generative AI space to generate statics for advertisers.
Nirant|2023-03-20 17:40:16|What is a static? Image? Text?
Heer Shingala|2023-03-20 17:44:20|Hey Kishore!
Heer Shingala|2023-03-20 17:44:34|Excited to see what you have so far. ‎[3/20/23, 17:48:41] Kishore GenAI: ‎image omitted
Amogh V|2023-03-20 17:51:49|Hi Kishore! Welcome to the group. Curious about the images you posted. Are they examples of what a static image is or output from your product's pipeline?
Kishore GenAI|2023-03-20 17:53:38|Hi [PHONE] . This is the output from my product pipeline.
Amogh V|2023-03-20 17:54:36|Pretty cool! So stable diffusion with some fine tuning magic I would guess?
Amir Nagri|2023-03-20 17:55:03|hey, nice to see you here [PHONE], amazing progress from last time we caught up 👍
Kishore GenAI|2023-03-20 18:00:27|You can do this without finetuning. There are many methods out there which you can implement to get similar results. But it does require a lot of trial and error and breaking apart the typical model. You can change the encoders. and other things in the HF pipeline for it to work.
~ Aman|2023-03-20 18:07:28|It was based of some prompt, or img2img?
~ Shivam|2023-03-20 18:15:11|‎~ Shivam joined using this group's invite link
~ Dh|2023-03-20 18:20:47|‎~ Dh joined using this group's invite link
~ Lance B|2023-03-20 18:21:30|‎~ Lance B joined using this group's invite link
~ Steve T|2023-03-20 18:54:17|‎~ Steve T joined using this group's invite link ‎[3/20/23, 18:55:09] Kishore GenAI: ‎image omitted
Shashank Generative AI Group|2023-03-20 18:56:32|Gen2 by RunwayML. paper, video  https://twitter.com/runwayml/status/1637800500459458562?t=cqgyop92cnoqISb8FPVDUw&s=19
Nishant Apne-App GenAI Hackathon|2023-03-20 19:55:30|‎Nishant Apne-App GenAI Hackathon joined using this group's invite link
Chirag Jain|2023-03-20 20:26:44|Can the world slow down a bit😂 I only saw GEN-1 a few days ago
Nirant|2023-03-20 20:32:29|My current favourite conspiracy theory: Someone is spiking SF's water supply with Adderall
Amir Nagri|2023-03-20 21:04:44|Not true, tech bros only drink sparkling water
~ Parth|2023-03-20 21:09:54|‎~ Parth joined using this group's invite link
Mannan Amroliwala|2023-03-20 21:22:11|‎Mannan Amroliwala joined using this group's invite link
~ Shreyas Prakash|2023-03-20 22:50:18|‎~ Shreyas Prakash joined using this group's invite link
Sudharshan GenAI|2023-03-20 23:18:30|https://vercel.com/templates/ai  Useful for hackathon folks
Rahul Seth|2023-03-20 23:25:34|‎Rahul Seth joined using this group's invite link
Anshul Bhide Replit|2023-03-20 23:26:14|some cool Replit templates -   https://replit.com/@replit/OpenAI-Python-GPT-4?v=1 https://replit.com/@replit/OpenAI-Python-GPT-35-Turbo?v=1 https://replit.com/@replit/OpenAI-Whisper-Speech-to-Text-Python?v=1
Anshul Bhide Replit|2023-03-20 23:26:42|check out all templates here - https://replit.com/templates?q=AI
Rohit GenerativeAI WhatsApp Group|2023-03-21 01:06:08|Great results! I played around with similar idea using controlnet but in my case I wanted to keep the actual product as it is. Here I see the main product has variations. Does your pipeline have that option where the actual product stays as it is and blends with a new background considering that as a seller if I already have a product, I don't want new ones while advertising?
~ Srikanth|2023-03-21 02:23:00|‎~ Srikanth joined using this group's invite link
Nirant|2023-03-21 06:09:50|I'm curious, why not inpaint the main product from a separate LoRA finetuned on the product?
~ Srijan Shukla|2023-03-21 06:49:41|‎~ Srijan Shukla joined using this group's invite link
Nirant|2023-03-21 07:06:26|For folks working on multiple images with minor variations, here is a _tutorial_ (yes! we're in the tutorial era of Stable Diffusion) using ComfyUI for generating similar images but with models of different ethnicities and different anime styles of same character  https://www.youtube.com/watch?v=OdMtJMzjNLg
Kishore GenAI|2023-03-21 09:05:32|Hi [PHONE] the main product here doesn’t vary. The main product isn’t the candle. It is the matchstick box with the person holding it. ‎[3/21/23, 09:08:19] Kishore GenAI: ‎image omitted
Kishore GenAI|2023-03-21 09:08:41|This image should be a better representation [PHONE]
Sudharshan GenAI|2023-03-21 09:13:27|Is that how tools like flair / booth.ai work?  Inpaint based on a dreambooth/Lora? ‎[3/21/23, 09:16:12] Nirant: ‎image omitted
Sudharshan GenAI|2023-03-21 10:01:59|How do they retain the text? Lora screws it up usually right  I think there’s some masking + I painting going on to place the images properly
Rohit GenerativeAI WhatsApp Group|2023-03-21 10:29:59|Didn't try it. Will give it a shot
Sudharshan GenAI|2023-03-21 10:42:14|I think there's some smart img2img + masking going on apart from dreamboothing
Shivendu Kumar|2023-03-21 11:05:12|https://bit.ly/hf-nvidia-meetup
Kishore GenAI|2023-03-21 11:08:01|Flair isn't using dreambooth. They are using their own custom trained models, which to my understanding was some sort of mask based, with outpainting. The issues with dreambooth are not only text but also product fidelity. You cannot get the original product fidelity preserved with dreambooth. Also dreambooth required people to custom train models which was very inefficient. better methods have popped up after that. ControlNet, Adapters, Composer(pending release).  finetuning models to my understanding is not needed as of now. You can control, style, image composition, colour scheme without finetuning a model for usecases similar to flair. ‎[3/21/23, 11:10:26] Kishore GenAI: ‎image omitted
Kishore GenAI|2023-03-21 11:32:38|[PHONE] I missed this. Primarily speaking training a model on an object and trying to recreate it during the generation process fails when the product fidelity cannot be compromised. The only method which exists as of today is to start the init image of the pipelines and then create the rest of the image. Even when you do that you can see that the product will get changed because all the SD algorithms work in latent space and not in pixels space. This compression and reconstruction of the image makes it impossible to get the original product image which is present in init image. however the solution is very straightforward . All you need to do is copy paste the pixels on the final image where the product exists. No need for LORA or anything of that sort.   However, this means that there is no existing method through which you can recreate a product in different angles. The angles are preset and that mean your prompts, reference images and the rest of the inputs need to be suitable your product image.
Shubhi Saxena|2023-03-21 11:32:51|Is anywhere working on apps like these : https://news.ycombinator.com/item?id=35236275  code search/document search/etc? I had a few questions.
Ravi Theja|2023-03-21 11:35:07|Worked on document search.
Amogh V|2023-03-21 11:39:43|Thanks for explaining! I was thinking about this problem statement the other day. What if we take a pic of the product photo in the exact orientation we want, remove the background and inpaint a new one around the product? Haven't tried out Booth ai myself though
Ravi Theja|2023-03-21 11:40:09|They are using LLM + embedding approach. Guess they use LangChain as well under the hood. ‎[3/21/23, 11:43:23] Kishore GenAI: ‎image omitted ‎[3/21/23, 11:43:24] Kishore GenAI: ‎image omitted ‎[3/21/23, 11:43:24] Kishore GenAI: ‎image omitted
Amogh V|2023-03-21 11:44:53|Yes this is exactly what I was talking about ‎[3/21/23, 11:46:04] Amogh V: ‎image omitted ‎[3/21/23, 11:46:05] Amogh V: ‎image omitted
Amogh V|2023-03-21 11:46:46|And that's why you will have these differences. This will work for e-commerce folks at all. Especially for high value items like furniture
Kishore GenAI|2023-03-21 11:47:37|it will or won't? My understanding is that it won't work.
Amogh V|2023-03-21 11:48:11|It definitely WON'T work! Sorry, did a typo in the worst possible place 😅
Amogh V|2023-03-21 11:52:49|But here's a method that I am reasonably confident WILL work - Users can use a Nerf capture app like Luma to generate a 3D model from any novel viewpoint. It's as easy as walking around a product while taking a video and takes like 30s. Perhaps extract a mesh from the capture because that's easier to render in a browser than Nerf. Then in your product let the user rotate and orient the accurately captured product however they want. Take a snapshot of it without background. Then mask and inpaint like you did.
Amogh V|2023-03-21 11:56:11|This will remove all limitations. Highly accurate and infinite product photo generation from any angle in every aspect ratio for all your visualization needs. I led product at Avataar doing 3D for e-commerce for 2 years so I am very confident this can be done. Getting the capture right is that hardest part which Luma seems to have done well. So has Avataar but they haven't released 🤷‍♂️
Soumyadeep Mukherjee|2023-03-21 11:56:24|[PHONE] isnt simple bg subtraction and some bg improvement good enough for ecommerce? :thi  Maybe it depends on product.
Soumyadeep Mukherjee|2023-03-21 11:56:50|[PHONE] s images also seemed mostly really smart bg replacement only.
Kishore GenAI|2023-03-21 11:56:58|[PHONE] you can read up on this as well. https://www.deepset.ai/blog/build-a-search-engine-with-gpt-3 This is by deepset and they have a framework called Haystack. I was looking into it in June of last year, and it's pretty good. Suggest you check it out as well.
Soumyadeep Mukherjee|2023-03-21 11:57:03|There is a slight halo that is visible if you stare at it long enough 😅
Kishore GenAI|2023-03-21 11:57:20|Yes, because that is what it is. It is BG replacement.
Soumyadeep Mukherjee|2023-03-21 11:57:47|I was using similar method too for characters in a scene but this halo hurt the continuity. I am moving to using controlnet for this. It looks far more realistic then.
Kishore GenAI|2023-03-21 11:57:56|A lot frankly. But that was mainly cause the original lighting of the image had it and I didn't wan't to spend time to remove it.
Kishore GenAI|2023-03-21 11:58:15|I am using controlnet
Kishore GenAI|2023-03-21 11:58:21|The images are from using controlnet
Soumyadeep Mukherjee|2023-03-21 11:58:24|Yea. Lighting causes it. Magic brushing with smudge over it removes it usually.
Soumyadeep Mukherjee|2023-03-21 11:58:33|Ah really. 🤔
Soumyadeep Mukherjee|2023-03-21 11:58:54|Maybe mine have a halo too. lemme check 😅
Amogh V|2023-03-21 11:59:21|Yes that's the ideal case if you already have the product photo in the exact orientation you want. Real world situation is that product photography is a whole other expensive initiative usually done by a different team. Marketing which creates the final images comes in much later and they have to make do with what they already have. Like there's a whole workflow for this thing.
Soumyadeep Mukherjee|2023-03-21 11:59:47|^Yea. I was asked to once build a 3D rotating platform to take ecommerce photos :P
Soumyadeep Mukherjee|2023-03-21 11:59:59|For constant lighting, bg etc.
Amogh V|2023-03-21 12:00:24|So if you have a 3D capture that the marketing team can put into ANY orientation to generate images that's a big advantage.
Soumyadeep Mukherjee|2023-03-21 12:00:50|3D is hard for a lot of use-cases like clothes, grocery no?
Amogh V|2023-03-21 12:01:15|Your eyes will fall out if I show you Nerf captures of clothes and grocery
Soumyadeep Mukherjee|2023-03-21 12:02:26|Hahaha. I have not done nerf but in my freelancing days, number of folks who reached out to me for 3d capture of clothes expecting realistic results was 🙏
Soumyadeep Mukherjee|2023-03-21 12:03:01|"And then folks also wanted these clothes to go over humans and look ""natural"""
Soumyadeep Mukherjee|2023-03-21 12:03:49|"I might even have a long mail explaining ""Cloth Simulation is not a solve problem"". Definitely not in freelancing monies :P ‎[3/21/23, 12:05:09] Amogh V: ‎GIF omitted"
Amogh V|2023-03-21 12:05:27|😛
Sudharshan GenAI|2023-03-21 12:05:43|Danny postama is doing to decently well now
Sudharshan GenAI|2023-03-21 12:06:25|Catching up with these messages
Amogh V|2023-03-21 12:09:31|I'll add my colleague Bharath here who can go even deeper into the nuances of product capture and visualization for e-commerce. [PHONE] he can share a lot of great inputs about product imaging for e-commerce. He was interacting with a lot of e-commerce store owners and product photographers from enterprise to small Shopify merchants ‎[3/21/23, 12:10:08] Kishore GenAI: ‎image omitted
Aniket Kamath Nexus IIT B|2023-03-21 12:13:56|Hey folks!  Hosting a small informal AI meet-up this weekend on Saturday afternoon (25th March) from 11:30 AM onwards in Koramangala, Bangalore. If you are a founder, builder, or just hacking in AI - this is for you!  Sign up here - https://partiful.com/e/RJ7SGI35jhCKAGNcCYJR
Ajat Prabha|2023-03-21 12:15:00|‎Ajat Prabha joined using this group's invite link
Kishore GenAI|2023-03-21 12:16:54|Also [PHONE] The code for this is still pending. but you can look into this project as well. https://dolorousrtur.github.io/hood/
Amir Nagri|2023-03-21 12:18:23|the demos are 🙌
Soumyadeep Mukherjee|2023-03-21 12:27:35|Damn. This looks good. But lets see how replicable it is. I am a little skeptical. 😅
Soumyadeep Mukherjee|2023-03-21 12:28:14|Damn this is also my lab 😂
~ Jaswanth|2023-03-21 12:33:47|‎~ Jaswanth joined using this group's invite link
~ Siddish|2023-03-21 12:34:07|‎~ Siddish joined using this group's invite link
Dev Aggarwal|2023-03-21 12:59:10|‎Dev Aggarwal joined using this group's invite link
Karan Ganesan luma.ai|2023-03-21 13:24:47|‎Karan Ganesan luma.ai joined using this group's invite link
~ Bharath|2023-03-21 13:49:38|‎~ Bharath joined using this group's invite link
Kunal Bhatia Hexo|2023-03-21 15:00:07|‎Kunal Bhatia Hexo joined using this group's invite link
Amogh V|2023-03-21 17:36:06|Welcome [PHONE]. Bharath is a colleague of mine from Avataar who has worked extensively on generating 3D models using Nerf for e-commerce. Bharath, we've been talking about rendering 3D clothing and using screenshots of Nerf viewpoints + Stable Diffusion generated backgrounds for product photography and marketing
~ Bharath|2023-03-21 17:42:04|Ah, I see.
~ Bharath|2023-03-21 17:42:09|Hello everyone!
Shubham Sharma 2012C6|2023-03-21 18:53:12|https://a16z.com/2022/11/17/the-generative-ai-revolution-in-games/
Dev Aggarwal|2023-03-21 19:01:47|Hey Bharath! Really excited to see someone work in the nerf space. Thoughts on zero123? https://zero123.cs.columbia.edu/
Aditya Agrawal SuperU|2023-03-21 19:20:50|Hi All, Anyone in here who is interested in https://www.adept.ai/ and similar space? This is a different space than generative AI but will be game changer in how we use computers.
Rohit Ganapathy|2023-03-21 19:23:47|Yes! afaik this was always a research area in RL. https://proceedings.mlr.press/v70/shi17a.html. Curious to learn how they’re going about it.
Dev Aggarwal|2023-03-21 19:28:59|This space is very exciting! Even more so that this can actually be done via prompt engineering- https://github.com/microsoft/visual-chatgpt
Pranjal Mehta|2023-03-21 19:40:53|[PHONE] and myself :)
~ Arsalaan|2023-03-21 20:02:15|The model at adept is pretty good
Nirant|2023-03-21 20:03:01|Someone replicated Adept
Nirant|2023-03-21 20:03:17|Using GPT4 API, same control as GPT4:  https://youtu.be/c1UClT-P1uA
Sudharshan GenAI|2023-03-21 20:03:58|I don’t think adept uses VQA or image captioning  - looks like it works with the DOM
Sudharshan GenAI|2023-03-21 20:04:44|Might be wrong, but that’s the impression I got when I played with it back in august
Nirant|2023-03-21 20:06:14|August 2022, might as well have been last century in LLM years 😅
Sudharshan GenAI|2023-03-21 20:06:57|Hahaha true
Nirant|2023-03-21 20:07:00|Folks in US can sign up for Google's BARD (waitlist) here:  https://bard.google.com/
Sudharshan GenAI|2023-03-21 20:07:04|But VQA is still prett shit right
Sudharshan GenAI|2023-03-21 20:07:17|I tried blip-2 from Salesforce and it was average
Nirant|2023-03-21 20:07:18|^That's Google's attempt at making GPT3
The GenerativeAI Group|2023-03-21 20:27:48|‎New participants need admin approval to join this group.
Amogh V|2023-03-21 20:44:14|Predictably, Adobe is going to drop something big in generative AI. It's a tough fight for horizontal gen AI startups. Adobe ships solid products https://twitter.com/bilawalsidhu/status/1638172373244411906?t=BZZIyqEzz98k58v3AaOz7g&s=19
Shubham Sharma 2012C6|2023-03-21 20:44:31|https://mobile.twitter.com/ESYudkowsky/status/1635577836525469697
Sudharshan GenAI|2023-03-21 20:47:34|idk, it's adobe -people will avoid lol
Nirant|2023-03-21 20:48:09|Only people believing that Alpaca is as good text-davinci-003 are the ones who've not tried both.
Amogh V|2023-03-21 20:48:16|Creative world runs on Adobe. Nobody avoids. At max they pirate
Amogh V|2023-03-21 20:51:34|Niche and industry specific vertical AI products are fantastic markets for startups right now. Like textile design, which uses Adobe products, but only as a part of a deeper workflow in which a generative AI startup can capture the entire stack. From tilable texture generation to fabric pattern generation.  But AI typography, logo maker and other such horizontal products will find it quite hard to crack distribution because of Adobe's distribution. A Figma doesn't happen every day. But that gets eaten up by Adobe too.
Soumyadeep Mukherjee|2023-03-21 21:03:23|I agree also adobe is the OG computer vision company. They literally are deepest in computer vision tools.  They also might have best legal data to give the best models.
Soumyadeep Mukherjee|2023-03-21 21:05:52|You couldnt be a creative without adobe tools before gen ai.  It is the Microsoft office for creativity. But then like office, I don’t think they’ll make their weights public. 😞
Amogh V|2023-03-21 21:07:02|Yeah they're going to play it like Microsoft.
Amir Nagri|2023-03-21 21:08:28|For a large corporate company, it's overcoming the inertia is the challenge  With 1000s of employees on their payroll, can't recall any significant paper related to stable diffusion from Adobe  But it's see, elephants will have to dance or die
Shashank Generative AI Group|2023-03-21 21:10:15|products which focus on specific workflows like Descript, RunwayML will carve out some market share, i think.
Shashank Generative AI Group|2023-03-21 21:11:41|otoh, crazy to see how Canva is not visible in the GenAI space. although they launch stuff only once a year, still idk if they have a focus on ML research or not.
~ Anurag|2023-03-21 21:16:48|https://youtu.be/DiGB5uAYKAg
~ Anurag|2023-03-21 21:17:09|Nvidia livestream is live Rn
Amogh V|2023-03-21 21:17:10|The criteria for these horizontal products to succeed is that they have to enable a non expert to create output that hits ALL 3 criteria - fast, cheap and good quality. A designer using Photoshop or Premier Pro currently can hit only 2/3. Fast + cheap is rarely good, and so on. Canva worked because it let an accountant create a classy looking event poster in minutes. There are some ways to do this, true. Like radically new UX, template based creation and having the best model in production consistently. But it's very very hard.
Sudharshan GenAI|2023-03-21 21:24:55|Okay holy shit firefly is impressive
Sudharshan GenAI|2023-03-21 21:24:58|This is so good.
Shubham Sharma 2012C6|2023-03-21 21:25:15|Do you have access?
Sudharshan GenAI|2023-03-21 21:25:32|No just checked the features out and wrote a thread on it  https://twitter.com/sudu_cb/status/1638206330585358339
Sudharshan GenAI|2023-03-21 21:25:54|But they basically are problem first.
Sudharshan GenAI|2023-03-21 21:26:29|Not for fun, or entertainment. How do you use AI Art models effectively to solve problems (vs entertainment)
Shubham Sharma 2012C6|2023-03-21 21:29:24|This is mostly catch up on mid journey and runway, right?
Sudharshan GenAI|2023-03-21 21:30:26|Nope
Sudharshan GenAI|2023-03-21 21:30:38|It’s competing with designer and canva
Sudharshan GenAI|2023-03-21 21:30:48|But completely overthrew them
Amogh V|2023-03-21 21:37:10|⚠️➡️🧵 🙄
Soumyadeep Mukherjee|2023-03-21 21:48:43|I had the same question 😅
Harsh Gupta Felvin|2023-03-21 21:51:14|This is Yudkowsky's propoganda trying to make the business model of building foundational models less attractive
Harsh Gupta Felvin|2023-03-21 21:51:41|In the thread he explicitly said if this was pointing in the other direction, he wouldn't have tweeted it 😂
Swastik Banerjee|2023-03-21 21:55:34|The ImageCaptioning model it’s using, i.e., BLIP, is pretty bad imo. Is there a better image-captioning model?
Abhishek Maiti|2023-03-21 22:00:36|this worked very well for me https://huggingface.co/spaces/fffiloni/CLIP-Interrogator-2
Shivendu Kumar|2023-03-21 22:30:09|Or use VPN.
Sudharshan GenAI|2023-03-21 22:31:41|I know lol, I didn't take it seriously but saw the features. Blew my mind
Sudharshan GenAI|2023-03-21 22:32:07|Adobe have done a very good job
Sudharshan GenAI|2023-03-21 22:32:24|Open to changing my opinions and not going to be rigid
Rohan Manchanda|2023-03-21 22:33:02|https://twitter.com/vinniemourax/status/1638218512760971277?s=20 have people seen this?
Rohan Manchanda|2023-03-21 22:33:17|https://www.youtube.com/watch?app=desktop&v=DiGB5uAYKAg&feature=youtu.be
Swastik Banerjee|2023-03-21 22:54:14|Is there an API version of this? [PHONE]
Abhishek Maiti|2023-03-21 22:54:54|I converted this into an API, I will send you the script if i find it.
Swastik Banerjee|2023-03-21 22:56:49|I found this, but seems like a task to integrate: https://github.com/rmokady/CLIP_prefix_caption
Shashank Generative AI Group|2023-03-21 23:01:12|i think replicate also has this ‎[3/21/23, 23:05:28] ~ Arsalaan: ‎image omitted
Ravi Theja|2023-03-21 23:10:29|People started interacting with BARD already 😅😅😅
~ Arsalaan|2023-03-21 23:10:53|Twitter is fastest
~ Arsalaan|2023-03-21 23:11:06|I tested lamda 3 months back only
~ Arsalaan|2023-03-21 23:11:17|It's worst model
Abhishek Maiti|2023-03-21 23:13:55|this maybe useful https://gist.github.com/ovshake/69efb594f3b1e8d98b34687b16916145
~ Innovator|2023-03-21 23:15:38|‎~ Innovator left
Swastik Banerjee|2023-03-21 23:37:12|Link?
Shashank Generative AI Group|2023-03-22 00:30:42|this one probably https://replicate.com/pharmapsychotic/clip-interrogator
~ Prateek|2023-03-22 05:38:43|‎~ Prateek requested to join ‎[3/22/23, 08:39:21] Vishal Tripathi NSS 2013: ‎image omitted
Vishal Tripathi NSS 2013|2023-03-22 08:46:34|Also sorry, have been lurking, didn’t introduce myself. Vishal Tripathi, Venture Investor, worked on a fund of funds strategy for Google Ventures - Plexo Capital. Currently with Legacy Venture, investors in many of the funds people have mentioned above (Sequoia, A16z, Matrix, Accel, True, etc). Love the conversation and learning a lot about the space, also building tools on the side/over weekends. Someone mentioned Yohei (from untapped VC) above, he’s a close friend and I’ve collaborated with him on some of those GPT tools and love learning about these new use cases.
Achal Mall|2023-03-22 08:50:57|Hi,  Any YouTube vid, blogs on 1. How to build features /  code on top of gpt3 2. How to integrate gpt3 or variants on production?? Things to take care of , API response times etc??
Achal Mall|2023-03-22 08:51:43|I have a proof of concept script that I would like to take to customers 😃.
Nirant|2023-03-22 09:20:05|Fun blog post for folks who are in marketing or content or do a lot of writing work in other ways:  fast.ai/posts/2023-03-20-wittgenstein.html
Nirant|2023-03-22 09:20:58|The last line of this link is: This will make certain people really mad
Mannan Amroliwala|2023-03-22 10:02:19|Wowww! ‎[3/22/23, 10:11:53] Amogh V: ‎video omitted
Nirant|2023-03-22 10:13:31|Damn, this is so good. Me want!
~ Anurag|2023-03-22 10:14:44|I hope its as good as it appears, would be sooo coool
Shashwat TDC|2023-03-22 10:14:45|Infinite customization is actually a pain. Firefly imo is a great example of limiting functionality and making it more useful than the competitors.
Amogh V|2023-03-22 10:26:21|Pre Firefly Adobe was doing all its ML inference on user's local system? Can anyone confirm? I guess that changes with Firefly?
~ Anurag|2023-03-22 10:28:05|Adobe express is not local, you could do stuff there online.  I guess firefly is built on top of that
Sudharshan GenAI|2023-03-22 10:28:59|Hey Vishal, nice to meet you!  I was the one who mentioned Yohei - we’re building  a tool to make creating executive summaries easy. Similar to what he shared.  I’m chatting with Yohei now, would love to know your thoughts too
Vishal Tripathi NSS 2013|2023-03-22 10:30:56|DMing :)
~ Bharath|2023-03-22 10:31:23|Just came across this paper today from another route as well. Planning to try it on HF and look through it
Sudharshan GenAI|2023-03-22 11:35:59|Can add him here
Sudharshan GenAI|2023-03-22 11:36:06|He published in CVPR 2023
Sudharshan GenAI|2023-03-22 11:36:54|https://www.cs.umd.edu/~shishira/Nirvana/nirvana.html
Sudharshan GenAI|2023-03-22 11:38:10|Works with video compression, he’s a good friend of mine
Ojasvi Yadav|2023-03-22 12:13:56|‎Ojasvi Yadav requested to join
~ Nitish Alodia|2023-03-22 13:21:52|‎~ Nitish Alodia requested to join
~ Nitish Alodia|2023-03-22 13:23:07|‎~ Nitish Alodia joined using this group's invite link
Ojasvi Yadav|2023-03-22 13:23:09|‎Ojasvi Yadav joined from the community
~ Prateek|2023-03-22 13:23:12|‎~ Prateek joined using this group's invite link
Sudharshan GenAI|2023-03-22 14:53:16|https://github.com/microsoft/MM-REACT  ChatGPT with multimodal reasoning
Sudharshan GenAI|2023-03-22 14:53:27|Demo looks good and better than BLIP-2
Kaushik Bokka|2023-03-22 15:17:47|tf, they literally cloned the langchain repo in it
Dr. Ashith Generative AI WA Group|2023-03-22 15:18:14|https://huggingface.co/spaces/microsoft-cognitive-service/mm-react
Dr. Ashith Generative AI WA Group|2023-03-22 15:18:47|i uploaded my picture and asked it to describe it to describe me in close detail. It did a decent job.
Sudharshan GenAI|2023-03-22 15:44:01|send results?
~ Abhishek Sharma|2023-03-22 17:27:17|‎~ Abhishek Sharma requested to join
Rohit Ganapathy|2023-03-22 17:31:34|folks noob question but has openAI exposed multimodal inputs to GPT4? I see that I can only feed chatGPT plus text. ‎[3/22/23, 17:35:34] Rohit Ganapathy: ‎image omitted
Shashank Generative AI Group|2023-03-22 17:45:00|not yet. very few have access to visual input right now.
Rohit Ganapathy|2023-03-22 17:45:29|ah understood thanks!
~ All ways 😄Happy|2023-03-22 17:46:27|‎~ All ways 😄Happy left
Dr. Ashith Generative AI WA Group|2023-03-22 18:31:46|anyone working in any projects related to healthcare?
Dev Aggarwal|2023-03-22 18:49:17|Yes
Siddharth Agarwal|2023-03-22 19:07:00|Do tell.
Arnav Bansal Replit|2023-03-22 21:56:32|‎Arnav Bansal Replit requested to join
~ Srijan Saxena 😎|2023-03-22 22:28:15|‎~ Srijan Saxena 😎 requested to join
Achal Mall|2023-03-23 09:43:30|‎Achal Mall left
Ojasvi Yadav|2023-03-23 13:20:22|Patiently waiting for them to let everyone use it 😂
Ojasvi Yadav|2023-03-23 13:25:46|Oh I realised I did not introduce myself. I'm Dukaan's head of AI.   We've implemented many tools built on generative models. Few notable ones are product description generator, SEO tags generator.  Once they enable multimodal inputs we're planning to push more features.  Outside of work I'm also regular with sideprojects in generative AI. Most notable one being JadooSnap.
Ojasvi Yadav|2023-03-23 13:26:03|If anyone's interested in seeing Jadoosnap you can use the link below
Ojasvi Yadav|2023-03-23 13:26:09|JadooSnap.com
~ Nj|2023-03-23 13:27:18|‎~ Nj requested to join
Sudharshan GenAI|2023-03-23 13:27:48|Have seen this, great work!  And welcome :)
Sudharshan GenAI|2023-03-23 13:28:45|Going to take some time for public access - there are a few companies using it already
Ojasvi Yadav|2023-03-23 13:29:44|Any way we can request access for Dukaan?
~ Aman|2023-03-23 13:35:52|https://twitter.com/T_Goody3/status/1638203321704955904?t=8aQye9lDksWh81DJjhZGlg&s=08  Did anyone see this? There are some reasons in the comments
~ Srijan Saxena 😎|2023-03-23 13:36:26|‎~ Srijan Saxena 😎 joined using this group's invite link
Arnav Bansal Replit|2023-03-23 13:36:26|‎Arnav Bansal Replit joined using this group's invite link
~ Nj|2023-03-23 13:36:26|‎~ Nj joined using this group's invite link
~ Abhishek Sharma|2023-03-23 13:36:26|‎~ Abhishek Sharma joined from the community
The GenerativeAI Group|2023-03-23 13:36:26|‎You turned off admin approval to join this group
Dev Aggarwal|2023-03-23 13:50:16|Hoping to get a contract with the gates foundation to build a Whatsapp chatbot to guide rural nurses in India.   Works by using embeddeding search over a pdfs of who guidelines + gpt. Also building the whisper + translate pipeline for voice notes.  Demo - https://gooey.ai/video-bots/?example_id=hho7u0f4
Shubham Sharma 2012C6|2023-03-23 13:58:11|Rural india would need Hindi
~ Arvind Sankar|2023-03-23 13:58:29|‎~ Arvind Sankar joined using this group's invite link
Nirant|2023-03-23 13:58:33|Hindi is supported by both GPT4 and Whisper, so quite doable
Nirant|2023-03-23 13:58:52|Most popular Indian vernacular languages are in fact
Dev Aggarwal|2023-03-23 13:59:16|We’re also using bhashini - an indian government funded research project that has a fine tuned whisper model for hindi
Shubham Sharma 2012C6|2023-03-23 13:59:23|The hindi results of gpt are not as great as english
Pranjal Mehta|2023-03-23 13:59:40|Slightly confused then by Bill Gates writing about an Indian startup working on LLMs for Indian languages
Pranjal Mehta|2023-03-23 13:59:50|This is probably why
Dev Aggarwal|2023-03-23 14:00:29|Yes, same findings. Plus the source documents are all in English too. Using google translate so that gpt only ever sees english
Nirant|2023-03-23 14:01:21|Hmm. Doesn't look like it with GPT4 — original ChatGPT was worse. Using Google Translate would invariably add error. Propose a test set on this — why discuss opinions when we can run experiments!
Dev Aggarwal|2023-03-23 14:01:45|Openai/evals ✨
Sumod K Mohan|2023-03-23 14:59:19|‎Sumod K Mohan joined using this group's invite link ‎[3/23/23, 15:11:04] Dr. Ashith Generative AI WA Group: ‎image omitted
Dr. Ashith Generative AI WA Group|2023-03-23 15:12:16|Anybodys got any idea how to achieve this?
Amir Nagri|2023-03-23 15:25:46|Change the tint of image to RGB (may be converting to grey scale then colorify it), add noise and then denoise guided by prompt a photo of baby  🤔
Dev Aggarwal|2023-03-23 15:26:28|Controlnet / depth2img
Amir Nagri|2023-03-23 15:31:04|This is too clear ultra sound
Dhruv Anand|2023-03-23 15:31:52|might create false expectations for parents 😅
Amir Nagri|2023-03-23 15:31:56|unet came out of medical imaging, so i think in future, rather than taking home ultra sound, you might take back a generated photo realistic image
Nirant|2023-03-23 15:32:29|Why stop there? Ultrasound → Baby Photo → Age by X years is a known dataset
Amir Nagri|2023-03-23 15:32:51|That as well, bachche ki shakal to pregnancy scanning se mil hi nahi, hospital be bacha badal diya hai 😂
Gokul Krishnan|2023-03-23 16:00:44|Link? ‎[3/23/23, 16:01:41] Nirant: ‎GIF omitted
Gokul Krishnan|2023-03-23 16:18:57|You jest, but I'll wait for the next medical provider data breach to get this dataset ‎[3/23/23, 16:19:10] Gokul Krishnan: ‎GIF omitted
Dev Aggarwal|2023-03-23 18:47:15|https://gooey.ai/ai-photo-editor/?run_id=4ndpy7e0&uid=Nli0J2dP80WU3sdJ9RCw3DeNvIT2  🙂
~ Rohan|2023-03-23 19:30:59|Regarding the Adobe products that someone else mentioned, it’s out now
~ Rohan|2023-03-23 19:31:02|https://www.linkedin.com/posts/alexandru-costin-a4367_adobefirefly-ugcPost-7043965991910854656-pjbp?utm_source=share&utm_medium=member_ios
~ Dx|2023-03-23 20:21:50|‎~ Dx joined from the community ‎[3/23/23, 23:09:55] Amogh V: ‎image omitted ‎[3/23/23, 23:09:56] Amogh V: ‎image omitted ‎[3/23/23, 23:09:56] Amogh V: ‎image omitted ‎[3/23/23, 23:09:57] Amogh V: ‎image omitted
Anagh Prasad|2023-03-24 00:08:08|What was the prompt :) ‎[3/24/23, 00:12:18] Amogh V: ‎image omitted
Sudharshan GenAI|2023-03-24 00:13:17|What model?
Anagh Prasad|2023-03-24 00:14:11|Omg the second prompt 😂😂  “Extra fingers”
Amogh V|2023-03-24 00:15:00|But this prompt and neg prompt alone isn't enough. It won't give you the robot heads or the glowing eyes, colour tone or the exact kind of armour and rifle that you want. So you need to do a lot of composition iterations ‎[3/24/23, 00:17:01] Amogh V: ‎image omitted
Amogh V|2023-03-24 00:18:12|I've created my own now based on what kind of output I want. It's a checkpoint merge between deliberate v2, dreamlike_photoreal v2 and a few others
Amogh V|2023-03-24 00:19:44|The style reference for this second pic was not in the prompts, rather it was a Rembrandt painting, which is why he's wearing medieval looking plate armour along with what looks like leather and chainmail
Chirag Jain|2023-03-24 08:52:56|https://openai.com/blog/chatgpt-plugins
Ananth Radhakrishnan 2012A7|2023-03-24 09:10:30|Curious to see if this goes the way of ios/android apps or Alexa skills.
Chirag Jain|2023-03-24 09:44:48|I would bet better success than  Alexa Skills anyday  but the paradigm of building software on almost exclusively unstructured text output feels  odd (yet) 😅
~ Pravin|2023-03-24 10:04:24|‎~ Pravin joined using this group's invite link
Shashwat TDC|2023-03-24 10:37:44|https://platform.openai.com/docs/plugins/introduction  Natural language + API => becoming of a search engine within chatgpt  Don't you guys think chatgpt plugins will put chatgpt in head-on competition with Bing search?
Pranjal Mehta|2023-03-24 11:35:35|[PHONE]
Vijay Aggarwal Bharatpe CTO|2023-03-24 12:59:49|‎Pranjal Mehta added Vijay Aggarwal Bharatpe CTO
Pranjal Mehta|2023-03-24 13:00:57|[PHONE] is working on his next company. He was CTO at BharatPe until recently.
Vijay Aggarwal Bharatpe CTO|2023-03-24 14:14:52|Thanks Pranjal!
Vijay Aggarwal Bharatpe CTO|2023-03-24 14:15:08|Hi everyone! Glad to be here! 🙂
~ Rashmi|2023-03-24 15:58:49|‎~ Rashmi joined using this group's invite link
Mannan Amroliwala|2023-03-24 15:58:50|Very very unrelated: Has anyone here worked on Firestore?
Mannan Amroliwala|2023-03-24 15:58:50|We’re stuck at one place and need some help
Nirant|2023-03-24 16:00:08|Very off topic 😅  Please message Mannan directly, instead of replying here ‎[3/24/23, 16:35:24] Sudharshan GenAI: ‎image omitted
~ Mohnish Landge|2023-03-24 17:31:48|‎~ Mohnish Landge joined using this group's invite link
Aniket Kamath Nexus IIT B|2023-03-24 18:33:23|Hey everyone, got quite a bunch of people who showed interest in attending this. There are a lot of people in this group who are hacking projects on the side, DM me if any of you would want to talk (or show demos) about your projects tomorrow, would love to host 🙌🏻
~ Srijan Saxena 😎|2023-03-24 19:31:40|Can you share that message again, some of us joined the group after the message was sent 😬
Aniket Kamath Nexus IIT B|2023-03-24 19:33:50|Hey folks!  Hosting a small informal AI meet-up this weekend on Saturday afternoon (25th March) from 11:30 AM onwards in Koramangala, Bangalore. If you are a founder, builder, or just hacking in AI - this is for you!  Sign up here - https://partiful.com/e/RJ7SGI35jhCKAGNcCYJR
Aniket Kamath Nexus IIT B|2023-03-24 19:33:52|here you go
~ Srijan Saxena 😎|2023-03-24 19:34:00|Thanks 🫡
~ Rikkin Majani|2023-03-24 20:30:03|‎~ Rikkin Majani joined using this group's invite link
Shubham Sharma 2012C6|2023-03-24 20:49:26|https://analyticsindiamag.com/the-hidden-cost-of-chatgpt-for-indian-languages/ Is this cost analysis accurate?
Harsh Gupta Felvin|2023-03-24 20:51:56|Yes
Harsh Gupta Felvin|2023-03-24 20:52:15|You can try it out here
Harsh Gupta Felvin|2023-03-24 20:52:15|https://platform.openai.com/tokenizer
Shubham Sharma 2012C6|2023-03-24 21:01:59|Got it. Thanks
Swastik Banerjee|2023-03-24 21:37:27|does anyone know if opencv videocapture() can connect to an external iOs camera? old documentation and stack exchange says it cannot. Was it ever updated, or is there a workaround?
~ ボルツザマク|2023-03-24 21:46:24|Not sure about iOs but in android you can capture using any wifi camera app, if there is same kind of app for ios then I think you can do this.
Anirudth N|2023-03-24 21:59:57|Do you interact with GPT in English or directly in vernacular languages?
Shashwat TDC|2023-03-24 22:18:33|Direct vernacular is supported
Dev Aggarwal|2023-03-24 23:49:57|Doesnt have very good performance though
Lavish 2017|2023-03-25 00:07:13|‎Lavish 2017 joined using this group's invite link
Shashwat TDC|2023-03-25 00:09:36|Can try few shot learning for training
Dev Aggarwal|2023-03-25 00:45:20|I ran out of context length before I could stuff enough context for it to have significant improvements 😂  But I think even with few shot learning, the vocabulary and finesse of writing is just not there yet
~ Karan|2023-03-25 03:18:51|‎~ Karan joined using this group's invite link
~ santhosh|2023-03-25 09:51:36|‎~ santhosh joined from the community
~ Diwakar|2023-03-25 11:11:32|‎~ Diwakar joined using this group's invite link
~ Arpit Maheshwari|2023-03-25 12:49:11|‎~ Arpit Maheshwari joined using this group's invite link ‎[3/25/23, 18:54:48] Amogh V: ‎image omitted ‎[3/25/23, 18:54:48] Amogh V: ‎image omitted
Jay Pokarna 2014 BPCC|2023-03-25 18:57:02|What was your workflow? Like what tools did u use?
Amogh V|2023-03-25 19:14:49|Completely using Stable Diffusion. Workflow was first using text2img with controlnet depth map of this image. I got the depth map from Clipdrop's API because it's really good. Thanks to Sudharshan's tweet for this tip! Fixed the red background using this.  2. Moved over to inpainting sketch feature which lets you influences the colour of your generation based on colour of the inpainting mask (my favourite feature lately). This gave the hand a blue texture. Lot of tweaking controls to get the hand's features like knuckles and veins. 3. Moved over to img2img to stylize it further Overall about 100 generations to achieve a result I was creatively happy with.
Dev Aggarwal|2023-03-25 19:15:30|Do you use automatic1111 for all this? Or just code
Amogh V|2023-03-25 19:16:15|Automatic1111. You would go mad doing this with code 😅 Wrote a quick script to call the clipdrop API though
Dev Aggarwal|2023-03-25 19:19:00|Makes sense. Have you played around with langchain agents / chatgpt plugins?  The grand idea is that if we give stable diffusion, controlnet, clipdrop, img2img etc as tools to chatgpt, there’s a very interesting possibility where we can just write this workflow in english and chatgpt would execute the pipeline automatically without needing code or automatic1111
Sudharshan GenAI|2023-03-25 19:28:45|"I think certain things are easier and more fun with a UI - when you need more control and direction a UI would do  Plugins would do well for linear actions - ""book an uber"""
Sudharshan GenAI|2023-03-25 19:29:03|Neat! The depth maps have more control
Amogh V|2023-03-25 19:29:22|The only problem with this is that you need to run iteration loops in every step until you are satisfied with the output before moving to the next step. Doing 1, 2, 3 successively would not work. Also with visuals chatGPT can't decide whether your output is good enough. You, the human needs to decide that based on the context of where you are using it in - as art, as marketing material, as a photoshoot. Code is deterministic. It either runs with expected time/space complexity or it doesn't. Art by nature is non deterministic. The human decides whether the output satisfies the emotional response they were looking for, which is what makes one an artist.
~ Bharath|2023-03-25 19:30:14|And this is nothing new for artists: retakes are common
Amogh V|2023-03-25 19:35:58|Personally what fascinates me more about AI generating art than generating code is how a deterministic input (auto encoder, model weights, controlnet algorithms etc) can give infinite non deterministic output.
Dev Aggarwal|2023-03-25 19:37:11|I believe the non deterministic output still stems from a classical random number generator :) if you keep the seed constant, its very much deterministic.
Ojasvi Yadav|2023-03-25 19:38:06|Yep
Ojasvi Yadav|2023-03-25 19:38:28|Simple but quite useful, the entire concept of seeds
Amogh V|2023-03-25 19:38:45|To someone who has control over enough constraints the entire universe becomes deterministic
Amogh V|2023-03-25 19:39:08|There are in theory infinite seeds
Dev Aggarwal|2023-03-25 19:40:01|Oh man, this debate itself is infinite 😆  https://mitpress.mit.edu/9780262525794/free-will/
~ Anurag|2023-03-25 19:47:01|‎~ Anurag joined using this group's invite link
Pratyush Choudhury|2023-03-25 23:06:23|‎Pratyush Choudhury joined using your invite
Shibangi Barua Budweiser Teetotaler|2023-03-25 23:06:58|‎You added Shibangi Barua Budweiser Teetotaler
Micheil|2023-03-25 23:47:43|‎You added Micheil
Sachin Legaltech|2023-03-26 02:56:47|https://www.youtube.com/watch?v=L_Guz73e6fw
Sachin Legaltech|2023-03-26 02:58:10|No technical details (few hints here and there); but lots of philosophical nuggets about how Sam Altman and by extension OpenAi is thinking about development trajectory
~ Vartika|2023-03-26 09:15:47|‎~ Vartika joined using this group's invite link
~ Vidyasankar|2023-03-26 09:32:50|‎~ Vidyasankar joined using this group's invite link
~ Phaneendra B|2023-03-26 10:21:06|‎~ Phaneendra B joined using this group's invite link
~ pt|2023-03-26 12:25:06|‎~ pt joined from the community
~ blingstaysgoa|2023-03-26 18:24:20|‎~ blingstaysgoa joined using this group's invite link
~ Pradyumna Bang|2023-03-26 18:43:24|‎~ Pradyumna Bang joined using this group's invite link
Shubham Sharma 2012C6|2023-03-26 19:17:44|https://www.youtube.com/@aajtakai/videos
Nipun Sadvilkar|2023-03-26 19:26:44|As we all work on AI and have been inundated with new AI advancements & specifically blitzscaling of OpenAI & Microsoft since last many days, here is a video on *The A.I. dilemma* talking about safety and what's at stake with respect to new exponential growth of LLMs.  PS: The same guys who made *The Social Dilemma* documentary on Netflix.  https://vimeo.com/809258916/92b420d98a
~ Soumya Patro|2023-03-27 10:32:09|‎~ Soumya Patro joined using this group's invite link
~ Aneesh|2023-03-27 11:13:35|‎~ Aneesh joined using this group's invite link
Nirant|2023-03-27 11:20:22|Putting on my friendly salesperson hat, please share this with your friends (and lovers?) in Bengaluru
Nirant|2023-03-27 11:20:27|**Deep Hack Demo Day Invite**  🗓️ When: Saturday, April 1st at 5 PM sharp — expect to end by 7 PM 📍 Where: Koramangala (exact location revealed via SMS by March 31st) 🔗 RSVP: Secure your spot by registering at https://partiful.com/e/sxaGTl08k6NwUfDeazoe (first come, first serve, limited invites)  Whether you're a seasoned tech expert or simply curious about Generative AI, Deep Hack Demo Day is the place to be for 🤯 demos!
Micheil|2023-03-27 11:35:28|Wish I could attend but flying out that day
Abhishek Sahu Ultrahuman|2023-03-27 12:06:00|‎Abhishek Sahu Ultrahuman joined from the community
Ankita Mathur|2023-03-27 12:07:06|‎You added Ankita Mathur
~ Ananya|2023-03-27 12:24:22|Jobot, a ChatGPT-powered bot is live at Jovian  https://www.linkedin.com/feed/update/urn:li:ugcPost:7046007262393352192/
~ Anirudh Venu|2023-03-27 12:49:40|‎~ Anirudh Venu joined using this group's invite link
~ Arko Cy|2023-03-27 13:08:02|Would u be streaming the Demos ?  ( for those who wish to join yet can't )
Prayank Swaroop Accel|2023-03-27 13:50:27|‎Prayank Swaroop Accel joined using this group's invite link
~ Amit Kumar|2023-03-27 14:03:24|‎~ Amit Kumar joined using this group's invite link
Micheil|2023-03-27 14:30:58|For those unfamiliar with who I am: Anthropologist and senior fellow with the Max Planck Institute for Social Anthropology (Halle, Germany). Am originally from Amsterdam but often in India (in Bangalore as we speak). I’m particularly interested in the way those working with AI - data scientists, ML professionals, artists - relate to the inherent unpredictability of their models.
Hasan Tech Art Guy|2023-03-27 14:38:06|Welcome to the group 😄✨
Chinmay Singh Generative AI WhatsApp Group|2023-03-27 14:39:56|‎Chinmay Singh Generative AI WhatsApp Group joined from the community
Micheil|2023-03-27 14:42:42|Better introduce yourself real fast!
Hasan Tech Art Guy|2023-03-27 14:48:03|Sure. I’m Hasan, a new media artist and an educator. My practice is focused on making the cutting edge accessible. I use AI, Robotics and code to build magical experiences. I have been mentoring international artists over the last 5 years about how to use technology to augment their practice. [PHONE] and I also run https://responsibletoday.in focused on addressing the societal challenges of technology in the Indian context. Glad to be a part of this community, you can find my website on my WhatsApp bio and please leave a message if you want to have a conversation. ✨ ‎[3/27/23, 14:51:32] Hasan Tech Art Guy: ‎video omitted
Dr. Ashith Generative AI WA Group|2023-03-27 14:54:03|is it done via stop motion?
Kaushik Bokka|2023-03-27 14:55:25|Hey Hasan! I remember seeing your work at the art tech community fair. Good stuff!
Hasan Tech Art Guy|2023-03-27 14:56:08|No vfx have been used for this video. It’s the raw recording. OCR -> content search -> style transfer  -> projection mapping
Hasan Tech Art Guy|2023-03-27 14:57:02|I’m trying out some generative video models for the future iterations but those are very slow at the moment. ‎[3/27/23, 14:58:46] Swastik Banerjee: ‎video omitted
Swastik Banerjee|2023-03-27 14:59:22|https://github.com/justanotherlad/blindvisaidgpt
Swastik Banerjee|2023-03-27 14:59:56|"nice to meet everyone here btw; i’m swastik, search engineer at wolfram|alpha :)"
Sumod K Mohan|2023-03-27 15:23:27|Isn't OpenAI already is doing this with BeMyEyes, am I missing something? Guessing you want a open source version?
Swastik Banerjee|2023-03-27 15:24:42|correct
Swastik Banerjee|2023-03-27 15:25:59|it’s always a plus to be able to add a bunch of other visual foundation models :)
Gokul Krishnan|2023-03-27 15:27:21|What about blip-2? Seems that's been doing well on captioning tasks?
Soumyadeep Mukherjee|2023-03-27 15:29:03|Also, a kick ass demo of this built over 12h is amazing bragging rights 😅
Nirant|2023-03-27 15:30:26|Swastik has a great demo of WIP stuff here btw: https://twitter.com/_justanotherlad/status/1640120489128476673
Swastik Banerjee|2023-03-27 15:32:24|[PHONE] i was trying a bunch of stuff aside work :)  would love to see where this goes
Swastik Banerjee|2023-03-27 15:33:34|esp integrating ControlNet to alter per specific requirements for a particular color blind person?
Nirant|2023-03-27 15:43:43|I'll look into this. Traditionally, have avoided doing this because participants feel like their ideas or work might come under too much light too soon. Will ask the folks at the hackathon itself and decide accordingly.
Sumod K Mohan|2023-03-27 16:05:42|Were you able to get the WiFi camera connected? Using the wifi camera steaming apps as someone had suggested. We had done something similar but for visually users to navigate in indoor environments. This was device that detects collision probability and provides feedback to user using haptic feedback. This was a long time ago, so running complex enough model on cheap hardware (think 2014, < Rs 10k phones) was quite hard. All the very best.
Sumod K Mohan|2023-03-27 16:06:00|*streaming
Swastik Banerjee|2023-03-27 16:08:52|sounds interesting
Swastik Banerjee|2023-03-27 16:08:59|do you have a repo for it?
Sumod K Mohan|2023-03-27 16:11:55|This wasn't open source per se. We had done this for TechMahindra. Please don't share outside. https://m.economictimes.com/tech/ites/tech-mahindra-tests-goggles-for-blind-plans-variant-for-cars/articleshow/45302948.cms
~ Prajwal|2023-03-27 16:17:13|‎~ Prajwal joined using this group's invite link
Sumod K Mohan|2023-03-27 16:17:30|But one could do this today, if someone is looking for ideas. Phones have decent compute to do interesting stuff. There is a challenge in distribution because you might need different  optimizations for different manufacturers. But for a quick demo this could be really possible.
Nirant|2023-03-27 16:18:30|If anyone is interested in making ControlNet work on iPhone, this is a good start: https://github.com/apple/ml-stable-diffusion/issues/131
Shubham Sharma 2012C6|2023-03-27 16:21:56|Hi, Does anyone know of any text to video tool through which one can do camera movements over still images?
Shubham Sharma 2012C6|2023-03-27 16:22:18|Zoom/pan/tilt that kind of thing
Dev Aggarwal|2023-03-27 16:24:24|We have a controlnet webapp and API too :)  https://gooey.ai/ai-photo-editor/?run_id=4lztwohy&uid=Nli0J2dP80WU3sdJ9RCw3DeNvIT2
Sudharshan GenAI|2023-03-27 16:26:30|Nice do you offer all modes? I’m building an app and was looking to deploy on runpod or modal ‎[3/27/23, 16:27:23] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-03-27 16:28:11|The underlying container is opensource too so you should be able to deploy on modal  https://github.com/dara-network/gooey-gpu ‎[3/27/23, 16:28:45] Nirant: ‎GIF omitted
Dev Aggarwal|2023-03-27 16:29:11|No sir, I bring my own gpus 😂
Dev Aggarwal|2023-03-27 16:30:13|Ive tried at least 5 different serverless gpus. None of them have a way to get excellent cold start times where you have over 30 models and sparse network activity.
Nirant|2023-03-27 16:31:09|See, I need clients like you who have over 30 serverless models 😅  Most of my clients have 2-5 and for that, Banana.dev is now at less than 5s cold start, while Modal is closer to 10s
Sumod K Mohan|2023-03-27 16:31:29|If you define a simplistic DSL (something like MOVE LEFT 3) then you can directly call the transform or scale. Or you could also provide some examples, in your pre-promt to GPT to create the transformation functions.
Nirant|2023-03-27 16:31:31|That is quite good price to perf ratio for most B2B use cases
Nirant|2023-03-27 16:31:58|I think it'd be helpful to have a more simplified answer. [PHONE] isn't a ML Engineer
Shubham Sharma 2012C6|2023-03-27 16:32:19|I’ve worked as an ml engineer at amazon.
Shubham Sharma 2012C6|2023-03-27 16:32:20|Thanks i got that
Shubham Sharma 2012C6|2023-03-27 16:32:22|:)
Aishwarya Goel Inferless 5s for 5G|2023-03-27 16:32:49|For what model sizes you are getting these latencies?
Nirant|2023-03-27 16:33:42|Aeee, you told me you wrote for TVF Pitchers S2!   Unfair that you're so talented
Soumyadeep Mukherjee|2023-03-27 16:34:14|Wow what!
Shubham Sharma 2012C6|2023-03-27 16:34:26|Haha in my previous avatar I was an ML Engineer. Can't help combine the two skills now that AI is going where it is going.
Dev Aggarwal|2023-03-27 16:34:56|I use accelerate to offload to cpu which lets me deploy all of them on a single a100 without running out of gpu. Latency is less than 5 seconds for the diffusion models.  https://github.com/dara-network/gooey-gpu/blob/67836d8c7ad2ae71ad077a30c378a55ca387434b/gooey_gpu.py#L119
Shubham Sharma 2012C6|2023-03-27 16:35:02|My vision is to be able to  make full scale movies with AI
Nirant|2023-03-27 16:35:32|Model sizes isn't perhaps a good proxy for the kind of work I am doing: think TorToise TTS, GPT-6J as a proxy
Nirant|2023-03-27 16:36:20|People accuse OpenAI of putting software engineers out of job, Shubham here is putting King Khan and Deepika Padukone out of work. No one is safe any more
Sumod K Mohan|2023-03-27 16:36:39|On second thought, very curious to know how GPT will handle degeneracies.
Shubham Sharma 2012C6|2023-03-27 16:36:51|Or trying to save himself from going out of work
~ ボルツザマク|2023-03-27 16:37:24|Make AI to write and create episodes for the final season of GOT, my goal 🥲
Aishwarya Goel Inferless 5s for 5G|2023-03-27 16:37:33|Makes sense. Because i have tried with around 5GB model size and it was more than 40 secs
Nirant|2023-03-27 16:38:11|1. Their own cold start times have improves over Feb and more in March 2. Their community templates are often faster than using your own models
Soumyadeep Mukherjee|2023-03-27 16:38:47|I started up with this dream. 😅 ‎[3/27/23, 16:38:50] Nirant: ‎GIF omitted
Aishwarya Goel Inferless 5s for 5G|2023-03-27 16:39:29|Yes.. they are getting better. In feb it was around 60 secs
~ Arihant|2023-03-27 16:49:16|‎Soumyadeep Mukherjee added ~ Arihant
~ Prakhar|2023-03-27 16:54:38|‎~ Prakhar joined using this group's invite link
Sumod K Mohan|2023-03-27 17:07:22|Just checked this, basic part works. It is even able to create even Homography matrix if I say move left by 20% etc (Homography Matrix tells how to transform an image by translation, scaling eyc). I thought it will  gets tripped by degeneracy. But it gets tripped up even before with non commutativity of matrix multiplication. So please use that idea with caution.
~ Amit|2023-03-27 17:13:23|‎~ Amit joined using this group's invite link
Swastik Banerjee|2023-03-27 17:22:21|unrelated but this seems really interesting; i’m a regular user of sam harris’s Waking Up
Dev Aggarwal|2023-03-27 17:30:15|I’ve tried giving it those direction questions (start north move 30degree south … where are you now), from a mental ability textbook and the performance is shit.  But GPT4 sparks of AGI paper does claim that it has an improved sense of directionality ‎[3/27/23, 17:30:33] Dev Aggarwal: ‎image omitted
Nirant|2023-03-27 17:32:25|New AGI test: Can GPT4 do route planning for a Logo (anyone remember that?) pointer in specific shapes and mazes?
Siddharth Agarwal|2023-03-27 17:50:54|That's gonna be a yes, I think.
Siddharth Agarwal|2023-03-27 17:51:47|I am a little more curious about its ability to reason about problems in its distribution but not in its data: eg. leetcode hards that it might not have been trained on. ‎[3/27/23, 17:53:02] Nirant: ‎image omitted
~ Diwakar|2023-03-27 17:54:32|Asked GPT-4 (via ChatGPT Plus) the following puzzle for and it fumbled and failed.  _Let’s pretend we’re on the metric system and use kilograms instead of pounds to give us a starting base number of 100. Four people (Alex, Brook, Chris and Dusty) want to cross a river in a boat that can only carry 100kg. Alex weighs 90kg, Brook weighs 80kg, Chris weighs 60kg and Dusty weighs 40kg, and they have 20kg of supplies. How do they get across? The boat cannot row itself. The boat cannot carry more than 100 kg at any time._   Failed to answer and gave up even after multiple prompts and attempts.
Sumod K Mohan|2023-03-27 17:55:29|As per the paper they can't do well. See Aravind's post about contamination: https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks
Gokul Krishnan|2023-03-27 17:55:36|Is it 20kg of supplies all together or each person? Can the supplies be broken?
Siddharth Agarwal|2023-03-27 17:55:38|Thanks, yall.
Sumod K Mohan|2023-03-27 17:56:01|👆🏽
~ Diwakar|2023-03-27 17:56:56|The 20Kg of supplies are together. No, the supplies can't be broken down. Have to be carried as a whole 20Kg.
Nirant|2023-03-27 17:57:57|GPT-4, on NEW Leetcode problems past its training date, in 5 attempts, gets - 86% on easy - 60% on medium - 15% on hard  https://arxiv.org/abs/2303.12712
Sumod K Mohan|2023-03-27 18:17:10|Yeah, not 100% sure of this. There are just so many questions out there, that these newly created questions could just rewording without change in core idea. See Aravind's blog. In my experience with ChatGPT, when I give problems that are easy to medium and then I change the problem ever so slightly in its core idea and it will get it wrong. Or there are tell tale signs it has mugged up. Like I will give a problem that is a coin change in disguise with coins that are multiples of each other.  Thus allows greedy solution, it will provide a DP Solution (I am not even testing for corner cases etc or even if it will run). Just whether the core structure is right, which it did not. So in my experience small perturbations to core idea causes drastic change in correctness.
Sumod K Mohan|2023-03-27 18:18:17|Hard questions usually are what differentiates for top ranks (and much fewer) and could just be what people put more effort in creating.
~ pt|2023-03-27 18:58:05|I saw someone on Twitter saying gpt-4 does much worse than leetcode hard on newer Euler problems.
~ Parth|2023-03-27 20:02:20|https://about.sourcegraph.com/blog/cheating-is-all-you-need
Chirag Jain|2023-03-27 20:35:43|The author for some reason seems to be discounting Github's excellent search product which has similar or maybe larger advantage than Sourcegraph
Nirant|2023-03-27 20:36:24|The author is quite famous Steve Yegge.
Chirag Jain|2023-03-27 20:36:45|yeah I noticed, I liked the rant style
Nirant|2023-03-27 20:37:08|Why do you think my Substack is called niranting.substack.com ? xD
~ Diwakar|2023-03-27 20:40:35|His infamous Google rant from 2011 https://gist.github.com/chitchcock/1281611
~ Parth|2023-03-27 21:09:58|Yeah, obviously he'll be baised for his company. But larger point he makes about how people are underestimating potential of LLM powered coding assistants by seeing a few edge case failures of code generation on chatgpt is quite valid. Finetuning LLMs for user's existing codebases + building search capabilities on codebases will be gamechanger
Dev Aggarwal|2023-03-27 21:13:20|I believe https://www.buildt.ai does this
~ Diwakar|2023-03-27 21:15:23|Github Copilot X(available for preview only) is doing it (https://github.com/features/preview/copilot-x)
Sumod K Mohan|2023-03-27 21:23:58|Thanks for sharing. I absolutely think this is monumental and going to change how we work. And working on something using LLMs. Funny thing is the same time, question I asked it is the exact kind of question I would usually ask a fresher to know if they are faking it (as in just knowing the answers mugging up a lot of leetcode answers) or they conceptually know it. I do think lot of the code today we write, will easily to automated too. That begs the question what won't be. All the glue code, all the templates, all the code that is quickly needed to get a project up and running will all be automated. What will possibly remain? So what skills will become more important?
~ Nishanth Prabhu|2023-03-27 22:32:57|‎~ Nishanth Prabhu joined using this group's invite link
~ Parth Sharma|2023-03-27 22:53:16|‎~ Parth Sharma joined using this group's invite link
Ambarish Ganguly|2023-03-27 23:41:51|‎Ambarish Ganguly joined using this group's invite link
Ambarish Ganguly|2023-03-27 23:43:35|Remote submissions are eligible for prize. Correct ?
Nirant|2023-03-27 23:43:46|Yes
~ Parth Sharma|2023-03-28 00:12:24|Hello everyone, this is Dr. Parth Sharma...I am a doctor by profession...i have keen interest in python and likes of AI, deep learning for some years now...i look forward to learning/implementing some good stuff here in medical AI especially
~ Pradyumna Bang|2023-03-28 02:56:05|Hi all,  What would be the best way to bring myself upto speed with all the AI theory that's powering LLMs? I'm a Computer Science graduate but haven't done much AI related coursework or projects in college as most of my work was in Software Dev.
Dev Aggarwal|2023-03-28 02:57:16|Andrej karpathy on youtube ✨
Gokul Krishnan|2023-03-28 03:56:18|Which videos?
Amogh V|2023-03-28 08:11:03|We are vision-mission buddies
Nirant|2023-03-28 12:10:18|New Prompt trick: Every time ChatGPT gives an answer I am not satisfied with in terms of detail, I just go full gym bro on it:   ```Is that the best we can do?```
Kishore GenAI|2023-03-28 12:11:35|Realised that you can use GPT-3.5 as data resource even without internet connection. I asked for a list of shopify websites in USA which sell Candles. I use those links and asked chatGPT for a crawler code to get email Ids. Till now I got 130 valid links. Incase anyone doesn't have the money to splurge on databases and want some free solution, try this.
Dhruv Anand|2023-03-28 12:14:07|were you inspired by: https://twitter.com/AKASpencerScott/status/1638996898941124609?s=20 ?
Sumod K Mohan|2023-03-28 12:15:06|It's pretty good at competitor analysis too. If you give precise small collection and ask it to give you similar companies, it will get you really good ones. It tends to give general answers, so need to do prompt engg to really get the interesting things.
Kishore GenAI|2023-03-28 12:16:37|Oh wow. No. I was trying to get shopify lists and thought it will give me a way to get it. However, it started giving me the actual links. ‎[3/28/23, 12:19:25] Nirant: ‎image omitted
Pratyush Choudhury|2023-03-28 12:24:34|"Hmm, interesting - didn't quite for me  Says ""As an AI language model, I can only provide an objective analysis of the pros & cons...""  Depends on the task I guess - should work for areas where the problem set is well defined is my guess. But thanks for the tip: will try it out more widely"
~ Gaurav Singh Nijjer|2023-03-28 12:47:05|‎~ Gaurav Singh Nijjer joined using this group's invite link
Nirant|2023-03-28 13:03:24|Pratyush bhai, Is that the best you can do? ‎[3/28/23, 13:09:43] Amogh V: ‎GIF omitted
Nirant|2023-03-28 13:10:58|Thor got depressed after that win. Let's not do that to GPT4
~ Blessin Varkey|2023-03-28 13:59:38|‎~ Blessin Varkey joined using this group's invite link ‎[3/28/23, 14:06:14] Lucky Murari: ‎GIF omitted
Narendranath Gogineni|2023-03-28 14:56:18|‎Narendranath Gogineni joined using this group's invite link
Shreyansh Chandak|2023-03-28 15:47:30|‎Shreyansh Chandak joined from the community
Rohit Aggarwal|2023-03-28 20:10:28|‎You added Rohit Aggarwal
Diptanu Choudhury FB AI|2023-03-28 20:49:13|‎Diptanu Choudhury FB AI joined using this group's invite link
~ Sachin|2023-03-28 21:02:04|‎~ Sachin joined using this group's invite link
~ Sachin|2023-03-28 21:12:01|Hi,  I am a freelance science writer/journalist. For a feature story, I'm looking to speak to founders/executives/marketers at D2C companies that are using third-party ChatGPT-powered chatbots (such as Lexi from Velocity) for any aspect of their work. If that's you or if you know someone I should speak to, please DM me.  Thanks! ‎[3/28/23, 21:25:09] Amogh V: ‎image omitted
Mannan Amroliwala|2023-03-28 21:27:13|Is this a real person?
Amogh V|2023-03-28 21:27:21|No ‎[3/28/23, 21:30:42] Amogh V: ‎image omitted ‎[3/28/23, 21:31:38] Amogh V: ‎image omitted
Prayank Swaroop Accel|2023-03-28 21:32:19|Which checkpoint are you using ?
Prayank Swaroop Accel|2023-03-28 21:32:35|Does the image have Exif data of generation ?
Ojasvi Yadav|2023-03-28 21:33:03|Did you try dreamboothing her?  She looks a bit like Rakhi Sawant here 😂
Nirant|2023-03-28 21:35:08|I'm a simple man. I see Deepika Padukone, I ❤️ it
Amogh V|2023-03-28 21:35:09|No, I was too tired to dreambooth today. Spent so much time on the jacket and trees that I was pretty exhausted 😛 Perhaps tomorrow
Amogh V|2023-03-28 21:35:21|I know, right?
Shashwat TDC|2023-03-28 21:35:53|Dude this became a point of debate.   Is this really AI generated? Any proof will be helpful to settle.the debate here 😅 ‎[3/28/23, 21:36:26] ~ Karan Gandhi: ‎GIF omitted ‎[3/28/23, 21:39:52] Nirant: ‎image omitted
Nirant|2023-03-28 21:40:02|Not aiming for photorealistic fwiw
~ Sachin|2023-03-28 21:41:56|On the one flower in focus, the petals look weird. ‎[3/28/23, 21:42:27] Nirant: ‎image omitted
Amogh V|2023-03-28 21:44:22|Depressed software engineer from Bangalore spends all night generating AI girl, falls in love. Laptop crashes at midnight, man loses checkpoint, seed, prompt, everything. Cannot recreate girl. Has only 1 image. Shares image online with heartbroken message. Kind netizens of Bangalore organize a search for the real girl. Girl is found! She is a photographer. They get in touch, romance kindles, they get married, AI generates their wedding invitation. Cinderella 2023.
Nirant|2023-03-28 21:45:43|The plot of Her, Yash Raj Films edition
Yash Pandya|2023-03-28 21:47:28|Sell the movie rights to this
Amogh V|2023-03-28 21:47:56|Make this movie using AI > Sell the movie rights to this
~ Rohan|2023-03-28 21:47:59|Would watch this movie. Extra props if it’s made using AI
Yash Pandya|2023-03-28 21:49:14|“There is no good and evil. There is only Balenciaga”.
Dev Aggarwal|2023-03-28 21:49:22|https://youtu.be/kCc8FmEb1nY  This one specifically, but I think you really should watch the 5 part series before this one too. And if you’re really curious also the cs231n series :)
Amogh V|2023-03-28 21:57:36|I had a Deepika in Arcane animation art style. But literally lost the seed, prompt and everything 😭
Nirant|2023-03-28 21:58:05|Arre arre yeh movie tou real hain
~ Siddardha G|2023-03-28 22:08:13|‎~ Siddardha G joined using this group's invite link
Ruthvik Reddy|2023-03-28 22:14:57|‎Ruthvik Reddy joined using this group's invite link
Ananth Radhakrishnan 2012A7|2023-03-28 22:47:11|In Greek mythology, there's a similar story of a sculptor who falls in love with a statue that he carved: https://en.m.wikipedia.org/wiki/Pygmalion_(mythology)
Narendranath Gogineni|2023-03-28 22:52:10|This is my bumble bio from today
Lucky Murari|2023-03-28 23:32:19|Length of the neck gave away a little🤪
jyotirmayjk Hackathon|2023-03-29 01:02:43|‎jyotirmayjk Hackathon joined using this group's invite link
~ Aman|2023-03-29 01:50:10|https://twitter.com/io_Y_oi/status/1634835399918108673?t=malrs07ZHMBbup1Pr7gO-g&s=19  Interesting project, just used it
Anshul Bhide Replit|2023-03-29 02:03:01|Google Partners with AI Startup Replit to Take on Microsoft’s GitHub  https://www.bloomberg.com/news/articles/2023-03-28/google-partners-with-ai-startup-replit-to-take-on-microsoft-s-github
~ tushar|2023-03-29 02:20:55|i wonder if ghostwriter is gonna use Bard now
Nirant|2023-03-29 06:28:02|Anshul sir [PHONE] runs India Replit — and they're sponsoring the hackathon (https://has.gy/gpt4hack), ask him how you can try GCP features on Replit!
Nirant|2023-03-29 06:54:59|For engineers wanting to get a first hand feel of how to write a GPT from scratch, this is great — but I wonder how popular will be that in the months, years to come?  Lot of applied/commercials apps need more ability to get a behavioural understanding of LMs work and the limits of their reasoning ability — and not the ability to implement one in torch/numpy
Aditya Ankur|2023-03-29 06:57:17|Theory enthusiats who are still in college might do it as it gives them the sense of having deeper knowledge.  I would have if I was still in college.
~ Vinoj|2023-03-29 07:08:55|‎~ Vinoj joined using this group's invite link
Nirant|2023-03-29 07:17:24|"Elon Musk, Emad Mostaque, Yoshua Bengio, Steve Wozniak and bunch of other famous people have asked AI Labs to not train systems more powerful than GPT4 for 6 months and instead use this time to ""jointly develop safety protocols""   https://futureoflife.org/open-letter/pause-giant-ai-experiments/"
Satyajeet Kanetkar|2023-03-29 07:18:53|Playing around with alien technology needs a built-in stop-loss 👍🏽
Nirant|2023-03-29 07:22:15|I wonder if you'd have felt the same way about printing press, Internet or smart phones/social media.
Nirant|2023-03-29 07:23:46|Zooming out, the Church hated printing press, horse-specialists hated Ford cars, Govts hate social media and engineers outside Microsoft/OpenAI hate GPT4 — there seems to be a pattern here :)
Nirant|2023-03-29 07:24:08|The only sane way to align incentives is to buy $MSFT, Nvidia and ASML xD
Satyajeet Kanetkar|2023-03-29 07:24:52|Yea, but we 'understood' how these technologies worked, right?
Satyajeet Kanetkar|2023-03-29 07:25:50|Like printing a book by itself does not have any meaningful emergent properties, unlike AI.
Nirant|2023-03-29 07:26:16|Ofc, printing a newspaper has emergent properties? How do you think nation states came into existence?
Satyajeet Kanetkar|2023-03-29 07:26:26|There are of course societal effects, which can be called emergent
Nirant|2023-03-29 07:27:11|Also, we've gone too off-topic — let's move to DMs 😆 ‎[3/29/23, 07:42:50] Micheil: ‎image omitted ‎[3/29/23, 07:43:24] Micheil: ‎image omitted
Nirant|2023-03-29 07:47:42|Does anyone know Richa Gandhi, the journalist who wrote this? Would be fun to have her here perhaps?
Satyajeet Kanetkar|2023-03-29 07:50:37|"BIC is having an event on ""ChatGPT and it's Ilk"" by Anil Ananthaswamy, a science writer and editor. https://bangaloreinternationalcentre.org/event/chatgpt-and-its-ilk/"
Abhay Jani|2023-03-29 08:24:30|‎You added Abhay Jani
Nirant|2023-03-29 08:32:42|For folks who are wondering how this'll play out wrt Search and ads, Bing Chat has ads: https://twitter.com/debarghya_das/status/1640892791923572737
Rohit Aggarwal|2023-03-29 08:59:46|Will be waiting to see stats on CTRs and their subsequent effect on CPCs.   Any idea if Flipkart etc are tracking this differently?
Hasan Tech Art Guy|2023-03-29 09:05:18|I think those are valuable discussions though. Can we utilise the WhatsApp community feature to have a philosophy room? So people can continue those discussions.
Ojasvi Yadav|2023-03-29 09:08:10|Yeah man if there's anything related to gen AI it's cool with me
Ojasvi Yadav|2023-03-29 09:08:19|I don't care if it's just 2 people talking
Ojasvi Yadav|2023-03-29 09:08:38|Context can be figured about scrolling in the north direction 😂
Bharat Kumar Ramesh Hashmal Web3|2023-03-29 09:13:24|‎Bharat Kumar Ramesh Hashmal Web3 joined using this group's invite link
Micheil|2023-03-29 09:23:01|That would be great!
~ Rohit|2023-03-29 09:26:08|‎~ Rohit joined from the community
Nirant|2023-03-29 09:27:43|The group is small and would want to keep our _attention_ here at the moment — as a reminder, most people here don't do this full time :)
Nirant|2023-03-29 09:27:44|Will consider doing a philosophy fork if we've more topics like David Chalmers coming up organically  Too many spin-offs and we become like Marvel: All glam, not enough fun 😂
Ayush Deva|2023-03-29 09:31:04|While we are on the topic - another point to support the case for forks at some point would be to have some use-case specific groups - such as photo studio, legal, education
Hasan Tech Art Guy|2023-03-29 09:31:20|That’s fair. we can make a small philosophy group with the few people interested in that and do this full time. Is it okay with you if I share the link here?
Nirant|2023-03-29 09:34:47|Yeah, go ahead! Added a group to the community which makes it easier for folks here to find that hopefully 🫰🏻
Rhythm Gupta IITD|2023-03-29 09:36:24|‎You added Rhythm Gupta IITD
~ ab|2023-03-29 09:40:09|‎~ ab joined using this group's invite link
Shashwat TDC|2023-03-29 09:51:29|‎POLL: while we on the topic, a quick poll. Identify yourself with whatever applies ‎OPTION: Doing full-time. #buildingonAI (24 votes) ‎OPTION: Has live projects #inproduction (21 votes) ‎OPTION: Python exploration (0 votes) ‎OPTION: Leading/ managing any AI project (7 votes) ‎OPTION: Learning (30 votes) ‎OPTION: Enthusiast (7 votes)
~ Mohit|2023-03-29 10:00:50|‎~ Mohit joined using this group's invite link
Shashwat TDC|2023-03-29 10:02:27|so missed the important classifier _Funding_ feel free to drop a 🔥 emo to identify :)
Sanket Nadhani|2023-03-29 10:03:25|‎Sanket Nadhani joined using this group's invite link
Sankalp PickYourTrail|2023-03-29 10:17:15|‎Sankalp PickYourTrail joined using this group's invite link
Nirant|2023-03-29 10:36:55|Reposting because lot of new friends!  *Generative AI Hackathon Demo Day Invite*  🗓️ When: Saturday, April 1st at 5 PM sharp — expect to end by 7 PM 📍 Where: Koramangala (exact location revealed via SMS by March 31st) 🔗 RSVP: Secure your spot by registering at https://partiful.com/e/sxaGTl08k6NwUfDeazoe (first come, first serve, limited invites)  Whether you're a seasoned tech expert or simply curious about Generative AI, Deep Hack Demo Day is the place to be for 🤯 demos!
~ Amit|2023-03-29 10:38:24|Streaming, pls!
Nirant|2023-03-29 10:41:20|And for those who want to _participate_ in the hackathon in BLR: https://has.gy/gpt4hack
~ Deven|2023-03-29 10:47:10|‎~ Deven joined from the community
~ Rishi|2023-03-29 11:00:14|‎~ Rishi joined from the community
~ Abhishek Sharma|2023-03-29 11:00:58|‎~ Abhishek Sharma joined using this group's invite link
Vishaka Vanjani|2023-03-29 11:46:25|‎Vishaka Vanjani joined using this group's invite link
~ Abhijeet|2023-03-29 11:46:39|‎~ Abhijeet joined using this group's invite link
Nilesh Christopher|2023-03-29 11:52:36|‎Nilesh Christopher joined using this group's invite link
~ just_a_tofu|2023-03-29 11:58:59|‎~ just_a_tofu joined using this group's invite link
Swastik Banerjee|2023-03-29 12:40:47|One of my recent best reads: https://direct.mit.edu/daed/article/151/2/183/110604/Do-Large-Language-Models-Understand-Us
Dipin Chopra|2023-03-29 14:02:57|‎Dipin Chopra joined from the community
Soumyadeep Mukherjee|2023-03-29 14:03:26|Hey hey I want to be in these DMs 😅
~ Karan Gandhi|2023-03-29 14:44:13|Same
Adithya L Bhat Hackathon|2023-03-29 15:16:43|‎Adithya L Bhat Hackathon joined from the community
~ Priti|2023-03-29 15:52:27|‎~ Priti joined using this group's invite link
~ Krishna|2023-03-29 15:56:05|‎~ Krishna joined using this group's invite link
Shubham Sharma 2012C6|2023-03-29 16:30:39|https://twitter.com/tobi/status/1641010421493637122
~ Shubham|2023-03-29 17:52:02|‎~ Shubham joined using this group's invite link
~ Santhosh Guru|2023-03-29 18:36:32|‎~ Santhosh Guru joined from the community
Chirag Jain|2023-03-29 19:24:01|what is the source for 100 Trillion? have we already reached triple digit in trillions 😮
Gaurav Arora|2023-03-29 19:44:04|Don’t think 100 trillion is right. Sam Altman had clarified in the podcast with Lex that 100 trillion is just a meme going around. ~1-10 trillion is what seems probable (though thats also a speculation, no authoritative source)
~ Santosh|2023-03-29 20:07:27|‎~ Santosh joined using this group's invite link
~ Kaustav K Bose|2023-03-29 20:12:17|‎~ Kaustav K Bose joined using this group's invite link
~ Ranajoy|2023-03-29 20:25:41|‎~ Ranajoy joined using this group's invite link
~ Bash|2023-03-29 21:30:26|‎~ Bash joined from the community
Gayathri Meka Hyperverge|2023-03-29 21:54:38|‎Gayathri Meka Hyperverge joined using this group's invite link
Ramakrishnan Lokanathan|2023-03-29 21:59:46|‎Pranjal Mehta added Ramakrishnan Lokanathan
Sudharshan GenAI|2023-03-29 22:08:18|https://twitter.com/marckohlbrugge/status/1640961076039925760  2500 USD grant from OpenAI - [PHONE] Can we get OpenAI to give credits are prizes to the winners?
Sudharshan GenAI|2023-03-29 22:08:42|Alt - builders can apply too for any projects this weekends fyi
Nirant|2023-03-29 22:11:14|"You kinda need an active project with a website, ""CTO"" and stuff to apply"
Dev Aggarwal|2023-03-29 22:11:34|Why does this look like a phishing attack?
Nirant|2023-03-29 22:12:48|We're talking to Azure and going via them for Azure OpenAI credits — OpenAI ghosted already. Will see how this pans out!
Sudharshan GenAI|2023-03-29 22:12:49|Grant Eligibility: - Founded within the last 7 years - Haven't applied for a credit grant from OpenAI before - Need to have a working company website/online presence  Only reqs ‎[3/29/23, 22:15:52] Nirant: ‎image omitted
Sudharshan GenAI|2023-03-29 22:16:10|Ah got it
Dev Aggarwal|2023-03-29 22:17:35|I mean its a random google form with no actual announcement from openai, feels very phishy
Nirant|2023-03-29 22:21:11|And a Google form instead of their usual Microsoft thing which they use in Wait list
"Arpan Desai | MobileFirst"|2023-03-29 22:33:39|https://futureoflife.org/open-letter/pause-giant-ai-experiments/
Dhruv Anand|2023-03-29 22:37:08|I found this which looks more plausible: https://openai.com/microsoft-for-startups
Nirant|2023-03-29 22:37:17|[PHONE] scroll up maadi, this is the first thing we discussed today xD
Lavish 2017|2023-03-29 22:47:20|"any good hacks to reduce hallucination of gpt?   I know one ""don't make up an answer if you don't know"" which does solve however it also leaves some gaps where LLM tries to answer regardless of confidence.  I've also tried asking it to publish confidence score along side and dodge replying when confidence is low however in certain cases, that gets leaked too."
Nirant|2023-03-29 22:49:56|"Add to System Prompt: You are a Harvard Professor of <whatever domain>.   Similarly, ""Never break character"", ""Remember that you're honest and only answer using what you see"""
Nirant|2023-03-29 22:50:41|Treat GPT4 as a naughty 5-7 year old who talks a lot, wants to be helpful and if you say the same thing in 4 different ways it'll eventually listen to you
Zainab Bawa|2023-03-29 22:53:45|The talk at BIC was excellent today.
Zainab Bawa|2023-03-29 22:53:51|And it was a packed house.
Sumod K Mohan|2023-03-29 22:54:20|I use a score in interactive sessions. So penalize when it starts to hallucinate. That seems to help. But not in first time prompting. Similarly score for speed seems to help  🤫
Shubham Sharma 2012C6|2023-03-29 22:54:21|More like a 9 year old since it passed the theory of mind test
~ Bash|2023-03-29 22:55:18|btw  what do you mean by gpt hallucinating? 🥹
Nirant|2023-03-29 22:55:34|We'll not go there, because it's already better at Leetcode, Chess, flirting and bunch of other things than me. The only things I'm better at are puns and Shayari at this point.
Shubham Sharma 2012C6|2023-03-29 22:56:24|I bet it could very soon be better at those too 😅
Sumod K Mohan|2023-03-29 22:56:33|It making up stuff and saying things that not true, creating references, articles etc
~ Kaustav K Bose|2023-03-29 22:56:56|Ask for references or sources ?
~ Kaustav K Bose|2023-03-29 22:57:11|Its like doing a peer review of a paper when it is to be published
Nirant|2023-03-29 22:57:17|Once the model hallucinates, this doesn't help — it'll make up a source
Nirant|2023-03-29 22:57:50|"But if you've an extra API call, you can do a self-consistency check: ""Are you sure your answer was correct using the information below:"""
~ Kaustav K Bose|2023-03-29 22:58:03|But we can verify if the source is legit or not ? Or does it cite something that might be obscure ?
Sumod K Mohan|2023-03-29 22:58:33|And yeah very good one at that. I had it create references with actual researcher in that area of maths. Just that they didn't write the paper (at least not yet or don't know if it had access to data I don't have access to ;)
jyotirmayjk Hackathon|2023-03-29 22:59:20|Are you using penalty system like the Dan jailbreak?  How do you persist score over multiple sessions ?  What 1 way I can think of is to constantly keep summarising previous chat scores and keep feeding it as context in subsequent prompts but I m not sure if it’s feasibility
Nirant|2023-03-29 22:59:26|Depends on the task — for open domain QA, it'll make up very believable stuff and you'll be tripping acid for a while. For closed domain QA, verification is somewhat easier but harder to use this signal.
Nirant|2023-03-29 22:59:51|Ghosts of Future Past: Math Papers edition
Nirant|2023-03-29 23:00:26|```refine``` from langchain works well for gradual operations around this
Sumod K Mohan|2023-03-29 23:02:25|Not not across sessions. No did not use DAN jailbreak.
Sumod K Mohan|2023-03-29 23:05:03|What surprised me was that the speed one worked. Can others try and let me know if it works for you too. Nothing Fancy: start with saying you get +1 for producing the output fast and -1 for slow responses. But ensure that you doing when things are bit slow. Last 3-4 days, it adds a disclaimer that it will be slow irrespective but in my experience it was decently fast compared to otherwise.
Sumod K Mohan|2023-03-29 23:06:28|Because if this works, seems like they might be throttling using prompts!! Which just didn't seem right.
Kishore GenAI|2023-03-29 23:11:38|I was thinking of doing something else. Basically you can make a series of questions answer pairs based on the output it gave and then search using serp or other available tools to validate or invalidate the answer. Haven’t tried this out but will do so when I get the time.
Lavish 2017|2023-03-29 23:12:12|second one does seem to work. will share here if I find any really good solution. was thinking if a custom agent implementation helps which first figures out if this is made up (does induce recursive problem) and then dodges the reply if yes.  in my use case the domain of conversation is unknown. hence also not possible to penalize upon hallucination as I'm not moderating between user & bot.
Nirant|2023-03-29 23:12:22|Self Consistency is empirically known to work: arxiv.org/abs/2203.11171 ‎[3/30/23, 00:33:28] Nipun Sadvilkar: ‎image omitted
~ Arko Cy|2023-03-30 00:44:38|was this before or after the GS report of 300 million jobs likely to get impacted ?
Sudharshan GenAI|2023-03-30 00:45:19|Yeah this was a surprise - Stuart russel and Yoshu bengio signed off on this
Ojasvi Yadav|2023-03-30 00:45:45|I personally think any kind of hindrance to tech hurts the entity that's hindered, and is hardly ever fruitful.
Sudharshan GenAI|2023-03-30 00:45:52|But this won't happen
Sudharshan GenAI|2023-03-30 00:45:58|OpenAI is a for-profit company
Sudharshan GenAI|2023-03-30 00:46:09|And backed by microsoft
Sudharshan GenAI|2023-03-30 00:46:30|It's like asking Apple to stop innovating and launching new things
Ojasvi Yadav|2023-03-30 00:46:30|In 6 months openAI went from gpt 3.5 to gpt4, will they really stop training new AI models for the next 6 months just because of a document on the internet?
Sudharshan GenAI|2023-03-30 00:46:50|Perhaps more marketing/bringing awareness to the issue - like Balaji
Ojasvi Yadav|2023-03-30 00:47:01|They won't, and they shouldn't. It's a joke.
Ojasvi Yadav|2023-03-30 00:49:53|Even if I was running a non-profit AI research lab.   I would have to be downright dumb to freeze myself in time when AI is progressing the fastest ever that it has ever progressed.
Sudharshan GenAI|2023-03-30 00:53:16|true lol
Ojasvi Yadav|2023-03-30 00:55:06|It's all virtue signalling, which I completely understand. But that's for outsiders. If you're an insider, you really should see this as a joke.
~ Others|2023-03-30 04:17:43|‎~ Others joined using this group's invite link
~ Kunj Naik|2023-03-30 05:06:18|‎~ Kunj Naik joined using this group's invite link
Amir Nagri|2023-03-30 07:21:38|I'm surprised with Elon  backing it  Generally he is very vocal against bureaucratic interventions, here he is asking for it
Amir Nagri|2023-03-30 07:22:27|So looks like strategy to catch up rather than concern
~ Lakshya|2023-03-30 07:49:45|‎~ Lakshya joined using this group's invite link
Nirant|2023-03-30 09:38:15|Yann Lecun drew a line in the sand! 🔥  And he used the same example of Church and printing press that I did — all francophiles think alike 😅 https://twitter.com/ylecun/status/1641274105503576064 ‎[3/30/23, 09:39:33] Nirant: ‎image omitted
Madhur Chadha|2023-03-30 09:40:09|‎You added Madhur Chadha
Nirant|2023-03-30 09:41:43|Google Bard is trained on ChatGPT — the first author of BERT, Devlin, resigned over this?  https://twitter.com/steventey/status/1641267979399704576
Micheil|2023-03-30 09:43:32|Wasn’t the whole point of buying Twitter the data it offers? Hard to justify the price he paid for it otherwise
Nirant|2023-03-30 09:45:27|Elon is famously very pro-Govt when it benefits him: He takes tax rebates for Tesla via their Solar City acquisition, lobbies NASA and Congress to use US launch vehicles instead of European or Indian. He's basically Ambani Redux.
Aditya Agrawal SuperU|2023-03-30 09:48:09|As someone who has worked with Elon : I second that..
Amir Nagri|2023-03-30 09:48:22|FYI - most likely this was a phishing scam (that i fall for as well), have reported it to twitter and google, let's see what happens  also, if you want to apply for openai grant, check this form out on official website - https://openai.com/microsoft-for-startups
Aditya Agrawal SuperU|2023-03-30 09:48:59|I got 2500 OpenAI credit as well.
Amir Nagri|2023-03-30 09:50:31|"by filling this form? i doubt it  someone would have filled the form on openai website with the data they collected using google forms, so all your data is phished, very clever ""form"" in the middle attack 🤔"
Shashwat TDC|2023-03-30 09:52:17|Loss of long term memory is a feature not a bug.
Aditya Agrawal SuperU|2023-03-30 09:52:22|Got it.. I got email from OpenAI
Ojasvi Yadav|2023-03-30 10:03:13|In what capacity?
Aditya Agrawal SuperU|2023-03-30 10:04:04|Leading data program at Tesla.
Ojasvi Yadav|2023-03-30 10:11:42|Oh nice!
Nirant|2023-03-30 10:12:03|Aditya is working on building an Adept rival from Namma Bengaluru! Hit him up if that's your vibe :)   https://www.linkedin.com/in/meadityagrawal/
Aditya Agrawal SuperU|2023-03-30 10:12:45|Thanks Nirant..
Ojasvi Yadav|2023-03-30 10:13:02|We've got a bunch of very interesting folks here, feels like home 🙈  Cheers to you Nirant.
~ Anurag|2023-03-30 10:21:10|This calls for more elon gossips 🍿
Nirant|2023-03-30 10:22:57|Would be way more interested in Karpathy's work, the work Tesla did with synthetic data e.g. simulations and how they manage _truly_ big datasets!
Aditya Agrawal SuperU|2023-03-30 10:25:25|Sure. I def have some nice ones to share...
~ Anurag|2023-03-30 10:26:01|I vote for aditya focussed meetup 😂 tesla pe charcha
Aditya Agrawal SuperU|2023-03-30 10:26:13|I dint work with Karpathy as Data Org is different than car engineering. But worked on data privacy program which had overlap.
Aditya Agrawal SuperU|2023-03-30 10:33:34|Hi All,   I am Aditya.  After working as lead data program for Tesla, I returned back to India last year to build my startup in the AI Space : https://www.superu.ai/ . We are building rival of https://Adept.ai and https://inflection.ai/ right here from Bangalore. If you are interested in discussing what we are building and/or join hands to build a world class AI product, I would love to talk to you.  Here is my LinkedIn profile: https://www.linkedin.com/in/meadityagrawal/  Cool AI Toolkit: https://sauce.superu.ai/  Best, Aditya
Harsh Gupta Felvin|2023-03-30 10:34:29|Hey Aditya great to see you here :)
Harsh Gupta Felvin|2023-03-30 10:36:42|In case you are comfortable sharing, would love to hear about your 'Bhramastra' against adept and inflection.
Vishaka Vanjani|2023-03-30 10:37:06|Hey Aditya!✨
Adithya L Bhat Hackathon|2023-03-30 10:37:21|Definitely 😅
Aditya Agrawal SuperU|2023-03-30 10:45:28|Thanks guys. Sure will share more. Any additional AI groups on reddit or discord I should be part of?
jyotirmayjk Hackathon|2023-03-30 12:03:13|Are you looking to minimise hallucinations during QnA over documents or just plain vanilla chat conversations?  In case of QnA I think this evaluation model shipped by Llama Index might help.  They just released it few hours back co incidentally
jyotirmayjk Hackathon|2023-03-30 12:03:28|https://twitter.com/jerryjliu0/status/1641234014991446016?s=46&t=icC0fizZK8E3ONsDVuGFWA
Nirant|2023-03-30 12:03:39|The maker of that evaluation model is [PHONE] — he is here!
Ravi Theja|2023-03-30 12:05:03|Thanks, Nirant for the mention.
jyotirmayjk Hackathon|2023-03-30 12:06:13|[PHONE] Ravi great to have you here 🙌🏻🙌🏻 Been following your work and Llama Index for quite a while !
~ Jobel Shaji|2023-03-30 12:24:57|‎~ Jobel Shaji joined using this group's invite link
Amogh V|2023-03-30 13:11:14|Asking a dumb question what is Llama index? Been so caught up with visual AI that I've missed a lot of LLM progress 😬
Nirant|2023-03-30 13:12:15|This project: github.com/jerryjliu/gpt_index  The creator+maintainer Jerry Liu will also do a demo at the hackathon — so you'll be able to catch up pretty quick after that!
Kaushik Bokka|2023-03-30 13:13:47|did llama index and langchain raise funds?
Kaushik Bokka|2023-03-30 13:14:50|Curious to see if Harrison would tackle the langchain deployment layer himself
Ravi Theja|2023-03-30 13:14:53|Give a read of Overview section here Amogh, you will get pretty good idea - https://github.com/jerryjliu/llama_index. ‎[3/30/23, 13:15:05] Nirant: ‎image omitted
Ravi Theja|2023-03-30 13:15:15|They are trying to afaik
Kaushik Bokka|2023-03-30 13:16:21|SLAs are so tricky with open source projects; a lot of companies try to prioritize their features and fixes
Kaushik Bokka|2023-03-30 13:16:29|feature requests*
Nirant|2023-03-30 13:16:32|Chase is also doing a lot of community events/webinars btw. Almost 2 a week at this point, Chatbase, Explain Paper and other projects built around that
Kaushik Bokka|2023-03-30 13:16:59|ikr, what a machine
Dev Aggarwal|2023-03-30 13:31:35|Small offtopic: anyone here who got an O1? Looking for advice on lawyers..
~ Animesh mishra|2023-03-30 13:47:45|‎~ Animesh mishra joined from the community
Shreya Rajpal Guardrails|2023-03-30 13:50:45|‎Shreya Rajpal Guardrails joined using this group's invite link
~ Shriniket Acharya|2023-03-30 13:54:23|‎~ Shriniket Acharya joined from the community ‎[3/30/23, 13:55:49] Amogh V: ‎image omitted ‎[3/30/23, 13:55:50] Amogh V: ‎image omitted ‎[3/30/23, 13:55:50] Amogh V: ‎image omitted ‎[3/30/23, 13:55:51] Amogh V: ‎image omitted ‎[3/30/23, 13:58:06] Amogh V: ‎image omitted ‎[3/30/23, 13:58:07] Amogh V: ‎image omitted ‎[3/30/23, 13:58:07] Amogh V: ‎image omitted ‎[3/30/23, 13:58:08] Amogh V: ‎image omitted
Dev Aggarwal|2023-03-30 14:00:32|https://huggingface.co/google/pix2struct-textcaps-large  Found this
Ravi Theja|2023-03-30 14:06:07|The results shown are pretty impressing with pix2struct.
Sudharshan GenAI|2023-03-30 14:11:25|Pretty good
Sudharshan GenAI|2023-03-30 14:11:39|I've found mm-react to be the best - probably SOTA till GPT-4 launches multimodal ‎[3/30/23, 14:12:33] Sudharshan GenAI: ‎image omitted
Sudharshan GenAI|2023-03-30 14:13:20|Randomly collaborating on someone who DMed me on twitter to build poetry CAM   Take a photo and create a poem out of anything
Sudharshan GenAI|2023-03-30 14:13:40|"""In the garden of fading hues, A faithful hound surveys the scene, Where autumn's touch bestows its muse, And time's unyielding hand is keen.  Beneath the canopy of leaves, Of verdant green and pink in bloom, The dog, a sentinel, perceives, A world where beauty meets its doom.  The road, the concrete, side by side, Bear witness to the fall's embrace, While bushes, bricks, and stones abide, In quiet corners of this space.  Rectangular, the stone lies near, A testament to gardens past, As clouds adorn the skies, austere, A canvas where the shadows cast.  Amidst the landscape's fleeting grace, The dog, a guardian, stands proud, In silent vigil, guards his place, Beneath the sky's encroaching shroud."""
Sudharshan GenAI|2023-03-30 14:13:45|Fed to GPT-4
Kaushik Bokka|2023-03-30 14:14:26|what product use cases could you think of with such features?
Sudharshan GenAI|2023-03-30 14:25:35|I see the first wave as mostly fun and interesting products  Like my fridge tweet and this.  An interesting use case my friend wants me to build is company wide docs and image organization (along with docs)  Automatically organize images, understand data etc.
Sudharshan GenAI|2023-03-30 14:25:46|Like glean, for images too
Sudharshan GenAI|2023-03-30 14:26:26|There's also llama mulitmodal - need to benchmark that too.
Nirant|2023-03-30 14:39:54|Please welcome Shreya Rajpal [PHONE], creator+maintainer of Guardrails: github.com/shreyar/guardrails  The project makes it easy for you to get structured output using LLMs like GPT4 — including Python objects (e.g. Pydantic) and of course, JSON. They also have nice tools for you to check for semantic structure too e.g. you can add syntax validators  They've a Discord too: discord.gg/Jsey3mX98B
Aishwarya Goel Inferless 5s for 5G|2023-03-30 14:40:54|Something on these lines : https://www.springworks.in/albus/
Shreya Rajpal Guardrails|2023-03-30 14:43:53|Thanks for inviting me to the group [PHONE]! If you all decide to give Guardrails a spin, lmk! It's pretty helpful if you run into reliability/quality issues with LLMs, or even just for making prompting really easy for getting structured outputs. Excited to see all the cool LLM apps ppl are building in this group!
Sudharshan GenAI|2023-03-30 14:46:35|You have any ideas?
Nirant|2023-03-30 14:47:19|Shreya has also kindly agreed to give a Guardrails demo on Friday late night at the hackathon. Should be pretty useful for anyone working on LLM-Agents, structured parsing and similar sub-tasks!
Sudharshan GenAI|2023-03-30 14:47:43|Btw a fun usecase I saw in my improv group was using GPT-4 to do improv with as a scene actor  Could plugin image models to understand scenes and act better
Shivendu Kumar|2023-03-30 14:56:53|https://twitter.com/sama/status/1641181668206858240?s=20
Shivendu Kumar|2023-03-30 14:56:53|Sam altman coming to india
Sudharshan GenAI|2023-03-30 14:57:47|OpenAI Tour haha
Nirant|2023-03-30 14:58:04|"Very shady ""regulate-in-my-favour-please"" tour on behalf of Microsoft"
Ramakrishnan Lokanathan|2023-03-30 14:58:40|Yes. Not even coming to Bangalore.
Shivendu Kumar|2023-03-30 14:59:49|Mostly travelling to capitals. Talking to different govts.
Sudharshan GenAI|2023-03-30 15:00:01|why govts?
Shivendu Kumar|2023-03-30 15:00:31|reason ^
~ Adhitya Swaminathan|2023-03-30 15:01:07|‎~ Adhitya Swaminathan joined from the community
Adithya L Bhat Hackathon|2023-03-30 15:01:25|He’s going to Delhi not Bangalore! Bad choice
Nirant|2023-03-30 15:01:59|"Microsoft runs World's largest Govt cloud, and was the first company to offer a backdoor to CCP for Windows. At that time, Windows was ""dangerous"" technology.  Microsoft understands that the largest part of any country is not enterprise, or consumer — but Govt!  OpenAI is a Microsoft subsidiary for all practical purposes"
Amir Nagri|2023-03-30 15:02:02|Bhai saab, itni job losses hone wali hai from openai, thoda confidence main to Lena padega
Adithya L Bhat Hackathon|2023-03-30 15:02:14|I have heard about this . Apparently how to tune it according to different rules of each government , like free speech rules and such!
Adithya L Bhat Hackathon|2023-03-30 15:03:23|What to show ! And what not to show
Nirant|2023-03-30 15:04:35|Github (MSFT acquisition) used to share when they got take down requests from Govt here: https://github.com/github/gov-takedowns  They no longer do. Censorship-at-scale is extremely profitable business.
Adithya L Bhat Hackathon|2023-03-30 15:06:04|Unfortunately yes! Great leavy for power ‎[3/30/23, 15:08:10] Dhawal Jain Generative AI Group: ‎image omitted
Hasan Tech Art Guy|2023-03-30 15:09:07|Let me invite them here. I’m currently doing an art residency with that group.
Nirant|2023-03-30 15:09:18|A DNS cert is basically you taking someone else's word instead of a small Twitter celeb 😅
Adithya L Bhat Hackathon|2023-03-30 15:09:35|How many years y’all are into AI?
Hasan Tech Art Guy|2023-03-30 15:09:49|They performed at rang Shankara and BIC recently. AI improve
Nirant|2023-03-30 15:11:38|I was born in the ashes of SVM Kernels and raised in the wilderness of Random Forests  I saw the Deep trenches of ULMFit (github.com/nirantk/hindi2vec — made the first Hindi LM) and was there when BERT moved into the jungle. This is me: https://nirantk.com/about
Hasan Tech Art Guy|2023-03-30 15:12:20|https://instagram.com/climateprov?igshid=YmMyMTA2M2Y=
Kaushik Bokka|2023-03-30 15:13:32|import tensorflow as tf  print(tf.__version__)  >> 1.x
Dev Aggarwal|2023-03-30 15:16:49|6 months here 😬👶
Nirant|2023-03-30 15:17:27|In days or days and nights?
Adithya L Bhat Hackathon|2023-03-30 15:18:54|Been 3 months I guess! Been trying to do things on Kaggle and others ! Small things creating model , tuning different parameters . Lot to learn ! Long way to go!
Dev Aggarwal|2023-03-30 15:19:20|How do you tell the difference ? 😵‍💫
~ Adhitya Swaminathan|2023-03-30 15:22:26|I started training when tf.Session was the only way to do it :))
Adithya L Bhat Hackathon|2023-03-30 15:23:48|So I suppose that’s an OG statement ‎[3/30/23, 15:24:09] Nirant: ‎image omitted
Sumod K Mohan|2023-03-30 15:24:22|For exploring new capabilities and building quick things: no of years might be weak indicator, may be even negative indicator. It's a Brave New World !! 😂.
~ Adhitya Swaminathan|2023-03-30 15:24:22|Theano folks in the house?
Nirant|2023-03-30 15:24:55|They'll need a Caffe before they step out with a Torch
Adithya L Bhat Hackathon|2023-03-30 15:29:25|Sam Altman over elon musk ‎[3/30/23, 15:37:59] Swastik Banerjee: ‎image omitted
Swastik Banerjee|2023-03-30 15:38:20|probably he has changed his view this year lmao
Chirag Jain|2023-03-30 15:40:46|since tf-idf features were slowly being replaced by word2vec from gensim and mainstream torch was in lua
Siddharth Agarwal|2023-03-30 15:41:08|That's a long, long time.
Nirant|2023-03-30 15:41:19|Now you'll have to explain what are gensim and Lua 🤣
Chirag Jain|2023-03-30 15:41:53|but also this doesn't matter if foundations stuff evolves every 2-3 years
Adithya L Bhat Hackathon|2023-03-30 15:42:32|Crazy’
Nirant|2023-03-30 15:42:32|"In before someone says that it's all just matrix multiplication and those ""foundations"" haven't changed"
Siddharth Agarwal|2023-03-30 15:42:33|When I started, word2vec, maybe GloVE, were the bleeding edge of NLP tools. ‎[3/30/23, 15:43:53] Nirant: ‎image omitted
Sudharshan GenAI|2023-03-30 15:44:43|"Haha. Here's mine   import caffe  File ""/home/pbu/Desktop/caffe/python/caffe/__init__.py"", line 1, in <module> from .pycaffe import Net, SGDSolver"
Chirag Jain|2023-03-30 15:45:31|started roughly in late ~2016 during those times industry adoption was at least 2 years behind research publication  these days the abstractions and open source contributions are so good, research is ready to be adopted in 2-3 months
Shubham Sharma 2012C6|2023-03-30 15:45:41|https://www.researchgate.net/publication/308719279_Sentiment_Analysis_for_Mixed_Script_Indic_Sentences i worked on this paper in 2015 and i thought i was working on bleeding edge stuff.   Shows how out of touch research work in our universities was
Nirant|2023-03-30 15:47:38|Same pinch.   I've a 2019 ACL paper from when Sentence Transformer finetuning was still _new_, on Code Mixed Hinglish — though my ex did most of those experiments and I mostly did eval, data and writing: https://aclanthology.org/2020.semeval-1.119/
Chirag Jain|2023-03-30 15:48:31|and likewise infra spend has also increased dramatically back then companies would grind their teeth provisioning even a single gpu, now some of those companies are looking to provision DGX pods 🙏
Dhruv Anand|2023-03-30 15:51:01|Coded a sparse autoencoder in MATLAB back in 2012. Not ashamed to admit that was the peak of my ML prowess ‎[3/30/23, 15:52:40] Gokul Krishnan: ‎GIF omitted
Nirant|2023-03-30 15:53:41|I actually first heard about ML first from [PHONE] nerding about Tom Mitchell's book ‎[3/30/23, 15:56:21] Gokul Krishnan: ‎image omitted ‎[3/30/23, 15:56:22] Gokul Krishnan: ‎image omitted
Siddharth Agarwal|2023-03-30 15:57:12|I think I still have a pdf of it somewhere. The only major book I got a hard copy of was the AI AMA.
Dev Aggarwal|2023-03-30 15:57:59|Curious to know if there are folks from the mlblr / tsai community here!
Gokul Krishnan|2023-03-30 15:59:34|I mucked around with theano and also had a gsoc proposal that didn't go through 😅
Shubham Sharma 2012C6|2023-03-30 15:59:58|What’s your source for discovering the latest papers/works? I saw someone shared a paper from a week ago
Gokul Krishnan|2023-03-30 16:00:29|Tbf, matmul optimization is still an unsolved problem and folks do PhDs on this even today
Nirant|2023-03-30 16:01:33|Follow this firehose, turn on notifs  https://twitter.com/_akhaliq
Yash Pandya|2023-03-30 16:03:14|Deepmind's AlphaTensor is beating them 😅 https://www.nature.com/articles/s41586-022-05172-4
Gokul Krishnan|2023-03-30 16:09:09|Except there was a paper in the next day that found faster matmul algorithm. Just that they were academics that didn't have a PR team behind them
Gokul Krishnan|2023-03-30 16:11:18|https://arxiv.org/abs/2210.04045
Karthik GenerativeAI WhatsApp Group|2023-03-30 17:42:54|‎Karthik GenerativeAI WhatsApp Group joined using this group's invite link
Saurav Akaike|2023-03-30 17:56:20|‎Saurav Akaike joined using this group's invite link
~ Munjal Patel|2023-03-30 18:14:43|‎~ Munjal Patel joined using this group's invite link
Sachin Legaltech|2023-03-30 21:46:03|Wrote A3C in lua torch (it was asynchronous as we were using threads instead processes in Lua) and trained the agent to play doom game .
Bharat Kumar Ramesh Hashmal Web3|2023-03-30 21:49:26|Since alpha zero beat stockfish.  There was some excellent chess coverage around those matches
Bharat Kumar Ramesh Hashmal Web3|2023-03-30 21:49:51|Thankfully it's much simpler to do something with it now
Rahul Bhatnagar|2023-03-30 22:04:48|Around 2018. When I saw Deepminds first demos of neural nets playing Tetris.   Trained my first CNN around that time and taught it to crush the Chrome Dino game.  https://mobile.twitter.com/rhlbhatnagar/status/1309553303156486144
~ Prajna Prayas|2023-03-30 22:12:30|‎~ Prajna Prayas joined from the community
~ Munjal Patel|2023-03-30 22:37:48|https://www.linkedin.com/posts/munjal-patel_mlops-llmops-mlengineer-activity-7047185045303738368-tsA0?utm_source=share&utm_medium=member_android
Nirant|2023-03-30 22:42:26|Hey Munjal, welcome to the group!  For future reference: We actively discourage _self promotion_. Admins will be obliged to remove you the next time this happens.
~ Munjal Patel|2023-03-30 22:46:04|Hi Nirant sorry will not repeat again. My intention was not self promotion but education.
Ojasvi Yadav|2023-03-30 23:10:11|hackathon idea - get all relevant WhatsApp chats from [PHONE] [PHONE] [PHONE] [PHONE] and other organisers related to questions they've been receiving about the upcoming event. Fine-tune a LangChain model on those question answers.   Make the life of organisers easy, probably securing a guaranteed award before the hackathon even begins 😝
Kaushik Bokka|2023-03-30 23:11:04|[PHONE] expected footfall for the hackathon? 🔥
Nirant|2023-03-30 23:12:20|154 invites sent out for the in-person Bengaluru hackathon 20 calls with folks who're likely to submit demos remotely from London, Delhi, Dubai, and Mumbai. 100 people will be there for the demo day alone on Saturday — making the demo day a *250 people event* if 100% people show up!
Kaushik Bokka|2023-03-30 23:12:48|woohooo! ‎[3/31/23, 01:48:23] jyotirmayjk Hackathon: ‎video omitted
jyotirmayjk Hackathon|2023-03-31 01:49:11|A quick hack for DeepMind GPT to handle questions by participants for the upcoming event 😀
jyotirmayjk Hackathon|2023-03-31 01:49:54|It is able to handle multiple context questions ,check the demo vid till the end
jyotirmayjk Hackathon|2023-03-31 01:51:18|Sorry *DeepHack GPT
Shashwat TDC|2023-03-31 01:51:49|Quick extension++ Train it on Modiji's++ msgs vs all the queries to him to create an AI politician 🤖
Dev Aggarwal|2023-03-31 01:57:29|Small flex - you can export this group chat from whatsapp and just upload the text file to gooey and it will get you this search without writing any code  - you can change the prompts and change model settings from the ui!  https://gooey.ai/doc-search/?run_id=x4noe5h3&uid=BdKPkn4uZ1Ys0vXTnxNnyPyXixt1 ‎[3/31/23, 01:57:41] Dev Aggarwal: ‎image omitted
Zainab Bawa|2023-03-31 02:00:42|Will this also herd adults? 😀
Rohit Aggarwal|2023-03-31 07:48:49|Has anybody worked with making LLMs understand table structures? If I have it a document / PDF that has a table in it, the LLM needs to read it row by row, remembering context of the columns as well.
Shashwat TDC|2023-03-31 08:51:34|chatpdf.com
~ Pradyumna Bang|2023-03-31 09:09:56|This is the best!
Amogh V|2023-03-31 09:13:36|Nice, gonna try this out. Did you build it Shashwat?
Shashwat TDC|2023-03-31 09:15:19|No Amogh. I'm building on databases. Text2Sql usecase primarily.
Rounak Datta Hackathon Winner|2023-03-31 09:23:04|From when did WhatsApp start allowing exporting chats as txt 😮
~ Pradyumna Bang|2023-03-31 09:24:01|I think it's been there since quite a while
Aditya Agrawal SuperU|2023-03-31 09:33:50|Yeah used that feature 4-5 years back.. they did in a zip..
Nirant|2023-03-31 10:20:35|2016
Ritesh Invideo Nilenso|2023-03-31 10:41:40|Rephrase.ai just launched a completely automated blog to video powered by GPT-4. I made some contributions to it, and am working on the next version of it.  https://www.rephrase.ai/blog-to-video
Rohit Aggarwal|2023-03-31 11:21:59|thanks! pinged Mathis
Sumod K Mohan|2023-03-31 11:22:01|Ritesh, Some issues in your form. One time the email input field did not render at all, the other time it took more than 20s for the form to load. May be just a load thing.
Sumod K Mohan|2023-03-31 11:22:02|Interesting work btw.
~ Pradyumna Bang|2023-03-31 11:25:04|Hi all, I have a 50min long .mp3 audio file of a meeting which I want to generate transcript from using Whisper. At present, I don't have access to the GPU. Is there any website where I can upload this file and get the transcript Whisper model ?  Thanks in advance!
Ayush Deva|2023-03-31 11:26:02|Hi Pradyumna. You can just use the Whisper API to get the transcript. Don't need GPUs
Dev Aggarwal|2023-03-31 11:26:08|You can upload this to gooey doc search too, might take a while. You can select the asr model in settings  https://gooey.ai/doc-search/
jyotirmayjk Hackathon|2023-03-31 11:27:19|You can use Colab  I’ve run Whisper large model on Colab Jupyter notebooks on free tier account not paid  If you use base model ,then for 50min audio the compute provided should be sufficient in Colab
~ Pradyumna Bang|2023-03-31 11:27:50|Thanks alot, trying this right now
Dev Aggarwal|2023-03-31 11:28:16|Oh you just needed the transcript. Sorry, that’s at https://gooey.ai/asr/
~ Pradyumna Bang|2023-03-31 11:29:05|Oh, thanks!  Do you mind if I ask any follow up questions on DM ?
jyotirmayjk Hackathon|2023-03-31 11:29:21|Sure
Ravi Theja|2023-03-31 11:31:03|You could even use - https://www.gladia.io/ - 1-hour audio file transcript will be extracted in 10-20 seconds which uses openai Whisper backend. Currently, the API is free.
~ Sachin|2023-03-31 11:43:04|‎~ Sachin left ‎[3/31/23, 11:53:37] ~ Pradyumna Bang: ‎image omitted
~ Adhitya Swaminathan|2023-03-31 11:54:42|Maybe check out Assembly.ai, they have a playground to upload files to and try transcription, accuracy is pretty good too.
Ravi Theja|2023-03-31 11:57:00|Checking. I usually use their python API.
Ravi Theja|2023-03-31 11:58:02|[PHONE] I tried just now with a 50-minute audio file by uploading. It worked fine.
~ Pradyumna Bang|2023-03-31 11:58:26|Wierd, I'll try again. Thanks
Ravi Theja|2023-03-31 12:46:27|Tried on one of the medium blogs and it’s pretty good. Is there a constraint on time limit on the video generated?
~ Arpit Maheshwari|2023-03-31 12:51:23|seems like the default is 1 minute
Ritesh Invideo Nilenso|2023-03-31 13:03:09|yes we are generating videos for around 1 minute. There is a limit on size of blog - upto 20k characters
Nirant|2023-03-31 13:03:28|Is the 1 minute limit because of computation/cost or technical limitations?
Ritesh Invideo Nilenso|2023-03-31 13:03:33|let me check
Ritesh Invideo Nilenso|2023-03-31 13:04:16|just a product decision for now, since it's free for now - cost is also a reason
Nirant|2023-03-31 13:04:40|What'd it take to make a Tiktok/IG reels version of this?
Rohit GenerativeAI WhatsApp Group|2023-03-31 13:07:24|Or use whisper.cpp
Ritesh Invideo Nilenso|2023-03-31 13:08:39|You mean in terms of only the resolution or is there any other difference
Nirant|2023-03-31 13:08:58|Pitch, editing style, cuts, screen transitions, overlays
Ritesh Invideo Nilenso|2023-03-31 13:09:17|yes all of that is what i am working on, that is the plan
Ritesh Invideo Nilenso|2023-03-31 13:10:15|i mean there are lower hanging fruits then these , but all of these will come.  Making pitch better will happen sooner
Nirant|2023-03-31 13:10:55|Do it before Bytedance/Tiktok does it!
Dev Aggarwal|2023-03-31 13:15:11|Or runwayml!
Shivendu Kumar|2023-03-31 13:37:04|Could you please share the results? 👀
Shubham Sharma 2012C6|2023-03-31 13:47:44|https://mobile.twitter.com/svembu/status/1641710194458791939
Ravi Theja|2023-03-31 13:49:43|Video: https://personalized.rephrase.ai/?campaign_id=0Rhz6gA1qhU07BWGCjHap03Pfr9SRQ&shareable=true Blog: https://medium.com/mlearning-ai/pre-training-language-models-with-document-links-the-new-way-to-unlock-knowledge-and-answer-4aa8017cd294
~ Lakshya|2023-03-31 13:50:48|hi i built something - https://twitter.com/heat_bender/status/1641716360513486850?s=20
Shubham Sharma 2012C6|2023-03-31 17:51:34|https://arxiv.org/abs/2303.17580 HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. What do you guys think of this?
~ Soumya Patro|2023-03-31 18:09:56|ChatGPT plugins and langchain agents already do this in a way.
~ Arko Cy|2023-03-31 18:13:36|Calling out to fellow Product Managers  - need some insight on some KPI error corrections. Please DM. Thanks :)
Nilesh Christopher|2023-03-31 19:36:11|The Italian Data Protection Authority (DPA) has some interesting things to say about ChatGPT's training models and finds it violation of their data laws.  https://www.garanteprivacy.it/web/guest/home/docweb/-/docweb-display/docweb/9870832#
Akshat Shah - Gojek|2023-04-01 13:31:47|‎Akshat Shah - Gojek joined using this group's invite link
~ jvenom 🦥|2023-04-01 14:15:50|‎~ jvenom 🦥 joined using this group's invite link
Aditya Agrawal SuperU|2023-04-01 16:41:26|Who all going to the DeepHack demo day?
Zainab Bawa|2023-04-01 16:45:08|Live stream is set up here - https://has.gy/ULYt
Zainab Bawa|2023-04-01 16:45:21|Demo Day live stream
~ Nishanth Prabhu|2023-04-01 19:23:52|Hi, Are we done with all the submissions? The live stream just stopped
Nirant|2023-04-01 19:24:44|Taking a 5 min break
~ Nishanth Prabhu|2023-04-01 19:25:19|Oh okay. Thanks Nirant!
Anubhav mishra Zupay|2023-04-01 22:11:10|‎You added Anubhav mishra Zupay
Dev Aggarwal|2023-04-02 05:01:08|https://magicfusion.github.io
Vishaka Vanjani|2023-04-02 05:56:46|‎Vishaka Vanjani left
Shashank Generative AI Group|2023-04-02 19:08:40|hey folks. are there any good/free/local alternatives to D-ID, ElevenLabs? so that i can upload my custom image, audio and get a lip-synced avatar video.
Dev Aggarwal|2023-04-02 19:10:15|https://gooey.ai/lipsync/  Works better on short video clips as input, but yes images also work.
Shashank Generative AI Group|2023-04-02 19:11:49|also, is there anywhere I can read the difference b/w Dreambooth, LoRA, Texual Inversion - differences, pros, cons, training time etc. I had trained custom DB model last year, know a lil bit about the other two, but haven't used them yet...looking to.   i know i can find tutorials for all of them so mainly interested in any pros,cons, comparison bw all 3 methods. thanks.
Shashank Generative AI Group|2023-04-02 19:12:04|thanks!
~ Prajwal|2023-04-02 20:08:26|I don't have a brief doc written but based on my experience, LoRA works really well compared to other two especially after being trained on small amount of data relatively, followed by dreambooth which would provide decent results after multiple attempts of fine tuning whereas textual inversion did'nt return any good results for me, i did try making small changes but that didn't help much as well.
Amir Nagri|2023-04-02 20:50:06|https://youtu.be/dVjMiJsuR5o
Shashank Generative AI Group|2023-04-03 00:07:07|thanks [PHONE] [PHONE] 🙏
Shivendu Kumar|2023-04-03 02:00:34|> But it’s very possible that creativity and what we think of us as human intelligence are just an emergent property of a small number of algorithms operating with a lot of compute power (In fact, many respected neocortex researchers believe there is effectively one algorithm for all intelligence.  I distinctly remember my undergrad advisor saying the reason he was excited about machine intelligence again was that brain research made it seem possible there was only one algorithm computer scientists had to figure out.)  He wrote this in 2015 (8 years ago). Full of crazy but really sensible points. https://blog.samaltman.com/machine-intelligence-part-1
Shivendu Kumar|2023-04-03 02:02:05|> Human brains don’t look all that different from chimp brains, and yet somehow produce wildly different capabilities.  We decry current machine intelligence as cheap tricks, but perhaps our own intelligence is just the emergent combination of a bunch of cheap tricks.  Emergence is all you need?
Karan Ganesan luma.ai|2023-04-04 11:32:07|https://twitter.com/lumalabsai/status/1642883558938411008?s=46 ‎[4/4/23, 11:41:11] Micheil: ‎image omitted
Micheil|2023-04-04 11:41:35|Report here: https://aiindex.stanford.edu/report/
Shimanta Generative AI|2023-04-04 14:06:13|‎Shimanta Generative AI joined using this group's invite link
~ Srinivasan Nandakumar|2023-04-04 14:06:17|‎~ Srinivasan Nandakumar joined using this group's invite link
~ Jatin|2023-04-04 14:06:21|‎~ Jatin joined using this group's invite link
~ Harsha.B|2023-04-04 14:06:34|‎~ Harsha.B joined using this group's invite link
Ritwik 2013|2023-04-04 14:06:53|‎Ritwik 2013 joined using this group's invite link
~ Kartik Sawant|2023-04-04 14:07:25|‎~ Kartik Sawant joined using this group's invite link
Anudeep Yegireddi|2023-04-04 14:08:39|‎Anudeep Yegireddi joined using this group's invite link
Rajdeep Singh GeniePaint From The Hackathon|2023-04-04 14:10:42|‎Rajdeep Singh GeniePaint From The Hackathon joined using this group's invite link
Harshal Bhatia|2023-04-04 14:20:40|‎Harshal Bhatia joined using this group's invite link
Kartik Mandaville|2023-04-04 14:29:00|‎Kartik Mandaville joined using this group's invite link
~ Raveen S|2023-04-04 14:29:37|‎~ Raveen S joined using this group's invite link
~ Rishi|2023-04-04 14:34:01|‎~ Rishi joined using this group's invite link
Deep Samsung R&D|2023-04-04 14:39:57|‎Deep Samsung R&D joined using this group's invite link
~ Praveen Sridhar|2023-04-04 14:43:19|‎~ Praveen Sridhar joined using this group's invite link
Kartik Kwatra|2023-04-04 14:45:23|‎Kartik Kwatra joined using this group's invite link
~ Yash More|2023-04-04 14:49:02|‎~ Yash More joined using this group's invite link
Ankita Mathur Microsoft Sales|2023-04-04 14:53:52|‎Ankita Mathur Microsoft Sales joined using this group's invite link
~ Aditya Chivukula|2023-04-04 14:58:24|‎~ Aditya Chivukula joined using this group's invite link
Snehal Joshi Deloitte|2023-04-04 15:25:18|‎Snehal Joshi Deloitte joined using this group's invite link
~ Sanjeed|2023-04-04 15:46:53|‎~ Sanjeed joined using this group's invite link
~ Rohit Kv|2023-04-04 16:20:05|‎~ Rohit Kv joined using this group's invite link
~ Ketan Sethi|2023-04-04 16:42:49|‎~ Ketan Sethi joined from the community ‎[4/4/23, 17:21:29] Micheil: ‎image omitted
Nirant|2023-04-04 17:22:10|Funny but off topic, we do not encourage this :)
Micheil|2023-04-04 17:22:39|No worries
Manu Hegde|2023-04-04 17:23:56|‎Manu Hegde joined using this group's invite link
~ Rishabh Chandel|2023-04-04 17:30:23|‎~ Rishabh Chandel joined from the community
~ Shreyas Kolte|2023-04-04 17:31:52|‎~ Shreyas Kolte joined using this group's invite link
Abhishek Sahu Ultrahuman|2023-04-04 17:33:17|Hey Hackers, [PHONE] and I have built something in the generative AI space, that we wanted your feedback on: https://twitter.com/CyberSahu/status/1643166480794791938?s=20
~ Rajath|2023-04-04 17:50:53|‎You added ~ Rajath
Dev Aggarwal|2023-04-04 17:59:37|https://github.com/nat/openplayground  They finally released it! The best UI for comparing different LLMs
Nirant|2023-04-04 18:01:36|Collateral Damage: Killing Suhail's playgroundai.com any chance of entry into text LLMs 😂
Dev Aggarwal|2023-04-04 18:03:05|Playground.ai is very different na? I think its more about popular prompts and upvoting rather than comparing models
Ravi Theja|2023-04-04 18:05:43|playgroundai lets you experiment with different diffusion models, parameters, inpainting, base image generation...openplayground also does same thing for LLM's right. ‎[4/4/23, 18:07:42] Dev Aggarwal: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-04-04 18:08:21|Surprised they don't have mid journey 5
Dhruv Anand|2023-04-04 18:10:21|it's free, which is a big deal
Rohit GenerativeAI WhatsApp Group|2023-04-04 18:10:45|AFAIR it's only accessible through discord
Dev Aggarwal|2023-04-04 18:11:31|Yes, I’ve heard that API is in the works
Bharat Kumar Ramesh Hashmal Web3|2023-04-04 18:11:58|Yes, you're right. I presumed it would be in some alpha by now
Rohit GenerativeAI WhatsApp Group|2023-04-04 18:12:51|once it comes out, I believe it's going to be chatgpt moment for them
Kaushik Bokka|2023-04-04 18:19:35|Why the strategy to have a discord bot but not an API?
Rohit GenerativeAI WhatsApp Group|2023-04-04 18:22:13|I think they are/were bootstrapped and inference infra is hard & expensive
~ Adhitya Swaminathan|2023-04-04 18:22:55|I think Stability supports them with GPU resources, not completely sure though.
Sudharshan GenAI|2023-04-04 18:25:06|They’re rolling out API access soon. Heard in their office hours.   They have all the infra they need, the founder sold his last company and has a good amount of funding.
Dev Aggarwal|2023-04-04 18:25:54|Anyone remember magicleap? That’s the guy behind it 😬
Dev Aggarwal|2023-04-04 18:27:09|Sorry leap motion*
Dev Aggarwal|2023-04-04 18:28:47|https://youtu.be/xNqs_S-zEBY  This thing
Kaushik Bokka|2023-04-04 18:29:33|AirBnB for GPUs would be such a thing
Nirant|2023-04-04 18:30:40|Used to be called AWS
Kaushik Bokka|2023-04-04 18:31:03|those are hotels
Kaushik Bokka|2023-04-04 18:31:08|vast.ai
Nirant|2023-04-04 18:31:50|Hetzner Cloud was the OG hotels no? https://www.hetzner.com/cloud
Rohit GenerativeAI WhatsApp Group|2023-04-04 18:34:11|if you mean someone letting renting out their GPUs, then runpod is doing it
Kaushik Bokka|2023-04-04 18:34:37|Damn, didn’t know Jasper trained their models on the Cerebras systems https://www.cerebras.net/press-release/cerebras-systems-and-jasper-partner-on-pioneering-generative-ai-work
Sudharshan GenAI|2023-04-04 19:12:10|Claims to be unofficial MJ API - https://www.imagineapi.dev ‎[4/4/23, 19:12:20] Anudeep Yegireddi: ‎image omitted
Dev Aggarwal|2023-04-04 19:13:33|Did they create a MJ bot for the MJ bot?! 😆
Nirant|2023-04-04 19:46:08|W&B speaks to OpenAI, answers questions about cutoff date and bunch of other tidbits:  https://www.youtube.com/watch?v=eMZpTzFyOWY&t=1 ‎[4/4/23, 22:58:41] Nirant: ‎image omitted
~ Deven|2023-04-04 23:03:05|Langchain is awesome.  Most of the projects I see on Twitter(funded ones too) are just UI on top of Langchain(no harm in that :) ) It has sort of become the foundation layer to build chatbots.
Nirant|2023-04-04 23:03:40|Indians in India should've a globally used GenerativeAI library within next 12 months if we're to be still in the running. We missed the PyTorch/Tensorflow/transformers wave completely.   I don't want to memorise names like Jerry Liu (Llama Index) and Harrison Chase, and would rather remember names like Shreya Rajpal (Guardrails)!
Rasagy Sharma|2023-04-04 23:04:09|For anyone interested in my AI-generated comic from the weekend hackathon:  “Tale of Dattā” is a short comic on mythology of data, created by Rasagy Sharma, using AI to create the art, parts of text & generate background music. It was conceptualized, crafted & presented in under 24 hours for DeepHack hackathon in Bangalore. https://www.youtube.com/watch?v=LflHZZ-3VFM  Finally finished documenting the process here: https://rasagy.in/projects/datta/
Ishavasyam Antler|2023-04-04 23:06:15|‎Ishavasyam Antler joined using this group's invite link
Mannan Amroliwala|2023-04-04 23:16:07|Sooo good
Nirant|2023-04-04 23:16:40|Praise Lord Dattā!
~ Prajna Prayas|2023-04-04 23:19:17|it's actually impressive 🔥
~ Vartika|2023-04-04 23:23:15|Love it! Publish a sequel :)
Krishna Ntkris|2023-04-05 00:20:09|‎You added Krishna Ntkris
jyotirmayjk Hackathon|2023-04-05 00:49:01|Does anyone know if we can utilise OpenAI embeddings model to create graph embeddings?
Ravi Theja|2023-04-05 00:57:28|"One naive approach is if you have graph structure with sentences as nodes, you can use openai embeddings - ""text-embedding-ada-002"" to get node embeddings directly, and using adjacency matric you can compute edge embeddings by averaging the connected nodes."
Nirant|2023-04-05 00:58:33|Pinterest — the OG graph folks would recommend starting off with any base embedding and then update them   The abstract itself is quite good by 2018/19 standards: https://dl.acm.org/doi/abs/10.1145/3292500.3330671
jyotirmayjk Hackathon|2023-04-05 01:07:35|I came across this article on HN and was wondering if it can be done using some form of text representation using ‘text-embedding-ada-002’  https://eng.lyft.com/lyft2vec-embeddings-at-lyft-d4231a76d219
~ Nishant Bhansali|2023-04-05 01:33:34|‎~ Nishant Bhansali joined using this group's invite link
Swastik Banerjee|2023-04-05 02:12:05|Is there a gpt model that i can currently use finetuned with financial data and analysis?
~ Lakshya|2023-04-05 02:15:37|there's some bloomberg gpt ig
Swastik Banerjee|2023-04-05 02:15:53|its not usable yet
~ Adhitya Swaminathan|2023-04-05 02:15:54|Yeah but I don’t think this is available publicly
~ Adhitya Swaminathan|2023-04-05 02:16:08|I somehow doubt they will ever open source it
Swastik Banerjee|2023-04-05 02:16:11|its just a paper by far
Satish DeepHack Sponsor|2023-04-05 02:41:33|It’s a paper of an existing /closed implementation- won’t be open sourcing . It’s trained on their proprietary data .
Satish DeepHack Sponsor|2023-04-05 02:41:42|*sourced ‎[4/5/23, 05:58:23] Ojasvi Yadav: ‎image omitted
Dev Aggarwal|2023-04-05 05:59:13|It works?
Ojasvi Yadav|2023-04-05 05:59:24|500 lol
Ojasvi Yadav|2023-04-05 05:59:56|but it's around the corner it seems
Ojasvi Yadav|2023-04-05 06:00:04|maybe they've rolled it out already to a few people
Ayush Pepper|2023-04-05 06:41:30|‎Ayush Pepper joined using your invite ‎[4/5/23, 07:39:43] Shashwat TDC: ‎Contact card omitted
Shashwat TDC|2023-04-05 07:40:07|[PHONE] can you pls add Abhinav here. He is Shop101 CEO, wanted to join the community
Abhinav Shop101|2023-04-05 07:53:06|‎You added Abhinav Shop101
Nirant|2023-04-05 07:54:04|PSA: Please DM for add or other admin requests in future :)
Nirant|2023-04-05 08:12:06|"In the words of Kaggle Grandmaster Sanyam Bhutani — the ""World's best Deep Learning course""  And I am inclined to agree wholeheartedly :)  This is accessible to anyone with a ~year of programming experience in a modern programming language e.g. Rust, JS, Python. The course is taught completely in Python.  https://twitter.com/jeremyphoward/status/1643410603363692544"
~ Raj|2023-04-05 10:10:32|‎~ Raj left
Manjot Pahwa|2023-04-05 10:56:11|Hey folks! Thinking of having a light beer + pizza mixer of ~20 people building in generative AI at the Lightspeed office in Koramangala opposite to third wave on the 13th of April, next week Thursday. We can keep the conversations focused on just new things people are building as well as what I'm seeing in the market more broadly in the US and around the world. Folks that are interested, please do a thumbs up on this thread! I'll start a separate group with you all! Looking forward 🙂
Manjot Pahwa|2023-04-05 11:12:01|If we exceed 20, no worries, will do this at least once in 3 weeks, so should be just including people in the next set.
Manjot Pahwa|2023-04-05 11:27:54|If you all can fill up this form: https://docs.google.com/forms/d/e/1FAIpQLSfRg1AOSSfSs8ZBbKzWd5ne_8JqzJrwFvy_NN0K-TUIdG2jYA/viewform
~ Soumya Patro|2023-04-05 12:11:38|Good to see so many events around AI happening in Bangalore. Sharing one I am hosting on April 14th, 6pm at the Draper Startup House, Koramangala.   Open to both founders and researchers.  RSVP here - https://lu.ma/uy389zl2
Dhruv Anand|2023-04-05 12:31:49|Folks, I got the 2500$ openAI credits from here! You all should check it out 😀
Sudharshan GenAI|2023-04-05 12:32:41|Not a phishing attack? Share an email screenshot etc?
Dhruv Anand|2023-04-05 12:34:27|I mean this is an open ai link. Not sure what else would convince you
Sudharshan GenAI|2023-04-05 12:35:09|Oh right, this link is different ‎[4/5/23, 12:35:29] Dhruv Anand: ‎image omitted
Shimanta Generative AI|2023-04-05 12:36:04|You had a crunchbase profile? I set it to NA while filling the form 😅
Dhruv Anand|2023-04-05 12:36:32|lol I created on last year for lulz after I incorporated my company
Ayush Deva|2023-04-05 12:37:11|Same. I did too. Although I have an incorporated company so that might have helped.
Shimanta Generative AI|2023-04-05 12:37:27|Guess I won’t be receiving the credits anytime soon ‎[4/5/23, 12:49:50] Kartik Mandaville: ‎image omitted
~ Srinivasan Nandakumar|2023-04-05 12:51:19|You can get this only if you are registered as a start-up or even if you are an individual looking to build stuff?
The GenerativeAI Group|2023-04-05 12:52:03|‎You added Anandamoy RoyChowdhary Sequoia and Pushpak Kedia Sequoia
Kartik Mandaville|2023-04-05 12:52:08|registered as startup and then got this but took many months
Anurag Singh Amul Twitter Friend|2023-04-05 12:52:20|I recently came across a Blind post saying Google is moving the majority of its resources from Assistant to Bard, and heard similar sort of news for Amazon's Alexa.  It doesn't make sense to me, leveraging generative AI for more natural voice based assistants with  longer conversation context is not the priority for these established players in voice assistant domaiy.  Am I missing something, a noob ask?
Nirant|2023-04-05 12:53:02|Incentives explain more of these decisions than insight :)
~ Sanjeed|2023-04-05 12:56:07|Do we get this only if it's an incorporated company?
Shashwat TDC|2023-04-05 12:56:35|‎POLL: y'all, who is chasing yc deadline? 830 AM IST, 7 Apr ‎OPTION: me (3 votes) ‎OPTION: not me (12 votes)
Anudeep Yegireddi|2023-04-05 12:57:05|8:30am 8th April no?
Dhruv Anand|2023-04-05 12:57:57|Perhaps, but I didn't provide any official details of the company (only website and crunchbase)
Shashwat TDC|2023-04-05 12:58:23|sorry for the scare guys :P
Gokul Krishnan|2023-04-05 12:59:01|This is two phenomenon occurring almost at the same time. Amazon Alexa and Google assistant orgs were slowly being shutdown / dismantled due to economic downturn. With the sudden hype around LLMs, they're simply pivoting these teams instead of firing and hiring
Anurag Singh Amul Twitter Friend|2023-04-05 13:22:12|This makes sense, but I thought post LLM hype they will just rejuvenate these projects but understandable.
Aditya Agrawal SuperU|2023-04-05 13:28:36|May be next time.
Vineet Agarwal Antler|2023-04-05 13:41:03|‎You added Vineet Agarwal Antler
~ Akhil Ramolla|2023-04-05 14:48:02|‎~ Akhil Ramolla joined using this group's invite link
Kishore GenAI|2023-04-05 15:07:33|Update on this.   The total number of valid links drastically decreased after it provided close to 1000 unique urls. I was able to reduce repetitions by making it state “I will not repeat any url from your messages or my previous answer”.  It was a fun experiment but not scalable at all.
Nirant|2023-04-05 15:09:22|All that I'm hearing is the first 1000 are free 🤣
Dev Aggarwal|2023-04-05 15:11:24|https://community.riscv.org/events/details/risc-v-international-risc-v-in-india-presents-nerds-talking-to-nerds-about-risc-v-hosted-by-tenstorrent/waitlist/151  Any way you guys have contacts here? I didn’t register but Jim Keller is in Bangalore and I must meet him 😭🔥
~ Nikhil|2023-04-05 15:24:19|‎~ Nikhil joined using this group's invite link
Swastik Banerjee|2023-04-05 16:31:08|Is anyone aware of research happening in Deepfake detection?
Swastik Banerjee|2023-04-05 16:31:17|any good app/software for it? ‎[4/5/23, 16:31:51] Swastik Banerjee: ‎image omitted
Nirant|2023-04-05 16:32:52|[PHONE] from Spoofsense.ai is working on this I believe.
Swastik Banerjee|2023-04-05 16:32:57|Found this effort by Microsoft as well, but it doesn’t have a working model for public ig: https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/
Nirant|2023-04-05 16:35:14|Not releasing is probably a good call, tricky thing to release authenticators because that makes it easier for next generation of cheaters to evolve/reverse engineer.
Nirant|2023-04-05 16:36:41|I recall that long time ago Y! had released a nudity detection model, and a bunch figured out Wordpress and other social media companies were using similar CNN based methods — and had bypasses to detect babies from adults.   Voila, you suddenly had tattoos and other photo morphs which fooled CNNs into thinking that lady isn't naked.  Ofc, this JAV-porn-funded-tech was great for Taiwanese protestors hiding from CCP cameras, but now I've digressed enough.
Nirant|2023-04-05 16:37:53|Found the model. It's 7 years ago and written in Caffe.  https://github.com/yahoo/open_nsfw
Swastik Banerjee|2023-04-05 16:39:16|interesting, thanks for sharing Nirant
Swastik Banerjee|2023-04-05 16:48:13|one lofty way I could think of is all newly created images having a mandatory hash/digital signature like NFTs to verify and validate their origin; much like how cash functions basically; not having one would make it a forged piece and socially unacceptable.
Swastik Banerjee|2023-04-05 16:48:33|not sure what’ll be the limitations of this. would probably take a decade to implement
Nirant|2023-04-05 16:49:23|Sigh, every generation re-invents pgp keys, pdf standards, and SSO 😅
Swastik Banerjee|2023-04-05 16:49:24|not only images, I mean any digital “information”
Swastik Banerjee|2023-04-05 16:51:02|sure but vulnerability is better than no-check, i mean ig
Nirant|2023-04-05 16:51:35|I meant, that we've to re-invent to keep up. The threat surface has evolved too.
Swastik Banerjee|2023-04-05 16:54:47|absolutely; cryptography is a constantly-evolving process/field
~ Uneet|2023-04-05 17:12:51|can use this https://kroop.ai/the-vizmantiz/
Kartik Mandaville|2023-04-05 18:30:00|Has anyone seen an API to categorize questions into HR, Finance, Marketing etc?
Nirant|2023-04-05 18:31:01|DM, send me 20 samples, can make you one over the weekend?
Kartik Mandaville|2023-04-05 18:33:10|Yes but will need to host etc / I was thinking if there's a service which could do analytics etc, retagging etc
Nirant|2023-04-05 18:33:40|Google Sheets has GPT4 if it's batch 😂
Kartik Mandaville|2023-04-05 18:34:25|"are you think of a prompt ""Please categorize this into HR, Finance"" etc?"
Nirant|2023-04-05 18:34:48|That's the baseline, yeah
Ojasvi Yadav|2023-04-05 18:35:19|It would be great if you can give it samples in the prompt itself and perhaps chain it with the system response and then in the second user message send your input query
Kartik Mandaville|2023-04-05 18:35:42|Does anyone know how to get more than $1K/month hard limit of OpenAI? We're going to be crossing that any day and I've already applied for an increase.
Ojasvi Yadav|2023-04-05 18:35:43|Sorry didn't bother with punctuations 😅
Kartik Mandaville|2023-04-05 18:35:57|yes / can get very expensive very quickly. 5K questions a day.
jyotirmayjk Hackathon|2023-04-05 18:38:50|Can it be done by similarity search ?  Create Index of topics and sample questions Create index of these indexes  Then compute similarity of question and then use chaining to assign category based on max similarity score ?
Ojasvi Yadav|2023-04-05 18:38:58|You can perhaps then use gpt4 data do generate your own dataset
Ojasvi Yadav|2023-04-05 18:39:12|And then train a model of your own labelled dataset
Ojasvi Yadav|2023-04-05 18:39:20|And use that in prod
Nirant|2023-04-05 18:39:31|Over engineering friends
Ojasvi Yadav|2023-04-05 18:39:44|Perhaps :p
Nirant|2023-04-05 18:40:03|Run this against a decent prompt and see how most of it will just work
Ojasvi Yadav|2023-04-05 18:40:14|Prone to less accuracy
Nirant|2023-04-05 18:40:44|I used the Google Sheet workflow to decide who to invite for the hackathon, over 200 folks applied
Dev Aggarwal|2023-04-05 18:41:29|Just descibe what HR and Finance mean, and gpt will classify pretty well.   I used this technique to classify harmful content for the hackathon project  https://gooey.ai/compare-large-language-models/?example_id=e5e6tba3
Dev Aggarwal|2023-04-05 18:41:56|This technique was also used by openai to train gpt4
Ojasvi Yadav|2023-04-05 18:42:10|Gooey is such a cool ass Swiss knife
Ojasvi Yadav|2023-04-05 18:42:13|Kudos to you
jyotirmayjk Hackathon|2023-04-05 18:46:23|The trade off I was considering was using prompt to classify would require a more expensive API end point   Using embedding end point would be cheaper,you need to create embeddings only once And subsequently API calls would be just embedding the user input which won’t consume a lot of tokens
Nirant|2023-04-05 18:46:51|Turbo is cheaper than Ada?
jyotirmayjk Hackathon|2023-04-05 18:56:11|Could be that I might have referred to wrong prices then  Based on that I assumed ada embedding to be cheapest
Nirant|2023-04-05 18:57:11|I could be wrong as well, let's check and come back
Kartik Mandaville|2023-04-05 18:59:26|who's the largest openai customer in India? ‎[4/5/23, 19:01:30] Nirant: ‎image omitted ‎[4/5/23, 19:01:30] Nirant: ‎image omitted
Dev Aggarwal|2023-04-05 19:04:42|https://www.buildt.ai/blog/incorrectusage  “Our solution is simple, generate a moderately sized corpus of completions made by davinci for a given task, and fine-tune a model like babbage to do the same task. If done correctly you can get near-identical completions (or at least 90% similarity) at a 40x lower price and around 4-5x better latency.”
Rohit Aggarwal|2023-04-05 19:04:59|Pepper is one of the larger customers.. fwik
Anshul Bhide Replit|2023-04-05 19:06:10|how much do you think they spend per month?
Rohit Aggarwal|2023-04-05 19:07:29|not sure if I can share that, but what are you looking for?
~ Mohit Khullar|2023-04-05 19:24:20|‎~ Mohit Khullar joined using this group's invite link
Shashwat TDC|2023-04-05 20:12:45|https://analyticsindiamag.com/hugging-face-launches-gpt-4-alternative-vicuna-13b/
Gokul Krishnan|2023-04-05 20:33:19|Neat! This seems to be essentially knowledge distillation+human in loop for higher quality labels. Or do folks think this is a false equivalence?
jyotirmayjk Hackathon|2023-04-05 20:49:45|Here’s on Zero Knowledge Machine learning published by WorldCoin   https://worldcoin.org/blog/engineering/intro-to-zkml#motivation-and-current-efforts-in-zkml  I think it might work well for this use case to prove authenticity vs Ai generated content
jyotirmayjk Hackathon|2023-04-05 20:52:05|One good use case they’ve highlighted is on using ZMKL for the purpose of inference on medical data
Dhruv Anand|2023-04-05 21:12:06|"""HuggingFace launches"""
Nirant|2023-04-05 21:44:48|Please don't share outright wrong press. Erodes trust in the group 😀
Shashank Generative AI Group|2023-04-05 22:03:12|hey folks, what's the status of prompt injection in gpt4?  are there some prompt injection templates which worked in 3/3.5 but not in 4?  would love to have 3-5 examples 🙏  im trying out a new way of making these work again, need some examples to prove it 😅
~ Rohan|2023-04-05 22:06:48|Funny you should ask, just earlier today I was experimenting with prompt injection out of curiosity. I know that in chatGPT and GPT 3, 3.5, asking it to simulate another agent with different ideals works well. I don't have access to GPT 4 but have heard that this doesn't work well with it. What, in particular, are you interested about in prompt injections? ‎[4/5/23, 22:07:04] ~ Rohan: ‎image omitted
~ Rohan|2023-04-05 22:07:16|one silly example from my experiments
Shashank Generative AI Group|2023-04-05 22:07:59|thanks. i just want examples which worked before but don't right now in chatgpt-4.
Shashank Generative AI Group|2023-04-05 22:08:49|ask it to create a full form for that name 😂
~ Rohan|2023-04-05 22:11:00|You can make it do a lot of funny things with this hack. I'll probably get kicked out by the admins if I post too many of those screenshots 😂
Ojasvi Yadav|2023-04-05 22:12:03|My DMs are open, send me your darkest work
Nirant|2023-04-05 22:29:40|Go ahead da. Dumbledore's Army will always have a space in Room of Requirements!
~ mouryA|2023-04-05 22:42:52|‎~ mouryA joined using this group's invite link
~ Prajwal|2023-04-05 23:10:08|I've experimented with GPT-4 and it is really good with handling prompt injections. It sticks to the system prompt and straight up denies such prompt injections methods. Atleast with the experiments I did, I had no luck to get promo injection working with GPT-4. OpenAI seems to have worked well on handling it.
~ Adhitya Swaminathan|2023-04-06 00:09:34|I reckon they made good use of the system prompt this time. My guess is that it’s appended at the END of all previous messages and the network is trained to ignore the grammatical content of it, but obey the instructions.
~ Prajwal|2023-04-06 00:11:42|Yep, could be the case.
Anubhav mishra Zupay|2023-04-06 01:05:44|yo anyone building anything for gen ai applications in schools?
Krishna Ntkris|2023-04-06 04:34:33|Im looking to create Sparse Veccors and do hybrid search. What is the best model to use in a prod environment? ‎[4/6/23, 05:29:31] Dev Aggarwal: ‎Contact card omitted
Dev Aggarwal|2023-04-06 05:29:43|Doing a small experiment, say hi to this guy 😬
~ Lakshya|2023-04-06 05:48:52|Nicee
~ Lakshya|2023-04-06 05:49:01|What are you using for text2vid
Ojasvi Yadav|2023-04-06 06:56:08|Goodmorning folks. Does anyone know how Danny postma is doing cloth transfer?  For example, he's able to take a picture of a model wearing a tshirt and replace that with another clothing. I think he can also re-imagine an apparel on customer's body.  https://twitter.com/dannypostmaa/status/1635630263148355585?s=46&t=FvScmWlwJalkIndmUHhjjQ
Ojasvi Yadav|2023-04-06 06:57:19|Is he masking the cloth first, and then doing style transfer? Even then, the results look near perfect and artefact free, unlike what style transfer or img2img can do
Prayank Swaroop Accel|2023-04-06 07:15:15|https://arxiv.org/abs/2304.01852
Prayank Swaroop Accel|2023-04-06 07:20:02|This came out two days ago 👆
Dev Aggarwal|2023-04-06 08:01:54|https://github.com/sangyun884/HR-VITON
~ Prajna Prayas|2023-04-06 08:34:52|Has anyone tried a paid subscription of MidJourney from India? My payments seem not to be going through.
Abhinav Shop101|2023-04-06 08:36:36|Yes - my team had setup a subscription
~ Prajna Prayas|2023-04-06 08:42:19|Did you pay for it by credit card or is there any other mode of payment available?
Harsh Gupta Felvin|2023-04-06 08:43:45|This is so cool!!
Saurav Akaike|2023-04-06 09:06:31|https://youtu.be/E7fGsSNKMc4
Abhinav Shop101|2023-04-06 09:07:26|Personal citi Indian master credit card
Shashank Generative AI Group|2023-04-06 09:54:15|it's a stripe link, right? i think other modes should work as well. i used my amazon icici cc
Heer Shingala|2023-04-06 13:10:59|more good ideas on how to use the platform ---  https://www.linkedin.com/feed/update/urn:li:activity:7047626780601442304?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7047626780601442304%29
Ojasvi Yadav|2023-04-06 13:12:12|I see my college's library in the preview 👀
Heer Shingala|2023-04-06 13:12:25|😱
Ojasvi Yadav|2023-04-06 13:12:51|"Yeah that's definitely Trinity college Dublins library ""the book of Kells"""
~ Ankur Khandelwal|2023-04-06 13:15:21|‎~ Ankur Khandelwal joined using this group's invite link
Dipin Chopra|2023-04-06 13:17:53|Hi folks. I’m trying to achieve text to color grading similar to this model provided by RunwayML.   https://runwayml.com/ai-magic-tools/text-to-color-grade/  Has anyone come across a model available for this.
Amir Nagri|2023-04-06 13:41:34|Nice, runwayml is 🔥
Nirant|2023-04-06 14:01:51|Can't recall which teams had asked for this specifically, but finetuned STT for Indian languages: https://huggingface.co/blog/fine-tune-whisper
Nirant|2023-04-06 14:02:48|And dataset, wave2vec models: https://github.com/Open-Speech-EkStep/vakyansh-models
~ Pradyumna Bang|2023-04-06 14:07:57|https://twitter.com/MetaAI/status/1643602729615646720   Meta has released a segmentation model which can be tried here : https://segment-anything.com/
~ Ankur Khandelwal|2023-04-06 15:03:15|hey everyone,  is it possible to get the list of all the pinecone ids?  Some context- I have content(youtube transcriptions) stored into pinecone. Now I want to generate some tweet ideas based on pinecone db data. Is it possible? there is no query involve.
Dev Aggarwal|2023-04-06 15:03:57|Quick q, how big is the database?
Nirant|2023-04-06 15:03:59|cc [PHONE] did you work with Pinecone?   Also, [PHONE] has hacked around a bit with this
~ Ankur Khandelwal|2023-04-06 15:05:01|3361 - vector count
Dev Aggarwal|2023-04-06 15:05:45|Not to derail your project, but this sounds like an xy problem. You dont need the complexity of a vector database at this scale. Just use pandas
~ Ankur Khandelwal|2023-04-06 15:06:29|Will the response be faster?
Dev Aggarwal|2023-04-06 15:06:58|Yes. It will be in-memory and require no network calls.
Dev Aggarwal|2023-04-06 15:07:17|Openai has notebook examples of it too
Dev Aggarwal|2023-04-06 15:07:39|Not to mention, so much easier to debug and inspect
Nirant|2023-04-06 15:08:06|Ankur, how comfy are you with Python/pandas ecosystem?
~ Ankur Khandelwal|2023-04-06 15:08:21|Very little.. learning on go
Dev Aggarwal|2023-04-06 15:08:55|Hmm, in that case you can also do what I do and just do python lists and not even do pandas 😂 But I guess that’s not for everyone
Nirant|2023-04-06 15:09:01|Okay, if I can teach you how to do this in Google Sheets, will that be faster for you?
~ Ankur Khandelwal|2023-04-06 15:09:07|Any link?
~ Ankur Khandelwal|2023-04-06 15:09:25|And how you decide when vector db is better ? And which vector db is much pinecone, superbase etc.. or all these are just brands and using same tech under the hood?
Dev Aggarwal|2023-04-06 15:09:28|Very interested as well
Nirant|2023-04-06 15:09:42|Aside: Keeping this convo on main, since 2-5 people have pinged with similar/adjacent questions, and hoping that answering this would help more folks :)
~ Ankur Khandelwal|2023-04-06 15:10:23|Really..
~ Ankur Khandelwal|2023-04-06 15:10:44|Nah.. not looking at google sheets ways..
Dev Aggarwal|2023-04-06 15:10:46|Yes. 3000 rows is pocket change
Dev Aggarwal|2023-04-06 15:11:13|https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb ‎[4/6/23, 15:11:32] ~ Ankur Khandelwal: ‎image omitted
Nirant|2023-04-06 15:12:55|For any indie hackers, you can use Google Sheet as a db to launch a GPT4 app as well:  https://coefficient.io/ — full CRUD https://steinhq.com/ — CRD
Dev Aggarwal|2023-04-06 15:13:43|Small self promotion: Gooey.ai supports this as well, and even lets you create bots that refer to google sheets 😬
~ Aman|2023-04-06 15:14:56|You can use self-hosted postgres with pgvector too
Nirant|2023-04-06 15:15:16|Pinecone and Supabase are both over the network. Pinecone is _vector first_, while Supabase is basically managed Postgres. So querying metadata is hard and it's terrible at ranking/search for both. If you've a complex webapp at launch, you can launch with Supabase. It's just Postgres.   If you're working on something with search needs e.g. QA, would recommend looking at trychroma.com because it wraps around Duckdb — you can run analytics and add basic filters quite reliably via SQL
Swastik Banerjee|2023-04-06 15:16:00|nice
Nirant|2023-04-06 15:16:24|Chroma works in-memory, persists state (unlike Pandas) — and no network overhead. Unlike Weaviate, it's quite a thin Docker image and doesn't need bells and whistles — just pip install and it works.
Nirant|2023-04-06 15:16:52|"Chroma can do a lot better dev marketing by saying: ""It works"""
Dev Aggarwal|2023-04-06 15:17:01|The Founder is also very nice
Nirant|2023-04-06 15:17:39|And in a market where Pinecone deletes your vectors, Weaviate doesn't review PRs — that's quite important 😅
Dev Aggarwal|2023-04-06 15:17:47|Indian gov has finedtuned checkpoints too - https://huggingface.co/vasista22/whisper-hindi-large-v2
Swastik Banerjee|2023-04-06 15:18:41|is there an api for this?
Dev Aggarwal|2023-04-06 15:19:12|Sorry I can’t help self plug again - https://gooey.ai/asr/
Swastik Banerjee|2023-04-06 15:20:51|this notebook had serious finetuning-example problems ‎[4/6/23, 15:20:57] Nirant: ‎GIF omitted
Nirant|2023-04-06 15:21:34|You can make $500 MRR by fixing OpenAI Notebook bugs and putting behind a Stripe link and Fly.io deployment at this point
Swastik Banerjee|2023-04-06 15:22:03|wait what
Swastik Banerjee|2023-04-06 15:22:20|I’m a contributor of openai cookbook: https://github.com/openai/openai-cookbook/blob/6df6ceff470eeba26a56de131254e775292eac22/examples/fine-tuned_qa/olympics-1-collect-data.ipynb
Swastik Banerjee|2023-04-06 15:22:26|How can I make money?
Ravi Theja|2023-04-06 15:25:08|[PHONE] how much time it takes to insert embeddings/ data into chroma? Asking this in the context of online/ on the fly data insertion.
Nirant|2023-04-06 15:25:50|Problem Statement: Finetune off the shelf embedding for a specific domain, extremely useful for improving search ranking and QA. Empirically proved by ColBERT and Vespa both.   How to solve: Write a thin feed forward network which takes the OpenAI embedding for a chunk (e.g. langchain chunk) and a corresponding question — train using the ideas in the OpenAI notebook you shared and/or contrastive learning. Very light, very fast. Can do on CPU even, since it's batch.  Who to sell: Every damn SiteGPT/Chatbase kinda jokeass idiot launching on PH  How to price: Since you own the code and will eventually have domain specific data embeddings, can license those to on-prem players for much larger e.g. $5K MRR
Nirant|2023-04-06 15:26:30|Host on a web service to show that it works, market with a ton of benchmarks — mock every commercial service who can't answer questions from their own pricing page _almost always_
Nirant|2023-04-06 15:27:07|10% kalesh marketing (why does this problem matter), 90% convince that it's enough value (here is my solution)
Nirant|2023-04-06 15:27:51|Haven't profiled it tbh, but for a 50K chunk/rows size, it was more than 30s. So on the fly should be worth taking a shot at
Nirant|2023-04-06 15:29:15|This kinda homework/advice is what I invoice $500 to Series A CTOs/Founders usually 😆
Dev Aggarwal|2023-04-06 15:29:15|Nirant since we’re on this topic, is there any way to use colbert / dsp over an unlabelled dataset?
Anagh Prasad|2023-04-06 15:30:12|This is very interesting commercially. Many fashion brand owners are quite keen on AI generated catalogues, and do away with model photoshoots
Anagh Prasad|2023-04-06 15:30:20|The market pull is real for that use case
Nirant|2023-04-06 15:30:53|"Happy to share ideas on DM, when I am sober on Sunday. Have not tested this enough. But zooming out, I refuse to believe that there is such a thing as ""unlabeled text data"" anymore."
Krishna Ntkris|2023-04-06 15:33:06|Anybody know if I can use hydbrid embeddings on Chroma?
~ Harsha.B|2023-04-06 15:33:56|Embedding search is very powerful but I feel the linear nature of the embeddings can be limiting, not in terms of performance but the semantic capacity.  Is there are work on representing a semantic graph DB which can be traversed upon some text input? Might be a better solution for having a “data” interface to these LLMs. Essentially we can consider this as the “memory” of the brain and LLMs can act the the main processing component of the brain.
Nirant|2023-04-06 15:34:54|"Would be helpful if you elaborated on what do you mean by ""hybrid"" :)"
Nirant|2023-04-06 15:36:23|I love this constant human urge to decouple systems into memory, reasoning, context and what not — despite 15 years of ML research proving that combined systems outperform decoupled systems.   Hell, even Google and Youtube search is powered via Brain. And Spotify Recsys is a pseudo-blackbox
Krishna Ntkris|2023-04-06 15:36:59|Sure, so hybrid meaning searching for keywords + semantic meaning. My understanding is that you can use sparse + dense embeddings to achieve better accuracy on results. Pinecone for example allows you to store both of these for a single ID. Wondering if Chroma does the same  https://www.pinecone.io/learn/hybrid-search-intro/
Nirant|2023-04-06 15:38:25|Yes, Chroma does the same. They don't have good docs around it yet though. Assuming that you're a hacker solving for time to market, launch with Pinecone. Move to Chroma when someone asks on-premise
~ Harsha.B|2023-04-06 15:40:02|Combined system definitely will perform better and I feel we are on the verge of achieving this in AI. But as of now it’s clear that memory is a limiting factor of LLMs and hence we need alternative solutions.  But I feel that along these lines, the “semantic DB” can potentially be incorporated completely within future language models or at the very least be tightly coupled with them.
Swastik Banerjee|2023-04-06 15:41:06|something related: https://twitter.com/LangChainAI/status/1643628476505681920?s=20
~ Harsha.B|2023-04-06 15:41:38|Thanks, will have a look 🙏🏽
Nirant|2023-04-06 15:42:47|"""Managed Retrieval Engines"" — clearly a Management Consultant type was paid to rebrand hosted services into something cooler, so that we can add one more category to G2 and then become it's leader 🤣"
Dhruv Anand|2023-04-06 15:44:24|The most basic model is to use sklearn's CountVectorizer (which is based on bag of words) on the text, and use the sparse vectors generated by it. All conventional systems use bm25, tfidf etc., So you could generate sparse vectors from that as well.
Dhruv Anand|2023-04-06 15:45:42|What would be the nodes and edges of this graph. Idea sounds interesting, but would like to hear more of your thoughts on it
~ Harsha.B|2023-04-06 15:47:57|Some sort of a entity relationship graph might work, upon some text input, we could semantically traverse the graph to filter out the relevant nodes and edges and focus on them for future processing (using LLMs maybe)  The entire creation, traversal and updation of this graph could be facilitated by a language model as well, possibly a smaller and faster one
~ Harsha.B|2023-04-06 15:49:45|Even I’m not sure if it will work but I definitely feel there are some semantic gaps when using purely embeddings and this might be a solution
Dhruv Anand|2023-04-06 15:51:37|The thing is: *everything* can be (and is) linearly embeddable. Even graphs themselves 😀.  Kind of separate: There is a possibility of using an existing graphDB (like on Neo4j) in conjunction with text embeddings for each node/edge based on their content, to do a semantic semantic search (semantic was also used for graphDBs at one point)
~ Harsha.B|2023-04-06 15:52:26|Understood, yea the graph db approach makes a lot of sense
Dhruv Anand|2023-04-06 15:52:46|I'm actually designing something like the second for a company right now
~ Prateek|2023-04-06 15:52:59|‎~ Prateek left
~ Sumon K Chakrabarti|2023-04-06 15:54:18|‎Soumyadeep Mukherjee added ~ Sumon K Chakrabarti ‎[4/6/23, 15:54:27] Dhruv Anand: ‎image omitted
~ Sumon K Chakrabarti|2023-04-06 15:54:38|‎Soumyadeep Mukherjee removed ~ Sumon K Chakrabarti
~ Suman Agarwal|2023-04-06 15:54:53|‎Soumyadeep Mukherjee added ~ Suman Agarwal
~ Harsha.B|2023-04-06 15:55:31|Nice nice thanks will check it out 🙏🏽
Dhruv Anand|2023-04-06 15:57:32|I wonder how many of their new integrations are going to be business-motivated (eg: the bm25 being with Elastic). I'm guessing we can still contribute our own adaptors for other platforms to their GitHub..
Anudeep Yegireddi|2023-04-06 15:57:52|Nope, used an in memory JSON file with embeddings stored in a key value store. For the hack it was good enough, but for scaling it I was planning to use weaviate.   Are they equivalent or in one preferred over the other?
Swastik Banerjee|2023-04-06 16:06:54|b25 is more fundamental I think… it’s a class in lucene, on top of which Elastic is essentially built. So can’t say it’s entirely business-motivated in this case: I can see scenarios: a few bootstrapped search system getting benefitted by this
Swastik Banerjee|2023-04-06 16:10:04|By “bootstrapped” I mean those who have their own “search-system”, and do not use Elastic, etc. I cannot say more than this. 👀
~ Santhosh Guru|2023-04-06 16:15:57|‎~ Santhosh Guru left
Shashank Generative AI Group|2023-04-06 16:27:41|btw, langchain has some stuff around graphs as well   https://python.langchain.com/en/latest/modules/memory/types/kg.html https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html
Shashank Generative AI Group|2023-04-06 16:29:41|for anyone using pinecone, just be careful. their pricing is very confusing. this dude paid $1000 for ... ~no usage https://twitter.com/Exploringfornow/status/1642607079285219328
~ Ankur Khandelwal|2023-04-06 16:35:22|yeahs got $24 billing for 5 days with just 10 queries -
Ravi Theja|2023-04-06 16:36:38|For how many indexes?
~ Ankur Khandelwal|2023-04-06 16:38:05|2
Shashank Generative AI Group|2023-04-06 16:39:41|damn. could've had one month of ChatGPT Pro and still have $4 left 😂
Ravi Theja|2023-04-06 16:40:27|Then it should be correct I guess. One index costs approx $2.3 per day and 2 indexes for 5 days it’s $24
Krishna Ntkris|2023-04-06 16:41:31|Was the bill because he was creating an index per customer or something?
Lavish 2017|2023-04-06 17:11:34|only after his tweet I deleted my unused stuff on Pinecone, did not know I was paying for it.
Amir Nagri|2023-04-06 17:25:56|i checked my account as well, just in case  Saas companies today lure you in with free tier, but need to have credit card on file, and then shock you with a bill. i got shafted in that fashion by digital ocean, created a project there as part of hackathon credits, and then suddenly was sent a bill last month, no way to get out, luckily it was only ~40$
Dev Aggarwal|2023-04-06 17:26:33|Digital ocean used to be the nice ones 🥲
~ Ankur Khandelwal|2023-04-06 17:27:28|thats why i use credit card with limits. so if by any chance any tools more than what I can pay. Service stops.
Amir Nagri|2023-04-06 17:28:38|pinecone started off with a lot of community collaboration, their blogs on semantic search by james briggs are still my favorite on the topic ‎[4/6/23, 17:31:29] Swastik Banerjee: ‎image omitted
Shashank Generative AI Group|2023-04-06 17:34:37|this was generated by chatgpt, right?
Swastik Banerjee|2023-04-06 17:35:02|lol, no
Shashank Generative AI Group|2023-04-06 17:35:22|i only use stolen credit cards 😎
Rhythm Gupta IITD|2023-04-06 17:35:38|pure dadaji vibes..
Mannan Amroliwala|2023-04-06 17:36:00|‎Mannan Amroliwala left
Shimanta Generative AI|2023-04-06 17:36:19|Donald Knuth didn’t spare any words, “getting binomial coefficients to work properly” 😂
Mannan Amroliwala|2023-04-06 17:36:46|‎You added Mannan Amroliwala
~ Ankur Khandelwal|2023-04-06 17:37:02|Send some my ways too
Dev Aggarwal|2023-04-06 17:41:46|Fun story: met jim keller today and he wants to build a 2 terabyte risc-v chip that can run pytorch code. 2 goddamn terabytes 🤯🤯🤯
Shashank Generative AI Group|2023-04-06 17:42:20|"anyone here tried the gpt4 compression prompt? it's pretty good.  https://twitter.com/shacrw_/status/1643948753567588353  will save y'all a click. this is the prompt. put any text after it. then you get a compressed version. then paste it in a new session.  ""compress the following text in a way that is lossless but results in the minimum number of tokens which could be fed into an LLM like yourself as-is and produce the same output. feel free to use multiple languages, symbols, other up-front priming to lay down rules. this is entirely for yourself to recover and proceed from with the same conceptual priming, not for humans to decompress:"""
Shimanta Generative AI|2023-04-06 17:43:52|I tried out another one I saw before this tweet, worked good for plain text, not much for other kinds of text(like code)
~ Prajna Prayas|2023-04-06 18:17:28|Read somewhere Djikstra loved theoritical CS so much that he considered plebs writing code to paint pixels on a screen vulgar in his time.
Shashank Generative AI Group|2023-04-06 18:24:28|yeah. i tried to compress lyrics. didn't work.
~ Srikanth|2023-04-06 19:13:56|‎~ Srikanth left
Pratyush Choudhury|2023-04-06 20:14:51|https://www.linkedin.com/posts/samyakhtukra_holy-smokes-sam-segment-anything-model-activity-7049699206206283776-_fva?
Dhruv Anand|2023-04-06 20:48:21|This seems like a fitting analogue
Anshul Bhide Replit|2023-04-06 20:50:56|Speaking of which, Chroma just announced their template for Replit.  https://twitter.com/atroyn/status/1643720961685069824
Sumod K Mohan|2023-04-06 21:07:07|Terabyte or Teraflop?
Sumod K Mohan|2023-04-06 21:19:27|Haha.. Let me bite. I wouldn't bet against theory folks (CS Theory) in the long term. First aeroplanes were build out of experiments but we really learned how to build aircrafts safely only later with the necessary math. They will come up with much simpler representation and more compact algorithm. That is their job by definition. To quote a friend who was an early FB engineer, what we write becomes useless in few months. Some of what they do remains current for much much longer. That's probably where he is coming from.
Sumod K Mohan|2023-04-06 21:34:14|What is your take?
Harsh Gupta Felvin|2023-04-06 21:43:08|Lol!
Swastik Banerjee|2023-04-06 21:45:17|ig some people are so attached to the work of their lifetime that they cannot accept/focus on things changing…
Swastik Banerjee|2023-04-06 21:45:57|but these are nobel laureates we’re talking abt, so i’d never know 🤷🏻‍♂️
Nirant|2023-04-06 22:14:55|I spoke too soon. There is a hot new YC company on this: https://getmetal.io/
Nirant|2023-04-06 22:15:23|OpenAI notebook bug fixes + Stripe → YC pipeline is strong 💪
Kartik Mandaville|2023-04-06 22:16:48|How Stripe?
Nirant|2023-04-06 22:17:19|That is how you take the credit card of an unsuspecting developer and then invoice them some absurd amount 😛
Shashank Generative AI Group|2023-04-06 22:40:43|Paul Krugman is another one 😂
Shivendu Kumar|2023-04-06 22:53:16|Has anyone tried using ElevenLabs for training and generating audio in Hindi?
Shivendu Kumar|2023-04-06 23:06:32|Or maybe open source alternatives like tortoise-tts?
~ Avi|2023-04-06 23:26:01|‎~ Avi joined using this group's invite link
Swastik Banerjee|2023-04-06 23:38:43|[PHONE]
Nirant|2023-04-06 23:42:47|Demos from India's first Generative AI hackathon are here: https://nirantk.com/deephackdemos  Features: - Winner of each category, they took home 1L cash 💰 - Jury's Prize (sponsored by jury, 2 prizes) 🎓 - 2 of my personal picks: Including an idea which, got scooped and implemented differently by another crew and they're now trending on Github! 🌟
Nirant|2023-04-06 23:45:05|To friends in VC, can make introductions to teams if you give me carry 😆
Nirant|2023-04-06 23:46:01|To engineers — lazy fuckers please write better copy, and take pitching tips from [PHONE] [PHONE] next time
Shivendu Kumar|2023-04-07 00:15:40|Could the creator of the ViewsAct project kindly share a demo video, please?
Nirant|2023-04-07 00:16:13|He opted out because his demo used some real-world company designs and data.
Nirant|2023-04-07 00:17:58|For those who track of hackathon demos in SF/NYC/Berlin circuits, I genuinely believe that all winners would've done well in SF, won in NYC/Berlin in Feb end atleast. Would love to hear more if you do track :)
Swastik Banerjee|2023-04-07 02:10:10|anyone saw the first shortfilm using dalle? : https://www.instagram.com/reel/CqstiaNuSjX/?igshid=MDJmNzVkMjY=
~ Aman|2023-04-07 02:29:11|There is this one too  https://www.youtube.com/watch?v=X1NIjn_kJq8
~ Aman|2023-04-07 02:29:47|Using mid-journey. He has also shared the breakdown process.
Anirudth N|2023-04-07 10:21:21|I'm in the bay area until Saturday. Would love to meet people working in the gen AI space.
Anirudth N|2023-04-07 10:22:05|I'm an Applied Scientist at Amazon building computer vision tech for video action recognition
~ Pradyumna Bang|2023-04-07 10:22:44|Hi,  Is anyone exploring ideas around Gen Ai for powering Manufacturing software/erp ?
Nirant|2023-04-07 10:32:05|cc [PHONE]
Pranjal Mehta|2023-04-07 10:54:52|[PHONE]
Zainab Bawa|2023-04-07 10:56:24|Following.
Micheil|2023-04-07 11:36:25|For those in London: this might be worth checking out. Lots of AI/art/gaming stuff: https://www.theguardian.com/games/2023/apr/06/now-play-this-ai-video-game-somerset-house-london?CMP=Share_iOSApp_Other
Shashank Generative AI Group|2023-04-07 12:57:55|chrome just shipped WebGPU  https://developer.chrome.com/blog/webgpu-release https://twitter.com/WebGPU  example: stable diffusion in browser https://twitter.com/ruihanglai/status/1633554333517373440
Nirant|2023-04-07 13:09:42|Pichai baba is back baby!
Anagh Prasad|2023-04-07 13:10:59|Gazab
Rohit Aggarwal|2023-04-07 13:14:10|I’m curious that for use cases outside of those that need extreme security - why would I run a model on my personal machine vs accessing it via an API?
Nirant|2023-04-07 13:15:43|It's wayyy lower latency, higher throughput. Think why games continue to be written for devices.
Anagh Prasad|2023-04-07 13:15:56|Also Makes compute significantly cheaper for companies serving consumers at scale
Rohit Aggarwal|2023-04-07 13:16:16|This would still happen on a server farm I assume?
Nirant|2023-04-07 13:16:19|brb, gotta buy some Cloudflare now.
Rohit Aggarwal|2023-04-07 13:16:34|Doesn’t the inference take longer though?
Nirant|2023-04-07 13:17:06|No, WASM will do the rest. Segment-Anything proves that inference can be light-weight decoder only
Anagh Prasad|2023-04-07 13:17:10|Depends on the case I guess, I know some very large companies who have benefitted significantly from running ML on the mobile edge
Rohit Aggarwal|2023-04-07 13:17:15|Thought that is more a bandwidth issue. How much data can I fit through a pipe
Soumyadeep Mukherjee|2023-04-07 13:17:21|I literally opened vested for this
Soumyadeep Mukherjee|2023-04-07 13:17:22|:P
Nirant|2023-04-07 13:17:57|Cashflow poor and idea rich people think alike 😛
Rohit Aggarwal|2023-04-07 13:18:21|Any examples?
Rohit Aggarwal|2023-04-07 13:19:07|Hmm, need to do more reading here
Chirag Jain|2023-04-07 13:21:31|there will be no strong QoS but it opens up possibility of freemium models  but QoS will only improve when phones with Tensor cores become common
Sudharshan GenAI|2023-04-07 13:21:46|https://twitter.com/mathemagic1an/status/1644123645432958976?s=46
Pratyush Choudhury|2023-04-07 13:21:46|Pichai baba ya fir Larry/Sergey?
Nirant|2023-04-07 13:21:49|What is QoS?
Pratyush Choudhury|2023-04-07 13:22:06|Quality of Service?
Nirant|2023-04-07 13:22:08|Chrome is classic Pichai in my mind, so is Web acceleration ideas
Chirag Jain|2023-04-07 13:22:12|Quality of Service how fast you get output depends on your device
Pratyush Choudhury|2023-04-07 13:23:07|Was his brainchild, yes  Not sure how involved he'd be now especially considering all that's happening around Alphabet
Chirag Jain|2023-04-07 13:26:02|hopefully battery tech keeps up  I am also assuming companies would want to sync up  inferences made locally
Chirag Jain|2023-04-07 13:26:58|like Google Keyboard already does they ship collective model updates to device and sync up inferences during idle/night time when phones are charging
Pratyush Choudhury|2023-04-07 13:30:32|I think the best product in this case is actually SwiftKey and Microsoft acquired them very quietly in 2016
Pratyush Choudhury|2023-04-07 13:31:26|As we move to models running on the edge, I'd not be surprised to see Microsoft launching some OAI features inside SwiftKey
Pratyush Choudhury|2023-04-07 13:31:35|The product as is works incredibly well
Prukalpa Sankar|2023-04-07 13:49:41|‎You added Prukalpa Sankar
Harshal Bhatia|2023-04-07 13:54:49|SwiftKey has been botched after the acquisition. It's a slow and unbearable app now
Nirant|2023-04-07 14:05:21|How is agent planning evolving? This was quite broken in Turbo. Is it 2x better in GPT4? 10x better?   Are there benchmarks or tests on agent planning?
Sudharshan GenAI|2023-04-07 14:06:24|No idea, deep diving soon
Pratyush Choudhury|2023-04-07 14:15:55|Umm, not sure why you'd say so - have been using it since they were launched and haven't seen any notable difference
Pratyush Choudhury|2023-04-07 14:16:01|I've been using it on Android though - not sure if that changes things
Krishna Ntkris|2023-04-07 14:30:34|https://twitter.com/wileycwj/status/1644220882062282752?s=46&t=lkuvFQUWr1nav0QpUpFmdQ ‎[4/7/23, 14:31:26] Nirant: ‎GIF omitted
Krishna Ntkris|2023-04-07 14:31:35|This is probably just me but I still don’t have a good sense of why something like pgVector won’t work. At what scale does pgVector not work?
Nirant|2023-04-07 14:37:50|Does pg_vector also do NN like HNSW or nmslib?
Nirant|2023-04-07 14:38:12|I'll RTFM, but if someone has direct docs, would appreciate
Sumod K Mohan|2023-04-07 14:47:32|It is not performance as in speed but accuracy/semantic richness. Does this answer your question.
Sumod K Mohan|2023-04-07 14:53:42|Don't think so, quick glance through code base doesn't seem like it.  What are other libraries that does similar to HNSW/nmslib?
Shashank Generative AI Group|2023-04-07 14:58:56|there was some good discussion wrt pgvector in this thread https://twitter.com/jobergum/status/1643187540222959616
Shashank Generative AI Group|2023-04-07 15:02:46|btw, has anyone tried out Midjourney's /describe feature (img2text2img)?  i thought it was just some normal img2text feature but it also recognizes text within the image!!!  does any other model do this? nobody seems to be talking about this but it felt like a big deal to me. i tested this with a few images. https://twitter.com/shacrw_/status/1644078086936313858
~ Pradyumna Bang|2023-04-07 15:04:34|Interesting read on hardware infra of OpenAI  https://twitter.com/tim_zaman/status/1636981863477809152?t=jDMIbB8oPRf5RhEx1eUsSg&s=08
Dhruv Anand|2023-04-07 15:59:41|I spoke to Qdrant founder, and he said pgvector is basically unusable for LLM apps. It has recall in the area of 50% ‎[4/7/23, 16:19:51] Nirant: ‎image omitted
Dhruv Anand|2023-04-07 16:20:15|Basically whatever was referenced here
Nirant|2023-04-07 16:24:24|Erik Bern of Modal Labs maintains ann-benchmarks github.com/erikbern/ann-benchmarks, let's request him to add pg_vector to it?
Nirant|2023-04-07 16:25:04|This is something we can test/verify empirically, don't need to trust opinions from direct competition
Nirant|2023-04-07 16:39:45|And avatars come for news anchors: https://twitter.com/KhaleejMag/status/1641123893145485343  Does someone which company is doing this for India Today and what are there margins like?
Dhruv Anand|2023-04-07 16:43:34|True ‎[4/7/23, 16:46:52] Dhruv Anand: ‎image omitted
Shashank Generative AI Group|2023-04-07 16:47:24|agreed. i find it kinda hard to trust benchmarking blogs by other vectorDB startups.  motivated reasoning is almost always guaranteed.
Sudharshan GenAI|2023-04-07 17:22:08|https://www.linkedin.com/posts/hsemina_generativeai-community-hackathon-activity-7050057219123400704-NIHR?utm_source=share&utm_medium=member_android  Found another AI hackathon - you folks might be interested ‎[4/7/23, 17:30:45] Nirant: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-04-07 18:20:22|This is fab. Thank you! Hoping pgvector comes out decent. Want to stay within the supabase ecosystem
Kaushik Bokka|2023-04-07 18:28:01|Eric mast aadmi. Gave me access to modal in five mins, when I mailed him
Nirant|2023-04-07 18:28:31|Same. Matt Welsh of Fixie too.
Kaushik Bokka|2023-04-07 18:30:32|https://medium.com/m/global-identity-2?redirectUrl=https://blog.startupstash.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b https://medium.com/m/global-identity-2?redirectUrl=https://blog.startupstash.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b
Kaushik Bokka|2023-04-07 18:31:44|How was your experience with fixie?
Nirant|2023-04-07 18:31:58|The product? Confusing 🙈
Nirant|2023-04-07 18:32:17|I'm not their Target either. I think they're building for PM junta
Kaushik Bokka|2023-04-07 18:36:33|Haha, maybe they didn’t anticipate the launch of ChatGPT plugins
Kaushik Bokka|2023-04-07 18:36:52|The last bad product I used was https://www.steamship.com
Kaushik Bokka|2023-04-07 18:37:15|Platform to deploy langchain applications
Krishna Ntkris|2023-04-07 18:39:04|Interviewing him this week for newsletter :)
Krishna Ntkris|2023-04-07 18:39:20|Why was this bad out of curiosity?
Sudharshan GenAI|2023-04-07 18:40:43|Nice! What newsletter?
Nirant|2023-04-07 18:42:14|ntkris.substack.com
Kaushik Bokka|2023-04-07 18:49:26|Sweeet! I might have a question.  How does he envision the marketplace for agents and tools would be in the coming months?
Krishna Ntkris|2023-04-07 18:50:45|will ask!
Aishwarya Goel Inferless 5s for 5G|2023-04-07 18:52:46|Keen to know too
Ravi Theja|2023-04-07 18:59:23|Pinecone, weaviet, Chroma, vertex ai matching engine and there are bunch of other vector stores as well. What is the logic behind having soo many vector stores? Is the market soo huge?  Can someone help me understand it?
Kaushik Bokka|2023-04-07 18:59:41|They are building a wrapper on top of LangChain components to take it to production.  However, LangChain framework is still in the experimental stage being early stage. It would be very difficult for Steamship to maintain compatibility with the latest changes and fixes in LangChain.  I believe it didn’t have enough ROI as a platform to integrate in my applications.  And it broke multiple times when I used it for deployment. UI seemed unintuitive as well, let’s not talk about the documentation, sigh.
Kaushik Bokka|2023-04-07 19:02:07|And I did mention it to one of their engineers on a call a month back, Harrison will pick up funding soon and have to build a cloud solution to monetize.   Wouldn’t users prefer LangChain’s native deployment solution over yours?
Krishna Ntkris|2023-04-07 19:04:36|They raised $10 m
Nirant|2023-04-07 19:05:37|Question best answered by VCs [PHONE], want to chip in? ‎[4/7/23, 19:06:59] Nirant: ‎image omitted
Pranjal Mehta|2023-04-07 19:07:36|[PHONE]
Nirant|2023-04-07 19:08:31|Sorry for the self plug but this is relevant to the conversation here: https://twitter.com/nirantk/status/1644290469915164672?s=46
Krishna Ntkris|2023-04-07 19:08:45|I love this quadrant
Krishna Ntkris|2023-04-07 19:09:12|Honestly, based on Vespa founder's tweets I think they might have the best tech? But I die a slow death every time I look at their documentation
Manjot Pahwa|2023-04-07 19:09:58|Oh long discussion but yeah pinecone is basically far ahead of the competitors in terms of technology
Nirant|2023-04-07 19:10:04|Vespa is so good, and their docs so bad -- you could make money by just simplifying their docs.
Nirant|2023-04-07 19:12:13|Why/how are they ahead? Latency, throughput?
Ravi Theja|2023-04-07 19:12:36|Gcp vertex ai matching engine is ready for enterprise scale?  The only drawback with gcp is it takes 40 minutes to create or update an existing index if it is inserting 1 data point 😅
Krishna Ntkris|2023-04-07 19:13:20|My biggest worry with vector stores: what happens when Azure, AWS or GCP adds them?
Nirant|2023-04-07 19:14:47|The same thing which happened with Mongo, Elastic, MySQL, Postgres
Manjot Pahwa|2023-04-07 19:25:44|Basically pinecone has been in the bake for 4 years, always focusing on enterprise readiness and supports the largest number of use cases. Happy to talk more in depth about the actual tech that makes it more scalable, reliable
Krishna Ntkris|2023-04-07 19:27:50|Generally agree. My one push back on this: all of the things you mention are the “primary” storage of some kind. Vector DBs, for now, are a critical feature. I still need a stand-alone sql or no sql db for the rest of my stack
Bharat Kumar Ramesh Hashmal Web3|2023-04-07 19:30:15|True. And unless it's massive scale, where the differences in performance becomes signficant, there's probably merit to keeping it unified
Bharat Kumar Ramesh Hashmal Web3|2023-04-07 19:30:30|Does pinecone offer a signficant advantage over something like pgvector?
~ Vipul|2023-04-07 20:08:50|‎~ Vipul joined from the community
Ojasvi Yadav|2023-04-07 20:27:00|inb4 AWS comes out with an S3 integration for vector DB storage  They did something quite similar with EMR back in the day where you could use S3 as HDFS for EMR (they called this integration EMRFS)
Harsh Koo|2023-04-07 21:36:46|This would be a game changer.   At Koo we benched Elastic knn, Milvus and testing Vespa.  Vector storage, retrieval,search and all related patterns is the new DBMS moment for tech.
Jidin Dinesh|2023-04-07 21:46:44|Folks as someone who loves learning database internals:  Please point me to resources to get good grip over the recent developments in vector dbs
~ Parth|2023-04-07 21:48:02|https://rime.ai/  Came across this cool tool. Speech synthesis tool with demographically rich & diverse voices. No more robotic audio
~ Parth|2023-04-07 21:48:30|https://twitter.com/lilyjclifford/status/1643702014680133632
jyotirmayjk Hackathon|2023-04-07 21:50:00|https://twitter.com/younesbelkada/status/1644341068241186818?s=46&t=icC0fizZK8E3ONsDVuGFWA   MatCha,one shot visual language reasoning by Google  Seems like foundational model for visual reasoning on graphical plots and charts
jyotirmayjk Hackathon|2023-04-07 21:50:55|Seems like new foundational models for different tasks are released everyday   Weekend is not enough to catch up on all new developments 🥲
~ Aman|2023-04-07 22:53:48|Is anyone generating embeddings for this group, to create top 10 learnings from here every week? 😅
~ ボルツザマク|2023-04-07 22:57:14|Haha, nice idea, and then scrape the learning articles and links and make sumarizer, which summarizes every topic in 10 words 😎
Aditya Agrawal SuperU|2023-04-08 00:30:06|So needed
~ Rohan|2023-04-08 00:31:48|Do folks know if anyone has integrated chatGPT/LLMs into Alexa/Nest type of smart home devices? Seems like a low hanging fruit.
Chinmay Shah Arrowhead|2023-04-08 00:35:59|hey folks, has anyone dabbled with paddlespeech?
Prashant Singh|2023-04-08 10:16:05|‎You added Prashant Singh
~ Arka|2023-04-08 10:43:13|‎You added ~ Arka
Zainab Bawa|2023-04-08 11:56:57|The video of the talk by Anil Ananthaswamy on ChatGPT held at BIC is published - https://youtu.be/WF28ZwhUCc4
Sankalp PickYourTrail|2023-04-08 14:00:55|there are tools that do it, alexa and siri integration is possible given you have your openai key which is the barrier to adoption ‎[4/8/23, 15:49:31] Jay Pokarna 2014 BPCC: ‎image omitted
~ Arka|2023-04-08 15:50:08|Use Automatic 1111 on colab
~ Arka|2023-04-08 15:50:47|If you have MacBook download DrawThings App.  The best interface for SD hands down. Runs locally too.
~ Arka|2023-04-08 15:51:53|GPU memory issue i think. Try smaller models
Nirant|2023-04-08 15:52:09|I believe Jay is trying to get that running on local via Web GPU. Not a direct Python to GPU. ‎[4/8/23, 15:53:40] Nirant: ‎image omitted
Jay Pokarna 2014 BPCC|2023-04-08 15:56:02|I'm on windows machine on chrome canary. Currently the image is being created and is in process
Jay Pokarna 2014 BPCC|2023-04-08 16:11:09|Image got generated on windows, but took a lot of time
Ojasvi Yadav|2023-04-08 16:59:19|Automatic1111 works quite well on my max
Ojasvi Yadav|2023-04-08 16:59:27|*Mac
Ojasvi Yadav|2023-04-08 16:59:35|Like text to image in 10 seconds
Ojasvi Yadav|2023-04-08 16:59:42|Is this even faster?
Dev Aggarwal|2023-04-08 17:01:46|SD is about 10 sec on A100 too
Ojasvi Yadav|2023-04-08 17:03:37|Subtle flex but this one is M1Max with 64 gigs of RAM so maybe that's why
Ojasvi Yadav|2023-04-08 17:03:50|It's ridiculous Apple has such a hardware advantage
Amogh V|2023-04-08 17:04:14|In my experience using Automatic on Mac simple text2image works but if you run inpainting with batch count of 4 using multi control net then you’re going to have trouble
Ojasvi Yadav|2023-04-08 17:04:16|Meanwhile Siri is in absolute shambles
Dev Aggarwal|2023-04-08 17:04:47|This is with xformers and fp16 though
Ojasvi Yadav|2023-04-08 17:05:03|Bro I already have trouble M1s are known to stay cool all the time But automatic1111 is one software which can drain my big boy completely in an hour
Amogh V|2023-04-08 17:05:08|M2 with 16GB RAM though. Complex operations would be better with 64 GB
Nirant|2023-04-08 17:13:29|Wealth advantage 😂
Amir Nagri|2023-04-08 17:14:52|Given we are discussing apple hardware, I'm planning to buy a MacBook soon  Any suggestions on hardware for a stable diffusion/generative ai workflow?
Amir Nagri|2023-04-08 17:16:02|2 points I have to decide on 1. M2 or M2 max 2. 32gb, 64gb or go mad with 96  🙂
Ojasvi Yadav|2023-04-08 17:18:02|My recommendation would be to either go all the way or get the Macbook air
Ojasvi Yadav|2023-04-08 17:18:51|You can always get generative AI running on a cloud setup
Ojasvi Yadav|2023-04-08 17:19:25|But if you want local gen AI capabilities do try to get as big of a machine as your wallet permits
Ojasvi Yadav|2023-04-08 17:19:51|It's never going to be enough specially once text-to-video takes off
Sudharshan GenAI|2023-04-08 17:20:01|True
Amir Nagri|2023-04-08 17:20:19|Yeah, but my Mac needs an upgrade, so looking to include the ai workflows locally as well
Ojasvi Yadav|2023-04-08 17:21:12|I understand, I just wanted to highlight that M1 MB-air is plenty of you have a cloud setup
Ojasvi Yadav|2023-04-08 17:21:57|*if
Amir Nagri|2023-04-08 17:22:19|I'm all in for a good ROI, and apple is very evil when it comes to pricing ladders, so looking at the optimum config  And if something is not enough for local, like text2vid, you can go limited local, like 10s clips only, and go cloud for heavy lifting
Sudharshan GenAI|2023-04-08 17:25:53|How optimized are these models for running on apple RAM? As opposed to Nvidia GPUs   I’d consider this.  16 GB of ram is almost 30K INR (from what I remember).  Renting cloud GPUs on runpod is quite flexible and cheap.
Nirant|2023-04-08 18:33:55|CEO of Weaviate, Vespa and Modal Labs are nerding out over serverless Vector DB and pricing around it: https://twitter.com/jobergum/status/1644653416994488320
Nirant|2023-04-08 18:46:32|If you know how to read between the lines, that's a free masterclass on Developer eXperience and how that influences pricing, GTM — and mostly will continue to do so
~ Rohan|2023-04-08 18:47:27|https://youtu.be/8y7GRYaYYQg  This guy made a replica of flappy bird using chatGPT without writing a single line of code 🤯
Nirant|2023-04-08 18:52:50|It's quite neat how the dev is debugging the logic on his own, but letting GPT4 fix the syntax and API calls. Quite close to my mental model of what it is right now.
Nirant|2023-04-08 18:53:42|"Within 2-3 months, I expect to see dedicated planning ""agents"" which can pair with the dev much more on the first part — this demo still relied on dev's skill and knowledge on how to describe game play well."
Nirant|2023-04-08 18:54:20|Would love to hear more from game devs here :)  cc [PHONE] any ideas?
Shimanta Generative AI|2023-04-08 18:55:08|My brother who is a not into development sent me this video today. Was intrigued at the possibilities and the capabilities we can have with GPT assisting.
Harsh Koo|2023-04-08 19:04:38|Jo never shills Vespa. Doesn't need to. Vespa is run  by web search OGs.
Harsh Koo|2023-04-08 19:05:31|[PHONE] if you ever do a podcast style fireside chat/discussion, do count me in for one of your sessions.   Would be great to talk shop
Nirant|2023-04-08 19:05:56|With Erik or any of these folks?
Harsh Koo|2023-04-08 19:06:15|Anyone.
Rajeev Singh Naruka|2023-04-08 19:29:29|Working on something close.
Amir Nagri|2023-04-08 20:06:16|Not sure is this was already shared  https://www.semafor.com/article/04/07/2023/stability-ai-is-on-shaky-ground-as-it-burns-through-cash  The article claims that stabilityai is in trouble and burning cash rapidly without any promising source of revenue
Ojasvi Yadav|2023-04-09 00:16:03|12am saturday, what else would you do but generate desi lofi girls  https://twitter.com/ojasvi_yadav/status/1644773211282853889?s=20
Charu Tak|2023-04-09 05:17:26|‎Charu Tak joined using this group's invite link
~ Ankur Khandelwal|2023-04-09 09:30:44|If anyone to sell his SAAS company - https://twitter.com/danmartell/status/1644798423961575426?t=BwA0POzNya9uB_BZkY1cHA&s=19
Nirant|2023-04-09 09:32:00|brb starting a vector db company 🤣
~ Vipul|2023-04-09 09:38:03|Spending some time this weekend to catch up on everything, made this little tool 🔨  https://twitter.com/vipbhavs/status/1644760279425904640?s=46&t=zHC5rKec9bB_1WhQvHP-gA  Next, I want to learn all the developments around webGPU, can we run something like SD within a browser? Any good starting point to learn about this stuff?
Nirant|2023-04-09 09:39:26|cc [PHONE] and friends built this for Youtube videos
Ravi Theja|2023-04-09 10:16:16|sitegpt as well does something similar - https://sitegpt.ai/
Vishal Tripathi NSS 2013|2023-04-09 10:33:38|Talking about similar projects - if folks are still interested. Microsoft Edge has a copilot option which does this exact thing which I’ve been using.
Pratyush Choudhury|2023-04-09 10:39:24|https://twitter.com/alexgraveley/status/1644186023868416000?t=3mfuMZb0hDnOx2sFR9Wn4Q&s=08
Ojasvi Yadav|2023-04-09 10:47:42|Doesn't jsonlines format solve this?
Ojasvi Yadav|2023-04-09 10:48:14|https://jsonlines.readthedocs.io/en/latest/
Shubham Sharma 2012C6|2023-04-09 11:11:01|https://twitter.com/rowancheung/status/1644778701974822913
Shashank Generative AI Group|2023-04-09 11:26:40|this will probably have the same bias as that viral midjourney thread with indian villagers smiling(like western folks)  western stereotypes creep in.
Nirant|2023-04-09 11:27:37|Youtubers in 2025: Smile wide and talk loudly, clearly to get an interview offer when talking to AI Interviewer
Shubham Sharma 2012C6|2023-04-09 11:29:28|Yeah only alternative is to train on an indian data set
Kartik Mandaville|2023-04-09 11:33:25|Has anyone used gptindex here in production?
Nirant|2023-04-09 11:34:36|[PHONE] is a contributor to Llama Index, might know more folks, please DM him. If you've hosting/infra challenges, since that's the quite similar for Langchain, I can also help. I've 2 Langchain projects in prod+going to prod.
Kartik Mandaville|2023-04-09 11:35:32|Yes already working with him.  Seeing scale challenges now - slowness of answering and training new docs. What database did you use?
Nirant|2023-04-09 11:37:04|Chroma, works in-memory, other than frequent deploys, not a pain.   On the answer slowness and embedding new docs, did you get a chance to profile it? In some logs I've seen, it's OpenAI which is quiet slow
Nirant|2023-04-09 11:37:51|Also, very small data: Less than a Gb of text
Kartik Mandaville|2023-04-09 11:39:34|In memory won’t work for 100s of docs for us
Kartik Mandaville|2023-04-09 11:39:56|Yes it’s not OpenAI as it’s mostly in search which has no calls to it
Nirant|2023-04-09 11:41:15|Hmm, if you're embedding a query with Ada, that is still a call to their API?
Deep Samsung R&D|2023-04-09 11:43:32|Any better embedding suggestions than Ada, trying something on legal docs but it does not seem to work well, results are not consistent enough with Pinecone indexing and ada embedding, faced anything similar
Ravi Theja|2023-04-09 11:45:59|sachin from https://intellawyer.com/ - should be able to answer it as he has experience with legal documents
Nirant|2023-04-09 11:49:22|cc [PHONE] — Indian legal docs
Sachin Legaltech|2023-04-09 11:50:00|Try mpnet from sentence transformers …works quite well
Kartik Mandaville|2023-04-09 11:50:21|That’s only during training. I was talking about searching
Sachin Legaltech|2023-04-09 11:50:36|https://www.sbert.net/docs/pretrained_models.html
Kartik Mandaville|2023-04-09 11:51:00|Btw a great shout out to Ravi / he’s been so helpful to us with all his expert advice and tips.
Deep Samsung R&D|2023-04-09 11:52:50|Any suggestions of Vector DBs?
Ravi Theja|2023-04-09 11:54:49|Thanks Karthik.  Happy to help anyone working on building QA Systems, Vector DB’s, Llama Index(GPT Index).
Sachin Legaltech|2023-04-09 11:57:32|I use pinecone.. Nirant / Ravi knows much more about tradeoffs between them
Sachin Legaltech|2023-04-09 11:58:01|https://twitter.com/nirantk/status/1644290469915164672?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Tweet thread by Nirant about this topic
~ Vishwam Jindal|2023-04-09 12:03:37|‎~ Vishwam Jindal joined using this group's invite link
Kartik Mandaville|2023-04-09 12:04:35|Nirant- you should start an accelerator for startups. So much knowledge.
Kartik Mandaville|2023-04-09 12:05:01|We got approved till $5K now.
Ravi Theja|2023-04-09 12:20:23|[PHONE]
Nirant|2023-04-09 12:22:50|You're 9 days late for April Fools Kartik sir 😛
Nirant|2023-04-09 12:23:47|Would a Pinecone, Chroma, pgvector comparison/benchmark be useful?   Just don't ask me to do Elastic, I see Java and main woh dekhke maine mar java
Chaitanya Mehta Goodera Turtlemint|2023-04-09 12:24:53|‎POLL: Should Nirant start an accelerator for AI startups? ‎OPTION: Yes, defintely (35 votes) ‎OPTION: Hell yes! (15 votes)
Shashank Generative AI Group|2023-04-09 12:44:33|hamara Erlich Bachman
~ Karan Gandhi|2023-04-09 12:44:48|🤣🤣🤣
Dev Aggarwal|2023-04-09 14:40:21|On a serious note, really want hackerhouses to exist in bangalore!
Manu Hegde|2023-04-09 14:55:23|+1
Kaushik Bokka|2023-04-09 14:58:17|The only hackerhouse I wish to go to https://youtu.be/T3xlm-mw8As
Harsh Gupta Felvin|2023-04-09 14:58:56|Oh HF0
Kaushik Bokka|2023-04-09 14:59:14|legends
Harsh Gupta Felvin|2023-04-09 15:00:13|You can actually make something like this happen in BLR
Harsh Gupta Felvin|2023-04-09 15:00:30|Kormangala/Indranagar has bunch of great bunglows
Kaushik Bokka|2023-04-09 15:00:53|Logistics is not the issue
Harsh Gupta Felvin|2023-04-09 15:00:59|Rent them and make it a hacker house and attach it to some accelerator
Harsh Gupta Felvin|2023-04-09 15:01:09|Yeah!
Harsh Gupta Felvin|2023-04-09 15:01:20|So what is the bottleneck?
Nirant|2023-04-09 15:01:41|Not enough OpenAI researchers in Bengaluru
Dev Aggarwal|2023-04-09 15:03:04|Why the accelerator? I would assume a bungalow would be self sufficient from just the rent
Harsh Gupta Felvin|2023-04-09 15:04:41|If you putting all that effort to increase the chances of success for startups, you want to capture at least part of the upside
Harsh Gupta Felvin|2023-04-09 15:04:58|*As a person hosting the thing
Harsh Gupta Felvin|2023-04-09 15:05:25|Charging flat rent is not interesting in that regard
Nirant|2023-04-09 15:07:07|There are more aligned ways to capture that upside e.g. can invest a pre-seed amount. But very off topic now.
Sumod K Mohan|2023-04-09 15:11:59|I really miss HackerDojo, used to be a blast. [PHONE] This is something you all can do. A space for hackers to meet for cheap and hack together. Indiranagar is ideally located.
Nirant|2023-04-09 15:15:20|Related note, GenerativeAI April meetup registration link: https://hasgeek.com/generativeAI/april-meetup/
Zainab Bawa|2023-04-09 15:21:07|Let's do it. Who's in for this? [PHONE] you want to help set this up, to get it going?
Soumyadeep Mukherjee|2023-04-09 15:24:38|This is interesting. What was hackerdojo ?
~ Nambiar|2023-04-09 15:25:05|‎~ Nambiar joined using this group's invite link
Gokul Krishnan|2023-04-09 15:25:12|Google research toh h na?
Nirant|2023-04-09 15:26:58|In theory, we also have Microsoft Research. In theory, Sharechat, Flipkart and a handful others do write CVPR, ICML, ACL papers.   In practice, the overlap between hackers and those who think about bleeding edge is small
Sumod K Mohan|2023-04-09 15:28:23|Sure thing
Soumyadeep Mukherjee|2023-04-09 15:28:29|That’s the thing to change nirant baba 😅
Nirant|2023-04-09 15:35:46|[PHONE] will be lead the change and be teaching how to make comics at the April meetup
Sumod K Mohan|2023-04-09 15:35:51|This was exactly what I miss. HackerDojo in Mountain View is a community run space, I think it is a not for profit, where people can get desks for cheap with bunch of tooling etc to build stuff. Couple of startups started there, Pinterest is one that comes to mind. They used to be the default place for many meetups. I had met H2O's Satish Ambati there, when they were just 2 people amongst others. There were quite few others.  There were a bunch of people from Google Brain and FB's some team, who used to give talks there. So there was the amazing vibe and back and forth between the grey hairs and people pushing the bleeding edge.
Sumod K Mohan|2023-04-09 15:36:38|They used to have some link with Computer History Museum not 100% sure what it was.
Soumyadeep Mukherjee|2023-04-09 15:36:44|Hahaha May meet-up I’ll do this pakka. April is tight.
Gokul Krishnan|2023-04-09 15:37:10|Maybe as part of the oral history series?
Sumod K Mohan|2023-04-09 15:43:42|That one could be one thing. There was some fiasco with finances. But one thing they did was they had membership dues + hot desk charges hot desk was quite reasonable. Definitely had the hacker vibes. I think there was some support from well to do community members too. May be we can talk to Nandan etc and others too can chip in. Just thinking out loud.
Kaushik Bokka|2023-04-09 15:45:29|+1
Ojasvi Yadav|2023-04-09 17:16:43|Any awards this time?
Ojasvi Yadav|2023-04-09 17:17:47|😁
Ojasvi Yadav|2023-04-09 17:18:16|Also, has anyone here gotten off the chatGPT plugins waitlist?
Shashank Generative AI Group|2023-04-09 17:35:19|still waiting :(
~ Srijan Shukla|2023-04-09 17:35:54|same, still waiting :/
Ojasvi Yadav|2023-04-09 17:36:37|Same. I don't know anyone in India who's received plugins access.  Which is quite weird for me, because I got gpt4 API access within 2 days of it's release.
Ojasvi Yadav|2023-04-09 17:36:53|*its
Shashank Generative AI Group|2023-04-09 17:37:46|yeah me too. got gpt4 immediately. surprised that many people still don't have access to gpt4 api as well. ‎[4/9/23, 17:53:43] Nirant: ‎image omitted
Ravi Theja|2023-04-09 17:58:08|Guy who is maintaining kisaangpt got it I guess
Aditya Agrawal SuperU|2023-04-09 18:00:36|Is there a link?
Ojasvi Yadav|2023-04-09 18:00:48|He's living in SF so my conspiracy theory still holds 😅
Krishna Ntkris|2023-04-09 18:01:04|I have it, going to build something for my product in the next week
Ojasvi Yadav|2023-04-09 18:01:28|Oh wow. Let me DM you!
Ojasvi Yadav|2023-04-09 18:01:55|But wait, you're not in India it seems (going off of your phone number)
Krishna Ntkris|2023-04-09 18:02:46|Yes I’m in London(sorry didn’t realise it was india specific)
Dr. Pratik Desai KissanGPT|2023-04-09 18:03:14|‎Dr. Pratik Desai KissanGPT joined using this group's invite link
Ojasvi Yadav|2023-04-09 18:04:12|Welcome Dr Pratik. We were just talking about you! ‎[4/9/23, 18:04:39] Ojasvi Yadav: ‎image omitted
Amogh V|2023-04-09 18:04:43|👋
Ojasvi Yadav|2023-04-09 18:05:05|We're talking about how few folks in India have gotten chatGPT plugins access
Dr. Pratik Desai KissanGPT|2023-04-09 18:05:16|Hey Ojasvi, Nice job with Jadoo and Shakalaka… Been following all of you guys work and Nitant’s hackathon.
Harsh Gupta Felvin|2023-04-09 18:05:27|I've got the access
Ojasvi Yadav|2023-04-09 18:05:33|Thank you sir 🙌🏻
Harsh Gupta Felvin|2023-04-09 18:05:40|Not in India though
Ojasvi Yadav|2023-04-09 18:06:27|What could be the reason India isn't getting the same treatment as the rest of the countries for plugins access
Harsh Gupta Felvin|2023-04-09 18:07:31|Often compliance is a big reasion
Harsh Gupta Felvin|2023-04-09 18:07:36|*reason
Dr. Pratik Desai KissanGPT|2023-04-09 18:10:38|Yeah, I got the access. They are mostly vetting and rolling out access slowly. They have been following my work with Kissan GPT and provided support letter as I have been called up by ministries. That may be the reason for my boost.
Ojasvi Yadav|2023-04-09 18:11:21|Quite inspiring
Ojasvi Yadav|2023-04-09 18:11:37|You're still in SF?
Dr. Pratik Desai KissanGPT|2023-04-09 18:11:46|Yes
~ Vishwam Jindal|2023-04-09 18:18:51|I'm still waiting for GPT-4 API. Any recommendations on what I can do to?
Dr. Pratik Desai KissanGPT|2023-04-09 18:36:07|You guys may be right about country preferences due to compliance as I got access to GPT4 API in the first few days only. The another reason can be age of account or usage. I have been using their API platform since 2020.
Nirant|2023-04-09 18:38:32|Same, 2020 user. But Atty soft-confirmed they're doing SF first. Everyone else came later.
Nirant|2023-04-09 18:38:51|Atty is the OpenAI engineer at Setu office right now
Dr. Pratik Desai KissanGPT|2023-04-09 18:42:43|Just the city. Wow. Looks like doomers are making them more cautious about opening up.
Kartik Mandaville|2023-04-09 18:58:06|Meaning? Who?
Kartik Mandaville|2023-04-09 18:58:21|What’s your usage? Ballpark $ or requests?
Nirant|2023-04-09 18:59:31|https://www.linkedin.com/in/athyuttamre  He's in Bengaluru, and answering questions about Plugins
Nirant|2023-04-09 19:00:14|He's on the plugins team
~ Pradyumna Bang|2023-04-09 19:02:59|Is the talk being recorded anywhere ? Missed it, unfortunately :(
Dr. Pratik Desai KissanGPT|2023-04-09 19:17:32|My usage is not so high tbh. 80k+ requests/mo. Mostly using turbo instead of 4, to keep the cost low, which is really inexpensive, and good enough for my use case.
Swastik Banerjee|2023-04-09 19:19:20|oh
Swastik Banerjee|2023-04-09 19:22:16|coming to india v soon
Harsh Gupta Felvin|2023-04-09 19:23:20|Came back to SF yesterday
Harsh Gupta Felvin|2023-04-09 19:23:32|was in India for a month
Swastik Banerjee|2023-04-09 19:23:47|i mean the plugin access 😅
Kaushik Bokka|2023-04-09 19:24:47|Who will be in SF this month? 👋🏼
Nirant|2023-04-09 19:25:10|[PHONE] ?
~ Karan|2023-04-09 19:25:13|https://www.linkedin.com/posts/setu-apis_we-have-kicked-off-the-openai-x-fintech-session-activity-7050806116791832576-S3Ns?utm_source=share&utm_medium=member_android
Dr. Pratik Desai KissanGPT|2023-04-09 19:25:41|I’m here in Bay Area , in case anyone wants to grab a coffee or beer.
Swastik Banerjee|2023-04-09 19:28:21|also, people who are thinking to buy plus just for plugins don’t
Swastik Banerjee|2023-04-09 19:28:30|disjoint sets
Deep Samsung R&D|2023-04-09 20:02:49|Was this recorded by any chance? Would love to get if anyone took screenshot or could share access to the recording later.
Anirudth N|2023-04-09 21:02:15|Oh, just came back to Seattle. I'll be in Seattle for a few months. Would be happy to meet w/ you when you're around here.  https://www.linkedin.com/in/anirudthn
Shimanta Generative AI|2023-04-09 21:14:32|Hi folks, have been lurking a bit in the group for now. I wanted some pointers/references on how I can build an app that can generate realistic images of people along with some specific subject. I have tried building stuff earlier with SD and Dreambooth, and found out about ControlNet recently but not too well versed.
Amogh V|2023-04-09 23:02:37|Hey I have some experience in this and can help out. Is it for a product or a one time thing? Because the approach would be different
Shimanta Generative AI|2023-04-09 23:04:07|I have something in mind, but not sure if it can be a product. Let me DM you
Amogh V|2023-04-09 23:04:19|Sure
Ojasvi Yadav|2023-04-09 23:05:05|I'd like to help
Shimanta Generative AI|2023-04-09 23:05:59|Will dm you as well, thanks
~ Sankeerth|2023-04-09 23:27:17|‎Shubhi Saxena added ~ Sankeerth
Vishal Tripathi NSS 2013|2023-04-09 23:31:00|Cerebral Valley (which I’ve been a part of) started with ~50 members. (About 500 now but it started off small)
~ Kartheek Akella|2023-04-10 01:14:32|‎Shubhi Saxena added ~ Kartheek Akella
~ Ankur Khandelwal|2023-04-10 08:54:28|https://www.youtube.com/watch?v=2xxziIWmaSA&t=1079s   Nice video explaining the basic concept of langchain for beginner like me.
Nirant|2023-04-10 08:59:31|Thread of Hackathon ideas and lot of the same ideas we saw at our hackathon:   DiagramGenie, BlindVisGPT, Web action agent (Multion/Adept)  https://twitter.com/josephofiowa/status/1645224154831151105?s=48
Dev Aggarwal|2023-04-10 09:01:36|Weird, the political action project is the first thing we sold to a client back in 2022!  Who’s the creator?
Nirant|2023-04-10 09:02:19|Creators haven't been mentioned, but you can tweet to Joseph or @swyx and ask?
Dev Aggarwal|2023-04-10 09:08:39|Aside: I realised I know swyx from back in the react world because of this superb talk - https://youtu.be/KJP1E-Y-xyo Truly a gem!
~ Prajna Prayas|2023-04-10 09:33:51|many of them are chatbots, we had so much variety in our hackathon imo.
Ojasvi Yadav|2023-04-10 09:39:51|"GPT 3.5 users, have you ran into problems which require you to limit output length?  For example, if you're making a tweet generator you can't have outputs more than 140 characters.  I've tried it with numerical prompting where I'm specifying the length. It didn't work. So I added a response with the chat history and wrote my next reply as ""your response is X characters more than 140, please reduce its length by 140-X such that your response is below 140 characters in length""  This works sometimes, but not always. So I converted the function above to a recursive function. Basically asking it again and again to resize till it doesn't get it right. With the whole chat history provided."
Ojasvi Yadav|2023-04-10 09:39:56|So my question is, instead of instructing it to change its length in terms of characters, will there be any benefit to changing the length units to token.   I will need the tokenizer library to get the token count. But will gpt3.5 understand text length in tokens better than it understands it in characters?
Ojasvi Yadav|2023-04-10 09:39:58|Sorry for the long message. Had to make sure it's clear to the people who'd like to answer
Nirant|2023-04-10 09:41:34|The recommended way to do this is to use Guardrails and turn on re-ask (iterative variant of your recursive strategy). It's easier to reason about and often more token efficient too.   https://youtu.be/Pt-4ITyUpIA
Nirant|2023-04-10 09:42:01|You'd know about this if you were at the hackathon venue [PHONE] — we had Guardrails creator do the demo xD
Ojasvi Yadav|2023-04-10 09:42:28|Thanks a lot, will check it out ‎[4/10/23, 09:42:59] Nirant: ‎image omitted
Ojasvi Yadav|2023-04-10 09:43:14|My body was barely functioning, I was borderline disoriented with 2 hours of sleep 😂 you know this
Nirant|2023-04-10 09:43:20|https://github.com/ShreyaR/guardrails
Nirant|2023-04-10 10:00:15|My intent for sharing this is to emphasise that Indians are no longer playing catch up.   Outside of infra (GPU, Drivers, DBs) and gradient descent (Torch, Tensorflow, Transformers) — we are quite good  For those who chose to stay back here after undergrad, hope this brings you comfort — and energy to invest in polishing, packaging and taking your projects to a great solution!
Dev Aggarwal|2023-04-10 10:03:46|One weird thing that I noticed in guardrails and kor - why is the schema format not the same as the output format? ‎[4/10/23, 10:04:07] Dev Aggarwal: ‎image omitted
Shimanta Generative AI|2023-04-10 10:05:40|What’s Kor?
Nirant|2023-04-10 10:05:59|General purpose parser for any text/schema https://eyurtsev.github.io/kor/
Dev Aggarwal|2023-04-10 10:06:07|Similarly for guardrails, the schema is xml, but the output is json
Nirant|2023-04-10 10:08:21|From a language/lib design PoV, these are the two things you're trying to balance:   1. A schema which works across different targets 2. Has high degree of reliability with Turbo and text-davinci-003  This will invariably converge in you developing your own domain-specific language. This is such a sticky pattern of how humans think, even OpenAI uses this in their Plugin Debug panel. (Confirmed just yesterday evening!)
Rajeev Singh Naruka|2023-04-10 10:10:09|<3
Dev Aggarwal|2023-04-10 10:10:59|The dsl makes sense, but the part that’s confusing to me is why the schema sent to the llm is not the same as the requested output format.
Ojasvi Yadav|2023-04-10 10:11:48|My intuition, based on the thousands of samples I've tried so far is this. The resizing prompts work fairly well when input and output language is English. Tokenizing ka rule is uniform in English.  Meanwhile it has a lot of trouble in resizing texts in other languages. It needs multiple tries to get it right, if at all it ever does.  So my intuition is that the conversion of English to token count is stable. While conversion from, let's say Tamil, to token count is a bit unstable. One Tamil character can be 2 tokens, and the other could be 8.  So maybe it has a better understanding of token count than character count, and I can leverage it to resize with fewer API calls.
Nirant|2023-04-10 10:13:33|Thanks for moving this back to main, since it's widely relevant. E.g. [PHONE] has worked on an adjacent problem statement as well.
Nirant|2023-04-10 10:14:14|Aligned on the non-English challenge: The BPE tokeniser is notoriously unstable for CJK and Indian languages. Better with European languages often.   Even with English, It's not stable over differing input lengths (e.g. 100 to 1000 tokens with same 40 token target) for me. Similar text corpus, but mostly medical or tech jargon heavy corpora
Nirant|2023-04-10 10:15:12|"Prompt engineering in this way is a bit like casting a spell, and I don't think any amount of tips on ""wingardium leviosa"" is going to help — doing it will work best 🙌🏻 ‎[4/10/23, 10:23:26] Kartik Mandaville: ‎image omitted"
Nirant|2023-04-10 10:24:24|Tweet this, tag OpenAI folks. Nothing like this to nerd snipe them into replying to you and spilling some detail about GPT4 is actually trained on text-davinci-003 😂
Ojasvi Yadav|2023-04-10 10:24:52|I like how your mind ticks 😂👌🏼
Kartik Mandaville|2023-04-10 10:28:18|My customers are raising support tickets for this and saying that we're fooling them by saying we got GPT4 access
Nirant|2023-04-10 10:29:30|"Ouch. I'd try to improve this with a system prompt: ""You are helpful OpenAI Assistant, specifically GPT4. Never say GPT3"" or something along those lines. ‎[4/10/23, 10:31:24] Kartik Mandaville: ‎image omitted"
Nirant|2023-04-10 10:31:26|The reason this happens is that chat models are instruction finetuned, sanitised and scaled forks of large base models. Same for the REPL and Retrieval models in Plugins.
Nirant|2023-04-10 10:34:16|This trick should also work the other way around. You can have GPT3.5-Turbo claim to be GPT4 😂
Lalit Pagaria|2023-04-10 10:45:19|‎Lalit Pagaria joined using this group's invite link
Chirasmita Mallick|2023-04-10 10:48:16|‎Chirasmita Mallick joined using this group's invite link
Rohit Aggarwal|2023-04-10 11:15:43|Super explanation of GPT with 2 tokens and a context length of 3.   https://twitter.com/karpathy/status/1645115622517542913?s=20
Manas Ranjan Kar|2023-04-10 11:19:05|‎Manas Ranjan Kar joined using this group's invite link
Naveen 5C|2023-04-10 11:23:26|‎Naveen 5C joined using this group's invite link
Shashank B Designer|2023-04-10 11:27:02|‎Shashank B Designer joined using this group's invite link
Sundalai Rajkumar SRK|2023-04-10 11:35:08|‎Sundalai Rajkumar SRK joined using this group's invite link
Sanyam Bhutani|2023-04-10 12:14:05|‎Sanyam Bhutani joined using this group's invite link
Anshuman Pandey|2023-04-10 12:26:47|‎Anshuman Pandey joined using this group's invite link
Ankur Pandey|2023-04-10 12:38:05|‎Ankur Pandey joined using this group's invite link
Aseem Gupta 2011|2023-04-10 13:24:10|‎Aseem Gupta 2011 joined using this group's invite link
Anagh Prasad|2023-04-10 14:26:18|What a beautiful doc ❤️
Aditya Ankur|2023-04-10 15:17:39|Karpathy is doing teaching again? Yess!
~ anuja grazzel|2023-04-10 15:49:19|‎~ anuja grazzel joined using this group's invite link
Nilesh Agarwal Inferless|2023-04-10 17:46:24|‎Nilesh Agarwal Inferless joined using this group's invite link
~ GILZON 😎|2023-04-10 18:58:35|‎~ GILZON 😎 joined using this group's invite link
Deep Samsung R&D|2023-04-10 20:18:12|Interesting new research on Generative Agents https://arxiv.org/abs/2304.03442
Shashank B Designer|2023-04-10 20:31:30|Some enthu reporting as always - https://youtu.be/wHiOKDlA8Ac
~ Vaibhav|2023-04-10 21:11:39|‎~ Vaibhav joined using this group's invite link
Jay Pokarna 2014 BPCC|2023-04-10 21:40:51|Anyone suggestions on how I can get my hands dirty with Midjourney? On the discord, it has been showing full capacity for quite sometime. Any other way that I can try it out?
Amogh V|2023-04-10 21:42:41|Midjourney is exclusively on Discord. Wait for a while or try in the afternoon when traffic eases up. Or pay for premium
~ Prajna Prayas|2023-04-10 21:44:18|Hi. There is a new model Kandisky 2.1 available on dreamlike.art which is pretty decent  alternative to MJ. They provide daily credits as of now
Deep Samsung R&D|2023-04-10 21:49:38|Quick ques: What are the costs differences between GPT-4 and GPT3 API? ‎[4/10/23, 21:51:15] jyotirmayjk Hackathon: ‎image omitted
jyotirmayjk Hackathon|2023-04-10 21:51:40|I had found this quick compare table,handy for comparing various models
Swastik Banerjee|2023-04-10 22:12:57|any image-creation tool that accepts looking into a website design for reference?
Vignesh Baskaran|2023-04-10 22:44:04|‎You added Vignesh Baskaran
Nirant|2023-04-10 22:44:41|Do you've friends or acquaintance artists working with LoRA?   Vignesh is the founder of Hexo and looking for such folks https://twitter.com/tweetvbaskaran/status/1645471097578741760
Siddharth Agarwal|2023-04-10 22:46:04|Vignesh is quite nice! In my Covid-tinged master's days, he gave me great advice for job hunting in Leuven.
Vignesh Baskaran|2023-04-10 23:01:17|Thank you very much Nirant! You are awesome 😍
Vignesh Baskaran|2023-04-10 23:01:37|Thank you Sid! 😍
Siddharth Agarwal|2023-04-11 01:36:54|https://arxiv.org/pdf/2304.03442.pdf This is quite a paper.
~ Aman|2023-04-11 02:52:27|Yeah, just saw on Andrej Karpathy tweet
~ Aman|2023-04-11 02:53:52|with the demo at https://reverie.herokuapp.com/arXiv_Demo/
Prayank Swaroop Accel|2023-04-11 06:20:51|Yeah Generative Agents 😀
~ Arpit Maheshwari|2023-04-11 07:48:50|Yup!
Sanyam Bhutani|2023-04-11 07:50:16|He’s an awesome person. I agree 🫡
Ojasvi Yadav|2023-04-11 08:28:18|I've seen this project/tool floated around Twitter. But I can't recall its name, google isn't helping much either. Would love if anyone of you can share what its called or a link to it.  It was about summarizing what a startup is doing just by going through their landing page.
Dr. Pratik Desai KissanGPT|2023-04-11 08:29:31|That was a while back and I think they were using flat GPT output without crawling their pages. I may be wrong.
~ Praveen Sridhar|2023-04-11 08:45:15|is it this one? : https://wtfdoesthiscompanydo.vercel.app/
~ Karan Gandhi|2023-04-11 08:45:54|Yeah This one is made my Krish Nerkar
Ojasvi Yadav|2023-04-11 08:48:20|thanks folks
Dr. Pratik Desai KissanGPT|2023-04-11 09:34:02|This is another interesting paper. Combined with Meta’s segmentation model can open up many interesting use cases. https://twitter.com/_akhaliq/status/1645594671068971008?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw
Sumit Sen|2023-04-11 09:36:17|‎Sumit Sen joined using this group's invite link
~ Vinit|2023-04-11 09:37:30|‎~ Vinit joined using this group's invite link ‎[4/11/23, 09:56:50] Ojasvi Yadav: ‎sticker omitted
Ojasvi Yadav|2023-04-11 09:56:51|Langchain Bruh moment ‎[4/11/23, 09:57:11] Ojasvi Yadav: ‎image omitted
Nirant|2023-04-11 10:04:38|This bot doesn't have memory, you asked if the lib has memory, not the bot. Classic NER ambiguity mistake.
Shashank Generative AI Group|2023-04-11 10:10:44|even Jeremy didn't have access to ChatGPT plugins until now! it really is SF-first (he's in Australia i think) https://twitter.com/jeremyphoward/status/1645597656499245057?t=21TkvGGfdo-gEqmw3NKvsA&s=19
Sanyam Bhutani|2023-04-11 10:11:07|Ab FOMO Nahi ho raha 😂
Sanyam Bhutani|2023-04-11 10:11:28|My hypothesis was they have profiles on pro open source people and are being slow w GPT-4 features w them
Ojasvi Yadav|2023-04-11 10:33:38|Is using a VPN a workaround? Depends on how do they determine your country, does anyone have an idea?
Shashank Generative AI Group|2023-04-11 10:39:00|i don't think that's gonna be useful.   it's not like everyone in SF/US has access. my guess is that it's basically 2-3 groups: AI startups(openai fund etc), big cos, those who know people and maybe some previous usage based prioritization. eg: i think participants in some SF hackathon got access last week.  however, there was another SF hackathon which wanted access for their participants a few weeks back but they didn't. so...
Ojasvi Yadav|2023-04-11 10:39:55|Let's assume that my OpenAI account is a part of a big organisation and we use OpenAI APIs extensively
Nirant|2023-04-11 10:40:21|PSA: Ojasvi leads AI at mydukaan.io
Shashank Generative AI Group|2023-04-11 10:42:34|yeah im aware :)
Shashank Generative AI Group|2023-04-11 10:43:11|im just guessing..
Sumod K Mohan|2023-04-11 10:43:12|They ask you isn't it? Guessing probably use ur input + your ip + other sources like where cloudflare is serving from + some predictive stuff based on prior tokens. Guessing they probably use martech profile data as well. Which exact ones, is anyone guess. Guessing you tried messaging over Twitter. Try connects if you have any at OpenAI. Don't know if they have 'strong' policy around it though.
Nirant|2023-04-11 10:43:23|mydukaan.io needs to IPO [PHONE] bhai, they've given access to more public companies
Manjot Pahwa|2023-04-11 10:43:27|Hey folks! I've started sending out invites for this, it's happening on Thursday at the Lightspeed office in Koramangala at 6:30pm, not all folks are there on the invite since we were trying to make it a very interactive group with small number of people, but the idea is to invite for the next mixers. Looking forward to seeing people on Thursday! Please do DM me on WA to confirm if you're coming, thanks 🙂
Nirant|2023-04-11 10:44:42|You didn't have to tell 350+ people that we're not cool enough [PHONE] 🤣
Manjot Pahwa|2023-04-11 10:46:10|Haha, more like we have a small rooftop which can only support so many people😂
Swastik Banerjee|2023-04-11 11:43:05|It’s not entirely location based. It’s org working with openai + selected startups + particular use cases of person working on a specific domain openai is experimenting on
Swastik Banerjee|2023-04-11 11:43:32|I have access to all the plugins sitting near bellandur lake 🤣
Swastik Banerjee|2023-04-11 11:43:59|So I don’t think vpn would work
Dev Aggarwal|2023-04-11 12:21:32|https://www.inferless.com/serverless-gpu-market  Very detailed analysis of the incumbent serverless gpu players out there. We still have a long way to go for true serverless
Aishwarya Goel Inferless 5s for 5G|2023-04-11 12:42:11|Thank you for the shoutout, Dev!   Folks, do give it a read if you are dabbling between serverless GPU providers OR just want to learn the reality of the space so far.  We have stress-tested latency, autoscaling, and other capabilities for GPT Neo - 1.3B, 125Mn, and Roberta Large models and shared results.
Kaushik Bokka|2023-04-11 12:48:00|This is well written! Great job
Rohit GenerativeAI WhatsApp Group|2023-04-11 12:54:41|This is great!  Been using runpod for a while.  1. They don't do batch processing. 2. You can avoid 2 api calls using webhooks 3. Machines are turned off if no request is pending in the queue, so you won't be charged for no usage 4. They are very active on discord.
~ Vaibhav|2023-04-11 13:21:26|This is a very comprehensive guide, Aishwarya.   I was planning to use a serverless gpu offering for one of my hobby projects.  This will help me to make a more sound decision now.
Adithya L Bhat Hackathon|2023-04-11 14:34:19|Anybody know any Ai research labs in Bangalore?
Saurav Akaike|2023-04-11 15:01:06|I have a client which is an AI lab. What's up?
Adithya L Bhat Hackathon|2023-04-11 15:02:00|Looking for some research based experience on cutting edge tech! [PHONE]
Adithya L Bhat Hackathon|2023-04-11 15:02:07|In Ai itself
Saurav Akaike|2023-04-11 15:04:54|Can connect you, DM!
Rahul Rai|2023-04-11 15:05:52|‎Pranjal Mehta added Rahul Rai
Pranjal Mehta|2023-04-11 15:08:58|Rahul is one of the smartest people I know. He's worked at MS on Wall St and then started a crypto hedge fund. He sold it to BlockTower Capital. He's now spending all his time on AI
Pranjal Mehta|2023-04-11 15:25:27|Has anyone tried using YubiBert? CredAvenue's OSS Financial LLM?
Abhishek Maiti|2023-04-11 16:15:26|Linkedin has one of its research arm at Bangalore.
Adithya L Bhat Hackathon|2023-04-11 16:16:07|[PHONE]  whom do i contact?
Abhishek Maiti|2023-04-11 16:16:20|I work there. DMing you
Micheil|2023-04-11 16:27:34|I would also be keen to learn more about this AI lab
Adithya L Bhat Hackathon|2023-04-11 16:28:58|[PHONE] what kind of work do they do?
Abhishek Maiti|2023-04-11 16:34:53|The team works on content moderation and content quality on the Linkedin platform.
Adithya L Bhat Hackathon|2023-04-11 16:35:47|So they build their own models or something for all these?
Abhishek Maiti|2023-04-11 16:37:08|Yes, we train our own models, since the data distribution is different from the datasets used in academic setting.
Adithya L Bhat Hackathon|2023-04-11 16:38:36|Yes got it!
Kartik Mandaville|2023-04-11 17:37:07|Anyone attending the OpenAI meetup in HSR today?
Garv Malik 2012H|2023-04-11 17:40:14|How to find out more?
Ravi Theja|2023-04-11 17:40:55|https://lu.ma/y7uu4m4e
Kartik Mandaville|2023-04-11 17:57:00|https://www.inkle.io/resources/events/talks
~ Adhitya Swaminathan|2023-04-11 18:02:28|Any chance this will be streamed?
~ Sid|2023-04-11 18:43:02|‎~ Sid joined using this group's invite link
Harveen Singh Chaddha|2023-04-11 18:46:03|‎Harveen Singh Chaddha joined using this group's invite link ‎[4/11/23, 20:07:50] Kartik Mandaville: ‎image omitted
~ Shri|2023-04-11 20:21:06|‎~ Shri joined using this group's invite link
~ Arihant|2023-04-11 20:48:11|On providing the required config files to access a service that requires authorisation, can we ask gpt to access let's say a specific table in database and make commits in that?
Shashwat TDC|2023-04-11 21:45:24|Yes. It's possible. You can perform CRUD ops in database
~ Arihant|2023-04-11 21:52:55|this can be done using tools for dml,ddl commands or do you have any other method?
Shashwat TDC|2023-04-11 21:55:57|Yes. Just the dml commands. Connect with [PHONE] if u are still blocked
Deep Samsung R&D|2023-04-12 00:15:45|"Has anyone compared/experimented with OpenAI's best embedding model available ""text-embedding-ada-002"" vs Huggingface models or Sentence Transformers. Have seen most people using OpenAI's embedding, does it have any advantage over others available?"
Krishna Ntkris|2023-04-12 00:18:40|I believe many of the OS ones are superior. There was a thread on this, let me see if I can find.
Krishna Ntkris|2023-04-12 00:19:26|https://twitter.com/mr_cheu/status/1626261050566778880?s=46&t=lkuvFQUWr1nav0QpUpFmdQ
Krishna Ntkris|2023-04-12 00:19:46|That was Feb 2023 so like a decade ago by AI standards…
Sachin Legaltech|2023-04-12 00:45:26|I had compared sentence transformers with OpenAI embeddings 6ish months ago..For my use case, sentence transformers turned out to be quite competitive
Deep Samsung R&D|2023-04-12 00:46:29|Got it, thinking to try this model 'sentence-transformers/all-mpnet-base-v2', is that the best mpnet variation?
Sachin Legaltech|2023-04-12 00:48:50|Multi-qa-mpnet-base-dot-v1 works a little bit better for semantic search ..but I will recommend tryiing top 2 or 3 and checking
Sachin Legaltech|2023-04-12 00:49:46|Also if you need better scoring mechanisms, use cross-encoder for scoring afterwards
~ Tarun Raheja|2023-04-12 05:36:47|‎~ Tarun Raheja joined using this group's invite link
~ Nilay Pochhi|2023-04-12 07:20:21|‎~ Nilay Pochhi joined using this group's invite link
Ojasvi Yadav|2023-04-12 07:37:59|https://youtu.be/540vzMlf-54
Ojasvi Yadav|2023-04-12 07:38:09|Awfully painful questions 😂
Dr. Pratik Desai KissanGPT|2023-04-12 08:12:25|Traditional News Media looks really frightened with AI. Even I got call for Interviews for that tweet 🤦🏽‍♂️. The buzz is really hot and controversial, people are waiting to take you opinion out of context and attack. Everyone is on edge.
Nirant|2023-04-12 08:45:30|Ohh, the ChatGPT Plugins SF hackathon announced their winners: https://twitter.com/atroyn/status/1645954654394802176  You can our demos at https://nirantk.com/deephackdemos —  yourself now.  Highlights:  1. Multimodal model is what [PHONE] built (and didn't win), 2. The Bot or Not is quite a neat application of adversarial ideas (my fav!) 3. One of the winners is literally a weather app 😞
Nirant|2023-04-12 08:46:12|All the winners here have much higher _usability_ than what we had though
Nirant|2023-04-12 08:46:15|Reminder: My intent for sharing this is to emphasise that Indians are no longer playing catch up.   Outside of infra (GPU, Drivers, DBs) and gradient descent (Torch, Tensorflow, Transformers) — we are quite good  For those who chose to stay back here after undergrad, hope this brings you comfort — and energy to invest in polishing, packaging and taking your projects to a great solution!
Anudeep Yegireddi|2023-04-12 09:02:06|Thank you for sharing [PHONE]. The chatrooms concept was super cool, brings social networking into it. I’m going to explore that. It is analogous to an idea I had about enabling long term conversational memory, by vector indexing the conversation history itself.
Nirant|2023-04-12 09:04:21|Langchain has some pretty good abstractions around memory (in addition to the index+retrieve approach): https://python.langchain.com/en/latest/modules/memory/examples/conversational_customization.html
Shashwat TDC|2023-04-12 09:21:45|Happening as we speak : https://twitter.com/i/spaces/1djGXldPqNyGZ?s=20
Nirant|2023-04-12 09:24:19|Very off topic. Appreciate the intent to share news though.   Leaving this here for now, will delete and throw folks out on 2nd strike.
Shashwat TDC|2023-04-12 09:25:59|depends on where you draw the lines. There are obv going to be some AGI conversations in this space. But anyway,
Swastik Banerjee|2023-04-12 09:31:45|Silicon valley is stealing my ideas >.>
Aishwarya Goel Inferless 5s for 5G|2023-04-12 09:36:39|Elon just spent at least $250M on GPUs for training generative AI at Twitter.  https://twitter.com/josephjacks_/status/1645872805647646720?s=48&t=DtzjOgXVCgwDUiK5fng9Mw
~ Tarun Raheja|2023-04-12 09:41:55|https://twitter.com/yoheinakajima/status/1645811071230545920?s=48&t=vVjNVO7AhqZtPO3IJxRokA  Anyone following this babyAGI stuff? Someone just implemented it in LangChain
~ Tarun Raheja|2023-04-12 09:42:45|I’m really liking this autonomous GPT agent stuff :  https://twitter.com/sullyomarr/status/1645205292756418562?s=48&t=vVjNVO7AhqZtPO3IJxRokA
jyotirmayjk Hackathon|2023-04-12 09:43:33|AutoGPT -4 SigGravitas  babyAGI by Yohei
jyotirmayjk Hackathon|2023-04-12 09:46:10|Harrison Chase implemented a custom LangChain abstraction for BabyAGI based on Yohei’s method  Worth checking it out
jyotirmayjk Hackathon|2023-04-12 09:47:19|https://twitter.com/langchainai/status/1645808279849947137?s=46&t=icC0fizZK8E3ONsDVuGFWA
Nirant|2023-04-12 09:47:24|https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html
jyotirmayjk Hackathon|2023-04-12 09:52:31|Also worthwhile checking this out  https://twitter.com/hwchase17/status/1645834030519296000?s=46&t=icC0fizZK8E3ONsDVuGFWA
jyotirmayjk Hackathon|2023-04-12 09:53:33|Smaller version of the “Westworld Sims” experiment
Kaushik Bokka|2023-04-12 09:53:42|Design Principles for building Agents  https://web.media.mit.edu/~lieber/Lieberary/Letizia/AIA/AIA.html
Naman Maheshwari Nimblexbox|2023-04-12 09:56:23|‎Naman Maheshwari Nimblexbox joined using this group's invite link
jyotirmayjk Hackathon|2023-04-12 10:03:26|https://github.com/eumemic/ai-legion
jyotirmayjk Hackathon|2023-04-12 10:03:45|For folks using Typescript for agent building
Manjot Pahwa|2023-04-12 10:04:55|We're starting to see first steps towards regulation by governments https://www.wsj.com/articles/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b
~ Aakash Kaushik|2023-04-12 10:07:33|‎~ Aakash Kaushik joined using this group's invite link
~ Arka|2023-04-12 10:08:26|Obligatory next step for gov of India to try to build BharatGPT. 😅  While GoI's meddling in most economic sectors actually makes it worse, tech might be a lucky exception. (Till now)
Manjot Pahwa|2023-04-12 10:09:22|They're already doing that
~ Arka|2023-04-12 10:09:55|Yeah I heard in a Nadella interview.
Nirant|2023-04-12 10:12:25|Sam Altman is making a DEL trip, not BLR. Clearly, monopolisation and regulations are best buddies.
jyotirmayjk Hackathon|2023-04-12 10:13:04|Monopoly play clearly 😅
~ Nishant Shah|2023-04-12 10:13:32|‎~ Nishant Shah joined using this group's invite link
jyotirmayjk Hackathon|2023-04-12 10:13:32|https://github.com/RSTLess-research/Fauno-Italian-LLM
jyotirmayjk Hackathon|2023-04-12 10:13:49|Italy might have banned OpenAI  But they have built /fine tuned their own LLM
jyotirmayjk Hackathon|2023-04-12 10:14:16|Petition to create a Bharat LLM instead of Bharat GPT
Pranjal Mehta|2023-04-12 10:14:20|Are you referring to a foundational model or a GPT model fine tuned on India data?
Pranjal Mehta|2023-04-12 10:14:30|+100
~ Arka|2023-04-12 10:18:00|I would assume it would start off with GPT first.  Then move to LLM later.  We always buy off the shelf, then local assembly, finally fully local.  From aircraft, to metro, to chip making.
jyotirmayjk Hackathon|2023-04-12 10:29:21|Problem is with all the examples you’ve mentioned we are not fully local till today    There is a strong possibility that regulatory restrictions might apply in future on tech for AI  For example US might just decide to place export controls on A100s  Because these are foundational capabilities to build on top off,blocking access to them artificially stops others from investing and growing independently
jyotirmayjk Hackathon|2023-04-12 10:30:19|A better example would be India’s nuclear programme and ICBMs  It was a ‘foundational’ capability which was denied to us by other nations who had already achieved it  But we did end up building our own completely
Anubhav mishra Zupay|2023-04-12 10:40:55|I think they'll create an LLM because Gov is more focused on self owned public infrastructure
Dev Aggarwal|2023-04-12 10:41:27|https://ai4bharat.iitm.ac.in/models  iitm is making an effort to train indic llms
Anubhav mishra Zupay|2023-04-12 10:41:36|Anyways, AI4Bharat is working on it ig. The IITM one
Anshul Bhide Replit|2023-04-12 10:41:44|BabyAGI on Replit in just 105 lines of code https://replit.com/@YoheiNakajima/babyagi?v=1
Anubhav mishra Zupay|2023-04-12 10:41:57|Lol what a coincidence
Dev Aggarwal|2023-04-12 10:42:34|But I think it will be very hard to beat translation + gpt-4 performance
Anubhav mishra Zupay|2023-04-12 10:43:18|For now their focus can be on transliteration
Anubhav mishra Zupay|2023-04-12 10:44:18|Also they might just invest 500 mil and ask Microsoft and Nvidia to just do it too who knows.
Dev Aggarwal|2023-04-12 10:45:42|Yeah, pratuysh works at msft research only so
Shubham Sharma 2012C6|2023-04-12 10:47:01|https://www.medianama.com/2023/02/223-nadella-bhashini-language-translation-platform/
Dev Aggarwal|2023-04-12 10:48:18|https://farmer.chat  I created another hindi bot for indian farmers :)
Shubham Sharma 2012C6|2023-04-12 10:50:27|Can add more Indic Languages, add voice support and link to government schemes via plugins
Dev Aggarwal|2023-04-12 10:51:08|Voice support is there via one of the ai4bharat models
Dev Aggarwal|2023-04-12 10:52:19|More Indic languages will come :) We’ve tested this with the field workers, and hindi translation performance was acceptable for release..
Dr. Pratik Desai KissanGPT|2023-04-12 10:52:30|We are using IndicTrans in KissanGPT for few already
Dev Aggarwal|2023-04-12 10:52:58|We use google translate. How are the latencies for indictrans? Where are you hosting it?
Dr. Pratik Desai KissanGPT|2023-04-12 10:53:05|Trying to add TTS but the inference is not optimized yet
Lalit Pagaria|2023-04-12 10:53:19|The US got another tool for its leverage and control 🤦  It seems soon each govt will impose conditions like localized deployment,   restrictions on its usages and conditional generation (with moral, religious and political boundaries).
Dev Aggarwal|2023-04-12 10:53:37|You mean stt?
Dr. Pratik Desai KissanGPT|2023-04-12 10:54:10|TTS as we are trying to also return answer in same language
Vignesh Baskaran|2023-04-12 10:54:19|https://www.inferless.com/serverless-gpu-market  Just read this detailed write up on Serverless GPUs. This is too good. We hired a consultant a couple of months ago and did similar benchmarking for our usecase. The conclusion was serverless GPUs have a long way to go forward.  The blog is extremely very well written. Please do give it a read if you would like to know about the current state of serverless GPUs
Dr. Pratik Desai KissanGPT|2023-04-12 10:54:25|You can check it out at https://kissangpt.com
Dev Aggarwal|2023-04-12 10:55:05|Pretty slick!
Dr. Pratik Desai KissanGPT|2023-04-12 10:55:44|We have been working in AI for agriculture for sometime so we have significant amount of knowledge base and in talk with ministry to access huge amount of information that we will start adding
Shubham Sharma 2012C6|2023-04-12 10:55:53|Our government is actually working to enable the ecosystem. They're hiring PMs for AI roles too. bhashini.gov.in/en/ecosystem
Swastik Banerjee|2023-04-12 10:55:59|While [PHONE] speaks of how the country is advancing and getting ahead in the tech-contribution at par with the westworld, the only difference is the tools that people build there start getting used quite immediately and you can see it’s effect, while it’d probably have 0 usability here. ‎[4/12/23, 10:56:53] Swastik Banerjee: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-04-12 10:56:56|Of course we are doing better than most, these models are good but our local open ecosystem needs to jump on making these models production ready from research output. ‎[4/12/23, 10:57:05] Swastik Banerjee: ‎image omitted ‎[4/12/23, 10:57:16] Swastik Banerjee: ‎image omitted
Shubham Sharma 2012C6|2023-04-12 10:57:19|That's probably because we don't have PMF with the end user. Our products are still not designed well for them
Swastik Banerjee|2023-04-12 10:57:47|By what time do you think farmers of India will start using https://kissangpt.com? 🙃
Dr. Pratik Desai KissanGPT|2023-04-12 10:58:02|I have been getting calls from all type of farmers and hobbyist about using Kissan GPT and feature requests. Not getting time to add features as I’m talking to them.
Shubham Sharma 2012C6|2023-04-12 10:58:29|Probably when it stops having foreign words like GPT in its name for starters
Shubham Sharma 2012C6|2023-04-12 10:58:45|(foreign to the local farmer)
Swastik Banerjee|2023-04-12 10:59:00|that’s insane, kudos!
Dr. Pratik Desai KissanGPT|2023-04-12 10:59:04|Already there is a good amount of folks using it. Farmers have phone and they are very much aware of news and things going on then you tokan think.
Dr. Pratik Desai KissanGPT|2023-04-12 10:59:13|Folks*
Dr. Pratik Desai KissanGPT|2023-04-12 10:59:38|There are large club house groups where talk regularly
Swastik Banerjee|2023-04-12 10:59:42|Would love to see an use case like above! 😃
Dr. Pratik Desai KissanGPT|2023-04-12 11:00:52|When last time I was on clubhouse, they were suggesting requests for their everyday use thay I have to look for note pad.
Anubhav mishra Zupay|2023-04-12 11:01:33|Hey how are you ensuring RLHF ? Here ?
Anubhav mishra Zupay|2023-04-12 11:01:42|Do you have any systems in place ?
Lalit Pagaria|2023-04-12 11:01:49|Yes, our students are capable but they don't have the required resources (computing is costly). Hopefully corporate and govt will support this ecosystem.
Dr. Pratik Desai KissanGPT|2023-04-12 11:02:18|No I don’t. But I’m collecting enough information that I can implement something in future and May be share voice dataset with Bhasini.
Dr. Pratik Desai KissanGPT|2023-04-12 11:02:58|Let’s see, lot of initial conversation going on multiple front
Dev Aggarwal|2023-04-12 11:03:53|I got one interesting request to integrate visual capabilities to detect bad signs in the crop photos. Do you have any plans or thoughts there?
Dr. Pratik Desai KissanGPT|2023-04-12 11:05:02|I have asked OpenAI to give me access to multimodal when it is available in gpt4 api, let’s see when that available. We will be integrating it.
Lalit Pagaria|2023-04-12 11:05:03|This is a novel and socially good use case.  Ping me if you need support, especially in scalability and infra aspects.
Dr. Pratik Desai KissanGPT|2023-04-12 11:05:54|Yes soon, I’ll have to move from my home rigs to cloid infra. I’ll reach out.
Dev Aggarwal|2023-04-12 11:06:21|You are running this on your home infra? 🔥🤯
Anubhav mishra Zupay|2023-04-12 11:06:44|🙏🙏
Dr. Pratik Desai KissanGPT|2023-04-12 11:06:46|Yes 😔
Anubhav mishra Zupay|2023-04-12 11:07:05|What will the cost to move it to the cloud?
Dr. Pratik Desai KissanGPT|2023-04-12 11:07:09|Need to keep cost low as possible to make it available for Agri domain ‎[4/12/23, 11:07:27] Dev Aggarwal: ‎GIF omitted
Anubhav mishra Zupay|2023-04-12 11:07:51|Register a company and apply to Microsoft for startups get 150k in credits donot for 2 years
Dr. Pratik Desai KissanGPT|2023-04-12 11:07:55|One PSU already gave up
Dev Aggarwal|2023-04-12 11:08:07|Same, we got google cloud for 2 years.
Dr. Pratik Desai KissanGPT|2023-04-12 11:08:11|Working on it
Dev Aggarwal|2023-04-12 11:08:26|Amazon before that. Just keep moving clouds until you get free credits from everyone
Anubhav mishra Zupay|2023-04-12 11:08:29|They are supportive
Lalit Pagaria|2023-04-12 11:09:28|With open source, non-profit research use cases any cloud provider can provide credits easily.
Dev Aggarwal|2023-04-12 11:10:11|How big are you guys? Just you?
Dr. Pratik Desai KissanGPT|2023-04-12 11:10:55|I am not thinking non-profit case as it won’t help me scale. I have Agri startups to integrate in their platforms lined up. But still they do give startup credits which I’m going to apply for.
Dr. Pratik Desai KissanGPT|2023-04-12 11:11:31|Im here in Bay Area and small team in Surat, 7.
Dr. Pratik Desai KissanGPT|2023-04-12 11:15:11|I know [PHONE] is also from Surat. Small city folks. 😁
Harsh Gupta Felvin|2023-04-12 11:21:35|Any Finance bros/gals in this group playing with AI? There is an idea I'm toying with would love to chat.
~ Vishwam Jindal|2023-04-12 11:23:02|Not finance but building in the legal space.
Aishwarya Goel Inferless 5s for 5G|2023-04-12 11:23:27|Glad to find that it was helpful! :)
Nirant|2023-04-12 11:25:09|‎POLL: Proposal: Weekly Summary, mostly links, some messages (with names) mentioned on public web e.g. https://nirantk.com ‎OPTION: Yes (40 votes) ‎OPTION: No (0 votes) ‎OPTION: Yes, remove names, can retain topics and links (5 votes)
~ Chan|2023-04-12 11:33:06|‎~ Chan joined using this group's invite link
Karthik CRED|2023-04-12 11:38:04|Have you used TTS ? Can’t locate their weights
Karthik CRED|2023-04-12 11:38:39|What are you using, quality is good
~ Jyotsna Varkey|2023-04-12 11:49:39|‎~ Jyotsna Varkey joined using this group's invite link
Dr. Pratik Desai KissanGPT|2023-04-12 11:54:13|You have to literally hack into their XMLs and storage path to get those. They are saying they have them on Bhasini and open sourced them but I couldn’t find direct links. I tried to request on their account but I didn’t get any reply, and then the inference is not optimized. That’s the reason I’ve to run everything on my rigs right now, as a lot of hacks are involved. ‎[4/12/23, 12:14:35] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-12 12:14:51|Just realised that SAM runs inside a browser on the cpu 🤯
Nirant|2023-04-12 12:15:11|cc [PHONE] do you want to do a demo on this in the April meetup?
Ravi Theja|2023-04-12 12:16:32|Yup. Working on it.
Nirant|2023-04-12 12:16:59|Link for April meetup, for those who've joined recently https://hasgeek.com/generativeAI/april-meetup/
Nirant|2023-04-12 12:17:04|In-person, BLR only
~ rohan~|2023-04-12 12:20:45|‎~ rohan~ joined using this group's invite link
Dr. Pratik Desai KissanGPT|2023-04-12 12:22:44|https://huggingface.co/spaces/abhishek/StableSAM
Sanyam Bhutani|2023-04-12 12:23:27|I’ll be there 🫡
Vedant Trivedi Sequoia|2023-04-12 12:23:49|Folks, a portfolio co which generates research reports on quality of carbon credits, is looking for tools that can help write their research reports on top of the research they have done. This report will be a mix of text & charts.   Is there an existing tool in market that can help with this?
Vedant Trivedi Sequoia|2023-04-12 12:24:19|Else, if someone is willing to hack something like this along with the portfolio co, happy to make the introduction.   Pls DM!
Nirant|2023-04-12 12:24:33|whosoever picks this up, please charge more than $10K
Yash Pandya|2023-04-12 12:44:10|The initial encoder uses GPUs, it's only the decoder which runs on web browser.
Shimanta Generative AI|2023-04-12 13:45:43|I have a question regarding SAM. Has anyone checked or knows about the difference in quality of segmenting with SAM and then out painting, compared to masking and out painting which we can see in automattic ui and others?
Nirant|2023-04-12 13:46:24|Compare yourself here: https://huggingface.co/spaces/abhishek/StableSAM
Nirant|2023-04-12 13:50:40|You'll need a 512X512 to try this link btw. Errors out for all else dims
Ravi Theja|2023-04-12 13:54:18|Internally resizing is happening right
Shimanta Generative AI|2023-04-12 13:54:41|Thanks, will try this ‎[4/12/23, 13:55:09] Nirant: ‎image omitted
Dev Aggarwal|2023-04-12 13:55:36|Dumb Q: Wont you use SAM to just generate a mask for the inpainting or outpainting model? ‎[4/12/23, 13:56:49] Ravi Theja: ‎image omitted
Shimanta Generative AI|2023-04-12 13:57:37|I’m still a noob at these.  I guess what you’re saying is right. I was thinking about how creating a mask with SAM compares to other masking techniques which happen, in say the automattic ui
Dev Aggarwal|2023-04-12 13:58:18|I think the advantage with SAM is the interactivity from a UX perspective
Dev Aggarwal|2023-04-12 13:58:34|This looks like SD code, not the sam code
Ravi Theja|2023-04-12 14:00:05|Yes SAM gives mask
~ Manav Shah|2023-04-12 14:29:31|‎~ Manav Shah joined using this group's invite link
Ojasvi Yadav|2023-04-12 15:01:45|tried, still didn't work
~ Kaustubh Mundra|2023-04-12 15:26:03|‎~ Kaustubh Mundra joined using this group's invite link
jyotirmayjk Hackathon|2023-04-12 15:32:36|https://twitter.com/kevinafischer/status/1646009719314841601?s=46&t=icC0fizZK8E3ONsDVuGFWA
~ Akshi|2023-04-12 15:38:44|‎~ Akshi left
~ Mani|2023-04-12 15:39:52|‎Soumyadeep Mukherjee added ~ Mani
Manjot Pahwa|2023-04-12 16:50:31|AI agents writing their own plugins  https://twitter.com/nicolaerusan/status/1644120508173262853
~ Prateek|2023-04-12 16:51:59|‎~ Prateek joined using this group's invite link
Pushpak Kedia Sequoia|2023-04-12 18:14:23|https://twitter.com/shivam124081/status/1645691399164026880?s=46&t=kpJ79jqt9oDMH6ZCqnhylA   Meta’s SAM being applied to medical imaging
Nirant|2023-04-12 18:25:55|Cc [PHONE] karde Kya?
Sudharshan GenAI|2023-04-12 19:29:58|Hey folks, anyone here know any dataset agencies? (Need to curate an instruct type dataset.)
~ Sayantan|2023-04-12 20:10:57|‎~ Sayantan joined using this group's invite link
~ Vasu 🥸|2023-04-12 20:15:52|‎~ Vasu 🥸 joined using this group's invite link
Bharat Kumar Ramesh Hashmal Web3|2023-04-12 21:37:17|Folks, this langchain webinar with harrison, yohei among others is quite nice - https://www.crowdcast.io/c/46erbpbz609r. Is live now
Anubhav mishra Zupay|2023-04-12 22:38:17|Can anyone share Langchain resource i can checkout to get started ?
~ Prajwal|2023-04-12 22:40:10|The Langchain docs are really good to get started with they also have guides for reference too. Check them out here :   Here's YT channel which is creating videos around using LanchainJS and building web apps : https://www.youtube.com/@chatwithdata
~ Prajwal|2023-04-12 22:40:28|*- https://python.langchain.com/en/latest/
Anubhav mishra Zupay|2023-04-12 22:45:54|Thanks
Naman Jain Stellaris|2023-04-12 23:16:22|https://huyenchip.com/2023/04/11/llm-engineering.html
Yash Pandya|2023-04-12 23:40:34|OpenAI have released open source implementation and model weights for their latest work. These models do one step image generation.   https://github.com/openai/consistency_models
Anagh Prasad|2023-04-13 00:35:55|Love how they crowd sourced the dataset from own employees: https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
Dr. Pratik Desai KissanGPT|2023-04-13 04:04:15|This can be amazingly fast as it doesn't use diffusion. If someone finds memory requirements and inference speed, please share. If it is small enough to tinker without using the A100 cluster, we can see its versions of Dreambooth and ControlNet popping out soon.
Dev Aggarwal|2023-04-13 04:10:57|A nice summary - https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/
~ Varun|2023-04-13 10:39:55|‎~ Varun joined using this group's invite link
~ Kaustubh Mundra|2023-04-13 11:49:44|‎~ Kaustubh Mundra joined using this group's invite link ‎[4/13/23, 13:26:07] Nirant: ‎image omitted
~ Kaustubh Mundra|2023-04-13 13:26:48|‎~ Kaustubh Mundra left
Kartik Mandaville|2023-04-13 13:26:56|oh no! we just went live with Pinecone and this is scary
Nirant|2023-04-13 13:27:50|Ditch em. That's a key risk. Even if you ever want to tell your customers how good your recall your QA is, Pinecone prevents you from doing so. Will handicap your marketing/sales.
Kartik Mandaville|2023-04-13 13:28:19|yes agreed. Weaviate had other problems though - scale, connectors. Will check out Qdrant
Nirant|2023-04-13 13:29:34|Yeah, hear you on Weaviate's scaling issues. Qdrant scales betters. Connectors solution is to go via Llama Index for recall.   [PHONE] also has an built a query-context evaluation component, so you can later flag to customers that your answer rate is dropping or changing.
Nirant|2023-04-13 13:30:06|That is quite valuable to my enterprise SaaS friends, any sort of reporting/tooling to see what they're missing in FAQ
Kartik Mandaville|2023-04-13 13:35:17|yes using LlamaIndex with Pinecone in prod with Ravi's evaluation
Nirant|2023-04-13 13:36:17|Please forgive me for being repetitive, I am a sucker for neatly executed ideas 😅
Ravi Theja|2023-04-13 13:40:23|Much needed one. As more people use it, it helps me to get feedback and make it better 👍😉
Ambarish Ganguly|2023-04-13 13:48:42|Which is the best Vector DB for production ?
Ambarish Ganguly|2023-04-13 13:48:52|Naive question but being bold asked
Nirant|2023-04-13 13:49:16|Not naive at all, the answer is — we don't know
Ambarish Ganguly|2023-04-13 13:49:26|😎
Ambarish Ganguly|2023-04-13 13:49:32|Ok
Nirant|2023-04-13 13:49:38|Worse, we don't know if it's worth answering this question when 32K context windows become a thing
Pratyush Choudhury|2023-04-13 13:50:04|I am a little biased but I'd throw in the name of Redis
Pratyush Choudhury|2023-04-13 13:50:18|Inferencing costs?
Ambarish Ganguly|2023-04-13 13:50:52|People married to Azure Redis is the only choice which is PAAS
Nirant|2023-04-13 13:51:24|[PHONE] sir, sponsor a grant to do this ANN Recall vs $$ benchmark? I'll do it for 💵
Ambarish Ganguly|2023-04-13 13:51:38|I am liking this group so lively
Ambarish Ganguly|2023-04-13 13:52:42|There is one Vector DB Millivus
Nirant|2023-04-13 13:52:44|The current inferencing costs are about 10-50x from what they can be at scale, even for GPT4. I think the price will drop another 10x in next 6-12 months.
Nirant|2023-04-13 13:53:42|Name your favourite Pokemon: Milvus, Weaviate, Qdrant, Chroma, Pinecone, Redis Vector Cache, Vespa, Elastic, pgvector on Supabase
Pratyush Choudhury|2023-04-13 13:54:22|I like you 2x2 matrix actually here   But Redis has the most production adoption from what I have seen (could be my sampling bias)
Kartik Mandaville|2023-04-13 13:54:59|I'll let you know how Pinecone goes. Will push to 250 customers next week.
Krishna Ntkris|2023-04-13 13:56:08|I’m implementing hybrid search and really annoyed with their docs. Literally tried their example and it doesn’t work. Good time to move away it sounds like
Pratyush Choudhury|2023-04-13 13:56:20|Umm, could I ask what makes you believe so?   GPT4 has become more expensive than GPT3.5 Turbo
Pratyush Choudhury|2023-04-13 13:56:40|Cloud Providers' APIs are also fairly expensive
Pratyush Choudhury|2023-04-13 13:56:45|Azure, AWS, GCP
Pratyush Choudhury|2023-04-13 13:58:33|For example, https://aws.amazon.com/comprehend/medical/pricing/
Kartik Mandaville|2023-04-13 13:58:49|GPT3.5 was cheaper than GPT3
Rohit GenerativeAI WhatsApp Group|2023-04-13 14:05:24|Was?
Nirant|2023-04-13 14:05:58|text-davinci-003 is more expensive than gpt3.5-turbo
Kartik Mandaville|2023-04-13 14:06:12|sorry, is.
Dr. Pratik Desai KissanGPT|2023-04-13 14:06:28|2M tokens for $2
Rohit GenerativeAI WhatsApp Group|2023-04-13 14:06:29|Ah! I thought they increased overnight
Kartik Mandaville|2023-04-13 14:07:07|point is that LLM models will only get cheaper and faster - as proven in the past few months. GPT4 is more expensive than 3.5 until GPT5 comes up
Nirant|2023-04-13 14:07:33|GPT4 has two major releases pending:   1. Vision 2. 32K context windows
Nirant|2023-04-13 14:08:07|3. Plugins for all practical purposes. I doubt they want to stop at giving 20K people access to that.
Nirant|2023-04-13 14:08:57|Plugins has _at least_ 2 new GPT4 finetuned forks:  1. Python REPL 2. Retrieval  Confirmed by OpenAI Engineering
Kartik Mandaville|2023-04-13 14:09:35|and plugins in API
Kaushik Bokka|2023-04-13 14:09:50|I got zero juice from that Atty OpenAI event
Kaushik Bokka|2023-04-13 14:09:54|sigh
Nirant|2023-04-13 14:10:21|The juice from the Setu event was worth 30 min commute tbh
Kaushik Bokka|2023-04-13 14:10:44|Setu event?
~ Haider Ali Khan|2023-04-13 14:10:52|‎~ Haider Ali Khan joined using this group's invite link
~ Akki|2023-04-13 14:11:43|‎~ Akki joined using this group's invite link
Nirant|2023-04-13 14:12:01|"Before the open-for-all event, Setu hosted Atty in a closed door meeting. He answered questions like finetuning for plugins, API design, release plans and constraints, internal tooling, some benchmarks (and who makes them), checkpointing and how they decide to brand one model as ""GPT4"""
Kaushik Bokka|2023-04-13 14:12:30|bruh, this sounds so much better
Kaushik Bokka|2023-04-13 14:12:46|lol
Lalit Pagaria|2023-04-13 14:13:03|Can add libraries to the list? Faiss, Annoy, ScaNN, ANNlite
Nirant|2023-04-13 14:13:26|Yeah, at the very least FAISS and Annoy qualify
Nirant|2023-04-13 14:13:35|But I ran out of storage in my Pokedex
Soumyadeep Mukherjee|2023-04-13 14:53:44|How much? :P
Nirant|2023-04-13 14:58:12|If you've to ask ...
Prayank Swaroop Accel|2023-04-13 14:59:47|I doubt it Karthik, most of the foundational LLM companies are losing a lot of money + there is a GPU shortage in the market ... they have to jack up prices to customers.  At least I think next 12 months prices will increase, until there is mass adoption and so we reach supply demand equilibrium.
Nirant|2023-04-13 15:01:33|Will you take a personal wager of 1L INR on price hike?
Nirant|2023-04-13 15:01:58|I'm willing to take a personal wager that prices drop — either via people switching to internal GPUs or OpenAI or some other mechanism
Prayank Swaroop Accel|2023-04-13 15:03:01|Sorry not a gambler here. But happy to buy you a drink. And as I said my comment is for commercial LLM providers - a company switching from commercial to self-hosted / open source LLM is not where my perspective applies.
Prayank Swaroop Accel|2023-04-13 15:03:43|Cost of compute is high, moving to open source / self hosted makes a lot of sense. But then you have to include the LLMOps cost + team cost + data cost etc etc ...
Prayank Swaroop Accel|2023-04-13 15:04:10|And I don't believe most startups have the money to hire very expensive research scientists that OpenAI has
Nirant|2023-04-13 15:05:11|It is a gamble if you think it's a game of chance and not skill :)
Dr. Pratik Desai KissanGPT|2023-04-13 15:05:22|Maybe once the usage of private data to train the model is restricted, APIs can be free if the user consent to give up on data rights. Paid for those who don't.
Prayank Swaroop Accel|2023-04-13 15:05:27|The moat for a company lies in proprietary dataset is my view.
Kartik Mandaville|2023-04-13 15:10:23|I believe even commercial ones will get cheaper and willing to bet on it. We haven’t even seen AWS, Google, Microsoft enter yet
Prayank Swaroop Accel|2023-04-13 15:14:56|Unfortunately to me it feels like Google is not even in the game. And Microsoft has such a sizeable investment in OpenAI that most probably Azure APIs will be essentially OpenAI APIs repackaged.
Prayank Swaroop Accel|2023-04-13 15:15:26|I think the fight is between Oracle (yes lot of people don't know that they are cheapest out there in GPU pricing) vs. AWS
Nirant|2023-04-13 15:16:24|TPUs don't make a difference?
Nirant|2023-04-13 15:17:46|Fantastic case study from StableCog and what did they consider when selecting between all the popular Vector Databases.  Spoiler: Qdrant won on good docs, low RAM consumption and scales well for both latency and throughput  And slowness complaints of pgvector on Postgres should be a meme now 😂   cc [PHONE] might be of interest to you. https://stablecog.com/blog/the-best-vector-database-for-stablecogs-semantic-search
Kartik Mandaville|2023-04-13 15:23:37|lets discuss in 6 months
Ashwin Matrix|2023-04-13 15:25:02|‎Ashwin Matrix joined using this group's invite link
Ambarish Ganguly|2023-04-13 15:32:30|good documentation
Kishore GenAI|2023-04-13 15:47:42|https://github.com/lllyasviel/ControlNet-v1-1-nightly
Ambarish Ganguly|2023-04-13 16:16:18|Is anybody using Milvus ?
Nirant|2023-04-13 16:17:30|I hear it's popular at Zilliz
Ambarish Ganguly|2023-04-13 16:17:52|It's their opensourc
Ambarish Ganguly|2023-04-13 16:17:55|opensource
Ambarish Ganguly|2023-04-13 16:18:24|https://zilliz.com/
Nirant|2023-04-13 16:18:48|You didn't have to ruin the joke for everyone by explaining it
Kartik Mandaville|2023-04-13 16:20:16|someone will need to build a migration tool to avoid re-embedding
Sumod K Mohan|2023-04-13 16:28:16|AFAIK: That is an open research problem.
Ojasvi Yadav|2023-04-13 16:43:49|I'm currently in touch with the Lead who's managing vector similarity search in Redis  Does anyone have any questions that they'd like to know more about?
Nirant|2023-04-13 16:44:58|Recall against $$, recall against qps
Sumod K Mohan|2023-04-13 17:21:10|Prayank, I agree with your arguments from the economics pov. From a technical pov, it seems like models will get smaller without drastic reduction in accuracy unlike now. The fact that we can train them with simple optimisation algorithms, the fact that you train on 570GB to create a 170B parameter model etc, all sort of allude to the fact that we possibly have a much smaller model (possibly this is just a smaller model embedded in larger space, so to speak). There are things that can still  help these companies make money and we still have to use them.
Pranjal Mehta|2023-04-13 17:28:12|The research community is super split on this. There is a smaller model future faction and a larger model faction. Smaller you described and larger you can guess. After having spoken to enough researchers, it feels like only time will tell which way we will head. OpenAI is clearly interested in larger and larger models.
Pranjal Mehta|2023-04-13 17:30:21|Is any meaningful alternative to Nvdia coming up in the next 12 months that can alleviate the stress on chip supply?
Prayank Swaroop Accel|2023-04-13 17:31:12|From what I have read, smaller models are accurate for certain tasks but for higher accuracy still larger models are required. And, also emergent abilities are coming out in larger models
~ Pranay Desai|2023-04-13 17:33:04|‎~ Pranay Desai joined using this group's invite link
Dev Aggarwal|2023-04-13 17:33:53|https://tenstorrent.com
Pranjal Mehta|2023-04-13 17:33:56|[PHONE] good to see you here
Pranjal Mehta|2023-04-13 17:36:26|[PHONE] any idea on who is using them and what is the cost/performance comparison to NVidia?
Pallav Nadhani Fusion Charts|2023-04-13 17:37:17|‎Pallav Nadhani Fusion Charts joined using this group's invite link
Dev Aggarwal|2023-04-13 17:37:48|This is jim keller’s new chip company. Openai put money into it. Don’t know the specifics right now, but jim informally told us that they want to build a 2 terabyte ram ai accelerator.
Dev Aggarwal|2023-04-13 17:39:47|Sorry I dont think the openai funding got through yet - https://techcrunch.com/2023/01/10/openai-in-talks-to-back-zeloof-and-chip-legend-kellers-startup-at-100-million-valuation/amp/
Sugam Docyt|2023-04-13 17:40:09|‎Sugam Docyt joined using this group's invite link
Pranjal Mehta|2023-04-13 17:40:46|Just noticed they have a Bangalore office. Unbelievable!
Dev Aggarwal|2023-04-13 17:40:51|But the vibe at the bangalore meetup was very clear, they want to give the incumbents a run for their money :)
Sumod K Mohan|2023-04-13 17:41:05|You are 100% accurate on this. There is interesting dynamics around what is needed by the task at hand. So really the question is are there going to be lots of reasoning like applications or better search/similarity like applications. How much larger models resoning like capability requires, that probably is anyone guess. Given the semiconductor lifecycle, new chips will take time. OpenCL has been trying to make inroads for last decade. Would be interesting if new models can do reasoning (GPU like) + table lookups (traditional computers), AllenAI did some work on this but nothing mind blowing afaik.
Dr. Pratik Desai KissanGPT|2023-04-13 17:42:03|IMO these are very long term play and probably only help OpenAI or whoever can afford development out side of cuda. Also OAI, reportedly using Cerebras.
Pranjal Mehta|2023-04-13 17:43:18|AllenAI's announcement this summer will change that mostly but I wouldn't swear by it yet
Dev Aggarwal|2023-04-13 17:44:29|Cant tell about the long term play part, but they were a lot of talks about open ISAs because of risc-v and how they’re actually trying to democratise access to chip designs. They also talked a lot about open source.
~ Abdul Khalid|2023-04-13 17:48:14|‎~ Abdul Khalid joined using this group's invite link
~ yasoob|2023-04-13 17:50:04|‎~ yasoob joined using this group's invite link
Sagar Patidar Primathon|2023-04-13 17:50:33|‎Sagar Patidar Primathon joined using this group's invite link
Karan Lightspeed|2023-04-13 18:36:19|‎Karan Lightspeed joined using this group's invite link
~ Mani|2023-04-13 18:48:30|folks, have you come across any open source LLMs that are strong with code generation & various programming languages?
Dr. Pratik Desai KissanGPT|2023-04-13 18:51:20|If I'm not wrong, Replit and Aws codewishperer are both using CodeGen
Dr. Ashith Generative AI WA Group|2023-04-13 18:53:19|Anybody knows Something which can be hosted locally without internet... Can Alpaca be finetuned for local codebase?
Shimanta Generative AI|2023-04-13 18:54:53|I recently tried running GPT4ALL locally and it worked pretty good on my 8gb ram laptop ‎[4/13/23, 18:57:39] Shashank Generative AI Group: ‎image omitted
jyotirmayjk Hackathon|2023-04-13 19:01:56|https://github.com/ravenscroftj/turbopilot
~ Mani|2023-04-13 19:15:02|I was just trying this since noon. This is good for text generation and the onboarding is super simple. But it’s not really strong with code yet
~ Mani|2023-04-13 19:17:04|Will check this out 👍
Shimanta Generative AI|2023-04-13 19:18:08|Agreed. OpenAI has kind of merged their codex model with GPT 3.5 turbo so they have a single purpose code generation model kind of integrated which makes it powerful ‎[4/13/23, 19:40:51] Nirant: ‎image omitted
Nirant|2023-04-13 19:41:37|Feat. [PHONE]
Sudharshan GenAI|2023-04-13 19:41:51|Nice! Any way deck can be shared?
Nirant|2023-04-13 19:43:12|There is no deck, it's a survey thing they did live
Sudharshan GenAI|2023-04-13 19:44:17|Ah
Deep Samsung R&D|2023-04-13 19:57:47|🔥Commercially Viable LLM from Databricks - Dolly 2.0 - 12B parameter language model (LLM)  https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
Deep Samsung R&D|2023-04-13 19:58:20|They have open-sourced training code, the dataset, and the model weights, all suitable for commercial use :)
Pranjal Yadav Razorpay|2023-04-13 20:01:57|That's their top highlight while selling the contract renewal of the data bricks platform 😂
Dev Aggarwal|2023-04-13 20:03:22|https://github.com/huggingface/diffusers/releases/tag/v0.15.0  Huggingface is on fire 🔥
Harsh Koo|2023-04-13 20:17:38|Such a good share.
Ojasvi Yadav|2023-04-13 20:20:48|Anyone wants to join hands on translating Spectrogram Diffusion to work for images?  I have already published 2 papers in this domain. So most of the help is required in mastering this repo.
Harsh Koo|2023-04-13 20:22:25|We (Koo)want to identify generated images.   I'm at Lightspeed. We should talk if you are around too.
Nirant|2023-04-13 20:22:57|cc [PHONE] runs a company called Spoofsense.ai if I remember correctly, but I might be wrong
Ojasvi Yadav|2023-04-13 20:24:34|Perfect. I'm wearing a Dukaan tee. How can I spot you?
Kartikeya Bharadwaj|2023-04-13 20:25:30|Hi Harsh, Kartikeya here (spoofsense.ai) would love to connect.
Harsh Koo|2023-04-13 20:34:38|Coming back up. Stepped our to buy cigs
Karan Lightspeed|2023-04-13 20:36:00|Are you sure, heard it can’t be done
~ Abdul Khalid|2023-04-13 20:41:09|Let me know how we can collaborate. Sending you DM
Kaushik Bokka|2023-04-13 21:42:49|https://twitter.com/ashe_cs/status/1646543644038397952?s=46&t=0NBX3C3Uma-Su4_rjA3OMA
Ojasvi Yadav|2023-04-13 21:51:12|Thanks a lot [PHONE] for hosting today's mixer. Met so many cool people and it was absolutely delightful to hear what everyone in Bangalore AI space is up to.
Nirant|2023-04-13 22:07:13|You forgot to thank them for free beer and food 😂
Ojasvi Yadav|2023-04-13 22:08:53|Ehh they'll probably make it back 10x if they invest in some of the killer startups that people represented today 😉
Harsh Koo|2023-04-13 22:10:51|Nirant should get carry!! He runs a group that has the highest ROI of perhaps most groups in Bangalore tech space.
Sanyam Bhutani|2023-04-13 22:17:20|Anyone else experiencing crazy timeouts with GPT-4 API? 🥺
~ Priyal Motwani|2023-04-13 22:22:06|‎~ Priyal Motwani joined using this group's invite link
~ Arsalaan|2023-04-13 22:25:54|Yes
Deep Samsung R&D|2023-04-13 22:26:04|Ohh yes, I think so. It started to feel slower from evening today
Nirant|2023-04-13 22:26:54|They're rolling out new access, so small spike. Will even out tomorrow hopefully. Consider using tenacity with exponential backoff in the meantime and be nice :)
Nirant|2023-04-13 22:27:21|Tenacity is a Python lib for retrying with exponential backoff
Sanyam Bhutani|2023-04-13 22:27:55|Mujhe laga life skill of being patient bola aapne 😂
Sanyam Bhutani|2023-04-13 22:28:07|(Not kidding. I actually didn’t the framework. Thanks 🙏)
Chirag Jain|2023-04-13 23:45:34|Cerebras is doing some solid work but not planning to be consumer focused chips  they have their own massive chips in their data centers running their software all  behind a cloud
Harsh Koo|2023-04-13 23:58:33|https://www.linkedin.com/posts/harshsinghal_under40-activity-7052341005978615809-EaUX?utm_source=share&utm_medium=member_android
Satish DeepHack Sponsor|2023-04-13 23:58:35|Sambanova building FPGA based chips for AI https://sambanova.ai/products/datascale
Harsh Koo|2023-04-13 23:58:50|Open to working on this with interested folks.
Shashank Generative AI Group|2023-04-14 00:01:32|langchain uses Tenacity too!
Chirag Jain|2023-04-14 00:04:32|"+1 on this  my bet is  small and finetuned for ""assisting"" models and a single massive (both context length and params) aligned generative models that the former models can stuff context into  the creativity and emergence is just not there (yet) under a certain number of params and training tokens"
Dev Aggarwal|2023-04-14 00:25:34|We have an api for this kids as superheros idea 😆  https://gooey.ai/face-in-ai-generated-photo/?run_id=rpwr6kg6&uid=BdKPkn4uZ1Ys0vXTnxNnyPyXixt1
Anubhav mishra Zupay|2023-04-14 00:34:13|https://techcrunch.com/2023/04/13/with-bedrock-amazon-enters-the-generative-ai-race/
~ Jay|2023-04-14 00:35:07|‎~ Jay joined using this group's invite link
~ Arpit Jain|2023-04-14 00:36:50|‎~ Arpit Jain joined using this group's invite link
~ Aman|2023-04-14 00:48:20|Today i finished the Andrej Karpathy's video on Neural Nets. Even though i knew few things, i learned a lot in depth. Will highly recommend to anyone starting or even in the field. He teaches really well and in depth.
~ Aman|2023-04-14 00:50:58|https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ  This one
Rohit GenerativeAI WhatsApp Group|2023-04-14 00:53:58|cache LLM calls and save $$  https://python.langchain.com/en/latest/modules/models/llms/examples/llm_caching.html
Harsh Koo|2023-04-14 00:57:14|Tried this on an online image. Pretty good.   Wary about sending kids images to anything online. Will try img2img models
Abhiram Ramesh|2023-04-14 00:58:10|‎Abhiram Ramesh joined using this group's invite link
Dev Aggarwal|2023-04-14 00:58:22|Img2img models for inpainting? How?
Harsh Koo|2023-04-14 01:07:29|"I'm not an expert and things are moving fast - I'll ask GPT-4, browse diffusers like crazy, watch a ton of YouTube videos or wait for someone here to suggest.  But, it'll get figured out like all other things that get figured out if I follow the above ""process"""
Dev Aggarwal|2023-04-14 02:02:33|https://stability.ai/blog/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users  So glad that they still plan to open source it. Must thank lightspeed for funding them 😁
Ojasvi Yadav|2023-04-14 08:58:09|Morning everyone. I remember seeing a Twitter post about 'ChatGPT for a github repository'.  Basically lets you ask questions on a github repository.  Does anyone remember what it's called?
jyotirmayjk Hackathon|2023-04-14 08:59:25|https://js.langchain.com/docs/modules/indexes/document_loaders/examples/web_loaders/github  Is it this?
jyotirmayjk Hackathon|2023-04-14 08:59:46|Demo video of Chat with GitHub  https://twitter.com/mayowaoshin/status/1646556740253515786?s=46&t=icC0fizZK8E3ONsDVuGFWA
~ Aman|2023-04-14 09:16:55|Must be this one only
Ojasvi Yadav|2023-04-14 09:17:38|sweet, thanks bud. Have a great day.
Lalit Pagaria|2023-04-14 10:07:37|"What if someone build this ""Google me what I have seen or heard somewhere"" 😅"
jyotirmayjk Hackathon|2023-04-14 10:11:01|It is entirely possible using LangChain   Use SerpAPI as tool 1,PythonRepl as tool 2(for tasks like scraping data)  Optional tool -bash shell  And set up your agent
~ ボルツザマク|2023-04-14 10:13:23|Actually, I am using Bard for asking questions on a github repository, and it is performing pretty well for me until now.
Lalit Pagaria|2023-04-14 10:13:39|Seen/Read: On Twitter, Browser, WhatsApp, Slack, and any other platform/app   Heard: Calls, meetings, video calls, YouTube videos, and similar
jyotirmayjk Hackathon|2023-04-14 10:14:05|Check Reflect.Ai then
Lalit Pagaria|2023-04-14 10:15:45|Thanks I will check. Is this one? https://reflect.app/
jyotirmayjk Hackathon|2023-04-14 10:16:03|Ah no,I think I got the name wrong  Let me check again
Ravi Theja|2023-04-14 10:16:21|Directly asking questions to bard about certain repository by providing link or some other way?
~ ボルツザマク|2023-04-14 10:18:02|For famous repositories, it directly works by typing the name of repo, for new repo or repo that is not ranked, I provide link and ask questions.
Sachin Legaltech|2023-04-14 10:19:02|I think you meant rewind.ai
jyotirmayjk Hackathon|2023-04-14 10:19:07|I could really do with that tool just now 😅 Not able to find the reference at all  As soon as I get it ,I’m buying the subscription
jyotirmayjk Hackathon|2023-04-14 10:19:13|Yes exactly
jyotirmayjk Hackathon|2023-04-14 10:22:41|Their tagline itself is  “Ask Rewind about anything you’ve seen,said or heard”
~ Pradyumna Bang|2023-04-14 11:03:40|Building LLM applications for production  https://huyenchip.com/2023/04/11/llm-engineering.html
Deep Samsung R&D|2023-04-14 11:15:53|https://grail.cs.washington.edu/projects/dreampose/
Deep Samsung R&D|2023-04-14 11:16:23|Here's a new AI model called DreamPose that can generate Video from Image.  Given an input image of a person and pose sequence, DreamPose synthesizes a photorealistic video of the input person following the pose sequence.
Ravi Theja|2023-04-14 11:36:44|do we need to finetune the model on the subject-specific image before creating the video?  [PHONE]
Deep Samsung R&D|2023-04-14 11:47:20|Yeah it looks like it, https://github.com/johannakarras/DreamPose#finetune-on-sample
Prashant Singh|2023-04-14 13:11:59|ok. noob question may be but how is this diffrent from an edge detection algorithm on steroid .
Sriram Covid19 Endcoronavirus|2023-04-14 13:23:32|‎Sriram Covid19 Endcoronavirus joined using this group's invite link
~ Siddhartha|2023-04-14 13:25:04|‎~ Siddhartha joined using this group's invite link
Swastik Banerjee|2023-04-14 14:04:43|question: for smaller sets of data, what’ll be the difference between generating embeddings and storing them in vectorDBs v/s providing them directly to the LLM for question-answering?
Ravi Theja|2023-04-14 14:07:50|If data set has >4000 tokens you have to chunk it and store them in dbs and do QA by taking relevant chunks….if it’s <4000 tokens you can directly ask LLM for QA.
Rohit GenerativeAI WhatsApp Group|2023-04-14 14:15:31|4k is still high. One should consider prompt tokens and tokens to generate in the answer too. Else they are left with just 97
~ Ankur|2023-04-14 14:17:37|‎~ Ankur joined using this group's invite link
Chirag Gandhi Trifecta Capital|2023-04-14 14:36:12|‎Chirag Gandhi Trifecta Capital joined using this group's invite link
~ Madhur|2023-04-14 14:36:18|‎~ Madhur joined using this group's invite link
~ Vinam Suri|2023-04-14 14:37:55|‎~ Vinam Suri joined using this group's invite link
Suhas Motwani|2023-04-14 14:38:05|‎Suhas Motwani joined using this group's invite link
~ Ishan Goenka|2023-04-14 14:38:50|‎~ Ishan Goenka joined using this group's invite link
Vaishak IndiaQuotient|2023-04-14 14:40:55|‎Vaishak IndiaQuotient joined using this group's invite link
Ranjeet Walunj iMayavi|2023-04-14 14:41:36|‎Ranjeet Walunj iMayavi joined using this group's invite link
~ Prateek|2023-04-14 14:41:49|‎~ Prateek joined using this group's invite link
~ Abhilash Inumella|2023-04-14 14:43:03|‎~ Abhilash Inumella joined using this group's invite link
Shobhit Bakliwal|2023-04-14 14:44:10|‎Shobhit Bakliwal joined using this group's invite link
~ Amit|2023-04-14 14:48:42|‎~ Amit joined using this group's invite link
Ishaan Preet Singh Frontrow|2023-04-14 14:51:10|‎Ishaan Preet Singh Frontrow joined using this group's invite link
Anurag Ramdasan|2023-04-14 14:52:10|‎Anurag Ramdasan joined using this group's invite link
~ Ujjwal Trivedi|2023-04-14 14:55:15|‎~ Ujjwal Trivedi joined using this group's invite link
gmisrag Gananth|2023-04-14 15:00:13|‎gmisrag Gananth joined using this group's invite link
~ Yogesh Ghaturle|2023-04-14 15:02:52|‎~ Yogesh Ghaturle joined using this group's invite link
~ pds|2023-04-14 15:03:09|‎~ pds joined using this group's invite link
~ Shyam|2023-04-14 15:04:48|‎~ Shyam joined using this group's invite link
~ Prithvi|2023-04-14 15:09:02|‎~ Prithvi joined using this group's invite link
~ Pranav|2023-04-14 15:20:08|‎~ Pranav joined using this group's invite link
Rahul Gupta|2023-04-14 15:27:35|‎Rahul Gupta joined using this group's invite link
Siddharth Gopi GenerativeAI WhatsApp Group|2023-04-14 15:32:58|‎Siddharth Gopi GenerativeAI WhatsApp Group joined using this group's invite link
~ Ashray Iyengar|2023-04-14 15:37:01|‎~ Ashray Iyengar joined using this group's invite link
Ruchil Sharma|2023-04-14 15:50:12|‎Ruchil Sharma joined using this group's invite link
~ Suchana Seth|2023-04-14 16:26:15|‎~ Suchana Seth joined using this group's invite link
~ Chitrak Gangrade|2023-04-14 17:26:45|‎~ Chitrak Gangrade joined using this group's invite link
~ Samar|2023-04-14 17:31:38|‎~ Samar joined using this group's invite link
~ Ravi|2023-04-14 18:14:17|‎~ Ravi joined using this group's invite link
~ Aaquib Al Hossain|2023-04-14 18:26:17|‎~ Aaquib Al Hossain joined using this group's invite link
Anmol Maini|2023-04-14 18:47:32|‎Anmol Maini joined using this group's invite link ‎[4/14/23, 19:36:26] Rohit Aggarwal: ‎image omitted
~ Umesh Kumar|2023-04-14 19:38:35|‎~ Umesh Kumar joined using this group's invite link
Prayank Swaroop Accel|2023-04-14 19:46:28|Akto.io just launched AktoGPT - https://www.akto.io/blog/aktogpt  Using GPT to secure APIs.
Prayank Swaroop Accel|2023-04-14 19:46:53|@ankush talks about things to watch out for before deploying GPT LLM in production - https://twitter.com/Ankush12389/status/1646779395833741313
~ Jan|2023-04-14 20:07:15|‎~ Jan joined using this group's invite link
Prayank Swaroop Accel|2023-04-14 20:07:49|Folks I'm here as myself not a VC, but yes Akto is funded by Accel India so here is a disclaimer
Ritwik 2013|2023-04-14 20:11:24|https://arxiv.org/abs/2303.01469  Did anyone read through this paper about consistency models? Pretty curious on how autonomous agents would be to interact with other machine interfaces using consistency models for image comprehension.
Rajesh Kumar SA |2023-04-14 20:19:00|‎Rajesh Kumar SA  joined using this group's invite link
Mahesh Suthar|2023-04-14 20:20:44|‎Mahesh Suthar joined using this group's invite link
Lalit Pagaria|2023-04-14 20:24:35|"In the software world, we call it ""avoiding premature optimization"" ‎[4/14/23, 20:27:38] Prayank Swaroop Accel: ‎image omitted"
~ Rahul Rajvanshi|2023-04-14 20:27:53|‎~ Rahul Rajvanshi joined using this group's invite link
Alok Bishoyi|2023-04-14 20:28:22|‎Alok Bishoyi joined using this group's invite link
~ ∆|2023-04-14 20:29:57|‎~ ∆ joined using this group's invite link
Edgar Monis Mumbai WHO|2023-04-14 20:31:05|‎Edgar Monis Mumbai WHO joined using this group's invite link
~ Tirtha|2023-04-14 20:32:49|‎~ Tirtha joined using this group's invite link
~ Aryan Agal|2023-04-14 20:33:36|‎~ Aryan Agal joined using this group's invite link
~ Aryan Agal|2023-04-14 20:34:15|‎~ Aryan Agal left
~ Ved Khandekar|2023-04-14 20:34:42|‎~ Ved Khandekar joined using this group's invite link ‎[4/14/23, 20:37:09] Prayank Swaroop Accel: ‎image omitted
~ Poobesh Gowtham|2023-04-14 20:38:51|‎~ Poobesh Gowtham joined using this group's invite link
jyotirmayjk Hackathon|2023-04-14 20:40:38|Has anyone used LangChain with Azure endpoints instead of OpenAI  directly ?
~ Aman|2023-04-14 20:43:16|https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html
~ Aman|2023-04-14 20:43:23|Tried this?
jyotirmayjk Hackathon|2023-04-14 20:44:18|Yup I’ve tried this  It’s working for simple examples  Im looking to implement agents and not able to find documentation for it
~ Aman|2023-04-14 20:45:04|They have examples for custom LLM agents, not sure if that helps
~ Unmesh Raskar|2023-04-14 20:45:45|‎~ Unmesh Raskar joined using this group's invite link
jyotirmayjk Hackathon|2023-04-14 20:47:08|Using gpt-3.5 response as it is from Azure endpoint response and then customising it for use is a huge headache for me currently 🥲 ‎[4/14/23, 20:48:45] jyotirmayjk Hackathon: ‎image omitted
jyotirmayjk Hackathon|2023-04-14 20:48:59|Prompt was simple “Tell me a joke” nothing more
~ Siddie|2023-04-14 20:51:31|‎~ Siddie joined using this group's invite link
~ Aman|2023-04-14 20:52:44|This has happened before too
~ Rohit|2023-04-14 20:55:41|‎~ Rohit joined using this group's invite link
~ Siddhant Sahay|2023-04-14 21:01:25|‎~ Siddhant Sahay joined using this group's invite link
~ Chinmay Talegaonkar|2023-04-14 21:01:36|‎~ Chinmay Talegaonkar joined using this group's invite link
~ Phoenix Elsa(nutan)|2023-04-14 21:06:24|‎~ Phoenix Elsa(nutan) joined using this group's invite link
Gokul Krishnan|2023-04-14 21:29:01|https://colin-scott.github.io/personal_website/research/interactive_latency.html
Prashant Singh|2023-04-14 21:52:35|wow
Prashant Singh|2023-04-14 21:56:26|latency for 2000 Bytes over commodity network went from 2000NS in year 2009 to 44 NS in 2020 . 😮
~ Sid|2023-04-14 22:05:29|‎~ Sid joined using this group's invite link
Prayank Swaroop Accel|2023-04-14 22:10:15|CTO of Stability AI is talking about Stability diffusion if anyone is interested   https://www.twitch.tv/lablabai
~ Priyadharshini|2023-04-14 22:22:07|‎~ Priyadharshini joined using this group's invite link
Deep Samsung R&D|2023-04-14 22:22:51|ChatGPT for Robotics https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/
Gokul Krishnan|2023-04-14 22:38:08|Fire optics became more widely adopted over this time 😊
Gokul Krishnan|2023-04-14 22:39:24|It's fun to see these numbers and trends as a way to understand industry directions and opportunities.   For examples, iirc, bezos decided to jump into Amazon after seeing the exponential growth of the internet
~ Saumil Agarwal|2023-04-14 22:50:11|‎~ Saumil Agarwal joined using this group's invite link ‎[4/14/23, 23:33:38] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-14 23:39:09|https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing  Here’s a small colab notebook I put together - It searches through a webpage and does Q&A in about 80 lines of code.
Swastik Banerjee|2023-04-14 23:40:48|you have it in your name ‎[4/15/23, 06:14:19] Satish DeepHack Sponsor: ‎image omitted
Ishan Sharma|2023-04-15 06:15:34|Awesome 👏🏽
Sanyam Bhutani|2023-04-15 06:16:51|Enjoy 🫡
Satish DeepHack Sponsor|2023-04-15 06:18:56|on a different note: Are any there any React devs available for a paid weekend project? Appreciate any leads, DM Me.
Kishore GenAI|2023-04-15 09:13:21|Has anyone here been able to get the latest controlnet v1-1 nightly release models working with inpainting? There is one controlnet model which is for inpainting, any inputs on how that would fit with multi controlnet? I got the models working with multi controlnet but have not been able to do so for inpainting yet.
Dev Aggarwal|2023-04-15 09:38:07|https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb  Karpathy strikes again! Using svm for embeddings search
Dev Aggarwal|2023-04-15 09:38:25|Sounds very cool, must put into gooey
Lalit Pagaria|2023-04-15 09:58:41|You may check Haystack. It provides very easy abstraction.  https://haystack.deepset.ai/
Ojasvi Yadav|2023-04-15 09:59:57|Would love to see some comparisons at production level scale  Indexing latency, querying latency etc
Dev Aggarwal|2023-04-15 10:00:39|This was about controlnet inpainting
Dev Aggarwal|2023-04-15 10:01:51|We are not at production level scale yet anways 😅 about 1% of dukaan probably
~ Joy Mehta|2023-04-15 10:02:26|‎~ Joy Mehta joined using this group's invite link
Ambarish Ganguly|2023-04-15 10:17:48|Enterprise Document Search in Azure - MSFT recommends using Azure Cognitive Search with Azure OpenAI . I would be interested to know your thoughts . Azure Cognitive Search may be costly
Bulia Siddharth Aurashop|2023-04-15 10:18:32|‎Bulia Siddharth Aurashop joined using this group's invite link
Ambarish Ganguly|2023-04-15 10:19:04|Another Option is traditional - Upload documents embeddings into a Vector DB and do semantic search
Ambarish Ganguly|2023-04-15 10:19:25|Interested to know from the community of production level deloyments
Kartik Mandaville|2023-04-15 10:20:14|This is what we’re live with.
Ambarish Ganguly|2023-04-15 10:21:17|Thank you [PHONE]  . Size of the DB = ? and your choice of Vector DB = ?
Osborne Saldanha|2023-04-15 10:25:17|‎You added Osborne Saldanha
~ Rohin Siddhartha|2023-04-15 10:25:25|‎~ Rohin Siddhartha joined using this group's invite link
~ Rakesh Pai|2023-04-15 10:26:41|‎~ Rakesh Pai joined using this group's invite link
Shashank Generative AI Group|2023-04-15 10:42:32|twitter discussion for this https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19
Kartik Mandaville|2023-04-15 10:42:55|10681 vectors and pinecone
Ambarish Ganguly|2023-04-15 10:45:25|Thanks so much
~ Venkatesh|2023-04-15 10:46:50|‎~ Venkatesh joined using this group's invite link
~ Eshaan Gulati|2023-04-15 10:55:39|‎~ Eshaan Gulati joined using this group's invite link
Anirudth N|2023-04-15 11:15:49|Wait, but isn't this already known? He's training a classifier on top of embeddings and explicitly labeling for retrieval. This probably requires retraining for every update to the db. Also, if I draw a parallel, this is similar to the old world where they built a cat classifier through KNN first and then iterated to SVM, DNN, CNN, etc for better accuracies.
~ Busy|2023-04-15 11:21:32|‎~ Busy joined using this group's invite link
Anubhav mishra Zupay|2023-04-15 11:22:57|https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman
Nirant|2023-04-15 11:23:02|Yes, works great though when you don't have too many data refreshes/updates.
Soumyadeep Mukherjee|2023-04-15 12:11:51|I have a friend called gpt 4. Fairly reasonably priced. 😋
Rohit Aggarwal|2023-04-15 12:14:57|immediately reminded me of spam detection PoCs :P
Satish DeepHack Sponsor|2023-04-15 15:59:21|True! I recently pushed a project thru the deadline and practically - copilot helped w a good chunk of front end code . GPT for all those complex Cloud formation templates .
Lavish 2017|2023-04-15 16:18:00|has anyone figured good ways to reduce time in getting output from an LLM?  or if you have some ideas, please shoot: I'll try them out and get back on if they work.
Lavish 2017|2023-04-15 16:19:24|also anyone knows if there's a mathematical formula to calculate highlighted words in bionic reading technique?  not able to find it anywhere as of now  wanted to experiment with converting a text to it's bionic reading format and then pass that to LLM as input instead of plain text to save on tokens, increase context and increase speed of reading of output.
~ Avi|2023-04-15 16:22:12|Introduced to this recently for a similar problem statement https://rapidapi.com/bionic-reading-bionic-reading-default/api/bionic-reading1
Lavish 2017|2023-04-15 16:37:16|wow amazing. thanks a lot, been searching for 2-3 days
Shivendu Kumar|2023-04-15 16:38:36|https://twitter.com/pratyush_r8/status/1647104801950552064
Dhruv Anand|2023-04-15 16:47:14|Interesting thought. I always thought bionic reading just highlights the first 2-3 characters of each word.  Wouldn't the algorithm just be to always highlight named entities and never highlight connectors/stowpords? ‎[4/15/23, 16:57:13] Lavish 2017: ‎image omitted
~ Vinam Suri|2023-04-15 17:00:38|‎~ Vinam Suri left
~ Mayank|2023-04-15 17:04:52|‎~ Mayank joined using this group's invite link
~ Mohit Anand|2023-04-15 18:15:42|‎~ Mohit Anand joined using this group's invite link ‎[4/15/23, 18:54:47] Lavish 2017: ‎image omitted
~ A Ram Bharadwaj|2023-04-15 20:20:36|‎~ A Ram Bharadwaj left
Ojasvi Yadav|2023-04-15 21:21:30|I have a question and I think people here would be well suited to answer
Ojasvi Yadav|2023-04-15 21:21:31|If projects like langchain are open-source, then why do they raise money? What are the economics here?
Ojasvi Yadav|2023-04-15 21:21:31|Ideally value proposition is the code. But if it's opensourced then why do people invest in that value proposition?
Ojasvi Yadav|2023-04-15 21:22:24|Fowarded a thread I'm having elsewhere. Let me know if anyone has any understanding about this.
Dev Aggarwal|2023-04-15 21:23:10|Users and distribution. As a man once said, your monetisation techiniques are very different when you have 10K users vs 10M users
Nirant|2023-04-15 21:23:17|Managed Services. Including enterprise. See dbt cloud for reference.
Nirant|2023-04-15 21:25:19|Also people don't like writing code or reading docs. This is also the Fixie thesis
Gokul Krishnan|2023-04-15 21:23:58|OpenSUSE and RedHat open sourced their code. Still profitable by providing training and support
~ Aman|2023-04-15 21:24:11|Don't know about langchain plans apart from the distribution, but generally open-source companies go in the self hosted and Cloud hosted startegies
Dev Aggarwal|2023-04-15 21:24:16|What’s dbt cloud? Heard this from my investors too
Nirant|2023-04-15 21:26:16|That'd be off topic. I love dbt too. Happy to talk more on DM
Nirant|2023-04-15 21:26:52|I'd wager Llama Index should/will raise too if they build a company around it
Kartik Mandaville|2023-04-15 21:30:39|Hosted cloud version - that’s a great value prop Id pay for. Like mongodb
Bharat Kumar Ramesh Hashmal Web3|2023-04-15 21:34:08|It's a fantastic model. A wrapper around Foss. With a lot of successes  1. Confluent on Kafka 2. Vercel with Nextjs 3. Clickhouse 4. Supabase with postgres+
Bharat Kumar Ramesh Hashmal Web3|2023-04-15 21:34:48|Cal.com has turned that into a pretty decent content model as well
Ojasvi Yadav|2023-04-15 21:37:30|Like elasticsearch went into AWS?
Ojasvi Yadav|2023-04-15 21:38:06|Anyone here who has invested in such a business model before?
~ Aman|2023-04-15 21:41:33|Won't compare to AWS services, but more like mongodb, appsmith, vercel etc.
~ Aman|2023-04-15 21:42:39|Where you get hooked to the service by first using it on your instances, but as team/complexity grows, you prefer to just use their hosted offerings
Nirant|2023-04-15 21:44:24|Vercel and NextJS is a great example
Ojasvi Yadav|2023-04-15 21:46:03|Gotcha
Ojasvi Yadav|2023-04-15 21:46:10|Makes sense
~ Aman|2023-04-15 21:47:34|Yeah, and when you try using NextJS on AWS amplify, it had terrible build times (as per my last experience). We had no choice, but to use the Vercel hosting
~ Eshaan Gulati|2023-04-15 22:14:08|Is anyone familiar with AI for crime detection (loud noises etc)
Lalit Pagaria|2023-04-15 22:29:50|Redhat $1B Hashicorp $0.5B ARR Both are open source companies  https://twitter.com/adamhjk/status/1618795275665162247
Manjot Pahwa|2023-04-15 22:30:17|https://twitter.com/anoushkavaswani/status/1646976994637406211?t=qixyvkorGoWv78hRdUJPaQ&s=19 🤯 New use cases
~ Haider Ali Khan|2023-04-15 22:39:32|https://www.linkedin.com/feed/update/urn:li:activity:7053046289256632320  We are live with our Talk with Kundan Kumar Descript  Welcoming you all for this insightful conversation 🙏🙏🙏
~ Haider Ali Khan|2023-04-15 22:39:43|https://twitter.com/foyerwork/status/1647282584907579393?s=20 ‎[4/15/23, 22:43:02] Dev Aggarwal: ‎image omitted
Anirudth N|2023-04-15 23:03:16|AWS has released their GitHub Copilot knockoff for free. It seems reasonably good although I don't have a direct comparison with Copilot. https://aws.amazon.com/codewhisperer/
Pratyush Choudhury|2023-04-15 23:09:38|https://aws.amazon.com/blogs/machine-learning/how-accenture-is-using-amazon-codewhisperer-to-improve-developer-productivity/
Pratyush Choudhury|2023-04-15 23:13:54|https://blog.lucas-simon.com/amazon-codewhisperer-vs-github-copilot#heading-final-thoughts  Actually, a good comparison
jyotirmayjk Hackathon|2023-04-16 09:06:39|Any sci-fi enthusiasts here ? 😃  Has anyone read “The Last Question” by Isaac Asimov?
Rahul Rai|2023-04-16 09:07:27|Yeah it’s great
Rahul Rai|2023-04-16 09:07:44|This is even better - it’s also very timely because of AI
Rahul Rai|2023-04-16 09:07:46|https://www.gregegan.net/MISC/CRYSTAL/Crystal.html
jyotirmayjk Hackathon|2023-04-16 09:08:03|Doesn’t the Multivac sound eerily similar to today’s LLMs /Auto-GPT ?
jyotirmayjk Hackathon|2023-04-16 09:09:02|You ask a question ,it finds answers  Or you set an objective it goes about fulfilling it
Rahul Rai|2023-04-16 09:09:47|Yeah lol, Asimov basically predicted AGI
Rahul Rai|2023-04-16 09:10:22|I guess Turing had already predicted it before him though
jyotirmayjk Hackathon|2023-04-16 09:11:42|Asimov did do that in many stories ,I’ve read basically all of his books   What’s remarkable is not prediction of AGI  It’s how the Multivac being used is very similar to how we are using ChatGPT
Rahul Rai|2023-04-16 09:12:17|Yeah agreed!
Anudeep Yegireddi|2023-04-16 09:12:52|The interface is similar, but I think the big difference is that LLMs are conceptually structured, but untethered from reality. That I think is the big difference between multivac and LLMs
Anudeep Yegireddi|2023-04-16 09:13:42|Like it understands conceptually that colors should cluster together, but doesn’t really understand a color
Anudeep Yegireddi|2023-04-16 09:13:56|Multimodality will help a lot with that
jyotirmayjk Hackathon|2023-04-16 09:14:57|On the color front I just happened to come across this paper :)   https://arxiv.org/abs/2109.06129
jyotirmayjk Hackathon|2023-04-16 09:15:25|Agreed they are largely conceptually structured
Anudeep Yegireddi|2023-04-16 09:15:53|Great share thanks 🙏🏽
Anudeep Yegireddi|2023-04-16 09:16:50|Like in the “last question” the question asked over eons is can entropy be reversed. The fact that it took sooo long to answer because it is such a difficult question based on its understanding of reality was amazing
Anudeep Yegireddi|2023-04-16 09:17:45|But thank you for bringing up Asimov’s work, that man was my first brush with sci-fi and a genius
jyotirmayjk Hackathon|2023-04-16 09:18:31|It kept updating its understanding of reality   And one huge step which might seem trivial was interfacing of such AIs with real world  The way we are building agents/tools with LLMs now,I think the day is not far off where we design interfaces for AIs to interact in real world
jyotirmayjk Hackathon|2023-04-16 09:19:14|Glad to meet a fellow Asimov fan!  I was also introduced to sci-fi thorough the works of Asimov 🙌🏻
Rahul Rai|2023-04-16 09:20:19|Cixin Liu is my all time favorite
Nirant|2023-04-16 09:51:46|Draft Community Guidelines for this WA group. Will hopefully make it easier for you to decide for yourself what is off topic 🥲  Suggestions, rebuttals most welcome on that PR!  https://github.com/NirantK/nirantk.github.io/pull/7 ‎[4/16/23, 09:52:36] Nirant: ‎image omitted
Deep Samsung R&D|2023-04-16 09:59:00|Very cool, curious was it generated using AutoGPT, it seems to have 1 numbering only but also working links.
Ojasvi Yadav|2023-04-16 10:00:06|Get yourself an admin that defines community guidelines in git 🫂 ‎[4/16/23, 10:05:31] Nirant: ‎image omitted
~ Nirmal|2023-04-16 10:17:07|off-topic - orion's arm is a cool website for sci-fi enthusiasts.
Alok Bishoyi|2023-04-16 10:26:37|Sci-fi thats relevant to this group  https://qntm.org/mmacevedo
~ Kruti|2023-04-16 10:32:49|‎~ Kruti joined using this group's invite link
~ Kalai|2023-04-16 10:34:46|‎~ Kalai joined using this group's invite link
Harsh Koo|2023-04-16 10:54:31|Huge fan here. Probably read Asimov, Clark and Heinlein all through college and masters. Kept me sane and got me excited about the future.   And feel even more privileged to be working in tech/ai and seeing a lot of parallels.  Btw, a lot of Clarks stories paved the way for real science like Geo-synchronous satellites.  Eternals from Asimov is a great book if anyone wants to spend their Sunday reading
Ojasvi Yadav|2023-04-16 10:56:41|Does anyone have a link to that service which let's you use chatGPT interface built on top of the API? Just using your API key?
Ojasvi Yadav|2023-04-16 10:56:53|I figured that's cheaper than buying chatGPT plus
Deep Samsung R&D|2023-04-16 10:57:21|https://www.chatbotui.com/
Ojasvi Yadav|2023-04-16 10:57:32|And also, how is the context window handling of such services? Surely they'll lose the memory ability once the past chats get out of the max token limit?
Deep Samsung R&D|2023-04-16 10:57:43|Is this the one you are looking for?
Ojasvi Yadav|2023-04-16 10:58:14|Seems so
Ojasvi Yadav|2023-04-16 10:58:17|Thank you
Rohit Aggarwal|2023-04-16 11:00:59|I mostly use plus because it lets me use GPT-4 with large context windows and that turns out to be cost efficient. Do consider that.
Deep Samsung R&D|2023-04-16 11:01:14|Can anyone share some guidance on how many documents would be required for fine-tuning, ballpark could be fine? Some fine-tuning resources would also be great!
Swastik Banerjee|2023-04-16 11:03:02|https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
Deep Samsung R&D|2023-04-16 11:34:23|Thanks for sharing, was actually looking specifically for ways to fine-tune model with custom data than In-context learning. Any inputs on rough data size required for it could be helpful.
~ mouryA|2023-04-16 11:38:41|I love sci-fi,  This maybe not in the similar line but there's Ray Bradbury's The Illustrated Man which is quite intriguing.
jyotirmayjk Hackathon|2023-04-16 11:41:28|+1  Even I’d like to know this  Only thing I’ve read on are InstructGPT with 13k QnA pairs and Dolly LLM with 15k QnA pairs  How is domain specific tuning achieved ?
jyotirmayjk Hackathon|2023-04-16 11:41:47|https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html
jyotirmayjk Hackathon|2023-04-16 11:42:00|https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
jyotirmayjk Hackathon|2023-04-16 11:42:45|These are articles by Databrick on how they’ve tuned the open source Dolly LLM for reference if anyone is interested   Might need more deeper expertise to understand how to train on custom data domains
Ambarish Ganguly|2023-04-16 11:56:01|I am trying to use sentence transformers and OpenAI combined and making a Docker Image. Obviously the image is quite big [ > 4 GB ] , did anybody try deploying this type of thing to Kubernetes / AKS / EKS ?
Ambarish Ganguly|2023-04-16 11:56:40|Doing it in a VM is ok and works fine. Interested to know the community viewpoints
Aditya Agrawal SuperU|2023-04-16 11:59:04|Anyone who has performed Model Distillation?
Diptanu Choudhury FB AI|2023-04-16 12:03:28|I am curious - what’s your use case?  Use different models based on inference request parameters/tasks?
Ambarish Ganguly|2023-04-16 12:04:31|Standard ones [ Q&A , Chatbot]. The reason I am using Sentence Transformers instead of OpenAI embeddings to save cost
Diptanu Choudhury FB AI|2023-04-16 12:06:37|Oh I see, so using embeddings from ST to do information retrieval and then add the context into OpenAI prompt?
Ambarish Ganguly|2023-04-16 12:06:49|Correct
Ambarish Ganguly|2023-04-16 12:07:43|OpenAI embeddings are good but they would charge. Hence alternative ST , but con is image is huge
Ambarish Ganguly|2023-04-16 12:08:23|In the VM it works fine but when containerize ing it is becoming huge [ which is obvious ]
Diptanu Choudhury FB AI|2023-04-16 12:10:42|May be deploying the model separately behind a service endpoint could be a way to go. That way you wont have to distribute the model in the application containers.
Ambarish Ganguly|2023-04-16 12:13:14|Yes that's correct ; but the model itself is huge [ ST with all its fanfare Torch and … ] ; Are you suggesting deploying the Model in a VM and exposing as a service ?
Diptanu Choudhury FB AI|2023-04-16 12:13:36|Yeah
Ambarish Ganguly|2023-04-16 12:14:35|Thank you for your views
Ambarish Ganguly|2023-04-16 12:16:04|I am just wondering how the community is thinking about using OpenAI for everything [ Embeddings and Chat Completion ]. My views are Embeddings can be done using ST and Hugging Face and reduce cost
Diptanu Choudhury FB AI|2023-04-16 12:17:04|I agree.
Rohit Aggarwal|2023-04-16 12:31:03|Have seen it start to work with 200 odd examples. OpenAI suggest 1000+ for accuracy.   I think the dolly training is different than fine-tuning. But not sure
Dhruv Anand|2023-04-16 12:32:33|Sorry I'm not sure i understand. Do you mean the image is large because of storing the vectors?
Rohit Aggarwal|2023-04-16 12:33:00|Different than the OpenAI fine-tuning*
Ambarish Ganguly|2023-04-16 12:33:39|I am using Sentence Transformers for Word Embedding. The ST has dependencies on Torch and NVIDIA libraries , hence the image is large
Ambarish Ganguly|2023-04-16 12:34:42|Your standard flow is Embeddings + Chat Completion [ Very Himalaya level flow ] . For Embeddings to minimize cost using ST
Ambarish Ganguly|2023-04-16 12:35:13|and Context / Chat Completion using OpenAI / Azure OpenAI
Dr. Pratik Desai KissanGPT|2023-04-16 12:36:11|It’s not recommended to use fine tuning where you can get away with embeddings.
~ Aman|2023-04-16 12:36:45|How many GBs are we talking about?
Ambarish Ganguly|2023-04-16 12:37:02|> 5GB
Ambarish Ganguly|2023-04-16 12:37:52|One solution from one helpful community member is to convert ST into ONNX format
Ambarish Ganguly|2023-04-16 12:37:59|and this would reduce the size
Ambarish Ganguly|2023-04-16 12:38:39|Any other solutions / viewpoints would be highly appreciated . even the approach is wrong with reason would also be highly appreciated
Ambarish Ganguly|2023-04-16 12:39:53|I love this community . So very quick and helpful members
Swastik Banerjee|2023-04-16 12:42:04|wait, I thought finetuning means providing extra/specific information to the model which it already doesn’t know. And, generating embeddings using relevant documents is a part of the process. Am I fundamentally wrong? ‎[4/16/23, 12:42:37] Prayank Swaroop Accel: ‎image omitted
~ Aman|2023-04-16 12:43:53|https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images  There is one answer here related to cuda, but I'm sure you have already done this
Sanyam Bhutani|2023-04-16 12:45:31|Harrison is really open about their strategy and sharing the plans.   In the last webinar he mentioned they’re just focusing on open source rn
Ambarish Ganguly|2023-04-16 12:49:34|https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696
Ambarish Ganguly|2023-04-16 12:50:24|Nice article to convert ST into ONNX format ‎[4/16/23, 13:24:39] jyotirmayjk Hackathon: ‎image omitted
Ambarish Ganguly|2023-04-16 13:29:22|Haha
Nirant|2023-04-16 13:43:05|This is quite neat. I missed pinned messages for this!
Diptanu Choudhury FB AI|2023-04-16 13:44:53|Fine tuning adjusts the weights of a model, with more training samples. Embedding are usually used for similarity search(among other things).
Swastik Banerjee|2023-04-16 13:47:17|calculating embeddings is a part of adding “more training samples”, right? Or not necessarily…?
Diptanu Choudhury FB AI|2023-04-16 13:48:05|These things are orthogonal to each other.
Diptanu Choudhury FB AI|2023-04-16 13:51:08|Are you talking about fine tuning the embedding model or something?
Diptanu Choudhury FB AI|2023-04-16 13:51:35|These things are nuanced based on the context :)
Swastik Banerjee|2023-04-16 13:54:51|ah
Ojasvi Yadav|2023-04-16 13:54:52|"Think of it this way  Fine-tuning is changing the model itself to better represent your target datasets input->output mapping.  Embeddings and similarity search does not change the model. Model's ""intelligence"" remains the same. All it does is use that intelligence to differentiate the topics you care about (that is, the text whose embeddings you index)"
~ Priyadharshini|2023-04-16 13:54:55|You can say embeddings is an LLM's mother tongue. It understands text by converting in into an embedding to understand the meaning and relation between words. Finetuning is giving the llm lot's of examples to learn a particular new skill or subject
Ojasvi Yadav|2023-04-16 13:58:24|"I used ""differentiate"" in a explanatory flavour  99% of the times embeddings search is used to look for similarity in the text you care about  The accuracy with which your similarity search will work depends entirely on the model's ""intelligence"". The more weights and the more variance there is in the model's dataset, the better it's embeddings will work for similarity search."
Shubham Sharma 2012C6|2023-04-16 13:58:27|https://twitter.com/tree_industries/status/1647416130753945601?s=46
Ojasvi Yadav|2023-04-16 13:58:46|I imagine gpt3.5 and gpt4 embeddings will be much better for similarity search
Ojasvi Yadav|2023-04-16 13:59:37|Anyway gpt3 embeddings are 1536 in length 3.5 and 4 should be even higher if they are bottlenecked by the 1536 degrees of freedom
Swastik Banerjee|2023-04-16 14:00:53|I see….
Swastik Banerjee|2023-04-16 14:03:45|just trying to understand, so if this “intelligence” depends on the models’ weights, variance, etc which is obviously the case (basically upgrading from gpt3 to gpt4), there are ways to finetune, i.e., add more weights, etc. ourselves also? instead of waiting for a new release like gpt5?
Swastik Banerjee|2023-04-16 14:05:22|I so long thought finetuning just means giving it more documents (storing the embeddings in a db)… i didn’t know there are ways to make the model smarter without burning huge computation powers
~ Priyadharshini|2023-04-16 14:07:16|Check this out https://huggingface.co/spaces/microsoft/HuggingGPT
jyotirmayjk Hackathon|2023-04-16 14:10:23|Hmm ,think of embeddings as transformations (At very high level)  When you create an embedding you transform something which was represented in letters to be represented in numbers This is usually called text embedding  When you do a QnA over embeddings it’s not making the model smarter  You convert that query to a number And then use similarity search to find another number just like it  What you see in QnA bots is one more step After finding the similar number you put it into prompt and then ask it to synthesize it into a user friendly format   What each model does in embedding is to represent a meaning to more accurate degree in form of numbers .GpT embeddings could be better than GPT-3 for this
Swastik Banerjee|2023-04-16 14:11:26|ya I understood that…
jyotirmayjk Hackathon|2023-04-16 14:11:27|When you fine tune a model It actually updates the weights From what I have understood  You can ask a question directly to the model after training and it will be able to answer Usually called zero shot prompting   Fine tuning improved zero shot prompting over any domain you train it on
Swastik Banerjee|2023-04-16 14:12:22|what is the “process” of ‘finetuning’ then if not generating and storing embeddings?
Swastik Banerjee|2023-04-16 14:12:34|Providing it with prompts?
Swastik Banerjee|2023-04-16 14:12:52|to use those embeddings more smartly?
Dr. Pratik Desai KissanGPT|2023-04-16 14:12:53|larger dof is not good for longer run, latency wise, too.
Sumod K Mohan|2023-04-16 14:13:00|Calling the api and updating the weights for your use cases.
Sumod K Mohan|2023-04-16 14:13:21|Weights being updated with example data
Swastik Banerjee|2023-04-16 14:14:13|Can I get a more comprehensive guide on how to ‘update these weights’ please? it’d be very helpful…. thank you very much
Sumod K Mohan|2023-04-16 14:15:13|https://platform.openai.com/docs/guides/fine-tuning
jyotirmayjk Hackathon|2023-04-16 14:15:19|Providing with example date like rightly said   I’ve read on chat-gpt like models They have been trained on pairs of questions and answers   Embeddings are not stored in the model ,models are only used to create embeddings.
Sumod K Mohan|2023-04-16 14:16:17|There was recent tweet from someone about comparing fine-tuning and prompting. Will see if I can find it. That had some details of effects of fine tuning and what prompting can deliver.
Sumod K Mohan|2023-04-16 14:16:36|Tweet about a paper
~ Priyadharshini|2023-04-16 14:19:13|Make sure if finetuning is really necessary for your usecase (computational costs involved) or if you can simply  use a external vector database like pinecone or weaviate instead.
Swastik Banerjee|2023-04-16 14:24:08|I had read a little bit of this when I was initially exploring, but never tried myself: ```question and answer pairs to additionally create adversarial questions and context pairs``` https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb
Shubham Sharma 2012C6|2023-04-16 14:52:36|What do you people think of this?
Harsh Koo|2023-04-16 14:59:25|"This is interesting but needs more finesse.   Like give more details about the family, names that are popular, what are some personality traits that go with names in popular culture.  Baby names typically have conversations with so many ""stakeholders"" as part of the process of discovering, filtering and fine-tuning.  GPT can make this process accessible to more, elevate the level of intelligence perhaps of such conversations and also showcase more avenues that for that user was previously unknown."
~ Harsha.B|2023-04-16 15:00:19|"Hey, not sure if this was asked here before, but how do we determine a good chunk size to use while converting a huge text dump + documents into embeddings. From what I understand a smaller chunk size make the extractions more ""precise"" while doing emb search but at the cost of much more computations wheras it's the opposite with large chunk size and also with larger chunk sizes we can't keep too many of the chunks in the final LLM prompt for answering the question. Any other ways of looking at this?"
~ Priyadharshini|2023-04-16 15:02:38|I think langchain's conversation memory types can be combined to optimise for your chunks
~ Priyadharshini|2023-04-16 15:03:44|https://python.langchain.com/en/latest/modules/memory/how_to_guides.html
~ ayush saraswat|2023-04-16 15:08:30|‎~ ayush saraswat joined using this group's invite link
~ Pratyush Rai (Foyer)|2023-04-16 15:58:22|‎~ Pratyush Rai (Foyer) joined using this group's invite link
Anubhav mishra Zupay|2023-04-16 16:15:50|https://trib.al/HIuiF1K
~ Pradyumna Bang|2023-04-16 16:17:05|Is it possible for a specialized piece of hardware (ASICs or FPGAs) to speed up the embedding search ?
Shan|2023-04-16 16:22:27|‎Shan joined using this group's invite link
Shivendu Kumar|2023-04-16 17:26:14|Hey [PHONE] can we summarize the things going on here with GPT. It's getting really hard and time consuming to catch up with 50+ messages on WA. As more people are joining, the number of messages here is just exploding 😅
~ Nijil Y|2023-04-16 17:31:43|‎~ Nijil Y joined using this group's invite link
Ojasvi Yadav|2023-04-16 17:44:10|This guy is literally raising funds via his github repository
Ojasvi Yadav|2023-04-16 17:44:11|https://github.com/jdagdelen/hyperDB
Ojasvi Yadav|2023-04-16 17:44:24|someone said langchain will probably integrate this by end of the day
Ojasvi Yadav|2023-04-16 17:45:13|it's a joke apparently
~ Srijan Shukla|2023-04-16 17:45:50|yea it opens up that nyan cat youtube video 😄 ‎[4/16/23, 17:45:59] Ojasvi Yadav: ‎image omitted ‎[4/16/23, 17:48:11] Dhruv Naik: ‎image omitted
~ Srinath Nair|2023-04-16 17:48:38|‎~ Srinath Nair joined using this group's invite link
~ Deeksha💁‍♀️|2023-04-16 18:19:55|‎~ Deeksha💁‍♀️ joined using this group's invite link
Bulia Siddharth Aurashop|2023-04-16 19:04:05|"I tried asking GPT for this. This is what it responded with.  Summary: Links/Websites Discussed:  Twitter discussion: https://twitter.com/karpathy/status/1647025230546886658?t=zQ2IYIjiKMNc0mUHUdqlBw&s=19 The Verge article on GPT-5 rumors: https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman Bionic Reading API: https://rapidapi.com/bionic-reading-bionic-reading-default/api/bionic-reading1 GitHub Copilot knockoff for free by AWS: https://aws.amazon.com/codewhisperer/ Community Guidelines for WA group: https://github.com/NirantK/nirantk.github.io/pull/7 ChatGPT UI for API: https://www.chatbotui.com/ Fine-tuning large language models: https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html Databrick's Dolly LLM: https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm Sci-fi story ""The Last Question"" by Isaac Asimov: https://www.gregegan.net/MISC/CRYSTAL/Crystal.html Paper on understanding color: https://arxiv.org/abs/2109.06129 Open-source project: https://qntm.org/mmacevedo Sci-fi story ""The Illustrated Man"" by Ray Bradbury Question_answering_using_embeddings notebook: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb Article on decreasing Docker image size: https://stackoverflow.com/questions/63521958/is-this-a-right-way-to-descrease-size-of-my-docker-images Article on PyTorch ONNX Sentence Transformer Optimization: https://medium.com/@TheHaseebHassan/pytorch-onnx-sentence-transformer-optimization-e24bdbed9696 Topics Discussed:  Generative AI community Vector DB and semantic search Production-level deployments Fine-tuning and in-context learning GPT-5 rumors Bionic reading technique Open-source projects and their economics AI for crime detection Model distillation Sci-fi stories and their relevance to AI Fine-tuning large language models Sentence Transformers and OpenAI Deploying large models to Kubernetes ChatGPT API usage and context window handling Using embeddings for cost reduction Converting Sentence Transformers to ONNX format"
Bulia Siddharth Aurashop|2023-04-16 19:05:27|A smart summariser Bot for WhatsApp groups will be really helpful.  If anyone is enthu to build something, loop me in!
~ Soham|2023-04-16 19:27:44|‎~ Soham joined using this group's invite link
Shashank Generative AI Group|2023-04-16 19:32:33|im very inspired by this. gonna launch my own database next week. have a killer name in mind.
Shashank Generative AI Group|2023-04-16 20:42:11|post by Vespa founder https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
~ Anubhav Tiwari (Vicky)|2023-04-16 21:04:17|‎~ Anubhav Tiwari (Vicky) joined using this group's invite link
Deep Samsung R&D|2023-04-16 22:18:29|IPython ChatGPT extension https://github.com/santiagobasulto/ipython-gpt
Nirant|2023-04-16 22:20:34|Neat, this can work with Google Colab in theory too ‎[4/16/23, 22:35:11] Rohit Ganapathy: ‎image omitted
Rohit Ganapathy|2023-04-16 22:36:37|or is it just ranking them and using the closest match to the input
Ojasvi Yadav|2023-04-16 22:37:17|Good questions
Ojasvi Yadav|2023-04-16 22:37:37|Would love to hear what people have to say
Ojasvi Yadav|2023-04-16 22:38:43|Auto GPT does have an intermediate summary phase where it tries to break the webpage down to 8192 token chunks  Summarises each chunk  And then summarises the summaries of the chunks obtained in the step above
Ojasvi Yadav|2023-04-16 22:40:18|Not sure whqts happening in here though Can't imagine it to be wildly different from autoGPT approach
Rohit Ganapathy|2023-04-16 22:41:18|makes sense..
Ojasvi Yadav|2023-04-16 22:42:04|Anyone here who has worked extensively with these agents?
Nirant|2023-04-16 22:42:04|There are few different things:  1. The OpenAI Plugin does NOT do summarisation. It simply does a search and select. This is similar to their Retrieval Plugin in that way. The _context_ window limits do not apply in the same way there because OpenAI has confirmed that these are smaller, lightly finetuned models for specific tasks. E.g. is it possible they can parse HTML in a 32K GPT4 model and use it? Yes.  2. AutoGPT or most GPT4 products use the map-reduce/combine approach from Langchain, which [PHONE] described
Nirant|2023-04-16 22:42:31|[PHONE] uses them almost daily to run his company and cribs about how broken they are
Lalit Pagaria|2023-04-16 22:57:12|If you do not like to use LLM for HTML parsing then this tool I found does a great job. But use it at arm distances because it is GPL3 licensed.  https://trafilatura.readthedocs.io/en/latest/
Lavish 2017|2023-04-16 23:12:31|not extensively yet but have the same experience.  since for now my workflow to be executed was limited on a theme level so I went ahead with a classifier to detect task, and then LLM to extract details of the task to be done and do the tasks in code and output by LLM again.  custom and less useful agent but doesn't break on prod
Lavish 2017|2023-04-16 23:16:56|for now my plan is also to keep adding new tasks in classifier and seperating their workflow standalone  previously tried with the agent too but things were happening randomly most of the times and without any control.  I'm yet to go through the new blog that Chip has posted but it might have good nuggets - if anyone has already went through, feel free to DM me if something better is already possible
Rohit GenerativeAI WhatsApp Group|2023-04-16 23:36:53|There are strategies in langchain for this.. map_reduce, refine, ...
Ojasvi Yadav|2023-04-16 23:38:57|Will read up on it. What's the umbrella term langchain uses for these?
Rohit GenerativeAI WhatsApp Group|2023-04-16 23:40:31|https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html
~ Priyadharshini|2023-04-16 23:40:35|memory chains or conversation memory
Rohit GenerativeAI WhatsApp Group|2023-04-16 23:40:58|those are different I think
Ojasvi Yadav|2023-04-16 23:41:46|Summarisation sounds about right
Ojasvi Yadav|2023-04-16 23:42:12|Memory is retrieval Summarisation is computational
~ Priyadharshini|2023-04-16 23:42:31|Sorry. You are right. It's summarization
Shashank Generative AI Group|2023-04-17 00:22:07|"btw folks langchain discord has a ""ask-kapa-langchain"" channel for asking doubts. very useful bot while building with langchain. it's based on the langchain docs, codebase."
Deep Samsung R&D|2023-04-17 00:24:16|they also have integrated https://www.mendable.ai/ into their documentation, works like a bot, could be similar. Does the bot also allows to ask query on discord chat?
Shashank Generative AI Group|2023-04-17 00:28:18|yeah. the kapa langchain bot is discord based. when you ask a question, it generates the answer in a thread
Mahesh Suthar|2023-04-17 00:28:26|https://www.paradox.ai/solutions/recruiters  Pretty useful for recruiters. We spend a lot of time filtering & scheduling :-/
jyotirmayjk Hackathon|2023-04-17 00:30:03|Does this also have automated screening of resumes?
Mahesh Suthar|2023-04-17 00:32:11|https://www.skillate.com/  this one claims to do automated screening
Mahesh Suthar|2023-04-17 00:34:50|https://leoforce.com/  and this for automated sourcing. something like this focussed on tech hiring would be huge.  Companies pay $50k-100k for manual sourcing tools like Gem crm
jyotirmayjk Hackathon|2023-04-17 00:38:40|Gottit ,I was planning on building an automated screening in my company   Goal was to use semantic search driven similarity results  Ethically it struck me as very wrong,this process would end up in adversarial selection 😅  Only people savvy enough to manipulate resumes to match job requirements would be screened as a result who might or might not be the candidates we want  And some genuine candidates could be left out
jyotirmayjk Hackathon|2023-04-17 00:39:01|How do you solve for this issue if automated screening is used?
jyotirmayjk Hackathon|2023-04-17 00:39:50|I abandoned working on the prototype all together because of these issues 🥲
Ojasvi Yadav|2023-04-17 00:44:53|Sounds a lot like the SEO - google war
Ojasvi Yadav|2023-04-17 00:44:58|It's perennial
Ojasvi Yadav|2023-04-17 00:45:14|One party is trying to deliver the best results to its usere
Ojasvi Yadav|2023-04-17 00:45:30|The other party is trying to hack around that delivery logic
jyotirmayjk Hackathon|2023-04-17 00:45:42|True. The other side of this spectrum is someone building a resume builder to job candidates so that the resume is maximally similar to JD
jyotirmayjk Hackathon|2023-04-17 00:45:58|Never ending arms race
Ojasvi Yadav|2023-04-17 00:46:51|Yes, it's unethical. But if you won't use it, someone else probably will
Lavish 2017|2023-04-17 00:48:09|"even today, recruiters don't do the first touch on resumes in big corps.  there are always softwares altho at keyword match capability probably and people already hack it by adding ""java spring"" in white font so it's not visible to naked eye"
jyotirmayjk Hackathon|2023-04-17 00:48:10|Then the other side will start too :) Semantic Resume Builder Do a semantic search over target JDs Take inputs from user on experience Generate resume which would be most similar to Job requirements
Yash Pandya|2023-04-17 00:48:42|There is also the matter of possible bias which the AI solutions might have. Which is difficult to solve for and a very sensitive issue.
Ojasvi Yadav|2023-04-17 00:51:49|And then use chat GPT during the interview
Ojasvi Yadav|2023-04-17 00:51:51|Boom
jyotirmayjk Hackathon|2023-04-17 00:52:32|Slightly off track but it reminds me of this dialogue from Batman Begins :)  Jim Gordon : What about escalation? Batman : Escalation? Jim Gordon : We start carrying semi-automatics, they buy automatics. We start wearing Kevlar, they buy armor piercing rounds.
jyotirmayjk Hackathon|2023-04-17 00:53:42|I’m seeing many companies ask candidates to come in person to the office for interviews for this very reason 😂 ‎[4/17/23, 01:11:40] Swastik Banerjee: ‎image omitted
Swastik Banerjee|2023-04-17 01:13:39|The _“actions”_ settings say it can retrieve upto 500 rows, but I’ve only been able to reach that limit for small, tokenised, chunked datas in each row ‎[4/17/23, 01:46:01] Kaushik Bokka: ‎image omitted
Lavish 2017|2023-04-17 01:57:45|anyone here who can share some basic dope on how some people are creating realistic music with AI?
Yash Pandya|2023-04-17 02:01:48|Check:  https://google-research.github.io/seanet/musiclm/examples/  https://github.com/riffusion/riffusion
Lavish 2017|2023-04-17 02:17:03|thanks ✅  I run riffusion everyday while coding, didn't check they had a paper too 😅
Lavish 2017|2023-04-17 02:19:38|so there's no elevenlabs like product yet - right?  where you plugin sample voice, and prompt to generate some music? surprised if not.
Dev Aggarwal|2023-04-17 04:46:39|https://gooey.ai/text2audio/
Prayank Swaroop Accel|2023-04-17 07:58:19|Folks .. this is an amazing lecture on the question whether GPT4 is really AGI ? I highly recommend watching it.  https://www.youtube.com/watch?v=qbIk7-JPB2c  The speaker is Senior Principal Research Manager at Microsoft Research and and ex-assistant professor at Princeon.  http://sbubeck.com/
Ravi Theja|2023-04-17 08:17:28|Summary of this in a thread here - https://twitter.com/psurya1994/status/1647628166792372224?s=20
Nirant|2023-04-17 08:56:39|Sharing the original paper here as well for completeness. The talk, thread are based off this and paper has some amazing examples https://arxiv.org/abs/2303.12712
Nirant|2023-04-17 09:37:10|If you'd like to present a paper summary e.g. Reflexion, Sparks of AGI, Amazon's MM-CoT at the meetup this Saturday, happy to help you outline and prepare. Please DM me soon!
Nirant|2023-04-17 09:37:27|BLR Generative April meetup:  https://hasgeek.com/generativeAI/april-meetup/
~ Ravi|2023-04-17 10:01:35|‎~ Ravi joined using this group's invite link
Sumod K Mohan|2023-04-17 10:08:50|Here is one about review of fine tuning techniques  https://arxiv.org/abs/2303.15647 . There is one more, will see if I can find it which spoke more specifically prompting vs fine-tuning.
Nirant|2023-04-17 10:09:42|Are we also calling model distillation as fine-tuning now? I see them both being used interchangeably on interwebs
Manjot Pahwa|2023-04-17 10:17:49|Hey folks! I normally don't post things like this, but thought this would be relevant here. We're hosting Benn Stancil, co-founder of Mode, he's one of my favourite bloggers (if you've read his work, you would know what I mean), the idea is to generally chat about the BI and how generative AI will be vastly disruptive for the whole BI layer. You can sign if you're interested here: https://bit.ly/lsip-dataverse-ep4  On another note, would love to hear the group's thoughts on how they see the BI layer being affected?
Amritanshu Simplismart|2023-04-17 10:31:47|‎Amritanshu Simplismart joined using this group's invite link
~ Aman|2023-04-17 10:52:25|https://www.indiatoday.in/technology/news/story/chatgpt-fails-jee-advanced-manages-to-solve-only-11-questions-in-both-papers-2358952-2023-04-12  Anyone aware of this, whether they used GPT4?
jyotirmayjk Hackathon|2023-04-17 10:57:15|This seems to be GPT-3.5
jyotirmayjk Hackathon|2023-04-17 10:57:44|Someone tested using GPT-4 and they reported 21/108 questions being solved by GPT-4   https://twitter.com/amuseddaman/status/1647367373354328065?s=46&t=icC0fizZK8E3ONsDVuGFWA
jyotirmayjk Hackathon|2023-04-17 10:59:56|Also IMO these tests are very misleading ,it’s performance on zero shot prompting of JEE questions would obviously be poor    Like someone else had pointed out  let GPT-4 have access to Wolfram plugin and/or fine tune on corpus of 30 yrs JEE questions ,it could score decent enough
Amir Nagri|2023-04-17 11:00:17|Present LLMs fake understanding  So if you don't train it sufficiently on data you are testing it on, it is going to fail  We can fine tune a model that is good at solving jee problems, but might fail on other simpler tasks
~ Harsha.B|2023-04-17 11:00:24|Plus we don’t really know what prompting strategy they have used, they might have simply kept the question and asked for the answer. Having a simple CoT based promoting strategy will probably lead to much better scores
~ Ameya|2023-04-17 11:00:39|Isn't having access to a Wolfram plugin basically cheating?
~ Nijil Y|2023-04-17 11:01:14|It is sort of consistent with the fact that it cannot do complex math. For now. Physics and chemistry it can reproduce well with decent reasoning
jyotirmayjk Hackathon|2023-04-17 11:01:52|I’m 100% sure the ones reporting failure of GPT on JEE would be copy pasting questions in ChatGPT
~ Nijil Y|2023-04-17 11:02:31|"""Significant gains are visible in the accuracy of the GPT4 model, in decreasing order of Chemistry(✨36%✨), Physics(14%), and Maths(3%) over ChatGPT on our challenge set"" thread says"
~ Harsha.B|2023-04-17 11:02:40|I’m curious to see the performance with Wolfram access + textbook content retrieval. Even though it’s kinda like cheating, considering the complexity of JEE it’s still impressive if it can solve with content retrieval and tools access as well
Ojasvi Yadav|2023-04-17 11:03:44|Also we're forgetting the value of negative marking  If you prompt GPT4 to skip the question if it's not confident then I'm sure it will score much better
~ Aman|2023-04-17 11:03:52|Exactly, these people just post results with some general prompting and then give a wrong impression
jyotirmayjk Hackathon|2023-04-17 11:04:05|Not sure how else to train a LLM to solve complex math   No amount of fine tuning can help it be proficient in complex maths I think
Ojasvi Yadav|2023-04-17 11:04:20|Also perhaps there is some value in prompting it to skip math more than chem and physics
Ojasvi Yadav|2023-04-17 11:04:31|Since it's dumber at maths
jyotirmayjk Hackathon|2023-04-17 11:05:19|+1 on this   Also even humans iterate on a question for getting answers  If there was a way to incorporate feedback while it solves JEE questions then perhaps we could see better results
jyotirmayjk Hackathon|2023-04-17 11:05:51|In Zero shot prompting you’re just posting a question and taking at face value the first answer GPT provides
~ Nijil Y|2023-04-17 11:05:52|Someone can experiment autogpt with jee and see where it leads
~ Nijil Y|2023-04-17 11:06:03|Will be still useless with math I am guessing
Ojasvi Yadav|2023-04-17 11:06:10|And also many low hanging fruit problems in JEE are repeat questions with slightly different values  I'm sure if there's a a vector db of all the past questions and test papers it will do much better in collecting all these low hanging fruits
Ojasvi Yadav|2023-04-17 11:07:34|Also I'm sure GPT finishes the entire test in like 5 to 10 minutes  There should be a secondary review pass where it is prompted to check it's solutions with proper logical reasoning. There is a chance that it might revise a few of its previously wrong answers.
~ Ram|2023-04-17 11:07:34|‎~ Ram joined using this group's invite link
~ Raj|2023-04-17 11:09:41|‎~ Raj joined using this group's invite link
Ojasvi Yadav|2023-04-17 11:09:48|And also sequential questions. Where one question's answer leads to the context of next one. I'm sure whoever implemented this experiment did not take into account the previous questions context and prompted GPT to answer it in isolation.   There should be a question context window which looks at N-1 and N+1 question when GPT is on question N. And verify if these questions are interrelated. If they are, then use all three questions in context window.
Ojasvi Yadav|2023-04-17 11:10:10|Anyone wants to join hands and work on this with me?
~ Ameya|2023-04-17 11:11:25|Sure!
~ Ameya|2023-04-17 11:11:46|Also had another idea if anyone is up to collab: https://replit.com/bounties/@JosephJacks/llm-ify-any-app
Bulia Siddharth Aurashop|2023-04-17 11:12:05|It still can't do math calculations, that must have been main reason why it failed brutally. I think it must have scored great in reasoning questions. I also tried few math questions to GPT-4 from last year paper, the method was 80% correct but still the final answers were wrong.
Ojasvi Yadav|2023-04-17 11:12:17|Making a group
Ojasvi Yadav|2023-04-17 11:12:21|Anyone else?
~ Harsha.B|2023-04-17 11:14:49|A lot of questions have diagrams as well, GPT4 can probably handle that but image functionality isn't even out yet afaik so that's also something to consider
Swastik Banerjee|2023-04-17 11:15:22|actually interesting idea, I could give this a try…
Ojasvi Yadav|2023-04-17 11:15:57|Clip it up
Ojasvi Yadav|2023-04-17 11:16:24|Not going to help 100% of the time but that is indeed very valuable context
~ Harsha.B|2023-04-17 11:16:32|I doubt clip would be effective with academic diagrams, worth a shot but i'm skeptical
Ojasvi Yadav|2023-04-17 11:17:06|Let's see
Ojasvi Yadav|2023-04-17 11:17:28|If it isn't then we'll just prompt it to be a little hesitant in answering diagram based questions
~ Harsha.B|2023-04-17 11:17:31|CLIP + some OCR logic + some prompting on top of that maybe idk
Nirant|2023-04-17 11:17:34|Can probably glue up something like Amazon's MM-CoT and see if that helps with diagrams and figures? cc [PHONE]
Ojasvi Yadav|2023-04-17 11:17:56|I'm sure folks in this group can do much better than what these guys did
Ojasvi Yadav|2023-04-17 11:18:10|I've already made a group with [PHONE]
Ojasvi Yadav|2023-04-17 11:18:20|We'll crack it soon!
Ojasvi Yadav|2023-04-17 11:18:30|Happy to have more folks on board
Ojasvi Yadav|2023-04-17 11:18:45|OCR is definitely required
Nirant|2023-04-17 11:18:55|Flip your work to FOSS and post weekly updates :)
Swastik Banerjee|2023-04-17 11:20:28|are we opening a fiitjee for llms now :p
jyotirmayjk Hackathon|2023-04-17 11:21:01|If you start fine tuning it then definitely it’s FIITJEE
~ Harsha.B|2023-04-17 11:21:22|overFIITJEE
jyotirmayjk Hackathon|2023-04-17 11:21:43|After all aren’t students “fine tuned” for cracking JEE ? 😝
Bulia Siddharth Aurashop|2023-04-17 11:26:51|We can also skip image related questions in first try? and see how it performs on questions with no images.
Harveen Singh Chaddha|2023-04-17 11:27:02|I am already in process of writing a paper on this. Should be up on arxiv by this weekend
Kartik Mandaville|2023-04-17 11:29:26|Problem: Problem: Albus gets three types of questions: 1. Internal company wiki 2. AI 3. Support questions How can we decide what type of question it is? Langchain agents have the framework but it would need to be programmed. Has anyone worked on something like this?
jyotirmayjk Hackathon|2023-04-17 11:34:27|Working on similar problem statement currently  I’m evaluating this framework from GPT-Index  https://twitter.com/jerryjliu0/status/1647626532519841793?s=46&t=icC0fizZK8E3ONsDVuGFWA
~ Suchana Seth|2023-04-17 11:34:46|Should we spin off a separate group for speculative fiction enthusiasts?
~ Harsha.B|2023-04-17 11:35:38|You can create a separate prompt for determining the question type. In the prompt you can keep the three options in MCQ format at the end of the prompt so you can easily parse the output. Keep this prompt at the very beginning before the retrieval part
Nirant|2023-04-17 11:35:40|Already exists: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
~ Suchana Seth|2023-04-17 11:36:17|Thank you! ‎[4/17/23, 11:39:08] Ojasvi Yadav: ‎image omitted
~ Prashanth YV|2023-04-17 11:39:54|‎~ Prashanth YV joined using this group's invite link
~ Vivek Karna|2023-04-17 11:41:21|‎~ Vivek Karna joined using this group's invite link
Sumod K Mohan|2023-04-17 11:49:38|I agree we need better terms. Not sure what to call soft-prompting. It's not distillation. Customer don't want to use OpenAI + only davinci knows enough context to generate valid outputs but still needs fine tuning on data not publicly available. But they are insanely expensive to serve ($.12/1k token, that's 10Rs per output).
Sumod K Mohan|2023-04-17 11:50:41|So we are in this world of fine tuning local models. To be able to serve/train them reasonably, you need small models. Anyone else fine-tuning local models or using fine tuned davinci.
Anubhav mishra Zupay|2023-04-17 11:52:55|Btw did anyone try to ask chat GPT4 to solve ie Itodov?
Anubhav mishra Zupay|2023-04-17 11:55:53|Imo atleast for the physics part for waves i did try. Let me know if anyone is able to try with questions of IE Irodov 😅
Sachin Legaltech|2023-04-17 11:59:50|Models like MatCha or DePlot are trying to answer based on diagrams. https://huggingface.co/docs/transformers/main/model_doc/matcha , https://huggingface.co/docs/transformers/main/model_doc/deplot
Shashank Generative AI Group|2023-04-17 12:04:11|for diagrams, there's Google's Pix2Struct. trained on 9 tasks. links:  https://github.com/google-research/pix2struct https://replicate.com/cjwbw/pix2struct https://twitter.com/search?q=Pix2Struct
~ Rachitt|2023-04-17 12:33:02|‎~ Rachitt joined using this group's invite link
Keertana S Suvy|2023-04-17 13:45:17|‎Keertana S Suvy joined from the community
~ Sanjeeth kumar|2023-04-17 15:24:31|‎~ Sanjeeth kumar joined using this group's invite link
Nirant|2023-04-17 16:27:18|Vicuna-7B runs in Chrome Canary on M2 Macs with WebGPU https://simonwillison.net/2023/Apr/16/web-llm/
~ Ravi|2023-04-17 16:27:33|‎~ Ravi left
Nirant|2023-04-17 16:28:33|Super exciting direction because this means we can have LLMs which are private to _user_, not just _organisation_
Nirant|2023-04-17 16:29:20|Perhaps, some day we'll have lightly finetuned weights for every person and you just take them from one company to the next like you do with your personal phones today
Ananth Radhakrishnan 2012A7|2023-04-17 16:35:14|Giving me Blade runner 2049/Her vibes.
Dev Aggarwal|2023-04-17 16:36:32|_Apple silently beefing up their little ml cores inside iphones_
Yash Pandya|2023-04-17 16:36:54|We already have that at a very small scale, your phone keyboard is personalised
Dhruv Naik|2023-04-17 16:39:20|Fun fact: Person behind WebLLMs also developed XGBoost, TVM and MXNet
Shashank Generative AI Group|2023-04-17 16:40:15|yup. google did some very impressive stuff for on-device ML for Assistant and Gboard apps, a few years back.
~ Shobhit Jaipurkar|2023-04-17 16:41:48|‎~ Shobhit Jaipurkar joined using this group's invite link
Krishna Ntkris|2023-04-17 16:47:31|Before my current product, I wanted to build an AI-enabled analytics product. Some thoughts on this: - Incumbents have a big advantage here IMO, more so than other areas - Anyone who has semantics on the data will definitely build AI on top. Because the data is structured, it feels easier to do so. - I do think there is a large business to be built here but it needs go much further - Being able to ask causal questions (e.g. why did conversion fall in X area last week?), have the machine do the work and get an answer for you feels very powerful  Always happy to chat about this :)
Nirant|2023-04-17 16:51:13|Talk about a boss-mode Github https://github.com/tqchen
Ojasvi Yadav|2023-04-17 16:52:32|Goat
Soumendra Dhanee|2023-04-17 17:17:02|Fine-tuning davinci doesn't really work is what I have heard
Soumendra Dhanee|2023-04-17 17:17:28|Prompt engineering davinci is almost always better than fine-tuning it
Nirant|2023-04-17 17:19:52|For those not familiar with naming conventions:  davinci and GPT3 are the same. That is an original instruction - finetuned LLM and not a Chat LLM  GPT3.5-Turbo and GPT4 are Chat LLMs with a conversational mode
Abhishek Sahu Ultrahuman|2023-04-17 17:23:15|The Analogy i like to use is: what if just a handful of people at a company knew how to Google stuff? The whole place would struggle to make decisions based on data. We see the same thing happening with data analysis.   We’re trying to solve this at https://www.probeai.app/
Dhanush Speciale Invest|2023-04-17 17:37:55|‎Dhanush Speciale Invest joined using this group's invite link
Manas Ranjan Kar|2023-04-17 17:59:00|Can I get access? Trying to integrate something similar for our data warehouses
Abhishek Sahu Ultrahuman|2023-04-17 18:09:08|DMing
~ Sudhanshu Heda|2023-04-17 18:10:48|‎~ Sudhanshu Heda joined using this group's invite link
Rohit Aggarwal|2023-04-17 18:32:32|https://www.together.xyz/blog/redpajama
Rohit Aggarwal|2023-04-17 18:32:45|who's picking all these names 😂
Ojasvi Yadav|2023-04-17 18:40:58|An Indian employee of huggingface worked on this and published it  https://huggingface.co/blog/lora
Ojasvi Yadav|2023-04-17 18:42:00|During my research days I came across this dataset called LOL dataset
Ojasvi Yadav|2023-04-17 18:42:52|It was a dataset of low light pictures and their well-lit versions
Ojasvi Yadav|2023-04-17 18:43:13|I think I even used it in my papers and cited it
Nirant|2023-04-17 18:43:45|Ohh I know this one: paperswithcode.com/dataset/lol
~ Shivansh|2023-04-17 18:43:46|‎~ Shivansh joined using this group's invite link
Ojasvi Yadav|2023-04-17 18:44:01|Yes exactly that!
Ojasvi Yadav|2023-04-17 18:45:13|It was the wild West in 2017   People would just publish all sorts of crazy improvements with no reproducibility - no code and no exhaustive description of algorithms
Ojasvi Yadav|2023-04-17 18:45:56|How could anyone compare their claims to these unreproducable publications
Ojasvi Yadav|2023-04-17 18:46:14|Paperwithcode.com was quite helpful to compare my research with others
~ navi|2023-04-17 18:47:28|‎~ navi joined from the community
~ Preet|2023-04-17 18:53:54|‎~ Preet joined using this group's invite link
~ Akki|2023-04-17 19:21:01|‎~ Akki left
Shan|2023-04-17 19:22:10|Haha lol yes. I remember those days. I spent months trying to make a sota model work for our data, then failed to reproduce then rebuilt with some more data then fine tune and rebuild and so on. Eventually I realised their sota was reproducible but nothing else worked.
Nirant|2023-04-17 19:22:59|PSA: Please inform whosoever you're sharing the invite link with that this group is a firehose and somewhat technical in it's spirit.  It'll save them time and spare the rest of us from getting ```left``` notifs.
Shashank Generative AI Group|2023-04-17 19:24:55|but the lora paper didn't have any indian author https://arxiv.org/abs/2106.09685
Nirant|2023-04-17 19:25:47|LoRA is from MSFT, that blog is from Huggingface DevRel — which has a couple of Indian origin folks in Europe
Shashank Generative AI Group|2023-04-17 19:26:52|yes
Ojasvi Yadav|2023-04-17 19:28:04|You exactly know my pain 🫂
Ojasvi Yadav|2023-04-17 19:29:16|Were you working for a research group back then? Or was this an industrial task?
Ojasvi Yadav|2023-04-17 19:29:22|[PHONE]
Ojasvi Yadav|2023-04-17 19:30:32|Oh my bad I thought the huggingface team was the one named this
~ Rishabh Raj|2023-04-17 19:31:10|‎~ Rishabh Raj joined using this group's invite link
Nirant|2023-04-17 19:31:44|Huggingface built a wrapper around multiple finetuning methods, called it PEFT: https://github.com/huggingface/peft  That blog is specifically PR for that ‎[4/17/23, 19:32:26] Nirant: ‎image omitted
Shan|2023-04-17 19:37:04|for my startup 🙂 Bewgle.
Ojasvi Yadav|2023-04-17 19:46:27|My salutations
Ojasvi Yadav|2023-04-17 19:46:57|Can't help but admire any founder ready to roll their sleeves up and get their hands dirty in some R&D
Kartik Mandaville|2023-04-17 21:37:32|https://twitter.com/NathanLands/status/1647864974323204096 relevant to our previous conversation on more companies entering the space. Google and Amazon both launched code completion etc - getting very similar to OpenAI
Prayank Swaroop Accel|2023-04-17 21:47:13|Which LLM will you use ... I did benchmarking on all open source ones against GPT4.. all open source ones are bad 😞.. and really the only one commercially available is Dolly 2.. it can't compare to GPT4.
Prayank Swaroop Accel|2023-04-17 21:48:13|"Just ask each of them - ""What is Bengaluru? Be concise"" and see all of them spectacularly fail. 😫"
Ramakrishnan Lokanathan|2023-04-17 21:53:26|So Magi is Bards sister? / is this a rebrand because of all the bad press from the bard launch?  The underlying is still Lambda. These multiple launches are confusing and shows massive desperation.  https://twitter.com/gergelyorosz/status/1647905401432571904?s=46&t=5aQS86mRo7ytzWcjKYKPUQ
Siddharth Agarwal|2023-04-17 21:54:45|Not PaLM?
Ramakrishnan Lokanathan|2023-04-17 21:59:41|Is it PaLM? not sure.
Shashank Generative AI Group|2023-04-17 22:03:15|it's Google. multiple launches, rebranding of the same product is their forte 😂
Shan|2023-04-17 22:03:53|We build some models and ensemble some others. Our use case is deliberately narrow- we don’t need super powers. Besides, the problem with LLMs is that you have no control over them at all. If an LLM doesn’t behave the way you want it to, what will you do? Prompt tinkering is ok but it assumes that the LLM is perfect. And it isn’t. There are other issues with prebuilt LLMs as well which makes it tough to use in an enterprise environment.
Pranjal Mehta|2023-04-17 22:05:01|[PHONE]
Nirant|2023-04-17 22:43:58|LLM Components to decide and weigh memory in Langchain, from the Generative Agents paper. Implements 2 agents talking to each other as well.  https://twitter.com/hwchase17/status/1647987713449263106
~ Prajwal|2023-04-17 22:48:05|i saw that many people here have published research papers here, I am really interested in knowing about how it's done and how I can publish a research paper on an interesting problem?
~ Prajwal|2023-04-17 22:48:31|especially in this case related to generative AI
~ Bhoumik|2023-04-17 22:49:53|‎~ Bhoumik joined using this group's invite link
Keertana S Suvy|2023-04-17 22:50:14|Has any of you worked with LLMs for math problem solving, or used chain-of-reason prompting? We're delving into the problem solving use case and would love to discuss if you have.
Nirant|2023-04-17 22:51:37|A good starting point: 1. https://www.youtube.com/watch?v=j1DvCavAmhE 2. https://www.froihofer.net/students/how-to-write-a-computer-science-paper/  Note that writing a paper is a different skillset from doing research or engineering, in the same way that interviewing for a job is a different skill from doing the job.  Would encourage others to directly DM the friend :)
Shan|2023-04-17 22:53:32|Grab hold of a prof. Or.. Enterprise researchers can help if you intern with them.
Sumod K Mohan|2023-04-17 23:10:52|Did you try something improve controllability. We are also having issues, esp when you need executable or near executable like outputs. Think DSL like outputs etc.
Nirant|2023-04-17 23:36:37|github.com/shreyar/guardrails might be useful here, uses LLMs to give structured outputs including JSON, Python objects, XML and DSL like outputs should be possible too
Ojasvi Yadav|2023-04-17 23:57:16|Something something PCA Nishant
Ojasvi Yadav|2023-04-17 23:57:34|*Nirant
Ojasvi Yadav|2023-04-17 23:57:50|We caught you using old dimensionality reduction techniques 👀
Swastik Banerjee|2023-04-17 23:58:14|[PHONE] : delt game moderate
"~ Suryansh | Building ES"|2023-04-18 00:37:16|"‎~ Suryansh | Building ES joined using this group's invite link"
~ Jonathan Ve Vance|2023-04-18 06:30:07|‎~ Jonathan Ve Vance joined using this group's invite link
Nirant|2023-04-18 09:07:45|Adept.ai got copied as an in the OpenAI Plugin Store, called Multi-on  Adept.ai is best known for being started by the creators of Transformers (Vaswani, Parmar, who've left the co as well) and raising $415M till date.  https://twitter.com/DivGarg9/status/1648074780430696448
Akash Chandran|2023-04-18 09:43:17|‎Akash Chandran joined using this group's invite link ‎[4/18/23, 10:11:54] Ojasvi Yadav: ‎image omitted
Ojasvi Yadav|2023-04-18 10:12:05|We will need people who have the following experience:  1. CLIP and image analysis models - this will be used to tackle questions with diagrams 2. Opensource maintainers and contributors - to help in making this an accessible and reproducible project 3. Problem solving with GPT or LLMs - technical, analytical problems.
~ ➕📆|2023-04-18 10:13:36|‎~ ➕📆 joined using this group's invite link
Amir Nagri|2023-04-18 10:14:18|Meeting invite?
~ ι|2023-04-18 10:14:33|‎~ ι joined using this group's invite link
Nirant|2023-04-18 10:16:27|1. cc [PHONE] has worked with CLIP, BLIP-2 and VQA 2. You've [PHONE] sir, the creator of Vakyansh 🙏🏼 3. OpenAI Evals has some clever examples: github.com/openai/evals
Nirant|2023-04-18 10:17:07|As mentioned in the screenshot — Please find the group from Community in WhatsApp, Apply to Join, meeting link will be shared there :)
~ Bhoumik|2023-04-18 10:22:22|What are you trying to build? Chat bot which can solve JEE questions? Or a Chatbot which can help students preparing for JEE?
~ Nischal - Collectiv AI|2023-04-18 10:23:02|‎~ Nischal - Collectiv AI joined using this group's invite link
Ojasvi Yadav|2023-04-18 10:23:36|[PHONE] ajao sir, sending you the whatsapp invite directly
Naman Jain CollectivAI|2023-04-18 10:30:31|‎Naman Jain CollectivAI joined using this group's invite link
Ojasvi Yadav|2023-04-18 10:32:42|4. Multimodal vector similarity search - we're going to index image and text embeddings of useful information. Will definitely need someone with solid experience here.
Ravi Theja|2023-04-18 10:33:58|https://github.com/marqo-ai/marqo - probably can take a look at this db
Ravi Theja|2023-04-18 10:34:00|*vectordb
Ojasvi Yadav|2023-04-18 10:36:20|I'm a bit oldschool here and prefer to stick with elasticsearch 😂
Ojasvi Yadav|2023-04-18 10:36:43|Is it tough to setup and maintain? yes, but I have production level experience of doing that so it's fine i guess
Nirant|2023-04-18 10:38:29|Should I bring an all-purpose AK47 to a knife fight and mention FAISS 😅
Ojasvi Yadav|2023-04-18 10:38:58|Additionally, all kinds of financial help in terms of openAI credits, GPU credits are welcome with huge open arms.   Heck, I'll even break-up with ES if someone can help with getting credits for a vectorDB 😂
Ayush Deva|2023-04-18 10:41:07|I'm in. I have curated a tagged dataset of a large number of JEE-styled questions that can be used for training.
Ojasvi Yadav|2023-04-18 10:44:49|Go ahead, I'll bite 🙈
Aaditya Sood Sequoia|2023-04-18 10:45:50|‎Aaditya Sood Sequoia joined using this group's invite link
Nirant|2023-04-18 10:47:39|Lot of the modern DL infra is built around FAISS: Haystack (Deepset), Milvus, txtai. Even Langchain launched with FAISS.  FAISS is probably tested in more production systems than ES Vector/HNSW. And ofc, it's a lib, you manage state in a file, so all CRD is quite straightforward —  if you do not want frequent updates.
Ojasvi Yadav|2023-04-18 10:50:19|makes complete sense  index would stay static after the first pass with final preprocessed data
Ojasvi Yadav|2023-04-18 10:50:58|Maybe we can just train a KNN model and save its artifact locally so people can run it locally too
Ojasvi Yadav|2023-04-18 10:51:31|Karpathy baba's SVM approach also makes complete sense in this usecase
Nirant|2023-04-18 10:52:32|Keep going down the path of Baba Karpathy, and soon you'll find yourself in a Random Forest with Boosted Trees. There my friend, I first saw wisdom.
Ojasvi Yadav|2023-04-18 10:55:29|Are you saying that Baba Karpathy is the Yoda of the machine learning world?
~ Paritosh Sanadhya|2023-04-18 10:55:33|‎~ Paritosh Sanadhya joined using this group's invite link
Nirant|2023-04-18 10:58:11|So Karpathy (w/ Fei Fei Li and others) was the one who demonstrated the LSTM+CNN Image Captioning Model in his PhD Thesis. He was also the one who introduced the idea of using model weights projected as an _attention_ map to debug models. This was a precursor to _Attention_ in the philosophical sense.   He is a bit young to be Yoda, but sure he's Yoda given that a year in Deep Learning counts as 7 in Real world 😅
Ojasvi Yadav|2023-04-18 11:05:48|Truly a pioneer
Ojasvi Yadav|2023-04-18 11:29:44|found this in the eval PRs  https://github.com/openai/evals/pull/123
~ pt|2023-04-18 12:51:03|https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 Looks like there is a corelation between reasoning and code percentage in pretraining. Do you think finetuning a codgen model with jee data would work for problem solving? ‎[4/18/23, 13:10:52] Sudharshan GenAI: ‎image omitted
Nirant|2023-04-18 13:24:42|Are there folks in this group interested in working on these problems?   Happy to have a long-running working group with occasional demo days. Can remove basic bottlenecks like GPU, OpenAI Credits and such.
Sudharshan GenAI|2023-04-18 13:25:42|Me - Problems I like  1) Long lived conversations: What would a good implementation of an AI therapist, teacher, or advisor look like who remembered what you did/said 1 day/week/month/year ago?  2) Mind uploading: How do you memorialize a loved one? How do you upload yourself to the everlasting ether?  3) Theory of Mind: e.g. Educational chatbot that knows what you don't know
jyotirmayjk Hackathon|2023-04-18 13:25:51|Interested  Especially AI agents for conversations
Sudharshan GenAI|2023-04-18 13:26:11|3) Is something I've bee thinking about for a few years - How do you reduce unknown unknowns
Sudharshan GenAI|2023-04-18 13:26:38|Also - https://www.together.xyz/blog/redpajama  New group (MILA, eth zurich etc) working on a commercial LLaMA
Azhan Mohammed Generative AI WhatsApp Group|2023-04-18 13:28:33|I’m interested as well.  A problem I’m interested in AI agents for day to day conversation
Swastik Banerjee|2023-04-18 13:29:27|what does the “personal search” problem statement mean?
Sumod K Mohan|2023-04-18 13:29:38|Been working on personal search. Will keep you guys posted.
Nirant|2023-04-18 13:29:49|rewind.ai
Siddharth Agarwal|2023-04-18 13:31:37|I'm interested in the multimodal AI project. ‎[4/18/23, 13:31:58] Sumod K Mohan: ‎image omitted
Sumod K Mohan|2023-04-18 13:32:18|DM me if you find mistakes. ‎[4/18/23, 13:33:18] Harsh Koo: 2304.08448.pdf • ‎26 pages ‎document omitted
Swastik Banerjee|2023-04-18 13:33:41|interesting…this must be really memory-heavy?
Pranjal Joshi US FINTECH|2023-04-18 13:35:25|The multi-modal AI project finds a direct correlation to what I work on currently. I would love to explore Generative AI to solve problems and build systems which are multi-modal.
Harsh Koo|2023-04-18 13:35:31|My key takeaway from skimming this paper was the iterative prompting.   A lot of jargon from medicine I'll decipher with a doctor friend and share a summary here in the future.
Anudeep Yegireddi|2023-04-18 13:36:25|Interested as well
Harsh Koo|2023-04-18 13:36:47|Interested in how to do domain specific feedback loop and fine-tuning.   A few friends in industry (security, appliances, medicine) are interested in learning more.
Deep Samsung R&D|2023-04-18 13:44:14|+1 Interested in this too [PHONE]
~ Rachitt|2023-04-18 13:45:05|+1 to domain specific feedback and fine-tuning
Nirant|2023-04-18 13:45:48|What do you all mean by domain specific feedback? RLHF? ‎[4/18/23, 13:46:30] Nirant: ‎image omitted
Karan Lightspeed|2023-04-18 13:46:55|Check out character.ai. They are doing something similar.
Sudharshan GenAI|2023-04-18 13:47:02|Nice! Any comparison for open source LLMs?
~ Khush|2023-04-18 13:47:27|‎~ Khush joined using this group's invite link
Harshal Bhatia|2023-04-18 14:06:51|Interested
Nirant|2023-04-18 14:09:16|Folks, please share ideas which you can contribute/implement to indicate interest. Or even better, share any relevant code/paper which you've seen on the topic :)
Harsh Koo|2023-04-18 14:10:29|Yes RLHF from the domain experts and internal team users.   Say if there is an LLM answering questions from docs that are firewall installation manuals.  What sort of items should be shown in response? Sources, code snippets, correct nomenclature.  What are the issues with licencing, MIT licensed LLMs.  Annotation tools to collect feedback.  How to rewrite traditional PDF/Word manauls.  The questions are diverse and multi-dimensional and traditional industry leaders are savvy enough to bite the LLM bullet to improve their workflows, but have a ton of questions across paradigms I mentioned above.
Nirant|2023-04-18 14:11:33|Helpful list of directions
Kaushik Bokka|2023-04-18 14:15:46|are you planning to talk to Anton?
Shimanta Generative AI|2023-04-18 14:23:45|Augmented reality Pokedex caught my eye. Pardon my noob language but is there any way to convert images to 3D models?
Shimanta Generative AI|2023-04-18 14:26:14|There is a openai model to convert image/text to 3D model I have seen: github.com/openai/point-e
jyotirmayjk Hackathon|2023-04-18 14:26:25|Yes there seems to be a project on this   https://arxiv.org/abs/2301.08247
jyotirmayjk Hackathon|2023-04-18 14:27:10|Segment Anything Model was used to create an object mask from image
jyotirmayjk Hackathon|2023-04-18 14:27:53|Demo for anyone interested  https://twitter.com/nikolauswest/status/1646093500478369792?s=46&t=icC0fizZK8E3ONsDVuGFWA
jyotirmayjk Hackathon|2023-04-18 14:29:51|https://t.co/sVSHuljpwe  This paper outlines the core of the technique used
Sudharshan GenAI|2023-04-18 14:55:33|Might DM, but this program is US or US remote. Wbu?
Ritwik 2013|2023-04-18 15:06:28|Anyone else facing issues with huggingface endpoints rn?
Soumyadeep Mukherjee|2023-04-18 15:16:50|Both Gh and hf are facing issues.
Shashank Generative AI Group|2023-04-18 15:20:20|personal search related: https://github.com/KnowledgeCanvas/knowledge
Shashank Generative AI Group|2023-04-18 15:24:41|interested. working on PKM adjacent problems (personal search etc), mostly solving for myself...building on top of my Readwise data.  more than the ML part (mostly solved IMO), I'm thinking about interfaces, better UX.
~ Ravi Trivedi|2023-04-18 15:42:17|‎~ Ravi Trivedi joined using this group's invite link
~ Bhoumik|2023-04-18 16:20:15|These are some really interesting directions. I have been spending some time on these questions recently.
~ Mehul Kaushik (WckD)|2023-04-18 16:42:35|‎~ Mehul Kaushik (WckD) joined using this group's invite link
Shimanta Generative AI|2023-04-18 16:44:37|Clashes with this meetup
Nirant|2023-04-18 16:56:27|Removing the previous message since we discourage self promotion and the person hasn't replied to a personal ping, has no name on WA, nor an active contributor here
Nirant|2023-04-18 16:57:14|That is amazing! BLR should've more gatherings, hackathons for people to choose from!
Anagh Prasad|2023-04-18 17:05:32|Very good read
Anagh Prasad|2023-04-18 17:05:34|https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/
Anagh Prasad|2023-04-18 17:05:36|Title is a bit misleading though. The point is that models will become better, but not by adding more base training data
Pranjal Mehta|2023-04-18 17:13:16|Better chance of playing catchup for startups :)
Rohit Aggarwal|2023-04-18 17:22:47|Especially comes after together  said that their model will be 1.3 trillion params
Rohit Aggarwal|2023-04-18 17:24:04|Quick question for folks who are using LLMs in production(guessing there would be many in the group)  Do you create different organisation for the development and production environments OR just separate keys?  I’m hearing companies are trying to keep the costs and usage metrics separate. Curious how are you folks doing this? ‎[4/18/23, 17:26:33] Nirant: ‎GIF omitted
Kartik Mandaville|2023-04-18 17:29:00|One account with multiple keys - easier to consolidate and have conversations with OpenAI team on priority access.
Ravi Theja|2023-04-18 17:29:17|we use AzureOpenAI, so tracking is pretty easy over there.
Nirant|2023-04-18 17:29:32|I'm also doing this fwiw
Kartik Mandaville|2023-04-18 17:29:42|btw do Azure Credits work for Azure OpenAI?
Nirant|2023-04-18 17:30:05|cc Ankita [PHONE] works for Azure India, can you please folks and confirm here?
~ Max 🦧|2023-04-18 17:30:29|‎~ Max 🦧 joined using this group's invite link
Rohit Aggarwal|2023-04-18 17:31:23|Can you track dev and prod on the same keys though? I didn’t know that functionality was there
Ankita Mathur Microsoft Sales|2023-04-18 17:31:24|Our OpenAI access   is on a subscription level , so if you have credits on that subscription, absolutely will work
Ravi Theja|2023-04-18 17:32:38|probably create different resources for prod and dev? haven't tried it though.
Rohit Aggarwal|2023-04-18 17:34:55|Yea, building for this along with 2-3 more things now. Will use my 1 strike week to post the link of the product 😅
Rohit Aggarwal|2023-04-18 17:35:14|1 strike next week*
Nirant|2023-04-18 17:35:55|You can always ask someone else to post, including me sir! 🙏🏼
Rohit Aggarwal|2023-04-18 17:36:24|Haha yea! Have to book some time with you anyway
~ Bhaskar|2023-04-18 17:38:00|‎~ Bhaskar joined using this group's invite link
Kartik Mandaville|2023-04-18 17:39:13|count me in as an early user
~ Mani|2023-04-18 17:40:30|[PHONE] I heard there’s a meet up this sat. Where can I find details about this and how do I register?
Nirant|2023-04-18 17:40:38|https://hasgeek.com/generativeAI/april-meetup/
~ Anuj|2023-04-18 17:47:30|‎~ Anuj joined using this group's invite link
Rohit GenerativeAI WhatsApp Group|2023-04-18 17:56:32|has anyone worked with context based search with cohere embeddings and openai gpt3.5 for non-english languages? how good it is in terms of results?
Ritwik 2013|2023-04-18 18:03:04|Has anyone worked here with map_rerank chain types in LangChain? Would like to know of there is away to return the document metadata for sources alongside the QA responses
Sourasis Roy|2023-04-18 18:03:38|‎Sourasis Roy joined using this group's invite link
Nirant|2023-04-18 18:03:39|map_reduce and refine both have this already. map_rerank should too?
Krishna Ntkris|2023-04-18 18:09:05|Worked with OpenAI. Good for some languages (eg Spanish) not good for others (Czech) based on feedback from our users
Krishna Ntkris|2023-04-18 18:09:42|Haven’t seen a good resource on what languages are good VS bad. Presume it’s based on amount of training data on the open web
Rohit GenerativeAI WhatsApp Group|2023-04-18 18:11:13|I am trying with Arabic but it just says hmm. I am not sure 🥲 even though the context is in arabic. Do you think I have to write the whole prompt in that language?
Ritwik 2013|2023-04-18 18:12:18|I think you're right, I need to explicitly define which keys I want in the chain response, let me give it a try
Nirant|2023-04-18 18:12:21|Assuming you're on 3.5, did you mention the response language in your system prompt? Something like: دائما الرد باللغة العربية ‎[4/18/23, 18:13:06] Nirant: ‎image omitted
Soumendra Dhanee|2023-04-18 18:13:09|Hey everyone, please welcome [PHONE]. My old roommate. He's from CMI in case anyone from CMI is here. 15+ yrs in tech. 8+ yrs in fintech space , currently building AI solutions for real estate sector in India/Middle East/ North America/ Australia. ‎[4/18/23, 18:13:57] ~ Ankur Khandelwal: ‎image omitted
Rohit GenerativeAI WhatsApp Group|2023-04-18 18:14:36|I just said, replay in context's language.. but let me be specific.  it works with a generic llm where there's no context with with context prompts it didn't  let me explore more on the prompt side
Rohit GenerativeAI WhatsApp Group|2023-04-18 18:14:39|thanks!
Pinaki Panda|2023-04-18 18:37:52|‎Pinaki Panda joined using this group's invite link
Lalit Pagaria|2023-04-18 18:54:52|I faced a similar problem where the text (customer feedback) language was unknown to us. So we added one step to detect text language and then prompted LLM to specifically reply in that language. In some cases (especially in code mix text) we did this via two-step chains. First, detect language using prompt and later pass it as a param to another.
Nirant|2023-04-18 18:55:32|In the right place and product, this reply is worth hundreds of dollars!
Dev Aggarwal|2023-04-18 18:55:51|Is there any cheaper and lower latency way to detect language? Especially in audio
Lalit Pagaria|2023-04-18 18:56:55|Open-source knowledge sir 🙏🏻
Edgar Monis Mumbai WHO|2023-04-18 18:56:59|In text we do this.https://github.com/Mimino666/langdetect
Edgar Monis Mumbai WHO|2023-04-18 18:57:24|But audio is a bit more difficult
Lalit Pagaria|2023-04-18 18:59:04|Not worked in audio. But for the text case also there are few libraries and API solutions (it is difficult to find the right one which works for you)
Rohit GenerativeAI WhatsApp Group|2023-04-18 19:00:21|exactly what I started using.. by specifying the language it works for a generic question  now figuring out how to do with with some context  the context is in non-english but the whole system prompt is in english
Ashfakh GenerativeAI WA Group|2023-04-18 19:28:06|‎Ashfakh GenerativeAI WA Group joined using this group's invite link
~ Arjun Rakesh|2023-04-18 19:28:15|‎~ Arjun Rakesh joined using this group's invite link
Shubham Sharma 2012C6|2023-04-18 19:55:42|https://www.youtube.com/watch?v=30xueN12guw
Pratyush Choudhury|2023-04-18 20:05:15|How easy/complex was this language detection/translation?
Pratyush Choudhury|2023-04-18 20:05:30|And did it introduce some latency?
Lalit Pagaria|2023-04-18 20:20:27|[PHONE] check this. If API based solution then it will add latency for sure.
Rohit Aggarwal|2023-04-18 20:20:42|Of the top of my head - Cut out a very short snippet of the audio, then use something like deepgram or whisper?
Rohit Aggarwal|2023-04-18 20:20:57|smaller the file, lower the latency is my guess.. but haven't tried it
~ Kalai|2023-04-18 20:21:36|‎~ Kalai left
Ashfakh GenerativeAI WA Group|2023-04-18 20:22:52|Best way to do this imo will be by sampling. Splice the audio into smaller chunks, hit parallelly, and give a best case score if your use case is language detection, else concatenate and map reduce for translation
Ashfakh GenerativeAI WA Group|2023-04-18 20:25:54|One issue is translation depends on context too, so chunks can’t be super small
~ Varath|2023-04-18 20:29:36|‎~ Varath joined using this group's invite link
~ The Last Samurai|2023-04-18 20:31:25|‎~ The Last Samurai joined using this group's invite link
Edgar Monis Mumbai WHO|2023-04-18 20:35:40|So you can split on gaps in amplitude. With a rule like 5 gaps in one chunk
Rohit Aggarwal|2023-04-18 20:49:34|This might actually make for a good cost reduction (compromising latency though) use case as well. Read the amplitude and omit parts of the audio where no sound was detected and then translate/transcribe
Edgar Monis Mumbai WHO|2023-04-18 20:51:30|Yeah that's pretty common in audio pre processing.
Rohit Aggarwal|2023-04-18 20:51:51|Interesting.. didn’t know that
Ashfakh GenerativeAI WA Group|2023-04-18 20:52:54|Same for text too. we remove white spaces and new lines to save for tokens in document chunks.  Another way is to downscale the audio a bit, you don’t need high quality always, again, depends heavily on usecase
~ Sangeeta Oak|2023-04-18 20:56:10|‎~ Sangeeta Oak joined using this group's invite link
~ Shivansh|2023-04-18 21:06:50|"Hey Everyone, We were working on a task of background replacement using text query. For example - there is a image of painting in a house and we want to change the background from house to museum. Our observation: 1. https://app.runwayml.com/video-tools/teams/Shivanshmundra/ai-tools/replace-backdrop we wanted to do something like this but with fine tuning on our data. Couldn't find model or api for this. 2. We tried conventional diffusion models like instructpix2pix and blended-latent-diffusion(https://github.com/omriav/blended-latent-diffusion) but these are not trained for background so the results were pretty bad. 3. We found MidJourney has this option of blending two images which worked well but it distorted main object. 4. We tried segmentation using Segment-Anything and choose ""best"" mask - crop it and pass to diffusion model to generate background or blend. But choosing ""best"" mask is problematic, sometimes it choose background.  If anyone has tried anything in this space or could help, please DM! Thanks already :)"
Nirant|2023-04-18 21:08:02|Props for asking a well-formed question! 👏
Shivendu Kumar|2023-04-18 21:16:38|Can you please create a poll for this?
~ Lakshya|2023-04-18 21:27:51|I am building something similar to the spaced repetition app here - basically learning stuff from large corpuses   Eg Learn lead gen from a popular podcast on marketing  sounds cool but I'm not sure what features to start with lol  would love to get some use cases from y'all
Nirant|2023-04-18 21:29:07|Let me zoom out a bit: I'm personally convinced that there is sincere interest. For a working group to happen, the bottleneck isn't buyer, reader or user interest — but builder/experimenter effort.  So what stops someone here from simply taking up an idea from the list and going ahead with it—what are the sources of friction? What can we do to remove those? This is highest RoI question worth answering.  My role then would be to remove as much friction as I can :)
~ aarthimuralidharan|2023-04-18 21:30:34|‎~ aarthimuralidharan joined using this group's invite link
Krishna Ntkris|2023-04-18 21:31:44|I’m looking to slice audio too. What would folks recommend with Python? I know pydub is popular but I saw it requires an external package
Edgar Monis Mumbai WHO|2023-04-18 21:33:21|pydub is fine
Shashank Generative AI Group|2023-04-18 21:47:54|hey, can you post an example input image? on which you're trying to do this task.
Sudharshan GenAI|2023-04-18 21:49:33|Nice! Share more? or DM
Sumod K Mohan|2023-04-18 21:51:56|Happy to chat. Have build/deployed something like this before but not with LLM.
Deep Samsung R&D|2023-04-18 21:52:51|I think someone had asked on Text to Video, do check this https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis
Sudharshan GenAI|2023-04-18 21:54:09|quick thoughts  - Do simple background segmentation to separate foreground from bg - generate background with SD separately (mask off area where subject is or block it somehow so SD generates around it) - stitch foreground and background together  If you want to make sure lighting is correct - do very light img2img to fix stuff
Sudharshan GenAI|2023-04-18 21:54:32|[PHONE] might have some good ideas
Sudharshan GenAI|2023-04-18 21:57:12|Just read your last point - have you thought of asking the user to select the best mask? Simple product problem vs complex AI pipeline
Sudharshan GenAI|2023-04-18 21:57:51|could work depending on your product!
Jay Pokarna 2014 BPCC|2023-04-18 22:12:41|Anyone aware about applications of generative AI in finance? Was excited about this and wanted to explore more
Nirant|2023-04-18 22:15:30|Not GenerativeAI tbh, but pretty neat offering: https://www.causal.app/  And ofc, there is Bloomberg GPT, a 50B model for finance: https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/
jyotirmayjk Hackathon|2023-04-18 22:15:47|https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2
jyotirmayjk Hackathon|2023-04-18 22:15:57|Open Source Bloomberg GPT
Nirant|2023-04-18 22:16:27|OpenBB is pure terminal play, right?
Nirant|2023-04-18 22:17:07|I don't recall them doing a LLM, and if yes, what data and arch are they building on?
jyotirmayjk Hackathon|2023-04-18 22:19:09|Yup I’d thought the same based on their site   But apparently there seems to be SDK/library Someone integrated it with Auto-GPT for investment research agent  https://twitter.com/derekcheungsa/status/1647772023731494912?s=46&t=icC0fizZK8E3ONsDVuGFWA
~ Rachitt|2023-04-18 22:19:22|Yeah, pure terminal play, i think they get direct market data, earnings calls, and reports
Jay Pokarna 2014 BPCC|2023-04-18 22:24:29|Making videos via SD. This guy's last couple of reels are very good : https://www.instagram.com/reel/Cq5eWq4rRQC/?utm_source=ig_web_copy_link
Kishore GenAI|2023-04-18 22:44:18|Have you tried using the latest control net models for intruct pix2pix (https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-instruct-pix2pix)   Given that you want to use text query, have to looked into grounded Segment anything ( https://github.com/IDEA-Research/Grounded-Segment-Anything) or even https://github.com/geekyutao/Inpaint-Anything  Also fine tuning a model look into this: https://github.com/mkshing/e4t-diffusion.  However I do not completely get why you would want to fine tune ? There are 100’s of modes already available in huggingface and third party sites which you can try to generate results with.  Control net works with automatic1111 with mikubil web extension (https://github.com/Mikubill/sd-webui-controlnet). It even supports the latest models.  Hope this helps. ‎[4/18/23, 22:48:08] Nirant: ‎image omitted
Nirant|2023-04-18 22:48:17|Discovered by [PHONE]
Harsh Koo|2023-04-18 22:53:07|[PHONE] have you come across any img2img models where I can generate variations of UI elements.   UI elements could be a button, a spinner, jackpot wheel (cred has some of these) and so on.  Basically, want to enable designers with a plethora of variations across shape, size, color and fonts
Nirant|2023-04-18 22:56:50|a very limited version of this used to be logojoy.com  some inside sauce: I hear Figma is building a version of this with some partners
Dev Aggarwal|2023-04-18 22:56:55|Pretty cool that its open https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0
Harsh Koo|2023-04-18 23:00:29|"This is nice. I've played with Midjourney for logo creation and it was pretty good.   I have existing designs I want to try AI on and with SD I didn't get good results.  A model that can ""segment"" various attributes of a UI element and then replace with a guided text prompt would be killer.  I guess Figma stands a good chance to build this."
~ Chinmay|2023-04-18 23:17:07|‎~ Chinmay joined using this group's invite link
Kishore GenAI|2023-04-18 23:25:55|Can you explain what you mean by you have existing designs? Is it some type of sketch? Also can you elaborate on “segment various attributes of UI elements “   My understanding is what you want exists. Can you tell what methods have you tried till now?
Kishore GenAI|2023-04-18 23:27:57|Try this gradio space if you already have a sketch. https://huggingface.co/spaces/hysts/ControlNet
Kishore GenAI|2023-04-18 23:32:18|My understanding is that the maximum amount of control right now comes from control net models. Given that multiple controllers can be clubbed together and img2img and inpainting is also supported, with even huggingface launching a control net sprint , we will get a lot of community controlnets which can be used. T2I adapters is another approach but controlnet has community momentum with it.
~ Sanjeed|2023-04-18 23:57:56|Noob here, but would Controlnet (https://github.com/lllyasviel/ControlNet) be useful?  Used here:  https://github.com/Nutlope/roomGPT
Harsh Koo|2023-04-19 00:05:40|Existing designs - I've used some UI elements from the Koo app and tried dreamstudio.   The prompt was basic things like change color to make it more engaging, bright, sharp edges and so on.  Results were lacklustre.  I havent tried with pix2pix Or controlnet models, yet.
Kishore GenAI|2023-04-19 00:08:03|Cool. Use the gradio space I shared. It would be a good starting point. You can also try playgroundai.com and see if that can help you
Harsh Koo|2023-04-19 00:09:33|Thanks a lot [PHONE]
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 00:23:34|Hi, An off topic question, not really related to generative models. I have a regression problem, but the problem is that the training dataset I have is really confined. Will performing Shapiro Wilk test on the target variable demonstrate that the data I have is really bad, and cannot be worked with at all. I performed the test and got a p value in range 1e-18
Nirant|2023-04-19 00:24:29|For readers, Shapiro Wilk is a measure of whether the data is normally distributed or not. https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test
Nirant|2023-04-19 00:27:14|In theory, that should convince your stakeholders. In practice, normality is not _necessary_ for you to regress on a dataset — sure, it informs what methods you can or cannot use, but there are methods which don't make normal distribution assumption.   Unless I'm missing something and you were my co-worker, that'd be my thought process with limited info here
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 00:29:37|Thanks for your input. Do you have any suggestions for methods I can use with a non normal dataset.
Soumendra Dhanee|2023-04-19 00:29:44|This was my thought too. This just violates some assumptions for linear regression variants, you can consider 1. other regression algorithms like tree based ones, or 2. See if the target can be transformed via a sensible function to close to normal distribution.
Soumendra Dhanee|2023-04-19 00:30:44|2. *and then apply liner regression family
Gokul Krishnan|2023-04-19 00:32:30|Can you elaborate what you mean by confined? And really bad for what exactly?
Gokul Krishnan|2023-04-19 00:32:41|Also, can you plot it somehow?
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 00:32:53|I tried using support vector regression and experimented with non linear kernels, the results remained the same. Will try tree based methods as well. ‎[4/19/23, 00:38:45] Azhan Mohammed Generative AI WhatsApp Group: ‎image omitted
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 00:40:28|Also, really sorry if I am making some stupid remarks/comments about the data. I have not worked a lot with tabular data, and I am just a beginner in Machine Learning.
Soumendra Dhanee|2023-04-19 00:42:09|This is not some sort of time series data?
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 00:45:46|No it’s not a time series data ‎[4/19/23, 01:14:51] Gokul Krishnan: ‎image omitted
Gokul Krishnan|2023-04-19 01:17:08|It's not a function in the traditional sense. It could the case that y = some_prob_distribution(x). Ex. Y = normal_distributed(mean =x)
~ Shivansh|2023-04-19 01:22:46|Hey Guys, thanks a lot for suggestions on this.  1. I am attaching a photo I just took, I wanted to extract the glass from the image and place it on a fancy dining table without distorting the structure of glass.  2. We have tried segmentation methods but the problem is to choose the highlighted object, sometimes mask quality of background is better than that of object.  3. Normal background removal algorithm works well to extract object but then the issue lies in stitching object to generated background. In all open source models I’ve found - controlnet, pix2pix etc, these are bad at stitching. Probably they were trained to generate images and not blend. The commercial ones like runway and midj are good but we can’t use them ;( ‎[4/19/23, 01:22:53] ~ Shivansh: ‎image omitted
Ojasvi Yadav|2023-04-19 01:25:04|Try jadoosnap.com
~ Shivansh|2023-04-19 01:26:38|Wanted to give users of I’m feeling lucky option :) Though a nice suggestion if they want total control!
Rohit GenerativeAI WhatsApp Group|2023-04-19 01:27:30|how did you blend the images? only if you want to share or is it a completely different approach?
~ Shivansh|2023-04-19 01:28:24|Yeah man curious to know! Results look quite nice!
Rohit GenerativeAI WhatsApp Group|2023-04-19 01:29:37|I actually did this exact approach.. researched online on how to blend.. saw adobe firefly results.. and dropped it 🥲
Sumod K Mohan|2023-04-19 01:30:31|Two cents 1. Your target seems categorical, is this true? 2. Just eyeballing there does seems like there are (some) patterns. But will be very difficult to say what will make sense. It could be the case that you have mixture of distributions, it could be that there are other variables that should have been considered etc. You will need to look the process that generated the data and decide whether this makes sense. It could also just be that you have a bunch of outliers. If they are outliers, use a regularised regression. As you might have guessed, am a Bayesian. 3. Confined to a small range per se is not a problem, you could normalise etc. But the real issue whether your new data will be interpolatable from the models/do you know something about the process that informs you that. 4. To say you have bad data can be quite challenging. But incomplete may be so, as only part of the explanation might be provided by the current variable.
Ojasvi Yadav|2023-04-19 01:30:57|DM me brother
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 01:36:03|For the first part no my data isn’t categorical.  Will surely try Bayesian methods as well. As for the better understanding of the data, can I dm you? ‎[4/19/23, 01:36:11] Ojasvi Yadav: ‎image omitted
~ Charlie|2023-04-19 01:38:53|‎~ Charlie was added
Paddy|2023-04-19 01:38:53|‎Paddy was added
~ Shivansh|2023-04-19 01:39:41|Would be great if we could get prettier backgrounds! Thanks already! ‎[4/19/23, 01:58:08] Abhishek Maiti: ‎image omitted ‎[4/19/23, 01:58:10] Abhishek Maiti: ‎image omitted ‎[4/19/23, 01:58:11] Abhishek Maiti: ‎image omitted ‎[4/19/23, 01:58:13] Abhishek Maiti: ‎image omitted ‎[4/19/23, 01:58:15] Abhishek Maiti: ‎image omitted
Abhishek Maiti|2023-04-19 01:58:32|Along with SD 1.5 inpainting ckpt
Abhishek Maiti|2023-04-19 01:59:29|And this was with minimal effort on the prompting end, so results may get better with better prompting.
Kishore GenAI|2023-04-19 02:19:20|Have you tried to use any inpainting models? They are opensource by runwayml. The one shared above by Abhishek.   Regarding image stitching, you said you controlnet was bad at it. Did you use the regular model? Or did you use inpainting checkpoint? What flaws did you see with them? ‎[4/19/23, 02:23:16] Kishore GenAI: ‎image omitted
Prayank Swaroop Accel|2023-04-19 02:25:52|Folks hoping all of you have seen launch of Open Assistant - https://open-assistant.io/ - opensourced alternative to ChatGPT by the LAION-AI initiative.
Rohit GenerativeAI WhatsApp Group|2023-04-19 02:40:08|I have seen this image somewhere. Is this a product of any startup?
Kishore GenAI|2023-04-19 02:43:03|The image is from my startups website. The “ product” is from a Instagram image of this company which sells candles. I just dropped out the hands, matchbox and light of the matchstick and incorporated into other image which I then used as base for controlnet inpainting.
Rohit GenerativeAI WhatsApp Group|2023-04-19 02:44:32|do you have a website to check it out more?  now I remember. I saw it here itself last month. ‎[4/19/23, 02:46:01] Kishore GenAI: ‎image omitted ‎[4/19/23, 04:02:24] Prayank Swaroop Accel: ‎image omitted
Sourasis Roy|2023-04-19 07:49:17|https://github.com/geekyutao/Inpaint-Anything maybe this can work for you
~ Shivansh|2023-04-19 08:10:07|Thanks for the suggestions. I did use normal checkpoints with a basic prompt to see if they are understanding physical structure. I’m attaching one of the result where I gave the prompt “add dining table in background”.    I’ll definitely try inpainting one as Abhishek told. ‎[4/19/23, 08:10:25] ~ Shivansh: ‎image omitted
~ prakashpvss|2023-04-19 08:22:37|‎~ prakashpvss joined using this group's invite link
Shan|2023-04-19 08:26:30|if your data is not normally distributed then you can use Extreme Value Theory tools. See Hill Estimator for instance, but there are others
Lalit Pagaria|2023-04-19 08:48:28|Just curious to understand -  Have you introduced ChatGPT like LLM to younger kids (8-13 yrs age bracket)?  If yes then how are you making sure it is safe to use for them? (preventing hallucination, bias, etc)
Nirant|2023-04-19 08:49:37|fwiw, in my experience trusting things which are made up is more common with my parent's age cohorts than urban, educated teenagers who seem to be skeptics by design
Lalit Pagaria|2023-04-19 08:52:31|Yeah, they are curious but how about keeping things age appropriate for them? ‎[4/19/23, 08:57:00] Nirant: ‎image omitted
Lalit Pagaria|2023-04-19 08:57:50|Thank you 🙏 Really helpful
Nirant|2023-04-19 08:57:56|cc [PHONE] works on making the Google Play Store safe for kids and minors. Would love to hear more product design, generic principles from you 🙏🏼
Nirant|2023-04-19 09:02:49|Since these interfaces will have image (search, generation) soon, there has been academic interest in detecting _sexy_ images as well. These are suggestive, but not porn or nudity. The line gets blurred even more with comics/anime/hentai.  This is a neat project in that direction: https://github.com/GantMan/nsfw_model. I wish they'd share datasets and not just model weights
Madhur Chadha|2023-04-19 09:08:04|Speaking purely in individual capacity   More than companies, I think the governments in various countries are always actively working on rules and regulations around minors and are becoming better at it  Principles vary widely from age to age
Kartik Mandaville|2023-04-19 09:10:05|We've been using this to ensure all questions are safe for works. Works decently well and is a requirement from companies
Madhur Chadha|2023-04-19 09:14:04|This will be super interesting as I do not know of any specific regulation yet....  A lot of big tech typically adds supervision by default for users <13 (Depends on country to country)   I would presume - Chatgpt needs login : so if its something like a gmail account, the parent would know they used it  ChatGPT itself i dont kow if it has build parental controls. I suspect eventually they may....
~ Siddharth Malik|2023-04-19 09:14:25|‎~ Siddharth Malik joined using this group's invite link
Azhan Mohammed Generative AI WhatsApp Group|2023-04-19 09:17:13|Sure, will look into that as well. ‎[4/19/23, 09:17:56] Madhur Chadha: ‎image omitted
Lalit Pagaria|2023-04-19 09:36:21|Kids in my daughter's (10yrs) class are already using it. And she is asking me questions like why can't I use it? I showed this to her but asked why others were able to access it? Why are parents allowing them to use it?  I am having a hard time answering these questions 😅
Madhur Chadha|2023-04-19 09:36:59|ouch
~ Harshad Deo|2023-04-19 09:57:09|‎~ Harshad Deo joined using this group's invite link
~ ~|2023-04-19 10:11:04|‎~ ~ joined using this group's invite link
Bulia Siddharth Aurashop|2023-04-19 10:16:57|Hi! I need one help. How to create a bot which can impersonate me? Currently it can be used to impersonate Elon Musk or someone famous about which ChatGPT already knows. How can I create a ChatGPT who can act like me? There is a token limit on Prompt Engineering, so I can't put my raw data there. What are the alternative ways?
Edgar Monis Mumbai WHO|2023-04-19 10:17:34|Fine tune vicuna on your WhatsApp chats
Akash Chandran|2023-04-19 10:17:58|index n retrive from vectorDB could be a easy quick start
Akash Chandran|2023-04-19 10:18:49|fine-tuning is not to save info . Its to teach a skill to the LLM
Shubham Sharma 2012C6|2023-04-19 10:19:07|Do you think dependence on these for home work affect reasoning abilities in kids?
Bulia Siddharth Aurashop|2023-04-19 10:22:05|I want to use it in ChatBot style. So I want to build it on something like GPT-4 or any other LLMs.  Can we incorporate these embedding with existing LLMs as well?
Lalit Pagaria|2023-04-19 10:22:19|Yes, in my view
Akash Chandran|2023-04-19 10:25:08|yes. you just retrive the relavant context with cosine similarity , and simply feed it into the prompt. with character limit . it should work well . with some prompt engineering + if you using GPT4 put in the system message  to impersonate you based on the context provide. LLM chains
Nirant|2023-04-19 10:26:13|Do you think dependency on Google Search and Saved contacts affect our memory skills?
jyotirmayjk Hackathon|2023-04-19 10:27:10|These are memory recall skills aren’t they ?
Akash Chandran|2023-04-19 10:27:23|hey guy quick intro i'm Akash , we are building a embedding engine specifically for code syntax.  also anyone here worked with Siamese search stuff ?
jyotirmayjk Hackathon|2023-04-19 10:27:50|Parents I guess would be more concerned with reasoning skills being affected coz of using GPT
Bulia Siddharth Aurashop|2023-04-19 10:28:32|Thank you Edgar and Akash! I will check these out!
Nirant|2023-04-19 10:28:58|Our parents were worried about memory and we seem to be doing okay without them 😛
Shashank Generative AI Group|2023-04-19 10:29:22|https://twitter.com/hwchase17/status/1648474409819340801?t=msztWX1rHzcmTfo3Zg2Uvw&s=19  webinar on evaluation by langchain.  OpenAI Evals maintainer will also be here in case anyone is interested in evaluation.
Shashank Generative AI Group|2023-04-19 10:30:04|cue the pessimists_archive twitter handle 😂
jyotirmayjk Hackathon|2023-04-19 10:31:03|🤣🤣🤣 Step 1:Outsource memory Step 2:Outsource reasoning . . Infinite end:Outsource consciousness 😝
Jay Pokarna 2014 BPCC|2023-04-19 10:33:34|Heard it from Altman in the Lex friedman interview that he repeatedly says in the company to treats it's users like adults
Nirant|2023-04-19 10:33:51|cc [PHONE] for questions on QA evaluation and fact checking — since you worked on that problem cc [PHONE] since you are looking at ```openai/evals``` for JEE
Soumendra Dhanee|2023-04-19 10:38:36|I did. Curious how you are thinking of applying it.
Ravi Theja|2023-04-19 10:43:06|GPT4 8k and 32k versions are now available on Azure Openai India as well.
Jay Pokarna 2014 BPCC|2023-04-19 10:46:32|https://twitter.com/varunshenoy_/status/1648374949537775616?s=52  Connecting chatgpt with health data
Ravi Theja|2023-04-19 12:02:08|You could additionally change the object's position and use SD Inpainting, which gives more variation results. [PHONE] has mentioned those in details section of his product here - https://gooey.ai/product-photo-background-generator/
Shashank Generative AI Group|2023-04-19 12:17:22|anyone here using promptlayer or other tools for prompt versioning?  https://promptlayer.com/
Sudharshan GenAI|2023-04-19 12:52:53|Want to use a tool badly - is this good?
~ Rachitt|2023-04-19 12:55:46|Humanloop does A/B testing+versioning of prompts as well
Sudharshan GenAI|2023-04-19 12:59:24|https://www.izzy.co/blogs/robo-boys.html  Has all the code - llama, and modal  Use whatsapp chats for creating a dataset
Shashank Generative AI Group|2023-04-19 13:01:26|haven't used it yet. but they integrate with langchain too.
Shashank Generative AI Group|2023-04-19 13:03:44|btw [PHONE] is also working on this!  portkey.ai
Rohit Aggarwal|2023-04-19 13:05:11|thanks! Yes, I'm going to announce this soon.. we have a few companies in beta right now so happy to help if someone wants a tool that works out of the box
Sourasis Roy|2023-04-19 13:13:34|👍 joined the waitlist
Sandeep Generative AI WhatsApp Group|2023-04-19 13:24:35|‎Sandeep Generative AI WhatsApp Group joined using this group's invite link
Alok Bishoyi|2023-04-19 13:33:13|https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html
Rohit Aggarwal|2023-04-19 13:45:44|interesting attempt at structuring prompts better. guardrail:XML, this:SQL
Alok Bishoyi|2023-04-19 13:49:10|There should be some way to get nudged about cost incurred when running these via LLM calls lol Reminiscent of orphaned resources that get spun up in cloud services
Shashank Generative AI Group|2023-04-19 14:00:33|https://python.langchain.com/en/latest/modules/models/llms/examples/token_usage_tracking.html
Shreya Rajpal Guardrails|2023-04-19 15:08:11|Appreciate the guardrails shoutout! My understanding of AI functions from databricks was different -- essentially, it's an easy way to create a pipeline of applying LLMs to data in a SQL DB using a UDF. This would be an alternative to applying an LLM to data in a DB by creating a pipeline in python where connect to the DB via an ORM, calling the LLM, and then writing the results of the LLM back to the DB via ORM. In comparison, guardrails would slot in around the single LLM call and make sure that the LLM output is correct/validated/structured/etc. Hope this helps!
Nilesh Christopher|2023-04-19 15:10:28|Folks, I have a request.   I ran out of Midjourney prompts while running an experiment. Can someone here run the prompt and share results with me?
Nilesh Christopher|2023-04-19 15:10:40|*/imagine* Indian politician Kamal Nath wearing white kurta, smiling , doing namaste, while meeting 4 tribal people in front of their hut on a hot summer day during an on-ground campaign ahead of elections.
Nirant|2023-04-19 15:11:27|Friends, Nilesh [PHONE] is an engineer-turned-journalist covering Generative AI in India and it's impact on jobs and business
Jay Pokarna 2014 BPCC|2023-04-19 15:20:01|You can try openjourney if it's urgent ‎[4/19/23, 15:20:09] Shashank Generative AI Group: ‎image omitted
Charu Tak|2023-04-19 15:21:36|https://cdn.discordapp.com/attachments/1059408411890028584/1098182375965478963/charu_Indian_politician_Kamal_Nath_wearing_white_kurta_smiling__ada7b30f-2a97-49b7-90ed-5df58d4d1879.png
Nirant|2023-04-19 15:23:15|TIL Discord CDN has no auth!
Swastik Banerjee|2023-04-19 15:23:44|trying out the chatgpt-retrieval plugin.  Pinecone currently seems to have a waitlist for new users Which is the next-best db to use? supported dbs: pinecone, weaviate, zilliz, milvus, qdrant, redis, llamaindex (i know it heavily depends on the usecase…any pointers on how to decide? im just basically trying to create an experimental semantic search over certain documentations)
Pratyush Choudhury|2023-04-19 15:25:06|It's an embedded image right?
Nirant|2023-04-19 15:25:55|just do qdrant if you're running locally, lowest Memory footprint, the cloud has a decent free plan too
Nirant|2023-04-19 15:26:12|full disclosure: trying to sign qdrant as consulting client
Soumendra Dhanee|2023-04-19 15:28:16|Yeah, using SQL lets me do embed ontology a little better, saves me a bit of time doing prompt engineering with vectordbs, but I have a theory about where all this is going to end up
Soumendra Dhanee|2023-04-19 15:28:36|RDF2text2vector
Soumendra Dhanee|2023-04-19 15:29:46|Literally no solution out there allows me to embed both taxonomy and ontology in my text right now, so my workflow is to put both of them in the text first before embedding.
Soumendra Dhanee|2023-04-19 15:30:11|Hopefully someone comes up with RDF2vector directly
Swastik Banerjee|2023-04-19 15:30:21|my dataset has 7.5k rows…shouldn’t be a constraint right? In general, how do people decide over dbs? sorry if this was already discussed here earlier
Soumendra Dhanee|2023-04-19 15:30:46|Weaviate even had an issue in gh for RDF2vec, but it closed due to lack of interest
Nirant|2023-04-19 15:31:20|Less than a million rows should be fine. qdrant CTO told me that they can do entire Wiki with inference usage of ~1.2G RAM 😧
Soumendra Dhanee|2023-04-19 15:32:10|This sounds insane. Wiki text is around 80gb I think.
Soumendra Dhanee|2023-04-19 15:32:51|(not sure that's just English though)
Nirant|2023-04-19 15:35:52|English Wikipedia is the claim
Nilesh Christopher|2023-04-19 15:39:42|Thank you, Shashank.
Sankalp PickYourTrail|2023-04-19 15:52:09|what is the challenge with saving embeddings in a vector variable
Nirant|2023-04-19 15:52:54|In latency sense, for 7.5K rows, I don't think anything is going to beat np.array or torch.tensor on GPU — or FAISS
Amir Nagri|2023-04-19 16:00:59|@here getting really disappointing result when cloning my voice on elevenlabs, any other tool/saas suggestions?
~ Avi|2023-04-19 16:02:48|Checkout out VALL-E's unofficial PyTorch implementation  on GitHub. Facing similar issues with ElevenLabs
~ KJ|2023-04-19 16:03:17|‎~ KJ joined using this group's invite link
Swastik Banerjee|2023-04-19 16:06:45|Is there a way to use np.array for the chatgpt/retrieval-plugin? Didn’t find it in the documentation
Shashank Generative AI Group|2023-04-19 16:12:28|azure tts has a neural voice cloning service i think. haven't used it tho. i only used their presets.
Shashank Generative AI Group|2023-04-19 16:12:59|also Descript has cloning too
Shashank Generative AI Group|2023-04-19 16:26:56|is anyone working on AI financial advisors? change the incentive model.   or is this a bad idea for a product due to some other reason?  https://twitter.com/ravihanda/status/1648596410953244672?t=7l8UC2grkzzutVDWuVBIOA&s=19
Kaushik Bokka|2023-04-19 16:28:48|Chroma has a decent local db support, could start with that as well
Kaushik Bokka|2023-04-19 16:29:40|Simple local dev interface to get started with
Swastik Banerjee|2023-04-19 16:33:30|How to use these custom dbs in chatgpt/retrieval-plugin?? The official documentation says you have to set an ```export DATASTORE=<your_datastore>``` which currently allows only ```pinecone```, ```weaviate```, ```zilliz```, ```milvus```, ```dqrant```, ```redis``` and ```llamaindex``` it seems
Kaushik Bokka|2023-04-19 16:33:51|also, it’s entirely open source. I like knowing the hood, helps to extend, debug and hack around. They will come up with their hosted solution soon
Kaushik Bokka|2023-04-19 16:34:18|under the*
Kaushik Bokka|2023-04-19 16:35:33|Not sure, haven’t checked out the retrieval plugin repo in depth. It kinda looked like a mess when I saw it first lol
Kaushik Bokka|2023-04-19 16:35:49|Probably others could help here
Sankalp PickYourTrail|2023-04-19 16:41:00|Has anyone retrained an open source transformer like llama? Mostly content creators are going gung ho around architectures like few shot learning/vector similarity
Kaushik Bokka|2023-04-19 16:42:10|okay, I checked it out. You could check out this PR branch https://github.com/openai/chatgpt-retrieval-plugin/pull/59 and get started with Chroma
~ kjvenky|2023-04-19 16:49:31|‎~ kjvenky joined using this group's invite link
Karthik CRED|2023-04-19 17:15:00|Did you use it ? Issue with eleven labs is it doesn’t have Indian accent, it works well on American accent
Karthik CRED|2023-04-19 17:15:25|I mean does vall-e not have same issue
Swastik Banerjee|2023-04-19 18:34:23|I opened an issue: https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410 seems system-specific in the hindsight, but couldn’t get it to work Anyone who has used ```chromadb``` with the retrieval plugin?
~ Avi|2023-04-19 19:17:13|I haven't tried it myself, but will patch you in with some folks :)
~ Ravi Trivedi|2023-04-19 19:41:36|Sharing what I wrote today -  TLDR version 4 ways Generative AI can be used in Agriculture for farmers' benefit.  DPGs are gaining importance given rapid innovation around data sets. Agristack by Ministry of Agriculture becomes even more important.  Use Cases for Indian Agriculture 1.  Personalized Advisory to Farmer  - Answers to : What should I do today in field? Does my plant have a disease or pest ? 2.  Eligibility for Government Schemes - Answers to: What schemes can I benefit from? I have this need, is there anything government provides help with? 3.  Monitoring the problems faced by farmers in real time, and proactively managing those at state level. Answers to - What are the top issues facing farmers today in state if Karnataka. Is availability of inputs a challenge today in a region. 4. Personalized training in agriculture - educational content in Agriculture Answers to - I want to do crop diversification to grow Cotton from current Paddy. How do I make the transition? For more details, read the article. https://www.linkedin.com/pulse/4-ways-generative-ai-can-used-agriculture-ravi-trivedi/
Prayank Swaroop Accel|2023-04-19 20:18:38|Has anyone evaluated - DeepSpeed - https://www.deepspeed.ai/ ?
Rohan Babu|2023-04-19 20:19:11|‎Rohan Babu joined using this group's invite link
Nirant|2023-04-19 20:22:13|Deepspeed powers Bloom and LoRA from MSFT — so many people might've tried it without knowing
Nirant|2023-04-19 20:22:29|*tried the output model
Pratyush Choudhury|2023-04-19 20:29:32|Microsoft has always had a history of the most powerful image models - their (Bing) image search capabilities are/were better than Google
Pratyush Choudhury|2023-04-19 20:29:58|Has anyone felt/realized this anecdotally?
Shubham Gupta IIT K|2023-04-19 20:33:47|‎Shubham Gupta IIT K joined using this group's invite link
~ Arvindh|2023-04-19 20:36:40|‎~ Arvindh joined using this group's invite link
Swastik Banerjee|2023-04-19 21:04:36|thanks, that’d be v helpful
Nirant|2023-04-19 21:06:31|qdrant is now a consulting client. Please send Vector DB questions, can spam the CTO on Slack now 😅
Shuvi Shrivastava|2023-04-19 21:08:07|‎Shuvi Shrivastava joined using this group's invite link
Pratyush Choudhury|2023-04-19 21:14:53|If someone asks to choose b/w Redis and Qdrant, what would be your recommendation?
Rahul Bhatnagar|2023-04-19 21:14:57|Does a pod correspond to a pinecone index?   Because 25$ / pod / month is steep. Specially for someone building a low touch / self serve SAAS on top.
Nirant|2023-04-19 21:16:40|Redis for most things atm. qdrant is pointlessly long devX unless you care about low memory footprint in some way
Pratyush Choudhury|2023-04-19 21:17:21|DevEx is the key - long Redis  Somehow I've found it to be faster as well with lower consumption of memory/compute
Pratyush Choudhury|2023-04-19 21:23:18|https://github.com/Stability-AI/StableLM  Unsure how/why the date on it is 20th April but quite a cool release
Prayank Swaroop Accel|2023-04-19 21:35:59|Awesome !!! 🤩
Shimanta Generative AI|2023-04-19 21:42:14|I wanted to know about how the different language models out there today are different. Is it all about the training data, something else?
Shimanta Generative AI|2023-04-19 21:42:43|It’s already 20th April in some parts of the world so… 😅
Pranjal Mehta|2023-04-19 22:19:27|Any benchmark studies on how it's faring compared to existing models?
Dev Aggarwal|2023-04-19 22:21:24|“As is typical for any pretrained Large Language Model without additional finetuning and reinforcement learning, the responses a user gets might be of varying quality and might potentially include offensive language and views. This is expected to be improved with scale, better data, community feedback, and optimisation.”  😆😂
Ashfakh GenerativeAI WA Group|2023-04-19 22:21:52|Have anyone used Weaviate?  Been using it and found it pretty good for self hosting.
Ashfakh GenerativeAI WA Group|2023-04-19 22:22:55|Also, wrt to embedding models, has anyone here done considerable research on which model is better? Ada from openAI is good, but how different is it from sentence transformers from HuggingFace?
Pratyush Choudhury|2023-04-19 22:23:47|Haha... I thought so but then the founding team mostly isn't based out of those areas
Ashfakh GenerativeAI WA Group|2023-04-19 22:25:54|It’s always 4/20 somewhere 💁‍♂️
~ Arvindh|2023-04-19 22:26:29|‎~ Arvindh left
Pratyush Choudhury|2023-04-19 22:28:53|Haven't come across any benchmarks or anecdotal reviews  But param size is similar to LLaMa and (LLaMA is 1T tokens for its 7B model) considering Stability's track record, I'd expect similar results (?)  I'm sure better & smarter practitioners will tinker & let us know soon🙏🏻
Shashank Generative AI Group|2023-04-19 22:33:18|i think Cohere cofounder did a comparison some time back. IIRC, it's a google sheet.
Pratyush Choudhury|2023-04-19 22:34:45|Not sure how many folks have tried the new Bedrock product by AWS but curious if folks think some of it and the aspects of model benchmarks potentially move to AWS
Ashfakh GenerativeAI WA Group|2023-04-19 22:35:42|Any idea where I can find it?
Ravi Theja|2023-04-19 22:36:04|For indian languages cohere multilingual embeddings are having good discrimination based on my experiments.
Shashank Generative AI Group|2023-04-19 22:37:13|https://twitter.com/Nils_Reimers/status/1487014195568775173?t=qKHnPgJn4SvniSxT5SvXiw&s=19  idk if the medium article is updated or not. also correction: he isn't a cofounder at cohere.
"Arpan Desai | MobileFirst"|2023-04-19 22:44:07|https://twitter.com/jerryjliu0/status/1648709029777252352?s=46&t=gjIVQMn9Hp7sUgYs_m23Ww
"Arpan Desai | MobileFirst"|2023-04-19 22:44:25|[PHONE] - again contributing with Evalset generator
Vimal Singh Rathore|2023-04-19 22:57:10|‎Vimal Singh Rathore joined using this group's invite link
~ Lakshay Nagpal|2023-04-19 22:57:48|‎~ Lakshay Nagpal joined using this group's invite link
Ravi Theja|2023-04-19 23:19:13|Thank-you for the mention Arpan.  For the broader set of people, the idea here is to understand how well LLMs are good at doing QA on your documents. The dataset generator and evaluation modules are built to answer this question.  You can check more details here -  Dataset generator module - https://twitter.com/jerryjliu0/status/1648709020382023683?s=20 Evaluation module - https://twitter.com/jerryjliu0/status/1645451894637367298?s=20  Albus ([PHONE] ) is currently using the module in their production. I will be speaking more on this in Saturday’s meet-up.
~ Advait Shankar|2023-04-19 23:55:45|‎~ Advait Shankar joined using this group's invite link ‎[4/20/23, 01:05:42] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-20 01:05:50|Thanks for the mention ravi! ❤️ ‎[4/20/23, 01:13:10] Dev Aggarwal: ‎image omitted
~ NG|2023-04-20 09:12:30|sorry I must have missed. Where is the meet-up ?
Nirant|2023-04-20 09:13:05|BLR, Saturday evening: https://hasgeek.com/generativeAI/april-meetup/
Sachin Legaltech|2023-04-20 10:22:06|https://blog.replit.com/llm-training A good blog post by Replit where they give us high-level description of how they train their own LLMs
Anshul Bhide Replit|2023-04-20 10:44:17|What's amazing is that the team is <5 people :)
Bulia Siddharth Aurashop|2023-04-20 10:45:33|Replit is < 5 people???
Anshul Bhide Replit|2023-04-20 10:47:35|The ML team
Bulia Siddharth Aurashop|2023-04-20 10:48:09|Wow ❤️
Anshul Bhide Replit|2023-04-20 10:49:00|The entire engineering team ~50 people
Dev Aggarwal|2023-04-20 10:49:46|Talent density >> head count ❤️🔥
Shubham Sharma 2012C6|2023-04-20 11:14:39|https://twitter.com/fabianstelzer/status/1648700767992180737?s=48
Shubham Sharma 2012C6|2023-04-20 11:24:55|EyeQuant founder talks about text2film
Pratyush Choudhury|2023-04-20 11:29:27|Proven again and again in the world of Foundational Models - almost all top companies have lean teams
Nirant|2023-04-20 11:33:11|Midjourney is 8 engineers, Replit is 5, OpenAI Whisper was 6 (and 3 of those were Greg Brockman, C. McLeavy and Ilya S.), _Attention is All You Need_ paper had 8 authors  Machine Learning is really riding the coattails of infrastructure folks slogging 😛
Shashank Generative AI Group|2023-04-20 11:36:20|midjourney outsourced frontend to discord 😂
Dev Aggarwal|2023-04-20 11:38:54|https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/  Very interesting article about security and LLMs by one of my favourite programmers
~ Avi|2023-04-20 11:45:51|Cracked crazy adoption
~ Anuraag Gupta|2023-04-20 12:35:51|‎~ Anuraag Gupta joined using this group's invite link
Shivendu Kumar|2023-04-20 12:39:52|Original song by Ariana Grande: https://www.youtube.com/watch?v=DOJremEQw88 Same song in the voice of Dua Lipa (AI-generated): https://www.youtube.com/watch?v=m38CJBHO2RI  This is just soooo good. ✨
Dr. Ashith Generative AI WA Group|2023-04-20 12:58:51|What tech is used for this?
~ Shashank (PushOwl)|2023-04-20 13:06:10|‎~ Shashank (PushOwl) joined using this group's invite link
~ Revant|2023-04-20 13:06:14|‎~ Revant joined using this group's invite link
Ojasvi Yadav|2023-04-20 13:26:57|Are you tracking usage on a per-api key basis? Is this even possible?
~ Rachitt|2023-04-20 13:28:53|OpenAI tracks usage per organisation basis, one way to work through this might be setting up different teams for different keys
Harsh Koo|2023-04-20 13:29:31|I came across https://twitter.com/vboykis/status/1648756882679427072?t=JDfSjZx03Rlj9JHp1IbBpA&s=19  And i resonate with some of this.  Yesterday I tried ChatGPT to write code that could generate patterns for use as a background for quotes (a feature on Koo).  The code failed to run and i prompted ChatGPT with the error and while it kept rewriting the code, I wasn't able to get a version that worked.  Then good old Github search helped me find something useful.  Just wanted to share. Not dumping on ChatGPT. The code that i got would have taken me many hours to piece together and the errors were minor and fixable with more context on the exact library if I spend time with the docs.
jyotirmayjk Hackathon|2023-04-20 13:32:25|Someone had a very good analogy on this : It’s wrong to assume ChatGPT would replace programming jobs ChatGPT is like co-pilot for devs Which implies that you need an experienced pilot to go with it It can’t work like a pilot on its own(yet)
Kartik Mandaville|2023-04-20 13:34:08|just org / no tracking per key possible.  IMO one org is important to develop relationship with OpenAI - lower retention period, support, access to better models, SLA, credits
Harsh Koo|2023-04-20 13:37:36|Well said
Dev Aggarwal|2023-04-20 13:43:44|Tried this last night. Controlnet inpaint model isn’t much better than the regular sd inpaint. The advantage though is that you dont need a custom inpainting checkpoint, so you can inpaint with community models like analog diffusion, openjourney, protogen etc or maybe even a lora model?
Kishore GenAI|2023-04-20 13:49:27|"This is the comment by the author of the controlnet repo: "" OMG i find ControlNet inpaint and A1111 inpaint can work together to achieve perfect seamless and super robust inpaint and at the same time do not change unmasked area"" : https://github.com/Mikubill/sd-webui-controlnet/issues/736#issuecomment-1510598350  Also if you tried directly from the controlnet v1.1 repo , he has added a disclaimer for his gradio file:  ""This gradio demo does not include post-processing. Ideally, you need to post-process the latent image in each diffusion iteration and post-process the image after vae decoding, so that the unmasked area keeps unchanged. However, this is complicated to implement and perhaps a better idea is to make it in a1111. In this gradio example, the outputs are just the original outputs from diffusion, and the unmasked area in your image may change because of the vae or diffusion process.""  I am using mikubil's controlnet extension which fits into automatic1111. I am still experimenting as well. This is less than 4 days of support overall. There are still some bugs which are getting resolved."
Dev Aggarwal|2023-04-20 13:52:21|Thanks. I used diffusers lib with the hugginface checkpoint so yes probably not as good as a1111. The inpainting code in general has always been super well done in a1111, really amazing stuff! What’s the status of a1111’s python api these days? ‎[4/20/23, 13:52:42] Kishore GenAI: ‎image omitted
Kishore GenAI|2023-04-20 13:55:54|I haven't worked with the API yet. So wouldn't know. Also the diffusers library isn't upToDate with the latest release. This is because the repo author is working on integrating it with automatic1111 first.
Dev Aggarwal|2023-04-20 14:01:41|What resolution is this?
Kishore GenAI|2023-04-20 14:02:04|768x512
Dev Aggarwal|2023-04-20 14:02:50|The glass seems to have been modified a bit?
Kishore GenAI|2023-04-20 14:04:11|yeah. I didn't mask correctly. I am testing other aspects of the controlnet.
Dev Aggarwal|2023-04-20 14:08:25|Keep us posted :-) ‎[4/20/23, 14:51:12] Amogh V: ‎image omitted
Nirant|2023-04-20 15:16:13|cc [PHONE] since you opened this thread
Amogh V|2023-04-20 15:17:12|The best way to insert an external object like a glass into another image is to just overlay it in another layer using photoshop or free web based photopea. Export as a single image (img1). Also export an image in the same dimensions but with only the glass and the rest of the background black (img2). Then inpaint over and around the glass in img1. Load img2 into controlnet. Use canny, depth, hed maps or a combo of these based on the kind of object. Adjust the controlnet weight appropriately. Also adjust the weight of the right word in the prompt like (glass:1.2).
Amogh V|2023-04-20 15:20:21|Another way to achieve the same thing is to load just the glass image with transparent bg into controlnet. and only use the canny / depth / hed preprocessor (not the model). Download the map. Position the map image according to your final image dimensions such that it is exactly where you want the generation to happen. Black the rest of the background and export as another image. Load this image into controlnet and this time leave the preprocessor blank. Only select the appropriate model. This works great because your object map is already perfectly positioned where you want it in the image.
Harsh Koo|2023-04-20 15:31:06|This is awesome [PHONE] Thanks a lot for this. I'll update once I have setup Automatic UI.
Lalit Pagaria|2023-04-20 16:12:11|How hard to push per key API results to Prometheus? From there use any UI tool like grafana to monitor per API usages. https://github.com/prometheus/client_python
Kartik Mandaville|2023-04-20 16:40:35|Is anyone using GPT4 in prod? I'm sending gpt-4 as the model but its still using gpt-4-0314. Have heard gpt-4 is much more faster than the 0314
Sunil Ray Analytics Vidya Chief Content Officer|2023-04-20 16:49:23|‎Sunil Ray Analytics Vidya Chief Content Officer joined using this group's invite link
Rohit Ganapathy|2023-04-20 17:02:10|Anyone have any clue if multimodal LLMs are good reading images of documents? Say for OCR.
Ravi Theja|2023-04-20 17:04:29|Which LLM’s? Pix2instruct? Or any other LLM?
Rohit Ganapathy|2023-04-20 17:10:18|say GPT-4? I know the multi-modal functionality is not rolled out yet but curious of  Visual Document Q&A is an application since you can ask it questions about images.
Shimanta Generative AI|2023-04-20 17:11:47|I was just checking out this repo: https://github.com/clovaai/donut
~ Shobhit Jaipurkar|2023-04-20 17:11:51|Tesseract was a great solution for OCR the last time I tried but I'm not sure about it's performance in production environments
Shimanta Generative AI|2023-04-20 17:11:54|Doesn’t use OCR
Ritwik 2013|2023-04-20 17:14:35|I've tried it, hard to fine tune to your use case and get consistent results
Rohit Ganapathy|2023-04-20 17:15:52|Ya tesseract is great. I’m coming from the perspective of one model to rule them all. It’s clear that LLMs have absorbed a lot of vertical NLP usecases. Wondering if I can just use a multimodal LLM in the future for OCR also instead of using tesseract or a AWS/GCP API
Nirant|2023-04-20 17:18:20|In all likelihood, yes. Microsoft's LayoutLMv3 already does OCR: https://huggingface.co/microsoft/layoutlmv3-base
Nirant|2023-04-20 17:24:22|[PHONE] pointed out on DM, Donut also does OCR in a manner of speaking when it does Document Parsing ‎[4/20/23, 17:25:11] Nirant: ‎image omitted
Shimanta Generative AI|2023-04-20 17:26:15|I see. Since they are taking in images, I was thinking there might be some ocr involved
Shimanta Generative AI|2023-04-20 17:27:26|Would something like this be better and faster for resume parsing tasks, compared to feeding the resume text to an LLM and asking it to parse?
Nirant|2023-04-20 17:28:11|Today, or in future?   Today, this'd be faster perhaps because you'll only pass relevant sections to the text-LLM hopefully. Less clutter would make JSON-fixing easier I believe.
Shimanta Generative AI|2023-04-20 17:29:41|Got it, thanks. I was referring for today i guess.
Shimanta Generative AI|2023-04-20 17:29:57|Future changes everyday nowadays 😅
~ Aniket Behera|2023-04-20 17:34:16|‎~ Aniket Behera joined using this group's invite link
Utkarsh Ohm Thoughtspot|2023-04-20 18:00:42|‎Utkarsh Ohm Thoughtspot joined using this group's invite link
~ Rahul|2023-04-20 18:00:56|‎~ Rahul joined using this group's invite link
Ojasvi Yadav|2023-04-20 18:03:11|Sounds reasonable. Additionally, can I audit the requests made to each api key?
Lalit Pagaria|2023-04-20 18:09:13|Labels can be used to pass API key hash or user friendly name (do not pass exact API key :)) https://github.com/prometheus/client_python#labels
~ prakashpvss|2023-04-20 18:19:19|I tried using MM-REACT using hugging face space provided by them. It works much better than Donut. The work uses Reasoning capabilities of LLMs to extract information from visually rich documents
~ prakashpvss|2023-04-20 18:19:44|https://github.com/microsoft/MM-REACT
Shashank Generative AI Group|2023-04-20 18:29:46|https://github.com/Layout-Parser/layout-parser
Shashank Generative AI Group|2023-04-20 18:30:41|last time i checked, langchain had a layout-parser integration for pdfs
~ Pradyumna Bang|2023-04-20 19:22:15|https://blog.eleuther.ai/transformer-math/?s=08
~ Shreyas Prakash|2023-04-20 19:28:11|‎~ Shreyas Prakash left
Yash Pandya|2023-04-20 19:32:36|Optimised implementation for Whisper, faster than real time 🚀 https://twitter.com/sanchitgandhi99/status/1649046650793648128?s=20
Dev Aggarwal|2023-04-20 19:34:22|Sanchit is absolutely killing it
Gokul Krishnan|2023-04-20 19:36:08|Sahi! Anyone know the costs?
Utkarsh Ohm Thoughtspot|2023-04-20 19:37:03|Has anyone tried fine tuning dolly2 yet?
Bulia Siddharth Aurashop|2023-04-20 19:37:52|It is open source  https://github.com/sanchit-gandhi/whisper-jax
Shivendu Kumar|2023-04-20 19:58:46|[PHONE] This was so-vits-svc  https://github.com/voicepaw/so-vits-svc-fork
~ Abhi|2023-04-20 20:05:18|‎~ Abhi joined using this group's invite link
Deep Samsung R&D|2023-04-20 20:29:22|What tools or best practices you guys use for recording LLM experiments (for example, with what change of parameters, how much reasoning/relevancy of retrieved results increased along with tracking metrics like accuracy/precision improvements, finding difficulty in managing ways to look through various Jupyter notebooks etc? W&B is a familiar tool, but want to capture and know the Gist of all the experiments at one place. Looking forward to hearing your suggestions 🙏
Amir Nagri|2023-04-20 22:51:08|https://twitter.com/CohereAI/status/1649097293201547264?t=UsFrQQNyNhdkoqPz8AgcrA&s=19   This is a smart move by cohere, releasing a Wikipedia paragraph embedding dataset, will invite hackers to make their prototypes using cohere model, get traction in this competitive market
Amir Nagri|2023-04-20 22:53:04|Given the model specificity for any operations, the more open and accessible you are, the more acceptance you will have by early adopters, more traction you will get
Amir Nagri|2023-04-20 22:54:14|Cmiiw, stability haven't made their latest stable diffusion model available to public and is only available on their dreamstudio ui, right?
‪+91 80783 86131‬|2023-04-20 23:06:09|‎‪+91 80783 86131‬ left
Sudharshan GenAI|2023-04-20 23:28:18|minigpt-4 is better
Sudharshan GenAI|2023-04-20 23:30:32|and https://llava-vl.github.io/ is very good too. Does well on gpt-4 samples
Sudharshan GenAI|2023-04-20 23:36:26|https://twitter.com/marty_catboy/status/1649032460573745152  ...
Sudharshan GenAI|2023-04-20 23:37:03|Martin Shkreli's AI launch
Prayank Swaroop Accel|2023-04-20 23:56:45|Btw very nice talks going on live at Weights & Biases LLMOps London event - https://www.youtube.com/watch?v=YfBtytGNEKE ‎[4/21/23, 00:02:26] Prayank Swaroop Accel: Current Best Practices for Training LLMs from Scratch - Final.pdf • ‎23 pages ‎document omitted
~ Rohit|2023-04-21 00:13:36|‎~ Rohit joined using this group's invite link
~ Debashish Ghatak|2023-04-21 00:29:18|‎~ Debashish Ghatak joined using this group's invite link
Ojasvi Yadav|2023-04-21 02:16:58|This guy says he used langchain  https://twitter.com/ankur_maker/status/1648349266006495237?s=20  to make this https://www.producthunt.com/posts/autogpt-an-autonomous-gpt-4  How is this not a simple UI over the auto-GPT library? If not, then in what capacity could he have used LangChain here?
Shashank Generative AI Group|2023-04-21 02:27:24|WebGPT - run gpt models entirely on the browser. based on WebGPU.   https://twitter.com/willdepue/status/1649147091573432321?t=JJxHljJSm46bWzjqoyr7ag&s=19
Kaushik Bokka|2023-04-21 02:35:43|damn. WebGPU seems to be a great ROI for folks building apps that concerns client privacy
~ Shouvik Ghosh Roy|2023-04-21 07:12:51|‎~ Shouvik Ghosh Roy joined using this group's invite link
Shashank B Designer|2023-04-21 07:38:09|Absolutely love this resource!  Google search for LLM Engineering returns junk results.  Folks, Are there other links  you recommend?
Pratyush Choudhury|2023-04-21 08:23:52|https://kubiya.ai/  Unsure if this has been discussed before but found it to be a very nifty product
Pratyush Choudhury|2023-04-21 08:24:00|Has anyone tried something similar?
Nirant|2023-04-21 08:30:25|What caught your eye? Why is this interesting?
Pratyush Choudhury|2023-04-21 08:35:24|Can apply helm charts, debug, rollback on K8s clusters all via using a chat interface using natural language  I think it's a very good attempt at simplifying the end user experience
Shan|2023-04-21 09:09:01|Well computer engineering goes in circles. It all started with command lines, then started becoming fancier, spent enormous efforts building GUIs and now after all the decades of innovation we are back to … command lines 😆(essentially)
~ ➕📆|2023-04-21 09:33:34|😆😆
~ Ravi Trivedi|2023-04-21 09:37:34|https://blog.replit.com/llm-training this one
~ Santosh|2023-04-21 09:42:16|‎~ Santosh joined using this group's invite link
~ Akarsh|2023-04-21 09:43:18|‎~ Akarsh joined using this group's invite link
~ Siddie|2023-04-21 09:49:23|‎~ Siddie left
Poorvi Vijay Elevation SAIF|2023-04-21 09:52:01|‎Poorvi Vijay Elevation SAIF joined using this group's invite link
~ Akash Rathi|2023-04-21 10:01:30|‎~ Akash Rathi joined using this group's invite link
Amogh V|2023-04-21 10:03:29|I presented a talk on advanced stable diffusion techniques for a hackathon yesterday. It covers how to inpaint and use controlnet within the inpainting mask.  https://www.twitch.tv/videos/1798833016?t=0h34m44s
Amogh V|2023-04-21 10:03:50|Like this technique
Prayank Swaroop Accel|2023-04-21 10:09:23|I was hearing it live ! Pretty awesome talk Amogh !
Amogh V|2023-04-21 10:11:37|Thanks!
~ Sohil Bhagat|2023-04-21 10:28:23|‎~ Sohil Bhagat joined using this group's invite link
Amir Nagri|2023-04-21 11:01:07|You didn't pray to the demo Gods, they almost tested you there 😂
Amir Nagri|2023-04-21 11:04:34|Good demo and techniques there 👏
Amogh V|2023-04-21 11:05:08|I was going to do pre recorded videos but [PHONE] keeps me so busy at Dashtoon that I had no time and had to wing it live 😛
~ Shubham|2023-04-21 11:06:20|‎~ Shubham joined using this group's invite link
~ Satya Bharadwaja|2023-04-21 11:13:14|‎~ Satya Bharadwaja joined using this group's invite link
Harsh Gupta Felvin|2023-04-21 11:26:51|Is there any good drawing to 3D tools out there
Nirant|2023-04-21 11:27:12|cc [PHONE] is a 3d artist and has worked with NeRFs
Sudharshan GenAI|2023-04-21 11:30:15|https://www.reddit.com/r/StableDiffusion/comments/12etqvx/tutorial_creating_a_consistent_character_as_a/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
Sudharshan GenAI|2023-04-21 11:30:21|Create consistent AI characters across images with SD
Sudharshan GenAI|2023-04-21 11:30:37|Is there an AI art/ text to image group? [PHONE] [PHONE]
Nirant|2023-04-21 11:32:37|"This is the one for now — hence the ""DeepMedia"" in the name!"
Nirant|2023-04-21 11:35:48|‎POLL: Do you promise to share links and be generally helpful if we were to make a separate group for text to media (images, video, music)? ‎OPTION: Yes (51 votes) ‎OPTION: No (4 votes)
Soumyadeep Mukherjee|2023-04-21 11:36:10|I agree on separate image group too 😅
Soumyadeep Mukherjee|2023-04-21 11:36:50|Text is so much more popular but would want to have 100% coverage on images.
Nirant|2023-04-21 11:37:54|I'd like that as well. There are about 300 odd folks who haven't muted this group (yet) — so if more than 10% (>30) folks say yes in the poll, let's do it!
jyotirmayjk Hackathon|2023-04-21 11:37:55|Can we join if we are noobs looking to start in deep media ?
Soumyadeep Mukherjee|2023-04-21 11:39:04|[PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE]  please vote :P
Sanyam Bhutani|2023-04-21 11:39:32|I’ve not muted
~ kjvenky|2023-04-21 11:39:48|‎~ kjvenky left
Sanyam Bhutani|2023-04-21 11:39:52|It’s actually a really high quality group. I’ve met some really smart people on here 🫡
Soumyadeep Mukherjee|2023-04-21 11:40:08|I agree.
Soumyadeep Mukherjee|2023-04-21 11:40:23|But from discussion standpoint, just want images/video specific place too 😅
~ ボルツザマク|2023-04-21 11:42:20|Hey, can we make a public xlxs doc where we can put all the links and a short description about the link. Because a lot of people are already sharing lots of links and it's hard to keep track of .
Nirant|2023-04-21 11:42:33|Yessss. Beginners are welcome in the community! This is why I personally take the pain to dig up everything from UI components to VectorDB benchmarks for questions asked here!
Nirant|2023-04-21 11:42:55|Working on this. Releasing next Friday.
Ojasvi Yadav|2023-04-21 11:44:18|Hero we deserve
~ ボルツザマク|2023-04-21 11:44:34|Thanks, man. I recently got into LLMs stuff, so I'm missing the text to image and basically all the new recently released techniques on the image generation. This will really be helpful.
Aditya Agrawal SuperU|2023-04-21 11:45:13|There should be an option for Not Applicable
Sudharshan GenAI|2023-04-21 11:45:21|Agree!
Nirant|2023-04-21 11:45:27|"Yeah, that's ""No"""
Amir Nagri|2023-04-21 11:47:02|there are already like 5 groups in this community, it's becoming like the slack channel hell 😂
Vignesh Baskaran|2023-04-21 11:47:13|Yes please. Separate image group please
Sudharshan GenAI|2023-04-21 11:48:16|Ah! Have a lot of controlnet, SD and text to video stuff I’d love to share and have deeper discussions. Have felt this group is more towards LLMs and NLP and image stuff doesn’t get discussed as much.
Aditya Agrawal SuperU|2023-04-21 11:48:50|Haha “NO” can be rude
Aditya Agrawal SuperU|2023-04-21 11:48:51|😂
Nirant|2023-04-21 11:50:27|And much like Slack, the expectation is that you've 1-2 core channels where you contribute actively, sporadically in 2 more and lurk in the rest :)
Soumyadeep Mukherjee|2023-04-21 11:50:42|Dont follow all is the secret to all slack groups :D
Yash Pandya|2023-04-21 11:50:43|You can just choose to not vote 😅
Dhruv Anand|2023-04-21 12:15:44|I promise to contribute more actively to the resultant text-only group :)
Rasagy Sharma|2023-04-21 12:36:36|Guess I tipped the balance. Can us commoners get a new group? 😬
Nirant|2023-04-21 12:41:47|DeepMedia: Generative Art (Text to Images, Video, Music)  https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J ‎[4/21/23, 12:42:18] Rasagy Sharma: ‎GIF omitted
Aditya Agrawal SuperU|2023-04-21 13:14:11|Haha [PHONE]  we need a Text to Action group as well for the next revolution in AI ..
Amir Nagri|2023-04-21 13:14:49|New poll please
Aditya Agrawal SuperU|2023-04-21 13:15:00|Early joiners beer on me 🍺
Nirant|2023-04-21 13:15:28|Yes sir, in couple of weeks when we've more people interested in actions :)
Aditya Agrawal SuperU|2023-04-21 13:16:21|Haha 😂  I know an expert in building AI community..
~ Rachitt|2023-04-21 13:19:08|folks, noob request here.  I've built plug and play GPT wrappers, but I want to understand the basics of how LLMs work in detail, any resources for a deeper dive into understanding it from scratch?  Thank you :D
Nirant|2023-04-21 13:21:27|Illustrated Transformers: https://jalammar.github.io/illustrated-transformer/  Transformer Family: https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/
~ Rachitt|2023-04-21 13:21:49|Thanks a ton Nirant!
~ Shreyas Nair|2023-04-21 13:33:43|‎~ Shreyas Nair joined using this group's invite link
~ Tejeshwi Sharma|2023-04-21 13:48:59|‎~ Tejeshwi Sharma joined using this group's invite link
~ Aman|2023-04-21 13:52:26|https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ  Neural Networks: Zero to Hero - Andrej Karpathy
Dhruv Anand|2023-04-21 14:19:12|https://docs.google.com/spreadsheets/d/1G0_r4gg4tb0ZE1VQlp-pGLprJ-0qL44VoK7-39EDIO4/edit?usp=sharing quick and dirty effort on this
~ ボルツザマク|2023-04-21 14:21:20|🙇‍♂️ thanks, my weekend will go well
Shivendu Kumar|2023-04-21 14:41:42|Really nice. Did you write a script for whatsapp web?
Nirant|2023-04-21 14:42:45|Can export chat to plain text and regex on it :)
Dhruv Anand|2023-04-21 14:43:05|yeah this. now tweaking to get context. almost done
Nirant|2023-04-21 14:43:29|Langchain it! Release code to Github. I'll add the features I'm working on as well.
Arnav Kumar|2023-04-21 14:43:48|‎Arnav Kumar joined using this group's invite link
Lalit Pagaria|2023-04-21 14:45:34|My Ola's ex-colleague built this. See if this is helpful   https://supergroup.ai/
~ Balamurali A R|2023-04-21 14:53:07|‎~ Balamurali A R joined using this group's invite link
~ Yashwini|2023-04-21 15:31:26|‎~ Yashwini joined using this group's invite link
Shashank B Designer|2023-04-21 15:36:33|"""Researchers are exploring a curious phenomenon known as in-context learning, in which a large language model learns to accomplish a task after seeing only a few examples"" (from https://news.mit.edu/2023/large-language-models-in-context-learning-0207 )   So this an emergent property and we don't know how it happened! wtf! Anyone knows how few-shot / in-context learning works?"
~ Siddharth Srikanthan|2023-04-21 15:37:47|‎~ Siddharth Srikanthan joined using this group's invite link
~ prakashpvss|2023-04-21 15:39:54|https://arxiv.org/abs/2303.12712 in this paper Microsoft researchers who had early access describes to an extent how they think it works. Finally they also conclude they don't know how it works 🙁 ‎[4/21/23, 15:44:36] ~ prakashpvss: ‎image omitted
~ NG|2023-04-21 15:53:34|How did you do this so quickly
Dhruv Anand|2023-04-21 15:54:58|export chat+pandas
Dhruv Anand|2023-04-21 15:55:05|+github copilot ofc
Sidhant Sequoia|2023-04-21 15:57:34|‎Sidhant Sequoia joined using this group's invite link
~ Sanjeed|2023-04-21 15:58:19|"Love how ""Langchain it"" is becoming a verb here"
Shivendu Kumar|2023-04-21 16:45:37|"Am sorry if I'm missing something here. What's new in this? Isn't this what we have been doing in most LLM apps? Just feed the context. Model won't ""learn"" anything."
Dev Aggarwal|2023-04-21 16:47:39|In context learning examples include input/output pairs, not just stuffing data into the prompt
~ Srinivasan Nandakumar|2023-04-21 16:53:09|There is an interesting Microsoft paper that checks the values at various layers of the transformer when giving examples in the prompt vs fine tuning the models with the same examples for 1 epoch. They find similar values in both and have a theory that prompting with examples causes implicit gradient descent which helps the model perform on the unseen example.
~ Shristi|2023-04-21 18:49:15|‎~ Shristi joined using this group's invite link
~ Nikhil|2023-04-21 19:22:20|‎~ Nikhil joined using this group's invite link
~ Abhinav|2023-04-21 21:13:59|‎~ Abhinav joined using this group's invite link
Krishna Ntkris|2023-04-21 21:46:42|Question for the embeddings experts in this group: say I have a hybrid index on Pinecone. Then during my query, I *only* input dense (semantic) embeddings, what happens? Does this mean it will query only using the dense embeddings or am I likely to get bad results?
Nirant|2023-04-21 21:47:32|With Pinecone, we don't know. We'll have to read their docs
Krishna Ntkris|2023-04-21 21:48:39|okay cool, i will do some digging and report back here as Im sure its useful to others. FWIW I'm migrating from dense only -> sparse + dense and a lot of these little questions come up
Soumendra Dhanee|2023-04-21 21:59:59|Same story here, would be interested in hearing more about your experience (will share mine once I have gone through it)
~ Rohan|2023-04-21 22:58:13|Text to (relatively) high res video is here: https://research.nvidia.com/labs/toronto-ai/VideoLDM Code not released yet, but someone may be able to reverse engineer the method from the details in the paper one way or another.
~ Irfan|2023-04-21 23:33:15|‎~ Irfan joined using this group's invite link
Bulia Siddharth Aurashop|2023-04-22 00:55:58|Hi, I am bit new with using GPU. I want to train/run few models.  Which GPU providers do you suggest? I was checking AWS series but they seem very costly. I only need 1 GPU for now. Also, is it worth to buy the hardware itself rather than renting on the cloud?
~ The Last Samurai|2023-04-22 00:57:29|You can try this if it works for you https://colab.research.google.com/drive/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing
~ The Last Samurai|2023-04-22 00:58:33|You can get a free tesla T4 from google
Bulia Siddharth Aurashop|2023-04-22 00:59:50|You mean Google Colab? Actually I need to download lots of data and do it on a recurring basis, so colab notebook won't fit. I will try this anyway :(
Sachin Legaltech|2023-04-22 01:03:12|https://fullstackdeeplearning.com/cloud-gpus/ This comparison table might be useful.
Bulia Siddharth Aurashop|2023-04-22 01:04:03|Thank you Sachin and The Last Samurai. I will go through these links!
Nirant|2023-04-22 01:10:09|Industry's best kept secret: Kaggle Notebooks! You can have the data uploaded to Kaggle even. You often get better GPUs than Colab and lot more storage.
Bulia Siddharth Aurashop|2023-04-22 01:17:08|Wow! I think this will solve my problem! Thank you Nirant!!
Rohit GenerativeAI WhatsApp Group|2023-04-22 01:28:04|also there are ways to use ngrok and vscode with these hosted notebooks so that you can code with scripts and still use these GPU resources for free. It's like you have your own GPU system. In colab it used to work, you can try it with kaggle notebook too
Bulia Siddharth Aurashop|2023-04-22 01:38:01|https://www.freecodecamp.org/news/how-to-use-google-colab-with-vs-code/ You are talking about this? Let me try!
Bulia Siddharth Aurashop|2023-04-22 01:42:43|Seems like they have banned it  https://github.com/abhishekkrthakur/colabcode/issues/110  But this is a really great hack!!
Amir Nagri|2023-04-22 07:24:32|Cheapest for model fine tuning i found is rtx5000, runpod.io have reserved and on demand
Bulia Siddharth Aurashop|2023-04-22 10:44:48|Thank you!!
Bulia Siddharth Aurashop|2023-04-22 10:51:02|I am actually failing to understand the pricing of cloud gpus. Rtx 5000 gpu cost 1.5L While on cloud, even with the cheapest you will pay Rs 11k everymonth. So if I buy the GPU permanently and host it - I can get my returns just in 13 months. That’s a great business model. Even if it is on-demand - assuming AI is here to stay (ofcourse), I should be able to get returns in 2 years. What part am I missing here? Are there any cloud gpu providers in India?
Amir Nagri|2023-04-22 10:53:09|You need economies of scale, not considering maintenance and over head
Amir Nagri|2023-04-22 10:53:22|Also interests rate on capital investment
Nirant|2023-04-22 10:53:23|e2e networks give some GPUs.   But most GPUs get outdated within 12-18 months due change in RAM expectations or new models. Also datacenter GPUs are wayyy faster than retail ones for high volume data transfer.
Amir Nagri|2023-04-22 10:54:45|Also the current price point is similar across many providers, so we already have an optimum price discovery for this asset
Bulia Siddharth Aurashop|2023-04-22 10:58:18|Got it guys! Thanks. This makes sense.
~ Mohit Garg|2023-04-22 11:09:42|‎~ Mohit Garg joined using this group's invite link
~ Mayank|2023-04-22 12:04:46|I have one.  Add 50k for cooling and 40-60k for a good cpu. After that you need a constant power supply of at least 700w. I had 1200w psu , got damaged due to voltage /power fluctuations in blr.
~ Priyadharshini|2023-04-22 12:05:35|https://vast.ai/
~ Priyadharshini|2023-04-22 12:05:52|Any reviews on this cloud GPU rental
~ Mayank|2023-04-22 12:08:12|16Gb memory is not enough.
~ Shreya|2023-04-22 13:08:50|‎~ Shreya joined using this group's invite link
~ Akshay Naik|2023-04-22 15:23:16|‎~ Akshay Naik joined using this group's invite link
~ Saumya|2023-04-22 15:24:19|‎~ Saumya joined using this group's invite link
~ Abhimanyu|2023-04-22 15:24:45|‎~ Abhimanyu joined using this group's invite link
~ Shresht and Sutanu|2023-04-22 15:24:46|‎~ Shresht and Sutanu joined using this group's invite link
Anshul Khandelwal Invideo|2023-04-22 15:25:57|‎Anshul Khandelwal Invideo joined using this group's invite link
‪+91 85500 05447‬|2023-04-22 15:28:28|‎‪+91 85500 05447‬ joined using this group's invite link
~ kaushik c m|2023-04-22 15:30:01|‎~ kaushik c m joined using this group's invite link
~ Vibhas|2023-04-22 15:32:53|‎~ Vibhas joined using this group's invite link
~ Annapurna|2023-04-22 15:36:45|‎~ Annapurna joined using this group's invite link
~ Nayan Shah|2023-04-22 15:37:35|‎~ Nayan Shah joined using this group's invite link
Ambarish Ganguly|2023-04-22 15:37:35|Last weekend I had  posted a question on how if I used Sentence Transformers  for word embeddings the container image size was huge. The reason it was using Torch GPU image. You can reduce the size drastically  if use the Torch CPU image. This is common sense , but for those who may be struggling like me this might be useful
Ambarish Ganguly|2023-04-22 15:38:14|The Docker file will have this RUN pip3 install torch --index-url https://download.pytorch.org/whl/cpu for my Linux machine
Ambarish Ganguly|2023-04-22 15:38:19|Hope this is useful
~ Jatin|2023-04-22 15:41:29|‎~ Jatin joined using this group's invite link
~ Sundarrajan|2023-04-22 15:42:11|‎~ Sundarrajan joined using this group's invite link
~ Sudhanshu Heda|2023-04-22 15:43:13|Hi, How can you enable multiple checkpoints in automatic1111?
Amir Nagri|2023-04-22 15:50:53|While fine tuning the model using dreambooth?
~ Sudhanshu Heda|2023-04-22 15:51:20|Yeah
~ Arpit|2023-04-22 15:55:32|‎~ Arpit joined using this group's invite link
~ Ramanathan Murugappan|2023-04-22 15:56:59|‎~ Ramanathan Murugappan joined using this group's invite link
~ Sangeeth|2023-04-22 15:59:16|‎~ Sangeeth joined using this group's invite link
~ Subhrajit  Dey|2023-04-22 16:03:18|‎~ Subhrajit  Dey joined using this group's invite link
~ Rahul|2023-04-22 16:03:54|‎~ Rahul joined using this group's invite link
Lohith GenerativeAI WhatsApp Group|2023-04-22 16:08:40|‎Lohith GenerativeAI WhatsApp Group joined using this group's invite link
Arvind N Generative AI Group|2023-04-22 16:26:33|‎Arvind N Generative AI Group joined using this group's invite link
~ Aishwarya|2023-04-22 16:29:25|‎~ Aishwarya joined using this group's invite link
~ Shubhra Prakash|2023-04-22 16:33:51|‎~ Shubhra Prakash joined using this group's invite link
~ Mangesh Joshi|2023-04-22 16:40:39|‎~ Mangesh Joshi joined using this group's invite link
Dhruv Anand|2023-04-22 16:44:20|Awesome. If you have any public images/code, please share. Thanks
~ Kaushik Jaiswal|2023-04-22 16:48:28|‎~ Kaushik Jaiswal joined using this group's invite link
~ raj()|2023-04-22 16:52:45|‎~ raj() joined using this group's invite link
~ Nivesh|2023-04-22 17:23:44|‎~ Nivesh joined using this group's invite link
Shalabh Aspiro|2023-04-22 17:58:33|‎Shalabh Aspiro joined using this group's invite link
~ Sachin Patalasingh...|2023-04-22 17:59:14|‎~ Sachin Patalasingh... joined using this group's invite link
Prayank Swaroop Accel|2023-04-22 18:00:59|Folks will we get the recording or decks of today's talks ?
Nirant|2023-04-22 18:02:39|Decks yes. I'll email them to the email on the registration one.   Recordings, Hasgeek will need some time to edit up
‪+91 98806 60620‬|2023-04-22 18:02:46|‎‪+91 98806 60620‬ joined using this group's invite link
~ Vijay Choudhary|2023-04-22 18:09:13|‎~ Vijay Choudhary joined using this group's invite link
~ Amit|2023-04-22 18:10:54|‎~ Amit joined using this group's invite link
~ Gayatri|2023-04-22 18:49:50|‎~ Gayatri joined using this group's invite link
~ Yogesh Sangtani|2023-04-22 19:06:37|‎~ Yogesh Sangtani joined using this group's invite link
~ Anand|2023-04-22 19:12:19|‎~ Anand joined using this group's invite link
Vamshi|2023-04-22 19:16:58|‎Vamshi joined using this group's invite link
Sirisha Bavireddy H2O|2023-04-22 19:25:32|‎Sirisha Bavireddy H2O joined using this group's invite link
~ Ashwinkumar Jayagopi|2023-04-22 19:41:27|‎~ Ashwinkumar Jayagopi joined using this group's invite link
Rhythm Gupta IITD|2023-04-22 20:27:24|Hey guys, what’s the solution to privacy while using chatGPT? Most enterprises don’t want to risk sharing their sensitive information to chatGPT?  If not chatGPT, What’s the cost/ROI analysis on which model to use etc?
Arvind N Generative AI Group|2023-04-22 20:29:41|We are getting into the realm of fine-tuned domain specific language models that can run on consumer grade GPUs and even CPUs.
Gokul Krishnan|2023-04-22 20:36:14|What are the usecases where privacy is of utmost importance+you can't go lower in size than chatGPT to achieve expected results?
Shashank B Designer|2023-04-22 20:36:45|Thanks for organising the event! [PHONE] and others (whose names I didn’t catch 😅)
Gokul Krishnan|2023-04-22 20:36:53|IIRC, GPT-4 launched with McKinsey as a client. Maybe they can use that to assuage any privacy concerns
Shashank B Designer|2023-04-22 20:37:18|Then lightning rounds were good. Would like to hear more of what others have been building..
Ambarish Ganguly|2023-04-22 21:10:07|"FROM python:3.8-slim-buster COPY . /app WORKDIR /app RUN pip3 install torch --index-url https://download.pytorch.org/whl/cpu RUN pip install -r requirements.txt EXPOSE 8000 CMD [""uvicorn"", ""main:app"", ""--host"", ""0.0.0.0"", ""--port"", ""8000""]"
~ Deepak Khatri|2023-04-22 21:40:01|‎~ Deepak Khatri joined using this group's invite link
Aakash Kumar  Matrix Partners|2023-04-22 21:47:49|‎Soumyadeep Mukherjee added Aakash Kumar  Matrix Partners
The GenerativeAI Group|2023-04-22 21:48:11|‎Soumyadeep Mukherjee added ~ Lalith Gudipati and ~ Sanidhya
Shan|2023-04-22 21:54:02|https://www.qblocks.cloud/ is run by a friend. You can try it out and if needed I can put you in touch with the founder. I’ve used it frequently and it worked great for my use case
~ Aravinth Kumar|2023-04-22 21:55:23|‎~ Aravinth Kumar joined using this group's invite link
Rhythm Gupta IITD|2023-04-22 22:40:34|Will DM you!
Rhythm Gupta IITD|2023-04-22 22:53:36|Privacy is important as a principle for enterprises. What’s the best way to figure out which model will work for a particular use case? Any blog/advice on that?
~ Rajat|2023-04-22 22:56:59|‎~ Rajat joined using this group's invite link
Anudeep Yegireddi|2023-04-22 23:52:54|Have y’all seen this:  https://www.essence-ai.io/  You input the song name, lyrics and singer names and it will tell you what the underlying meaning of the song lyrics are.  I tried it on Doobey, from that Gehraiyan movie and it gave a scary good answer. Obviously shits on other songs, but for my use case of 1, it was pretty amazing.
~ Murchana Adhikary|2023-04-22 23:56:34|‎~ Murchana Adhikary joined using this group's invite link
Vamshi|2023-04-23 00:03:40|Looks interesting.   In case you follow such work, any chance you remember the little GitHub repo which created generative models for sample libraries?  I think it was trained using for techno drum loops. You could drop a sample library and run his script to randomly generate a new sample in the same style.  Audio to audio model.
Puneet Lamba Aspiro|2023-04-23 00:05:46|‎Puneet Lamba Aspiro joined using this group's invite link
~ Pranoot Hatwar|2023-04-23 00:31:12|‎~ Pranoot Hatwar joined using this group's invite link
Anudeep Yegireddi|2023-04-23 00:38:44|I can look around, but nothing comes top of mind.
Bulia Siddharth Aurashop|2023-04-23 01:26:45|Thank you!! I will reach out :D
Vamshi|2023-04-23 05:34:37|Thanks!
Rahul Rai|2023-04-23 06:26:47|Does anyone have access to Anthropics pitch deck?  https://techcrunch.com/2023/04/06/anthropics-5b-4-year-plan-to-take-on-openai/
Arvind N Generative AI Group|2023-04-23 06:44:43|OpenAI's John Schulman gave an interesting talk at Berkeley last week on why RLHF was needed to get the instruct models to behave nicely.   Yoav Goldberg interprets the talk and makes a convincing argument about the signals in the RLHF training regime as opposed to pure supervision based fine-tuning.  https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81
~ Sairam Chitreddy|2023-04-23 08:15:50|‎~ Sairam Chitreddy joined using this group's invite link
Alok Bishoyi|2023-04-23 08:21:21|First instance of an Indian politician referring to deepfakes / audio synthesis?  https://twitter.com/ptrmadurai/status/1649792158902173697?s=46&t=oCZGQA9ou-MHG2nmvsr-CA
~ Sairam Chitreddy|2023-04-23 08:31:41|Hi all, I've just joined this group. Can anyone please share the links to the slides for yesterday's talks?? ‎[4/23/23, 09:30:31] Prayank Swaroop Accel: ‎image omitted
Nirant|2023-04-23 09:31:38|course.fast.ai for being able to make sense of all of this — even as it changes in 2-3 months and we add VQA (Vision) to mainstream OpenAI APIs
Nirant|2023-04-23 09:33:31|"Lot of new work should come from STT and TTS side, including performance improvements like Whisper-JAX in the coming 4-6 month and more important, voice cloning, avatars and the like. They should have their own ""Lensa moment"" as such if someone markets it well."
Nirant|2023-04-23 09:34:56|Stable Diffusion/Generative video?
Prayank Swaroop Accel|2023-04-23 09:35:31|Not for beginners I think... but I should say Stable Diffusion does get people hooked ... I got hooked like that 🙂
Amir Nagri|2023-04-23 09:35:31|Depends if your friend would like to get more into theory or hands on applications
Prayank Swaroop Accel|2023-04-23 09:35:54|most devs want hands on first i think
Amir Nagri|2023-04-23 09:38:12|This is good learning path, only it skips all the LLM theory
Amir Nagri|2023-04-23 09:45:32|if i had to recommend a course to cover the NLP hands-on with theory - https://www.udemy.com/course/nlp-with-transformers/  if you like his teaching style, all the future videos on advance topics are available here for free - https://www.youtube.com/@jamesbriggs/playlists https://www.pinecone.io/learn/nlp/
~ Girish|2023-04-23 09:48:32|‎~ Girish joined using this group's invite link
Azhan Mohammed Generative AI WhatsApp Group|2023-04-23 11:20:51|This used to be super helpful when heroku was free and we could deploy our applications on heroku. Last I remember, Torch CPU and other packages took less than 500mb to deploy
Azhan Mohammed Generative AI WhatsApp Group|2023-04-23 11:21:15|Was talking about this
Nirant|2023-04-23 11:33:44|You can still pretty affordable (about $2/mo) instances on Fly.io
Anshul Bhide Replit|2023-04-23 12:38:31|If there's anyone interested, Mckay Wrigley is starting a course on Replit on AI dev. The advanced stuff is coming soon but here's the day 0 course. https://twitter.com/mckaywrigley/status/1649492404943323136  You can signup here - https://www.takeoff.school/
Azhan Mohammed Generative AI WhatsApp Group|2023-04-23 12:48:16|Thanks
Kishore GenAI|2023-04-23 13:15:18|controlnet Inpaint guidelines for A1111. https://github.com/Mikubill/sd-webui-controlnet/issues/968 [PHONE] you can try out with this and let me know how it is working for you.   Also [PHONE], saw your twitch where you mentioned segment anything. You can integrate it with A1111 with https://github.com/continue-revolution/sd-webui-segment-anything.
Kishore GenAI|2023-04-23 13:15:53|From the author of controlnet repo:   Now the ControlNet Inpaint can directly use the A1111 inpaint path to support perfect seamless inpaint experience. It supports arbitary base model without merging and works perfectly with LoRAs and every other addons.
~ Shreyas Gupta|2023-04-23 14:43:00|‎Ravi Theja added ~ Shreyas Gupta
~ Shreyas Gupta|2023-04-23 14:48:56|Hi everyone! Shreyas here, I’m a product designer at Clari working on revGPT, a chat interface to get on top of everything happening with sales in an organisation ( and a few personal projects:) ).   Also, yesterday’s meetup was amazing!
Shimanta Generative AI|2023-04-23 16:52:21|I saw this tweet by the guy who made BabyAGI, with a new approach to vector search & embeddings: https://twitter.com/yoheinakajima/status/1650049673770725378?s=46&t=WT1iAtjftW-5_e62F8FZTg
Shimanta Generative AI|2023-04-23 16:53:01|He then goes on to say that the “paper”, the code, and the twitter thread as well, were all created with ChatGPT
Shimanta Generative AI|2023-04-23 16:53:25|Can the experts here explain if this is all fluff or has actual basis?
Shimanta Generative AI|2023-04-23 16:53:36|https://yoheinakajima.com/asymmetrix-asymmetric-vector-embeddings-for-directional-similarity-search/
Aakash Kumar  Matrix Partners|2023-04-23 16:55:56|Not fluff. Nakajima has been tinkering with AGI for long
Shimanta Generative AI|2023-04-23 16:56:43|Yep. I was referring to this new technique for vector search which he came up with, or chatgpt came up with
Rahul Bhatnagar|2023-04-23 17:11:30|Lol. He literally said he has idea what it does.  https://twitter.com/yoheinakajima/status/1650054082852438017
Shimanta Generative AI|2023-04-23 17:13:43|Well I didn’t say he didn’t knew what he’s talking about or that what he’s speaking is fluff. I was wondering if the method and the code outlined is actually something new and works as proposed
Aakash Kumar  Matrix Partners|2023-04-23 17:15:09|Yep. Still assimilating. Atleast from a reco system lens can comment : in theory, this can potentially be a good approach
~ Lavalish|2023-04-23 18:03:29|‎~ Lavalish joined using this group's invite link
~ Vivek (CashBook)|2023-04-23 19:47:12|‎~ Vivek (CashBook) joined using this group's invite link
~ Ashish Sardana|2023-04-23 20:10:54|‎~ Ashish Sardana joined using this group's invite link
Kartik Mandaville|2023-04-23 20:36:29|what are some places to hire tech folks interested in GenAI? understanding of how GenAI works and the nuances of embeddings, text processing
Nirant|2023-04-23 20:37:13|This WhatsApp group 🙈
Mahesh Suthar|2023-04-23 20:39:04|I hear OpenAI has some decent folks
Kartik Mandaville|2023-04-23 20:39:33|should have a job board :)
Manas Ranjan Kar|2023-04-23 20:41:41|This would be helpful - looking for an AD/Director of ML for my team too 🙌🏼
Arvind N Generative AI Group|2023-04-23 20:42:31|How about a board that takes natural language input from job seekers and start-ups and matches them? Does something like this exist? Shouldn't be hard to build one.
~ Vishwam Jindal|2023-04-23 20:43:07|Looking to hire folks as well - full time or part time! Job board would be ideal
Kartik Mandaville|2023-04-23 20:44:18|I knew tokens used for non English languages is different but looking at the OpenAI bills, it gave me a shock. Some Asian languages take a lot more - is there a comparsion somewhere?
Rahul Bhatnagar|2023-04-23 21:11:16|Oh it’s ridiculous.   Woman (in English) is 1 token. స్త్రీ (woman in Telugu) is 18 tokens.  Ramsri had a nice thread. https://twitter.com/ramsri_goutham/status/1615217407378984960
Rahul Bhatnagar|2023-04-23 21:16:54|I haven’t come across a lang2lang comparison. But openAi has a tokenizer you can use to estimate tokens and build a comparison set.  https://platform.openai.com/tokenizer
Ambarish Ganguly|2023-04-23 21:21:12|For tokenization and word embeddings to reduce cost, you may like to use Sentence Transformers / [ something like that ] and pass the Embeddings to OpenAI for completion
Sidhant Sequoia|2023-04-23 21:21:22|They’re also building foundation models  https://helloentrepreneurs.com/technology/iit-madras-will-soon-develop-an-alternative-to-chatgpt-17857/
Sidhant Sequoia|2023-04-23 21:21:26|Hence, ^
Ambarish Ganguly|2023-04-23 21:21:29|Don't know if this helps, thought of putting this
Ravi Theja|2023-04-23 21:21:46|[PHONE] has built a wrapper around openai tiktoken to count tokens in a file or text - https://github.com/felvin-search/token-count - might be helpful for you.
Bulia Siddharth Aurashop|2023-04-23 21:28:00|I think we can put one google doc in the group description. Should be good enough to solve the purpose. :)
Bulia Siddharth Aurashop|2023-04-23 21:28:56|Or another group in the community for sole job seekers and employers!
Rounak Datta Hackathon Winner|2023-04-23 22:37:45|"I was trying to generate an image of ""a key ring with the OpenAI logo on it""  Couldn't get DallE, PlaygroundAI to generate even a half-decent image. Can anyone help/point out the right directions?"
~ Subhrajit  Dey|2023-04-23 22:41:25|u can use ControlNet canny model https://huggingface.co/spaces/hysts/ControlNet, just start with the openai logo, select the canny model and give the promptt ‎[4/23/23, 22:42:27] Dev Aggarwal: ‎image omitted
Rounak Datta Hackathon Winner|2023-04-23 22:43:45|If it had the keyring chain-thing, that'd be pretty cool, trying out the ControlNet model ‎[4/23/23, 22:46:12] Rounak Datta Hackathon Winner: ‎image omitted
Soumyadeep Mukherjee|2023-04-23 22:46:13|As someone who did hire from this group in some way and trying more.   It is far more exciting for an engineer to read what you’re building and some glimpses of problems you are solving and then reaching out to you out of interest/curiosity than applying  on yet another job board. ‎[4/23/23, 22:48:18] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-23 22:48:22|pardon my bad drawing
Rounak Datta Hackathon Winner|2023-04-23 22:50:01|Thx, this is something very close! will finish the remaining using gooey
Dev Aggarwal|2023-04-23 22:50:58|This was controlnet only btw, both canny and hed boundary worked well (you can change that in settings)
Diptanu Choudhury FB AI|2023-04-23 23:18:32|Anyone working on open domain Q&A type problems or ones which make use of retreievers/dense embeddings?
Krishna Ntkris|2023-04-23 23:21:57|Yes I am. My product helps businesses set this up for internal function (esp. customer service and customer success).
Diptanu Choudhury FB AI|2023-04-23 23:31:25|Oh cool, can you share what kind of models and retrieval algorithms you are using?
~ Ashwin N|2023-04-24 00:18:53|‎~ Ashwin N joined using this group's invite link
~ Amrit Kochar|2023-04-24 02:14:22|‎Soumyadeep Mukherjee added ~ Amrit Kochar
Krishna Ntkris|2023-04-24 03:09:29|Yup we use OpenAI at the moment and dense embeddings only (OpenAI again)
Krishna Ntkris|2023-04-24 03:09:34|Going to move to hybrid soon
Diptanu Choudhury FB AI|2023-04-24 03:24:21|Oh cool, are you doing similarity search on a flat embedding space to retrieve context?
Krishna Ntkris|2023-04-24 03:32:04|At the moment, yes. Might change depending on what we focus on / feedback from customer s
Suraj Nath|2023-04-24 05:18:47|‎Suraj Nath joined using this group's invite link
jyotirmayjk Hackathon|2023-04-24 09:20:29|Came across this GitHub where someone used PEFT to fine tune a LLM based on their iMessage chats to impersonate so that you can create a bot which talks like you  https://github.com/1rgs/MeGPT/blob/main/fine_tune.py    Reminded me of this discussion we had earlier
Anirudth N|2023-04-24 09:23:07|Son of Anton 😜 ‎[4/24/23, 09:26:26] Rohan Babu: ‎image omitted
Nirant|2023-04-24 09:27:33|cc [PHONE] who runs a similar community, [PHONE] who is in a Marketing role at Slice, and tech savvy generally
~ Pooja|2023-04-24 09:49:46|‎~ Pooja joined using this group's invite link
~ Aryan|2023-04-24 10:33:34|‎~ Aryan joined using this group's invite link
Garv Malik 2012H|2023-04-24 10:41:35|Hi rohan happy to connext
~ Meghana|2023-04-24 10:56:12|‎~ Meghana joined using this group's invite link
~ Meghana|2023-04-24 10:56:56|‎~ Meghana left
~ AmanMulani|2023-04-24 11:04:18|‎~ AmanMulani joined using this group's invite link
~ Ankur Khandelwal|2023-04-24 12:06:28|Any supabase user is there?   Whenever I am making the query to the function via the python sdk - getting timeout read operation error.  I checked CPU usage too- thats around 4% and memory usage 63% ( I don't know why this is so much, I am hardly making any api call)
Nirant|2023-04-24 12:07:42|You'll probably get a faster response here: https://github.com/orgs/supabase/discussions ?
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:07:47|If it's an rpc call, can you explain analyze the sql?
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:07:58|Or check your RLS policies
~ Ankur Khandelwal|2023-04-24 12:08:51|RLS polies are public.   Yeah, I thought some issue with RPC function but then I tried to creating index via the SQL editor but same issue.
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:08:57|https://explain.dalibo.com/
~ Ankur Khandelwal|2023-04-24 12:09:05|posted their too- but no response yet
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:09:17|Use this to visualize your query to understand where it's slow
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:10:00|Add indexes for parts of the query where there's a mismatch between planned rows and returned rows
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:10:49|Unoptimized reads on RLS policies won't show up here. So do check for that separately
~ Ankur Khandelwal|2023-04-24 12:11:23|ahh okay..
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:11:52|Send the specific link on the Github or discord forum with more details
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:11:53|Can help
~ Abhijeet D|2023-04-24 12:12:31|‎~ Abhijeet D joined using this group's invite link
Prayank Swaroop Accel|2023-04-24 12:13:02|Folks @brkirch ... Automatic1111 guy is doing a new branch for Mac release of Automatic1111 - I tried it much faster than the stock Automatic1111 ... but it is still experimental
Prayank Swaroop Accel|2023-04-24 12:13:03|https://github.com/brkirch/stable-diffusion-webui/releases
~ Ankur Khandelwal|2023-04-24 12:13:15|https://github.com/orgs/supabase/discussions/13923
Nirant|2023-04-24 12:14:53|cc [PHONE] [PHONE] [PHONE] [PHONE] Thought this might be interesting to you
Sudharshan GenAI|2023-04-24 12:15:25|Woah this is great
Nirant|2023-04-24 12:15:53|hahah was just tagging you and [PHONE]
Bharat Kumar Ramesh Hashmal Web3|2023-04-24 12:19:29|It's failing because the query us timing out. Two options :  1. ALTER DATABASE postgres SET statement_timeout = '15m'  Please remember to remove it from the session once done  2. Add a new column. Set the index on that column, and then copy the data into it.
Sudharshan GenAI|2023-04-24 12:19:59|Need to get a 64 gb mac like [PHONE] now ‎[4/24/23, 12:20:50] Nirant: ‎GIF omitted
~ Ankur Khandelwal|2023-04-24 12:21:12|ahh okay. let me try
~ Chetan 😇|2023-04-24 12:21:56|‎~ Chetan 😇 joined using this group's invite link
Anubhav mishra Zupay|2023-04-24 12:22:26|Are school kids in India using chatGPT ?  Is there a way to check the demographic analysis of age group using ChatGPT ?
~ 🌞  🌈 💧|2023-04-24 12:24:55|‎~ 🌞  🌈 💧 joined using this group's invite link
Nirant|2023-04-24 12:25:00|If I remember correctly, but I might be wrong, OpenAI requires you to be 18 years old to use ChatGPT in particular. OpenAI doesn't release any demographic data around it. That aside, pretty sure students are using it. [PHONE] mentioned how his daughter's friends are using it.
~ 🌞  🌈 💧|2023-04-24 12:25:18|‎~ 🌞  🌈 💧 left
~ NG|2023-04-24 12:26:03|https://e2eml.school/transformers.html
Anubhav mishra Zupay|2023-04-24 12:26:12|Yeah the demographic data isn't available but the percentage of users in India is just going up month on month
~ 🌞  🌈 💧|2023-04-24 12:26:52|‎~ 🌞  🌈 💧 joined using this group's invite link
~ Sundarrajan|2023-04-24 12:27:19|‎~ Sundarrajan left
Aaditya Sood Sequoia|2023-04-24 12:27:20|Same here. Hear anecdotal evidence of kids going majorly into it. My 12 yo son using it to rephrase stuff from Wikipedia for school essays 🤣😅
Vaibhav Bhargava Meesho Grab |2023-04-24 12:27:45|‎Vaibhav Bhargava Meesho Grab  joined using this group's invite link
~ Mani|2023-04-24 12:31:32|‎~ Mani joined using this group's invite link
Lalit Pagaria|2023-04-24 12:36:22|What is memory usage before hitting a query? Also what is data size? Conversations from raw data to objects might be taking time. Faced with a similar issue while using ORM. https://stackoverflow.com/questions/11769366/why-is-sqlalchemy-insert-with-sqlite-25-times-slower-than-using-sqlite3-directly
~ Ankur Khandelwal|2023-04-24 12:36:36|"on the second step , while copying the data from one column to another  still getting the error -  ""An error has occurred: Failed to fetch"""
~ Ankur Khandelwal|2023-04-24 12:38:11|Memory Usage is around 63% before and after...   CPU Usage increase to 21%  Data size (if you mean data records ) that is around 500K
Lalit Pagaria|2023-04-24 12:38:30|However you guard. Kids are smart and they know how to navigate around restrictions. 😅
Nirant|2023-04-24 12:38:35|"Friends, how long do I've to wait before I can say ""off-topic"" for Supabase/Postgres performance queries? Asking for a friend 😅"
Sudharshan GenAI|2023-04-24 12:38:42|Nice!   [PHONE] if we could have a transformers deep dive like this for a workshop it would be great. High quality Sesh like Amod’d
~ Ankur Khandelwal|2023-04-24 12:39:10|okay. sorry.. I didn't knew that..
~ Komal|2023-04-24 12:39:33|‎~ Komal joined using this group's invite link
Raghav Goyal EF|2023-04-24 12:40:16|‎Raghav Goyal EF joined using this group's invite link
Nirant|2023-04-24 12:40:28|No sweat, just want to be cognisant that we've 600+ folks here and they're here mainly for keeping up with GenerativeAI. Supabase is quite likely not relevant for them :)
~ Ankur Khandelwal|2023-04-24 12:40:51|make sense
~ Dhruv Tyagi|2023-04-24 12:42:14|‎~ Dhruv Tyagi joined using this group's invite link
Nirant|2023-04-24 12:42:26|Would ❤️ to have more Amod-esque speakers. The rarity is a challenge for any meetup curator. Have suggestions?   [PHONE] can reach out
Sudharshan GenAI|2023-04-24 12:42:51|https://www.reddit.com/r/selfhosted/comments/12w4p2f/localai_openai_compatible_api_to_run_llm_models/  LocalAI supports multiple models backends (such as Alpaca, Cerebras, GPT4ALL-J and StableLM) and works seamlessly with OpenAI API  Unsure of performance but this is pretty cool
Sudharshan GenAI|2023-04-24 12:43:03|Yourself? :)
Sudharshan GenAI|2023-04-24 12:44:32|[PHONE]
Nirant|2023-04-24 12:45:09|The intent is to have mid-speakers (we're all mid compared to Amod) as backup incase we've speaker cancellations.   And use this forum to give chance to someone perhaps lesser known but equally good
Prayank Swaroop Accel|2023-04-24 12:53:50|Would people in the group be interested in sessions from AI21 Labs, Cohere and Anthorpic ?
Nirant|2023-04-24 12:54:18|Cohere (Nils Reimers) for sure — I've a half a page of questions also!
Pratik Bhavasar|2023-04-24 12:54:49|‎You added Pratik Bhavasar
~ Kaushik Jaiswal|2023-04-24 13:01:11|Is there any event/session link to register for the same?
Prayank Swaroop Accel|2023-04-24 13:03:59|I will try to get it setup. Will share with the community
~ ☺️ ..ap.. 😊|2023-04-24 13:21:57|‎~ ☺️ ..ap.. 😊 joined using this group's invite link
Soumyadeep Mukherjee|2023-04-24 13:34:42|Yes please would love transformers or diffusion models in the May one. Any takers here?
Nirant|2023-04-24 13:37:10|For May, would prefer tasks like VQA, Stable/Latent Diffusion, image captioning. [PHONE] and I'll help you deliver a kickass talk. We've both spoken at different technical venues, ranging from Hasgeek events to Pycon.
Shalabh Aspiro|2023-04-24 13:39:58|https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting  A not-so-technical guide to proper prompt engineering
Nirant|2023-04-24 13:40:43|"Addendum: The April theme was Question Answering (hence a QA demo + QA internals) aka ""How to make your own ChatGPT for internal docs""   And Deep Dive on Quantization"
Nirant|2023-04-24 13:40:48|The May theme is yet to be decided but we're looking for work around image generation, video and sound. The curator will be Soumyadeep [PHONE] (https://www.linkedin.com/in/soumyadeepmukherjee/?originalSubdomain=in) — previously Infra at Udaan and now runs a Generative AI company in Bengaluru.
jyotirmayjk Hackathon|2023-04-24 13:41:05|💯  Small suggestion,if some these talks can also be accompanied by a walkthrough workshop on basics of each use case   It could look like this  Basics of VQA-Creating your own chat your docs  Basics of using Stable Diffusion-Generate your own images/Cartoonify yourself use case
Nirant|2023-04-24 13:42:04|[PHONE] taught a Stable Diffusion workshop in Feb, and there wasn't enough interest at that time. We'll consider this going foward.
Sudharshan GenAI|2023-04-24 13:45:02|Happy to do a session covering dreambooth, Lora, controlnet, creating realistic images, civitai and customisation and more.   Can gauge interest for this from the group first
Rahul Bhatnagar|2023-04-24 13:46:14|Idk about others, but I believe that workshops should be paid. If someone's creating course material + examples for me to follow, they should be compensated for their time.   Maybe we can send bookings with payment links in the future to gauge interest, and set up workshops after we confirm participation.  What say [PHONE] , [PHONE] ?
Nirant|2023-04-24 13:47:28|Yeah, by default, workshops will be paid. Upto the educator to price them. Can set this up early May and ask here :)
~ Aadith|2023-04-24 13:50:06|‎~ Aadith joined using this group's invite link
Soumyadeep Mukherjee|2023-04-24 14:05:56|So the way me and Nirant have been thinking to structure like 1 product/usage/use-case talk, 1 deep dive into some engg optimisations/libraries/use-cases and 1 deep dive into fundamentals.  Would like it more if you can do something like just controlnet from basics to demo rather than a little of many things.  Hope it makes sense?
Amir Nagri|2023-04-24 14:08:13|PSA - we had a stable diffusion workshop in March has.gy/1CNF  If folks here are interested, they can register their interest here - https://hasgeek.com/generativeAI/stable-diffusion-workshop2/  With enough interest going, will have organizers setup next one
~ Tanmay Yadav|2023-04-24 14:32:56|‎~ Tanmay Yadav joined using this group's invite link
Kishore GenAI|2023-04-24 14:56:41|"Hey [PHONE] can you explain a bit on ""creating realistic images"" specifically what would be the topics on this. Is it prompt oriented or model oriented or something else?"
~ Chao Gao|2023-04-24 14:58:27|‎~ Chao Gao joined using this group's invite link
~ Priyanka Thakran|2023-04-24 15:17:20|‎~ Priyanka Thakran joined using this group's invite link
Sudharshan GenAI|2023-04-24 15:35:13|Sure works - was thinking this would be similar to Amod’s talk but can do a paid workshop too
Sudharshan GenAI|2023-04-24 15:35:22|Makes sense
Sudharshan GenAI|2023-04-24 15:35:28|Both - but mostly model oriented and more complex dreambooth methods
Sudharshan GenAI|2023-04-24 15:35:34|Or rather less known
~ vibhorkarnawat|2023-04-24 15:36:36|‎~ vibhorkarnawat joined using this group's invite link
Swastik Banerjee|2023-04-24 16:37:57|Sounds good
Nirant|2023-04-24 16:42:09|Excellent criticism of _safetyism_ and discusses the loudest detractors and their main arguments (excellent if you want to catch up!)   Direct quote from author elsewhere: If we’d decided that Transistor Safety was a key issue in the 1960s, we’d probably still think of transistors as a tool mostly used for steering rockets and for lightweight combat radios—just like fears of nuclear war had a bigger impact on nuclear power than on the nuclear weapons themselves.  https://www.piratewires.com/p/against-safetyism
~ Ganesh Yeluri|2023-04-24 16:56:56|‎~ Ganesh Yeluri joined using this group's invite link
Anshul Bhide Replit|2023-04-24 17:17:12|https://warpspeed2023.devfolio.co/
~ AI|2023-04-24 17:25:50|‎~ AI joined using this group's invite link
Amogh V|2023-04-24 17:27:32|Piratewires is always great, one of my favourite substacks
~ Rawal Khirodkar|2023-04-24 18:24:32|‎~ Rawal Khirodkar joined using this group's invite link
~ Jonathan Ve Vance|2023-04-24 18:39:30|This is off topic. Is there someone here who has experience working with motion capture / face-body reenactment or topics related to pose estimation, that I can DM? I just want to get an idea of state of the art right now and to get started with the topic.
Soumyadeep Mukherjee|2023-04-24 18:40:43|[PHONE] ? 🤔
~ Rawal Khirodkar|2023-04-24 18:46:55|I work in these areas, happy to chat!
~ Aman|2023-04-24 19:06:19|Did some work few months back with mediapipe along with integration in blender. Though not updated with recent developments
~ Sam|2023-04-24 19:06:19|‎~ Sam joined using this group's invite link
Devanshu Tak 2015B3A4|2023-04-24 19:07:50|I've worked on a few projects where we did live performance capture, yes. Happy to chat about it!
Dev Aggarwal|2023-04-24 19:18:55|https://twitter.com/Uncanny_Harry/status/1650462479237931008?s=2  Holy smokes! This gen2 video is stunning ‎[4/24/23, 19:21:36] Rohan Babu: ‎image omitted
Nirant|2023-04-24 19:23:10|Text is easier to read on a phone than a text inside an image :) Type the text ;)
Pranjal Mehta|2023-04-24 19:25:03|If it's a marketing plug, please refrain.
Rohan Babu|2023-04-24 19:28:19|It is not. But happy to remove it if you think so. Sorry, I happen to be a marketer 🙏🏽
Kaushik Bokka|2023-04-24 19:28:33|Anyone here has experience working with Interoperable Master Format? Would love to connect.
Suraj Nath|2023-04-24 19:36:55|‎Suraj Nath left
Twishmay Shankar|2023-04-24 20:04:32|‎Twishmay Shankar joined using this group's invite link
~ Mayank Gupta|2023-04-24 20:35:38|‎~ Mayank Gupta joined using this group's invite link
~ Rohit|2023-04-24 21:18:05|Has anyone noticed differences between using newlines/replacing them when using openai's embedding api?
Nirant|2023-04-24 21:19:33|While you're at it, [PHONE] and I'd love to know why Langchain does a newline replacement too 😅 https://github.com/hwchase17/langchain/blame/d2520a5f1e78f8e7a2f5c888feda62bafd3ab963/langchain/embeddings/huggingface.py#L65
Diptanu Choudhury FB AI|2023-04-24 21:38:07|\n is probably not a token in the vocabulary ‎[4/24/23, 21:39:10] Nirant: ‎image omitted
Diptanu Choudhury FB AI|2023-04-24 21:42:31|Creating a token from an unknown world and having it in the vocabulary is different. The model’s vocabulary are words that it understands to encode into something meaningful in the encoder.
Nirant|2023-04-24 21:43:47|Can you elaborate or rephrase a bit? I didn't understand
~ Vishwam Jindal|2023-04-24 21:44:49|https://www.livemint.com/companies/start-ups/indian-engineering-colleges-lead-generative-ai-research-projects-in-indic-languages-facing-challenges-in-data-sourcing-and-computing-power-11681663553393.html
Diptanu Choudhury FB AI|2023-04-24 21:46:12|Let’s take a NLP model from huggingface which follows the transformer library specification. It will have a vocab file in it, you will see the vocabulary of the model, words  it was trained to encode. New line, tabs are not part of vocabulary.
Diptanu Choudhury FB AI|2023-04-24 21:46:41|So while a newline could be a token it doesn’t have any semantic meaning when it’s encoded.
Nirant|2023-04-24 21:47:35|Aaah, that'd make sense. Thanks for explaining!
Nirant|2023-04-24 21:49:43|So to rephrase the original question —  if we have the original vocab file for GPT3.5 and that has a newline, adding/removing it makes a semantic difference and vice versa?
Diptanu Choudhury FB AI|2023-04-24 21:54:11|If the vocabulary has new lines, you could keep them. But for all practical purposes I haven’t seen models contain any space, tab or new lines in models
Diptanu Choudhury FB AI|2023-04-24 21:54:31|You will use up tokens and not get any advantage in terms of results
Keertana S Suvy|2023-04-24 21:54:40|Sometimes, new line matters for text splitting/ chunking. (Such as splitting by para). Then the /n has meaning, correct?
Keertana S Suvy|2023-04-24 21:55:11|I'm referring to text splitting pre-embedding
Diptanu Choudhury FB AI|2023-04-24 21:55:51|Those are character splitters. Yeah they look into these control characters.
Diptanu Choudhury FB AI|2023-04-24 21:56:51|The assumption from the model author is that you would split texts the way you see fit and then remove unknown vocabulary, tokenize and then feed the texts into the model.
Diptanu Choudhury FB AI|2023-04-24 21:57:58|*text splitters ‎[4/24/23, 22:01:04] Rohit Aggarwal: ‎image omitted ‎[4/24/23, 22:01:05] Rohit Aggarwal: ‎image omitted
Diptanu Choudhury FB AI|2023-04-24 22:02:52|My approach for choosing splitting and sanitizing texts would be to run some experiments and see what preserves or improved the performance of the model with the least number of tokens.
Diptanu Choudhury FB AI|2023-04-24 22:03:23|Context length obviously plays a role also. Can’t go longer than ctx supported.
Rohit Aggarwal|2023-04-24 22:03:31|might be the reason for the extra tokens too? As the new line + word is not recognised as a common enough token
Diptanu Choudhury FB AI|2023-04-24 22:04:26|You could look into the source code of the tiktoken library on GitHub to see how they are doing it. It’s purely heuristics.
Diptanu Choudhury FB AI|2023-04-24 22:04:50|The tokenizer is called C100k or something
Shashank Generative AI Group|2023-04-24 22:05:49|gpt-4 uses a different tokenizer but they haven't updated the url you linked with that.  https://news.ycombinator.com/item?id=35453400
Shashank Generative AI Group|2023-04-24 22:06:51|yes ‎[4/24/23, 22:09:04] Shashank Generative AI Group: ‎image omitted
Sudharshan GenAI|2023-04-24 22:13:11|Nice, love pirate wires - good source of truth with lesswrong and scott alexander
Sudharshan GenAI|2023-04-24 22:13:51|Can help - explored and published on these topics
~ Busy|2023-04-24 22:22:09|‎~ Busy left
Sudharshan GenAI|2023-04-24 22:25:30|https://twitter.com/aribk24/status/1650372832524926977?s=20  Grimes responsed  Our hackathon project  We should launch and deploy lol [PHONE]
Sudharshan GenAI|2023-04-24 22:25:35|responded*
Sumod K Mohan|2023-04-24 22:26:07|Worked in pose estimation (egomotion/SLAM etc) and deployed in few places. Dabbled in human pose at some point but not up to date with lit. You can DM. Not much in mocap/face-body reconstruction.
Bulia Siddharth Aurashop|2023-04-24 23:02:11|How did you do this?
Sudharshan GenAI|2023-04-24 23:08:16|We did something very similar for the hackathon - there are some good voice models out there  Arib launched it and grimes responded
Kaushik Bokka|2023-04-24 23:22:28|Holy shit! Let’s go Arib. Arib hooked me up with a free ticket to a Sam Altman session. What a great dude
Vaibhav Bhargava Meesho Grab |2023-04-24 23:24:34|This thing is going to take over the world.
~ Varun|2023-04-24 23:33:42|‎~ Varun joined using this group's invite link
~ Junaid|2023-04-24 23:40:12|‎~ Junaid joined using this group's invite link
Vamshi|2023-04-24 23:58:21|Sounds legit ! Can you repost your hackathon link?   Is it using so-vits-svc or a different library?
~ Lakshya|2023-04-25 00:11:07|what are some cool chatgpt related chrome extensions y'all have come across?
Anagh Prasad|2023-04-25 00:35:19|V. interesting read on potential to use RL without human feedback: https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81
Siddharth Agarwal|2023-04-25 00:36:39|Not entirely sure if this belongs here, but which are most interesting OSS projects in the space? I finally have some free time and would love to contribute more.
Bulia Siddharth Aurashop|2023-04-25 00:52:42|ShareGPT!
Ojasvi Yadav|2023-04-25 01:02:32|One of my sideprojects is a bot that's trained on my bumble chats to reply like me....so that I can focus exclusively on AI 😝 and not be bothered to text-back during the week. And just be presented with a date on the weekend.
Ojasvi Yadav|2023-04-25 01:02:46|For that I had to make a chrome extension that can read all my chats
Lavish 2017|2023-04-25 01:05:13|she: you're so fun, so when do we go out? Ojasvi: as an AI language model, I can't go out as I've been ...
Ojasvi Yadav|2023-04-25 01:05:42|🤣🤣🤣🤣🤣
Ojasvi Yadav|2023-04-25 01:06:03|No it's trained exclusively to type like me with a super low temperature
Ojasvi Yadav|2023-04-25 01:06:24|I don't want to come across as someone I'm not
Ojasvi Yadav|2023-04-25 01:07:15|"Just wanted my own two extra hands, not an AI ""dating expert"""
Lavish 2017|2023-04-25 01:08:37|time to recreate: hang the DJ
Shashank Generative AI Group|2023-04-25 01:10:05|beware of prompt injection attacks 😂
Ojasvi Yadav|2023-04-25 01:15:32|Next feature is a vector search on all the girls I've swiped right in the past and autoswiping on girls that cross a certain similarity threshold. Will apply to their images and also their textual information like bios.
Ojasvi Yadav|2023-04-25 01:16:37|It's still in POC stage 😝
Ojasvi Yadav|2023-04-25 01:16:55|can those occur in my context?
~ Lakshya|2023-04-25 01:17:14|Damn exactly what I was looking for
Shashank Generative AI Group|2023-04-25 01:21:07|idk honestly. yours is also low temp. so maybe more difficult than usual? my understanding is that most prompt injection out there is tested on the default temperature 0.7
~ Rohan|2023-04-25 01:23:42|If anyone wants/needs help on prompt injection, please send me your model. I enjoy interacting with LLMs to trick them into breaking things.
Ojasvi Yadav|2023-04-25 01:34:31|Will do once I'm out of POC stage
Ojasvi Yadav|2023-04-25 01:35:13|Yeah plus the training dataset is made from my chats Not sure if I've been sent a prompt injection by anyone so far
Dev Aggarwal|2023-04-25 01:36:03|**creates fake profile to send ojasvi a prompt injection attack**
~ Surya SG|2023-04-25 03:16:17|‎~ Surya SG joined using this group's invite link
~ Anurag Dhingra|2023-04-25 05:53:58|‎~ Anurag Dhingra joined using this group's invite link
~ Sudhanshu Heda|2023-04-25 08:42:58|Feels like a dialogue straight outta ‘Indian Matchmaking’  How about you also get a summary of the conversation before you go on that date?
Kartik Mandaville|2023-04-25 09:27:41|https://openai.com/brand I don't understand how OpenAI can claim the word GPT - is it not a generic term?
jyotirmayjk Hackathon|2023-04-25 09:34:59|+1 on this  I was thinking if it’s a case where adding word GPT is misleading users that it’s an OpenAI model/something sold by OpenAI as a service  Rather than something built on top of OpenAI
~ Hemant Khandelwal|2023-04-25 09:36:12|‎~ Hemant Khandelwal joined using this group's invite link
Dhruv Naik|2023-04-25 09:37:49|Transformers is the generic term, GPT was their branding from the beginning
Dr. Pratik Desai KissanGPT|2023-04-25 09:38:29|This is for Branding if you want to mention OpenAI. Just don’t mentioned them and you can name anything. ‎[4/25/23, 09:38:55] Kartik Mandaville: ‎image omitted
Kartik Mandaville|2023-04-25 09:39:13|ah so do they have a trademark on GPT?
Dhruv Naik|2023-04-25 09:40:53|https://techcrunch.com/2023/04/24/gpt-may-be-trademarked-soon-if-openai-has-its-way/
~ Sarath Chandra|2023-04-25 09:55:17|‎~ Sarath Chandra joined using this group's invite link
~ AI|2023-04-25 09:57:22|The fact that ChatGPT, as being associated with OpenAI is widely known - they’re only trying to prevent any use of [insertword]GPT that may suggest an association/affiliation/partnership with OpenAI when there may be none.  Their guidelines are just a polite way of saying - we may bring a TM infringement suit against you (whether or not they succeed is a different question altogether). Note: that you don’t necessarily need to have a registered TM to bring a suit if it is otherwise widely known.
~ Chandana|2023-04-25 11:25:51|‎~ Chandana joined using this group's invite link
~ Tejas|2023-04-25 11:34:22|‎~ Tejas joined using this group's invite link
~ Likhith|2023-04-25 11:38:13|‎~ Likhith joined using this group's invite link
~ Pulkit Pandey|2023-04-25 11:38:20|‎~ Pulkit Pandey joined using this group's invite link
~ Chandrahas|2023-04-25 11:50:54|‎~ Chandrahas joined using this group's invite link
~ Priyaranjan Sinha|2023-04-25 11:55:18|‎~ Priyaranjan Sinha joined using this group's invite link
Diptanu Choudhury FB AI|2023-04-25 12:45:17|Any of you use qdrant for vector search? It looks really cool and easy to use as well.
Diptanu Choudhury FB AI|2023-04-25 12:45:51|The difference between pinecone, Milvus and Qdrant is so small!
Nirant|2023-04-25 12:52:42|Redis and Qdrant. Have tried Chroma too.   Disclosure: I'm a ML Consultant and Qdrant is a client
Pratyush Choudhury|2023-04-25 13:03:00|Developer Experience?
Anshul Bhide Replit|2023-04-25 13:11:35|off-topic - anyone wants to complete a Bounty for Yohei Nakajima? https://replit.com/bounties/@YoheiNakajima/scrape-an-api-and-se
Dev Aggarwal|2023-04-25 13:15:26|Too little money for trivial work?
~ Nikhil|2023-04-25 13:15:48|Has anybody tried training any of the openai models on code?  What I am trying to do: Razorpay has open sourced their design system (just like Bootstrap). I want to be able to describe to the model one or more components that I want to create in natural language and the model spits out these components as described using the  design system.  https://github.com/razorpay/blade
Shimanta Generative AI|2023-04-25 13:17:02|Embeddings plus GPT-3.5 should be able to do it
~ Nikhil|2023-04-25 13:17:05|While I read through the fine tuning section of openai docs, just wondering if there are any do/donts/tips that I should keep in mind
Shimanta Generative AI|2023-04-25 13:17:14|Not perfectly though
~ Adhitya Swaminathan|2023-04-25 13:17:55|Is fine tuning necessary?
Shimanta Generative AI|2023-04-25 13:18:29|I did kind of a similar approach to create diagrams using MermaidJS. Created embeddings from the docs and added gpt-3.5. Worked well for the most part
~ Nikhil|2023-04-25 13:20:38|Most of these components have several parameters that they accept that define the behaviour of the UI component.  I feel that fine tuning will help with getting better results overall.  I tried generating Bootstrap components since it is widely used and available. It does a decent job overall of creating components. However, takes a lot of prompting to get certain attributes to be set based on the behaviour described
~ Nikhil|2023-04-25 13:22:09|Plan of action that I have in mind: 1. Version 1 > Feed it the documents and code and see if the results are similar to what I get for generating Bootstrap components. 2. Version 2 > Check if any finetuning is necessary. Will play around with it and see if it generates better results.
Sumod K Mohan|2023-04-25 13:25:49|Afaik, fine tuning is only available for base models not for RLHF'ed/SFT models. So you may see degradation in performance.
~ Nikhil|2023-04-25 13:38:11|Thanks
Swastik Banerjee|2023-04-25 13:47:53|I couldn’t setup Qdrant and Chroma with the chatgpt-retrieval plugin 😢
Swastik Banerjee|2023-04-25 13:48:23|https://github.com/openai/chatgpt-retrieval-plugin/pull/59#issuecomment-1514694410
Twishmay Shankar|2023-04-25 13:49:23|Is there a consensus yet on the best affordable spot GPU / cloud providers?  Any recommendations pls 🙏
Sudharshan GenAI|2023-04-25 13:53:38|Haha great idea - how did you train it?
Ojasvi Yadav|2023-04-25 14:05:32|Haven't done it yet. Still trying to improve the chrome extension to make it smoother to use.  Also a little apprehensive about scraping my chats. Companies don't like that to happen on their webpages generally.
~ Siddharth|2023-04-25 14:16:51|‎~ Siddharth joined using this group's invite link ‎[4/25/23, 14:27:09] Shivendu Kumar: download (1).mp3 ‎document omitted ‎[4/25/23, 14:28:20] Shivendu Kumar: download (3).mp3 ‎document omitted
Sudharshan GenAI|2023-04-25 14:28:24|I got access to this. Haven’t installed yet   https://www.cupidbot.ai  Thinking this can be done with llama trained on my chats and run locally
Sudharshan GenAI|2023-04-25 14:28:42|Nice! Which model?   [PHONE]
Shivendu Kumar|2023-04-25 14:29:04|so-vits-svc fork
Prashant Singh|2023-04-25 14:29:15|This is how world will end
Prashant Singh|2023-04-25 14:30:21|"I like the disclaimer : "" Havent installed it yet "" . : ) ‎[4/25/23, 14:30:54] Shivendu Kumar: apna-bana-le-ariana.mp3 ‎document omitted"
‪+91 89709 02000‬|2023-04-25 14:31:07|‎‪+91 89709 02000‬ joined using this group's invite link
~ raj()|2023-04-25 14:57:36|Try out Weaviate if it fits your needs. We're using Weaviate with 15 million+ vectors. Good performance with normal index-wide vector search as well as pre-filtered vector search.   They have a blog post on using with chatgpt-retrieval that might be relevant to you: https://weaviate.io/blog/weaviate-retrieval-plugin
Sudharshan GenAI|2023-04-25 14:59:37|Haha
~ Jatin|2023-04-25 15:16:25|This was not a scam? Had strong scam vibes
Dev Aggarwal|2023-04-25 15:20:34|Can you tell us which parts require training vs which parts are zero shot / one shot inference?
Naman Jain Stellaris|2023-04-25 15:26:03|https://arize.com/observe-2023/
Shivendu Kumar|2023-04-25 15:30:58|I haven't trained these models myself because of data prep requirements.  But afaik it doesn't need lyrics/text for training or inference. It's trained on voice samples (.mp3/.wav files). Even at the time of training, just feed it a .mp3 file (sing yourself or use an existing song). So after training, it's all 0 zero-shot inference.
Jidin Dinesh|2023-04-25 15:32:01|Is someone kind enough to share their gpt4 access for a day and half please? 🥹
~ Nikhil|2023-04-25 15:32:49|For GPT4 access, you can try https://github.com/xtekky/gpt4free
~ Nikhil|2023-04-25 15:32:58|In case you do not have a paid subscription
Shivendu Kumar|2023-04-25 15:33:12|I want to clone Arijit Singh's voice. Will have to collect and clean the data.
Dev Aggarwal|2023-04-25 15:36:55|Ah, so its like style transfer for speech, nice
Shivendu Kumar|2023-04-25 15:38:18|Yup.
~ Soumya Ranjan Bairishal|2023-04-25 15:41:54|‎~ Soumya Ranjan Bairishal joined using this group's invite link
Sudharshan GenAI|2023-04-25 15:57:31|Hire someone on upwork/fiver? Costs <50 USD for this
Sudharshan GenAI|2023-04-25 15:57:33|And 2 dats
Sudharshan GenAI|2023-04-25 15:57:34|days*
~ Nikhil|2023-04-25 15:58:56|Are you using https://beta.elevenlabs.io/ for this?
Shivendu Kumar|2023-04-25 15:59:44|Nope. https://github.com/voicepaw/so-vits-svc-fork
Dr. Pratik Desai KissanGPT|2023-04-25 16:07:55|Someone leaked pretrained models of many popular singers a week back. Was that for this project?
Shivendu Kumar|2023-04-25 16:08:56|Probably. Wait I'll share.
Shivendu Kumar|2023-04-25 16:09:09|https://docs.google.com/spreadsheets/d/1qzeFdpUPr7E0jOFwWSXd8LF30ZLjz1CSVEBiG8gPHTU/edit#gid=1792554832 this one?
~ Arpit Sharma|2023-04-25 16:40:48|‎~ Arpit Sharma joined using this group's invite link
Dr. Pratik Desai KissanGPT|2023-04-25 16:41:02|They even got Freddy
~ Jitendra|2023-04-25 17:01:21|‎~ Jitendra joined using this group's invite link
~ Anurag Dhingra|2023-04-25 17:02:19|https://twitter.com/tivadardanka/status/1649721970886594561?s=21&t=r3oag1xERfq9yMvHrl3kqA
~ Praveen Patlola|2023-04-25 17:15:40|‎~ Praveen Patlola joined using this group's invite link
~ Divya|2023-04-25 17:25:24|‎~ Divya joined using this group's invite link
~ Prakhar|2023-04-25 17:28:27|‎~ Prakhar joined using this group's invite link
~ Srishti Bhandari|2023-04-25 18:08:40|‎~ Srishti Bhandari joined using this group's invite link
Pratyush Choudhury|2023-04-25 18:21:27|https://aiagent.app/  Very cool product in case people haven't tried it
~ Varun Rai|2023-04-25 18:26:07|‎~ Varun Rai joined using this group's invite link
~ Mayank Gupta|2023-04-25 18:34:42|This is pretty cool! Know who's built this?
Dev Aggarwal|2023-04-25 18:35:34|The toolkit says coming soon
Dev Aggarwal|2023-04-25 18:36:16|something that’s already here - fixie.ai
~ Rohit|2023-04-25 18:38:49|doesnt this look like godmode.space (or just AutoGPT in general)?
~ Rachitt|2023-04-25 18:38:54|Fixie's SDK is pretty powerful
~ Rohit|2023-04-25 18:39:36|has anyone used AutoGPT (or its derivatives) for anything useful so far? Let me know if there are some projects that do this.
Rohit Aggarwal|2023-04-25 18:41:07|have you used this?
~ Rachitt|2023-04-25 18:41:23|I have, a bit
Dev Aggarwal|2023-04-25 18:41:40|Worked for the 30 mins i played with it
Ashfakh GenerativeAI WA Group|2023-04-25 18:47:22|How are you running it on prod? Docker? Is it a cluster?
~ Adhitya Swaminathan|2023-04-25 18:48:06|The concept is fun, but I haven’t really found it useful.
~ raj()|2023-04-25 18:54:00|It's a cluster, but we're using their managed SaaS service WCS, https://weaviate.io/developers/weaviate/installation/weaviate-cloud-services
~ Mayank Gupta|2023-04-25 18:59:22|Just out of curiosity, why not?
~ Rohit|2023-04-25 19:02:35|depends on the application I guess? I generally use it for paraphrasing (for which chatgpt suffices) and coding (where none of these models work very well - haven't tried GPT4 which some people claim is much better, but more expensive too) ‎[4/25/23, 19:06:09] Amal David Futuryze: ‎image omitted
~ Rohit|2023-04-25 19:19:47|why not? at least thats the idea wit medical AI, as of now humans by nature will not trust AI diagnosis any more than a human doctor's diagnosis. AI assisted healthcare makes sense from both effort minimization and improving patient outcome
~ Rohit|2023-04-25 19:20:32|an example: https://whiterabbit.ai/
~ Saurabh|2023-04-25 19:47:11|‎~ Saurabh joined using this group's invite link
~ Yash|2023-04-25 19:49:46|‎~ Yash joined using this group's invite link
~ Sachin Kalsi|2023-04-25 19:50:48|‎~ Sachin Kalsi joined using this group's invite link
~ Prajjwal Khandelwal|2023-04-25 19:57:53|‎~ Prajjwal Khandelwal joined using this group's invite link
~ LW|2023-04-25 20:06:32|‎~ LW joined using this group's invite link
~ Mustafa Burhani|2023-04-25 20:17:07|‎~ Mustafa Burhani joined using this group's invite link
~ Shivansh|2023-04-25 20:31:44|Hey Guys, we want to host a stable diffusion based web app. I tried looking online to find best and cheapest approach but couldn't find good leads. Free sign up credits don't allow GPU based instances and diffusion doesn't work well(quality and time) on CPU based machines. Anyone here has some suggestions for good place to host?
Nirant|2023-04-25 20:33:57|Serverless? Modal and Banana type services?
Dev Aggarwal|2023-04-25 20:33:59|Have it forever - https://gooey.ai/compare-large-language-models/?example_id=7ihhyv3l
~ Shivansh|2023-04-25 20:37:17|Okay, I am not sure if serverless would be right for us. So I have a normal python script with multiple diffusion models and hosted via flask/streamlit. Sorry, little noob in hosting :p
Jidin Dinesh|2023-04-25 20:37:47|wow - this should help my case, if they offer what they claim. Thanks Dev!
Nilesh Agarwal Inferless|2023-04-25 20:38:11|Hey Shivansh ,  I am Nilesh, we are building a platform specially for GPU based workload  https://inferless.com/
Nilesh Agarwal Inferless|2023-04-25 20:38:25|happy to connect and understand how we can help you
Dev Aggarwal|2023-04-25 20:38:58|Arey this is mine only :) DM for bugs and feedback
~ Ravi Trivedi|2023-04-25 20:39:03|https://arize.com/observe-2023/ The third annual Arize:Observe is the first conference dedicated solely to ML observability in the year of generative AI. This (free to attend) event is starting in an hour.  Seemed to be a good one atleast few of the sessions. Check it out.
Twishmay Shankar|2023-04-25 20:39:58|We’ve spent a lot of time trying diff GPU hosting platforms.   Top picks for IaaS / PaaS type hosting:  Fastest:  (1) Banana.dev for fast scalable hosting / prototyping (₹150 per hour for 40GB)  Cheapest:  (2) Jarvis (~60-70 per hour for similar GPU as Banana)
Nirant|2023-04-25 20:40:09|Check Modal Labs perhaps? It's beginner friendly and they've Python-friendly web endpoints: https://modal.com/docs/guide/webhooks ‎[4/25/23, 20:42:39] Twishmay Shankar: ‎image omitted ‎[4/25/23, 20:45:36] Twishmay Shankar: e73ef8fe-7ddb-465b-8d54-a170f52ab287%2FGPU_Price_Comparison_Jan_22.pdf • ‎26 pages ‎document omitted
Karan Lightspeed|2023-04-25 20:56:51|Ongoing webinar on Dolly right now. Still on for another 30 mins.   https://event.on24.com/wcc/r/4187692/F74E3C2FB135A1C3CDC5302CCDED7772
Karan Lightspeed|2023-04-25 20:58:21|"Q&A so far. In case it's helpful for anyone.  Is loading and testing LLM different depending on type of training? ie. categorization vs q&a  Loading LLMs is generally about the same for most models. You will use Hugging Face, usually. Testing a classifier is straightforward because the right answers are clear. Testing QA is harder; is the answer accurate? how accurate? is the tone OK? because it's natural language.  After finetuning, how can you test/ensure new dataset is trained in new model? ie recent events such as covid, 2023 beijing hospital fire, etc.  You would hold out some fine-tuning data for test and evaluation, as with any other model. How you evaluate the model on that data depends a lot on the data!  At the public rate for GPU time at Databricks, how much did it cost to train/tune Dolly?  The largest 12B model cost several thousand dollars to fine tune. That is not cheap, but a lot less than training from scratch. You don't have to fine tune in many cases, or can tune less or tune a smaller model.  Do you think the large 12b%2B models will end up with different flavours and organisations will have to pick the LLM specialism to build on top or will there be a base model to rule them all?  I think the idea here is specialized models (single billions of params) could keep up with SOTA models (hundreds of billions) if fine-tuned for a specific task. Maybe.  are we bound to use data ingestion service like databricks for fine tune dolly 2.0  No, you can use or fine-tune Dolly anywhere. It's not tied to Databricks.  What is the optimal length for fine-tuning the model, or how many training samples are needed for effective fine-tuning?  No one answer to that. Depends on the data, model and problem. You can see that a couple epochs at 15K data points were roughly enough to turn Pythia into an instruction-following model. I'd aim for tens of thousands of examples, but, no hard rule here.  Is Dolly only pre-trained for english language or could you fine tune the model for other languages?  It is based on Pythia, which mostly saw English text. The fine-tuning set is also English. You could fine-tune on other languages instruction sets, but that doesn't mean the base model learned the language. It would work to a limited degree.  What the size of GPU Ram is required for hosting/fine-tuning Dolly 2.0?  A100 is nice, but A10/V100 and even T4 can work: https://github.com/databrickslabs/dolly#generating-on-other-instances  do you have a good tutorial to get started with Dolly  Sure, simplest thing is to run the couple lines of code you see on the model page: https://huggingface.co/databricks/dolly-v2-3b  Will there be a recording of this available?  We will send out the webinar recording after the event via email!  I'd like a LLM that simulates me, and how I think and answer questions. Is it possible to augment an existing LLM or do I need to build my own? I want it to learn based on all the content/collateral I create or have created.  You can create prompts like ""Here is some text I wrote: ... Now write X in the same style"" That can work with LLMs. You can also fine-tune on your text of course  will this session be recorded ?  The webinar will be recorded and sent out via email post event  what would be the token limit for an LLM made by our selfs , or we can decide that  It depends on your model's architecture. Pythia, thus Dolly, use a 2048 token context window. Others are larger or smaller.  Do you have any example costs of fine tuning? I nearly had a go but was nervous what cost I might incur!  It entirely depends on what you are tuning, on what hardware, and for how long. As a reference point, the 12B fine-tuned Dolly model cost several thousand dollars. Smaller models would be less. I wouldn't fine-tune unless you have a specific reason.  does LLM use reinforcement learning?  LLM training can use human-in-the-loop feedback. See ""RLHF"" https://huggingface.co/blog/rlhf  What was the GPU requirements to load the 12B Dolly model for inference & training?  See the repo: https://github.com/databrickslabs/dolly#generating-on-other-instances  I have a large amount of unlabeled, domain specific text data, as well as a much smaller set of labeled data. I would like to leverage both to fine tune a language model for a specific task. How would you recommend fine-tuning the model in a way that let's me use both the unlabeled and labeled data I have access to?  Hard to answer right here, but in the end the input to training are just chunks of text. You can feed it text, and text of data + label. You're asking it to learn to write the text you feed it, so there's some art to constructing the input. For labeled data you want to construct the text so that the desired output follows the type of question you'll ask.  What if you have domain specific corpus? How do you integrate that into Dolly  1) you can fine-tune on that data, 2) you can use langchain to feed related text from your corpus alongside your question to an off-the-shelf LLM. The latter is what we show at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot  Is it viable to use opensource generative models for instruction following data? Since generating a dataset is time consuming. This is regarding fine tuning dolly 2.0  You mean, can you generate fine-tuning data from another LLM? sure that's what Alpaca did, by scraping OpenAI. However the resulting model was not for unrestricted commercial use because the data was scraped from OpenAI.  I have an unstructured text corpus, think like wikipedia pages. Can we fine tune LLM by adding this data? Is there any notebook explaining this.  Yes, if you want to. Hard to explain the detail here, but see Dolly's training repo: https://github.com/databrickslabs/dolly We also have an example of Dolly + StackExchange data that does not need fine-tuning: https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot  Can Dolly 2.0 be used as an agent for something like Langchain?  Absolutely. We have a whole demo on that https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot  When does it make sense to start fine tuning your data vs sending lengthy, detailed prompts?  Good question. Fine-tuning takes more upfront work but indeed makes generation faster b/c you dont' stuff context into the prompt. Fine-tuning also means you have to re-fine-tune to have it learn new information, versus just stuffing the latest info into a prompt.  What use cases / applications are you seeing that companies / startups are doing using Dolly? What is your POV on the risk for technology being redundant due to the fast pace of development in Gen AI?  Most people are interested in question-answering over private text collections. Translation and summarization were already well understood use cases, but QA is 'new'. Chat not so much. This space is changing really fast, and what we use now will be obsolete next year, but, thankfully it all remains fairly accessible.  How can i train a locally hosted dolly 2 instance with my own datasets? I currently have data in a CSV format.  See https://github.com/databrickslabs/dolly though I don't know that CSV is natural language text, not really what LLMs have learned to process. CSV doesn't need LLMs to understand! however you can see in tools like langchain some patterns for querying databases with natural language and describing the results, so that is possible.  Why does Dolly 2.0 use pythia eleutherai instead of LlaMA as a base model?  LLaMa is not for commercial use, while Pythia is. We wanted to make something that was commercially usable like typical OSS code is.  Can I use LLM to classify a set of texts? Whether they are ""good"" or ""threat""?  Yes. You can present it a few examples of ""good"" and ""threat"" in the prompt and ask about a new example. This is few-shot learning. You could even fine-tune it to do that. However, for simple classification, far simpler off-the-shelf models would be easier to use.  Is fine-tuning required for us to use Dolly in generating insights and answering certain questions about dataframes or other data that we might have on Databricks?  No. See the example at https://www.dbdemos.ai/demo.html?demoName=llm-dolly-chatbot which answers questions over a domain corpus without fine tuning  How do you manage for picking the right hugging face model(s) for commerical use cases so that companies don't get stuck in litigating later?  Most of the models in Hugging Face have license information. You should look at the license specifics ‎[4/25/23, 21:03:38] Dev Aggarwal: ‎image omitted"
Nirant|2023-04-25 21:03:44|Open Source (Llama 30B-based) rival to ChatGPT from Huggingface: hf.co/chat
Nirant|2023-04-25 21:03:59|Must be WA blue 🤣 ‎[4/25/23, 21:05:21] Nirant: ‎image omitted
Karan Lightspeed|2023-04-25 21:06:11|You're welcome :P Did this via apple app on mac in case there's an actual constraint on other devices :P
~ Yashvardhan Didwania|2023-04-25 21:23:34|‎~ Yashvardhan Didwania joined using this group's invite link
Pratyush Choudhury|2023-04-25 21:26:21|Fine tuning vs sending long, detailed prompts is a very interesting topic/Product design requirement  Fine tuning is more upfront work and also requires constant re-training/re-fine tuning to keep it relevant  On the other hand, sending long, detailed prompts has its own set of pros/cons  Does anyone here have inputs on economics b/w the two?  My sense + anecdotal conversations have told me that fine-tuning often has a higher marginal cost. Eager to hear from others
Karan Lightspeed|2023-04-25 21:28:27|My biz perspective is use out of box to test if it will give a satisfactory but not great output and then build your moat via fine tuning once the use case starts having traction.   But interested to hear others perspectives.
Twishmay Shankar|2023-04-25 21:28:46|Added Q to above:  When context windows are super large (32K for GPT4 and someone tested 1M recently) will we still need fine tuning when almost all context will fit inside 1M tokens?
Karan Lightspeed|2023-04-25 21:28:47|*satisfactory output
Twishmay Shankar|2023-04-25 21:28:49|https://manifold.markets/IsaacKing/will-any-llm-have-a-context-window
Twishmay Shankar|2023-04-25 21:29:07|Related discussion here https://news.ycombinator.com/item?id=35682424
Pratyush Choudhury|2023-04-25 21:31:02|Interesting, are we saying that few-shot in-context learning is how FMs will be deployed in production?  As opposed to an ensemble of smaller fine-tuned models?
~ Varath|2023-04-25 21:31:30|Noob question: I work at an education company. We finetuned chatgpt's davinci model on some of our content to see if it can create good new content. Results so far are fairly poor, and I'm wondering if this should be expected since gpt-3.5 and gpt-4 significantly raised the bar from previous versions? Has anyone else seen sub-par quality output from finetuned models? Are there other options (such as Huggingface transformers) that might work better?
Twishmay Shankar|2023-04-25 21:31:50|Particularly when the context window will support 32K or 100K+ tokens which can fit all fine tuning data ?
Pratyush Choudhury|2023-04-25 21:32:09|How do we think of expenses?
Pratyush Choudhury|2023-04-25 21:32:27|More input tokens would mostly mean more expensive API calls?
Twishmay Shankar|2023-04-25 21:33:25|Expenses is ~ # of context window tokens to and fro on OpenAI atleast
Karan Lightspeed|2023-04-25 21:33:45|My understanding so far is that GPT 4 especially is very capable for most use cases with few shot in-context learning. So would be easier to test and learn like this, figure the nuances of the use case and then evaluate smaller fine tuned models.
Twishmay Shankar|2023-04-25 21:33:53|Makes sense. With that in mind 1M tokens of context will be much worse on $ than fine tuning maybe.
~ Surya Harsha Nunnaguppala|2023-04-25 21:33:54|‎~ Surya Harsha Nunnaguppala joined using this group's invite link
Twishmay Shankar|2023-04-25 21:35:01|But say we were using an open source model (Llama? alpaca? Of the future) where pricing isn’t a factor of token count. The large context window approach will work better with more flexibility?
Karan Lightspeed|2023-04-25 21:35:46|Open question still - anyone tried both approaches?
Shalabh Aspiro|2023-04-25 21:37:25|(Adding to what Karan said)  My experience with this- still iterating on this though... In rare usecases where LLM might not have seen that kind of data, fine-tuning might add value otherwise using few-shot prompting or coming up with even more complex chains for the usecase under consideration is sufficient
Pratyush Choudhury|2023-04-25 21:41:45|I think it's a function of Product maturity  Thinking out loud,  If I were experimenting the impact of GPT for my use-case/workflow, I'd almost always want to begin with few shot prompting to begin with and put the product in the hands of users, collect sufficient data and then experiment if fine-tuning with the collected data gives me better results  Anecdotally, it's also a function of the design requirement from a business perspective - if I support a multi-tenant architecture, every tenant might require a separate fine-tuned version of the same base model for various requirements
Shalabh Aspiro|2023-04-25 21:45:00|If it's a multi tenant setup, I think it's better to finetune on the combined data for all tenants and then use few-shot prompting to refine for every customer.  (Atleast that's what I am hoping to work 😂)
Pratyush Choudhury|2023-04-25 21:49:59|Umm, if I'm a chatbot/conversational AI company and have competing customers (say Axis and HDFC) as my clientele, I'd likely have a base model and fine-tuned (forked) versions of the same running inside the environments of Axis and HDFC  Either of them wouldn't be comfortable with me using their data to train my base model which can be offered to their competitor  I've seen the same concept in a different video analytics use-case - where CCTV camera feeds are analyzed to study multitude of things when deployed in a retail outlet
Pratyush Choudhury|2023-04-25 21:52:02|The former use-case was via anecdotal research  The later was from my personal experience as a Solutioning Exercise
Karan Lightspeed|2023-04-25 21:53:06|How much are we seeing Indian clients caring about their data being used for model training? Is it just regulatory heavy industries like banking or are non-reg industries saying the same? (Eg Ed-tech)
~ Sudhanshu Heda|2023-04-25 21:53:40|https://www.researchgate.net/publication/370213628_Scaling_Transformer_to_1M_tokens_and_beyond_with_RMT
Pratyush Choudhury|2023-04-25 21:54:23|Personal experience from a limited sample set - more about the use-case than regulations  Also, the more mature the company, the more concerns they raise  Happy to chat/share more 1:1
Shalabh Aspiro|2023-04-25 21:58:44|I think no ML product company can exist if *none* of their customers are ready to share their data for training purposes. So let's say big banks like Axis and HDFC are not ready, then the base model can't be trained on their data. But smaller banks might be ready to share their data for a lower price of implementation etc. (assuming this). So base model can be trained on the banks using the lower pricing tier and few shot prompting etc can be used for the Axis and HDFCs of the world, on-premise to make it work for their data.   If no one is sharing data, then you have to fine tune for everyone and the offering becomes closer to a service rather than a product in my opinion. Thoughts?
Karan Lightspeed|2023-04-25 22:00:23|Also important to build a differentiated solution. Else anyone can create the wrapper without fine tuning
Kartik Mandaville|2023-04-25 22:01:32|Well said. We have a similar vision - start with embeddings and then at some point fine tune per client (maybe per team)
Pratyush Choudhury|2023-04-25 22:01:36|Precisely why AI has higher marginal costs (and poorer GMs) than traditional cloud software  This is my biggest question to/for folks calling AI as the next biggest platform shift  Typical ways to bypass this though is to compensate those you're using the data from - either through partnerships or direct commercial agreements
Kartik Mandaville|2023-04-25 22:03:29|You can get away with embeddings right? So there’s no training?
Shalabh Aspiro|2023-04-25 22:10:21|discussing this for a complicated usecase where finetuning is required in some capacity. So pureplay embeddings and few shot prompting won't work is the assumption here.
Sumod K Mohan|2023-04-25 22:12:45|Those models doesn't not have RLHF etc, not just smaller models. So you will be seeing perf similar to GPT3 and some more: your fine tuning. You will need other models and then train RLHF or use one of the RLHF trained models and try. Haven't done the last part. You will most likely need to fine tune RLHF as well, as the new models might have drifted in the output space.
Kaustubh 2014|2023-04-25 22:16:15|‎Kaustubh 2014 joined using this group's invite link
Sumod K Mohan|2023-04-25 22:16:55|Very true. But at the same time all these companies are trusting MS, Goog and AWS with their data. One of our customers, large multinational, had absolute 'no' few weeks ago to if you can provide guarantee, nothing will be leaked, you can use OpenAI. Unfortunately, OpenAI fine print isn't that black and white.
Karan Lightspeed|2023-04-25 22:17:33|What's the exact fine print that is difficult to decipher?
Karan Lightspeed|2023-04-25 22:18:16|From what I understand, context is the application's and not Open AIs but want to understand this further.
Dev Aggarwal|2023-04-25 22:18:35|Tell them they’ll loose everything when their competition uses chatgpt to outperform them 😗😝
Karan Lightspeed|2023-04-25 22:19:30|Scare is definitely one approach haha :D
Pratyush Choudhury|2023-04-25 22:19:31|And it took the big 3 15 odd years to instil this trust  Which is why I really like AWS's push with Bedrock
Dev Aggarwal|2023-04-25 22:20:10|Or tell them you’re using azure, azure has like a direct passthrough of gpt
Amir Nagri|2023-04-25 22:20:16|Used replicate and runpod.io, would recommend both for serverless and stateful use cases
Pratyush Choudhury|2023-04-25 22:20:19|In typical Amazon fashion, better selection inside a VPC that customers trust with Anthropic which is possibly the biggest competitor to OAI today
~ Adhitya Swaminathan|2023-04-25 22:23:07|It feels like a good tool for scaffolding, but also a bit blind. The way the repo is also feels limiting.   It’s can also be a giant token consumption monster.
Sumod K Mohan|2023-04-25 22:24:25|"Their wordings are something like ""OpenAI may use content to provide and maintain services"". What he heard from an OpenAI engineer was won't be used for training* (*to be verified by the engineer). Don't know if Nirant or others heard an update from their team."
Dev Aggarwal|2023-04-25 22:30:03|https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy  The azure openai service is very clear on this.  “Microsoft hosts the OpenAI models within our Azure infrastructure, and all customer data sent to Azure OpenAI remains within the Azure OpenAI service”  “No prompts or completions are stored in the model during these operations, and prompts and completions are not used to train, retrain or improve the models.”
Karan Lightspeed|2023-04-25 22:31:04|"Open AI engineer Boris Power - ""Prompting leads to faster results, with fine tuning it's painful to edit with changing data. Use fine tuning for exact format of input and output and if you have lots of historical high quality data. New use cases - fine tuning acts a lot of cost. Fine tuning doesn't do well when you need to understand facts and then provide the output"" ‎[4/25/23, 22:32:00] Dev Aggarwal: ‎image omitted"
Sumod K Mohan|2023-04-25 22:33:01|Thanks for this. Could be helpful for us.
Kartik Mandaville|2023-04-25 22:33:32|They did say in an email that all data is deleted within 30 days and it’s not used for training
~ Hitech👽|2023-04-25 22:40:03|‎~ Hitech👽 joined using this group's invite link
~ Ramprashanth|2023-04-25 22:53:35|‎~ Ramprashanth joined using this group's invite link
Ravi Theja|2023-04-25 23:03:18|https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt - turnoff chat history on chatgpt
Karan Lightspeed|2023-04-25 23:06:34|Already did this. Like how this is fine print on the website since Sam said the purpose of releasing chatgpt to the world was (high frequency / diverse) user feedback.
Karan Lightspeed|2023-04-25 23:07:55|*this was
Anshul Khandelwal Invideo|2023-04-25 23:54:09|Openai doesn't need customer data to improve models at this stage.    No data sent over api by platform customers has ever been used.  When asked about it, they said they are just keeping the data around for 30 days for trust and safety.  As regards fine tuning, apart from it often not doing as well as prompt engineering, the other risk is that when a new model upgrade comes, it usually does better than the fine tuned model just out of the box.  We saw that with gpt4 and that trend is likely to continue.  As such, fine tuning is unlikely to be a reasonable moat for most players.
~ Riken Shah|2023-04-26 00:15:39|‎~ Riken Shah joined using this group's invite link
Sumod K Mohan|2023-04-26 00:27:45|OpenAI not needing data: Highly doubt that claim, they like everyone else would happily take more data. Esp when they are out of training data for GPT (they have exhausted text data). But also as feedback for fine-tuning layers like RLHF. The key there is they don't use API day, chatting on website probably will be used as is (which they say as well, in the free version). Ideally if they really don't need data, they should give a zero knowledge guarantee. They don't use input or output. But could they use intermediate layer info, can their folks eyeball it to improve the system. All those are probably open questions.
Sumod K Mohan|2023-04-26 00:30:14|I think multinationals too will move to start using them. Their models are quite good and it is just a matter of time.
Anshul Khandelwal Invideo|2023-04-26 00:36:21|They do need more data, just not api platform customer data.  They have sufficient data partnerships, etc.  This was their response to a very direct question when I was in their office.
Sumod K Mohan|2023-04-26 00:37:49|Data Partnership: Interesting.
~ Vishal|2023-04-26 00:39:43|‎~ Vishal joined using this group's invite link
Karan Lightspeed|2023-04-26 00:51:43|Anyone have a list of data partners for Open AI?
Anshul Khandelwal Invideo|2023-04-26 00:54:48|Nah... They don't talk about how they train their new models either in terms of data or architecture...  Their platform api  data policy is public info though...
Utkarsh Ohm Thoughtspot|2023-04-26 09:29:54|I spent a day in march at openai office when they have invited some startups. They are very much looking to get more data to train their models from the industry because they have exhausted internet and academic datasets. However their organization is so small that they are able to cater to partnership proposals only from the biggest tech companies right now, all of which are lining up at their door. Over time they may get to your request.
Vaibhavi Gangwar|2023-04-26 09:32:49|‎Vaibhavi Gangwar joined using this group's invite link
~ Priti|2023-04-26 09:36:14|‎~ Priti left ‎[4/26/23, 09:50:55] Nirant: ‎image omitted
Rahul Bhatnagar|2023-04-26 10:49:13|Woah, it would have easily made 90%'ile in my undergrad randomized algo course at IIT.
Nirant|2023-04-26 10:50:43|If it helps, BITS Pilani did not have a randomized algo course — we had a design and analysis of algorithms, which was more analysis than design: And even Turbo does better than on those questions (specially speed!) than I do even today 😅
Nirant|2023-04-26 10:53:38|Replit Codegen model is better than OpenAI Codex in many human eval tasks and at 2.7B params, wayyy smaller than OpenAI Codex, extremely over-trained by Chinchilla metrics  Built by former head of Google AI, less than 10-15 days of training perhaps 😅 https://twitter.com/amasad/status/1651019556423598081
Karan Lightspeed|2023-04-26 10:54:08|Apparently they built this under 2 weeks
Pratyush Choudhury|2023-04-26 10:56:42|https://twitter.com/Mascobot/status/1651022921056555008?t=3qozUieRAPdsnScv3XnQLw&s=19  Code + text datasets improves LLM performance at non-code tasks  Don't think this is discussed much
Nirant|2023-04-26 10:57:37|Widely known no? Even GPT3.5-turbo and GPT4 are a Codex iteration, not vanilla LLM?
Pratyush Choudhury|2023-04-26 10:59:08|Widely known to maybe scientists, not discussed much I feel  Someone was telling me that the probable reason for the same is the fact that most consumers of the tech this time around are outside of core ML
~ Shivansh Dadhich|2023-04-26 10:59:30|‎~ Shivansh Dadhich joined using this group's invite link
Nirant|2023-04-26 11:00:16|Fair, I might be suffering some form of inside-track groupthink here 😅  Also, _how_ the models are made isn't widely useful, is it?
Pratyush Choudhury|2023-04-26 11:06:17|To many, I wouldn't think it does  And the economics enthusiast in me likes it as it could be early signs of this tech becoming a utility (?)
Nirant|2023-04-26 11:06:50|Aligned, it's a utility like ec2 in 3 years or sooner
Diptanu Choudhury FB AI|2023-04-26 11:19:46|100% - this is the difference between AI now and 5 years back.
‪+91 85500 05447‬|2023-04-26 11:20:14|‎‪+91 85500 05447‬ left
Diptanu Choudhury FB AI|2023-04-26 11:20:28|The UX of consuming models was not great up until openai came into the picture.
Nirant|2023-04-26 11:22:15|Still kinda sad that HF hasn't learned this well enough tbh
Diptanu Choudhury FB AI|2023-04-26 11:22:56|Once we have a well supported IR which works across all platforms, serving and consuming models from source would become a lot easier too.
Diptanu Choudhury FB AI|2023-04-26 11:23:54|They were born at a different time. Compared to their competition at that time(2017-18) they have done well.
Diptanu Choudhury FB AI|2023-04-26 11:24:49|Almost everyone who does NLP now makes their models work their transformer library.
Diptanu Choudhury FB AI|2023-04-26 11:25:08|In 2018 we spent half a day finding out how to use a model someone trained lol
Pratyush Choudhury|2023-04-26 11:27:38|UX bhi and ML application development pipeline bhi 😅  Feature engineering et al was too complex for most companies to get going with AI
~ Shobhit Jaipurkar|2023-04-26 11:27:46|Stanford NLP 🤌🏼
Sudharshan GenAI|2023-04-26 11:32:17|https://www.reddit.com/r/StableDiffusion/comments/12yzd2a/google_researchers_achieve_performance/
Sudharshan GenAI|2023-04-26 11:32:25|Anyone working on ML on edge here?
Sudharshan GenAI|2023-04-26 11:32:30|This looks big
~ Chirag Ginglani|2023-04-26 11:33:16|‎~ Chirag Ginglani joined using this group's invite link
~ Abhishek Persad|2023-04-26 11:35:07|‎~ Abhishek Persad joined using this group's invite link
~ Naman Lahoty|2023-04-26 11:36:02|‎~ Naman Lahoty joined using this group's invite link
Diptanu Choudhury FB AI|2023-04-26 11:53:15|Some of this stuff like flash attention is generally applicable even on servers
Bulia Siddharth Aurashop|2023-04-26 11:53:57|Wow!
Gokul Krishnan|2023-04-26 11:56:58|https://www.qualcomm.com/news/onq/2023/02/worlds-first-on-device-demonstration-of-stable-diffusion-on-android
Gokul Krishnan|2023-04-26 11:57:10|Some earlier work from Qualcomm
Sumod K Mohan|2023-04-26 12:00:28|Pretty cool. Quite interesting that there is a huge jump from chatGPT. Will try this on the JEE ones we all were trying.
~ Natarajan|2023-04-26 12:01:34|‎~ Natarajan joined using this group's invite link
~ Sridhar A|2023-04-26 12:06:06|‎~ Sridhar A joined using this group's invite link
~ Bahulee Guha|2023-04-26 12:19:56|‎~ Bahulee Guha joined using this group's invite link
Nirant|2023-04-26 12:29:10|Palantir launches ChatGPT for war  https://twitter.com/KennethCassel/status/1650958033034309633
Sudharshan GenAI|2023-04-26 12:31:39|Damn expect anduril to come up with something too
~ Vishwajeet|2023-04-26 12:43:36|‎~ Vishwajeet joined using this group's invite link
Amir Nagri|2023-04-26 12:46:21|The full video link for those who are interested in involvement of tech in defence and future wars  https://youtu.be/XEM5qz__HOU
Kaushik Bokka|2023-04-26 12:50:17|this makes me sad
Dhruv Anand|2023-04-26 12:58:22|I hate that their tech usecases go from disaster relief efforts straight to drone warfare
~ Saksham|2023-04-26 13:25:16|‎~ Saksham joined using this group's invite link ‎[4/26/23, 13:41:07] Sumod K Mohan: ‎image omitted
Dev Aggarwal|2023-04-26 13:47:00|Well for one, this is clear proof that programmers are god living among us ☺️
Pratyush Choudhury|2023-04-26 13:47:29|Only 2 ML engineers that too :)
Dev Aggarwal|2023-04-26 13:53:09|Any idea how 10 days of traning time translates to total gpu time spent, i.e. including experiments?
~ Rahul|2023-04-26 14:03:36|‎~ Rahul left
~ Vaibhav Gupta|2023-04-26 14:12:41|‎~ Vaibhav Gupta joined using this group's invite link
‪+91 82105 79249‬|2023-04-26 14:16:01|‎‪+91 82105 79249‬ joined using this group's invite link
~ Shubham Srivastava|2023-04-26 14:17:50|‎~ Shubham Srivastava joined using this group's invite link
Vamshi|2023-04-26 14:20:53|I’ve worked with Pete Warden and the tinyml folks at Google, used to be with the company that owns the accelerators for their voice wake, happy to chat !
~ Manu Gupt|2023-04-26 14:21:14|‎~ Manu Gupt joined using this group's invite link
‪+91 83749 99651‬|2023-04-26 14:31:23|‎‪+91 83749 99651‬ joined using this group's invite link
~ Ravi|2023-04-26 14:33:01|‎~ Ravi joined using this group's invite link
Sudharshan GenAI|2023-04-26 14:33:57|Wonderful!
Sudharshan GenAI|2023-04-26 14:33:58|Will DM
~ Sharans Kabra|2023-04-26 14:37:56|‎~ Sharans Kabra joined using this group's invite link
~ Rishiķesh|2023-04-26 14:43:06|‎~ Rishiķesh joined using this group's invite link
~ Error 404!|2023-04-26 14:48:53|‎~ Error 404! joined using this group's invite link
~ Sharma|2023-04-26 15:16:37|‎~ Sharma joined using this group's invite link
~ Priyansha|2023-04-26 15:19:48|‎~ Priyansha joined using this group's invite link
~ Utsav|2023-04-26 15:24:35|‎~ Utsav joined using this group's invite link
~ Shreyansh|2023-04-26 15:28:15|‎~ Shreyansh joined using this group's invite link
~ Sandeep Kumar|2023-04-26 15:29:50|‎~ Sandeep Kumar joined using this group's invite link
~ Parth|2023-04-26 15:35:10|‎~ Parth joined using this group's invite link
~ Arjun Narain|2023-04-26 16:09:46|‎~ Arjun Narain joined using this group's invite link
Twishmay Shankar|2023-04-26 16:12:48|Anyone knows how they did it with 1/10th the parameter count?  More training data? More training cycles? Better quality of data from their platform?
Twishmay Shankar|2023-04-26 16:15:30|Keeping it coming pls. Beginner insights most welcome Some of us still noobs in the group. 3 month old industry for us 😂
~ Shaarang|2023-04-26 16:15:47|‎~ Shaarang joined using this group's invite link
Twishmay Shankar|2023-04-26 16:21:50|Anyone here worked with music generation / audio generation / jingle generation / song generation / new AI instruments => pls do share and open for discussions over DM 🙏 🎼
Nirant|2023-04-26 16:23:02|Doesn't look like they've some unfair data (qty or quality advantage) — they just decided to test Chinchilla limits and that worked. They trained for a lot more tokens than most people have tried for similarly sized models.   There was some research in Feb from the same guy who now works with Replit that existing LLMs might be overparameterized!
Nirant|2023-04-26 16:23:26|PSA: Dedicated group for music, images, video: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J
Twishmay Shankar|2023-04-26 16:23:51|If anyone remotely knows this person. An expert talk by then would be helpful ++
Twishmay Shankar|2023-04-26 16:24:00|them *
Nirant|2023-04-26 16:24:14|Replit Demo Day videos are soon going to be on Youtube from what I hear
Twishmay Shankar|2023-04-26 16:24:37|To all the silent VCs in this group feeding this chat thread to an LLM, pls help 🙏 😂
Nirant|2023-04-26 16:25:53|Slide Deck from Accel's [PHONE] on opportunities in Generative AI, finetuning vs prompting and so on. Worth your 5 minutes.   https://bit.ly/ai-webinar-ps  (Note: This is how it's supposed to be shared, have someone else e.g. one of the mods share your content)
Anshul Bhide Replit|2023-04-26 16:26:08|yeah will be up tomorrow - and the model should be released soon as well
Twishmay Shankar|2023-04-26 16:26:25|Thanks!
Nirant|2023-04-26 16:26:32|Thanks Anshul sir! Anshul sir [PHONE] leads Replit India ‎[4/26/23, 16:33:16] Twishmay Shankar: ‎image omitted
Sudharshan GenAI|2023-04-26 16:38:18|Thanks! Was this a closed session?
Prayank Swaroop Accel|2023-04-26 16:38:52|Yes Sudharshan .. i did this for Accel funded startups - founders and tech teams
Sudharshan GenAI|2023-04-26 16:40:40|Alright thanks, was going to ask for invites to future sessions - this is really good
~ Monty|2023-04-26 16:41:13|‎~ Monty joined using this group's invite link
Belong Saiteja|2023-04-26 16:41:14|‎Belong Saiteja joined using this group's invite link
~ Arpit|2023-04-26 16:41:51|‎~ Arpit joined using this group's invite link
Sudharshan GenAI|2023-04-26 17:06:14|https://twitter.com/matthieurouif/status/1650904940036890626  Smart - Suggests backgrounds for objects automatically  1) I think they use a multimodal model to understand the object 2) Ask GPT-4 to suggest backgrounds for the object 3) Generate appropriate backgrounds for the object
Dev Aggarwal|2023-04-26 17:07:29|The gpt-4 multimodal model has an api yet? I thought it was chatgpt only
Nirant|2023-04-26 17:08:06|GPT4 takes text in and can generate prompt for a SD/Midjourney landscape
~ Blessin Varkey|2023-04-26 17:10:18|They use photoroom  https://www.photoroom.com/api ‎[4/26/23, 17:10:46] ~ Blessin Varkey: ‎image omitted
Sudharshan GenAI|2023-04-26 17:11:31|Not out, you can use https://minigpt-4.github.io/ or https://llava-vl.github.io/  Quite good
Sudharshan GenAI|2023-04-26 17:11:43|Doesn't have image understanding
Dev Aggarwal|2023-04-26 17:11:47|https://dust.tt is awesome!
Sudharshan GenAI|2023-04-26 17:11:50|It's internal for now
Sudharshan GenAI|2023-04-26 17:12:39|better than modal or runpod?
Vamshi|2023-04-26 17:12:58|Shared interest, please keep me posted on your connects !
Dev Aggarwal|2023-04-26 17:13:56|It has an interesting ui for chaining prompts. I prefer python f-strings ofcourse, but the concept is interesting in its own
~ Rachitt|2023-04-26 17:14:56|Dust.tt is amazing!
~ Dhiraj|2023-04-26 17:18:50|‎~ Dhiraj joined using this group's invite link
Sudharshan GenAI|2023-04-26 17:19:18|Nice looking at the docs
Shashank Generative AI Group|2023-04-26 17:19:56|i don't get it. what's novel about this? segment, get image caption using any model blip, sam etc. then prompt gpt-4 to create background for photoshoot. then inpaint. right?  i only have doubt regarding how the shadow of the knight is added, does inpainting take care of that?  does one really need photoroom models specifically to achieve similar results?
~ Blessin Varkey|2023-04-26 17:26:29|https://www.linkedin.com/posts/genai-center_ai-generated-pizza-commercial-tools-used-activity-7056952600516046848-mvqm?utm_source=share&utm_medium=member_ios  AI-Generated Pizza Commercial  Tools used:  - Script: GPT4 - Images: Midjourney - Video Clips: Runway Gen2 - VO: Eleven Labs - Music: SOUNDRAW AI Music - Graphics and editing: Adobe After Effects
~ Pratyush Rai (Foyer)|2023-04-26 17:46:49|[PHONE] is playing with music gen these days
Nirant|2023-04-26 17:46:56|Novelty isn't the only dimension. Ease of use is greatly improved and tons of Shopify stores which sell everything from soaps and other trinkets would love this.   Not to mention IG influencers, and their teams :)
Shashank Generative AI Group|2023-04-26 17:53:25|oh totally agreed! my initial impression from the post here was that there's something new... technically speaking (as a lot of folks here are technical).   hence the question :)
Sudharshan GenAI|2023-04-26 17:56:06|The application.
~ Umang Keshri|2023-04-26 18:05:45|‎~ Umang Keshri joined using this group's invite link
~ °|2023-04-26 18:06:44|‎~ ° joined using this group's invite link
~ Sushiee|2023-04-26 18:08:27|‎~ Sushiee joined using this group's invite link
~ dolly|2023-04-26 18:09:20|‎~ dolly joined using this group's invite link
~ Puneet|2023-04-26 18:13:39|‎~ Puneet joined using this group's invite link
~ Lakshika|2023-04-26 18:16:04|‎~ Lakshika joined using this group's invite link
~ Tanisha…|2023-04-26 18:20:27|‎~ Tanisha… joined using this group's invite link
~ Yash Raj Ojha|2023-04-26 18:24:56|‎~ Yash Raj Ojha joined using this group's invite link
Amir Nagri|2023-04-26 18:25:08|Went through this, this is very useful  Do count me in as well for the next in person or online sessions 🙂
Amir Nagri|2023-04-26 18:27:17|Resharing the link, as someone has recently joined and is curious about the deck DM'ed   https://bit.ly/ai-webinar-ps
Prayank Swaroop Accel|2023-04-26 18:31:40|Folks any recommendations other than Google Colab for accessing GPUs ? (I'm ok with 5-6$ per month cost also) - mostly hobbyist dabbling
Pratyush Choudhury|2023-04-26 18:37:42|How's the availability on Amazon Sagemaker?  Should be good for hobby use-cases I'd guess
~ Ganga|2023-04-26 18:38:27|‎~ Ganga joined using this group's invite link
Dev Aggarwal|2023-04-26 18:38:49|Might not be applicable for everyone, but I think by far the fastest and best experience would be to apply for google cloud startup credits, and use a dedicated A100 for colab.  https://cloud.google.com/startup  https://research.google.com/colaboratory/marketplace.html
Twishmay Shankar|2023-04-26 18:39:25|Jupiter on VS Code with Banana on backend will cost ₹150/hour.   Deepnote offers a hosted service with a great free tier for this too but not on best GPUs.
Twishmay Shankar|2023-04-26 18:39:43|^ banana.dev also has a great free tier for 1 hour of use
Pratyush Choudhury|2023-04-26 18:40:30|Should still be good for tinkering use-cases I'd guess?
Twishmay Shankar|2023-04-26 18:40:36|Really nice for notebooks / automation / scripting  https://deepnote.com/
Twishmay Shankar|2023-04-26 18:41:40|Yes. Community model templates allow one click deployment. For 50+ models. Simple docs.
Shashank Generative AI Group|2023-04-26 18:43:05|Kaggle
Prayank Swaroop Accel|2023-04-26 18:43:37|I want to experiment with deploying StableDiffusion and running Gradio/Automatic1111 ... will also want to keep some of the models like Lyriel / Deliberate + Controlnets  etc .. so need storage ~50GB ... I'm newbie to serverless .. but I don't think serverless GPUs will cut it for this usecase
Sankalp PickYourTrail|2023-04-26 18:46:27|You can try paperspace, they are undercutting big tech on GPUs. https://www.paperspace.com
Prayank Swaroop Accel|2023-04-26 18:46:50|they have 5GB space on the Gradient .. 🙁 ‎[4/26/23, 18:47:49] Prayank Swaroop Accel: ‎image omitted
Prayank Swaroop Accel|2023-04-26 18:47:59|Google Colab is $12 - and 50GB
Aakash Kumar  Matrix Partners|2023-04-26 18:50:19|I have been using my Mac Pro as a server at home + socket + multiple LMs. Works like a charm :)
Aishwarya Goel Inferless 5s for 5G|2023-04-26 18:51:25|You can keep the model storage on hugging face and then use any serverless gpu player to import your model from there directly.
Prayank Swaroop Accel|2023-04-26 18:52:06|Will try this !
~ Shubhodeep|2023-04-26 18:52:54|‎~ Shubhodeep joined using this group's invite link ‎[4/26/23, 18:53:11] Sankalp PickYourTrail: ‎image omitted
~ Omkar|2023-04-26 18:56:01|‎~ Omkar joined using this group's invite link
~ .|2023-04-26 18:56:15|‎~ . joined using this group's invite link
~ kashish|2023-04-26 19:02:16|‎~ kashish joined using this group's invite link
~ Rahul Thota|2023-04-26 19:11:25|‎~ Rahul Thota joined using this group's invite link
~ Nikhilesh Jha|2023-04-26 19:11:46|‎~ Nikhilesh Jha joined using this group's invite link
Sthit Generative AI WhatsApp Group|2023-04-26 19:12:14|‎Sthit Generative AI WhatsApp Group joined using this group's invite link
Amir Nagri|2023-04-26 19:40:26|This doesn't work, start up credits cannot be used for colab, they have separate billing
~ Sharans Kabra|2023-04-26 19:41:04|‎~ Sharans Kabra left
Dev Aggarwal|2023-04-26 19:41:34|Yes, but now you can connect a gce vm to colab, giving you persistent sessions and dedicated compute
Dev Aggarwal|2023-04-26 19:41:49|https://research.google.com/colaboratory/marketplace.html
Amir Nagri|2023-04-26 19:43:06|Can recommend runpod, stop the instance when not using, will only be charged for storage  Similar options for jarvislabs, paperspace  At one point we using paperspace but then they kept running out of affordable GPUs like rtx5000, so switched, but things might have changed now
Soumyadeep Mukherjee|2023-04-26 19:51:08|Buy a 3080 machine. Looks like we are moving back to a world where we all have a desktop at home 😅
Soumyadeep Mukherjee|2023-04-26 19:52:01|On a more serious note, runpod, lambdalabs, fluidstack. Keep moving around 😅
Prayank Swaroop Accel|2023-04-26 20:50:30|Finally buckled to Google Colab - 100 compute units for 12$ - 2 units per hour for StableDiffusion stuff that I'm doing - so 50 hours of stable diffusion for 1000 rs or 20rs / hour FYI.
Dev Aggarwal|2023-04-26 20:52:39|Does anyone know what compute units mean? ‎[4/26/23, 20:55:21] Prayank Swaroop Accel: ‎image omitted
Sankalp PickYourTrail|2023-04-26 20:55:37|I asked gpt. this maybe helpful  For example, a Tesla K80 GPU, which is one of the most commonly used GPUs on Google Colab, provides approximately 12 compute units per hour. This means that if you use a Tesla K80 GPU for an hour, you will be charged for 12 compute units
Twishmay Shankar|2023-04-26 20:55:44|Back to On Prime? 😂
Twishmay Shankar|2023-04-26 20:56:15|What GPU do they offer at this price? How much RAM for SD?
Twishmay Shankar|2023-04-26 20:56:31|T4 24GB think for this rate
Dr. Pratik Desai KissanGPT|2023-04-26 20:57:56|"""No One Knows What It Means But It's Provocative, It Gets The People Going"" 🤣"
Dev Aggarwal|2023-04-26 20:58:07|Are these instances persistent? Or do yoh still have to do the google drive hack ‎[4/26/23, 20:59:23] Dev Aggarwal: ‎image omitted
Prayank Swaroop Accel|2023-04-26 21:03:40|not persistent
Aishwarya Goel Inferless 5s for 5G|2023-04-26 21:04:30|Which platform is this?
Dev Aggarwal|2023-04-26 21:06:18|Google cloud
Twishmay Shankar|2023-04-26 21:11:38|For non persistent / spot instances of GPUs GOOG was always in under supply while we were testing.   Hence spot prices there are always cheaper than reserved prices; but you don’t get them on time in real time inference at various times.
Pratyush Choudhury|2023-04-26 21:31:07|https://www.chartgpt.dev/  Very nifty product this, loved it
Pratyush Choudhury|2023-04-26 22:10:08|https://news.ycombinator.com/item?id=35697627  Some very interesting discussions/comments in the thread
Krishna Ntkris|2023-04-26 23:08:22|For anyone using Weaviate, do you store all of your metadata in Weaviate or in a different DB?
Krishna Ntkris|2023-04-26 23:09:13|Context: I'm using Pinecone and I'm saving most of my content in a different db (pinecone has a limit on size of meta data). Want to know if that is required / recommended for other Vector DBs like Weaviate
~ Rohit|2023-04-26 23:12:34|whats the major difference between storing it in vector dbs and something like a numpy array? is retrieval super fast for say 1000s of vectors
Krishna Ntkris|2023-04-26 23:13:53|Yep, our app allows users embed content so we need containerization + expect this to increase significantly (🤞). If you are building a vertical app (only embedding content yourself), numpy is probably ok - others probably have a better view tho
Anshul Bhide Replit|2023-04-26 23:30:52|https://www.youtube.com/watch?v=7TCqGslll-4
Dev Aggarwal|2023-04-26 23:57:00|https://github.com/ai-forever/Kandinsky-2  Came across a cool looking text2img model
Sidhant Sequoia|2023-04-27 00:06:54|https://twitter.com/rasbt/status/1651226178353614854?s=48&t=ACPHEfclkXmi9Z92RTsh9g
Vimal Singh Rathore|2023-04-27 00:34:46|[PHONE]
Aashay Sachdeva MPL Data Scientist|2023-04-27 00:52:14|‎Aashay Sachdeva MPL Data Scientist joined from the community
~ raj()|2023-04-27 00:58:01|In Weaviate itself. It also allows to do pre filtered vector search based on the metadata, it internally builds separate indices for the metadata as well.
~ Sandeep Kumar|2023-04-27 01:01:49|‎~ Sandeep Kumar left
Krishna Ntkris|2023-04-27 01:03:29|Oh cool, so you could store everything in weviate? Is the cost prohibitive? For example, if metadata is chunks of text
~ raj()|2023-04-27 01:06:11|Their managed SaaS  right now actually charges only based on the number of vectors and the dimensions of the vectors, irrespective of the extra metadata stored  https://weaviate.io/pricing
~ Tatparya Shankar|2023-04-27 02:19:48|‎~ Tatparya Shankar joined using this group's invite link
Anagh Prasad|2023-04-27 03:50:10|Replit's latest announcement is interesting: https://twitter.com/swyx/status/1650989632413401089?s=20
Shashank B Designer|2023-04-27 06:59:32|Anyone started learning LLMs/Transformers/ML in the last 3 months? I’d like to discuss and exchange notes 😁
Sakshi Khatabook|2023-04-27 07:14:27|‎Sakshi Khatabook joined using this group's invite link
~ Kuldeep Saxena|2023-04-27 07:29:41|‎~ Kuldeep Saxena joined using this group's invite link
Aditya Agrawal SuperU|2023-04-27 08:44:40|Let’s do a zoom session to discuss?
Kartik Mandaville|2023-04-27 08:46:34|How are people here dealing with rate limits, 5xx with OpenAI? Exponential backoff is what we have but its such poor UX
Kartik Mandaville|2023-04-27 08:47:07|bumping - has anyone been able to solve?
~ Nilay Pochhi|2023-04-27 08:48:56|I faced this problem before. We used some form of leaky bucket to smoothen the API calling rate.
~ Nilay Pochhi|2023-04-27 08:50:03|Not particularly for OpenAI but for a general solution for limiting API calling rates.
Rohit Aggarwal|2023-04-27 08:53:43|429s, use the retry-after. Are you getting rate limited for requests or tokenS?  500s - random jitter back off with fallbacks to 3.5 is the better experience
Kartik Mandaville|2023-04-27 08:55:17|all types of errors now. I wish there was a middle layer to solve this
Rohit Aggarwal|2023-04-27 09:09:20|:)
~ Aashish Loknath Panigrahi|2023-04-27 09:25:47|‎~ Aashish Loknath Panigrahi joined using this group's invite link
Lalit Pagaria|2023-04-27 09:48:17|Any proxies like Nginx with Lua JIT or Envoy with WASM/Lua can be used for production setup without adding any much latency and performance overhead.
Nirant|2023-04-27 09:49:22|Can you elaborate and/or share links? Hearing about Lua JIT and WASM in this context for the first time 😅
Lalit Pagaria|2023-04-27 09:54:14|https://openresty.org/en/
Lalit Pagaria|2023-04-27 09:55:46|https://tetrate.io/blog/wasm-modules-and-envoy-extensibility-explained-part-1/
Lalit Pagaria|2023-04-27 09:58:49|These enovy, istio, nginx are API proxy and they have a customised layer where we can add multiple filters. These filters can extend functionality. Which you can write in Lua, Wasm etc. Lua interpreters bring less overhead and way faster than python interpreter.
Lalit Pagaria|2023-04-27 10:04:50|Things like if you are testing multiple models on production one is main other are tests. And you like to send prod requests to all and then like to monitor outcomes. For this generally you need to write code. But in the case of these proxies you simply need to write small Lua or even yaml. And this proxy itself sends requests to all these services (which host models) and passes the response of the main service to the caller/client.  Actually there are multiple ways to achieve the same thing, this one is from DevOps/SRE perspective 😅
Shashank B Designer|2023-04-27 10:21:36|Thanks to those who reached out.  Thinking of proceeding this way: - Resources are being compiled here - https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240 - To participate (AKA edit the sheet ; discus on what else we can do) ping me
Aashay Sachdeva MPL Data Scientist|2023-04-27 10:28:56|Hey, I have been trying to train Indic-BloomLM (bloom finetuned on Indian language dataset via LoRA). I am stuck with this weird bug that everytime the forward pass happens it keeps occupying more and more gpu memory and then runs out of it. (Have tried all batch + gradient accumulation + gradient checkpoint combos).  This is the closest issue I have seen to my problem - https://github.com/huggingface/peft/issues/161  Anyone has any idea/has previously solved this. It would be great to connect. I have been banging my head on this for a few days now.
Shashwat TDC|2023-04-27 10:50:58|Guys quick question.   What does the model suffix stand for? Eg. gpt-3.5-turbo gpt-3.5-turbo-0301 ‎[4/27/23, 10:52:37] jyotirmayjk Hackathon: ‎image omitted
Anshul Bhide Replit|2023-04-27 10:52:37|https://twitter.com/raj_raj88/status/1631018786492157954
Anshul Bhide Replit|2023-04-27 10:53:00|i guess 302, 303 etc. are later versions
Shashwat TDC|2023-04-27 11:00:05|Not clear to me what does snapshop mean here. If this model is to be deprecated in 3 months, what's the need in the forst place. Is there a specific reason of not following conventional versioning. Would appreciate if someone can eli5
Nirant|2023-04-27 11:02:33|"Think of a continuous model training process with multiple forks, each ""named"" or versioned model is a actually a checkpoint in that.   So if you want to build on the latest model, the underlying behaviour might keep changing — so they're giving a named version for that, but it'll be deprecated. This ensures that the _behaviour_ change is explicit instead of implicit."
Nirant|2023-04-27 11:03:32|Workflow wise: Say you build on 0314 or any other 3 month model, when it gets deprecated, you have to explicitly upgrade and you'll be prepared to run your entire battery of tests again. This is better than a silent upgrade where the behaviour of underlying model changes silently.
Nirant|2023-04-27 11:03:36|Does this help?
Shashwat TDC|2023-04-27 11:06:38|Yes but basis this tweet https://twitter.com/raj_raj88/status/1631018786492157954 my understanding is 3.5-turbo refers to the latest model 3.5-turbo-x   If both model refer to the latest checkpoint then what's the need of retaining the snapshot explicitly - got me confused.
Nirant|2023-04-27 11:07:20|Let me move this to DM, need to understand your query better 😅
~ The Last Samurai|2023-04-27 12:08:45|Might be useful for you,i was trying to train a Bloom model  and i was running out of GPU memory..and this gradient notebook helped me https://github.com/rasbt/gradient-accumulation-blog/blob/main/src/1_batchsize-1.py where if we want to use a batch size of 256 but can only fit a batch size of 64 into GPU memory, we can perform gradient accumulation over four batches of size 64. (After processing all four batches, we will have the accumulated gradients equivalent to a single batch of size 256.) This allows us to effectively emulate a larger batch size without requiring larger GPU memory or tensor sharding across different devices.
Aashay Sachdeva MPL Data Scientist|2023-04-27 12:17:07|As I have mentioned, tried all possible combinations with gradient accumulation as well. Problem is of memory leak
~ Srinivasan Nandakumar|2023-04-27 12:40:01|If you are facing GPU constraints you can try using the quantized version and fine tuning using lora+ bits and bytes
~ Srinivasan Nandakumar|2023-04-27 12:41:04|Okay my bad I see you are already using peft
Harsh Koo|2023-04-27 12:55:56|Based on cursory research, rundiffusion seems like a good hosted solution for automatic SD UI.   If anyone has any gotchas using this please do tell 🙏  I want to give my design team the UI to play with for a day or two.
Sudharshan GenAI|2023-04-27 13:07:17|It's pretty good, just not that well known ‎[4/27/23, 13:08:25] Sudharshan GenAI: ‎image omitted
Harsh Sharma SRM 2023|2023-04-27 13:29:58|Hey Guys I need some advice  I have a few deep learning projects which I have to run on GPU - can you tell me any service or firm name which I can consider ? I am looking for a decent GPU - like V100 or A100 not very high end over cloud I have used Colab pro - its useless - no use when the computing credits are over
Pratyush Choudhury|2023-04-27 13:35:12|https://twitter.com/Replit/status/1651344182425051136?t=246tp7Zj7ABXzT7FXB936g&s=19  At the risk of sparking a debate on Smaller Models vs Larger Models for production workloads  What do people here think?  This is a surprising result by a team of 2 people and 10 days of training
Aashay Sachdeva MPL Data Scientist|2023-04-27 13:37:05|You can try qblocks.cloud
~ Prajwal|2023-04-27 13:37:06|Tried serverless GPUs like bananadev?
Aashay Sachdeva MPL Data Scientist|2023-04-27 13:37:29|I am using this. Comes to around 1 dollar for 24gb GPU
Harsh Koo|2023-04-27 13:50:49|This is some kind of membership. Optional I think
Akash Chandran|2023-04-27 13:52:46|any devrels here ?
~ Monty|2023-04-27 13:52:48|‎~ Monty left
~ Aman|2023-04-27 13:54:12|This has some nice comparison of serverless platforms  https://www.inferless.com/serverless-gpu-market
Anshul Bhide Replit|2023-04-27 13:57:01|You’re welcome to try it out for yourself next week when it drops :)
Anshul Bhide Replit|2023-04-27 13:57:22|Also the LLM relevant stuff is 46:00 onwards
Pratyush Choudhury|2023-04-27 13:58:38|Already signed up & looking forward :)
Poorvi Vijay Elevation SAIF|2023-04-27 13:59:44|This is optional but might turn out to be cheaper if you are using it for high-velocity use cases. I have tried the Automatic1111 on SD V1.5 and is pretty decent for playing around.
Kartik Mandaville|2023-04-27 14:03:54|Has anyone gotten higher rate limits from OpenAI?
Nirant|2023-04-27 14:06:27|cc [PHONE] has among the largest OpenAI bills in India, [PHONE] used to work with the same team
Puneet Lamba Aspiro|2023-04-27 14:21:09|Names please? 😅 (I see Rohit’s)
Rohan Babu|2023-04-27 14:32:46|Can this be used to solve marketing problems?
Nirant|2023-04-27 14:33:02|Anirudh Singla of Pepper Content and Rohit (now of Portkey), earlier at Pepper Content
Rohit Aggarwal|2023-04-27 14:43:23|yes, we got it upgraded multiple times at Pepper. (This is Rohit)
Aakrit Vaish Haptik PeerCheque|2023-04-27 16:08:42|‎Aakrit Vaish Haptik PeerCheque joined using this group's invite link
Kartik Mandaville|2023-04-27 16:11:11|was it for GPT4? or GPT3.5?
Ankur Pandey|2023-04-27 16:15:21|Yes. Take usually 2-3 days. Applies for all incl gpt4
~ Sujay Choubey|2023-04-27 16:26:28|‎~ Sujay Choubey joined using this group's invite link
~ Ankur Khandelwal|2023-04-27 16:38:30|Applied via the google forms or something else. I tried it but never got reply from them. also they have not increased rate-limit too
Ankur Pandey|2023-04-27 16:40:33|Stand corrected.. i misread it as quota increase. We had applied for rate limit increase a few months back (in 3.5) - took 2/3 days based on what I recall
Pranjal Mehta|2023-04-27 16:54:14|Hi. I'm hosting a talk by two leading US researchers in AI at 7:30 PM in Indiranagar today. Here is a link for the same: https://lu.ma/StateofAI  Sorry for the last minute invite. It is an ad-hoc event (got it all together in the last hour).
Pranjal Mehta|2023-04-27 16:55:35|We are limited to 20 seats so pardon me if we're unable to accommodate all
Nirant|2023-04-27 16:57:04|Just in the spirit of full disclosure: Please consider this a community event as well. Pranjal [PHONE] isn't doing self promotion here :).
Pranjal Mehta|2023-04-27 16:58:01|Oh yes thanks. It's free and there are no affiliations. Just shared passion for AI
Pranjal Mehta|2023-04-27 16:59:16|20 seats is a venue constraint
Pranjal Mehta|2023-04-27 17:00:02|[PHONE] truly missing your organising skills and energy today 😅
Lalit Pagaria|2023-04-27 17:38:28|Nirant is a one man army
Pranjal Mehta|2023-04-27 17:39:07|We've hit capacity. Optimising for maximum participation by limiting it to one VC per firm. Please pardon 🙏
Dhruv Anand|2023-04-27 17:39:20|Any chance of a live stream/recording?
Nirant|2023-04-27 17:39:59|It appears that way, but in practice, I'm simply the face for the work done by multiple folks e.g. [PHONE], [PHONE], [PHONE], Hasgeek crew: [PHONE] and co
Pranjal Mehta|2023-04-27 17:40:18|Don't have the infra/team. Sorry ‎[4/27/23, 17:43:55] Dev Aggarwal: ‎image omitted
Puneet Lamba Aspiro|2023-04-27 19:00:59|Is this happening? 🙂
~ Kaustav K Bose|2023-04-27 19:02:01|Any recommended resources?
Aashay Sachdeva MPL Data Scientist|2023-04-27 19:03:47|Try training your own via huggingface. I did that and learnt a lot more (had to beat my head around a lot)
Nirant|2023-04-27 19:04:15|1. https://course.fast.ai — probably the best there is  2. CS25 on Transformers: https://web.stanford.edu/class/cs25/ 3. HF Transformers Course: https://huggingface.co/learn/nlp-course/chapter1/1
Nirant|2023-04-27 19:04:30|3 is more NLP focussed, 2 is broader ranging from Vision to Speech and what not
Shashank B Designer|2023-04-27 19:10:09|Thanks Aashay and Nirant.  Have added these to the earlier shared sheet.
Shashwat TDC|2023-04-27 19:11:23|could you pls reshare or perhaps link it in group desc
Shashank B Designer|2023-04-27 19:13:20|https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
Shashank B Designer|2023-04-27 19:19:56|It starts from scratch. Not sure if useful to many here. Anyway Admin’s call if they want to add it group  desc
~ just_a_tofu|2023-04-27 20:52:30|https://twitter.com/andrewyng/status/1651605660382134274?s=46&t=wdMpftHBI367157ViAY2Gg
Bharat Kumar Ramesh Hashmal Web3|2023-04-27 20:54:52|Pinecone raised 100m
Bharat Kumar Ramesh Hashmal Web3|2023-04-27 20:55:04|https://twitter.com/pinecone/status/1651602704647553028?t=4BEHwzuba9-bvJ_ocusDQQ&s=19
Amir Nagri|2023-04-27 21:08:23|It's having the nvidia moment in age of langchain , good to raise when you have the buzz
Bharat Kumar Ramesh Hashmal Web3|2023-04-27 21:09:21|Yeah, also serendipity is a beautiful thing. Started in W15 cohort 8 years ago, to build for the vector search market. Raised series A after 7 years  And then Gen AI comes along and floods your TAM like a tsunami
Bharat Kumar Ramesh Hashmal Web3|2023-04-27 21:09:45|Took 8 years to be in the right place at right time. More power to them
Nirant|2023-04-27 21:10:15|Pinecone proves beyond doubt that DevRel matters a ton for Dev products. There's a ton of cheaper products, but James Briggs is a league of his own. Enviable execution!
Nirant|2023-04-27 21:10:29|This.
~ 🌞  🌈 💧|2023-04-27 21:16:20|‎~ 🌞  🌈 💧 left ‎[4/27/23, 21:21:01] Amir Nagri: ‎image omitted ‎[4/27/23, 21:21:24] Amir Nagri: ‎image omitted
Kartik Mandaville|2023-04-27 21:25:34|Woah! Have to say they’re good - literally 0 issues since we launched with them
Anshul Bhide Replit|2023-04-27 21:35:27|agreed, love his videos
~ Sanjeed|2023-04-27 21:43:15|For anyone looking for them:  https://youtube.com/@jamesbriggs
Pratyush Choudhury|2023-04-27 21:53:09|Oh absolutely,  This is true for any developer product and especially with emerging platform shifts  As new workflows emerge, there's new opportunity for tooling  Redis and Pinecone are very, very good with DevEx and DevRel around that
Pratyush Choudhury|2023-04-27 21:55:17|I have a friend there and he was telling me about their production traction from India - it's significant
Anshul Bhide Replit|2023-04-27 21:59:11|any idea if these individuals devs using it or more startups / small companies?
Pratyush Choudhury|2023-04-27 22:00:39|Startups/companies  We were talking about how to separate the control and data plane to adhere to data residency rules in India  And almost all of this traction is on AWS for the time being
Kartik Mandaville|2023-04-27 22:02:12|yes / would love to know who all so can share learnings. We are at 20K vectors
Lalit Pagaria|2023-04-27 22:06:56|Their content game is also great. In most AI keywords they are within 5.
Aishwarya Goel Inferless 5s for 5G|2023-04-27 22:23:01|https://www.databricks.com/blog/contributing-spark-loader-for-hugging-face-datasets
Aditya Agrawal SuperU|2023-04-27 23:01:34|Haan we can plan one on weekend. [PHONE]  would you want to take a lead on this?  cc [PHONE]
~ Krishna|2023-04-27 23:15:04|‎~ Krishna joined using this group's invite link
Shashank B Designer|2023-04-28 00:00:24|Sure
Shashank B Designer|2023-04-28 00:07:52|‎POLL: What time do you prefer for the Zoom discussion on “Learning Transformers / NLP / ML” ‎OPTION: Sat, 29th evening (5-6pm) (3 votes) ‎OPTION: Sat, 29th night (8-9pm) (4 votes) ‎OPTION: Sun, 30th morning (11-12pm) (2 votes) ‎OPTION: Sun, 30th evening (4-5pm) (39 votes) ‎OPTION: Sun, 30th night (8-9pm) (4 votes) ‎OPTION: Next weekend - Saturday (0 votes) ‎OPTION: Next weekend - Sunday (0 votes)
Shashank B Designer|2023-04-28 00:08:55|(There is a Nvidia-HF event on Saturday morning, hence kept slots after that)
Satish DeepHack Sponsor|2023-04-28 00:12:06|Online ? URL ?
Dev Aggarwal|2023-04-28 00:13:22|https://sites.google.com/huggingface.co/generative-ai-meetup  The registrations are closed though, I'm looking for invites too
~ Rakesh|2023-04-28 00:37:58|‎~ Rakesh joined using this group's invite link
Shashank B Designer|2023-04-28 00:38:08|Need an experienced person to guide and answer queries.. volunteer please
Aditya Ankur|2023-04-28 01:18:41|‎Aditya Ankur left
Pratyush Choudhury|2023-04-28 01:35:59|https://twitter.com/thesephist/status/1651677221797371904?t=UAtNw7WFH00_AS5oGpirUw&s=19  Didn't know that Notion uses Anthropic LLMs
Twishmay Shankar|2023-04-28 01:37:26|https://www.euractiv.com/section/artificial-intelligence/news/meps-seal-the-deal-on-artificial-intelligence-act/ ‎[4/28/23, 02:34:58] Sudharshan GenAI: ‎image omitted
Ojasvi Yadav|2023-04-28 02:36:05|same
Dev Aggarwal|2023-04-28 02:46:02|haha, whose place is this party going down at
~ Rohan|2023-04-28 03:27:34|Has anyone heard of using diffusion for detection / recognition or segmentation tasks? I've heard some chatter e.g. Tesla using diffusion as part of their lane detection algorithm, but I can't find any references to it or even papers that do something similar.
~ Rohan|2023-04-28 03:28:29|Or, more generally, using diffusion in a generic neural network or for some other application outside of generating content
Aashay Sachdeva MPL Data Scientist|2023-04-28 03:30:07|They use transformers for lane detection- https://youtu.be/aVjDX5XshYo  Diffusion pipelines are used to create healthcare datasets - https://hai.stanford.edu/news/could-stable-diffusion-solve-gap-medical-imaging-data
Yash Pandya|2023-04-28 03:31:07|https://arxiv.org/abs/2112.00390  Diffusion for image segmentation
Shashank Generative AI Group|2023-04-28 04:00:39|text2motion  https://mingyuan-zhang.github.io/projects/MotionDiffuse.html  more on this topic: https://deepsense.ai/data-generation-with-diffusion-models-part-1/
Ojasvi Yadav|2023-04-28 09:39:41|[PHONE] might know a thing or two
Ojasvi Yadav|2023-04-28 09:41:06|I got a call from someone inviting me here. Seems a lot like a marketing campaign. If someone is interested in  their data lake services then they should definitely attend it.
Ojasvi Yadav|2023-04-28 09:41:24|If not, then I don't see much why anyone would attend
Ojasvi Yadav|2023-04-28 09:42:24|Diffusion is a noise removal process at its core It's kind of like an IMG to IMG process, but that doesn't happen in the image domain. It happens in the image embedding domain.
Ojasvi Yadav|2023-04-28 09:49:02|You can use it to generate content, but you can also use diffusion to process content.  Example of former - midjourney Example of latter - image restoration or enhancement
Sudharshan GenAI|2023-04-28 10:43:25|[PHONE]’s place  [PHONE] covered - google page rank and its simplicity - linear algebra, embeddings and how they all come together - topology 101 - His MS, PhD stories and why he loves research - Lot of other good discussions
Anshul Bhide Replit|2023-04-28 10:45:45|[PHONE] is an incredible teacher - should do a talk for the group
Kartik Mandaville|2023-04-28 12:05:12|Has anyone used promptlayer? or anything similar?
Azhan Mohammed Generative AI WhatsApp Group|2023-04-28 12:23:22|Anyone who has resources for Data Exploration and Feature Engineering?
Nirant|2023-04-28 12:33:47|We can point you in a million directions, but perhaps the most value-for-time is this: Feature Engineering: https://www.kaggle.com/learn/feature-engineering DataViz: https://www.kaggle.com/learn/data-visualization  For feature engineering in particular, you can learn more from reading a single Kaggle Winner blog and code than you would from 10 papers — I say this as someone who has done both
Nirant|2023-04-28 12:41:14|What are the best projects around these areas of interest:  1. Fine tuning Frozen embeddings in-domain 2. Serving embedding with guarantees on latency 3. Ranking/search embedding from QA-pairs e.g. bi-encoder?  Across Modality? But can look at text2text for now
Ojasvi Yadav|2023-04-28 12:44:00|Is the intention to get more familiar with these problems? Like a project to assist coursework?
Nirant|2023-04-28 12:45:36|Hmm, that's part of the problem. Too many teams re-invent these pieces internally.
Nirant|2023-04-28 12:47:36|Why do you've to touch a GPU for doing custom embedding in 2023? That's a very 2016 thing to do
Puneet Lamba Aspiro|2023-04-28 12:51:22|https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/
Nirant|2023-04-28 12:52:37|Such a late stage hype cycle thing to do: Copy paste the docstrings and prompts from a FOSS project to a blog and people find that valuable 🤔
Rohit Aggarwal|2023-04-28 12:56:22|I totally agree! But in their defence, this space has been moving too fast for most people to catch up on. I'm surprised that most people have not heard of ReAct, but then know about AutoGPT :P
Nirant|2023-04-28 12:57:24|Yes. I was not criticising the writer, but the audience (i.e. us) for having poor taste. Artists have always been constrained by the times we work in.
Pratyush Choudhury|2023-04-28 12:58:14|Umm, almost all kinds of arts have an audience as well
Nirant|2023-04-28 12:58:26|Also, AutoGPT has fantastic marketing. Credit due where it is due.
Shivendu Kumar|2023-04-28 13:00:55|Did it actually do anything useful yet? Haven't seen any impressive results so far.
Dr. Pratik Desai KissanGPT|2023-04-28 13:02:15|AutoGPT has been major disappointment from the hype prospective
~ Prakhar|2023-04-28 13:04:08|it is only aboe to do small things/tasks with bounded scopes and well-defined goals   i was able to create python scripts for minor task automation and then some creative writing assignments. but give it anything a little broad, and it spirals out
Aashay Sachdeva MPL Data Scientist|2023-04-28 13:07:37|Can do basic financial analysis of companies. Somehow gets the easiest thing (getting the right current price from google) wrong. But was able to so SWOT + competitive analysis + DCF
Anshul Bhide Replit|2023-04-28 13:09:58|This could be a stupid question but beyond customisability (and maybe power), what's the difference between bing (powered by GPT) and AutoGPT for basic questions? Both have access to the latest information through search.
~ Rachitt|2023-04-28 13:10:01|Have done market sizing and memo writing using AutoGPT, but takes alot of time and gets into loops too often
Puneet Lamba Aspiro|2023-04-28 13:17:37|Oh my,  I see that link has led to a mini furore in this group 😟 I actually had a specific question but got a call.
Nirant|2023-04-28 13:17:59|Hahha, no furore. Just banter.
Nirant|2023-04-28 13:19:28|Bing has a lot longer context window — so can reason over more search results, is basically free for most people, easier to use.
Shalabh Aspiro|2023-04-28 13:19:43|AutoGPT took all the learnings developed by langchain, vectors DBs etc etc and made it available for the wider non-developer audience to use in the format they understand better.   The limelight always goes to what is easy to use 😬
Nirant|2023-04-28 13:19:45|Bing is also not powered 100% by GPT but uses an internal MSFT model quite often
Puneet Lamba Aspiro|2023-04-28 13:20:49|*Anyone here who has used such sequential prompting on a custom dataset to run a controlled conversation, say a roleplay?* We’re building a sales roleplay product that mimics conversations of a specific team, and I would like to know such available best practices to optimise the output if someone has dived deeper into something like this.
Nirant|2023-04-28 13:22:37|This is perhaps the best tooling for guided-chat with some roleplay.  https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/demo_chain_with_guardrails.py  Addendum: I used to run the ML team at Verloop.io — a chat automation company powering Nykaa, Rentomojo etc. a long time ago.  Have some interest and exposure to challenges in chat systems in particular.
Puneet Lamba Aspiro|2023-04-28 13:22:55|It’s for B2B enterprises, so the idea is that it better get as precise yet flair-ful as it can get (based on a team’s dynamics).
Aashay Sachdeva MPL Data Scientist|2023-04-28 13:41:41|AlignmentAI
Abhishek Sahu Ultrahuman|2023-04-28 13:42:13|PMGPT
Amir Nagri|2023-04-28 13:42:26|```Here are a few suggestions for a name for an AI assistant/co-pilot for product managers/product teams:  1. ProdigyAI 2. PMate (Product Manager's Mate) 3. CoPilotAI 4. ProductIQ 5. ProdigiAI 6. BrainstormAI 7. LaunchpadAI 8. ProductWave 9. VisionaryAI 10. ProductGenius```  welcome to generativeai group 😂
Aashay Sachdeva MPL Data Scientist|2023-04-28 13:42:26|No offence to any PM, you all are loved 😛
Ankur Pandey|2023-04-28 13:43:37|Tx. Deleted since it borders self promotion
Puneet Lamba Aspiro|2023-04-28 13:48:06|Still waiting for someone to name their product bhAI. Names like samurAI and ikigAI are already gone.
Ankur Pandey|2023-04-28 13:49:58|Used this only https://www.namefinder.ai
Ankur Pandey|2023-04-28 13:51:04|A dairy founder wanted g.ai but had to resort to mal.ai
Dr. Pratik Desai KissanGPT|2023-04-28 13:51:43|AIshwarIA
Dev Aggarwal|2023-04-28 14:40:56|I think something like autogpt becomes useful when human closed loop feedback cycles are involved at a large scale. Something that incorporates large scale human feedback and nudges into its reasoning, that's where I see real potential
Dev Aggarwal|2023-04-28 14:42:03|Eg for trading bots this might be a community of 1000s of traders constantly giving it nudges and guidance on its thoughts and actions
Shashwat TDC|2023-04-28 14:44:00|‎POLL: While i was thinking about my pending gpt-4 request.. quick poll about your status ‎OPTION: Has gpt-4 api access (24 votes) ‎OPTION: Requested and awaiting (34 votes) ‎OPTION: Didn't request yet (6 votes)
Nirant|2023-04-28 14:55:03|For the technical folks that are waiting on GPT4 API Access for more than 30 days, with any meaningful open source presence — please DM me.   Can share a tip which has helped [PHONE] get access as well recently :)
~ Puneet|2023-04-28 14:55:34|I got the access in 5 days. Had requested it last weekend and got it this week.
Dev Aggarwal|2023-04-28 14:56:10|Works like a charm. We had been pusing internal teams at Microsoft for a month, with no end in sight, but nirant's tip worked in 2 hours :)
Bulia Siddharth Aurashop|2023-04-28 15:10:18|Does anyone have access to GPT plugins?
Kartik Mandaville|2023-04-28 15:10:23|did you get through Azure OpenAI service?
Dev Aggarwal|2023-04-28 15:10:58|Yes, thanks to nirant as well
Bulia Siddharth Aurashop|2023-04-28 15:12:48|I haven't checked that yet. Is it available through that?
Bulia Siddharth Aurashop|2023-04-28 15:12:59|Are awesome. How did you get it?
Bulia Siddharth Aurashop|2023-04-28 15:13:15|I just want to play with the plugins and explore their capabilities.
Dev Aggarwal|2023-04-28 15:14:05|Interesting bit: the Microsoft folks pushed us to shift all our code to azure openai service, and something called semantic-kernel in order to get gpt-4 access, but none of it has materialised yet  https://github.com/microsoft/semantic-kernel
Dev Aggarwal|2023-04-28 15:16:07|I feel guilty open sourcing nirant's tips 😂
Nirant|2023-04-28 15:17:04|More important: We also shouldn't abuse OpenAI's goodwill :)
Bulia Siddharth Aurashop|2023-04-28 15:17:54|Haha. No worries. I have gpt-4 api access. I am just looking for Plugin access.
Sudharshan GenAI|2023-04-28 15:45:50|Anyone in Ben Tossel's AI maker group?
Krishna Ntkris|2023-04-28 15:55:04|I am
Amir Nagri|2023-04-28 15:58:58|Pray tell 🙂
Abhishek Maiti|2023-04-28 16:05:03|And also the joining link😅
Sudharshan GenAI|2023-04-28 16:05:59|Gotta apply
~ Nirmal|2023-04-28 16:06:23|maker club?
Abhishek Maiti|2023-04-28 16:06:39|Where?
Sudharshan GenAI|2023-04-28 16:08:27|let me find the link ‎[4/28/23, 17:02:42] Nirant: ‎image omitted
Nirant|2023-04-28 17:03:15|For folks wondering how is FP8 working? This is based on NVIDIA's Transformer Engine: https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/index.html
Lalit Pagaria|2023-04-28 17:05:12|What impact you foresee? Large Model, Faster Model, or new model arch?
Aashay Sachdeva MPL Data Scientist|2023-04-28 17:13:48|Coreweave talks about tier 3 datacenters in north america. What does that mean? Do we have any in India as well?
Nirant|2023-04-28 17:22:28|Mostly faster inference in the 3-6 month horizon as compute providers figure this out, and perhaps more Fp16, Fp8/int8 proliferation for task-specific models
Dev Aggarwal|2023-04-28 17:55:41|Faster inference means lesser costs because you can handle higher concurrent users per gpu
Nirant|2023-04-28 19:04:39|If I was running a serverless GPU company with mixed-GPUs e.g. A100, H100, P100 and what not — I'd resist the temptation to pass on these cost savings to customers. Mainly because I'm not quite sure how many customers will pay for 3x faster use cases
Kaushik Bokka|2023-04-28 19:10:25|Also at times you can’t guarantee to spawn up some of the higher end GPUs on demand, leading to slower spawn up time for users
Dev Aggarwal|2023-04-28 19:10:57|I doubt you'll have this luxury for long, imo serverless gpus are a perfect competition model with market competition dictating  the pricing instead of arbitrary end user value
Sudharshan GenAI|2023-04-28 22:28:28|https://twitter.com/bentossell/status/1636394074101153792
Sudharshan GenAI|2023-04-28 22:28:30|fyi
Amir Nagri|2023-04-28 22:59:56|Hey, this is nice, thanks for sharing
Amir Nagri|2023-04-28 23:00:13|Looks too good to be true, what do you think is the catch here?
Sudharshan GenAI|2023-04-28 23:00:29|No catch, it's Ben
Akash Chandran|2023-04-28 23:09:02|anyone  , building with langchain here ?  just deployed a private V2 for collectiv langchainX. would be happy to share access , if you building with langchain would help your process
~ Ameya|2023-04-28 23:09:05|Hi! Does anyone know of any tools that can summarize custom code repos/documentation? Something like https://github.com/mtenenholtz/chat-twitter but where you can maybe enter in any Github repo link and it'll summarize it for you.
~ Rachitt|2023-04-28 23:11:49|https://github.com/peterw/Chat-with-Github-Repo
Anshul Khandelwal Invideo|2023-04-28 23:13:03|https://stability.ai/blog/deepfloyd-if-text-to-image-model
~ Ameya|2023-04-28 23:15:27|Thanks
Nirant|2023-04-28 23:20:57|Research license only
Amir Nagri|2023-04-28 23:32:09|interesting approach, will be interesting to see if it will be able to displace the stable diffusion model given the eco-system that has already grown around it
Nirant|2023-04-29 00:49:44|Very lame question: Does LlamaIndex or Langchain support VectorDB with Sources with GPT4 or GPT3.5-Turbo?   For LLM libs, both of them have such embarrassingly bad doc search 🙈
Nirant|2023-04-29 00:50:52|If yes, can you please point me to the right docs 😅
Ravi Theja|2023-04-29 00:51:00|what does vectordb with sources with gpt mean?
Nirant|2023-04-29 00:52:31|Say the Vector DB replies with Doc1, 3, 5, 7 and only 5, 7 are actually used by the LLM to answer the question — I want the response to include 5, 7
Ravi Theja|2023-04-29 00:53:25|https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/PineconeIndexDemo.ipynb
Ravi Theja|2023-04-29 00:53:50|response.source_nodes should give you the sources.
Nirant|2023-04-29 00:54:12|That gives 1, 3, 5, 7 — all top k
Ravi Theja|2023-04-29 00:55:27|ohh okay. Sorry, I misunderstood then. One way is to use evaluation module on top these to get only 5, 7 are being used.
Dev Aggarwal|2023-04-29 00:56:54|I have a hack for this
Dev Aggarwal|2023-04-29 00:57:36|Use this prompt -   Cite the Search Results using [${number}] notation in your answer.
Dev Aggarwal|2023-04-29 00:57:55|Then simply parse the citations returned using regex
Nirant|2023-04-29 00:58:26|I've tried variants of this. Not consistent enough unfortunately across questions. Do you change the system prompt in some way? ‎[4/29/23, 00:59:24] Dev Aggarwal: ‎image omitted ‎[4/29/23, 00:59:47] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-29 00:59:54|Works very consistently
Dev Aggarwal|2023-04-29 01:00:10|(Haven't experimented with gpt-4 though yet)
Dev Aggarwal|2023-04-29 01:01:11|Including instructions and search results in system prompt made it forget the instructions sometimes
Dev Aggarwal|2023-04-29 01:01:23|So moved them to user prompt ‎[4/29/23, 01:03:03] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-04-29 01:05:33|This technique also in my experience has the added benefit of producing more grounded results, because you are kinda forcing it to cite sources. (Not sure why it works at all though)
Diptanu Choudhury FB AI|2023-04-29 01:22:00|OpenAI models don’t do this. What you want is basically the LLMs to cite references.
Diptanu Choudhury FB AI|2023-04-29 01:22:19|*The reader model
Diptanu Choudhury FB AI|2023-04-29 01:23:10|Interesting.
Rohit Aggarwal|2023-04-29 01:25:42|[PHONE] something like this - https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html ?
Nirant|2023-04-29 01:27:35|Yes, but this uses text-davinci-003 — which leads to couple of trade offs:    1. Slower and more expensive than gpt3.5-turbo 2. Confabulates more than Turbo, so have to keep answers really small and sentence-length often 3. Worse at reasoning than GPT4
Rohit Aggarwal|2023-04-29 01:31:15|what could be reasons that the methodology can’t be ported to GPT-4? (I haven’t looked at the code yet, only did a cursory read on this today)
Nirant|2023-04-29 01:32:40|Do you mean LLM or code reasons? There are no LLM reasons
Dev Aggarwal|2023-04-29 01:33:29|Replacing the OpenAI() classes in the example with ChatOpenAI() doesn't work?
Rohit Aggarwal|2023-04-29 01:33:51|Code reasons - is the “return_only_outputs” prop not available for ChatCompletions
Nirant|2023-04-29 01:33:53|Code Reasons: Langchain is structured around separation of LLMs and Vector Indices — the Chat LLMs (e.g. ```ChatOpenAI```) prompts aren't compatible with these other operands like qa_with_sources
Rohit Aggarwal|2023-04-29 01:34:30|You’ll have to extend the chain functions I guess..
Nirant|2023-04-29 01:34:37|Llama Index: [PHONE] can share more context, but I think they've just gotten around to it. From what I can tell, they have no such limitations
Nirant|2023-04-29 01:34:46|*just not gotten around to it
Rohit Aggarwal|2023-04-29 01:35:08|Aah, that makes sense. Will make for a great PR!
Rohit Aggarwal|2023-04-29 01:35:35|That was a quick delete 😂😂😂
Nirant|2023-04-29 01:36:13|"Yeah, sometimes I've to enforce that ""stay on topic"" policy to myself 🤣"
Rohit Aggarwal|2023-04-29 01:36:29|Langchain is very complex though. Tried doing some very simple modifications today and I just gave up and went back to good old OpenAI libs
Dev Aggarwal|2023-04-29 01:36:42|My eyes can’t believe this, what error does it throw?
Nirant|2023-04-29 01:36:46|It's definitely not meant for simple things
Rohit Aggarwal|2023-04-29 01:38:15|OpenAI has a function in one of their libs to convert chat prompts to text ones and vice versa - that’s needed here I guess 😅
Nirant|2023-04-29 01:38:48|Wait, what. I've not seen this. Is this part of their default Python SDK? If not, can you link it here?
Dev Aggarwal|2023-04-29 01:39:22|https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/prompt/base.py#L22
Nirant|2023-04-29 01:40:10|Okay, I see the code. Now I feel sad that I didn't think of this. Probably should've asked this question at 9 AM instead of 2 AM 😅
Dev Aggarwal|2023-04-29 01:41:54|while we are in this repo - these prompts are gold   https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/registry/modelgraded/fact.yaml  https://github.com/openai/evals/blob/4da6a6115ac03df4f8364903815a6e73e95c2fd1/evals/registry/modelgraded/closedqa.yaml
Nirant|2023-04-29 01:42:21|These kinda gems are what make this group worthwhile 🫰🏻
Rohit Aggarwal|2023-04-29 01:42:37|Yes! Writing a blog on how good the library is. We aren’t using so much of what became available here!
Shivendu Kumar|2023-04-29 02:54:42|anyone knows a model that can give aesthetic score for an image?
Nirant|2023-04-29 02:55:28|FID against LAION-A?
~ Phoenix Elsa(nutan)|2023-04-29 02:59:18|Please share after ur done
Nirant|2023-04-29 03:14:01|Adding context here:   Part 1: **FID**  FID (Frechlet Inception Distance) is a score which is primarily used for evaluating quality of generated images against a source dataset. It first came to notice when GANs were used to generate novel faces (circa 2019). FID is a distance score between features or vectors — so lower FID score means your images are closer to what you are comparing against.  Here is an example blog from that era: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/ ‎[4/29/23, 03:21:05] Nirant: ‎image omitted
Shivendu Kumar|2023-04-29 03:26:08|Pretty cool approach.
Nirant|2023-04-29 03:26:42|That said, if you've user-scored images, you can go very far with just a ResNet and a classification model. AirBnB Staff ML Engineers with a PhD were still doing that and getting promoted in Dec 2022: https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2
Nirant|2023-04-29 03:26:59|Basically, Big Data beats Big Brains any day, all day long
Nirant|2023-04-29 03:28:14|Before anyone asks, Airbnb uses AWS OpenSearch with HNSW for their VectorStore
Shivendu Kumar|2023-04-29 03:36:14|Thinking along similar lines, I'm eagerly waiting for a model that takes in any photo and gives out professional level DSLR photos. Perfect lighting, colors, focus, contrast, etc :)
Arvind N Generative AI Group|2023-04-29 03:44:33|For folks looking to fine-tune LLMs to their custom domains, the first step is to build a good quality dataset of ~50k data points. LAMINI AI launched a library today to make this process easier. You'll have to make a dataset of around 100 data points and the library will expand it to a nice 70k+ data points dataset that you own(CC-BY license). https://github.com/lamini-ai/lamini/  They also provide tools to quickly fine-tune some of the open trendy camel like creatures.
Mahesh Suthar|2023-04-29 03:47:14|Folks, this is a super exciting community and I love the sheer amount of activity here. Everytime I open Whatsapp and there’s 300+ new messages, and I do like the buzz of it (quite similar to the speed of AI development 😛).   But my non-AI brain just can’t keep up with all that’s happening in this group.  I must excuse myself for now.  Will probably be back once AI takes over my day job and I have more time to be present here.
Nirant|2023-04-29 03:47:53|Working on a summary web version and hopefully a weekly/monthly newsletter 🤞
Mahesh Suthar|2023-04-29 03:50:13|Cool che. Will sign up for that.  Until then cheers to Nirant and all the future AI millionaires / billionaires here ✌🏻
Mahesh Suthar|2023-04-29 03:51:00|‎Mahesh Suthar left
Anshul Khandelwal Invideo|2023-04-29 07:47:15|I prefer never using them... Just picking the prompts from their source code
~ Apurva Bhatt|2023-04-29 07:59:22|‎Ravi Theja added ~ Apurva Bhatt
Arvind N Generative AI Group|2023-04-29 08:03:25|Who here is using langchain in prod?
Lalit Pagaria|2023-04-29 08:28:39|How? Manually 😯
Ravi Theja|2023-04-29 08:42:15|No way. Shouldn't expect that from Nirant. Automate. 😁
Bharat Kumar Ramesh Hashmal Web3|2023-04-29 08:44:50|This is a nice read  https://a16z.com/2023/04/27/navigating-the-high-cost-of-ai-compute/
Lalit Pagaria|2023-04-29 08:57:43|Mainly my point about finding any good way to extract WhatsApp group data  automatically. I don't find any official APIs. There might be few unofficial ways but that may cause a number ban.
Harsh Koo|2023-04-29 09:00:47|Hey folks,   Any leads/info on the best text to video (paid and free/open source tech) available in the market.  Something with a wow factor.  thanks for the inputs.
Kishore GenAI|2023-04-29 09:08:42|My understanding is currently runwayml gen 2.
Harsh Koo|2023-04-29 09:09:08|This isn't available yet I thought.
Kishore GenAI|2023-04-29 09:10:54|Don’t know about access. I have seen multiple videos of it on twitter lately.
Shashank B Designer|2023-04-29 09:11:06|Few days old 😜:  https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/ (done in collab with openAPI - so has the best prompting tips)
Harsh Koo|2023-04-29 09:20:07|https://replicate.com/cjwbw/damo-text-to-video  https://replicate.com/deforum/deforum_stable_diffusion  Are the two I have found.
~ Mohit Sharma|2023-04-29 09:53:02|‎~ Mohit Sharma joined using this group's invite link
Anshul Khandelwal Invideo|2023-04-29 10:10:02|https://github.com/Picsart-AI-Research/Text2Video-Zero  Is quite good...
Shashank B Designer|2023-04-29 10:15:36|"Folks, so we are doing the ""Learning Transformers/NLP/ML"" discussion on Sunday 4-5pm.  Agenda: 1. Learners talk about what they'd like to learn about (So come prepared!) 2. If someone knows learning resources they share it  (We are trying to get an experienced person for this!) 3. The topics will be compiled and shared (So that experienced folks can add more learning resources to it after the event)  Calendar link: https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=NDBidDlwcXBzczRocjV0YTRndjBxbGMyN2Mgc2hhc2hhbmsuY2RvQG0&tmsrc=shashank.cdo%40gmail.com"
Sudharshan GenAI|2023-04-29 10:55:03|Anyone at the nvidia event?
Sudharshan GenAI|2023-04-29 11:00:31|Using openai APIs to expand?
Amir Nagri|2023-04-29 11:19:43|Fyi that calendar link doesn't do anything for me, using Android here
Sanyam Bhutani|2023-04-29 11:36:19|I can make a list of great solutions for it if there's interest :)
Sanyam Bhutani|2023-04-29 11:38:21|Tuned in for Gen AI, listening to GPU talks 💀
Shashank B Designer|2023-04-29 11:40:53|"Thanks for flagging it Amir.  Fixed the calendar link to ""Learning Transformers/NLP/ML"" discussion on Sunday 4-5pm: (You need to be logged in to google for it to work. Google calendar doesn't handle it well otherwise) https://calendar.google.com/calendar/event?action=TEMPLATE&tmeid=MXJxbm4xZDVlZmc3MGRpcDJna3NsODM3ZG4gMWNkNjI0MzA3ODkwN2JhN2M3YzhjNjg1NGVkNGVjMWUzZDhiMjc4MjU5NmMyZmRhNWI0MDFlZTI5ZDM3OTYzZUBn&tmsrc=1cd6243078907ba7c7c8c6854ed4ec1e3d8b2782596c2fda5b401ee29d37963e%40group.calendar.google.com  Alternatively, video link to join directly : https://meet.google.com/jag-jjny-owf"
Sanyam Bhutani|2023-04-29 11:41:00|https://twitter.com/bhutanisanyam1/status/1412933178411536384  Please see the replies to this^  Compilation of the most epic FE competitions^
~ Sumit|2023-04-29 11:42:39|‎~ Sumit joined from the community
Anshul Khandelwal Invideo|2023-04-29 11:49:55|https://postgresml.org/blog/tuning-vector-recall-while-generating-query-embeddings-in-the-database
Sudharshan GenAI|2023-04-29 11:50:40|Haha - I'm here
Sudharshan GenAI|2023-04-29 11:50:42|It's high quality
Sudharshan GenAI|2023-04-29 11:54:37|Will share insights
Adithya L Bhat Hackathon|2023-04-29 11:56:02|https://teams.microsoft.com/l/meetup-join/19%3ameeting_OGM2NDU4N2QtYjdmOS00YzJmLThmZTctYTkxYWEyNWQ0OGNj%40thread.v2/0?context=%7B%22Tid%22%3A%2243083d15-7273-40c1-b7db-39efd9ccc17a%22%2C%22Oid%22%3A%222e1cc663-be56-46e0-ab3b-b7a9f58868e7%22%2C%22IsBroadcastMeeting%22%3Atrue%2C%22role%22%3A%22a%22%7D&btype=a&role=a  link to the same .
Aditya Agrawal SuperU|2023-04-29 12:51:48|Hey [PHONE] [PHONE] : For tomorrow's zoom meet-up, can you drive 15 minute of the session on 101 of Generative AI? [PHONE] is looking for a tech expert in the session.
Aditya Agrawal SuperU|2023-04-29 13:22:22|Nirant is busy tomorrow.
~ Srinath Nair|2023-04-29 13:31:16|Hey guys. I am trying to build something with Generative AI in the advertisement space. I don’t have much idea on what exactly I should be doing and what are the issues faced by those running ads. So speaking with a few people who have experience running ads. If you know anyone or if you yourself are someone working on advertisements, would love to connect and discuss.
~ Srinath Nair|2023-04-29 13:31:46|My name is Srinath btw. And I am a final year BTech student.
~ Nitish Alodia|2023-04-29 13:32:56|Would love to help [PHONE] . Dm me whenever free
Nirant|2023-04-29 13:33:21|Folks, please reach out to our friend directly :)
~ Srinath Nair|2023-04-29 13:33:29|Thanks Nitish. DMing you.
~ Apurva Bhatt|2023-04-29 13:43:10|Hello everyone, I am Apurva. I am building a product to make content viral on social media using generative AI.  I am still exploring the way to build a product. Feel free to connect and exchange ideas. I am currently working at BertLabs and before that, I worked at sharechat.
~ Mohit|2023-04-29 15:29:29|Folks, I have an interesting research problem statement. I would like to build a generative model to generate legible pdf/image documents (text + image basically).  I see this being useful in intelligent document processing and ocr, where data collection is a very difficult task due to privacy and all.  If anyone has already done this, then please let me know. Else, if interested we can form a small group and build this as an open source lib.
~ Mohit Khullar|2023-04-29 15:34:14|Looks like all the Mohits are looking for same use case. 😂  I'm also looking for a solution for this specific use case
~ Mohit|2023-04-29 15:34:49|Brilliant. We can call our library mohit then!
~ Mohit Khullar|2023-04-29 15:35:15|Definitely 💯
Sankalp PickYourTrail|2023-04-29 15:42:28|Would anyone know a transcription open source or paid API that can handle hindi/english as well as indian regional languages
Nirant|2023-04-29 15:42:49|OpenAI Whisper does this off the bat
Sankalp PickYourTrail|2023-04-29 15:44:03|I tried assemblyAI as well but they are expensive, are there any other that I may have missed?
~ Shreyas Nair|2023-04-29 15:45:01|[PHONE] should definitely be able to help!
Sankalp PickYourTrail|2023-04-29 15:47:02|thanks will dm him
~ Rachitt|2023-04-29 15:55:56|Building this but for CSVs at the moment, would love to chat!
Ravi Theja|2023-04-29 16:00:24|For Hindi there are whisper models trained for Hindi from IITM.  Do check here - https://huggingface.co/vasista22
Ravi Theja|2023-04-29 16:00:26|Deepgram built using whisper works good as well. They give $200 credit to try it out.
Aashay Sachdeva MPL Data Scientist|2023-04-29 16:37:06|You can try monster api as well
~ Sachin Govind|2023-04-29 16:44:26|‎~ Sachin Govind left
Rohit Aggarwal|2023-04-29 16:50:00|If somebody is trying out deepgram nova vs Whisper - would love to hear results from both
Yash Pandya|2023-04-29 17:02:46|You don't need generative models for this. Converting raw text to PDFs/images and then applying simple distortions is a very common and effective way to get synthetic data for OCR.
~ Akshat Khare|2023-04-29 17:28:29|‎Ravi Theja added ~ Akshat Khare ‎[4/29/23, 17:54:18] Aishwarya Goel Inferless 5s for 5G: ‎image omitted
Dev Aggarwal|2023-04-29 18:00:41|https://playbook.samaltman.com  For all the fellow founders out here - a very grounded article by sam altman on building great products and companies
Soumyadeep Mukherjee|2023-04-29 18:08:58|Hey  Sorry. So am I. 🥺
Soumyadeep Mukherjee|2023-04-29 18:09:01|Will not be able to make it.
Anshul Bhide Replit|2023-04-29 18:58:02|Will you be recording this? ‎[4/29/23, 19:21:18] Bulia Siddharth Aurashop: ‎video omitted
Bulia Siddharth Aurashop|2023-04-29 19:22:26|Weekend fun!
Dev Aggarwal|2023-04-29 19:35:59|D-ID is crazy good. Any ideas on the underlying architecture?
Dr. Pratik Desai KissanGPT|2023-04-29 19:38:31|SadTalker is open and it getting there. Some friends are working on a project and they moved on from D-ID for SadTalker. You will need a good GPU though.
Bulia Siddharth Aurashop|2023-04-29 19:41:33|Not so sure but this tech is around since a while.
Dev Aggarwal|2023-04-29 19:42:04|Not zero shot lipsync / animation - that's hard and has limited work
Anshul Khandelwal Invideo|2023-04-29 19:45:47|Sad talker is arguably better...
Dr. Pratik Desai KissanGPT|2023-04-29 19:48:41|D-ID is very expensive if you’re building a project with a pipeline to generate content on an enormous amount.
Sudharshan GenAI|2023-04-29 19:50:24|How expensive?
Dr. Pratik Desai KissanGPT|2023-04-29 19:52:00|As mentioned on their Pricing page. 🤣
Sudharshan GenAI|2023-04-29 19:52:34|Have you deployed and tested at scale?
Dev Aggarwal|2023-04-29 19:52:41|Unreasonably expensive for an api product
Bulia Siddharth Aurashop|2023-04-29 19:52:48|We used multiple D-ID accounts to get this done :p
Bulia Siddharth Aurashop|2023-04-29 19:53:43|They have a full fledged web studio as well. So I don't think they are trying to build only API product.
Dev Aggarwal|2023-04-29 19:54:10|Yup exactly - I feel like the pricing is aligned for the dashboard only
Dr. Pratik Desai KissanGPT|2023-04-29 19:54:34|Right now SadTalker can generate 10min video per hour that’s 2$ GPU time
Dr. Pratik Desai KissanGPT|2023-04-29 19:57:47|D-ID is charging 6$ per 10 mins. If you can have 3090 or 4090 at home, that would be like 300-400h gpu time to get your money back.
Dr. Pratik Desai KissanGPT|2023-04-29 20:00:13|May be get one with nvlinks for larger runs and still it’s a lot better return time for investment
Sudharshan GenAI|2023-04-29 20:00:49|And yet has a lot of traction - good product to build.
Sudharshan GenAI|2023-04-29 20:01:06|Any idea on what models they use?
Dr. Pratik Desai KissanGPT|2023-04-29 20:01:40|🤷‍♂️ their own. SadTalker is new and evolving. From tencent I think.
Dr. Pratik Desai KissanGPT|2023-04-29 20:09:12|So many things to build, so many industries to disrupt.  I see this group producing pioneers for next India decade.
Dev Aggarwal|2023-04-29 20:14:32|Just ran it - seeing that its running gfpgan at the end too - so this time can definitely be reduced
Dr. Pratik Desai KissanGPT|2023-04-29 20:17:09|👍  I have offloaded that project to someone else to lead as my hands are full. I’ll pass on this info to them.
Shashank B Designer|2023-04-29 20:29:40|Only notes (as of now)
Sudharshan GenAI|2023-04-29 20:36:00|Yes and 2$ can be brought down if doing at scale (Assuming A100)
Sudharshan GenAI|2023-04-29 20:36:28|Margins are great for this - and competition is less. (text to talking head avatars vs rephrase ai etc). Good product to build.
Sudharshan GenAI|2023-04-29 20:36:41|I'll take a stab at building an mvp soon
Sudharshan GenAI|2023-04-29 20:37:03|Tried doing this back in 2019 and almost raised funding, but didn't work out
Bulia Siddharth Aurashop|2023-04-29 20:37:11|Not sure how big is the market for this though.
Sudharshan GenAI|2023-04-29 20:37:42|It's an evolving market. Also look at leading indicators ‎[4/29/23, 20:38:14] Sudharshan GenAI: ‎image omitted
Twishmay Shankar|2023-04-29 20:38:17|Wow this is very real
Dev Aggarwal|2023-04-29 20:38:58|I've built this product as both an API, and also earlier (2020) as a charcater.ai type offering, and even tried to sell as nfts.   Hard sell unless you know how to gain traction on social media.
Vaibhav Bhargava Meesho Grab |2023-04-29 20:39:08|Hillarious stuff man
Sudharshan GenAI|2023-04-29 20:39:15|I know how to do that :)
Sudharshan GenAI|2023-04-29 20:39:27|That's the easy bit
Dr. Pratik Desai KissanGPT|2023-04-29 20:39:27|Don’t you want 8 AI avatars on Arnab’s show with different personalities?
Dev Aggarwal|2023-04-29 20:39:34|*Shakes hands*
Bulia Siddharth Aurashop|2023-04-29 20:39:45|Thank you! [PHONE] spent lot of time in generating the voices!
Sudharshan GenAI|2023-04-29 20:39:53|Haha. We should jam.
Bulia Siddharth Aurashop|2023-04-29 20:44:24|If human can generate similar kind of content, I don’t think pureplay AI will sell. Human generated content is already limitless. Only when AI gives way higher quality production or heavily personalized content - then people might start liking it.
Dr. Pratik Desai KissanGPT|2023-04-29 20:45:22|It was just a joke. But AI fact checking anchor in every debate can be a nice start.
Bulia Siddharth Aurashop|2023-04-29 20:45:47|Thinking XYZ movie in Nolan style. Or personalized standup making references about my own personal life - that might really work.
Sudharshan GenAI|2023-04-29 20:46:17|Also if anyone else wants to jam with [PHONE] and me, and even potentially collaborate on building this - hit me up.   I can sell and market. We just need to build a good product.
Bulia Siddharth Aurashop|2023-04-29 20:46:31|There will be a popup after every statement then 😅😅
Harsh Koo|2023-04-29 21:12:28|Interested. Would like to offer something like this to creators on Koo.
Vamshi|2023-04-29 21:14:02|Also interested. Particularly interested in the AI Vocalist use case.
Vamshi|2023-04-29 21:14:27|Please do keep me posted on the jam
Vamshi|2023-04-29 21:15:13|Also interested in the jam in a literal sense, as I’d be happy to beta test to create viral content
Sudharshan GenAI|2023-04-29 21:18:39|Sure will make a group
Bulia Siddharth Aurashop|2023-04-29 21:29:37|Any opensource alternative to elevenlabs?
Ravi Theja|2023-04-29 21:29:53|bark
Deep Samsung R&D|2023-04-29 21:30:00|Anyone came across any examples/tutorials for QnA over CSVs which uses Python code or maybe some good way to answer queries?
~ Nayan Shah|2023-04-29 21:34:52|Text to sql kind of thing ? And then sql can be run on data or direct qna on csv data?
Bulia Siddharth Aurashop|2023-04-29 21:35:03|Thanks! Checking.
Ravi Theja|2023-04-29 21:36:18|Except for their officially released cloned voices, it hallucinates a lot.
Deep Samsung R&D|2023-04-29 21:43:11|Yes correct
Dev Aggarwal|2023-04-29 21:44:36|guardrails released this recently
Dev Aggarwal|2023-04-29 21:46:34|https://twitter.com/ShreyaR/status/1650883072324419587
Dev Aggarwal|2023-04-29 21:46:39|cc [PHONE]
Bulia Siddharth Aurashop|2023-04-29 22:51:08|Looks very interesting. DMing for further help.
~ Lakshay Nagpal|2023-04-29 23:24:58|Hey  What you guys are using for telemetry- scoring as per like/dislike, analysing feedback of the users.
Dev Aggarwal|2023-04-29 23:25:59|Couldn't find anything. Trying to build it in house with eventual plans to expose as API & dashboard
Dev Aggarwal|2023-04-29 23:26:24|[PHONE] please build this for us! 🫣
Dev Aggarwal|2023-04-29 23:27:14|The analysis part might be outsource-able to thoughtspot ‎[4/29/23, 23:33:31] Ojasvi Yadav: ‎image omitted ‎[4/29/23, 23:33:47] Ojasvi Yadav: ‎image omitted
Ojasvi Yadav|2023-04-29 23:35:08|This is what they're currently offering: ‎[4/29/23, 23:35:12] Ojasvi Yadav: ‎image omitted
Ojasvi Yadav|2023-04-29 23:35:50|Their responses have to be REALLY good to have people leave chatGPT and other LLMs and use these features. ‎[4/30/23, 00:21:34] Bulia Siddharth Aurashop: download (2).wav ‎document omitted
Bulia Siddharth Aurashop|2023-04-30 00:21:44|Bark is lit too 🔥
Bulia Siddharth Aurashop|2023-04-30 00:23:31|Lyrics by gpt, vocals and music by bark!
Dev Aggarwal|2023-04-30 00:26:10|This is the way!
Lalit Pagaria|2023-04-30 00:34:02|https://github.com/gventuri/pandas-ai
Deep Samsung R&D|2023-04-30 00:51:20|"Anyone has found any solution to ChatOpenAI giving ""Could not parse LLM output:"" errors?"
Dev Aggarwal|2023-04-30 03:39:44|https://github.com/jerryjliu/llama_index/blob/590639a14dd7346b7f5cc00a21dd24ce0d35ae30/gpt_index/langchain_helpers/text_splitter.py#L240  Baffled by the sheer genius of the SentenceSplitter in llama index
Dev Aggarwal|2023-04-30 06:42:10|https://github.com/openai/openai-python/blob/c556584eff3b36c92278e6af62cfe02ebb68fb65/openai/embeddings_utils.py#L21  just saw this too
Dev Aggarwal|2023-04-30 07:29:58|This is what openai used in their rlhf paper - https://scale.com/content-language
Pratyush Choudhury|2023-04-30 10:01:00|https://twitter.com/MisbahSy/status/1652479189747130368?t=l_GaFpmX5tP50AfqEut_Dw&s=09  Multi-lingual document search with a no-code interface
Rohit Aggarwal|2023-04-30 10:32:55|I'm excited to try cohere's multilingual model somewhere.. Maybe benchmark it to NLLB :)
Ojasvi Yadav|2023-04-30 10:42:04|basic project idea: train a chatbot on this : https://support.apple.com/en-in/guide/shortcuts/welcome/ios
Ojasvi Yadav|2023-04-30 10:42:11|shortcuts are super useful if you know what you're doing
Ojasvi Yadav|2023-04-30 10:42:26|Most people don't use them to their full potential since the documentation is so messy
Ojasvi Yadav|2023-04-30 10:43:34|Can be a vague, small step towards AGI for the common-man.
Ojasvi Yadav|2023-04-30 10:44:14|"Would love to get a functionality like : ""Create shortcuts to automatically change my wallpaper based on 7 images, 1 for each day of the week"""
Ojasvi Yadav|2023-04-30 10:44:38|One of my friends set up something like that and it took him 2 full hours to get his head around it
Ojasvi Yadav|2023-04-30 10:54:18|And even generating a step by step guide to make a shortcut should be plenty for people like me
Deep Samsung R&D|2023-04-30 10:58:01|"Any best resources for creating charts/graphs from data, open-source ""Chart-GPT"" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives."
~ Lakshay Nagpal|2023-04-30 11:30:57|Got it. Any open source solution which you know?
Rohit Aggarwal|2023-04-30 11:34:03|are you looking to fine-tune or perform RLHF?
Rohit Aggarwal|2023-04-30 11:34:17|RLHF on an open-source model*
~ Lakshay Nagpal|2023-04-30 11:39:41|Majorly for RLHF. Firstly, want to visualise the data in a nice format, so that can improve the prompt manually. With this, want to have analyse metrics like - per user usage, etc.
~ Lakshay Nagpal|2023-04-30 11:41:52|So, for the first case, let’s say If a user gets a false response from the assistant and gives a bad review, how should we go about analysing it - by the storing that particular message or by getting the complete chat as the message can be contextual with the other messages in the chat.
Saurab Paruthi|2023-04-30 12:58:56|‎Ravi Theja added Saurab Paruthi
~ Ankur Khandelwal|2023-04-30 13:29:48|Hey ,   I am using one of the sentence transformers models  for embedding.  I used to use the Replit but figured out the api stops working after some time and need to restart the function.  Is there any better solution?
Rohit Aggarwal|2023-04-30 13:35:26|Contextual is the way to go. Tracing will allow for this. Working on it now
~ Lakshay Nagpal|2023-04-30 14:01:10|Alright
Nirant|2023-04-30 14:28:08|Add more RAM to your REPL with a boost. Repl on Replit might've very limited RAM, they're like 2007 PCs in terms of specs. ‎[4/30/23, 14:31:18] Nirant: ‎image omitted
~ Ankur Khandelwal|2023-04-30 14:39:35|Any other alternative you suggest?  Let me try to increase the ram and see?
Manas Ranjan Kar|2023-04-30 14:41:56|How do I read this - how’s the recall measured?
Nirant|2023-04-30 14:45:58|Those details are the same as here: https://ann-benchmarks.com
~ Vipul|2023-04-30 14:47:05|What would be the best way to implement a file search? If I have a ton of documents and I want a semantic search on top of it to solve the discovery problem, how should I go about it? One use case could be for google drive.  I was thinking, get all documents' metadata + content, make embeddings, search on top of it. Not sure of the efficiency given I'm not looking for answers from the doc, just want to make relevant search... Thoughts?
Rohit Aggarwal|2023-04-30 14:48:11|Langchain has a drive connector fwik. You could use that to then do search with it's helper functions
~ Vipul|2023-04-30 14:48:57|okay, I'll check that.. thanks.
Amir Nagri|2023-04-30 14:58:27|Nice, performance gains attributed to rust vs golang? Assuming both are using the same algo (hnsw) ?
Dhruv Anand|2023-04-30 15:14:59|is the tuning of recall/speed done by building a new index for each point on this plot, or is it tunable per query?
Nirant|2023-04-30 15:17:05|This is the code outline we used:  https://github.com/erikbern/ann-benchmarks/blob/main/ann_benchmarks/algorithms/qdrant.py  See the runner for answer to your question (and other specifics on how indexing, single vs batch) are executed: https://github.com/erikbern/ann-benchmarks/blob/main/ann_benchmarks/runner.py  It's all FOSS, qdrant folks want Weaviate to get a chance to respond
Shashank B Designer|2023-04-30 15:40:31|Folks we are starting the Learners' discussion at 4pm - Join here : meet.google.com/jag-jjny-owf  cc'ing those who voted for this slot : [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE]
Shashank B Designer|2023-04-30 17:12:14|Thanks [PHONE]  [PHONE] [PHONE] for joining in and sharing pointers and notes 🙏
Shimanta Generative AI|2023-04-30 17:41:19|I found this tool that shows a nice dashboard of costs incurred while using OpenAI api’s : https://llm.report The demo looks good, can find out usage costs per model
Aditya Agrawal SuperU|2023-04-30 17:49:57|Thanks [PHONE] for hosting
Ishan Sharma|2023-04-30 18:32:39|Looking for feedback on a new product that I'm working on that generates design from prompts using a design system, would love to get some feedback. DM me or upvote and I will send a message 🧰 Thanks :D
~ Sharanya|2023-04-30 18:35:05|‎~ Sharanya joined using this group's invite link
Amogh V|2023-04-30 18:40:47|Are there any graphic designers in this group who are interested in learning more about using stable diffusion in their work? I'd love to talk and understand where generative AI can make the most impact in your work. And then hopefully show you how you can apply it
~ Lakshay Nagpal|2023-04-30 18:54:36|This is nice. Do you know any other tool which also has per user usage tables?
Ishan Sharma|2023-04-30 18:54:41|Would also love to interview product designers ❤️
Amir Nagri|2023-04-30 18:55:12|On that note, would like to connect to folks in marketing, specially graphic designers in marketing agencies, or if you know anyone in such agency, kindly connect 🙏
Jay Pokarna 2014 BPCC|2023-04-30 19:04:15|https://twitter.com/bohanhou1998/status/1652151502012837890?s=20
Shimanta Generative AI|2023-04-30 19:05:21|Haven’t found any other yet ‎[5/1/23, 00:53:21] Dev Aggarwal: ‎image omitted
Nirant|2023-05-01 00:54:06|It's quite public, OpenAI demos it everywhere?
Dev Aggarwal|2023-05-01 00:54:29|MUST get access to this tool
Nirant|2023-05-01 00:55:22|The fastest way to get GPT Plugins access is perhaps to make a Twitter viral demo 🥲
Dev Aggarwal|2023-05-01 00:56:02|I have GPT plugins access, but I don't this tool anywhere in the ui
Pratyush Choudhury|2023-05-01 02:56:26|https://github.com/georgia-tech-db/eva  AI enabled queries on top of unstructured data (videos, images) 🫡
Satish DeepHack Sponsor|2023-05-01 03:54:34|Any  *** flask / python web stack devs here for freelance? Thx!
Edgar Monis Mumbai WHO|2023-05-01 06:44:42|Dm ing.  I've been working with flask + django + k8s for the past 3 years while working for the World Health Organization.
Nirant|2023-05-01 09:19:42|AutoGPT is now emerging as a catch all for any automation it seems. Jason Calacanis has posted a bounty worth $270 on Replit for outbound sales emails  RIP high-volume, low-quality SDR:  https://replit.com/bounties/@JasonCalacanis/aichrome-extension-t?t=applications
Vaibhav Bhargava Meesho Grab |2023-05-01 09:50:43|I was able to deploy something locally ( followed line by line advice of chatgpt) to generate personalised DM, email + coffee conversation points for a linkedin profile as a non coder. Jason's requirement should be easy stuff for someone better.
Sudharshan GenAI|2023-05-01 10:32:53|Link to this group? Want to add a friend
~ naras|2023-05-01 10:57:01|‎~ naras joined using this group's invite link
Ankesh Atlassian AI|2023-05-01 11:28:45|‎Ankesh Atlassian AI joined using this group's invite link
Harsh Koo|2023-05-01 11:36:56|[PHONE] can I post an GenAI internship opportunity at Koo here?
Rohit Aggarwal|2023-05-01 11:38:06|Posting it without really posting it 😎
Nirant|2023-05-01 11:38:11|I just pinged [PHONE] ki please delete this too 😅  I've seen too many communities die once we allow hiring and fundraising news to be allowed
Amir Nagri|2023-05-01 11:50:59|We can have a separate, uncensored group in this community, folks interested in sharing and subscribing to such news can post it there
Sudharshan GenAI|2023-05-01 11:52:06|Agree
Sudharshan GenAI|2023-05-01 11:52:30|Lots of good talent here and opportunities
~ Rachitt|2023-05-01 11:56:02|A subgroup for hiring could be a great idea, keeping this group for ideas/discussions
~ Pradeep Ayyagari|2023-05-01 11:57:55|‎~ Pradeep Ayyagari joined using this group's invite link
Amogh V|2023-05-01 12:00:49|How about a subreddit with flairs for hiring, news, discussion etc?
Nirant|2023-05-01 12:01:05|Perhaps a weekly post with all open roles can work better instead of a separate WA group? That makes it easier for all seekers to discover open roles also.   I'll be happy to collate and do it myself. Maybe leave 👍 here if that works?
Harsh Koo|2023-05-01 12:01:11|The challenge is that posting on LinkedIn has been ineffective for specific areas and GenAI has very few communities.
Ojasvi Yadav|2023-05-01 12:02:30|Sent you something similar
~ Akhil|2023-05-01 12:03:53|‎~ Akhil joined using this group's invite link
Nirant|2023-05-01 12:40:51|For folks interested in hiring from the community, added a Google Form here: https://nirantk.com/community
Soumyadeep Mukherjee|2023-05-01 12:56:19|Why not have a diff announcement group? 🤔
~ Rachitt|2023-05-01 12:58:42|+1
Nirant|2023-05-01 13:01:20|Splintering off is a terrible idea — that is partially why of the last 3 groups which we've split off: Generative AI + {Art, Philosophy, Startups} — 2 are dead and one is comatose
Twishmay Shankar|2023-05-01 13:04:16|Why is no one discussing AI philosophy 😂🙈
Nirant|2023-05-01 13:05:46|Stems from my bias since I seeded this community from my friends. I've generally been a believer that the best philosophy is action, not discussion. That is why we care about OpenAI and not say, so many other brilliant teams
Anshul Khandelwal Invideo|2023-05-01 13:14:35|I would be interested in something that covers hiring freelancers too.
Nirant|2023-05-01 13:16:14|Yeah, please add there! You can mention in the questions that what kinda freelancing role is this e.g. contractual, but recurring, project based. That is why the questions are free form :)
Dev Aggarwal|2023-05-01 15:59:57|https://www.youtube.com/watch?v=FE88OOUBonQ  Damn, andrew ng is building a generic few shot computer vision platform ‎[5/1/23, 17:26:01] ~ Arsalaan: ‎image omitted
Sudharshan GenAI|2023-05-01 17:29:08|Send link?
Ritwik 2013|2023-05-01 17:30:12|Anyone interested in teaming up for Warpspeed?
Amir Nagri|2023-05-01 17:39:21|Looking forward to participate, hopefully this one is online
~ Nikhil|2023-05-01 18:14:14|It is mentioned that it is an offline event ‎[5/1/23, 18:14:46] ~ Nikhil: ‎image omitted
~ Arsalaan|2023-05-01 18:42:06|Offline, only selected candidates will be allowed
~ Anirudh Gupta|2023-05-01 19:11:40|‎~ Anirudh Gupta joined using this group's invite link
Harsh Koo|2023-05-01 21:44:40|Meta's SAM under the hood?
Manjot Pahwa|2023-05-01 22:02:07|Yes it's offline, please do apply :)
Shimanta Generative AI|2023-05-01 22:05:51|Will there be selections for attending the hackathon?
Dev Aggarwal|2023-05-01 22:12:15|Nope, this is a custom model, haven’t seen anything quite like it anywhere else
Vaibhav Bhargava Meesho Grab |2023-05-01 22:36:36|+ 1. Need more teams from this group. And winners! I’m up as well to jam with anyone looking. ‎[5/1/23, 23:37:19] Dev Aggarwal: ‎image omitted
Amir Nagri|2023-05-01 23:39:00|Have you tried if it works when you call it from outside those notebooks?
Dev Aggarwal|2023-05-01 23:39:21|Ok yeah doesn't work. Interesting.
Dev Aggarwal|2023-05-01 23:39:31|AuthenticationError: Your authentication token is not from a valid issuer.
Nirant|2023-05-01 23:39:55|Wireshark it and find if you can get the headers?
Nirant|2023-05-01 23:40:31|I mean, this is just nerd-sniping [PHONE], I feel ambushed 😂
Dev Aggarwal|2023-05-01 23:40:32|I also want this magic api key though that I can just publish in my code lol
Dev Aggarwal|2023-05-01 23:46:45|playwright might be easier than reverse engineering the jupyter notebook api 👀
Ramakrishnan Lokanathan|2023-05-01 23:51:48|Sal Khan just gave another Ted, the vision reimagined with AI. As good and powerful as the first one.   https://youtu.be/hJP5GqnTrNo
Sudharshan GenAI|2023-05-01 23:53:05|Hinton is leaving google
Gokul Krishnan|2023-05-01 23:55:34|https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html
Sudharshan GenAI|2023-05-02 00:04:13|Article is biased
Sudharshan GenAI|2023-05-02 00:04:14|His tweets are better
Sudharshan GenAI|2023-05-02 00:13:22|https://twitter.com/zoink/status/1653052807950536706  lol
Sudharshan GenAI|2023-05-02 00:28:05|How are you folks using ChatGPT to learn?  https://twitter.com/Suhail/status/1651091438367809537  This has been surprisingly good for a lot of topics
Siddharth Agarwal|2023-05-02 01:35:09|Yudbot.com If someone wants to test their AI safety knowledge in a frustrating way.
Lavish 2017|2023-05-02 01:42:52|I'm starting work on a llm vault manager to bring API level caps ($ &/or tokens)  right now I'm planning with: - configure_limits - record_input - record_output  any better abstraction here and ideas? not directly building inside langchain to keep it open for all LLMs.
Twishmay Shankar|2023-05-02 01:43:42|[PHONE] [PHONE]
Lavish 2017|2023-05-02 01:43:45|also is API level cap, something that you generally try to keep? got some responses on twitter - wanted to check here too if people would find it useful
~ Rachitt|2023-05-02 02:09:29|[PHONE] might be interesting for you
~ Tarun Raheja|2023-05-02 04:11:18|https://www.yudbot.com/
Shashank B Designer|2023-05-02 06:33:51|If something can cause the world harm, shouldn’t  the news article be open to all and not behind a paywall 🤷🏻‍♂️😜
Anirudth N|2023-05-02 06:51:39|If this was a political group, I'd say that this is an example of capitalism at its prime. But hey, I don't want to get banned 😞 ‎[5/2/23, 07:09:43] Prayank Swaroop Accel: ‎image omitted
~ Ashish|2023-05-02 10:03:50|‎~ Ashish joined using this group's invite link
Sudharshan GenAI|2023-05-02 10:18:40|How are you folks adding conversational memory to gpt-3.5-turbo?  Building a chat app and need it to remember previous chat history for context.
~ Aravinth Kumar|2023-05-02 10:19:45|Might help :) https://python.langchain.com/en/latest/modules/memory.html
Nirant|2023-05-02 10:19:51|I would have loved to plug Langchain here if they had absolutely anything which worked
~ Aravinth Kumar|2023-05-02 10:20:41|Could you please elaborate? Trying this out. Any shortcomings that we need to be aware of?
Aakash Kumar  Matrix Partners|2023-05-02 10:22:16|https://augmented-reality-knowledge.github.io/  Anyone here working on 3D generation problem statements ? Would love to jam
~ Nikhil|2023-05-02 10:22:49|Is this not working for you? https://platform.openai.com/docs/api-reference/chat/create  You can specify previous history as part of `messages` that you send to the model.
Nirant|2023-05-02 10:23:06|Random shortcoming from the last 24 hours alone which I've seen: 1. Adding any form of Retriever to this chat leads to tokenisation and other forms of errors, which require fixes in the lib itself 2. Because Langchain keeps the message history in memory as a Python object, we've to manually wire it back to some store e.g. I used Redis
Nirant|2023-05-02 10:25:04|For a lot of _common_ use cases (outside of agents), it's perhaps better to roll your own then to use Langchain — and I say this as the resident Langchain fanboi of this group
Sudharshan GenAI|2023-05-02 10:25:13|What if there are a lot of messages? Exceed 4096 tokens.
Nirant|2023-05-02 10:25:43|Make an extra API call and ask the model which messages are worth keeping up
Sudharshan GenAI|2023-05-02 10:26:37|Give an Example?
Nirant|2023-05-02 10:32:23|Code flow example: https://github.com/hwchase17/langchain/blob/master/langchain/memory/summary.py  tl;dr: keep moving the conversation to a `history` object and summarize it. With each message, you unfurl the `history` back to the user-AI dialogue format which chat models expect
Sudharshan GenAI|2023-05-02 10:47:26|thanks!
Shalabh Aspiro|2023-05-02 11:47:54|1) Does it make sense to use something else like llamaindex now. Anyone who has experience using both of them?  2) When not using langchain and rolling on your own, using document loaders and indexes becomes a pain. Do you recommend to look at their source code directly and copy paste the implementation in your own code or is there a better third party library for this?
Soumyadeep Mukherjee|2023-05-02 11:48:41|There was a person from luma labs here no? 🤔
Harsh Koo|2023-05-02 11:48:41|A friend has used llamaindex for chat conversations and was satisfied
Harsh Koo|2023-05-02 11:49:15|He is in the other group created  by Nirant.
Shalabh Aspiro|2023-05-02 11:51:55|DMing you
~ Sayan|2023-05-02 11:52:00|‎You added ~ Sayan
Harsh Koo|2023-05-02 11:52:31|[PHONE] for chat convos how has your experience been with llamaindex?
Harsh Koo|2023-05-02 11:52:42|I know you use both langchain and llama
~ Sayan|2023-05-02 11:53:15|Yeah I started of with gpt index but moved to langchain
~ Sayan|2023-05-02 11:53:28|Actually I wanted to create custom tools
Ankesh Atlassian AI|2023-05-02 11:54:00|My team's working on semantic search to feed in product content to LLMs. Anyone here has worked on Lucene based ANNs with OpenSearch 2.x ?
Nirant|2023-05-02 11:54:06|For these use cases, Langchain is still very good
Nirant|2023-05-02 11:55:00|Why Lucene/OpenSearch? Have a requirement which prevents you from using a decent VectorDB or Elastic itself?
Harsh Koo|2023-05-02 11:55:53|For storing chat history isn't llama better? Thought you had some points on this
Edgar Monis Mumbai WHO|2023-05-02 11:56:39|I have
Edgar Monis Mumbai WHO|2023-05-02 11:56:42|It gets the job done
Ankesh Atlassian AI|2023-05-02 11:57:03|Those are also options being evaluated but there are company level constraints on them.
Shalabh Aspiro|2023-05-02 11:57:22|[PHONE] any input on the 2nd question?
Ankesh Atlassian AI|2023-05-02 11:57:25|Thanks, I will DM you.
Lalit Pagaria|2023-05-02 12:12:51|This is my biggest worry of using LangChain in production env. This is a very active repo lot of PRs being merged but still don't see much quality checks around it (unit and integration tests). Like Haystack and even some part of Transformers repo has which I feel should be required for any production quality codebase.
Nirant|2023-05-02 12:15:05|It's not just about backward compatibility. It's also about clarity on what they want to do — Langchain seems to be prioritising agents, tools and toolchain around that over everything else
Akash Chandran|2023-05-02 12:31:12|True we wrote own in js stuff moved away from langchain , will open source soon once we have most basic func
Nirant|2023-05-02 12:36:04|Question was around data connectors and indexing:   My 2 cents: I wouldn't be rolling that on my own now. You're better off using Langchain, Llama Index anything. Rolling your own Transform in ELT as a Python lib is too much overhead, and will often break in ways that you've not thought of.
Govind C Semantics3 YC|2023-05-02 12:41:44|‎Govind C Semantics3 YC joined using this group's invite link
Sudharshan GenAI|2023-05-02 12:49:09|Does deforum have a commercial license?
Rohit Aggarwal|2023-05-02 13:14:05|interesting - I've been using https://deeplearn.org/ for this
Rohit Aggarwal|2023-05-02 13:24:15|Has anybody tried Semantic Kernel? Do you see this as langchain alternative?  https://github.com/microsoft/semantic-kernel/blob/main/python/README.md (Seems cleaner to me)
Nirant|2023-05-02 13:38:47|I don't see it as a Langchain alternative yet (doesn't care about agents, data indexing, tools at all) — but for the few things it does, it does have a cleaner API. I am planning to try it out if a project comes along
Rohit Aggarwal|2023-05-02 13:42:00|Hmm, you're right. I could see Semantic Kernel adding tools, agents as capabilities with a clean-ish API in the short term.
Nirant|2023-05-02 13:50:06|But it'd be quite ironical if $MSFT has better API design than a well-funded, immensely popular FOSS project to be honest 🥲
Rohit Aggarwal|2023-05-02 13:50:53|yea! heard they raised another round already (not sure about the source though)  MSFT has been doing some really good stuff lately though in OSS
Pratyush Choudhury|2023-05-02 13:54:12|Why though?
Dev Aggarwal|2023-05-02 13:54:38|I frankly don’t see any llm abstraction library really working out in the near term. Its like writing a C compiler for a changing chip design and Instruction set before x86
Pratyush Choudhury|2023-05-02 13:54:48|API design has little to do with community traction I'd believe
Nirant|2023-05-02 13:55:04|Say more, I don't understand you
Nirant|2023-05-02 13:55:17|Fun analogy, but the x86 is GPT4 no?
Dev Aggarwal|2023-05-02 13:55:36|Gpt is the processor, instruction set is the prompts
Aakrit Vaish Haptik PeerCheque|2023-05-02 13:59:07|MSFT is the fastest moving startup in his new world IMO
Nirant|2023-05-02 13:59:43|Reminds of the SaaS joke I've made since 2019: All B2B salesfolk work for Microsoft, only some know it
Shalabh Aspiro|2023-05-02 14:00:49|I love how one man Satya Nadella has changed that perception over a few years, completely
Ashfakh GenerativeAI WA Group|2023-05-02 14:03:16|Don't use langchain, absolute shit show at scale. Memory is essentially a list of chat messages, In our system, we save it in redis as a single serialised string, retrieved and constructed at run time. I've also implemented a moving window approach to summarise chat history to save on tokens. Happy to discuss more.
Dev Aggarwal|2023-05-02 14:03:48|https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/default_prompts.py  https://sourcegraph.com/search?q=context:global+repo:%5Egithub%5C.com/hwchase17/langchain%24+file:/prompt.py%24&patternType=standard&sm=1&groupBy=path  The most useful parts of langchain and llamaindex by far - but if you take 5 minutes to go through these you’ll know how impossible it is to build a good abstraction over this limited instruction set
Ashfakh GenerativeAI WA Group|2023-05-02 14:04:55|langchain is buggy as hell also.
Rohit Aggarwal|2023-05-02 14:06:40|this is gold! 🌟
Sudharshan GenAI|2023-05-02 14:06:58|Thanks! Will DM. We’re doing something similar - a simple moving window of 500 input tokens.
Kartik Mandaville|2023-05-02 14:07:05|fwiw we've been using llama index in prod for two weeks now doing around 500 questions on the company docs daily / no issues
Dev Aggarwal|2023-05-02 14:07:43|Please, can we make a simple colab notebook that has best practices of implementing rolling windows contexts?
Nirant|2023-05-02 14:07:49|"I've tried moving windows as well. It just results in weird issue when something important from opening conversation gets lost and users get angry because ""this is the first thing I said!"""
Dev Aggarwal|2023-05-02 14:08:50|maybe do dynamic rolling window for every question? Store all messages but only pass the ones relevant to the current questio
Sudharshan GenAI|2023-05-02 14:09:21|What about summarisation? We’ve tried calling the openai summarisation API to summarise the prev chat but it’s slow af
Dev Aggarwal|2023-05-02 14:10:14|We need some inside info on how chatgpt is doing this 🫣
Nirant|2023-05-02 14:10:35|OpenAI has a summarisation API? Didn't they deprecate that?
Ashfakh GenerativeAI WA Group|2023-05-02 14:11:34|Prompt engineering helps there. Think of your usecases as bucketed modules. Don't use a one size fits all prompt, but smartly create prompts that can preserve needed info. Has been working well for our usecases
Dev Aggarwal|2023-05-02 14:11:41|Openai once suggested to us in 2020 to use a smaller and faster model for summarisation here, wonder how well that works
Ashfakh GenerativeAI WA Group|2023-05-02 14:12:04|It's a trade off, experience vs expense. Have to take that call based on your product.
Ashfakh GenerativeAI WA Group|2023-05-02 14:12:35|use gpt-3.5 only, prompt it well, keep temp low.
Sumod K Mohan|2023-05-02 14:18:22|Had worked on Lucene (query side) and written custom rankers in Solr etc. But not worked with OpenSearch. It's been a while.
~ Nirmal|2023-05-02 14:25:00|[PHONE]
~ Ashwinkumar Jayagopi|2023-05-02 15:12:18|Would this be of help? It creates a running summary of earlier conversations while also retaining the latest n interactions in their richer form.  https://python.langchain.com/en/latest/modules/memory/types/summary_buffer.html
Harsh Koo|2023-05-02 19:20:35|Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com  He would be delighted to do an online discussion.  Hit 👍 if you are interested and I can reach out to him to set up a chat.
jyotirmayjk Hackathon|2023-05-02 22:54:34|I think we might have the answer why LangChain is so focused on tools and agents   https://twitter.com/colintjarvis/status/1653425662407987201?s=46&t=icC0fizZK8E3ONsDVuGFWA
jyotirmayjk Hackathon|2023-05-02 22:55:21|Using tools and agents with LangChain officially part of OpenAI cookbook
~ Debasmita|2023-05-02 22:58:19|‎~ Debasmita joined using this group's invite link
jyotirmayjk Hackathon|2023-05-02 23:08:15|Also a very basic question for anyone who can help   I’m seeing a lot of hype on GPT-3.5 with Code Interpreter plug-in  It’s able to perform reasonably good data analysis on data dump in CSV,XLSX files   How is this different than giving access to a Python Repl to an LLM agent instance  Eg could be ->Load CSV/XLSX into a SQLite3 db/pandas df and then ask the agent to carry out relevant analysis
Dev Aggarwal|2023-05-02 23:09:11|You mean executing untrusted code from an LLM?
jyotirmayjk Hackathon|2023-05-02 23:14:34|Python environment can be sandboxed ?
jyotirmayjk Hackathon|2023-05-02 23:16:58|Also not an agent like AutoGPT/BabyAGI  More like custom LLM agent using LangChain
Ojasvi Yadav|2023-05-02 23:18:55|Doing so in production at a decent scale
Ankesh Atlassian AI|2023-05-02 23:58:47|Awesome. Would love to talk. Will DM you
Ashfakh GenerativeAI WA Group|2023-05-03 00:18:34|What’s the scale?
Sudharshan GenAI|2023-05-03 00:54:17|https://twitter.com/samim/status/1653289578390749186?s=46   [PHONE] integrating?
Dev Aggarwal|2023-05-03 00:55:50|Done ✅  https://gooey.ai/compare-text-to-speech-engines/?example_id=m2royk7q
Sudharshan GenAI|2023-05-03 01:08:25|Nice
Krishna Ntkris|2023-05-03 04:52:08|GPT4 creates a vector DB: https://twitter.com/AlistairPullen/status/1653459578229788672?s=20
Anshul Bhide Replit|2023-05-03 08:09:16|Replit open source LLM just dropped. Its released under CC BY-SA 4.0, which allows for commercial use.  https://huggingface.co/replit ‎[5/3/23, 08:13:31] Nirant: ‎image omitted
Amir Nagri|2023-05-03 08:27:19|is this what powers ghostwriter?
~ Sudhanshu Heda|2023-05-03 09:50:04|https://twitter.com/grimezsz/status/1652696738820689921?s=46&t=v5MAnKU6XwMWCzMNzmBUuA
Anshul Bhide Replit|2023-05-03 10:12:48|Looks like he also called it out on his pod https://www.youtube.com/watch?v=WBgrfWW8xxA&t=2095s
Aashay Sachdeva MPL Data Scientist|2023-05-03 10:34:30|Finetune on instruction dataset curated from geeksforgeeks
Amir Nagri|2023-05-03 12:19:52|https://twitter.com/pirroh/status/1653586734641471490  Doesn't confirm if it is the same model that powers ghostwriter, 🤞on updates and improvements
Nirant|2023-05-03 12:26:20|Prompt Injection in less than 10 minutes (video, slides, transcripts):  https://simonwillison.net/2023/May/2/prompt-injection-explained/  Excellent primer
Dev Aggarwal|2023-05-03 12:28:36|Also the very fun follow up article to why you can’t use AI to fix this 😂  https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/
Swapan Rajdev haptik.ai|2023-05-03 12:59:45|‎Swapan Rajdev haptik.ai joined using this group's invite link
Kshitij Agrawal ML Engineer|2023-05-03 14:00:53|‎Kshitij Agrawal ML Engineer joined using this group's invite link
~ Nikhil|2023-05-03 14:30:59|Anybody applied for the OpenAI service on Azure?  How long does it take for your application to get reviewed?
Alok Bishoyi|2023-05-03 14:32:19|Got ours withing a couple of days
Nirant|2023-05-03 14:33:04|JSONFormer: https://github.com/1rgs/jsonformer — guaranteed JSON output with Huggingface LLMs
Nirant|2023-05-03 14:33:25|cc Ankita [PHONE] is from Microsoft Azure India — can reach out to her directly
Aashay Sachdeva MPL Data Scientist|2023-05-03 14:34:14|Why would you do that? 🤣Sorry ankita be ready to be bombarded with api requests
Ankita Mathur Microsoft Sales|2023-05-03 14:35:22|Please DM me - happy to help
Rohit Aggarwal|2023-05-03 14:40:48|the approach looks very promising! ‎[5/3/23, 18:00:25] Amogh V: ‎image omitted
Nirant|2023-05-03 18:00:55|DeepFloyd or Multi-ControlNet?
Amogh V|2023-05-03 18:01:02|Abstract artwork I made using stable diffusion. Abstracts are hard to conceptualize and compose but they're a lot of fun!
Amogh V|2023-05-03 18:01:10|Neither
Amogh V|2023-05-03 18:03:00|Custom trained checkpoint, good use of prompts and neg prompts, inpainting, upscaling. And several iterative loops with tweaks in each interation
Amogh V|2023-05-03 18:24:54|"Somewhat counterintuitive, but knowing art techniques, major movements and history really helps while working with Stable Diffusion. For example you will know to prompt ""impressionism oil on canvas painting, thick brush strokes, palette knife technique"""
Amogh V|2023-05-03 18:25:46|It was used in the prompt of several of the iterations used to make this
~ Priyanka Chandak|2023-05-03 18:45:50|‎~ Priyanka Chandak joined from the community
Shivendu Kumar|2023-05-03 18:47:19|Is there a model (other than gpt4) that can extract info from a image in JSON format?   I tried Google's new pix2struct. It's horribly bad. The examples that they have shared are definitely handpicked.
Soumyadeep Mukherjee|2023-05-03 18:51:08|What kind of info?
Kshitij Agrawal ML Engineer|2023-05-03 18:51:59|Basic OCR should be able to do that, unless you want only some part of the text
Bulia Siddharth Aurashop|2023-05-03 18:52:03|Does anyone know anyone who has access to multi-modal gpt4?
Hasan Tech Art Guy|2023-05-03 18:54:48|That’s true for multiple mediums. People who understand cameras really well can describe various aspects of the image in precise instructions. Similarly I have seen experienced writers perform much better in my workshops while using chatgpt.
Shivendu Kumar|2023-05-03 18:55:01|I feed it search result cards from any website and it gives me extracted data with {fieldName: value}  notice that value part is easy with OCR. But fieldName is often very hard.
Amogh V|2023-05-03 18:55:39|Yes! That’s so true
Shivendu Kumar|2023-05-03 18:57:04|Infact, we can extract values without OCR as well. HTML contains most of the info anyways.
Shimanta Generative AI|2023-05-03 19:13:11|[PHONE] check if this can help
Shivendu Kumar|2023-05-03 19:28:48|Thanks. But I think it's solving a different problem :(
Sudharshan GenAI|2023-05-03 19:33:40|https://www.spellpage.com/?utm_source=bensbites&utm_medium=newsletter&utm_campaign=pi-the-new-ai-on-the-block
Sudharshan GenAI|2023-05-03 19:33:41|autogpt app
Dhruv Anand|2023-05-03 19:51:21|A schema of the output json would help
Amir Nagri|2023-05-03 19:58:37|It should depend on how the clip model used to create  captions describes the image  That's a major difference between sd v1.5 and v2.0, from talking to many SD tinkerers, they prefer v1.5 because it's easier to do prompting on it compared to v2.0
~ Nikola Shrutika|2023-05-03 20:10:10|‎~ Nikola Shrutika joined using this group's invite link
Sachin Legaltech|2023-05-03 20:17:08|If these result cards are in tabular form, table-transformer might help. https://github.com/microsoft/table-transformer ‎[5/3/23, 20:31:10] ~ Nikhil: ‎image omitted
Rohit Aggarwal|2023-05-03 20:32:11|haha, been there!
Chinmay Shah Arrowhead|2023-05-03 20:40:06|Hey folks, can you help with the group invite link? (Can't find it in description)
Ankita Mathur Microsoft Sales|2023-05-03 20:43:59|No issues at all
Ankita Mathur Microsoft Sales|2023-05-03 20:44:04|Sorry for delay in response earlier
Sumod K Mohan|2023-05-03 20:51:58|Have worked on this before. This kind of information is hard to parse in general case (sometimes value can be left of field or right of field, the field and value both can be non regex-able etc). Is there strong geometric structure or is the layout confirming to some standard (think specific bank forms etc). If not folks train specific models to extract these for specific class of documents. Little busy for next day or so, if not urgent message me and happy to chat later.
~ Anuraag Gupta|2023-05-03 20:52:39|Has anyone tried langflow here? Please DM if you have, thanks!
Anudeep Yegireddi|2023-05-03 20:53:22|https://techcrunch.com/2023/05/03/where-is-india-in-the-generative-ai-race/
Anshul Bhide Replit|2023-05-03 21:35:50|https://www.latent.space/p/reza-shabani#details
Anshul Bhide Replit|2023-05-03 21:37:26|interview with our head of ML and swyx
Sankalp PickYourTrail|2023-05-03 22:08:59|While there are over 1500 AI-based startups in India with over $4 billion of funding, India is still losing the AI innovation battle,” said analysts at Sanford C. Bernstein.   This is outrageous. With UPI, ONDC, Healthcare we already are thought leaders with technology but this narrative underplays the India growth story! What does it take to train a LLM in indigenous Indian languages, thoughts? [PHONE] [PHONE]
Shashank Generative AI Group|2023-05-03 22:17:35|Chris Lattner's new ML focussed language  https://twitter.com/jeremyphoward/status/1653649643602051072?t=-IVYmQrfx4_-_wLaAHnaeg&s=19
~ Pradeep Ayyagari|2023-05-03 22:18:42|[PHONE] - is working on this. More from him.
Yash Kothari Cadence|2023-05-03 22:23:58|‎Yash Kothari Cadence joined using this group's invite link
Sankalp PickYourTrail|2023-05-03 22:24:55|Amazing. Would love to connect and contribute.
~ Surya SG|2023-05-03 22:39:28|https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table
~ Gayatri|2023-05-03 22:40:26|I would also like to learn more and contribute in this project
Amogh V|2023-05-03 22:44:59|I think the entire article can be summarised in 3 sentences -  1. No foundational model training happening in India 2. IT Services companies starting gen AI implementation projects (pretty obvious, no surprise) 3. Startups just getting started but nothing newsworthy yet.
Keertana S Suvy|2023-05-03 22:47:08|Yes, keen to learn more!
Amogh V|2023-05-03 22:49:03|Can someone add the author Manish Singh from Tech Crunch to this group if they have the number https://twitter.com/refsrc?s=21
Amogh V|2023-05-03 22:49:40|We have coders, designers, PMs and VCs here but any journalists or media folks? Please say hi!
Aakrit Vaish Haptik PeerCheque|2023-05-03 22:51:36|Asking
Manish Singh Techcrunch|2023-05-03 22:59:27|‎You added Manish Singh Techcrunch
Aakrit Vaish Haptik PeerCheque|2023-05-03 23:01:12|Hi Manish 👋🏻
Manish Singh Techcrunch|2023-05-03 23:03:01|Thanks for adding Aakrit -- good to be here
Suhas Motwani|2023-05-03 23:03:59|Good to see you here [PHONE]
Lavish 2017|2023-05-03 23:04:43|Good to see you here [PHONE]
Utkarsh Ohm Thoughtspot|2023-05-03 23:26:37|Yes
Rahul Chhabra 2016|2023-05-04 00:22:48|‎Rahul Chhabra 2016 joined using this group's invite link
Rahul Chhabra 2016|2023-05-04 00:29:26|Glad to be a part - thanks for adding me [PHONE]   Hey folks, I'm Rahul, was in BITS Pilani until 2020, now building stuff in fintech/edtech space.  Been dabbling w some generative AI stuff lately.  Here's something I built recently (generated a new physics lecture in feynman's personality,  cloned his voice/video): https://twitter.com/rahulchhabra07/status/1653828722519330817?s=20  would love to be a part of this group and jam on new ideas. :)
Pranjal Mehta|2023-05-04 00:31:02|Good to see you here!
Rahul Chhabra 2016|2023-05-04 00:31:30|Oh hi haha! likewise :)
~ Ashish|2023-05-04 00:45:51|‎~ Ashish left
Pratyush Choudhury|2023-05-04 00:58:33|https://twitter.com/alexwan55/status/1653437581768663040?t=dDWO7Li2FAECVcszYGsF6A&s=19  Not sure if this was shared here before but the potential to poison LLM models during instruction training or RLHF has significant implications I believe considering how central the tech is becoming
~ Rohit|2023-05-04 02:37:21|any model (large language or not) with many parameters suffers from the curse of dimensionality and it is fundamentally impractical to cover all modes of adversarial attack
Shashank Generative AI Group|2023-05-04 02:37:28|arrey hey rahul 👋!
Amir Nagri|2023-05-04 09:03:02|There is an opportunity here to create artist focussed digital painting tool using GenerativeAI, right now you are hacking with automatic1111, recursively using the output as the next input, using Photoshop to do what's not possible in automatic etc.  Similar story here - https://youtu.be/K0ldxCh3cnI
Edgar Monis Mumbai WHO|2023-05-04 09:45:39|Hey folks, does anyone in this group have experience creating large scale datasets for llm model training? Would love to have a chat if possible
Aashay Sachdeva MPL Data Scientist|2023-05-04 09:48:06|How large? I processed around 300GB for https://huggingface.co/aashay96/indic-BloomLM
Edgar Monis Mumbai WHO|2023-05-04 09:48:31|300gb is large enough DMing
~ Rawal Khirodkar|2023-05-04 09:54:02|‎~ Rawal Khirodkar left
Rohit Aggarwal|2023-05-04 09:57:18|Folks, I feel openai/evals has many under appreciated concepts. But the documentation is gruesome to simply get started. I'm writing a detailed beginners guide to explain the concepts and how to include evaluations in any generation pipeline.  Any folks who would like to review & give feedback?
Nirant|2023-05-04 09:58:42|cc [PHONE] [PHONE] would be great to hear from top of my head ‎[5/4/23, 09:58:52] Rohit Aggarwal: ‎image omitted
Aashay Sachdeva MPL Data Scientist|2023-05-04 10:00:52|Can you please look at https://github.com/EleutherAI/lm-evaluation-harness as well? [PHONE]
Nirant|2023-05-04 10:01:04|Doesn't have qdrant, Weaviate — has the same libs as earlier, only adds Vespa as far as I can tell? Did Erik choose to wait for Weaviate feedback?
Edgar Monis Mumbai WHO|2023-05-04 10:11:56|Would love this
Nirant|2023-05-04 10:12:58|A very interesting question to ask would be how does OpenAI do on the lm-evaluation-harness, and what does openai/evals which the harness does not?
Aashay Sachdeva MPL Data Scientist|2023-05-04 10:14:17|Unfortunately the whole pipeline is hugginface based. Would require a lot of rewrite
Vaibhav Bhargava Meesho Grab |2023-05-04 10:15:29|“To now be relevant as a SaaS co, depth+breadth of workflow is going to be more and more critical. Point problem solutions will find it harder to establish why they capture value”. . Good set of thoughts pinned by [PHONE]  https://www.linkedin.com/pulse/ai-eating-software-world-kumar-aakash-aacash-eth-?utm_source=share&utm_medium=member_ios&utm_campaign=share_via
Rohit Aggarwal|2023-05-04 10:16:16|yep, was wondering what the choice for libraries was.. Redis seems to be doing very well though
Amogh V|2023-05-04 10:31:05|Already building this artist’s tool 😉 Didn’t make that art on Automatic
Amir Nagri|2023-05-04 10:31:23|Oh nice 🔥
~ Ishan|2023-05-04 10:38:10|‎~ Ishan joined using this group's invite link
Ravi Theja|2023-05-04 10:39:44|HF <> Inferless ([PHONE] ) on deploying GenAI models meet-up on June 10th. Check it out here - https://twitter.com/risingsayak/status/1653984521962807298?s=46
Aishwarya Goel Inferless 5s for 5G|2023-05-04 10:41:48|Thanks for the shoutout Ravi! Folks, please share what all would you like us to cover specifically around model training and deployment.. I am all ears! 😃
~ Praveen|2023-05-04 10:46:03|‎~ Praveen joined using this group's invite link
Harsh Koo|2023-05-04 10:58:57|Folks - I know the creator of https://42papers.com/, artcompute.com and more importantly mindsjs.com  He would be delighted to do an online discussion.  Hit 👍 if you are interested and I can reach out to him to set up a chat.
Harsh Koo|2023-05-04 11:00:16|Hey folks - Vikram is excited to have a session.   Any specific times work? Given he is in Canada, and most of us are nocturnal, I'm proposing next week (Tuesday/Wed) 9p Or 10p IST
Ambarish Ganguly|2023-05-04 11:17:37|Has anybody used weaviate ? I am trying to use the near_vector with my own vector embeddings and its not returning any results . I could use some help if somebody has done it before.
Shahul Kaggle Kernel GM|2023-05-04 11:17:58|‎Shahul Kaggle Kernel GM joined using this group's invite link
Nirant|2023-05-04 11:32:44|I believe Soumendra [PHONE] was giving it a shot
Soumendra Dhanee|2023-05-04 11:50:10|What do you mean by your own vector embeddings?
Soumendra Dhanee|2023-05-04 11:50:23|How are you generating them?
Ambarish Ganguly|2023-05-04 11:52:19|Thanks for responding. I am not using any of the prebuilt vectorizers.
Ambarish Ganguly|2023-05-04 11:52:21|"with client.batch as batch: batch.batch_size=100 # Batch import all Questions for i in range(len_total): print(f""importing question: {i+1}"")  properties = { ""text"": Lines[i], ""vector"": embeddings_all[i] }  client.batch.add_data_object(properties, ""Question"")"
Nirant|2023-05-04 11:52:38|cc [PHONE] from RestOfWorld is here. He's also quite comfy with Midjourney and ChatGPT based apps.
Ambarish Ganguly|2023-05-04 11:52:50|Here the embeddings are my vectors generated thru Sentence Transformers  [ choose  your model ]
Ambarish Ganguly|2023-05-04 11:53:30|Example : from sentence_transformers import SentenceTransformer model = SentenceTransformer('all-MiniLM-L6-v2')
Ambarish Ganguly|2023-05-04 11:53:42|embeddings = model.encode(Lines)
Soumendra Dhanee|2023-05-04 11:54:26|What does the search query look like?
Ambarish Ganguly|2023-05-04 11:55:32|"result = ( client.query .get(""Question"", [""text"",""vector""]) .with_near_vector({ ""vector"": q_new_embeddings.tolist(), }) .with_limit(5) .do() )"
Ambarish Ganguly|2023-05-04 11:55:43|See the near_vector please
Soumendra Dhanee|2023-05-04 12:01:52|Moving this to one-on-ine as this is going to get technical
Ambarish Ganguly|2023-05-04 12:02:29|Yes that's better
Soumendra Dhanee|2023-05-04 12:02:33|Can you DM me output of print(result)? We'll take it forward from there.
Sourasis Roy|2023-05-04 12:02:52|"Maybe try reducing ""certainty"" to 0.7 and see?"
Lalit Pagaria|2023-05-04 12:03:36|How one can achieve multi-tenancy in Qdrant? Via filter or creating separate collection or something else?
Ambarish Ganguly|2023-05-04 12:04:44|Thank you ; reduced further still no luck
Dev Aggarwal|2023-05-04 12:06:54|+1 have the same question about vector dbs
Lalit Pagaria|2023-05-04 12:12:46|I have used Faiss and Milvus (via Haystack) for personal projects very long time ago. Used to create create separate collections for different type of datas. As that time filters were not common in these vector dbs. Now like to understand is there other better way, ideally separating storage from query layer.
Nirant|2023-05-04 12:26:12|Yes, separate collections is perhaps the cleanest way?   https://qdrant.tech/documentation/how_to/#serve-vectors-for-many-independent-users
Nirant|2023-05-04 12:37:57|For folks interested in Generative Art, cool results from inpainting and other SD tricks there: https://chat.whatsapp.com/GThJJhoF3cL7QCmrfIoY8J ‎[5/4/23, 12:38:35] Dhruv Anand: ‎image omitted
Lalit Pagaria|2023-05-04 12:55:45|https://github.com/unum-cloud/usearch  Yet another vector search engine
Nirant|2023-05-04 12:56:08|From NimbleBox folks in India, [PHONE] and friends — low-code for making chat experiences in particular: https://github.com/NimbleBoxAI/ChainFury
Anshuman Pandey|2023-05-04 12:57:13|Thanks for the shout-out Nirant 🙏🏻😊
Ashfakh GenerativeAI WA Group|2023-05-04 12:58:40|I have done this.  Quick question, were you using any vector store abstractions? Like haystack or langchain document store?
Ashfakh GenerativeAI WA Group|2023-05-04 13:00:31|What level of multi tenancy do you require? Separate collection is the easiest way, but you can go for a sharded approach, if you need horizontal scale
~ Anil|2023-05-04 13:16:56|‎~ Anil joined from the community
~ Shyam|2023-05-04 13:17:13|Hi everyone,   We are using gpt-3 da-vinci-003 model for a clustering use case, basically creating a set of relatable data points for a given 'input prompt + data points'. Due to token limit of 4096, we are not able to process for more than 150 data points.  Any advise on how to solve around this? It will be very helpful.
Aashay Sachdeva MPL Data Scientist|2023-05-04 13:17:51|Average out the embeddings for the document
Edgar Monis Mumbai WHO|2023-05-04 13:18:25|Are you predicting related keywords for a given text and then clustering somehow ?
~ Shyam|2023-05-04 13:19:39|For most prompts it's usually semantic keyword matching, in some scenarios there can be some logic involved
Nirant|2023-05-04 13:20:02|Shyam, a few details which will help us answer your question better:  1. Did you mean the OpenAI embedding endpoint? 2. What is the LLM doing in clustering directly? Are you using it to tag in some way?
Edgar Monis Mumbai WHO|2023-05-04 13:20:46|Could you describe your approach ?
~ Shyam|2023-05-04 13:20:47|Example, if the user is prompting 'x of 10%', but the data point has the absolute value of that variable, then some logic will be needed.
~ Shyam|2023-05-04 13:22:03|We don't implement the matching, because the prompts are varied as I mentioned, we are directly feeding the data and prompt to gpt-3
Nirant|2023-05-04 13:23:43|Is there a reason for using text-davinci-003 and NOT gpt3.5-turbo?
~ Kunal Vaidya|2023-05-04 13:24:08|‎~ Kunal Vaidya joined using this group's invite link
~ Ketan Vaidya|2023-05-04 13:24:09|‎~ Ketan Vaidya joined using this group's invite link
~ Goutham Yeluri|2023-05-04 13:24:11|‎~ Goutham Yeluri joined using this group's invite link
~ Aishwarya Guntoju|2023-05-04 13:24:22|‎~ Aishwarya Guntoju joined using this group's invite link
~ Parth Rajauria|2023-05-04 13:24:26|‎~ Parth Rajauria joined using this group's invite link
~ Ameya|2023-05-04 13:24:36|‎~ Ameya joined using this group's invite link
~ ~mahi|2023-05-04 13:24:47|‎~ ~mahi joined using this group's invite link
~ Shyam|2023-05-04 13:24:57|1. No, just the GPT-3 endpoint. 2. Not for tagging. We are using LLM to cluster based on user's input prompt directly.
~ Shyam|2023-05-04 13:26:25|No reason, have to try gpt-3.5-turbo and compare results
~ Shyam|2023-05-04 13:28:26|Any links/readings to understand this in detail?
Sourasis Roy|2023-05-04 13:28:28|Thanks ! Can you also please share the invite link for this group
Aashay Sachdeva MPL Data Scientist|2023-05-04 13:29:39|https://huggingface.co/gemasphi/laprador-document-encoder
Krishna Ntkris|2023-05-04 13:32:59|Has anybody used langchain or llama index for hybrid embeddings? I was looking through their code to find what they use for sparse embeddings. Llama seems to use BERT and langchain I couldn’t find
Ambarish Ganguly|2023-05-04 13:33:22|The error was the Vectors were not inserted properly. The correct code [ highly simplified is here]
Ambarish Ganguly|2023-05-04 13:33:25|"with client.batch as batch: batch.batch_size=100 # Batch import all Questions for i in range(len_total): print(f""importing question: {i+1}"")  properties = { ""text"": Lines[i] }  client.batch.add_data_object(properties, ""ENMAX"",vector = embeddings_all[i])"
Ambarish Ganguly|2023-05-04 13:33:50|Vector =  < Place your VECTOR embeddings here>
Nirant|2023-05-04 13:34:43|Llama Index has extensible Retrievers, so shouldn't matter either way no?
Ambarish Ganguly|2023-05-04 13:34:56|Thanks to  Soumendra @+91 74980 76111  for trying yo help me
~ RISHAV|2023-05-04 13:36:07|‎~ RISHAV joined using this group's invite link
Ambarish Ganguly|2023-05-04 13:36:17|Thank you for your interest. I used simple Python and Weavite librarues
Lalit Pagaria|2023-05-04 13:37:19|Thanks Sharding is another good way.
Krishna Ntkris|2023-05-04 13:37:48|Ah got it. So BERT was just an example
Ashfakh GenerativeAI WA Group|2023-05-04 13:38:00|Found haystack to be great btw. the code is same for embedding insert and retrieval independent of the vector store you use.
Nirant|2023-05-04 13:38:19|cc [PHONE] was a Haystack contributor :)
Nirant|2023-05-04 13:38:36|Yeah, Llama Index has decent Retriever design. Some Custom examples: https://github.com/jerryjliu/llama_index/blob/main/examples/query/CustomRetrievers.ipynb
Amir Nagri|2023-05-04 13:47:05|I always had this question, deepset haystack was doing the semantic search pipelines for so long, why langchain became so viral as if some novelty?
Edgar Monis Mumbai WHO|2023-05-04 13:47:56|Ease of use, right place at right time, became viral too fast before people even knew about alternatives
Edgar Monis Mumbai WHO|2023-05-04 13:48:35|Once the GitHub stars started picking up everyone's eyes were on it.  No stopping that train
Ashfakh GenerativeAI WA Group|2023-05-04 13:48:37|Haystack is much better in code quality and documentation imo. Langchain was mostly LLM focused, so got the hype, so the side things also got popularity I guess
Amir Nagri|2023-05-04 13:51:05|Chatgpt helped as well, probably they rode that wave, may be haystack didn't treat chatgpt as urgent requirement  I am out of semantic search for past 6mo, so just a guess
Nirant|2023-05-04 13:52:26|Langchain is not about semantic search, it's about QA, Tools and Agents. In fact, there is no search API in Langchain.
Amir Nagri|2023-05-04 13:53:12|I mean there is overlap between both
Amir Nagri|2023-05-04 14:03:59|indexes feels like semantic search interface - https://python.langchain.com/en/latest/modules/indexes/getting_started.html  but agree, tools, agents are unique to langchain
~ prakashkagitha|2023-05-04 14:06:57|‎~ prakashkagitha joined using this group's invite link
Amir Nagri|2023-05-04 14:15:39|Thanks, this discussion helped understanding strengths of langchain and/vs haystack
Dhruv Anand|2023-05-04 14:27:04|yeah, just discovered this: https://docs.haystack.deepset.ai/docs/document_store because of the discussion here. I was thinking of creating a similar abstraction layer (i.e. provide a single API for vector DBs, allowing any VectorDB to be plugged in), but I might just depend on this now
Lalit Pagaria|2023-05-04 14:29:17|True. Apart from code and documentation. Haystack is very good in design. Just check how haystack implemented PromptNode and compare it with Langchain. You will see the difference.
Dev Aggarwal|2023-05-04 14:31:47|“ This approach is the most flexible, but creating numerous collections may result in resource overhead.  only recommended to separate users into multiple collections if you have a limited number of users “  Looks like it won’t work when 100s of  users of mine create 100s of independent collections
Ashfakh GenerativeAI WA Group|2023-05-04 14:33:00|Agreed. And the vector store abstraction too. Granted it's not perfect, but flexible enough to mould it the way we want.
Nirant|2023-05-04 14:34:07|100s should be pretty fine from what I've been told internally
Dev Aggarwal|2023-05-04 14:34:41|100x100 na ‎[5/4/23, 14:36:07] Nirant: ‎image omitted
Ashfakh GenerativeAI WA Group|2023-05-04 14:37:52|Go for sharded approach imo, cluster will take care of fault tolerance, shards will take care of horizontal scaling. It's easy to build. Don't know if there is an existing solution out there for this. Vitess architecture is pretty great and I've seen it work in massive load in production, would be cool to build something like this for vectore stores.
Nirant|2023-05-04 14:39:22|fwiw, all FOSS Vector DBs offer cloud solutions so that you don't have to think about cluster sizing, managing servers, sharding and  problems like what [PHONE] just mentioned
Ashfakh GenerativeAI WA Group|2023-05-04 14:40:16|Build vs Buy 😄
~ Sushant Kumar|2023-05-04 14:45:30|‎~ Sushant Kumar joined using this group's invite link
Lalit Pagaria|2023-05-04 14:50:27|"Vitess is a great tool.  Even SQL proxy similar ""VectorDB proxy"" would also work 🙂  Almost all RDBMS follow some variant of SQL standards but we don't have the same for Vector DBs. Maybe in the future 🤞🏼"
Nirant|2023-05-04 15:36:38|For folks wondering: https://vitess.io/ is a tool for sharding — and here is a good primer for what sharding means: https://aws.amazon.com/what-is/database-sharding/
Anudeep Yegireddi|2023-05-04 15:42:57|Have y’all heard of Modular? Chris Lattner’s (authors of LLVM and Swift and programmer extraordinaire) startup that is trying to create a new AI programming language. Jeremy Howard is an adviser, and here he introduces the language. There are cases it is 3000x faster than equivalent Python code for matrix multiplication   https://www.youtube.com/watch?v=6GvB5lZJqcE
~ Prashanth YV|2023-05-04 15:45:11|https://planetscale.com/ does managed Vitess as well. We were exploring it at Razorpay.
Nirant|2023-05-04 15:45:15|Reminder: Programming language is called Mojo. It's not Free or Open Source. Given how Java shaped up, I'm wary of using anything without a community around it to maintain and at least do basic security fixes for 5-10 years.
Nirant|2023-05-04 15:45:58|How did Razorpay end up doing sharding?
Anshul Khandelwal Invideo|2023-05-04 15:46:29|Not being open source at launch was a weird choice...  Can't remember the last time a language launched like that...
~ prthamesh|2023-05-04 15:49:45|‎~ prthamesh joined using this group's invite link
~ Prashanth YV|2023-05-04 15:50:14|We didn't go ahead in the end. 😅 We bought some time through other means. So, there was still some time before we had the need to shard.
~ Mudassir Khan|2023-05-04 15:54:52|‎~ Mudassir Khan joined using this group's invite link
Gokul Krishnan|2023-05-04 16:04:04|Jeremy was a strong proponent of TF Swift as well. But that hasn't seen major adoption even inside G so ymmv
Aashay Sachdeva MPL Data Scientist|2023-05-04 16:12:17|https://open.substack.com/pub/semianalysis/p/google-we-have-no-moat-and-neither?r=2gao6&utm_medium=ios&utm_campaign=post ‎[5/4/23, 16:17:18] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-04 16:17:24|(from the above article)
Dev Aggarwal|2023-05-04 16:18:09|Why do I think this graph is on a log scale 😅
Aashay Sachdeva MPL Data Scientist|2023-05-04 16:18:55|Hey, i wanted to understand the difference between generative pre training vs instruction tuning in terms of huggingface trainer class. How does the training objective change?
Anshul Khandelwal Invideo|2023-05-04 16:20:30|This is using gpt4 as a judge having it rate llm outputs
Anshul Khandelwal Invideo|2023-05-04 16:21:12|https://lmsys.org/blog/2023-03-30-vicuna/
Dev Aggarwal|2023-05-04 16:21:42|“According to a fun and non-scientific evaluation with GPT-4. Further rigorous evaluation is needed.”  😂
Anshul Khandelwal Invideo|2023-05-04 16:22:06|Exactly!
Dev Aggarwal|2023-05-04 16:22:14|Maybe we run openi evals on it :)
Shahul Kaggle Kernel GM|2023-05-04 16:24:15|This eval doesn't make any sense to me. Already LLMs capabilities to produce such ranks/marks are highly debated to it's stochastic nature. It's like a teacher that gives a different score each time when she evaluates  answer from a different room
Anshul Khandelwal Invideo|2023-05-04 16:24:39|Yea... independent and good benchmarking of AI needs to be a thing...
Shahul Kaggle Kernel GM|2023-05-04 16:26:21|LLM evaluation is an open research question. We have some nlp eval methods like lm-eval-harness but need to improve from that.
Shahul Kaggle Kernel GM|2023-05-04 16:28:14|just to add one more point, alpaca and vinuca are LLAMA derivatives so I don't think it can fit in that graph since they aren't new base LLMs. Also I don't think its good idea to train models on chatgpts output like Alpaca did, if you're curious about the reason:https://twitter.com/Shahules786/status/1650898925178720256
Nirant|2023-05-04 16:28:43|Benchmarking has this weird dynamic of very useful for industry and their labs, but gives no glory to people who make them — so it doesn't attract hackers or academics.   But once you've a benchmark which is marketed by Stan-ahem-ahem-ford, everyone uses it and the PhD student gets a GoogleAI job on graduation
Anshul Khandelwal Invideo|2023-05-04 16:29:34|Sure... at the research level some objective ones will help but also at the consumer and solutions level... We have a full tech gadget review industry... A similar AI review industry is needed...  This impacts everyone and everything now...
Anshul Khandelwal Invideo|2023-05-04 16:29:52|Need a rtings.com of this space...
Nirant|2023-05-04 16:30:02|That is exactly how ImageNet was born fwiw, and Stanford DAWN Bench and so on. ‎[5/4/23, 16:32:05] Sourasis Roy: ‎image omitted
Lalit Pagaria|2023-05-04 16:40:54|This is the exact problem with building a tool for Devs 😅 - most of the time they prefer to build -  most of them don't have buying power  We also explored it for Careem but later we used open source only. 🙂
Dev Aggarwal|2023-05-04 16:42:41|Most devs actually have the highest buying power in any organisation. If a developer says they need to pay 100$/mo to keep their database up, that’s a bottom line for a business
jyotirmayjk Hackathon|2023-05-04 16:44:41|Devs are the end consumers The decision makers for purchasing tools are not devs  If devs say that they need to keep db up and spend money,that’s BAU  For buying or integrating new tools  it’s more complicated
Nirant|2023-05-04 16:46:01|Hmm, as tempted as I am to chime in and ask questions on how Postman, Stripe, BrowserStack were able to do a dev-first GTM — I'll resist the temptation since this is already off topic for a Generative AI focussed chat 😅
Pratyush Choudhury|2023-05-04 16:48:25|We should jam separately on this, very different problems and implications :)
Shashank Generative AI Group|2023-05-04 16:48:36|yeah. fastai was also going to build a tf swift version i think, but all those projects kinda got abandoned when Chris Lattner left Google.
Maneesh Mishra|2023-05-04 17:00:22|‎Maneesh Mishra joined using this group's invite link
~ Sachin H|2023-05-04 17:00:35|‎~ Sachin H joined using this group's invite link
~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿|2023-05-04 17:00:57|‎~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿 joined using this group's invite link
~ Ashutosh Agarwal|2023-05-04 17:04:16|‎~ Ashutosh Agarwal joined using this group's invite link
Sainath GenerativeAI WhatsApp Group|2023-05-04 17:04:17|‎Sainath GenerativeAI WhatsApp Group joined using this group's invite link
~ Gaurang Sanghvi|2023-05-04 17:07:45|‎~ Gaurang Sanghvi joined using this group's invite link
Raghotham Paypal Bargava's Friend|2023-05-04 17:14:17|‎Raghotham Paypal Bargava's Friend joined using this group's invite link ‎[5/4/23, 17:23:06] ~ Blessin Varkey: ‎image omitted
Nirant|2023-05-04 17:23:41|"Generative Pretraining is the default ""GPT"" training objective, I'll let you dig this up on your own. If you don't mind reading papers, the original Radford et al is still relevant for this.   On the words ""instruction tuning"", for all practical purposes — it just means finetuning using instruction datasets https://jasonwei20.github.io/files/FLAN%20talk%20external.pdf"
Aashay Sachdeva MPL Data Scientist|2023-05-04 17:28:16|On a concept level I understand the difference, but while training it, is there a difference? I checked databricks dolly script - https://github.com/databrickslabs/dolly/blob/master/training/trainer.py  There seems to be no difference.
Nirant|2023-05-04 17:28:19|For wider audience, the code interpreter is largely a Python REPL and a GPT4-fork finetuned on Python/code. This is not a separate feature or anything like that.   If you've GPT4 access, you can try this on your own by adding the Python REPL as a tool: https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html
Nirant|2023-05-04 17:28:51|Difference in outcomes or syntax/code which we write?
Aashay Sachdeva MPL Data Scientist|2023-05-04 17:30:51|Syntax/code - essentially the training objective
Nirant|2023-05-04 17:33:09|Going out on a limb, but I'd like to think that they should be identical with different configs — finetuning and training objectives are often kept identical these days
Aashay Sachdeva MPL Data Scientist|2023-05-04 17:35:49|Understood. So we are still doing next word prediction on instruction dataset. Then how does it learn when to stop?
Anshul Khandelwal Invideo|2023-05-04 17:38:42|Yep. Code interpreter is quite useful.  Threw a csv I had at it and it saved me at least an hour in data clean up if not more...
Anshul Khandelwal Invideo|2023-05-04 17:40:19|Chatgpt code interpreter and gpt-4 browsing models are more useful than I anticipated.
Nirant|2023-05-04 17:40:40|Guessing — stop word markers in the instruction dataset?
Ankita Mathur Microsoft Sales|2023-05-04 17:41:35|Are there specific communities/ influencers to follow for generative AI content on Twitter ?I see a lot of content across all groups from Twitter hence asking here
Nirant|2023-05-04 17:43:10|DM'd my list
Pratyush Choudhury|2023-05-04 17:44:15|https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table  This does seem upto date and is a very fine repository of all the models out there
~ Shweta Gaur|2023-05-04 17:47:34|‎~ Shweta Gaur joined using this group's invite link
~ Siddartha|2023-05-04 17:50:19|‎~ Siddartha joined using this group's invite link
~ vivekananda murari|2023-05-04 18:08:18|‎~ vivekananda murari joined using this group's invite link
Sudharshan GenAI|2023-05-04 18:20:56|https://www.reddit.com/r/StableDiffusion/comments/137ex2j/controlnet_tile_can_generate_details_for_each/  ControlNet tike - who's played with this>?
~ Suhas Baliga|2023-05-04 18:21:02|‎~ Suhas Baliga joined using this group's invite link
~ Gaurav|2023-05-04 18:28:56|‎~ Gaurav joined using this group's invite link
~ Ameya|2023-05-04 18:44:20|Does anyone have experience working with GPT4 for coding in Rust/working with libraries? GPT-3.5 is quite terrible, so wanted some insights on whether GPT4 is any better
~ pawangnanaraj|2023-05-04 18:45:04|‎~ pawangnanaraj joined using this group's invite link
~ Aayush|2023-05-04 18:46:33|‎~ Aayush joined using this group's invite link
~ Aravinth Muthu|2023-05-04 18:52:42|‎~ Aravinth Muthu joined using this group's invite link
Dr. Pratik Desai KissanGPT|2023-05-04 18:59:57|If it turns out to be as great as they are claiming, I’m sure someone will build and release open source version of Mojo soon, like OpenMojo etc, and it may create pressure on them.
Rakeshkumar Waghela|2023-05-04 19:18:09|‎Rakeshkumar Waghela joined using this group's invite link
~ Vibbs Dod|2023-05-04 19:24:03|‎~ Vibbs Dod joined using this group's invite link
Sivashankar Ramesh|2023-05-04 19:33:50|‎Sivashankar Ramesh joined using this group's invite link
Sumod K Mohan|2023-05-04 19:53:51|"Yeah, you train on( instruction+prompt, output). So the system learn from those instruction what the stop points are to some degree. But the real challenge is ""how do tell these specific words really messed up"". Here is where you do RLHF. Let me try to find some resource to explain this."
Aashay Sachdeva MPL Data Scientist|2023-05-04 19:54:33|I need to see a training script
Sumod K Mohan|2023-05-04 19:56:40|Doesn't the dolly one do.
Sumod K Mohan|2023-05-04 19:58:15|For all thos who asked me earlier and I couldn't find the original resource. This a great one from Stanford. Explains big picture of pretraining, fine-tuning and RLHF. https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf
Sumod K Mohan|2023-05-04 19:59:00|One will need to deep dive into each of those areas for more details. This is big picture intuition.
~ Subra Subramanyam|2023-05-04 20:00:23|‎~ Subra Subramanyam joined using this group's invite link
Prado Garv's Friend|2023-05-04 20:10:07|‎Prado Garv's Friend joined using this group's invite link
Lavish 2017|2023-05-04 20:27:07|asking without asking part-2 😂
Lalit Pagaria|2023-05-04 22:12:04|"https://twitter.com/pbteja1998/status/1654095756200931328?t=Q6vtkqrBGqOTgRE39s30Gg&s=08  Looks like OpenAI legal team sending a notice to companies using ""GPT"" in their product name. ‎[5/4/23, 22:12:23] Nirant: ‎image omitted"
Pratyush Choudhury|2023-05-04 22:15:11|Like Flash Attention more than multi-query attention for the kind of use-cases we're looking at - would be super interesting to see how this one does though
Nirant|2023-05-04 22:19:20|There are other differences:   StarCoder is ~15.5B, Replit Codegen is ~2.7B StarCoder is trained on 1T token, Replit is 525B tokens StarCoder is OpenRAIL-M license, Replit is CC — both are ok for commercial use
Nirant|2023-05-04 22:20:10|StarCoder is open that their model is GPT2 — so all GPT2 tricks, scripts will work! Replit — I didn't come across on model arch details
Krishna Ntkris|2023-05-04 22:21:25|Really interesting read from Simon Wilson on moats in closed source models quickly disappearing: https://simonwillison.net/2023/May/4/no-moat/
~ Nayan Shah|2023-05-04 22:21:45|https://blogs.microsoft.com/blog/2023/05/04/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge/
~ Nayan Shah|2023-05-04 22:29:18|If someone wants to start learning more about gpt model its training and how to train for a specific domain , any resources to recommend on this ,and has anyone found an opensource model which is comparable to gpt models mainly on context based converstion .. i saw dolly and open assist but if someone has to evaluate .. how someone can go about it ?
Nirant|2023-05-04 22:31:40|1. LM-evaluation-harness for Huggingface compatible models: https://github.com/EleutherAI/lm-evaluation-harness 2. OpenAI Evals for OpenAI models: https://github.com/openai/evals  Both have multiple tasks, including instructions, chat (often called dialogue as well) and some NLP tasks as well
~ Santhosh Guru|2023-05-04 22:33:40|‎~ Santhosh Guru joined using this group's invite link
Nirant|2023-05-04 22:34:16|I've not had a chance to try Dolly and OpenAssist yet, but GPT-JT (https://huggingface.co/spaces/togethercomputer/GPT-JT) is definitely comparable to text-davinci-003, which was their claim.
Nirant|2023-05-04 22:34:56|And I am honestly surprised that they were able to get this far by careful training data selection and training/finetuning params
Sudharshan GenAI|2023-05-04 22:35:41|new model?
Sudharshan GenAI|2023-05-04 22:35:57|Together are the ones behind redpyjamas right?
Nirant|2023-05-04 22:41:37|I think it's a bit old? Dec 2022/Jan 2023?
Nirant|2023-05-04 22:41:50|Yes, I believe so
Sudharshan GenAI|2023-05-04 22:46:19|okay
Sudharshan GenAI|2023-05-04 23:05:14|https://twitter.com/lmsysorg/status/1653843200975704069?s=46
Chirag Jain|2023-05-04 23:05:26|seema perfectly reasonable they are a small team, and because of the authors seminal work there will be lot of inbound activity  makes sense to stabilize the ideas and toolchains a little bit They do mention they plan to open source it in future
Soumendra Dhanee|2023-05-05 00:37:41|Having tried all the models from Google, I fully agree they have no moat.
Shubham Sharma 2012C6|2023-05-05 00:41:23|You think OpenAI has no moat either?
Aakash Kumar  Matrix Partners|2023-05-05 00:41:51|Community / dev side NFX is there
Aakash Kumar  Matrix Partners|2023-05-05 00:43:12|Also early mover is a real advantage for them. All that gets built/is getting built right .. tough/lethargy to rewrite/rewire
Nirant|2023-05-05 00:44:08|NFX?
Pratyush Choudhury|2023-05-05 00:44:37|Network Effects
Aakash Kumar  Matrix Partners|2023-05-05 00:44:39|Network effects 🙈
Soumendra Dhanee|2023-05-05 00:45:59|Of course not, which is why I pointedly talked only about Google 😀
Soumendra Dhanee|2023-05-05 00:48:46|Opensource models are far behind OpenAI right now. They may be able to catch up, and I do think they'll reach gpt4 level performance eventually, but there's a good chance OpenAI will be able to maintain its lead for 2 to 5 years or more, and that amount of moat is usually enough.
Soumendra Dhanee|2023-05-05 00:50:03|I don't think community/nfx is a moat here. Look at what happened to tensorflow.
Sankalp PickYourTrail|2023-05-05 00:50:23|I think even if open source becomes comparable or even more effective, the possibilities of building a business does exist.  Think about at OS market, linux vs microsoft vs macos.
Sreejith Puthanpurayil|2023-05-05 00:53:00|‎Sreejith Puthanpurayil joined using this group's invite link
Gokul Krishnan|2023-05-05 00:54:39|OpenAI's moat comes from aligning with MSFT/Azure. Government and finance domains are essentially theirs for the taking.
Sankalp PickYourTrail|2023-05-05 00:55:55|And the pace at with they can onboard other businesses on plugins- like uber, expedia
Gokul Krishnan|2023-05-05 00:57:03|That will take a while to mature, finance sector is where they'll make the big bags for now
Sankalp PickYourTrail|2023-05-05 00:58:00|esp now that they have solved EDA with code interpreter
Gokul Krishnan|2023-05-05 00:59:21|This seems a bit panicky. It's not difficult for big tech to integrate oss stuff back in. They'll most likely wait a while to see what works best before integrating and releasing into products
~ Nayan Shah|2023-05-05 00:59:51|have u guys tried out the code interpreter? is that on the waiting list right ?
Sankalp PickYourTrail|2023-05-05 01:03:05|With 3 million software devs in India second only to the US's 4 million, not sure about china numbers. I think the open source implementation may accelerate faster than commercial models.  Kaggle has 286 grandmasters; 1,945 masters; 8,632 experts; 68,119. contributors maybe roughly ~10,000 potential folks(expert+) who can build the open source linux equivalent for LLMs
Gokul Krishnan|2023-05-05 01:18:22|Not that I disagree. But as the terrain stands currently, (and please correct me if I'm wrong), all major oss developments in LLM (alpaca, llama.cpp etc) built on top of llama. It cost 30M to train that. I don't know how much we can replicate that in OSS.
Gokul Krishnan|2023-05-05 01:18:36|Perhaps works like Bloom could prove me wrong?
Dr. Pratik Desai KissanGPT|2023-05-05 01:27:50|Another thing is that Microsoft+OpenAI can make inference costs so low that hosting other LLMs probably doesn't make sense unless compliance issue. Just like on-premise vs Cloud. While OSS models catch up on GPT4 quality, they are already working on inference optimization. Microsoft just announced today that they are investing in AMD to counter Nvidia GPU monopoly and also developing custom inference GPUs.
Gokul Krishnan|2023-05-05 01:29:53|Man, MSFT under Nadella is gonna be a business school 101 case study in a few years. He's trying to commoditize their complement: https://gwern.net/complement
~ Rohan|2023-05-05 02:15:32|Not sure if someone shared this here, but super interesting/scary (also expected): ‎[5/5/23, 02:15:33] ~ Rohan: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-05-05 02:17:56|The nearest neighbors will fall first. Further away from it, less chance of being destroyed by the fast-moving train.
Chinmay Shah Arrowhead|2023-05-05 02:32:00|https://www.semianalysis.com/p/google-we-have-no-moat-and-neither
Swastik Banerjee|2023-05-05 02:36:47|Hello awesome people. Missed a week (feels like a decade). What’s new?
~ Akriti Gupta|2023-05-05 02:37:38|‎~ Akriti Gupta joined using this group's invite link
Swastik Banerjee|2023-05-05 02:37:53|wish there was an llm-summarisation hooked to this chatbox for the purpose, lol
Prayank Swaroop Accel|2023-05-05 04:03:15|Hugging face just launched StarCoder LLM  https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_bigcode-chatgpt-copilot-activity-7059941239277678592-hUmn?utm_source=share&utm_medium=member_android
Anirudth N|2023-05-05 06:12:38|You know this group became so big and intractable when you see the same article being shared 5 times in the past 100+ messages. 😅
Amir Nagri|2023-05-05 07:06:53|The Google doom story is about 6mo old, if they get their acts together, they can turn the tide as they still have their distribution intact
Keertana S Suvy|2023-05-05 07:48:06|Anyone using bharatforAI translation in prod? It seems to very require large server instances. Would love to chat if anyone has /is using
~ Abhinav|2023-05-05 08:06:07|‎~ Abhinav joined using this group's invite link
Shashank B Designer|2023-05-05 08:41:09|Good intro + inference optimisations on Diffusers shared by Huggingface folks at NVIDIA-HF Meet-up: https://docs.google.com/presentation/d/1cbcP-wpeb3jMS4-20cEKFmNJAObg13Q_JNbl0YV6qyU/edit#slide=id.g20f09001284_0_76   I could only attend only few parts. If someone has notes, please share.
~ Krishna|2023-05-05 08:46:40|Is there any good article with all available SoTA large models in multimodal space (text, image, video, audio, etc)
Nirant|2023-05-05 09:05:25|I'm afk, but look up Amazon's mm-CoT on HF and explore tags from there. Similar for PapersWithCode.
Nirant|2023-05-05 09:05:48|HF is huggingface.co
Chirag Jain|2023-05-05 09:18:27|we are getting alternatives now gpt-j (old), pythia, open llama, cerebras gpt, etc although without eval it is difficult to tell which might be better 😅
~ Aayush|2023-05-05 09:20:07|‎~ Aayush left
~ Akshay Agrawal|2023-05-05 10:22:42|‎~ Akshay Agrawal joined using this group's invite link
~ Aditya Mishra|2023-05-05 10:28:36|‎~ Aditya Mishra joined using this group's invite link
~ Vik|2023-05-05 10:37:52|‎~ Vik joined using this group's invite link
Sankalp PickYourTrail|2023-05-05 12:26:08|Does anyone know if the probabilistic functions in generative models are truly random or deterministic?
Nirant|2023-05-05 12:31:55|Can you elaborate on what you're trying to understand? This phrasing is hard to understand
Chirag Jain|2023-05-05 12:33:33|if you are talking about RNGs then they are psuedo random and can be controlled via seed
Chirag Jain|2023-05-05 12:34:11|although don't expect same results across devices (chipset)  the underlying rng implementation is different in many cases
Sudharshan GenAI|2023-05-05 12:38:52|What's the difference between gpt-3.5-turbo and gpt-3.5-turbo-0301?  I remember there was an explainer here
Nirant|2023-05-05 12:40:09|"gpt-3.5-turbo is a ""brand"", it will change under the hood when the _next version_ of gpt3.5 comes out.    gpt-3.5-turbo-0301 is a checkpoint/release which will not change"
Sudharshan GenAI|2023-05-05 12:40:46|got it thanks
Sankalp PickYourTrail|2023-05-05 12:45:00|The encoder takes in a sequence of input tokens, the decoder needs to generate/predict the output sequence. The decoder produces a probability distribution over the vocabulary of the language at each time step, conditioned on the previous tokens in the output sequence and the context vector. This probability distribution is then used to sample the next token in the sequence.  The probability function that is used in the decoder to generate the response, if deterministic would essentially mean the model responses are not truly random but have a predictive/deterministic element to it. Thinking out loud whoever controls that deterministic probability model essentially controls how the model hallucinates. Am I missing anything?
~ Siddish|2023-05-05 12:47:01|as they both have separate rate limits, can we use gpt-3.5-turbo-0301 as fallback when gpt-3.5 limits are over?
Nirant|2023-05-05 12:49:00|I think they've shared rate limits, but if they do separately -- yes
Nirant|2023-05-05 12:50:34|Depends on many parts in the decoder, from nucleus sampling to beam search. But safe to say that it's not a decoder problem.   GPT isn't an encoder-decoder model either. It's autoregressive
Sudharshan GenAI|2023-05-05 12:50:54|Does it work that way? Or rate limits are key based
Dhruv Anand|2023-05-05 12:56:05|so, in reality, could we control and fix the seeding of the model, so that it is guaranteed to generate the same output every time for a particular input (also, would temperature=0 do the same thing)? ‎[5/5/23, 12:59:07] ~ Siddish: ‎image omitted
Sudharshan GenAI|2023-05-05 13:00:39|Sure
Dhruv Naik|2023-05-05 13:04:28|Yes, but there is always some non determinism with GPUs.
Sankalp PickYourTrail|2023-05-05 13:09:39|In GPT, the randomness comes from the probability distribution over the vocabulary right? Is there a way we set top-k/top-p values though the chat interface?
Sudharshan GenAI|2023-05-05 13:09:45|What are some good tools for creating and managing prompts?  Prompt version control + feedback + easy collaboration
Dhruv Anand|2023-05-05 13:41:29|Does anyone have resources around how to do chunking while creating code embeddings? Also, pointers to the best open source model for code embeddings would be great.
"Arpan Desai | MobileFirst"|2023-05-05 13:46:26|Noob question: Can Meta's SAM (Segment Anything) and Track Anything - can be utilised for tracking logos from the video?  We are building some use case around detecting logos from video. Would love some pointers.
Sanyam Bhutani|2023-05-05 14:03:30|Yeah. Should work out of the box
Sanyam Bhutani|2023-05-05 14:07:04|What are the best tools/repos to replicate the AI songs like the ghostwriter ones (drake wala)
Chirag Jain|2023-05-05 14:56:58|on the same chipset, yes, as long as all software versions are pinned down to the lowest levels including the os and kernel
Vamshi|2023-05-05 15:15:40|So-vita-svc, afaik
Nishant Apne-App GenAI Hackathon|2023-05-05 15:15:43|https://agi-sphere.com/llama-models/
Vamshi|2023-05-05 15:16:05|so-vits-svc
Vamshi|2023-05-05 15:16:37|Would be interested to know what artist you’re replicating
Vamshi|2023-05-05 15:17:34|Also, it would be a fun get together for anyone trying to make a song, I know I haven’t taken an initiative here, but would be thrilled to jam with anyone who does 🙂
Sudharshan GenAI|2023-05-05 15:20:55|There was a sheet here with a list of fine-tuned models - anyone have it?
Sudharshan GenAI|2023-05-05 15:20:57|[PHONE]
Sanyam Bhutani|2023-05-05 15:52:32|Can you share a link plij?
Nirant|2023-05-05 15:55:42|I've heard good things about this https://github.com/voicepaw/so-vits-svc-fork
~ Akshat Khare|2023-05-05 17:17:15|Hi Akshat here. Hoping to learn and share here. I would love to be a part of hackathons/competition groups if any too. Excited to be in this group. ‎[5/5/23, 17:17:57] Shubham Sharma 2012C6: ‎image omitted
Shivendu Kumar|2023-05-05 18:07:39|Well that so-vits-svc models sheet is deprecated now (obviously because decades have passed 😛)  There's a discord community called AI Hub.  They train and share voice models all day and night. You can check out that instead.
Shivendu Kumar|2023-05-05 18:09:03|I want to train on Arijit's voice but I'm quite occupied these days :')
~ Srijan Saxena 😎|2023-05-05 18:21:33|++
Hasan Tech Art Guy|2023-05-05 18:26:31|https://discord.gg/aihub a lot of models here. It’s 7000 people big and people say all kinds of stuff there. [PHONE] did an amazing job of keeping this community focused and productive for this long, everyday I am blown away looking at the cutting edge work you’ll are doing. ✨
Anshul Khandelwal Invideo|2023-05-05 20:55:09|https://www.mosaicml.com/blog/mpt-7b  Mosaic announced a 7B LLM trained to 1T tokens...
Nirant|2023-05-05 20:55:40|SlackGPT — multiple business workflows, horizontally integrated with Slack.   https://twitter.com/SlackHQ/status/1654050811238928386
Amir Nagri|2023-05-05 21:05:07|Might have to rename it, gpt trademark
Sudharshan GenAI|2023-05-05 21:11:32|salesforce v openai soon
jyotirmayjk Hackathon|2023-05-05 21:12:28|Salesforce vs Microsoft
jyotirmayjk Hackathon|2023-05-05 21:13:14|Also didn’t Slack partner with OpenAI for this ?
Sachin Legaltech|2023-05-05 21:15:06|They are able to generate 84k tokens on a single A100 GPU by finetuning base model of 2k context length to finetuned model with context length of 65k.
Abhishek Maiti|2023-05-05 21:21:28|Just used for a few prompts that I tried for ChatGPT (GPT4), still a long way to go. I used mainly used code snippets and asked questions around it. I wasn't able to get  answers and abruptly stopped giving responses mid way.
Sachin Legaltech|2023-05-05 21:26:44|Which checkpoint did you use ? + it might not do that great with code understanding as it is trained only on 135B tokens from the stack.
Abhishek Maiti|2023-05-05 21:27:20|This one `MPT-7B-Instruct`
Sachin Legaltech|2023-05-05 21:29:01|I will also try it. Would be interesting to generate 6th book of GoT series as George RR Martin might never write it ‎[5/5/23, 21:56:23] Dr. Ashith Generative AI WA Group: ‎audio omitted
Dr. Ashith Generative AI WA Group|2023-05-05 21:56:43|Taylor Swift singing a kannada song :D
~ prthamesh|2023-05-05 22:27:53|I genuinely want to try out The Weeknd singing Arijit songs 😬
~ Subra Subramanyam|2023-05-05 22:50:12|Not sure if this has been shared / discussed before (since I joined late in this group), throwing it here.  https://youtu.be/V4gGJ7XXlC0  Mojo, just being unveiled as we speak now, seems very promising in its ability to solve AI hardware constraints .
~ Onkar Susladkar|2023-05-05 23:11:03|‎~ Onkar Susladkar joined using this group's invite link
Pratyush Choudhury|2023-05-05 23:15:20|https://wandb.ai/site/prompts  Super cool launch by wandb
~ Aravinth Kumar|2023-05-06 00:43:09|https://huggingface.co/spaces/mosaicml/mpt-7b-chat
Rohit Aggarwal|2023-05-06 01:36:13|A very good post on what transformers are for some of us who are getting started and others who just want to deepen fundamentals.  https://txt.cohere.com/what-are-transformer-models/?twclid=218dxtuiktvp0bq92br7zvxeek  Love cohere blogs for the simplicity
Dhruv Naik|2023-05-06 01:46:43|Luis Serrano and Jay Alammar - Cohere has two of best ML content creators ever.
Aakash Kejriwal|2023-05-06 09:58:29|‎Aakash Kejriwal joined using this group's invite link
~ Akshat Khare|2023-05-06 10:23:20|Hi. Anyone wants to join an already formed awesome team in Warpspeed GenAI hackathon? We have one open slot! We would love to have you.
Paras Chopra Wingify|2023-05-06 10:39:33|‎Paras Chopra Wingify joined using this group's invite link
~ Sankeerth|2023-05-06 11:53:51|Does anyone have/made a list of top AI themed newsletters??
Shuvi Shrivastava|2023-05-06 11:58:33|I followed a few but found this the best bensbites.co
~ Vik|2023-05-06 12:04:07|checkout 42papers.com
Nirant|2023-05-06 12:13:03|That's Twitter but worse because almost everything there is already from https://twitter.com/_akhaliq
Ashwin Matrix|2023-05-06 12:14:53|These are the one's ive found quite useful: - [https://www.bensbites.co/](https://www.bensbites.co/) - [https://www.semafor.com/newsletters] - [https://www.lennysnewsletter.com] - [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email] - [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7) - [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)
Paras Chopra Wingify|2023-05-06 12:55:43|New open source LLM, better than Llama, commercial use allowed https://www.together.xyz/blog/redpajama-models-v1
Rohit Aggarwal|2023-05-06 12:58:15|"""The 7B model is still training (at 800B tokens) and we see the training loss still decrease consistently. As a result, we will continue to train it to 1T tokens."" Fascinating that models will start to touch the trillion mark!"
Sumod K Mohan|2023-05-06 13:17:03|No. There are two ways to make it deterministic (this is not including RLHF magic, any fine-tuning magic etc, don't know what all they have here) but both with different behaviours. One by setting temp=0, here you are forcing softmax to select the top word pick, so this degenerates to greedy though you are sampling. Thus will have issues being it taking the most frequent word combinations.
Sumod K Mohan|2023-05-06 13:18:09|The other by setting seeds. This still allows you to 'actually'  generate using top-p/top-k. OpenAI does not let us to set the seed afaik. You can also play with combination of top-p and  temp for your particular problem to see when it is stable/deterministic, you don't need to always go to zero.
Nirant|2023-05-06 13:19:46|Pro Tip for anyone trying to pursue this line of reasoning and looking for first hand experience: Take a GPT2 or BLOOM model and try to get consistent outputs — you'll develop a very good mental model of what it takes to get a deterministic output.
~ Chirag Ginglani|2023-05-06 13:23:58|Hey everyone, Chirag this side from Endiya Partners, an early stage VC. Happy to be here!  Look forward to learning and exchanging notes on the space
Shivendu Kumar|2023-05-06 13:53:56|https://huggingface.co/spaces/Geonmo/laion-aesthetic-predictor https://github.com/google-research/google-research/tree/master/musiq  [PHONE] [PHONE] :D ‎[5/6/23, 14:06:48] Nirant: ‎image omitted ‎[5/6/23, 14:10:12] Nirant: ‎image omitted ‎[5/6/23, 14:10:51] Nirant: ‎image omitted ‎[5/6/23, 14:12:05] Yash Pandya: ‎image omitted
Dev Aggarwal|2023-05-06 14:17:31|Might have a better time just running clip interrogator and just asking gpt for a score from that genenrated caption
Sumod K Mohan|2023-05-06 14:22:48|Hallucination and determinism (the above definition of it, same output for same input) are not that related. Hallucination is largely an after effect of model learning patterns that aren't true, in the weights so to speak. The determinism issue is largely a final layer problem (and may be fine-tuning layers). As in how you select from most  reasonable walk amongst series of words choices (you essentially have k-ary tree starting from first word). Another meaning of determinism could be whether it could generalize well (minor perturbation of input don't lead to change in output), this is very related to hallucination and both are related model weights.
Sumod K Mohan|2023-05-06 14:34:08|I don't think this is doing human profile scoring per se 😀. It is trained on AVA, so doing scene scoring. So nice sunsets or bokeh images, highly saturated colors etc should get good rating.
Nirant|2023-05-06 14:38:01|[PHONE] sir would you like to explain AVA and image dataset curation methods/conventions — lot of folks here are not from Vision in particular
Yash Pandya|2023-05-06 14:40:41|It is pretty bad at scene scoring too unfortunately. Only the examples they've shared score well.
~ Pulkit|2023-05-06 14:42:24|‎~ Pulkit joined using this group's invite link
Anmol Sonthalia GenerativeAI WhatsApp Group|2023-05-06 14:51:52|‎Anmol Sonthalia GenerativeAI WhatsApp Group joined using this group's invite link
Sumod K Mohan|2023-05-06 14:51:58|Sorry, my bad. This is for the problem of Visual Aesthetic Scoring that is given a set of pictures, score pictures from interesting to least (think flickr interestingness if you know what that was, like what photos you will want in your album or showcase your photography talent). There were bunch of datasets created for this, AVA was one of those, I think curated from DPChallenge with score and sematic tags for each image.
~ Vik|2023-05-06 14:55:19|it's ranked based on likes etc not from a specific person also each paper is has a short summary as well as why it's important basically designed for a daily quick scan
~ Vik|2023-05-06 14:56:23|which part is worst always improving so happy to learn
~ Aravinth Kumar|2023-05-06 15:02:33|https://github.com/mosaicml/llm-foundry/tree/main/scripts/eval  Benchmarking framework but by Mosaic 😅 ‎[5/6/23, 15:02:53] ~ Aravinth Kumar: ‎image omitted
~ Sparsh Gupta|2023-05-06 15:04:57|‎~ Sparsh Gupta joined using this group's invite link
Rohit Aggarwal|2023-05-06 15:06:28|there needs to be a standard that everyone can use. Was hoping HELM becomes that
~ Ankit Jain|2023-05-06 15:06:49|‎~ Ankit Jain joined using this group's invite link
Pranjal Yadav Razorpay|2023-05-06 15:07:14|Any good library references to create datasets for LLMs? Say, training Vicuna/Dolly 7B/13B on a domain. I want to replicate what BloombergGPT did in finance but for a very specific bucket in finance. Also, any way to estimate infra cost for suchs training and hosting?
Kishore GenAI|2023-05-06 15:08:40|"Given a prompt, and a set of generations from the prompt, example, if the prompt is ""black and gold colour scheme, blue sky, white mountains, red house,... "" and 10 images are generated, is it possible to rank the generated images based on how well the prompt was followed?"
Kishore GenAI|2023-05-06 15:11:18|Additionally, given that there are numerous generations where there are small issues, for example, extra hand in one, incorrect tshirt representation in another, is it possible to auto build a workflow, which figures out where the image is incorrect , masks it, and sends through another generation to fix that area?  If so, what would be required for it to detect errors in the image? ‎[5/6/23, 15:11:25] ~ Aravinth Kumar: ‎image omitted
Dev Aggarwal|2023-05-06 15:12:30|Reply with: DM me 😂
~ Srinivasan Nandakumar|2023-05-06 15:14:30|you can check out the stanford alpaca repository.  They explain the method that lets you create the dataset based on few hand written examples. That uses distilling datasets using LLM's from open AI. But if this is something that is going to be for commercial use you have to check the terms of service.
~ Aravinth Kumar|2023-05-06 15:19:35|Could be a growth hack as well
Nirant|2023-05-06 15:23:50|"Are you a dev? Because you just pulled a ""It's a not a bug, it's a feature"" 😂"
Sumod K Mohan|2023-05-06 15:58:17|No that is a different problem altogether. The above one is a very visual problem, doesn't depend on things like semantic meaning or the implications of those as much. So for example, it will rank the fanous Henry Cartier Bresson's Leap into unknown photo (this photo's context is Europe entering world war 2) poorly. The visual aesthetic problem to a decent degree is sort of solved. Many models are production use, where you can remove human time required. But this problem requires more understanding of real world (like humans have 2 hands etc). So training on that dataset probably won't work as well. I think [PHONE] and others have worked on this more. They can chime in on what works.
Sumod K Mohan|2023-05-06 16:00:39|I mean, large scale deployments are common for Visual Aesthetic scoring, where revenue numbers can be impacted if you do poorly.
Kishore GenAI|2023-05-06 16:04:17|"Is it possible for a visual QA model to identify errors in a picture, if we use ""errors in the image"" as the question? Then use grounded SAM to auto-detect areas where the visual QA answered? And then use models which are finetuned on those datasets to fix those imperfections?"
Kishore GenAI|2023-05-06 16:05:14|I am asking more from a workflow, rather than one model doing it all. It would be difficult to make it work using a single model.
Dev Aggarwal|2023-05-06 16:06:02|this seems like a task for andrew ng's https://landing.ai/
Kishore GenAI|2023-05-06 16:07:19|Any open source suggestions?
Abhishek Maiti|2023-05-06 16:20:42|Could you expand a bit on errors, what kind of errors are you expecting, like logical, or edited in errors?
Abhishek Maiti|2023-05-06 16:22:04|Oh I just saw the above messages, you mean errors between the prompt and the images.
Abhishek Maiti|2023-05-06 16:23:47|a naive idea that comes to my mind, is divide the images into multiscale patches, embed with CLIP and then check similarity with the prompt.
Kishore GenAI|2023-05-06 16:24:20|The issue with this is that if the hands were incorrect, it would still return hands.
Rohit Aggarwal|2023-05-06 16:26:26|"Discussion on HN about Langchain https://news.ycombinator.com/item?id=35820931  - more useful when using OSS models - all the magic resides in prompts - good for building vector indices without worrying about writing adapters - can be brittle at times - the best on-ramp for ""practical uses of llms"" because it scratches just the right developer itch - some people defected to deepset haystack  Lots more gems in the thread though"
Abhishek Maiti|2023-05-06 16:31:44|"similarity of the string ""hands"" will still be less for it, compared to a good set of hands, is what I am hoping.  Another way (again, possibly naive) is to get the caption for the image, using BLIP-2 or something, and check if the logical components of the caption is same as the prompt."
Jay Pokarna 2014 BPCC|2023-05-06 17:33:19|Any idea how much time does it take to get access to chatgptplugins?
Pranjal Yadav Razorpay|2023-05-06 19:10:25|Thanks, I'll check.
Swastik Banerjee|2023-05-06 19:19:23|Is there any usable finance gpt yet? i.e., trained on yahoo finance or something?
~ Ankur Khandelwal|2023-05-06 19:34:21|Bloomberg gpt.. but it quite expensive
Swastik Banerjee|2023-05-06 19:34:45|they’ve released a product? Last I knew it was a paper
~ Ankur Khandelwal|2023-05-06 19:35:46|I think they released it into their terminal
Swastik Banerjee|2023-05-06 19:37:13|someone was finetuning gpt with yahoo finance in this group?
~ .|2023-05-06 19:54:38|‎~ . joined using this group's invite link
Pratyush Choudhury|2023-05-06 20:40:54|https://llava.hliu.cc/  LLaMa is everywhere
Shimanta Generative AI|2023-05-06 21:02:59|There’s an open source alternative to Bloomberg terminal called OpenBB. They released a blog on how one can train on their documentation to get the appropriate OpenBB command  https://openbb.co/blog/role-of-ai-and-openbb-in-future-of-investment-research
Amir Nagri|2023-05-06 22:46:05|I'm starting to look into the autonomous agents space  Any resources that covers the fundamentals of this field (and not the autogpt/babyagi hype)  🙏
Sudharshan GenAI|2023-05-06 23:37:51|https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents
~ Vik|2023-05-06 23:44:43|i built something for myself along these lines much simpler and no dependencies
~ Vik|2023-05-06 23:44:57|https://github.com/dosco/minds
Nirant|2023-05-07 03:29:53|OpenAI Chief Scientist Ilya S. explains that OpenAI is not doing closed source because of _safety reasons_ — as they've hinted in the past, , but because of competitive reasons. He believes models can be improved to the point _in future_ where it becomes a safety concern.    https://www.youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0
Nirant|2023-05-07 03:30:19|competitive reasons aka MSFT in simple words
Dev Aggarwal|2023-05-07 04:39:54|If anyone wants a longer rant, look up yannic kilcher on YouTube 😂
Pranjal Mehta|2023-05-07 07:06:25|Try yubibert for India
Pratyush Choudhury|2023-05-07 08:17:41|As LLaMa adoption suggests, once you release the weights publicly, the ecosystem catches up very, very strongly  So I guess they're mindful of the same  Also, I don't think we have anything in OSS today that's close to GPT3.5, GPT4 or Claude but the key question is can we get there in 1-1.5 years
Sankalp PickYourTrail|2023-05-07 12:32:14|they will have the RLHF edge in 1-1.5 years where OSS will keep playing catchup
Sankalp PickYourTrail|2023-05-07 12:40:38|True, and in 1-1.5 years they will have the RLHF edge which OSS will keep playing catchup on
Pratyush Choudhury|2023-05-07 14:44:34|Here's where my thoughts are -  1/ LLaMa weights leaking was a lucky incident - if we believe that models will become larger (which I do), do we expect similar weights being leaked for bigger models going forward?  2/ If/As models become bigger, how many labs/companies would be able to keep up with the training costs?  It'd slowly start moving towards an oligopoly even for the OSS model providers  3/ That said, it's very well possible that OSS models form the bulk of AI usage moving forward  I guess Emad from Stability believes this and is playing to the playbook - let an AWS monetize the long tail of the OSS model usage while some of the biggest customers will pay premium for small, incremental better performance
Nirant|2023-05-07 14:46:19|While [PHONE] already gets this, reminder for other readers:   Most FOSS models, including Llama are probably to 80-90% of text-davinci-003 — and do not show the reasoning and task planning abilities which GPT4 (or to a limited extent 3.5 show) _today_
Pratyush Choudhury|2023-05-07 14:57:27|Which (as per my current level of understanding) matters more in an Autonomous Agent powered world  Running thought: in the consumer world atleast, I think the most popular way of doing model orchestration could be something like this - an interface like Jarvis or LangChain or Fixie or the like takes my inputs and remediates across a series of FMs to get a task done  The interface takes care of the memory and reasoning aspect and would likely include a closed source FM
Anshul Bhide Replit|2023-05-07 16:10:39|Hot take from Jim Fan:  https://twitter.com/drjimfan/status/1654926960165011456?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg ‎[5/7/23, 18:03:08] ~ Pradyumna Bang: ‎image omitted
Nirant|2023-05-07 18:17:44|Summary of everything that we discussed yesterday with all the links:  https://nirantk.com/ai/6th-may-2023.html
Kaushik Bokka|2023-05-07 18:25:38|https://twitter.com/natolambert/status/1654190084428808194
Nirant|2023-05-07 18:31:06|This is also a work-in-progress preview of a daily summary of this group chat — going back to starting of the group itself:  https://nirantk.com/ai.html  This is hopefully useful:  1. Daily links — so you can catch up on what we've talked about 2. Each page has a title and table of contents, so you can dig into topics of your interest
Nirant|2023-05-07 18:31:47|Design Choices:  1. I've removed as much PII as possible, specially phone numbers 2. I've removed as many names as possible as well, unless they're part of the message itself 3. I've tried to add descriptions with links  Note that the poll indicated that people were okay with sender names being public, I've chosen to remove them out of abundance of caution. I want minorities in tech e.g. women to feel comfortable participating here despite being a large-public forum.  I've tried my best: read over 12 hours of summaries and >$100 in GPT bill so that summaries are useful — and there is still an advantage of participating in active conversation e.g. details, specific questions, Q&A and so on.
Nirant|2023-05-07 18:31:53|Asks:  1. Please read the summaries and report issues, bugs to me. 2. This is a manual hacked together bunch of Jupyter notebooks right now: https://github.com/NirantK/nirantk.github.io/tree/main/community_dev/nbs — would be really grateful for a single script which takes a .zip input and I can run every 2-3 days only on new data 🙏
Pranjal Yadav Razorpay|2023-05-07 18:31:59|Damn, I was about to start working on this exact thing!
Pranjal Yadav Razorpay|2023-05-07 18:36:57|The markdowns in content/ai/ are the summaries, right?
Nirant|2023-05-07 18:37:22|Yes
Nirant|2023-05-07 18:39:54|It's the markdown files which Hugo builds into static website served via Github Pages The build is also a Github action on the same repo
Nirant|2023-05-07 18:40:15|I'd love if we can use prettier CSS and better JS: https://quartz.jzhao.xyz/ — this has fast search and is also markdown friendly
Pranjal Yadav Razorpay|2023-05-07 18:42:56|I'll do 2. I'm guessing you have the zip file locally and you want to run manually for now?
Nirant|2023-05-07 18:43:55|Yes. I've the zip file locally — well everyone in the group can download it as well. And I want to run locally, but only incrementally.
Krishna Ntkris|2023-05-07 18:46:04|Thanks so much for doing this [PHONE]. Maybe we can have a pool where we can contribute to the bill or something? Happy to support in whatever way you suggest. Also realise its a fraction of the total effort, so double thank you ‎[5/7/23, 18:51:27] Soumyadeep Mukherjee: ‎GIF omitted
Bharat Kumar Ramesh Hashmal Web3|2023-05-07 20:53:57|You have to appreciate the hustle
~ Nikhil|2023-05-07 20:54:31|AI creating new jobs (NOT taking them away :P)
Bharat Kumar Ramesh Hashmal Web3|2023-05-07 20:55:57|Totally. Fiverrs a great window into what services are becoming valuable.  Prompting, especially for more complex art, will see a huge influx of freelancers
~ Nikhil|2023-05-07 20:58:24|Replit bounties are flooded with ChatGPT and AutoGPT related projects too.
Sudharshan GenAI|2023-05-07 20:59:06|promptbase is a better signal
Sudharshan GenAI|2023-05-07 20:59:21|They have loads of prompt engineers - they charge 50-500$ for custom prompts ‎[5/7/23, 21:15:58] ~ Nikhil: ‎image omitted
~ Vik|2023-05-07 22:00:47|the google memo leak seems to think smaller os models are the future
Nirant|2023-05-07 22:02:55|Reminder that is a single Google employee's opinion, not their company policy or even a team's mandate.
~ Vik|2023-05-07 22:08:23|https://arxiv.org/abs/2305.02301
Shimanta Generative AI|2023-05-07 22:08:47|Is the memo written and leaked by a single employee, or it was a memo shared internally and leaked by an employee?
Nirant|2023-05-07 22:09:24|Written by a single employee, shared internally, like an internal forum, and shared outside by someone else presumably
Shimanta Generative AI|2023-05-07 22:11:16|Got it, I was thinking it was shared by higher ups in some meeting or something
Gokul Krishnan|2023-05-07 22:19:42|Google is quite open internally, ex you can view almost anyone's code if you're an employee. Most likely someone wrote a Google doc, shared in an internal Google group and it went viral / leaked. Similar to the memo written by James Demore
Shashank Generative AI Group|2023-05-07 22:20:06|great thread wrt the  Google employee memo.  detailed thoughts on OpenAI's moats  https://twitter.com/labenz/status/1654853354529382407?t=zKjj004f4cWztIJbmGvWOw&s=19
Gokul Krishnan|2023-05-07 22:23:00|Koi tldr?
Aashay Sachdeva MPL Data Scientist|2023-05-07 22:25:09|Hey, who can I dm for a referral at dashtoon? It is for a friend
Vaibhav Bhargava Meesho Grab |2023-05-07 22:25:42|Ask admin literally.
Ravi Theja|2023-05-07 22:25:43|[PHONE]
Aashay Sachdeva MPL Data Scientist|2023-05-07 22:25:58|Thanks
Soumyadeep Mukherjee|2023-05-07 22:26:17|Yes please DM me :D
Soumyadeep Mukherjee|2023-05-07 22:26:28|I love referrals for dashtoon specifically :P
Sidhant Sequoia|2023-05-07 22:36:42|Personally am aligned to [PHONE] ‘s #3rd point above.  Situation - I’m developing a FM app and I have the option of using either a closed source or a FOSS FM. If the FOSS FM’s capability for a particular genre of task eg summarisation is broadly in the same range as a closed source FM and there is significant advantage that I get from fine-tuning it on my data, the self hosted FOSS choice may be a no brainer.  For certain sophisticated tasks eg task list gen for an agent there might be value in using a closed source FM with meaningful better output. Not sure if that would be the majority of the functionality of the app, unlikely.  So just like the trad software world both ecosystems might exist in tandem + balance. Different players will monetise and dominate both.  The extent of FOSS presence may be a function of how true the GPT benchmarking of Vicuna-13B v Bard v GPT4 really is, and if over time Vicuna et al can continue to match closed FMs. Also if future FMs are open sourced like the Llama lucky break for the community to innovate on.  If anyone here can shed light on how much to take the google employee’s claims on the stackability + value of LoRA and training on limited high value datasets (specific strong GPT4 outputs), would be useful. The claims seemed compelling but not sure how actually reliable. 🙏
Shashank Generative AI Group|2023-05-07 22:58:06|"TLDR. worth reading the whole thread but pasting some main points below:  - People in general are super confused, unnerved, and even outright scared by AI. Thus, many will want to use the safest, most established option - They used to say “Nobody gets fired for going with IBM”; the modern echo might be ""Nobody gets fired for going with OpenAI"" - OpenAI's product feedback loop.  They started with @ycombinator -style product-market fit obsession, & are now collecting data at unmatched scale via ChatGPT free tier - pricing power. OpenAI has led the market on price cuts, with ~97% price reduction over the last 9 months. No reason to think they're done. Developers are often surprisingly resistant to paying for software, but at $2 / 1M tokens, open source can only undercut so much - talent density extends to all parts of OpenAI, btw, including sales & account management. - insane distribution and partnerships. bing, consulting firms etc - network effects.  While AI doesn't seem to have the same network effects as web 2.0 / social media, it's still notable that every ""Prompting 101"" course, performance benchmark, library, and tool is built for / on / with OpenAI models first."
Shashank Generative AI Group|2023-05-07 22:58:48|⬆️ done
Gokul Krishnan|2023-05-07 23:06:05|What's the current hypothesis on how OpenAI is able to offer such a low price?
Aashay Sachdeva MPL Data Scientist|2023-05-07 23:14:00|I think if we dive a little deeper, openai has been making lots of optimisation on the inference side. Hence the cost is continuously coming down. Lilian weng (applied scientist at openai) wrote this -https://lilianweng.github.io/posts/2023-01-10-inference-optimization/
~ Lakshay Nagpal|2023-05-07 23:15:06|"Hi everyone, I am experimenting on the prompts with gpt3.5 api For cases where it doesn’t know the answer, it states the answer like “As an AI language model”. How can I improve my prompt in such a way that for such answers, it can say something like “I'll get back to you on this”.  My system prompt - If you are unable to answer a question and if the question is out of your scope, you can say that ""I am still learning, I'll get back to you on this""  I tried adding it in the user prompt, but it still answers the same."
~ Lakshay Nagpal|2023-05-07 23:15:12|Current result - User - What is the current time? AI - I'm sorry, but as an AI language model, I do not have access to real-time information. However, you can check the current time on your device or by searching online. Is there anything else I can assist you with?
Aashay Sachdeva MPL Data Scientist|2023-05-07 23:20:46|Is this the answer everytime? Have you tried it multiple times?
Aashay Sachdeva MPL Data Scientist|2023-05-07 23:22:06|https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html?highlight=don%27t%20know#the-stuff-chain  Refer to this.
Shashank Generative AI Group|2023-05-07 23:30:17|optimization is one reason but OpenAI's had a $540M loss last year. idk how much of the loss if from Free ChatGPT vs cheap API. lower pricing has also helped increase usage. search applications, chatbots, langchain, llama-index started taking off when OpenAI reduced embeddings model cost by 95% back in December. ‎[5/7/23, 23:31:18] Shashank Generative AI Group: ‎image omitted
~ Lakshay Nagpal|2023-05-07 23:33:03|The part “As an AI language model” is consistent in all the messages which model doesn’t know
~ Lakshay Nagpal|2023-05-07 23:33:10|Let me go through this
Rohit Aggarwal|2023-05-07 23:48:16|"have you tried few-shot prompting? Prime with examples where you respond with ""I am still learning, I'll get back to you on this"""
~ Lakshay Nagpal|2023-05-07 23:50:40|Not yet. Didn’t try it because I am running the bot which is solving multiple cases and for those cases prompt is already big.  Adding examples for this case, makes the prompt bigger which I was trying to avoid.
~ Suhas Baliga|2023-05-08 00:00:12|This group is cutting edge, folks! Can be monetised. 😄
Sankalp PickYourTrail|2023-05-08 00:08:50|Absolutely! These daily chat summaries can be signal amidst all the noise around AI for a lot of people as newsletter/podcasts(maybe with weekly frequency reviewed by mods).
~ Vik|2023-05-08 06:59:03|hard to speculate anything from losses they are a creation of accounting often sv companies have large stock comp. based losses. i work with llms in production mostly using react and other simpler prompting openai is the most consistent llm i can be confident around, cohere is the second most
Nirant|2023-05-08 10:46:46|Who're the best people in Bengaluru who could do a deep dive on computer vision/image generation topics like Unet, Segmentation, Self Supervised Learning e.g. SAM, Diffusion to someone with no computer vision background?  Please send suggestions to Soumyadeep [PHONE] Context: Looking for a May meetup speaker
Chinmay Shah Arrowhead|2023-05-08 10:48:29|[PHONE]
Vignesh Baskaran|2023-05-08 11:06:47|Thanks bhai. Will DM Nirant and Somu
Saurav Akaike|2023-05-08 11:09:35|Rohan from Inkers.
Kaushik Bokka|2023-05-08 12:00:39|Might schedule a meet with an executive at Midjourney soon.  Any questions you would like me to ask?
Paras Chopra Wingify|2023-05-08 12:02:00|are they profitable?  also what makes them stick to discord for so long, why not invest in their app
Siddharth Agarwal|2023-05-08 12:04:32|What is their plan for the long run? The discord model cannot be that sustainable.
Shashwat TDC|2023-05-08 12:05:46|hey admins, is there a way we can do beta launches in the group. Interestingly the first ever demo of the product was presented at deep hackathon. Thanks for adding [PHONE] in the first place. At a slightly more mature and functional stage now.
Nirant|2023-05-08 12:19:50|Glad to hear that you've a more mature product! 🫶🏻  Perhaps Product Hunt, Twitter and other hackathons (there are 2-3 of them across BLR, BOM in the next 50 days) are better forums for launches/demos than trying to have them over a WA group?  That said, if there are 3-5 people wanting to demo _exceptional_ work, please DM Loom demos to me and we'll take it from there 😁
Anshul Bhide Replit|2023-05-08 12:28:33|I believe [PHONE] literally did his PhD on this :)
Nirant|2023-05-08 12:29:11|He was our first pick as well, unfortunately he is occupied on the meetup dates
Shashank Generative AI Group|2023-05-08 12:32:11|"some users have access to the web app.  i think all the moves they've done till now, esp the discord one are pretty brilliant.   acc to their founder: not focussed on building a ""platform"" from the beginning. main focus right now is product.  i mean just look at Dalle. it has a webapp, API but i doubt anybody uses it srsly in a product. i have a ton of unused credits i got from OpenAI Artist grant. even with a webapp, Dalle UX is worse than MJ when you actually map out the workflow.  also 1-2 months back they did say that API is in the works.  my guess is they'll start testing it after they release v6 (2-3 months)"
Shashwat TDC|2023-05-08 12:32:26|Sure. Thanks Nirant. Will DM you with more context mid week.
Shashank Generative AI Group|2023-05-08 12:33:03|David's tweet https://twitter.com/DavidSHolz/status/1655122525616242690?t=aM1R-2Vk5gvrOIScY4ipWg&s=19
Aashay Sachdeva MPL Data Scientist|2023-05-08 12:35:01|Wouldn’t the investor group be a good fit for this
Rakeshkumar Waghela|2023-05-08 12:35:23|API. When are they launching official API for their products.  So many unofficial API providers mushrooming due to lack of official API.
Sumod K Mohan|2023-05-08 12:41:04|Sorry folks, too many things this month.
Sudharshan GenAI|2023-05-08 12:42:31|[PHONE]
Kshitij Agrawal ML Engineer|2023-05-08 12:43:56|Thanks Sudarshan.. Happy to share with the community!
Sudharshan GenAI|2023-05-08 12:46:38|He's published in ICCV, CVPR, consults a good number of startups, and has worked with IIIT-H. Much more too, but this is what I remember from our small chat at the Nvidia meetup :)
Sudharshan GenAI|2023-05-08 12:47:41|when API
Ojasvi Yadav|2023-05-08 13:15:15|How did they approach their hiring?  One of the most impressive things about them is their lean team. Would definitely love to learn about how they found the right people.
Dev Aggarwal|2023-05-08 14:25:59|I guess it would just be the leap motion team na?
Aashay Sachdeva MPL Data Scientist|2023-05-08 14:30:40|https://twitter.com/bindureddy/status/1655253111659978752?s=46  Bard vs chatgpt will be like android vs ios. Different Ux, prompting, features😅
~ Sarthak Kanodia|2023-05-08 15:07:47|‎~ Sarthak Kanodia joined from the community
~ Jatin|2023-05-08 15:39:36|Hi All,  Any idea on the timelines for GPT 4 api access? We need it for a pilot we are doing with an organisation. If anyone of you have it, we are looking to utilise it and pay for the usage.
Aashay Sachdeva MPL Data Scientist|2023-05-08 15:50:59|Ping [PHONE]
~ Lakshay Nagpal|2023-05-08 15:57:31|"I am able to fix this. I made few changes in prompt. I have mentioned about the type of message it can send & have specifically mentioned avoid saying the line.  Avoid saying that you are ""AI language model"" If you are unable to answer a question, you should ask the student to give more context about the question but refrain from making up the answer."
Kartik Mandaville|2023-05-08 15:59:48|you can email Atty from OpenAI / he is pretty helpful
Saurav Akaike|2023-05-08 16:00:02|Facing the same issue. If any of you have any hack for this- do help!
Kartik Mandaville|2023-05-08 16:02:18|Go live with GPT3.5 and show traction worked really well for us
Ankesh Atlassian AI|2023-05-08 16:08:43|I have access to both 3.5 turbo and 4. GPT 4 is both slower, more expensive and isnt necessarily a whole lot better than 3.5 Turbo. What worked more for us was iterating with system messages and measuring improvements to output.
Nirant|2023-05-08 16:10:45|GPT4 is slower, more expensive and almost 2-5x better for any reasoning e.g. QA or agent behaviour e.g. AutoGPT kinda things.
Kartik Mandaville|2023-05-08 16:13:35|no, we applied two weeks ago and haven't gotten gpt4 yet ‎[5/8/23, 16:21:45] Swastik Banerjee: ‎image omitted
~ Jatin|2023-05-08 16:28:29|Yes 100%.  This is already achieved for my company though.  For the pilot with an organisation we needed the access.
Karan Lightspeed|2023-05-08 16:45:10|Any good material on how folks are monetizing the GPT plugins?
~ Vibbs Dod|2023-05-08 16:55:39|There is another way to solve this, I am able to add context block for starting any communication with the llm model one of the fields of the context block is currentDateTime: <ISO string format>  Whenever the model needs to refer to the date for some output I explicitly mentioned that refer to context block for any missing info,.  For ever further fine-tuning ask it to follow a certain output format. If you are able to prompt back to user then great but if you are orchestrating the communication between two agents then expecting a proper formatting will help you reduce round trips for your llm model to understand what the instructions want. let me know if you want to explore. - I have played around with langchain for past 3 months now
Swastik Banerjee|2023-05-08 17:05:24|roughly equivalent to their api pricing plan because ultimately it calls their api?
~ Lakshay Nagpal|2023-05-08 17:06:11|Let me try this out. Have not thought about it yet
Kartik Mandaville|2023-05-08 17:07:28|Has anyone even monetized?
~ Vibbs Dod|2023-05-08 17:07:34|Hey folks,   Any body here facing the problem with payment on OpenAI platform - I am unable to complete my payment - tried multiple payment options and also tried VPN soln mentioned in one of the forums. Have reached out to the OpenAI team, but wanted to check in this forum as well.  Help would be appreciated!
Karan Lightspeed|2023-05-08 17:09:16|Exactly my question - especially for plugins that are not for an existing business like Open Table. Want to understand how folks are thinking about mid-term monetization
Shan|2023-05-08 17:27:46|I paid using an axis bank corporate debit card and it worked, lol.
Arvind N Generative AI Group|2023-05-08 17:32:14|Hello, What's the best resource to read up on the LoRA config (number of attention heads, scaling factor) settings best practices? I'm specifically interested in fine-tuning the OPT6.7B on my custom dataset.
Kartik Mandaville|2023-05-08 17:35:09|For short term, you can do stuff like custom search in slack, notion etc
Ravi Theja|2023-05-08 17:37:38|Facing same problem. Unable to pay for past 2 months 😅😅
Kartik Mandaville|2023-05-08 17:42:10|we use USA issued cards and those work fine
~ Sayan|2023-05-08 17:49:44|And manual payment goes through smoothly ‎[5/8/23, 18:14:57] Nirant: ‎image omitted
Pratyush Choudhury|2023-05-08 19:05:11|https://archive.is/elhiG  Future visions of Google Search
~ Onkar Susladkar|2023-05-08 19:09:15|Hello  Anyone who had published a paper in top-tier conferences like Neurips, CVPR, ICCV, ECCV, ICASSP, ACL, and NAACL as a 1st or 2nd author. I am looking for some people to collaborate with me on the research.
~ Omkar|2023-05-08 19:15:46|Hi, any suggestions for Natural Language to Code. Something similar to OpenAI Codex.
Nirant|2023-05-08 19:16:32|What are you looking for? I've an ACL SemEval paper: https://aclanthology.org/2020.semeval-1.119/
Nirant|2023-05-08 19:18:05|Do you want something which can follow instruction? If yes, this is the best FOSS I've seen so far: https://huggingface.co/bigcode/starcoder   If you're looking for more Github Copilot like completion: https://huggingface.co/replit/replit-code-v1-3b
~ Onkar Susladkar|2023-05-08 19:19:56|I am currently doing research mostly on MultiModel (Speech, Language, video) systems if you like to collaborate DM me
~ Omkar|2023-05-08 19:20:26|Thanks.
Nirant|2023-05-08 19:27:42|Not an academic  — the ACL Paper was to help an intern get into academia, done mostly as a hobby :)
~ Onkar Susladkar|2023-05-08 19:28:17|Ohh Fine !
~ Onkar Susladkar|2023-05-08 19:28:55|Please anyone is interested let me know
Aashay Sachdeva MPL Data Scientist|2023-05-08 19:33:35|Does KDD count? I know my friend who had worked on a paper at glance and it got published
Aashay Sachdeva MPL Data Scientist|2023-05-08 19:33:42|He can probably help you
~ Onkar Susladkar|2023-05-08 19:34:17|Ohh yaa KDD will also count in
~ Kartheek Akella|2023-05-08 19:36:22|What's up? I've published in ACL in low parameter adptation - https://arxiv.org/abs/2107.09622
Nirant|2023-05-08 19:36:56|Ohh Jawahar's student 🙏
~ Kartheek Akella|2023-05-08 19:37:20|Haha yeap...
~ Onkar Susladkar|2023-05-08 19:38:15|your too jawahar sir student
Nirant|2023-05-08 21:44:09|What's the solution for storing and querying embeddings in/from a MySQL db?
~ Ankit Sharma|2023-05-08 21:48:01|‎~ Ankit Sharma joined using this group's invite link
~ Rahul Rajvanshi|2023-05-08 22:01:32|‎~ Rahul Rajvanshi left
~ Akshit Banta|2023-05-08 22:19:46|‎~ Akshit Banta joined using this group's invite link
Dev Aggarwal|2023-05-08 23:21:05|np.array(SELECT * FROM db) 😂🫶
Pratyush Choudhury|2023-05-09 01:21:17|https://twitter.com/jxnlco/status/1655368751657676800?t=5t9flIlOSbLwO-N2fhza5A&s=19  Cool stuff and an even cooler name
Rohit Ganapathy|2023-05-09 01:46:00|facing massive timeout issues with /chat/completions/gpt-3.5-turbo. Status page is all green. Anyone been facing this lately?
Lavish 2017|2023-05-09 02:04:50|yes happens a bunch of times and can see some 50-60 timeouts yesterday. you can put retries in place if not already. 95% of 50 timeouts succeeded on retry.
Lavish 2017|2023-05-09 02:09:04|anyone knows what's the fastest open source llm right now?  been meaning to tinker with open llms for a while but haven't gotten to it, can anyone share some suggestions on what are the good ones with resources available in terms of documentation.
Kartik Mandaville|2023-05-09 03:16:11|https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec has anyone explored this technique? Seems very interesting ‎[5/9/23, 06:25:52] Nirant: ‎image omitted
Sidhant Sequoia|2023-05-09 06:25:59|https://twitter.com/kevinafischer/status/1655734333720633348?s=48&t=ACPHEfclkXmi9Z92RTsh9g
Anshul Khandelwal Invideo|2023-05-09 07:40:54|It shines when doing eda kind of work...
Nirant|2023-05-09 08:09:45|Oooof. Socher, the OG Prompter, woke up and chose violence against academic peer review today  https://twitter.com/RichardSocher/status/1655554763562385409
~ Nikhil|2023-05-09 08:20:41|If somebody has to build a chat, summarize and index type of application today, would yo recommend: 1. Cohere 2. Steamship 3. Write the code on your own (the openapi APIs are fairly straightforward to use)
Nirant|2023-05-09 08:21:37|Langchain or Llama Index — retain the flexibility to change both the underlying models, and how you interact with them with powerful abstractions
~ Nikhil|2023-05-09 08:22:44|What is cohere and steamship's play?  Cohere has 165m in funding.
Satish DeepHack Sponsor|2023-05-09 08:26:42|OpenAI apis , + Langchain to start
Aashay Sachdeva MPL Data Scientist|2023-05-09 09:32:27|I am assuming doesn’t work for all hf models? Since they need to have an endpoint.
Dr. Ashith Generative AI WA Group|2023-05-09 09:39:52|Is there a SAM but for audio?
Anubhav mishra Zupay|2023-05-09 09:48:51|You can convert it from speech to text and try for text
Dr. Ashith Generative AI WA Group|2023-05-09 09:49:38|For music?.. Something that strip away all instrumental + vocal layers
Anubhav mishra Zupay|2023-05-09 09:50:24|Yes I think there are
Arvind N Generative AI Group|2023-05-09 09:53:17|Open assistant
Anubhav mishra Zupay|2023-05-09 09:53:29|Are you looking for a source separation?
Anubhav mishra Zupay|2023-05-09 09:56:19|You can try spleeter
Shahul Kaggle Kernel GM|2023-05-09 10:00:09|I am part of OA team (safety and ML), I can help if you're interested in opensource LLMs.
Aankit Roy Khabri YC|2023-05-09 10:28:48|‎Aankit Roy Khabri YC joined using this group's invite link
~ Ankit Sharma|2023-05-09 10:29:04|What do you suggest for tabular data which contains Questions and Answers along with user queries. I want to use the questions set and return the answer for a particular query.
Nirant|2023-05-09 10:29:46|Embed → Nearest Neighbor → Return answer  Is there reason this cannot work for you?
~ Ankit Sharma|2023-05-09 10:36:21|Currently using BERT where I trained by grouping a set of questions and the related queries and labelling them either 0 or 1 based on if the query belongs to a set of questions. Then generating the similarity score for the new queries.  This method becomes slow in cases where the search space increases.
~ Ankit Sharma|2023-05-09 10:36:57|Will try this
Shan|2023-05-09 10:41:17|I'm guessing the dataset is fairly large, hence the question. Perhaps look into https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
Nirant|2023-05-09 10:44:24|Why is NN slow for embedding? I can do about a million comparisons in less than a second on 2vCPU and more on a modern M1/M2 Pro machine
Nirant|2023-05-09 10:46:58|Women in AI, Bengaluru meetup:  https://hasgeek.com/generativeAI/women-in-ai-meetup/  Please share with your colleagues e.g. copy-paste to Slack, forward to friends WA groups :)
Shahul Kaggle Kernel GM|2023-05-09 10:50:33|You can try FAISS
Shahul Kaggle Kernel GM|2023-05-09 10:51:20|Alternatively you can do PCA or similar methods for dimensionality reduction. This can improve speed
Diptanu Choudhury FB AI|2023-05-09 10:55:56|This approach, along with feeding the results into a reader model to refine the answer might work even better.
~ Ankit Sharma|2023-05-09 10:56:38|For hindi texts
Ojasvi Yadav|2023-05-09 11:01:23|At the cost of accuracy
Lalit Pagaria|2023-05-09 11:02:01|What are the techniques or preprocessing steps to reduce prompt with context tokens while sending it OpenAI without affecting outcome?
Ojasvi Yadav|2023-05-09 11:05:41|Removing stop words is a low hanging fruit  If your context has non-English characters (they consume a ton of tokens) explore if you can use some kind of translation to English to keep the same functionality  A few weeks back GPTs compression language was doing a lot of rounds, might be worth exploring  Try a map-reduce / summarisation approach where you try to summarise your context into atomic units
Ojasvi Yadav|2023-05-09 11:06:04|I'm sure people here can give you many other techniques to try
Lalit Pagaria|2023-05-09 11:09:21|I remember someone shared about compression. Thanks for reminding me about it. My data mostly have English chars only.
Amir Nagri|2023-05-09 11:48:00|what were the results using traditional keyword/BM-25 approach? what is not working with the traditional approach to apply the semantic search result techniques?
Rohit Aggarwal|2023-05-09 11:56:42|If the use case is very defined, consider fine-tuning
Lalit Pagaria|2023-05-09 11:58:04|Not yet. It is still in the experimental phase.
~ Nischal|2023-05-09 13:10:40|‎~ Nischal joined using this group's invite link
Dhruv Anand|2023-05-09 13:36:54|how do you all handle giving OpenAI API keys to various services/products? especially since there is no usage tracking/quota per key
Nirant|2023-05-09 13:40:49|Use the product, revoke every Wednesday 😅
Pranjal Yadav Razorpay|2023-05-09 13:41:02|Write logs from each service and review them in sumologic or coralogix for attribution.
Dhruv Anand|2023-05-09 13:41:41|"but these services are not under my control. I'm talking about external products which have a ""enter OpenAI API key"" flow"
Pranjal Yadav Razorpay|2023-05-09 13:44:01|Then you need to wrap the actual call and provide the wrapper to every service. That way you can control the abuse of the key and tag incoming calls for attribution.
Nirant|2023-05-09 13:44:24|Little tedious 😅
Dhruv Anand|2023-05-09 13:45:14|that doesn't make sense. how can I give the API key of my wrapper when they are (presumably) directly calling OpenAI with the key I'm providing?
Pranjal Yadav Razorpay|2023-05-09 13:45:23|Bottom line is to agree to a central wrapper call. Managed in one place.  That can be optimized at various levels within this layer.
Pranjal Yadav Razorpay|2023-05-09 13:45:56|Stop providing the keys, that's the point of creating a wrapper so that you control the key.
Dev Aggarwal|2023-05-09 13:46:06|Basically a proxy server is what he’s saying. Should be about 20 lines of fastapi
Pranjal Yadav Razorpay|2023-05-09 13:46:40|Precisely. Didn't want to use 'proxy server' to avoid confusion.
Dev Aggarwal|2023-05-09 13:47:28|Wait but the openai endpoint url should be editable on the service/product you give the api key to
Nirant|2023-05-09 13:47:54|[PHONE] is a CMU grad and Professional ML Engineer via Meta [PHONE] is a Lead DS at Razorpay  Please create as much confusion as you both want. I trust you both are technical enough 😅
Dhruv Anand|2023-05-09 13:48:08|Talking about things like: https://thesamur.ai/mygpt https://www.chatorg.ai/  Asking because I want to create an app which could benefit from using user's API keys, but not sure if people are actually providing their keys to these services
Dev Aggarwal|2023-05-09 13:48:43|Can you share the ss of the place where you enter the api key ‎[5/9/23, 13:50:30] Dhruv Anand: ‎image omitted ‎[5/9/23, 13:50:31] Dhruv Anand: ‎image omitted
Dhruv Anand|2023-05-09 13:50:42|they seem to be storing the key in plain text, which is kinda crazy in itself
Dhruv Anand|2023-05-09 13:51:24|[PHONE] what are your thoughts about this?
Dev Aggarwal|2023-05-09 13:52:39|Yeah I dont think the proxy / wrapper will work here ‎[5/9/23, 13:54:30] Dev Aggarwal: ‎image omitted
Dhruv Anand|2023-05-09 13:57:26|thanks, I'd forgotten about this. OpenAI is so miserably bad a devx
Dhruv Anand|2023-05-09 13:57:43|they should have like monthly views etc.
Pranjal Yadav Razorpay|2023-05-09 14:20:30|My bad, I assumed you were talking about service hosted within a company and you are trying to manage all those.
Shan|2023-05-09 14:35:35|The standard MS response is to use OpenAI through Azure
~ just_a_tofu|2023-05-09 14:40:21|https://github.com/eugeneyan/open-llms
Swastik Banerjee|2023-05-09 15:42:22|Has anyone faced the following issue while using gpt-4 model?: https://github.com/openai/openai-cookbook/issues/405
Samanyou WriteSonic|2023-05-09 16:58:54|‎Samanyou WriteSonic joined using this group's invite link
Kartik Mandaville|2023-05-09 17:05:18|It rarely works at scale. Keeps failing after $100/day
Dev Aggarwal|2023-05-09 17:05:50|Try this I suppose
jyotirmayjk Hackathon|2023-05-09 17:05:55|Are you using Azure? I’ve faced this same issue using Azure APIs
Swastik Banerjee|2023-05-09 17:08:59|No, im calling the APIs directly from my local machine
Swastik Banerjee|2023-05-09 17:09:09|how did you fix it?
jyotirmayjk Hackathon|2023-05-09 17:09:41|https://github.com/openai/tiktoken/blob/main/tiktoken/model.py  Check this file for the model names being implemented
jyotirmayjk Hackathon|2023-05-09 17:10:01|This does a match with the model name while calling the APIs   If the model name doesn’t match then this error is shown
Swastik Banerjee|2023-05-09 17:10:41|I’m doing per documentation for calling gpt-4
Paras Chopra Wingify|2023-05-09 17:11:04|Power users of Langchain, do you end up using custom prompts or default ones in tools / zero shot etc?
jyotirmayjk Hackathon|2023-05-09 17:11:15|I solved it by keeping deployment id of Azure same as model name   There’s an added headache in Azure that you have to set deployment id of model
Swastik Banerjee|2023-05-09 17:11:32|interesting
Aashay Sachdeva MPL Data Scientist|2023-05-09 17:14:07|Custom. Mostly experiment with  the prompt using the chat interface in playground and then use that prompt. Ofcourse not scalable if you need to check with vector embeddings etc. In that case tune the prompt on a small dataset and benchmark on a larger set
Swastik Banerjee|2023-05-09 17:14:59|documentation suggests doing something like ```encoding = tiktoken.encoding_for_model(“gpt-4”)``` , which is exactly what Im doing, but it’s throwing ```KeyError: ‘Could not automatically map gpt-3 to a tokenizer. Please use ‘ tiktok.get_encoding’ to explicitly get the tokeniser you expect.’```
jyotirmayjk Hackathon|2023-05-09 17:15:19|From the screenshot of the bug you’ve raised it’s the model.py file which is throwing the exception   Try to match the model names in the file exactly if possible
Swastik Banerjee|2023-05-09 17:16:01|Any idea which encodinf gpt-4 uses?
jyotirmayjk Hackathon|2023-05-09 17:16:32|"gpt-4"": ""cl100k_base"","
Swastik Banerjee|2023-05-09 17:16:41|nice, thanks 👍🏼
Swastik Banerjee|2023-05-09 17:22:20|Changing it to tiktoken.get_encoding(“cl100k_base”) fixed the error
Swastik Banerjee|2023-05-09 17:23:51|It’s funny that the error message suggests “try ```tiktok.get_encoding()```” instead of ```“tiktoken.get_encoding()”```  Probably that’s how tiktoken is imported in ```application.py```
Raghav Goyal EF|2023-05-09 17:24:18|Entrepreneur First India will be in conversation with a stellar panel of early career founders at *Draper Startup House* this _*Friday, 12th May at 6:00 PM*_.  Register here (https://joinef.info/3nIOZIk) to hear our speakers debunk all the myths around early entrepreneurship. ​ _-Rahul Samat (Partner & Head of Entrepreneur First India)_ _- ​Rishabh Shekhar (Co-founder & COO, Pepper Content)_ _- ​Shourya Lala (Co-founder & CTO, Fello)_ _- ​Ananya Singhal (Co-founder & COO, Rigi)_ ​ Pepper Content, Fello & Rigi are fast-growing startups backed by the world’s best investors like Sequoia, Accel, Elevation Capital, Bessemer, Lightspeed, YC & more!
Raghav Goyal EF|2023-05-09 17:24:28|Could be relevant to some folks here!
Swastik Banerjee|2023-05-09 17:30:25|ZThis is a bug in https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb then, right?  Passing ```model=“gpt-4”``` with ```ask()``` function like they’ve shown in _More Examples_ section is throwing an error. You have to explicitly mention ```encoding = tiktoken.get_encoding(“cl100k_base”)``` instead of ```encoding = tiktoken.encoding_for_model(“gpt-4”)``` to make it work? Can someone see if they can reproduce the error?
Swastik Banerjee|2023-05-09 17:31:18|edit: *is imported in ```model.py``` (not ```application.py```)
Swastik Banerjee|2023-05-09 17:33:22|The ```encoding``` variable is being set in ```num_tokens()``` method in _Ask_ section, incase anyone is looking into the code.
Swastik Banerjee|2023-05-09 17:46:04|AH OKAY, updating ```tiktoken``` to ```version 0.4.0``` solved the issue. It was just released 2 days ago
~ Vibbs Dod|2023-05-09 18:44:24|Actually a combination - there are certain things where using things out of the box helps -purely depends on the use-case.  As mentioned my Aashay Sachdeva - when leveraging the vector embedding things might get difficult to integrate if you are using custom prompts - doable but slightly difficult. Since langchain has grown so much in such a short time it is difficult to comprehend what capabilities can be used to achieve what use-case. Reading their use-case documentation can help you understand the framework better. Hope this helps.
Saksham Generative AI WhatsApp Group|2023-05-09 19:00:18|does anyone know of a contact/ email of someone in Warpspeed GenAI hackathon organising team?
Saksham Generative AI WhatsApp Group|2023-05-09 19:02:18|or if there is any open position in any team in case someone drops out
Nafeen WriteSonic ML Engineering|2023-05-09 19:05:15|‎Nafeen WriteSonic ML Engineering joined using this group's invite link
Manjot Pahwa|2023-05-09 19:08:31|What's up
Lalit Pagaria|2023-05-09 19:09:19|Better to mask ids while sharing on public platforms unless they are dummy IDs. 😅
Dev Aggarwal|2023-05-09 19:10:09|Its a public id na, the key is emerphal anyway
Shimanta Generative AI|2023-05-09 19:11:07|Hey Manjot, I have one question regarding the Warpspeed hackathon. Have the invites for who gets to attend, been sent out already?
Lalit Pagaria|2023-05-09 19:37:45|I can't comment about OpenAI but if I had designed their rate limiter and someone use this org id or user id for their brute force attack then it would have certainly banned that account tagging it as compromised account.
~ Sabbih|2023-05-09 19:37:50|‎Soumyadeep Mukherjee added ~ Sabbih
Ruthvik Reddy|2023-05-09 19:52:34|We built an internal tool when the one mentioned in this group for tracking OpenAI bills had some bugs, while charging $10 dollars per month 🥲 and we wanted some more features. We recently made the initial version available for everyone at https://puddl.io/ . User level data is next on this tiny tool's roadmap. Check it out and let me know. 🫡
Rohit GenerativeAI WhatsApp Group|2023-05-09 19:59:07|"hey guys! anyone working on document/custom sources based chatbots?  I am trying to make the chatbot handle very generic user inputs too so that it could reply normally to queries like ""hi, hello"" and not always go to vectorstore and search for an answer since in real world users are not always going to ask a question everytime and the pipeline should be robust enough to handle such queries.  one solution that I tried already is asking chatbot for a boolean value that indicates what kind of query it is (question or not) and redirect it to a custom llm if it is not. The output of this llm should be structured to parse it properly so I tried pydantic parser to handle that. But since it only parse the output that LLM generates, it fails sometime because llm doesn't always follow the formatting guidelines.  can anyone recommend other solutions they must have tried and worked for them?  thanks"
Arvind N Generative AI Group|2023-05-09 20:01:20|The LLM can perform intent recognition and entity extraction fairly well and respond/route accordingly.
Manjot Pahwa|2023-05-09 20:02:34|A lot of them yes, but not all invites are out yet
Shimanta Generative AI|2023-05-09 20:03:48|Got it, thanks for the update. 🤞🏼in that case
jyotirmayjk Hackathon|2023-05-09 20:04:25|Have you tried this from Llama Index   The RouterQueryEngine seems handy for exact such use cases https://github.com/jerryjliu/llama_index/blob/main/docs/examples/query_engine/RouterQueryEngine.ipynb
Nirant|2023-05-09 20:04:47|Have checked this link and spoken to Ruthvik — I don't think this counts as self promotion and hence leaving it here. Sharing the decision here before someone forwards this to me 😅
Lalit Pagaria|2023-05-09 20:05:17|One cheap way to write a script similar to this https://community.openai.com/t/how-to-track-individual-usage/15935/6 , deploy in some hourly cron push data to Airtable/DB/Excel and create graphs (excel graphs would be easy)
Paras Chopra Wingify|2023-05-09 20:06:14|Tried RasaGPT?
~ prthamesh|2023-05-09 20:08:23|I run a small service, pushing events from that API key to Simple Analytics. All successful, failed events go there with the key in metadata 😅
Rohit GenerativeAI WhatsApp Group|2023-05-09 20:12:12|checking this. currently trying guardrails
Shahul Kaggle Kernel GM|2023-05-09 20:20:32|I have also came across similar problem, one solution is to build a simple classifier and reroute prompts based on it's output.
Shahul Kaggle Kernel GM|2023-05-09 20:22:22|In my case I had a specific list of queries that I wanted bot to not answer using context, I kept them in a separate vector db and comparing incoming prompts with that list can also act as a classifier.
Rohit GenerativeAI WhatsApp Group|2023-05-09 20:23:26|"not sure if a classifier will work for eg. if someone asks ""What's the weather today?""  this is still a question, but not related to the context. User can attack the chatbot if not built efficiently so I guess some level of language understand is important here"
Shahul Kaggle Kernel GM|2023-05-09 20:25:37|Yeh, solution for this depends very much of the distribution of prompts you're getting.
Pratyush Choudhury|2023-05-09 20:29:46|https://jam.dev/  Very cool product
Nirant|2023-05-09 20:32:55|cc [PHONE] [PHONE] I'm sure you've seen this since you're building in the adjacent space. Thought this might be interesting to you
Rohit GenerativeAI WhatsApp Group|2023-05-09 20:36:26|who ever is building this should check this: https://twitter.com/pbteja1998/status/1654130363567071233
Kartik Mandaville|2023-05-09 21:07:58|anyone tried GPT4All and Atlas? Just met the founder and they're doing something very interesting. Runs on CPUs / open source / visualization on top of embeddings  https://gpt4all.io/index.html https://atlas.nomic.ai/
Shan|2023-05-09 21:18:18|Wonder if openai will tolerate the use of GPT4 In their name. Likely no.
~ prthamesh|2023-05-09 21:25:50|Thread about StarCoder, seems like there’s a correlation between coding and reasoning capability in a language model?   https://twitter.com/loubnabenallal1/status/1655932400541769728?s=46&t=iGppsOleuAsMXDWuVmzUPQ
Sumod K Mohan|2023-05-09 22:29:06|One thing that worked well for me was to play with temp and p to get the system to output on consistent output  format. Takes away some richness (with low temp) but if you give enough stakes points (think of using CoT, or other reasoning with intermediate steps etc) you can get enough richness.
Sumod K Mohan|2023-05-09 22:29:51|But again, depends on application. The above was more for a reasoning sort of application.
~ Vik|2023-05-09 22:34:43|i built this library to help work with llms it has lots of examples, supports multiple llms openai, cohere, etc. has sensible defaults for parameters etc and zero dependencies. designed to be easy and quick to use https://github.com/dosco/minds
Soumendra Dhanee|2023-05-09 22:35:25|Instead of using the bert model directly to output 0 or 1, use it as a vectoriser to extract embeddings, and then follow what Nirant suggested. Inference won't be slower as the search space increases, and this will likely perform better if you have trained your bert well
Raghotham Paypal Bargava's Friend|2023-05-09 22:35:41|We use Mrkl agent with custom built tools. Works well for now. It is WIP
Aashay Sachdeva MPL Data Scientist|2023-05-09 22:36:19|Was reading this - https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1
Ravi Theja|2023-05-09 23:11:24|https://twitter.com/MetaAI/status/1655989274620358656?s=20 - ImageBlind from MetaAI - model capable of binding data from six modalities at once. ‎[5/10/23, 01:06:49] Nirant: ‎image omitted
Rahul Bhatnagar|2023-05-10 01:10:21|Does a great job recognizing Chunky Pandey too. :)
Nirant|2023-05-10 01:15:05|Has great conceptual memory: Works for smiling woman with red hair, dog - finds a celeb with golden retriever hair 😆
Dr. Pratik Desai KissanGPT|2023-05-10 01:16:32|Literally every photo and video app or platform we know can be disrupted as you can literally talk to your library if implemented well
Rahul Bhatnagar|2023-05-10 01:17:46|Was going to index my iCloud library. Will share results on how it went.
Nirant|2023-05-10 01:18:09|Hmm. Yes. You can build your own Google Photos now. With power booster search --- better than anything Google can offer today
Dev Aggarwal|2023-05-10 01:18:15|https://imagebind.metademolab.com/demo  This demo is freaking insane.
Dev Aggarwal|2023-05-10 01:18:34|google photos does face recognition
Nirant|2023-05-10 01:19:27|So do these embeddings in a way, NN to a person is dead easy to find. It finds Jet Li by name -- that's face recognition already :)
Dev Aggarwal|2023-05-10 01:20:14|How??
Nirant|2023-05-10 01:21:08|Check the Google Colab notebook I shared, that demos this
Dev Aggarwal|2023-05-10 01:22:09|google photos does one-shot face recognition from custom labels
Dev Aggarwal|2023-05-10 01:23:16|E.g. this notebook won't find Nirant :3
Yash Pandya|2023-05-10 01:23:28|If it has some concept of celeb faces, then the embeddings would have atleast some one-shot recognition capabilities
Nirant|2023-05-10 01:23:49|If it has one photo of me, easy to do a nearest neighbor on that and expand from there
Shubham Sharma 2012C6|2023-05-10 01:48:00|Can replace the whole foley part of film making if executed on a huge dataset ‎[5/10/23, 01:57:50] Dev Aggarwal: ‎image omitted
Siddharth Agarwal|2023-05-10 01:59:39|This looks more the result of shallow feature matching.
Dev Aggarwal|2023-05-10 02:01:34|https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing
Gokul Krishnan|2023-05-10 02:02:44|Jawahar sir's former Student is the first author
Shalabh Aspiro|2023-05-10 02:03:00|Is that an ad in the bottom? Even that ad has Nirant 😵‍💫
Aseem Gupta 2011|2023-05-10 02:03:56|Anyone worked on OCR? Need some quick pointers
Yash Pandya|2023-05-10 02:04:09|try face recognition + aligned cropping (use keypoints to align faces)
Yash Pandya|2023-05-10 02:05:32|It is also very likely that the performance would vary a lot for different race, gender, age, etc.  FWIW this model was anyway not designed specifically for face identification/matching
Anirudth N|2023-05-10 02:06:59|I've been wanting a tool which can recommend soundtrack for shorts/reels. Looks like this might almost be there.
Dev Aggarwal|2023-05-10 02:11:46|yeah that ad probably needs a crop :D
Dev Aggarwal|2023-05-10 02:12:32|you mean detection + alignment? https://github.com/1adrianb/face-alignment
Yash Pandya|2023-05-10 02:13:00|Yeah
Dev Aggarwal|2023-05-10 02:16:36|I had a similar project with [PHONE] way back to play soundtracks based on mood. this could do it from facial expressions / heartbeat sounds / tone of my voice etc. 😵
Yash Pandya|2023-05-10 02:17:20|5 landmark points are usually enough though, you can check - https://github.com/ZhaoJ9014/face.evoLVe
Kshitij Agrawal ML Engineer|2023-05-10 02:21:22|First and last both IIITH folks :)
Kshitij Agrawal ML Engineer|2023-05-10 02:21:34|Yes ‎[5/10/23, 02:56:01] Dev Aggarwal: ‎image omitted
Aseem Gupta 2011|2023-05-10 03:30:56|thanks, pinging you in DM
Dhruv Anand|2023-05-10 03:50:42|But this is a great way to find doppelgangers
Sumod K Mohan|2023-05-10 04:56:40|https://openai.com/research/language-models-can-explain-neurons-in-language-models
Ravi Theja|2023-05-10 06:40:26|https://twitter.com/assemblyai/status/1656005887343960079?s=46 - LeMUR - AssemblyAI- LLM’s on audio files - now you can perform QA on your audio files directly.
Amir Nagri|2023-05-10 07:41:48|As i understand, it will transcript the audio files into text, chunk and index it in vector db, then allow QnA on those transcripts, right?  It's similar to QnA on large documents or is there anything different?
~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿|2023-05-10 07:58:58|What’s the dataset of images? One of them is my friend.
~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿|2023-05-10 07:59:25|I don’t think he’s in this group ‎[5/10/23, 08:02:50] Ravi Theja: ‎image omitted
Dhruv Anand|2023-05-10 08:49:43|Ugh I thought it was something new on modelling side
Amir Nagri|2023-05-10 08:55:45|Same, clever marketing, repackage and give it an acronym 😂
Hasan Tech Art Guy|2023-05-10 09:19:52|This is retrieving the audio from a database?
Nirant|2023-05-10 09:21:55|The database has 3 files in the demo, but yes, that is the intent.
Nirant|2023-05-10 09:36:02|Would perhaps be better to ask an outline of your questions?   E.g. I am curious about fine-tuned OCR for handwriting for Math or Musical Notations
Nirant|2023-05-10 10:46:58|Hello!   Shubhi Saxena [PHONE] (Coval.ai, Yellow.ai) has lined up an impressive speaker line up for the Women in AI meetup.  She's looking for a volunteer emcee for the event — can be anyone in tech e.g. folks from Product, Engineering, Marketing, everyone is welcome!  If you'd like to volunteer, or want to recommend a friend, please ping her!
Arvind N Generative AI Group|2023-05-10 10:47:14|All, Need some help.... For the past few days I have been trying to replicate the performance of a multimodal LLM using a much smaller LLM purely by crafting a high quality dataset. With Vicuna7B the results are pretty amazing but I would like to get similar quality from OPT2.7B which is still a very powerful LLM but tends to hallucinate way more. My gut feel is that I should try stacking a bunch of LoRA adapters, each trained on a small high quality dataset to achieve this goal. Has anyone had success with such stacking. Does this FUSE method work? (https://docs.adapterhub.ml/adapter_composition.html#fuse) If anyone wants to collaborate, please ping me - I have a few A100s to spare.
Sudharshan GenAI|2023-05-10 10:51:40|https://twitter.com/generatorman_ai/status/1655941986627772419
Shashank Generative AI Group|2023-05-10 10:58:53|https://twitter.com/OpenMMLab/status/1656127026687000578?t=bwtsiMeA6SNW2hWGHIo8Ww&s=19
Nirant|2023-05-10 11:00:54|doston, link dump na karo, ek line likh do what that link is about 😅
Sudharshan GenAI|2023-05-10 11:03:16|Lots of claims in this post - what do you guys think?
Nirant|2023-05-10 11:11:14|"65B model, calling a prompt a ""constitution"", worse performance than Vicuna — marketing team at IBM should be rewarded for doing such technical work"
Pratyush Choudhury|2023-05-10 11:13:02|More underwhelming than Watson actually 😅
Aashay Sachdeva MPL Data Scientist|2023-05-10 11:16:38|But what about the practicality of the approach? Seems promising, much better than distilling, which increases hallucinations
jyotirmayjk Hackathon|2023-05-10 11:18:31|https://twitter.com/_akhaliq/status/1656144222204903426?s=46&t=icC0fizZK8E3ONsDVuGFWA   Can someone help me understand this ?  This paper sclaims that their proposed Generative Retrieval is better than embedding and ANN based approach  But the way they have proposed is to generate “Semantic IDs” of items based on text description  How is it different than embedding the description and mapping it to 1 item ?
jyotirmayjk Hackathon|2023-05-10 11:19:23|For ex.as per the paper’s method  Semantic ID for “An orange leather shoe “ will be sequence of tokens representing orange,leather and shoe
Dev Aggarwal|2023-05-10 11:32:11|This is  similar to jerry liu’s new blogpost? [PHONE]
jyotirmayjk Hackathon|2023-05-10 11:36:09|Is that one using LLM for retrieval ?
jyotirmayjk Hackathon|2023-05-10 11:36:56|From what I’ve understood of Jerry’s post That was more like passing entire doc/doc summary to choose documents using LLM  This paper seems to propose a different approach
Nirant|2023-05-10 11:37:21|Reminds me of triplet generation from the bygones era.   Zooming out:  1. Dataset/Domain: This paper tests an approach on a single eCommerce use case heavy dataset. Such domains are usually quite noun and descriptors heavy (large sofa, blue Anarkali dress, and so on) — this does not translate well to most other domains.
Nirant|2023-05-10 11:37:34|Type karne do bhai log 🤣 ‎[5/10/23, 11:40:14] Nirant: ‎image omitted ‎[5/10/23, 11:42:39] Nirant: ‎image omitted
Nirant|2023-05-10 11:44:20|Analogy:  They've mapped every SKU to a code in the same way devs map errors: We know that 4xx is different from 5xx and 429 or 404 means.  If I tell a model that a service is seeing a lot of 429 errors, what error will you expect a few minutes or hours later? Perhaps a 404 or 5xx based on what we know from how services scale?
Nirant|2023-05-10 11:45:09|That's a terribly written on-the-fly blog on a paper which I read 20 minutes ago for the first time, but can answer more questions on DM 😅
jyotirmayjk Hackathon|2023-05-10 11:47:32|Still a good overall explanation 🙌🏻🙌🏻 thanks [PHONE]
Shaista Hussain|2023-05-10 12:30:46|‎Shaista Hussain joined using this group's invite link ‎[5/10/23, 12:40:23] Arvind N Generative AI Group: ‎image omitted
Nirant|2023-05-10 12:41:29|Yes, in fact that Y-axes is likely to be logarithmic, not linear
Shashank Generative AI Group|2023-05-10 13:04:29|"emergent capabilities in ImageBind:  ""Our model has new emergent capabilities, or scaling behavior — that is, abilities that didn’t exist in smaller models but appear in larger versions. This might include recognizing which audio fits with a certain image or predicting the depth of a scene from a photo....  We discovered that ImageBind features can be used for few-shot audio and depth classification tasks and can outperform prior methods tailored for those modalities. For example, ImageBind significantly outperforms Meta’s self-supervised AudioMAE model trained on Audioset and a supervised AudioMAE model fine-tuned on audio classification, with gains of approximately 40 percent accuracy in top-1 accuracy on ≤four-shot classification.  ImageBind also achieved new SOTA performance on emergent zero-shot recognition tasks across modalities, even outperforming recent models that were trained to recognize concepts for that modality.""  https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/"
~ Neeti Pokharna|2023-05-10 13:29:29|‎~ Neeti Pokharna joined using this group's invite link
Nirant|2023-05-10 13:41:28|"If someone wants to try ImageBind: colab.research.google.com/drive/1_erdut6xnikv5f1qnbutoik4us-w3pxm?authuser=0#scrollto=zjl-nv30rngb  Can also scroll up and see [PHONE] proving that ImageBind doesn't know ""Nirant's face"" well. Excellent hacker demos!"
Nirant|2023-05-10 13:46:47|PSA for Technical Folks: Fifthelephant — India's best ML Conference has the Call for Talks open:  https://hasgeek.com/fifthelephant/2023/sub  If you're someone who has done great work but don't know how to slot it or submit a proposal, please DM me — happy to assist in fleshing out the idea
Dev Aggarwal|2023-05-10 13:54:56|https://colab.research.google.com/drive/1wFFG4TbuXUPPppymqxdgKg8XShMfoGJZ?usp=sharing  The proof
Soumyadeep Mukherjee|2023-05-10 14:50:55|🚀Announcing the May Generative AI Meetup with more focus on Visuals - Images, Videos, Games  🎮🎨📽️  Structure being 2 talks opening up more time for discussions as compared to 3 last time. Secure Your Spot Now - https://hasgeek.com/generativeAI/may-meetup/ Seats are limited as always.  1 talk is already finalised and 1 slot for a technical deep dive like the one on Quantisation is still open. DM me for interest, sharing ideas  or volunteering to speak.
~ Arka|2023-05-10 15:06:58|Potential game changer   https://arxiv.org/abs/2305.01625?utm_source=tldrai
Lalit Pagaria|2023-05-10 15:28:57|Just an FYI it is CC BY-NC not truly open source.  In case one plans to use it commercially. I hope soon we will get a pure open-source version.
Karishnu Poddar Yellow.ai|2023-05-10 15:57:27|Dude the third photo is of a friends 😅
Sidhant Sequoia|2023-05-10 16:46:34|2nd photo looks freakishly like my IITD electronics prof. 🙈 Really hoping it’s not him
Nirant|2023-05-10 17:19:43|Glad to learn that even my face isn't unique friends
~ Hitesh Sagtani|2023-05-10 17:17:45|‎~ Hitesh Sagtani joined using this group's invite link
~ .|2023-05-10 17:27:14|‎~ . joined using this group's invite link
~ Kaustav K Bose|2023-05-10 17:38:40|Fun use of diffusion - https://youtu.be/KrjL_TSOFrI
Karman Sethi Conquest|2023-05-10 18:41:11|‎Karman Sethi Conquest joined using this group's invite link
Sidhant Sequoia|2023-05-10 19:04:43|https://www.zdziarski.com/blog/?p=12001  Interesting and well written, if cynical, take on FMs by a famous iOS security expert. 🙂
Rounak Datta Hackathon Winner|2023-05-10 20:03:15|What he wrote makes quite a lot of sense, and OpenAI's yesterday's research on understanding _which neurons_ is probably an answer in that direction
Raghav Goyal EF|2023-05-10 20:33:26|Which are some of the good Robotics, AI/ML newsletters I can follow?
~ Akshat Khare|2023-05-10 21:01:21|This message was answered just couple of days back. I'll copy paste: These are the one's ive found quite useful: - [https://www.bensbites.co/](https://www.bensbites.co/) - [https://www.semafor.com/newsletters] - [https://www.lennysnewsletter.com] - [https://whatshot.substack.com/p/whats-in-enterprise-itvc-335?utm_source=substack&utm_medium=email] - [https://therundown.ai/subscribe](https://t.co/Gm5KwesnA7) - [https://tldr.tech/ai?utm_source=tldr](https://tldr.tech/ai?utm_source=tldr)
Raghav Goyal EF|2023-05-10 21:02:03|Thankyou!
Swastik Banerjee|2023-05-10 21:30:04|I have generated embedding vectors using np.array, and the file size is roughly 230mb (saved as a csv). Im deploying an app on azure which uses this; any idea best place to store the embeddings? I’ve tried gdrive, azure blob storage and even gh-lfs(this changes the encodings of the file which openai api cant read it seems, so ive ruled this out), but everything is considerably slow
Dev Aggarwal|2023-05-10 21:30:52|npy files?
Swastik Banerjee|2023-05-10 21:38:10|saved as csv
Dev Aggarwal|2023-05-10 21:41:35|yes, npy files are much faster
Dev Aggarwal|2023-05-10 21:41:46|https://runwayml.com/hosted-models/  TIL runwayml  has a serverless gpu offering?!
Soumendra Dhanee|2023-05-10 21:44:36|https://mmappickle.readthedocs.io/en/latest/
Soumendra Dhanee|2023-05-10 21:45:29|Nothing is going to be faster than mmap. I think pickle supports storing objects as mmaps too.
Soumendra Dhanee|2023-05-10 21:45:54|This is likely just what you need
Soumendra Dhanee|2023-05-10 21:47:15|And you're storing the object itself. Very very unlikely to lose any accuracy.
Soumendra Dhanee|2023-05-10 21:48:24|If mmap doesn't work for you, then just use pickle (slower, but faster than anything else).
Dev Aggarwal|2023-05-10 21:49:12|This is lovely
Soumendra Dhanee|2023-05-10 21:50:13|But you could still lose accuracy/encounter changed embeddings even if you pickle an object. Ensure you recreate your environment exactly with venv or poetry.
Dev Aggarwal|2023-05-10 21:50:23|Do you have to use locks to handle concurrent writes though btw?
Rounak Datta Hackathon Winner|2023-05-10 21:51:07|Pickling is lossy? TIL
Shashank Generative AI Group|2023-05-10 21:52:16|yeah i think it's been there for a long time. i remember seeing something like this back when Runway had a few GAN models only (for generating shoes, cars etc )
Soumendra Dhanee|2023-05-10 21:52:52|Yes, depends on versions in your env. You can get by for a while, usually, but there are no guarantees in the long run.
Rounak Datta Hackathon Winner|2023-05-10 21:53:41|Okay. I used to think its comprehensive Ser/Deser
Soumendra Dhanee|2023-05-10 21:54:04|Depends on how you plan to write. If you're code guarantees it, you don't need locks, otherwise you do.
Soumendra Dhanee|2023-05-10 21:55:19|Far from it. Pickling itself might break with version changes, forget about guaranteeing losslessness ‎[5/10/23, 21:57:19] Dev Aggarwal: ‎image omitted
Soumendra Dhanee|2023-05-10 22:00:01|That's correct if you're only storing native python objects. He's interested in storing numpy arrays. Which may still be fine. As I said, you can get by for a while, but no guarantees in the long run.
Soumendra Dhanee|2023-05-10 22:00:21|The ling-run doing the heavy lifting 😂
Soumendra Dhanee|2023-05-10 22:00:32|*long-run
Swastik Banerjee|2023-05-10 22:23:35|Thanks, ill look into this
~ prakashpvss|2023-05-10 22:27:04|Hi All, I'm looking to generate images for words that can illustrate meaning of the word . To be used by school children. Tried by various prompts to illustrate using stable diffusion. Example : illustrate the word 'abhor'.  Provided different ways of conveying the meaning in sentences. Failed to create good illustrations for words in a scalable manner. Looking for help in the same. Also if there is anyone working in similar space to get inputs. Thanks.
Aakash Kumar  Matrix Partners|2023-05-10 22:34:17|https://www.assemblyai.com/blog/lemur-early-access/
Nirant|2023-05-10 22:35:27|We've already roasted this enough today. Please resist the temptation - note for myself
Aashay Sachdeva MPL Data Scientist|2023-05-10 22:35:30|You are a day late 🤣
Aakash Kumar  Matrix Partners|2023-05-10 22:36:22|🙈🙈 missed today’s chatter
Dev Aggarwal|2023-05-10 22:42:46|ugh, in that case why not just us numpy native mmap that guarantees backwards compat?  https://numpy.org/devdocs/reference/generated/numpy.lib.format.open_memmap.html
Dev Aggarwal|2023-05-10 22:44:44|I say this because I have a huge openai bill, 300$ of which is just embeddings, because I had to recompute them a bunch of times due to backwards incompat
Nirant|2023-05-10 22:48:02|On a related note, [PHONE] has built out an OpenAI embeddings API cost calculator: https://llmtown.com/e/openai-cost-calculator. Thought this might be interesting to folks here
Soumendra Dhanee|2023-05-10 22:54:13|Not sure where it mentions backward compatibility. It probably does it now. For small usecases it is perfectly fine.
Soumendra Dhanee|2023-05-10 22:54:57|I don't like that flush() operation though. I have to call it every single time I update something in the array! ‎[5/10/23, 22:55:01] Dev Aggarwal: ‎image omitted
Soumendra Dhanee|2023-05-10 22:55:16|Primary reason why I don't use npy
Soumendra Dhanee|2023-05-10 22:55:35|Awesome 👍🏻
Soumendra Dhanee|2023-05-10 22:56:10|As I said, this is perfectly fine for small usecases.
Soumendra Dhanee|2023-05-10 23:00:14|What were you using to store the embeddings?
Dev Aggarwal|2023-05-10 23:01:59|pickle, but my backwards compat issue was more of a data format upgrade not a file format upgrade
Soumendra Dhanee|2023-05-10 23:03:32|Ah ok, so you were storing them in a class you created or provided by a package or something?
Soumendra Dhanee|2023-05-10 23:05:04|As in, curious about why the embeddings were not recoverable from the pickle.
Dev Aggarwal|2023-05-10 23:08:20|changed the preprocessing a bunch of times, chunking strategies, X -> text conversion, added cleaning steps to transcripts, changed transcription engines, etc.
Soumendra Dhanee|2023-05-10 23:16:01|Oh acha, there's no fighting against this. Went with Weaviate modules from the start to avoid this cost.
Dev Aggarwal|2023-05-10 23:17:29|text2vec-bert?
Rounak Datta Hackathon Winner|2023-05-10 23:20:21|With the I/O event, I think Bard is now almost generally available. I applied through the waitlist and got access within minutes.
Bharat Kumar Ramesh Hashmal Web3|2023-05-10 23:21:29|They haven't released it for workspace yet
Bharat Kumar Ramesh Hashmal Web3|2023-05-10 23:21:31|Which is surprising
Sumod K Mohan|2023-05-10 23:21:35|Can you point me to where you saw that it is using lossy. This is news to me.
Bharat Kumar Ramesh Hashmal Web3|2023-05-10 23:21:38|I would have thought it would begin there
Soumendra Dhanee|2023-05-10 23:35:00|Models from sbert.io (sentencebert, they come with Weaviate modules by default)
Soumendra Dhanee|2023-05-10 23:36:39|This happened with version upgrade mismatches of tf 1.x (pre tf2 era).
Soumendra Dhanee|2023-05-10 23:38:36|We started with saving embeddings in a db, which was obviously bad. Then pickling sometimes led to this. Eventually we put some tests in place. I think GPU arch mismatch also had a role to play, but I may be misremembering that. We just matched everything and put tests in place.
Nirant|2023-05-10 23:54:18|Microsoft Researcher used GPT4 to solve a simple maze game. Quite clever hints for you to think about how to evoke world building with text based models.   cc [PHONE] might be interesting to you? https://ekzhu.medium.com/gpt-4s-maze-navigation-a-deep-dive-into-react-agent-and-llm-s-thoughts-b1823fb266ee
Rahul Bhatnagar|2023-05-11 00:18:59|Fun fact. I‘ve tried to run similar experiments with chess. And had some mind = blown moments initially.
Rahul Bhatnagar|2023-05-11 00:22:25|But it turned out that as games went on it started suggesting random/illegal moves.
Rahul Bhatnagar|2023-05-11 00:22:51|And all the aha moments came from games that were probably in its training data. ‎[5/11/23, 00:23:30] Rahul Bhatnagar: ‎image omitted
Rahul Bhatnagar|2023-05-11 00:25:51|Really wanted to try giving it access to a chess engine so it could evaluate moves, before making them. That’ll be the equivalent of giving it access to the code interpreter like the Microsoft researcher talks about in this blog.
Rahul Bhatnagar|2023-05-11 00:26:29|It’s on my weekend side projects list for now. Sigh… so much to do. Such little time…
Shashank Generative AI Group|2023-05-11 00:33:35|Render.com added pgvector to their PostgreSQL databases.   https://twitter.com/marckohlbrugge/status/1656294501483413504?t=ZeWpPLYJ4bDE19sfYXZmZg&s=19
Anshul Khandelwal Invideo|2023-05-11 00:59:15|https://twitter.com/scottbelsky/status/1656365796761694218?t=c9Gvl0xFQKA3Vn4nPnEtbA&s=08
Antidentite Paritosh Bola.ai|2023-05-11 09:24:25|‎Antidentite Paritosh Bola.ai joined using this group's invite link
Kartik Mandaville|2023-05-11 09:42:51|its sneaky / I got an email asking for a commitment of $2500/month for 6 months to be part of it. LOL
Nirant|2023-05-11 09:45:23|Ohh damn. That's _not startups_, that's just a VC funded Series B co
Kartik Mandaville|2023-05-11 09:46:39|yeah / I get that they are good but this is very bad / if you had this commitment then be upfront before you ask companies to fill a long form to apply
Ankur Pandey|2023-05-11 09:47:33|If you pay upfront annual
Ankur Pandey|2023-05-11 09:48:15|Ah others already pointed that
Pratik Bhavasar|2023-05-11 09:50:47|It’s unclear what does small and big mean. I think the disparity is small. I haven’t found any research on scaling laws of fine-tuning but know from experiments that for a narrow task the gap between small and big is not much. Palm 2 small beats Palm 540B. So it’s not a pure function of size.   From Palm 2 paper it seems chasing just language modelling loss is not correct  “However, the training loss is not a perfect proxy for downstream metrics. For example, the 8.95B model, which shows the lowest loss (Table 1) and is closest to the optimal model, slightly underperforms the 14.7B model on downstream tasks. This suggests that while scaling laws can be used to achieve optimal training loss for a given quantity of FLOPs, this does not necessarily transfer to achieving optimal performance for a given task.”
Shahul Kaggle Kernel GM|2023-05-11 09:52:59|one point to consider is task accuracy is evaluated using discontinuous non-linear metrics like exact match
Shahul Kaggle Kernel GM|2023-05-11 09:53:46|About PaLM2, I'm impressed by the reasoning ability of it as it has shown better performance with reasoning tasks than GPT-4 ‎[5/11/23, 09:53:57] Arvind N Generative AI Group: ‎image omitted
Shahul Kaggle Kernel GM|2023-05-11 09:55:50|this is total waste. 😂
Pratyush Choudhury|2023-05-11 09:56:39|Couple of months? 😳  Wow
~ Nikhil|2023-05-11 09:57:59|Does anybody have access to ChatGPT plugins API?  I applied for it sometime ago. Any hacks?
Nirant|2023-05-11 09:58:20|What do you mean by Plugins API?
Sthit Generative AI WhatsApp Group|2023-05-11 09:58:35|Not related to what's being discussed, but is there a comprehensive list of benchmarks used to gauge llm performance anywhere ? Ideally clustered based on type of tasks such as  reasoning, quantitative and qualitative, benchmarks used to measure intelligence parameters, etc ‎[5/11/23, 09:59:04] ~ Nikhil: ‎image omitted
Nirant|2023-05-11 10:00:25|OpenAI Evals, LM-Harness for HF models, and the extremely entertaining, useful and wrong ELO rating approach
Sthit Generative AI WhatsApp Group|2023-05-11 10:01:33|This is precisely what I wanted  to acquaint myself with well known benchmarks atleast. ELO doesnt seem to be a good measure of llm performance
Sthit Generative AI WhatsApp Group|2023-05-11 10:01:35|Thanks ‎[5/11/23, 10:01:36] jyotirmayjk Hackathon: ‎image omitted ‎[5/11/23, 10:01:38] jyotirmayjk Hackathon: ‎image omitted ‎[5/11/23, 10:01:44] jyotirmayjk Hackathon: ‎image omitted
Sthit Generative AI WhatsApp Group|2023-05-11 10:02:02|This looks good thank you
jyotirmayjk Hackathon|2023-05-11 10:02:51|https://arxiv.org/pdf/2303.17564.pdf  Source:BloombergGPT team released quite few details on training their model ,it’s quite interesting to read
Shahul Kaggle Kernel GM|2023-05-11 10:25:54|Checkout Big bench
Nirant|2023-05-11 10:27:48|Big Bench is a dataset curated by Google to make Google models look good, OpenAI Evals makes GPT4 looks good, only LM-Harness is real — it makes everyone look great! 🤣  https://paperswithcode.com/dataset/big-bench
Aashay Sachdeva MPL Data Scientist|2023-05-11 10:29:29|Only benchmarking that truly matters is community benchmarking
Nirant|2023-05-11 10:35:38|Controversial Take: Benchmarks don't matter when your product is great. Benchmarks are for plebs.   So imma go and work on my Vector Database benchmark 😅
Aashay Sachdeva MPL Data Scientist|2023-05-11 10:45:10|I think the fundamental difference is openai is doing all it can to break gpt-4, while google trying to show they are as good at chatgpt so use us
Rohit Aggarwal|2023-05-11 10:53:39|what is the source for this? What is the Elo based on?
Rohit Aggarwal|2023-05-11 10:54:46|Curious - why don't Elo ratings work? Because this is not a true head-to-head comparison?
Arvind N Generative AI Group|2023-05-11 10:55:03|https://lmsys.org/blog/2023-05-10-leaderboard/?s=09
Nirant|2023-05-11 12:09:59|Sequoia APAC is doing a curated *virtual* demo day called Bird of Feather on Generative AI next week. Has 15 curated demos from the wider web, not just their folio.   cc Shashwat [PHONE] since you had asked about a demo day  If you've questions, Vedant [PHONE] from Sequoia is here and please ping directly  If you're interested in attending: https://share.hsforms.com/1Oj8R_ze3QDeUnGAEGv5v6A406r9
Shashwat TDC|2023-05-11 12:14:40|superb thanks for the callout. Missed this ealrier
Aashay Sachdeva MPL Data Scientist|2023-05-11 12:20:07|https://arxiv.org/pdf/2305.05576.pdf  Paper by AI4bharat on why India needs its own stack and how these technologies can have a broad societal impact in india
Rahul Bhatnagar|2023-05-11 12:20:17|+1. Love what [PHONE] is building.
Swastik Banerjee|2023-05-11 12:20:51|What are some of the most useful resources for exploring AutoGPT and creating agents?
Lavish 2017|2023-05-11 12:26:06|anyone knows here which model powers Sage bot on Poe?  the bot works pretty well compared to chat GPT 3.5 even on code tasks
Nirant|2023-05-11 12:26:11|https://python.langchain.com/en/latest/use_cases/autonomous_agents/autogpt.html  https://github.com/Significant-Gravitas/Auto-GPT
Nirant|2023-05-11 12:26:21|Claude+ from Anthropic?
Lavish 2017|2023-05-11 12:28:20|don't think so since Poe has a seperate bot for Claude+ and that's paid  poe.com/sage is free poe.com/claude%2b is paid ‎[5/11/23, 12:29:58] Rohit Aggarwal: ‎image omitted
Lavish 2017|2023-05-11 12:30:01|"oh they have added ""powered by 3.5"" now. wasn't there earlier."
Lavish 2017|2023-05-11 12:30:30|why two bots for same model tho? poe.com/chatgpt is also by 3.5 turbo
Lavish 2017|2023-05-11 12:31:18|but good to know it's the same model 😅  I was feeling fomo if I missed any ground breaking model announcement
Abhinav Verma Longshot.ai|2023-05-11 12:33:11|‎You added Abhinav Verma Longshot.ai
Swastik Banerjee|2023-05-11 12:33:43|thank you
Shashwat TDC|2023-05-11 12:38:39|this to me feels like a NFT-like scam, only if they ICO'd with these kind of models lol. Creating own LLM powered by gpt-3.5
Rohit Aggarwal|2023-05-11 12:39:13|I’d assume different first “system” message if you’re seeing diff responses from both bots
Shashwat TDC|2023-05-11 12:42:10|it cud also be different model config. tempertaure,  etc.
Nirant|2023-05-11 13:03:46|A masterclass on how to PichAI  h/t [PHONE] [PHONE] https://www.linkedin.com/posts/yangpeter_its-really-hard-to-raise-money-right-now-ugcPost-7062259610383974400-IAgT/
Shahul Kaggle Kernel GM|2023-05-11 13:10:11|If you’re interested in reading paper checkout ReAct paper
~ Harshjit Sethi|2023-05-11 13:10:31|‎~ Harshjit Sethi joined using this group's invite link
Swastik Banerjee|2023-05-11 13:12:26|Im trying to make an agent with a finetuned model
Swastik Banerjee|2023-05-11 13:13:08|Actually 2-3 agents with separate finetuned models and I want to see them interact 😛
Swastik Banerjee|2023-05-11 13:13:19|just as a fun sideproject…will share if I succeed
Dev Aggarwal|2023-05-11 13:14:00|How do you tell which one us better at what task though is the key! 😆
Swastik Banerjee|2023-05-11 13:15:44|By separate finetuned models I mean not separate llms…for now im just trying to finetune gpt with separate additional informations about a particular subject
Shalabh Aspiro|2023-05-11 13:19:36|i.e. separate context and instructions using prompt engineering?
Swastik Banerjee|2023-05-11 13:22:48|not prompt engineering. Already trained models (im not training them) for example, say make BloombergGPT debate with YahooFinanceGPT whether its good to invest in a particular stock at this time or not
~ Shaaban Karim|2023-05-11 14:38:21|‎~ Shaaban Karim joined using this group's invite link
Ashfakh GenerativeAI WA Group|2023-05-11 14:53:52|Has anyone here worked extensively with LlamaIndex. Was going through it's docs, have some questions regarding it's base architecture.
Nirant|2023-05-11 14:57:05|cc [PHONE] is a Llama index contributor.   A general great practice is to ask the question(s) directly because:  1. Folks other than who we know already can chip in e.g. [PHONE] has used Llama Index extensively as well from a business+dev lens  2. People benefit from the answer greatly even if they've a passing interest in the topic
Krishna Ntkris|2023-05-11 15:06:46|Has anyone encountered this error from OpenAI when embedding? AFAIK it’s not a rate limit   The server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at http://help.openai.com if the error persists.' error_param=None error_type=server_error message='OpenAI API error received
Swastik Banerjee|2023-05-11 15:09:32|I think this is a common “too many requests, try again later” error when their servers are flooding. I’ve encountered this multiple times but resolves with retry after some time
Swastik Banerjee|2023-05-11 15:11:31|[PHONE] can you help me with this, i.e., your approach? [PHONE] said you’ve worked on something similar
Sidhant Sequoia|2023-05-11 15:16:23|I meant this ^
~ Ankit Sharma|2023-05-11 16:42:00|Anyone tried the Bhashini APIs?
Dev Aggarwal|2023-05-11 16:42:31|Asr Models yes, not APIs
Ravi Theja|2023-05-11 16:44:43|how are the results with asr models? can be used in prod?
Dev Aggarwal|2023-05-11 16:45:05|Using in prod. Best models for indic languages
Dev Aggarwal|2023-05-11 16:45:48|Not very good for long files, they use nemo, and doing chunked asr on it is not trivial
Dev Aggarwal|2023-05-11 16:46:00|Timestamps also are an issue
~ Ankit Sharma|2023-05-11 16:46:08|Do they support streaming??
Dev Aggarwal|2023-05-11 16:46:09|But the asr quality is good
Dev Aggarwal|2023-05-11 16:46:41|https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/intro.html
Dev Aggarwal|2023-05-11 16:46:53|This is what they use
Dev Aggarwal|2023-05-11 16:47:29|Seems to support streaming
~ Ankit Sharma|2023-05-11 16:59:00|https://github.com/opennyai/jugalbandi-api
Sidhant Sequoia|2023-05-11 17:36:42|https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi  There’s a visual mathematician Grant Sanderson with a YT channel named 3Blue1Brown who makes some fascinating videos on the intuition behind mathematical concepts.  There’s this ^ set of four on neural nets which forms a visual intuition of gradient descent, inference and backpropagation. Might be useful for anyone not very mathematically inclined but keen to have an intuitive sense of how simple NNs work.
Dev Khare Lightspeed|2023-05-11 17:42:46|‎Dev Khare Lightspeed joined using your invite
Shantanu Goel TraderDesk|2023-05-11 19:57:30|‎Shantanu Goel TraderDesk joined using this group's invite link ‎[5/11/23, 21:40:32] Bulia Siddharth Aurashop: ‎image omitted
~ Vishwam Jindal|2023-05-11 22:01:29|https://www-moneycontrol-com.cdn.ampproject.org/c/s/www.moneycontrol.com/news/business/startup/foreign-firms-like-google-have-to-invest-in-indian-ai-start-ups-for-access-to-countrys-data-sets-rajeev-chandrasekhar-10569191.html/amp
~ Rohan|2023-05-11 22:03:21|Seems like a smart idea. Thinking in the right direction, at least.
Ravi Theja|2023-05-11 22:11:31|https://twitter.com/AnthropicAI/status/1656700154190389248?s=20 -  Claude’s 100k tokens context window
Shivendu Kumar|2023-05-11 22:37:25|What exactly? [PHONE] can you please share a link?
Shashwat TDC|2023-05-11 22:40:21|Hey sure. We are building in co-pilot for Analyst space. Given business context in.csv file you can use it for text 2 SQL translation. Sharing the link in DM. ‎[5/11/23, 22:41:01] Shashwat TDC: ‎video omitted
~ Mayank Gupta|2023-05-11 22:42:39|[PHONE] - Something you experimented with as well right!
Shashwat TDC|2023-05-11 22:43:32|We are in closed beta. Feel free to DM for early access.
Suhas Motwani|2023-05-11 22:44:02|Would love to check it out
Shashwat TDC|2023-05-11 22:48:05|Yes. Quite a few player in this space. About 4-5 just last month in Bangalore. Overall 50+ in this space. Not seen true PMF yet.   Also, success of MSFT copilot system's now Google Bard AI in spreadsheet & Collab plays a key role in success of such 3P platforms.
~ Divya|2023-05-11 23:30:57|‎~ Divya joined using this group's invite link
~ Shyam|2023-05-12 02:09:06|Will the increase in context window size also increase latency of LLM's in any way?
Dev Aggarwal|2023-05-12 02:09:50|"“We fed Claude-Instant The Great Gatsby (72K tokens), except we modified one line to say that Mr. Carraway was ""a software engineer that works on machine learning tooling at Anthropic."" We asked the model to spot what was added - it responded with the right answer in 22 seconds.”"
~ Shyam|2023-05-12 02:16:21|The first 2 inputs were the 72K tokens and third input was the query right? In that case why the latency?
Dr. Pratik Desai KissanGPT|2023-05-12 02:17:37|This size of the attention window sounds like an amazing technical leap but not going to be practical with the current hardware. For that attention, the per 1k token prize is going to be crazy once out of beta and burning VC money. ‎[5/12/23, 02:23:23] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-12 02:23:32|https://www.mosaicml.com/blog/mpt-7b
Dev Aggarwal|2023-05-12 02:23:53|Doesn’t seem so - for the smaller models maybe it is feasible ‎[5/12/23, 02:24:41] Dr. Pratik Desai KissanGPT: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-05-12 02:26:00|It took 22second and the entire infra to generate something that is probably less than 50 tokens from 72K token
Dr. Pratik Desai KissanGPT|2023-05-12 02:27:00|May be I'm wrong, and may have to read some more documents.
Dev Aggarwal|2023-05-12 02:27:29|Whats the time complexity w.r.t. # of params?  Trillion parameters on 8k tokens vs billion params on 65k tokens?
Dr. Pratik Desai KissanGPT|2023-05-12 02:28:52|Good question. I don't know how significantly parameters will affect or which model they are using for this demo. ‎[5/12/23, 02:29:17] Dev Aggarwal: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-05-12 02:35:04|I'm going to let someone else figure it out and post a detailed analysis on Twitter. They are not saying the size of the model that will be used for 100k API. If they use 1T model for 100K, it is probably going to be very expensive to accommodate practical use cases. 🤷‍♂️ but then my temporal snapshot of knowledge is changing every day.
Dev Aggarwal|2023-05-12 02:54:43|https://bard.google.com  This is so fast 😵 and does 3 parallel generations at once too!
Gokul Krishnan|2023-05-12 04:15:21|They're probably showing top 3 probable beams as a part of their beam search decoding. Afaict, all LLMs do perform this decoding but other providers just give the top most beam
Nirant|2023-05-12 05:58:26|User shares preview from Anthropic's 100K tokens context window https://twitter.com/harishkgarg/status/1656718619651477505
Ravi Theja|2023-05-12 07:30:13|https://twitter.com/lijunnan0409/status/1656821806593101827?s=46 - InstructBLIP - sales force - vision language instruction tuning framework
Ravi Theja|2023-05-12 08:04:09|https://twitter.com/harishkgarg/status/1656724079183798273?s=20 - 100k tokens seem to cost ~$1, for 100k tokens with GPT4 it would cost ~$0.5. Multiple hits on a doc from users are still costly with 100k tokens with a compromise on latency probably 🤔
Paras Chopra Wingify|2023-05-12 09:19:43|Meta comment: - You sleep - You wake up  There are 2-3 new advances in this space to catch up on :)
Harsh Koo|2023-05-12 09:26:29|Need a news ticker for AI advances as a -1 screen replacement.
Shashwat TDC|2023-05-12 09:27:03|future tools will be helpful. https://www.futuretools.io/news ‎[5/12/23, 09:28:09] Arvind N Generative AI Group: ‎image omitted ‎[5/12/23, 09:28:10] Arvind N Generative AI Group: ‎image omitted ‎[5/12/23, 09:28:11] Arvind N Generative AI Group: ‎image omitted ‎[5/12/23, 09:30:23] Arvind N Generative AI Group: ‎image omitted
Bulia Siddharth Aurashop|2023-05-12 09:32:14|This is excellent!!  Did you build this model yourself? Or are you using any other open source model?
Bulia Siddharth Aurashop|2023-05-12 09:32:32|Can I try this out?
Arvind N Generative AI Group|2023-05-12 09:32:40|This is running on Vicuna13B. Even 7B is giving out awesome results
Vaibhav Bhargava Meesho Grab |2023-05-12 09:32:51|Pretty cool
Harsh Koo|2023-05-12 09:32:57|Looks very interesting. Details available?
Arvind N Generative AI Group|2023-05-12 09:32:58|I will send you the link Siddharth - ping me please
Anshul Khandelwal Invideo|2023-05-12 09:42:14|What is the attack here?  Can you give us a brief summary?  That looks impressive! ‎[5/12/23, 09:44:04] Bulia Siddharth Aurashop: ‎image omitted ‎[5/12/23, 09:44:05] Bulia Siddharth Aurashop: ‎image omitted
Arvind N Generative AI Group|2023-05-12 09:45:18|Ok. here is the high level view of how it works.  A vision transformer (frozen model) converts the image to a fixed sized embedding. An LLM (vicuna in this case) uses that information, and the user question/context to generate text.
Anshul Khandelwal Invideo|2023-05-12 09:45:42|Anyone try instruct-blip yet?
Arvind N Generative AI Group|2023-05-12 09:45:58|This IS instruct blip
Anshul Khandelwal Invideo|2023-05-12 09:46:13|Oh
Bulia Siddharth Aurashop|2023-05-12 09:46:42|That’s all we need for multi-modal gpt, right? This is all solved now 😅
Arvind N Generative AI Group|2023-05-12 09:47:37|The open source projects which will help you all get up to speed are BLIP2, MiniGPT4 and Instruct-BLIP (which came out yesterday)
Arvind N Generative AI Group|2023-05-12 09:48:34|Here is the challenge - this works quite well at 7B params. But with OPT2.7B it hallucinates a lot. Some of us have been trying to make that better over the past 4 days....it's slowly getting there
Sainath GenerativeAI WhatsApp Group|2023-05-12 10:16:34|Is this on mid journey
Shan|2023-05-12 10:25:14|popups and cookie requests are annoying. Numerous extensions have been built to tackle it and there's reader mode too, but none of them is perfect. If an AI extension which runs on the machine can tackle this, it's a $B idea. Essentially, it needs to - take a screenshot whenever there's a substantial change in the page, detect what needs to be clicked, click on it. If it runs on the machine, it can even go ahead do some slightly more advanced stuff like automatically login on sites which have logged you out, etc as well
Lalit Pagaria|2023-05-12 10:30:21|Don't already many tools exist to automate this? Also, taking a screenshot is a bit heavier approach than reading HTML data on a client machine? Like to understand what can't be automated except a captcha, which requires such AI-powered automation?
Paras Chopra Wingify|2023-05-12 10:31:26|Is there any model to perform QA on video?
Nirant|2023-05-12 10:31:56|Can make one with Instruct BLIP + Vicuna now
Nirant|2023-05-12 10:32:12|I think we can wait till Monday for someone else to do it 🥲
Dr. Pratik Desai KissanGPT|2023-05-12 10:33:29|I like this approach these days.
Arvind N Generative AI Group|2023-05-12 10:33:50|I have it for video. ‎[5/12/23, 10:34:12] Arvind N Generative AI Group: ‎video omitted ‎[5/12/23, 10:34:26] Arvind N Generative AI Group: ‎image omitted
Harsh Koo|2023-05-12 10:37:15|Any links to Instruct BLIP?
Ravi Theja|2023-05-12 10:38:57|https://github.com/salesforce/LAVIS/tree/main/projects/instructblip ‎[5/12/23, 10:39:32] Arvind N Generative AI Group: ‎image omitted ‎[5/12/23, 10:48:25] Arvind N Generative AI Group: ‎image omitted
Paras Chopra Wingify|2023-05-12 10:49:25|What approach? Is there an intro / write up to it?
Paras Chopra Wingify|2023-05-12 10:49:36|How do you find salient frames?
Arvind N Generative AI Group|2023-05-12 10:51:25|Good question. Increasing information density is the first step. short answer: cosine distances. Long answer: a lot of back and forth between LLMs and the ViT
Dr. Pratik Desai KissanGPT|2023-05-12 10:52:09|I was talking about Nirant’s approach of waiting for someone on Twitter to do it and post 😁
Shashank Generative AI Group|2023-05-12 10:57:06|someone took their tweets from last 1 year and dumped them into Anthropic 100k 😂.   got a summary in 38 seconds.  https://twitter.com/altryne/status/1656798898487463940?t=bPP8X-QmhxbnCC7vTeDVMA&s=19
~ Himani|2023-05-12 10:57:20|‎~ Himani joined using this group's invite link
Swastik Banerjee|2023-05-12 11:08:03|Damn! Can this be a step forward to do live commentary  for blind people with some obvious latency?
Arvind N Generative AI Group|2023-05-12 11:09:34|Yeah, I don't see why. With the speeds we achieve now (in known envs) this could happen sooner than people realize
Bulia Siddharth Aurashop|2023-05-12 11:41:10|Exactly!!
Swastik Banerjee|2023-05-12 11:48:09|I started a project back in march with the high hopes of this 😅 Had talked to [PHONE] about the lofty aims. This looks very cool! I’d be very interested to lend a hand of help if I fit anywhere
Arvind N Generative AI Group|2023-05-12 11:49:37|We are trying to get the vicuna7B performance out of OPT2.7B.  If you can help fine-tune, I'm happy to offer a few A100s.
Shashank Generative AI Group|2023-05-12 12:05:04|Google's PaLM 2 model training data is up to Feb 2023!  https://twitter.com/minimaxir/status/1656791154581700608?t=Fn9SFITeLhsLkkfzsQk8tw&s=19
~ Aarshay Jain|2023-05-12 12:14:09|‎~ Aarshay Jain joined using this group's invite link
~ VC|2023-05-12 12:27:51|‎~ VC joined using this group's invite link
Swastik Banerjee|2023-05-12 12:32:07|I’ll dm for more details ‎[5/12/23, 12:50:14] ~ Omkar: ‎image omitted
Arvind N Generative AI Group|2023-05-12 12:52:50|No
Arvind N Generative AI Group|2023-05-12 12:58:04|Wait, minigpt4 can be used. It's BSD3
Alok Bishoyi|2023-05-12 12:59:34|what's the best open source LM that I can use for finetuning purpose - specifically for tasks that involve code generation / interpretation ? Any leads would be helpful
Swastik Banerjee|2023-05-12 13:11:28|LLaMa I think
Swastik Banerjee|2023-05-12 13:12:00|I’ve already heard a couple of people/teams doing so
~ Pranav|2023-05-12 13:36:12|There's this company called bemyeyes which used to do this with volunteers- where someone who was visually impaired would open up the app camera and wait for someone on other end to describe it to them- now replaced with GPT- 4
~ Pranav|2023-05-12 13:36:13|https://twitter.com/BeMyEyes/status/1635690254689599488?t=qEPFpSZg2Rn8_PJu9CU0Vw&s=19
~ Pranav|2023-05-12 13:36:33|Insanely impactful stuff
jyotirmayjk Hackathon|2023-05-12 13:38:22|Related to previous discussion on vector DBs  Check this by vector DB service MS Azure  https://techcommunity.microsoft.com/t5/azure-data-explorer-blog/azure-data-explorer-for-vector-similarity-search/ba-p/3819626
~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿|2023-05-12 13:40:34|‎~ 𝗦𝘄𝗮𝗺𝘆 𝗩𝗶𝘀𝗵𝘄𝗮𝗻𝗮𝘁𝗵𝗮𝗻 𝗔𝘆𝘆𝗲𝗿 left
Swastik Banerjee|2023-05-12 13:42:50|right, but the volunteer thing reminded me of a funny incident. Someone once asked me, “so tell me, do you actually sit at the back and solve those tough integration problems and quickly return then when someone asks wolfram alpha?” 😂
Swastik Banerjee|2023-05-12 13:44:16|gpt integration with bemyeyes is v cool but they had a few limitations and challenges, mostly trained on west-accented tts/stt and not opensource
~ Omkar|2023-05-12 13:51:52|Yeah I saw the license file, but can we commercially use a model which is built on top of another non commercial model.
~ Omkar|2023-05-12 13:56:25|The Vicuna, MiniGPT4 shows license Apache 2.0 or BSD3. Which makes one belive that we can use this commercially. However LLaMa weights are not available commercially, making Vicuna model only usable for research purpose and not commercially.
~ Omkar|2023-05-12 13:58:37|p.s. Vicuna is fine-tunned LLaMa.
~ Ziyan Zafar|2023-05-12 14:41:35|‎~ Ziyan Zafar joined from the community
Nirant|2023-05-12 14:45:37|Code? StarCoder
Pratyush Choudhury|2023-05-12 14:48:36|Salesforce's codegen endpoint is also good alongside StarCoder
Paras Chopra Wingify|2023-05-12 15:00:08|folks, question: how do you iterate your prompts?  i'm exploring an automatic way to do this.  original prompts -> generate 5 variations -> have second LLM rate responses to all 6 prompt -> iterate  (optionally also add user feedback in addition to second LLM)  Any thoughts? ideas?
Rohit Aggarwal|2023-05-12 15:03:45|Try evaluations.. create a test data set  Then run models through the different evals. Did a lot of reading on this and is probably a great way to automate this
Paras Chopra Wingify|2023-05-12 15:10:04|can you elaborate?
Krishna Ntkris|2023-05-12 15:12:13|Iterate on them a lot. I've used this approach. Give GPT4 the outcome I want and then ask it to tell me what would be the most useful inputs. It's a good starting point
Vaibhav Bhargava Meesho Grab |2023-05-12 15:12:25|One layman approach that works for me a number of times :  For prompts that are intended to generate output during user interaction : I tend to form a hypothesis around the parts of my prompt that are responsible for unsatisfactory output. And ask the LLM itself why it did not create my desired output (with example) : often hear feedback on what I could do better in my prompt. GPT-4 is quite good at that.  I believe there are better technical methods, keen to know especially for images.
Nirant|2023-05-12 15:13:26|Rohit can't plug since he wrote this, but I can: portkey.ai/blog/decoding-openai-evals/
Paras Chopra Wingify|2023-05-12 15:17:25|read this too https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids
Nirant|2023-05-12 15:18:50|Source preprint which the blog discusses: https://arxiv.org/abs/2212.08073
~ Pradyumna Bang|2023-05-12 15:20:04|How to get Chatgpt to just output the code that I've asked it for instead of any other extra text. I've tried mentioning this multiple times but it ignores those instructions.
Nirant|2023-05-12 15:21:17|https://github.com/irgolic/AutoPR
~ Pradyumna Bang|2023-05-12 15:24:53|Thanks, I'll check it out!
~ Meera Sundar|2023-05-12 16:46:31|‎~ Meera Sundar joined using this group's invite link
Rohit Aggarwal|2023-05-12 16:50:08|Folks - what are sources where I can find standard evaluation datasets?  I was checking the Stanform/Helm github repo - I can dig into code and find each of the tar files, but is there a better way?
Nirant|2023-05-12 16:50:35|huggingface.co/docs/datasets
Rohit Aggarwal|2023-05-12 16:53:02|yea, was browsing this.. any way to filter LLM specific evaluation datasets?
Nirant|2023-05-12 16:54:27|https://huggingface.co/datasets?task_categories=task_categories:text2text-generation&sort=downloads
Rohit Aggarwal|2023-05-12 16:58:15|thanks so much man!
Pratik Bhavasar|2023-05-12 17:51:29|Can you explain what happens in iterate?
Pratik Bhavasar|2023-05-12 17:52:01|This might be useful  https://arxiv.org/abs/2302.12822 ‎[5/12/23, 18:42:42] Jay Pokarna 2014 BPCC: ‎image omitted
Paras Chopra Wingify|2023-05-12 18:47:02|thanks
Rohit Aggarwal|2023-05-12 18:47:44|reading material  https://aclanthology.org/2020.emnlp-main.346.pdf https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know https://arxiv.org/pdf/2101.00190.pdf
Aashay Sachdeva MPL Data Scientist|2023-05-12 18:48:53|Do we have extremely small llms that can work in js in the browser? A link would be nice.
Paras Chopra Wingify|2023-05-12 18:52:11|https://simonwillison.net/2023/Apr/16/web-llm/
Aashay Sachdeva MPL Data Scientist|2023-05-12 18:52:44|Yes this! Thanks ‎[5/12/23, 20:02:55] Ojasvi Yadav: ‎image omitted
~ Karan Gandhi|2023-05-12 20:03:55|Nirant shared this earlier  https://www.chatpdf.com/
Chirag Gandhi Trifecta Capital|2023-05-12 20:10:54|This also struggles to answer meta questions like summarising. Answers precise questions well, in my experience.
~ Miraj Shah|2023-05-12 20:22:17|‎~ Miraj Shah joined using this group's invite link ‎[5/12/23, 20:22:22] Rahul Bhatnagar: ‎image omitted
Rahul Bhatnagar|2023-05-12 20:23:08|This is a good blog
Rahul Bhatnagar|2023-05-12 20:23:10|https://medium.com/geekculture/prompt-engineering-with-llamaindex-and-openai-gpt-3-f52114aba8b7
Rahul Bhatnagar|2023-05-12 20:24:16|On a side note, just notized that the first author, Manzil, was a senior from college and his room was right next to mine.
Soumendra Dhanee|2023-05-12 20:59:45|So you're the first-adjacent author of this paper? 😀
Shubham Sharma 2012C6|2023-05-12 21:00:00|https://twitter.com/AiBreakfast/status/1656881667116613636 Could anyone tell me how computationally intensive is this technology?
jyotirmayjk Hackathon|2023-05-12 21:09:34|Or can we say he’s the literal ‘Approximate Nearest Neighbour’ 😁😁
Shashank Mehta Not 22|2023-05-12 22:04:18|‎Shashank Mehta Not 22 joined using this group's invite link
Shashwat TDC|2023-05-12 22:15:33|‎POLL: Assuming early adopters of this group wud be using some kind of wrapper LLM tool by now, how satisfied are you with these (text2x) tools in general? Have you been able to use any in production env. ‎OPTION: 1 (3 votes) ‎OPTION: 2 (0 votes) ‎OPTION: 3 (3 votes) ‎OPTION: 4 (0 votes) ‎OPTION: 5 (very satisfied) (0 votes)
Shashwat TDC|2023-05-12 22:18:08|Discovered chatpdf.com early.   Was early user but couldn't really extract value from a medical insurance pdf.
Bulia Siddharth Aurashop|2023-05-12 22:19:53|Have been a avid user of chatgpt directly
Bulia Siddharth Aurashop|2023-05-12 22:20:22|Will call it 5/5. Especially gpt4.
Raghotham Paypal Bargava's Friend|2023-05-12 22:34:45|I have heard good things about the new feature they have.   https://twitter.com/gpt_index/status/1655590126074863616
Lalit Pagaria|2023-05-13 00:29:54|Someone created an architectural overview of Langchain. It is useful to understand it's concepts. https://app.heptabase.com/w/12484a51f631edbddd6415dafbad56d8ae119058ece8bcb3e8d9a5a3ba80a45b?id=7d359c3d-b443-4547-a852-d384457cd23b
~ Hitesh Sagtani|2023-05-13 00:35:40|‎~ Hitesh Sagtani left
Shashank Generative AI Group|2023-05-13 04:05:03|Full Stack DL released their LLM Bootcamp lectures for free  https://twitter.com/full_stack_dl/status/1656683085524795393?t=Y0SGVw9taqbppYgNsmkDLQ&s=19
Dev Aggarwal|2023-05-13 04:11:13|https://lmql.ai/  Such a cool project - define variables inside your prompt, and it will automatically use prediction masks to enforce logical constraints
Paras Chopra Wingify|2023-05-13 09:13:59|Does it work with open ai models?  Those don’t offer logits, right?
Rohit Aggarwal|2023-05-13 10:07:08|Nice! Does this have similar concepts as jsonformer?
Lalit Pagaria|2023-05-13 10:08:31|Something similar to minddb  https://docs.mindsdb.com/custom-model/openai
Lalit Pagaria|2023-05-13 10:09:08|Mean query engine
~ Sreenath Nair|2023-05-13 10:36:42|‎~ Sreenath Nair joined using this group's invite link
Pranjal Yadav Razorpay|2023-05-13 12:10:04|For LLM training, what is the impact of choosing different hardware architectures across training and inference?  For instance, P2/P3 instance for training and P3/G3 for deployment? I'm aware that recent architectures provide functional advantage for efficiency, read somewhere that FastAttention(FA) uses it.  But is FA irrelevant for a P2, and if not, can I trade time for less cost and train and then benefit during inference?
Nirant|2023-05-13 12:11:00|cc [PHONE] was on the original TPU firmware team, would love to hear from him on training-inference trade offs for hardware
Chirag Jain|2023-05-13 12:32:57|Might be too technical for this group, but purely from a nvidia hardware point of view   H100 > A100 (P4D) > V100 (P3) K80 (P2) at this point is very old You can also train on T4 (G4DN) and A10 (G5), however these in chips have lower number of tensor cores as well as lower TDP - they can't go as fast but that also makes them less power hungry. You can exploit K80, P100s for cheap inference now - seemingly no one wants them.  Volta onwards - V100, T4, A10, A100, H100 - have special tensor cores that are specially made for fast matrix multiplications, allow mixed precision training, etc  Going beyond single gpu on a single machine - prefer V100, A100, H100 that are connected via high bandwidth NVLink and infiniband connections so you don't get bottlenecked by data, gradients and weights transfers  Going beyond a single machine, now you are entering the DGX/HGX super pods territory where multiple pods (1 pod = 8 gpu chips) are interconnected via high bandwidth NVSwitches and NVLink  https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/#The_Most_Important_GPU_Specs_for_Deep_Learning_Processing_Speed  https://www.nextplatform.com/2022/03/23/nvidia-will-be-a-prime-contractor-for-big-ai-supercomputers/
Shantanu Goel TraderDesk|2023-05-13 13:03:20|You can surely do this and in most cases save cost. But a lot depends on your input workloads, model architecture, pipeline etc. How much of it is/can be parallelized and how much is the actual utilization. This will also have a much more pronounced effect if you use inference focused accelerators which will provide a much bigger bang for the buck per watt compared to off the shelf GPU hardware
Pranjal Yadav Razorpay|2023-05-13 13:04:13|Thanks for the detailed response Chirag. The first paragraph is a great chronological summary. I'm aware of what you mentioned in the 2,3,4 paragraphs. My question is primarily around the cost/time trade-offs while choosing a specific hardware during training, and the switching to something else during inference.  For example, if I train on A100s and get my model and then I want to host on K80 or P100, I am bound to loose the Fast Attention properties because that architecture doesn't support that optimisation. Can I do the opposite? Train on cheap K80 or P100 and then host on V100 to get all matrix multiplication efficiency boost? ‎[5/13/23, 13:05:54] Dev Aggarwal: ‎image omitted
Shantanu Goel TraderDesk|2023-05-13 13:07:50|Ah I read your query the other way round. TBH this needs you to do some work either in the terms of architecturally mapping your model's architecture and compute/memory needs to the cores/sram/vram utilization besides the architectural needs to consider not just the performance but even feasibility of being able to do this. OR just try it out and see what the results you get.
Pranjal Yadav Razorpay|2023-05-13 13:09:35|Let's say for any QnA or text summarisation task for a domain specific model (assume Llama-30B fine-tuned works well), and less than 2K tokens a query, if I can train using a P2/P3 8xlarge and then switch to a V100 during inference, does it affect my performance?   I am not able to comprehend of the same attention matrix can behave differently. I an guessing the optimisation comes not purely due to more cores and better I/O but advanced data representation at compile time. The metadata to make that happen could be non-tranferable across architectures. All of this is in my head, I may be absolutely wrong.
Chirag Jain|2023-05-13 13:10:34|cheap would be subjective I guess considering A100 can go 10s of orders faster than K80 at some point training for lesser time on expensive A100 would be cheaper than training for longer on cheaper K80  that being said I am reading flash attention this week, so might be able to answer after that 😅
Pranjal Yadav Razorpay|2023-05-13 13:12:20|Agreed. Training cost is one of the factor. More important is performance during inference.
Shantanu Goel TraderDesk|2023-05-13 13:17:20|It may or may not impact you. I am not that conversant with off the shelf GPU HW and hence the need to test this. For inference accelerators, like Qualcomm's NPU or Google's TPUs, you get compilers/sdk that translates your trained model to best utilize the hardware during inference. LLMs are very tricky though, even run of the mill LSTMs for that matter, and we used to continuously run into lot more nuances there.
Nirant|2023-05-13 13:24:39|danke friends, learnt more about Inference optim and GPUs in this convo than 4 hours of Googling and reading blogs 🙏
Nirant|2023-05-13 13:28:09|ChatGPT Plugins will be rolled out to _all_ ChatGPT Plus ($20/mo) users in the coming week https://twitter.com/sama/status/1657143368198279168
Gokul Krishnan|2023-05-13 14:11:58|What's stopping you from running a small experiment with off the shelf model with these GPUs to find throughout / $ on a single GPU?   When going to multi GPU on same machine / multiple machine setup, the metric gets more complicated to compute and assumptions depend on your usecase
Pratyush Choudhury|2023-05-13 14:13:00|How much of it can be attributed to Bard?  Bard is surprisingly good for some use-cases but hallucinates still
Pranjal Yadav Razorpay|2023-05-13 14:13:46|Nothing, I plan to do that. Was looking for suggestions.
Gokul Krishnan|2023-05-13 14:14:03|Weights maybe the same but set of operations  performed / opset might be different for different card generations.
Nirant|2023-05-13 14:31:17|Haven't found a use case where Bard is better than GPT4 yet
Dev Aggarwal|2023-05-13 14:32:31|https://youtu.be/u_dSUtp4eM8  Palm2 is better in some tasks
Dev Aggarwal|2023-05-13 14:33:55|Clearly in multilingual capability but also in some other tasks in english too
Pratyush Choudhury|2023-05-13 14:36:25|"Surfing the web and embedded ""Google it""  Ask it to summarize yesterday's news or for a weather update for the coming week ‎[5/13/23, 14:40:17] Dev Aggarwal: ‎image omitted ‎[5/13/23, 14:40:41] Dev Aggarwal: ‎image omitted"
Dev Aggarwal|2023-05-13 14:42:09|Plus its blazing fast compared to the web browsing plugin probably because its google and they have internal indexes and tpus ‎[5/13/23, 14:44:29] Dev Aggarwal: ‎image omitted
Pratyush Choudhury|2023-05-13 14:44:44|Plug-in mila nahi hai so far :(   But yeah, it's a very good way to search the web + summarize news
Pratyush Choudhury|2023-05-13 14:44:48|Like a follow-up prompt could be summarize what social media is saying about this and the results are pretty accurate
~ Ketan Gangal|2023-05-13 14:44:51|‎~ Ketan Gangal joined from the community
Pratyush Choudhury|2023-05-13 14:44:53|And there's always the Google It button below for us to click
Dev Aggarwal|2023-05-13 14:45:11|But this is so wrong? Am i getting something wrong? ‎[5/13/23, 14:46:01] Pratyush Choudhury: ‎image omitted
Dev Aggarwal|2023-05-13 14:47:49|The crazy part is that in the exit polls it shows correctly, guess this is where the chat rlhf stuff is lacking
Lalit Pagaria|2023-05-13 14:55:18|"With my limited usage.  I found Bard faster than GPT4. One reason could be Bard publishes full completion output but GPT4 uses SSE/https.  Bard hallucinates more than GPT4. For example ""Compare supabase and appwrite"" prompt Bard mentions that appwrite supports PostgreSQL which is not true."
Nirant|2023-05-13 15:28:54|Bard is worse at code than my intern, GPT4 is better
Lalit Pagaria|2023-05-13 15:59:01|"""During exams, always attempt to answer the questions even though you don't know the real answer, but never leave any questions"" - AI learned from students"
Shruthi Badri|2023-05-13 16:31:40|‎You added Shruthi Badri
Dev Aggarwal|2023-05-13 18:19:28|TIL - openai pays indian contractors software engineer rates to train its models for code and maths
Dev Aggarwal|2023-05-13 18:19:57|Human evaluators write code for the model to train on, even do stuff like time and space complexity analysis
Bulia Siddharth Aurashop|2023-05-13 18:26:19|My friend used to work with them
Nirant|2023-05-13 18:29:09|Regarding Software Engineer rates: Which Software Engineer? TCS, Swiggy, Atlassian or Quant funds?
Shimanta Generative AI|2023-05-13 18:33:28|I saw a blog post recently which said they paid $15/hr to contractors. Going by that number, it comes to ~25lpa for 40hrs worked per week.
Dev Aggarwal|2023-05-13 18:35:58|35lpa
Dev Aggarwal|2023-05-13 18:36:35|They have many more projects, more deeper than just ranking, happy to take questions also. 😂
Siddharth Agarwal|2023-05-13 18:36:34|Goddamn!
Dhruv Naik|2023-05-13 18:36:57|I thought openai does data labelling through Surge AI?
Dev Aggarwal|2023-05-13 18:37:37|This is a moonlight btw ‎[5/13/23, 21:11:00] Ravi Theja: ‎image omitted
Shivendu Kumar|2023-05-13 21:15:40|So basically Indians are leading in AI in every possible way :p
Nirant|2023-05-13 21:16:34|AI stands for Anonymous Indians
Aashay Sachdeva MPL Data Scientist|2023-05-13 21:18:57|Is it wfh though?
Nirant|2023-05-13 21:23:38|I expect all the prize money is in this photo?
Ojasvi Yadav|2023-05-13 21:26:46|We're doing an edtech project
Ojasvi Yadav|2023-05-13 21:27:02|The name?  parh.ai
Shimanta Generative AI|2023-05-13 21:28:18|The name deserves an award in itself 😁
Lavish 2017|2023-05-13 21:31:25|"hey good people, had one simple question:  in running chats with a bot, upon receiving a new message from the user, currently I try to find the exact question [using the LLM itself] that user is asking before doing similarity search. I do this because sometimes users type ""with Sam"" after ""can you give me a brief summary of meeting""  new message -> fetch chat history + new message -> prompt the LLM to put exact question that user is asking -> similarity search -> LLM -> output  wanted to know if there are more creative solves for this"
Ravi Theja|2023-05-13 21:46:33|Do you want to do similarity search based on new message from user?
Ashfakh GenerativeAI WA Group|2023-05-13 21:49:07|Why not do the similarity search directly? What’s the LLM outputting on the first call? ‎[5/13/23, 22:51:51] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-13 22:52:27|Have LLMs analyze this
Nirant|2023-05-13 22:53:48|What questions are interesting you? Can throw the csv to code interpreter and ask questions
Abhinav Verma Longshot.ai|2023-05-13 22:54:26|Are these the only columns
Abhinav Verma Longshot.ai|2023-05-13 22:55:03|What's the churned senders Column mean actually?
Nirant|2023-05-13 22:55:36|People who have replied or sent a message here earlier but then stopped, presumably because they've muted or archived this group.
Abhinav Verma Longshot.ai|2023-05-13 22:55:55|Ok.
Abhinav Verma Longshot.ai|2023-05-13 22:57:38|Got it. At the moment, not a lot of questions to ask.
Puneet Lamba Aspiro|2023-05-13 22:59:35|LOL what were the themes for last few questions/statements from churned senders & group responses thereof, and are there any patterns there.
Abhinav Verma Longshot.ai|2023-05-13 23:03:51|But if all the Colmns are the ones being shown. It's not really much that can be asked
Lavish 2017|2023-05-13 23:04:08|"yes. like if this was a chat happening  AI: how can I help? User: what's the stock price for AI: sorry, can you share for what? User: tsla  now in my knowledge base, I can't do similiarity search for just ""tsla"" and will need a question like ""stock price of tsla"" before hitting the DB"
Abhinav Verma Longshot.ai|2023-05-13 23:04:48|Prompt engineering here
Lalit Pagaria|2023-05-13 23:04:52|Most active time period? Most discussed topics/theme?  A few fun queries: Avg time to get a reply, Active replies etc
Nirant|2023-05-13 23:06:52|Thought this might be interesting to you: HyDE — https://arxiv.org/abs/2212.10496  Has some implementations
Nirant|2023-05-13 23:07:35|Please contrib functions/code here  https://github.com/nirantk/nirantk.github.io/tree/main/community_dev  🙏
Lavish 2017|2023-05-13 23:09:07|"can you explain more? prompt what on which step?  also corner case of it might not always be just 4 last chats that mentions the context of the question user is asking and instead might be something mentioned in last 10 chats  what I'm doing right now is to summarise chat history and then pass new message of user and prompt LLM to generate a ""question with full context"""
Lavish 2017|2023-05-13 23:09:19|checking, thanks for sharing 🙏🏻
Nirant|2023-05-13 23:10:26|"""question with full context"" → give it a name as well and a conference workshop paper idea right there 😅"
Abhinav Verma Longshot.ai|2023-05-13 23:11:20|Arrey yaar. I'd done this for work a month back. Should publish this 😂
Abhinav Verma Longshot.ai|2023-05-13 23:11:49|I'll message you on this
Nirant|2023-05-13 23:12:47|You can ask GPT4 to write the paper as well, just give all the titles, method outline and results 😂
Abhinav Verma Longshot.ai|2023-05-13 23:13:52|Haan. Although long form mai Claude is very good. I'm liking it a little more. But gpt4 is very powerful
Abhinav Verma Longshot.ai|2023-05-13 23:17:47|for picking relevant messages - Langchain has a few memory management techniques like storing summary of previous chats beyond a certain context - embeddings to filter out relevant messages from old chat (not sure if there in langchain but I've used this)  Prompt to basically tell the AI to only focus on conversations and then tell it to generate a response if its not in the context  You might want to tweak your params here. temperature etc to avoid further hallucinations
Aashay Sachdeva MPL Data Scientist|2023-05-13 23:38:41|How are you exporting files? Automated or doing it manually everyday?
Nirant|2023-05-13 23:40:26|Yes, manual
~ Ankit Sharma|2023-05-14 00:14:34|Never Split the Difference: Negotiating As If Your Life Depended On It by Chris Voss.  GPT-4 was trained on this book and can implement Chris Voss’ negotiating strategies quite effectively.
Vaibhav Bhargava Meesho Grab |2023-05-14 00:34:52|I know someone whose favorite prompt is : Based on Robert Greene’s advice in xyz book, how should I deal with following situation.   Getting specific and not generic gyaan is a good use case .
Abhinav Verma Longshot.ai|2023-05-14 00:36:31|can also do something like, take a chapter of the book you like to base your answer on, feed it to claude 100k and ask it to asnwer in the tone of that chapter
Dev Aggarwal|2023-05-14 01:03:12|Dealing with the same problems. There is a query decomposition module in llamaindex that jerry demo'd in the gen ai hackathon that I'm eager to try out
Ravi Theja|2023-05-14 01:04:02|Query bundle is something you need to try out.
Dev Aggarwal|2023-05-14 01:14:39|Ok since people are DMing me - here are more deets on this -  This is a friend from Banaras who got this on a contract basis from Turing. He can't get us a referral either so no luck there :D  The more exciting part, though, is the sheer level of human training they are doing, which raises interesting questions about how intelligent their models are.  He said there are about 350 people that join the global meeting. And they run like 10s of different campaigns across that team.  He worked on 5 of them -  1. Plugins - Write lots of plugins, rate the responses on how accurately the model calls the plugins and give natural language feedback.  2. RLHF Ranking + Natural language feedback on responses from chatgpt and their internal QA testers + everything else they work on  3. Coding tasks - ask gpt to write code for common problems, rate the code it writes, provide feedback on how it could write better, give it time/space complexity analysis.  4. Maths - design chat sessions where someone is trying to solve maths problems - then they run those sessions with chatgpt to make sure it follows the script & gets to an answer  5. Truncation - In cases where it generates too verbose an output or spaghetti code, tell it how to truncate the output
Dev Aggarwal|2023-05-14 01:18:41|What this implies IMO, is that these models are really still just awesome search engines rather than general reasoning engines. (this is something people have been suspecting since the first time gpt3 paper did 2-digit arithmetic - it's probably parroting it from some table online)
~ Ayush Thakur|2023-05-14 01:30:44|‎~ Ayush Thakur joined using this group's invite link
Akash Kuttappa Flipkart PM|2023-05-14 08:33:16|‎Akash Kuttappa Flipkart PM was added
Nirant|2023-05-14 09:41:02|Langchain planning to host a webinar about Education and the role these tools, specially Langchain can play there  https://www.crowdcast.io/c/q5y8g08f1f74
~ mihir_parulekar|2023-05-14 09:53:17|‎~ mihir_parulekar joined using this group's invite link
Neeraj Kumar|2023-05-14 10:09:34|‎Neeraj Kumar joined using this group's invite link
~ Anvith|2023-05-14 10:56:44|‎~ Anvith joined using this group's invite link
Nitin Mahajan McKinsey|2023-05-14 11:04:33|‎You added Nitin Mahajan McKinsey
~ Ashutosh Kumar|2023-05-14 11:15:10|‎~ Ashutosh Kumar joined using this group's invite link
~ Ravikant|2023-05-14 11:15:21|‎~ Ravikant joined using this group's invite link
~ Sushant|2023-05-14 11:52:09|‎~ Sushant joined using this group's invite link ‎[5/14/23, 12:19:44] jyotirmayjk Hackathon: ‎image omitted
jyotirmayjk Hackathon|2023-05-14 12:20:57|Software subscriptions also 20% more expensive upfront  OpenAI bills just got more prohibitive
Nirant|2023-05-14 12:23:48|No, no. They got cheaper for funded companies. They will just not move money to India for these transactions anymore. Have a Delaware LLC, keep the money there. ‎[5/14/23, 12:24:30] Nirant: ‎GIF omitted
Harsh Koo|2023-05-14 12:32:36|Anyone know of colo providers in India?   Idea being I buy hardware and then pay them to house my server and I pay for rent and internet.
Nirant|2023-05-14 12:33:41|I intend to just ship them to [PHONE]'s house?
Harsh Koo|2023-05-14 12:33:59|😀
Sthit Generative AI WhatsApp Group|2023-05-14 12:34:07|"What's ""colo""?"
Harsh Koo|2023-05-14 12:34:15|Colocation
Sthit Generative AI WhatsApp Group|2023-05-14 12:34:26|I see
Harsh Koo|2023-05-14 12:35:19|https://www.esds.co.in/colocation-services?gclid=CjwKCAjwjYKjBhB5EiwAiFdSfsRbekZqh6173zJpqhDv4xaODkp1-2UxTy6mT2JSG8Vvg1nG9AGfqhoCbHAQAvD_BwE
Harsh Koo|2023-05-14 12:35:54|This is an example.   Was looking for recommendations. (I know there are providers in India but don't know anyone whove used them)
Nirant|2023-05-14 12:36:27|In the spirit of suggesting solutions, for those doing >$100K in business/earnings:   $500 to setup, $100/year recurring, $1000 annual expense — voila, you've a US entity: https://stripe.com/en-in/atlas  You can then head to privacy.com and use Virtual Credit Cards for online transactions.
Nirant|2023-05-14 12:36:44|e2enetworks? NSE listed company
Harsh Koo|2023-05-14 12:37:02|They don't do colo AFAIK. I've used their stuff in the past.
Dev Aggarwal|2023-05-14 12:37:05|You also get openai credits if you’re a stripe atlas customer 🤩
Shashank Generative AI Group|2023-05-14 12:48:19|"no gotchas like ""valid for only 1 year"" ?"
Dev Aggarwal|2023-05-14 12:50:10|https://twitter.com/jeff_weinstein/status/1636035301536833538?s=20  (2500$)
Shashank Generative AI Group|2023-05-14 12:53:41|👍. i meant whether they expire within a certain timeframe. like how the trial $18 expired in 3 months.
Nirant|2023-05-14 12:58:29|ICYMI: Community's Generative AI May Meetups:   Open for all: https://hasgeek.com/generativeAI/may-meetup/  Women in AI: https://hasgeek.com/generativeAI/women-in-ai-meetup/
Nirant|2023-05-14 13:14:17|Request:  Please add 1-2 lines about what you found interesting and why we should read this when sharing a 14 page pdf 😅
Nitin Mahajan McKinsey|2023-05-14 13:21:28|Sure.   For those interested in building global AI infrastructure they will benefit from perhaps a first peek into how Chinese companies are approaching their model developments. The key players and where they stand.  Not a lot of information on what’s happening behind the curtain wall and just like for some things Chinese cloud providers tended to be cheaper / better than US hyperscalers.  Didn’t find much to change my assumptions from this report but sharing in case anyone here is going deeper into infra engineering  New to the group and please excuse if that’s not the protocol ‎[5/14/23, 13:25:14] Nirant: ‎image omitted ‎[5/14/23, 13:25:15] Nirant: ‎image omitted
Rounak Datta Hackathon Winner|2023-05-14 13:28:42|https://twitter.com/goodside/status/1657396491676164096 😶‍🌫️ ‎[5/14/23, 13:35:11] Nirant: ‎image omitted ‎[5/14/23, 13:35:12] Nirant: ‎image omitted
Pratyush Choudhury|2023-05-14 13:36:55|Wow
Pratyush Choudhury|2023-05-14 13:36:57|Bard is underwhelming for reasoning - where it works is that it's connected to the web & can do things that GPT4 cannot w/o the browser plug-in   Do not have the Browser Plug-in to compare performance & accuracy
Pratyush Choudhury|2023-05-14 13:37:50|Simple prompt: try asking both for LangChain, GPT will respond saying nothing existed in the training corpus while Bard does this bit well atleast
Rounak Datta Hackathon Winner|2023-05-14 13:41:32|I feel Phind.com (GPT-4 under the hood tho) somehow is in between, and works best for reasoning + information retrieval use cases. ‎[5/14/23, 13:41:50] Nirant: ‎image omitted ‎[5/14/23, 13:41:58] Nirant: ‎image omitted
Shashwat TDC|2023-05-14 13:42:36|This raises so many thoughts 💭😅
Nirant|2023-05-14 13:43:19|If Shakespeare knew we're calling this a Bard, he'd roll in his grave.
Shashwat TDC|2023-05-14 13:43:32|Try comparing for UPSC predictions? And validate in a few weeks 😅
Nirant|2023-05-14 13:43:59|UPSC predictions? There is a betting market on who will become IAS now?
Pratyush Choudhury|2023-05-14 13:44:41|This is w/ Browser Plug-in?
Shashwat TDC|2023-05-14 13:45:21|UPSC prelims exam is due in a few weeks. So basis old question papers, predict major themes for current year exam
Nirant|2023-05-14 13:46:21|I've the entirety of humanity's history on the tip of my fingers. I am not using that for anything boring. 🤣 ‎[5/14/23, 13:46:48] Shashwat TDC: ‎GIF omitted
Rounak Datta Hackathon Winner|2023-05-14 13:48:58|Either it underlearns, or it overlearns, here's an example of the latter: https://masto.ai/@amodm/110353717014726946
Soumyadeep Mukherjee|2023-05-14 13:51:17|Yes. Have used a few across India from udaan.
Nirant|2023-05-14 13:51:19|"Actions like ""making it up"" is what brings a bad name to AI, why is Pichai doing this escapes me."
Soumyadeep Mukherjee|2023-05-14 13:51:59|The dream is to make it a colo one step at a time 😅
jyotirmayjk Hackathon|2023-05-14 13:52:01|“I saw the greatest minds of my generation  embrace 175b param models capable of creativity, reasoning, the knowledge of a thousand Libraries of Alexandria  rent massive clouds of $200,000 GPUs flashed to nanometer precision  to do document question answering with semantic search”   Having UPSC questions doesn’t seem so bad in comparison 😝 ‎[5/14/23, 14:02:51] Nirant: ‎image omitted
~ Priyansha|2023-05-14 14:05:25|‎~ Priyansha left
Abhinav Verma Longshot.ai|2023-05-14 14:05:47|Can anyone with ChatGPT browsing plugin try this https://twitter.com/averma12/status/1657302210760560640 [PHONE] maybe?
Shashwat TDC|2023-05-14 14:08:02|Imagine sitting in a meeting explaining how AI tech works. In my experience ML explanations were always hard in senior management levels. My glance experience was quite satisfactory tho. ‎[5/14/23, 14:08:47] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-14 14:09:26|ya this is correct
Neeraj Kumar|2023-05-14 14:09:52|I am curious how long before GPT is forced to add such a capability! Its a singificant problem for not having latest knowledge
Nirant|2023-05-14 14:10:54|GPT has this capability for at least last 2 months
Neeraj Kumar|2023-05-14 14:11:35|So it is trained on latest knowledge? Or is it via browser plugin?
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 14:11:45|Ah, but increasingly, you wouldn't need to.   An analogy would be explaining the science behind fission, in a discussion about nuclear proliferation.  Topically relevant, but can be abstracted away at certain levels
Abhinav Verma Longshot.ai|2023-05-14 14:12:07|via browser plugin
Neeraj Kumar|2023-05-14 14:14:19|On that note, need some help from a technical person here. I am trying to make use of my Notion knowledge base (lots books summaries, podcasts, articles, etc)  using OpenAI. Built a prorotype using langchain, chromaDb, and OpenAi embeddings. But anwers are very rudimentary. How do I improve it? Improve the prompts or any other tricks?
Shashwat TDC|2023-05-14 14:14:31|Related to teaching.   discovered about Gilbert Strang's final lecture @ MIT. Details for his email, linear algebra book and Livestream link >  https://www.linkedin.com/posts/consumableai_genai-gilbertstrang-linearalgebra-activity-7063390633398325248-VyLk?utm_source=share&utm_medium=member_android
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 14:15:31|+1  Also the speed. Any way to improve the speed of 3.5 turbo?
Abhinav Verma Longshot.ai|2023-05-14 14:16:09|You can use streaming here
Shashwat TDC|2023-05-14 14:16:28|‎POLL: Any fans here for Gil Strang? ‎OPTION: Watched his video (11 votes) ‎OPTION: Watched at 2x (0 votes) ‎OPTION: Felt addicted (1 vote) ‎OPTION: Have his book/ notes (7 votes)
Abhinav Verma Longshot.ai|2023-05-14 14:16:56|I hear today is his last lecture. Or was it yesterday
Shashwat TDC|2023-05-14 14:17:25|It's 16May 830PM IST
Abhinav Verma Longshot.ai|2023-05-14 14:31:24|Can you tell about how many tokens you're trying to generate here? That affects speed of model ‎[5/14/23, 14:37:16] Arvind N Generative AI Group: ‎image omitted
Arvind N Generative AI Group|2023-05-14 14:37:42|If you guys want to try any interesting VQA examples, please let me know!
Abhinav Verma Longshot.ai|2023-05-14 14:37:49|is vicuna multi modal?
Lavish 2017|2023-05-14 14:38:09|is there any browsing plugin that can be used with langchain? if yes can someone link its manifest json file here?
Abhinav Verma Longshot.ai|2023-05-14 14:38:41|with langchain you can integrate the serp tool
Lavish 2017|2023-05-14 14:38:44|I'm already using serp api as tool btw. would using a browser plugin change much?
Abhinav Verma Longshot.ai|2023-05-14 14:38:53|no.
Abhinav Verma Longshot.ai|2023-05-14 14:39:07|serp api is pretty costly no?
Lavish 2017|2023-05-14 14:39:27|yes it is costly $
Lalit Pagaria|2023-05-14 14:44:43|Please advice this with disclaimer. If you use your personal Indian credit card to incorporate US entity then you have to follow RBI's FEMA compliances. It is easy to neglect small things which may cause issue at later stages. Specially how you move your money across the border. This article by Upekkha is good to learn about this topic https://www.upekkha.io/blog/indian-saas-startups-going-global-a-detailed-legal-incorporation-guide  This is an important quote mentioned in this article - “We didn’t pay enough attention to how we recorded our personal investment in our own US company. Yes, you are supposed to have a specific form and remittance showing the RBI that you are buying shares in a foreign entity (even your own). This mistake and other small discoveries caused us several delays at the time of acquisition. These days it is a well-known fact but please do the process cleanly. Founders still ignore this fact.” - Raj Sheth, co-founder Recruiterbox.
Nirant|2023-05-14 14:46:18|I suspect a lot of the second half complications is when you've an intent to involve a third party e.g. an investor, acquirer or similar. As long as it's just vendors and buyers — only the first part should be applicable?
Lalit Pagaria|2023-05-14 14:55:26|Not entirely as you have to show your foreign holdings with your income tax (foreign bank account, equities etc) every year as well. Anyway I am not legal and compliance expert but my suggestion is  to use their advice before taking any steps.
Vamshi|2023-05-14 14:57:33|This is a nightmare with services like firstbase positioning themselves as Indian founder friendly, but not paying attention to any of this
Vamshi|2023-05-14 14:59:41|Anyone here use a FEMA compliant service which is more template based and not a full overhead law firm that actually does it right ?
Neeraj Kumar|2023-05-14 15:02:44|https://docs.cohere.com/docs/llmu  LLM university by CohereAI
Shashwat TDC|2023-05-14 15:03:37|Zomatos childgpt feature is neat deployment
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:03:59|Passing about 2500 in context and prompt
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:04:16|Set max as 4096
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:04:58|I've tried streaming, but still takes a bit of time to begin
Nirant|2023-05-14 15:05:28|What is a bit of time? What is your tooling here? Llama Index/Langchain or something else?
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:06:11|Varies. About 8 sec to 15 sec
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:06:44|Using Langchain
jyotirmayjk Hackathon|2023-05-14 15:06:48|Doesn’t seem like it’s generating anything in real time  It seems more like set of pre generated images and poems mapped to each possible response ‎[5/14/23, 15:07:24] Nirant: ‎image omitted
Shashwat TDC|2023-05-14 15:07:32|Didn't stress test. It's be stupid if they still did that. Lol
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:07:33|Is 8 sec normal
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:07:53|Any way to improve that?
Abhinav Verma Longshot.ai|2023-05-14 15:07:55|It doesn't actually take time to begin once the prompt has been sent. Atleast not this long. Might need to check how langchain is handling the streaming request. What module does langchain use for this
Nirant|2023-05-14 15:08:46|Langchain is Python async
Abhinav Verma Longshot.ai|2023-05-14 15:09:57|I'm still confused on the time it takes to begin streaming the responses. In my experience 3.5 turbo is actually really fast.
Abhinav Verma Longshot.ai|2023-05-14 15:10:11|Unless the api is slow at that point
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:11:02|Ah maybe
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:11:18|Let me try a few things again
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 15:56:28|On a related note, here's a q if you kind folks could help  Is this the normal flow for chat interfaces?  1. User asks a question from a browser client  2. Client invokes an API, which pipes back the response as a text stream using SSE  3. The response is displayed on the client. And when done, is written to a DB as a chat log  Does 2 have to come before 3? Is there a way to handle both in parallel?
~ Gyanesh Malhotra|2023-05-14 16:19:38|‎~ Gyanesh Malhotra joined using this group's invite link
~ Nikhil|2023-05-14 16:26:46|"Anybody in this group building on top of https://data.gov.in/apis?  It will be interesting to take all of this data and allow people to ask questions like -> ""Which sector GDP has slowed down over the years. Now compare that with stock prices for companies in that segment"" ...  I think something can be built quickly on streamlit."
Aashay Sachdeva MPL Data Scientist|2023-05-14 16:34:03|Very cool idea
Nirant|2023-05-14 16:41:15|Someone from the group shared that Chroma is pretty fast for upsert/insert operations — beating Huggingface lib in the embedding operation. If someone has similar experiences, would love to hear!
~ Nikhilesh Jha|2023-05-14 16:43:14|"Hey everyone, This is Nikhilesh. I'm a Product Manager at a startup where we utilize AI to minimize waste in manufacturing plants. Currently, I'm investigating how we might leverage Large Language Models (LLMs) to assist plant personnel in performing root cause analyses. This would involve identifying causes for waste generation, machinery breakdowns, and pinpointing appropriate corrective actions. As part of my research, I'm wrapping up Coursera's NLP specialization, which includes a focus on Transformers. While I've been doing some research, I haven't yet found any resources that specifically address the application of LLMs for analyzing Industrial Internet of Things (IIoT) data, or using raw data for similar purposes or integrating LLM with ERP data. A rudimentary example of what I'm envisioning is something like this - ""Based on sensor data, Machine X is exhibiting higher than usual vibrations, and maintenance hasn't been conducted for two months. It might be beneficial to utilize the free servicing that is due to expire in two months."" As you can clearly see, my thoughts are still in the early stages, but I'm excited about the potential. If any of you have come across resources or have experience that could help guide this exploration, I would greatly appreciate your insights. Thanks in advance!"
Sthit Generative AI WhatsApp Group|2023-05-14 16:50:02|1. What you are describing is an appealing Avenue but not exactly evidently appealing for a newcomer in the AI field.  2. I mention this because Coursera in my opinion is vested in courses which indulge that target sector, even if it's something as inherently irresistible as AI 3. Plenty out there in regards to this though: https://marcosanguineti.medium.com/the-importance-of-artificial-intelligence-for-industrial-engineers-how-ai-empowers-the-engineering-441cc94e92e8
Sthit Generative AI WhatsApp Group|2023-05-14 16:50:03|Google search term was
Sthit Generative AI WhatsApp Group|2023-05-14 16:50:20|Industrial process optimization ai
~ Nikhilesh Jha|2023-05-14 16:52:47|Thanks, [PHONE] We do use good traditional (non LLM) models like good old Random Forest and more sophisticated versions for optimization. But I am looking to explore the NLP part to facilitate Root cause analysis.
Sthit Generative AI WhatsApp Group|2023-05-14 16:53:01|Got it
Abhinav Verma Longshot.ai|2023-05-14 16:53:01|You can't do both in parallel as you want to save the entire thing at once.
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 16:54:03|Got it. Thanks
Sthit Generative AI WhatsApp Group|2023-05-14 16:54:23|Interesting article: https://www.forbes.com/sites/forbestechcouncil/2023/03/28/can-large-language-models-enhance-efficiency-in-industrial-robotics/
Dev Aggarwal|2023-05-14 17:16:28|Yes get a good lawyer here, especially if you plan to do a subsidiary too (which you probably will need if you are based out of india)
Lalit Pagaria|2023-05-14 17:26:21|Using proxy nginx/envoy you can do. check this blog something similar you can do adding extra things in proxy to publish SSE response to some queue as well.  https://medium.com/blogging-greymatter-io/server-sent-events-http-2-and-envoy-6927c70368bb
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 17:28:27|Thanks a bunch. Will look through ‎[5/14/23, 18:08:45] Ojasvi Yadav: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-14 18:12:53|I still need to understand this. You can only save to the database at the end of generation. You can't keep updating the same object after every token generation it is too expensive and costly.
Lalit Pagaria|2023-05-14 18:14:32|I am writing a simpler version using python itself and share gist. What I shared was for scalable approach which is bit complex.
Dev Aggarwal|2023-05-14 18:14:48|A try: {generation stream} finally: {save to db} seems like a good approach to handle failures too
Abhinav Verma Longshot.ai|2023-05-14 18:15:39|Yes but this is sequential not parallel
Dev Aggarwal|2023-05-14 18:16:14|Why would you need to save in parallel to the db?
Abhinav Verma Longshot.ai|2023-05-14 18:16:29|That's what the question was
Ravi Theja|2023-05-14 18:16:47|Our Team *parh.ai* won *$1000 from Google Cloud* for our work.  Here is the demo of our work: https://youtu.be/7p56GS7hrg0  [PHONE] [PHONE] [PHONE]
Dev Aggarwal|2023-05-14 18:19:14|I don’t see a very good reason unless you are doing realtime stuff to multiple frontends and would like them to be synced without dealing witht multiple hierarchies of data sources
Abhinav Verma Longshot.ai|2023-05-14 18:20:22|Yes I agree.
Sanyam Bhutani|2023-05-14 18:37:21|I can help you setup H2O LLM Studio for it 🫡
Sanyam Bhutani|2023-05-14 18:41:53|(After I’m back from LLM vacation^ 😂)
~ Sayan|2023-05-14 18:42:59|Very nice work man. I worked on a similar problem some time ago. Using a diagnostic test, understanding the students concept mastery and then prepare a adaptive learning journey for the student. We used mainly BKT ( also deep knowledge tracing can be used) to estimate concept mastery for students
Lalit Pagaria|2023-05-14 18:46:11|Created this sample gist using GPT4 itself which store SSE data to DB and along with serving frontend client. But as pointed out with [PHONE] it will not essentially parallel but storing will happen during wait period. https://gist.github.com/lalitpagaria/940573ea15bcd8d859243607c9564e75
Ojasvi Yadav|2023-05-14 18:52:25|Can finally claim I got seed funded by Google
Dev Aggarwal|2023-05-14 18:54:24|This is generated by gpt4? What did you edit?
Lalit Pagaria|2023-05-14 18:56:45|I did prompting to improve the output, first one was very bad. And added few things like disclaimer and description but that also generated by it GPT, thats why you may see gist edits :) I tested it though.
Dev Aggarwal|2023-05-14 19:04:52|Checks out. I would say about 10% of it is usable in prod 🫣
Dev Aggarwal|2023-05-14 19:06:36|You should try feeding this into gpt4 and see if it understands 😂   https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/
Anubhav mishra Zupay|2023-05-14 19:11:07|https://amp-lepoint-fr.cdn.ampproject.org/c/s/amp.lepoint.fr/2519782
Lalit Pagaria|2023-05-14 19:12:25|Of course it is sample code only showing a simple way to tap streaming data from openai api. Need proper DB schema (key against data to preserve), multiple clients, multiple api instances, latency, regeneration and many more required for production use.
Dev Aggarwal|2023-05-14 19:15:23|Any takeaways?
~ Animesh Srivastava|2023-05-14 19:59:31|‎~ Animesh Srivastava joined using this group's invite link
~ prthamesh|2023-05-14 20:38:15|QnA generation looks solid. Congratulations 🎉
Ojasvi Yadav|2023-05-14 20:50:05|Thank you.   We also went a step ahead and added a story telling mode where a concept is explained via a fictional story. We sent that story to ElevenLabs to speak as an old, authoritative man. Parallely we set up another LLM that can make image generation prompts out of the story, and got a few cool relevant images.  We then just combined the story, with the narration, with the AI generated images.  Here's a demo : https://youtu.be/B4Y9-x7DC9M
Ojasvi Yadav|2023-05-14 20:50:17|This story is an explanation of relativity
Ojasvi Yadav|2023-05-14 20:50:58|Just first two paragraphs of the entire story, which is slightly longer. Happy to share if anyone likes.
Shashwat TDC|2023-05-14 20:54:18|Looks absolutely amazing.
~ prthamesh|2023-05-14 20:55:00|Noice! I think there’s a lot of potential in auto learning generation. I’m trying to learn Dutch based on how I would converse with a paid in person tutor. The first pass seems solid
Shashwat TDC|2023-05-14 20:56:13|You can add t e x t on video with latest Floyd update. All sorts of engagement possibilities to convert any content into high dopamine content. That, with equitable access, is non-zero sum.
~ prthamesh|2023-05-14 20:56:32|Play.HT has some decent Dutch voices, which are monotone, but works well while hearing the pitch and pronunciation
Ojasvi Yadav|2023-05-14 20:56:35|"It doesn't exactly cater to our ""AI tutor for all-nighters"" main course of action.   This story mode is meant to help when you're eating or taking a break. I know for sure that I watched educational videos whenever I was taking a break in an all-nighter. I just couldn't bear the guilt of watching movies during study breaks :p"
Ojasvi Yadav|2023-05-14 20:56:53|Perhaps it's value lies more in the long term study plans
Ojasvi Yadav|2023-05-14 20:57:09|When you've been freshly introduced to a topic and exams are still far away
Ojasvi Yadav|2023-05-14 20:57:36|That's when these stories could help cement concepts
Shashwat TDC|2023-05-14 20:57:39|You are saying not suitable for goal based education?
Ojasvi Yadav|2023-05-14 20:57:46|Aligned
Ojasvi Yadav|2023-05-14 20:59:30|Yeah i would imagine students that reap the most benefit from all nighters are ones who focus exclusively on question answering. These stories shouldn't really be a part of those student's productive time.
Bharat Kumar Ramesh Hashmal Web3|2023-05-14 21:00:24|Well, I guess we know what byjus is buying next
~ Kalyan Sivasailam|2023-05-14 21:43:37|‎~ Kalyan Sivasailam joined using this group's invite link
Dhruv Anand|2023-05-15 00:49:19|Does anyone know the diff between langchain python and js featuresets? A client has a typescript backend and doesn't want to have a python microservice for the LLM app
~ Rishabh Chandel|2023-05-15 00:51:56|https://langchain.com/integrations.html https://langchain.com/features.html
Abhinav Verma Longshot.ai|2023-05-15 01:26:19|in langchain is there any agent flow which is for correcting hallucination that occur in generation. something along these lines https://github.com/jagilley/fact-checker You pass in a statement and it checks for correction in the statement. This uses langchain. I was wondering if there are more such flows or if langchain has some internal mechanism like ReAct which helps in this
~ Ranjan|2023-05-15 01:33:14|‎~ Ranjan joined using this group's invite link
Dev Aggarwal|2023-05-15 01:33:44|This is so scary
Abhinav Verma Longshot.ai|2023-05-15 01:34:37|What doomsday scenario has come to your mind
Dev Aggarwal|2023-05-15 01:35:01|A ny times journalist using this to fact check something
Abhinav Verma Longshot.ai|2023-05-15 01:35:54|They will bias it to their own views.  No. Elizabeth Holmes is not evil 😂
Rohit Aggarwal|2023-05-15 01:57:47|chain of thought reasoning on open domain Q&A will only lead to more hallucinations no?
Abhinav Verma Longshot.ai|2023-05-15 01:58:21|haan, this repo is good. although has some limitations
Dev Aggarwal|2023-05-15 03:02:08|https://twitter.com/gdb/status/1657860994956410880?s=20   Bet this is dalle3
Dev Aggarwal|2023-05-15 03:05:23|https://twitter.com/main_horse/status/1657810453278658560?s=20
Aseem Gupta 2011|2023-05-15 05:31:44|What's your use case? Hyde is one approach to improve quality of answer. You can also reduce hallucinations with better prompts.
~ Happy Chaudhury|2023-05-15 07:49:15|‎~ Happy Chaudhury joined using this group's invite link
Phani Srikanth|2023-05-15 08:12:52|‎Ravi Theja added Phani Srikanth
Phani Srikanth|2023-05-15 08:20:30|Hello everyone! 👋   I’m Phani Srikanth and I’ve been in Data Sciences space since 2013.  I can attribute most of what I know to open communities such as Kaggle, fast.ai, Analytics Vidhya, the amazing DS peers and the companies I’ve worked with. Heard so much about this vibrant community and so glad to have been invited here.  Most recently, I’ve worked as a Data Scientist at Microsoft in the security space (both as an IC and a manager) for the last 4 years.  Just this week, I’ve relocated from Seattle, USA to Hyderabad, India and I’ll be glad to share my move back to India experiences with anyone interested.  So looking forward to contributing and learning from this community. Thanks!
~ Ankit Sharma|2023-05-15 09:06:35|https://docs.cohere.com/docs/llmu
Neeraj Kumar|2023-05-15 09:11:11|There is this and then fullstackdeeplearning came up with a course which [PHONE] posted on Twitter!  Anyone knows which one would be better to go down the rabbit hole.
Nirant|2023-05-15 09:13:49|If you're working on NLP heavy areas e.g. search, chat, question-answering: https://docs.cohere.com/docs/llmu — this is perhaps more deverloper-friendly because NLP is Cohere's bread and better.  If you're someone who is well-versed with basics e.g. everything from finetuning your own LMs to beam search: https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/
Neeraj Kumar|2023-05-15 09:20:27|Thanks. Still working my way through basics and building small applications.  Langchain seemed perfect way to start! Now need to go deeper.
Abhinav Verma Longshot.ai|2023-05-15 11:30:31|Oh I've done all that. Taking this one step further.
Nirant|2023-05-15 11:32:13|Abhinav [PHONE] would you be open to giving an advanced prompting for Q&A talk at the BOM meetup in June?   cc the BOM meetup curator Lalit [PHONE] can help you convert your code to a talk
Paras Chopra Wingify|2023-05-15 11:32:38|Does anyone here understand how hashing works in recommendation systems?  Been reading about the two tower architecture of recommendation systems where items and users are embedded in the same space and relevant items are found through cosine similarly to user embedding.  But a paper like Monolith (TikTok recommendation system) talks about hashing but I don’t understand where and how is it used. Any idea?
Paras Chopra Wingify|2023-05-15 11:33:01|Paper https://arxiv.org/pdf/2209.07663.pdf
Paras Chopra Wingify|2023-05-15 11:33:25|I understood Cuckoo Hashing, but why is hash used when you have an embedding?
Nirant|2023-05-15 11:36:54|Embeddings start to collide at social media scale because power creators and consumers skew the distribution:   This is a delightful exposition to why/where hash when embed exists from Instagram Engineering in 2019: https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48 ‎[5/15/23, 11:37:05] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-05-15 11:38:38|What would embed start to collide mean?  Does it mean say in word2vec sort of a context, different words will have same embedding?  I don’t think it’s clear to me why in social media embedding will collide and how hash algorithms prevent it
Sumod K Mohan|2023-05-15 11:39:22|Haven't seen the paper. Hashing is the general technique and some of these are related to Locality Sensitive Hashing, where the idea is instead of hashing to random locations to use probability theory of local chance of collision, here you want similar things to hash to similar locations. These are different class of hashing algorithms.
Sumod K Mohan|2023-05-15 11:39:29|Two cents, busy to into details.
Nirant|2023-05-15 11:41:47|word2vec isn't a good analogy for recsys embedding perhaps. But yes, that is one way to imagine.   Different words have _similar_ embedding.  As [PHONE] mentioned, you want them to be co-located in storage perhaps? One figures out an embedding-aware hash to do so — this 2 step sometimes also improves throughput
Paras Chopra Wingify|2023-05-15 11:46:23|Got it.  So instead of using raw feature for learning embedding, you hash it and then learn embeddings in the hash ‎[5/15/23, 11:46:32] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-05-15 11:47:48|It is moving away from one-got encoding -> embedding  To  Hash -> embedding  Did I get it right?
Sumod K Mohan|2023-05-15 11:50:56|Sorry if I caused more confusions. Embeddings are a type of hashing. You can do them from pure theoretical computer science ways, think Random Projections, Kernel Embeddings etc. Or you can do using a neural network. We in ML community (atleast these days), generally this the embedding. Sorry we use words means too many thing.
Sumod K Mohan|2023-05-15 11:51:43|So people might be using it interchangeably, except when they are not and using embedding followed by hashing (not sure when this is useful).
Paras Chopra Wingify|2023-05-15 11:52:35|Yeah, I understand embedding is a type of embedding (compression)  I meant in colloquial sense.  Embedding (learned function), hash (deterministic function)  Combining both is what I understood modern large scale recommendation systems are using
Paras Chopra Wingify|2023-05-15 11:52:45|Embedding is a type of hashing*
Sumod K Mohan|2023-05-15 11:55:46|Will look at the paper and come back later. Can you send the link to the original paper.
Abhinav Verma Longshot.ai|2023-05-15 11:56:34|Ya.
Paras Chopra Wingify|2023-05-15 11:57:31|This is the paper I wanted to understand and got stuck up on hashes  https://arxiv.org/pdf/2209.07663.pdf
Paras Chopra Wingify|2023-05-15 11:57:51|Thank you for offering to help [PHONE]
Lavish 2017|2023-05-15 12:22:06|just bumping this thread back again to see if there is any plugin i can use to enable browsing via API except using serp as a tool? or any other library that's optimised on cost.
Bulia Siddharth Aurashop|2023-05-15 12:24:56|I want to summarize a long piece of text consisting of several 100 thousand+ tokens. What open source model can I use?
Bulia Siddharth Aurashop|2023-05-15 12:25:03|Could anyone help?
Aashay Sachdeva MPL Data Scientist|2023-05-15 12:25:40|Llama index
Bulia Siddharth Aurashop|2023-05-15 12:26:35|Thank you!!!
Lavish 2017|2023-05-15 12:27:56|you can do map reduce on langchain. load summarize chain and do with map reduce chain type.  just double check the prompts that langchain is using in their repo, I've found tweaking those in your custom implementation works better for your use case
Nirant|2023-05-15 12:29:38|You can see some of the community discussions here: https://nirantk.com/ai   They're all made with Langchain's Map Reduce + Custom Prompts
Bulia Siddharth Aurashop|2023-05-15 12:34:31|This is great!!
Nirant|2023-05-15 12:35:23|code is here if it helps:  https://github.com/NirantK/nirantk.github.io/tree/main/community_dev
Bulia Siddharth Aurashop|2023-05-15 12:35:39|It can be turned into newsletter as well.
Nirant|2023-05-15 12:41:45|👋 Hello everyone! 🎉   On popular request — we have some exciting job opportunities to share with you today:  👥 *Posted by*: Kunal Bhatia, Cofounder, hexo.ai 🔹 *Role*: Generative AI includes all text, vision, typically 📝 *Job Description*: Senior ML engineer (3-4y exp), founding team role (team <6 people), should have some understanding of how diffusion models work 🔗 *Apply here*: https://wellfound.com/l/2yJX3z ❓ *Questions? Contact*: Reach out to Vignesh (Co-founder) https://www.linkedin.com/in/vigneshbaskaran0123/  -------------------------------  👥 *Posted by*: Twishmay Shankar, Founder PsyTech.AI 🔹 *Role*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools 📝 *Job Description*: Looking for someone who can help us upgrade and build our AI product stack. Willingness to learn, tinker, and grit to make lots of mistakes yet emerge with insight is what we are fundamentally looking for. Also a strong interest in maths and physics and comp science. 🔗 *Apply here*: No link. Direct DM my number / email on [EMAIL] ❓ *Questions? Contact*: WA, Email [EMAIL], Twitter @twishmay and IRL in NCR.  -------------------------------  👥 *Posted by*: Data Science/GenerativeAI Interns 🔹 *Role*: Generative AI includes all text, vision, typically 📝 *Job Description*: Looking for self-motivated, self-driven Data Science/GenerativeAI interns, students, learners, or enthusiasts interested in working on real-world use cases. You should have a passion for technology and a constant desire to learn. Please share your GenerativeAI work, including GitHub, blogs, apps, and/or hackathon participation along with your application. 🔗 *Apply here*: [EMAIL] ❓ *Questions? Contact*: [EMAIL]  -------------------------------  👥 *Posted by*: Aishwarya Goel, Cofounder, Inferless Backed by Sequoia) 🔹 *Role*: Not Related to Generative AI directly, but broad ML role 📝 *Job Description*: Looking for a young technical product manager for our serverless gpu offering who can closely work with engineering team & founders and lead user retention & onboarding. 🔗 *Apply here*: https://wellfound.com/l/2yNHw2 ❓ *Questions? Contact*: [EMAIL]  -------------------------------  👥 *Posted by*: Founder, Writesonic 🔹 *Role*: Generative AI includes all text, vision, typically 📝 *Job Description*: Looking for a builder with a track record of building their own generative AI side projects and a desire to learn and iterate quickly. 🔗 *Apply here*: https://writesonic.notion.site/Machine-Learning-Engineer-NLP-44bf67fd4f464af1ba5aa473ad5aa428 ❓ *Questions? Contact*: Samanyou Garg - [EMAIL]  -------------------------------  Best of luck with your applications! 🍀
~ adityachintawar|2023-05-15 12:46:11|‎~ adityachintawar joined using this group's invite link
Abhinav Verma Longshot.ai|2023-05-15 12:46:17|The approach would be to break it down and summarize each chunk separately.
Nirant|2023-05-15 12:46:37|If you want to make hiring posts: https://nirantk.com/ai/community.html  [This is free]
Prayank Swaroop Accel|2023-05-15 12:48:21|A friend is looking for using GenAI for AR/VR - any pointers ?
Bulia Siddharth Aurashop|2023-05-15 12:49:00|I essentially want to build something similar to anthropic where I can give long texts, pdfs, transcripts, entire tweets of a hashtag per day - and then can ask to generate insights out of it.
Bulia Siddharth Aurashop|2023-05-15 12:49:03|Want to do it for personal use first, so okay with extra cost of personal hosting, etc.
Aakash Kumar  Matrix Partners|2023-05-15 12:49:29|Would have to be a bot ore specific. XR + gen AI super wide
Rohan Babu|2023-05-15 12:50:40|FYI. If anybody is interested:  https://twitter.com/mundinmd/status/1657434764821905408?s=46&t=JFQp6n8tGBMX2faQoAuY3g
~ Jitendra|2023-05-15 12:53:07|Any open-source alternative for https://www.glean.com/?
Sudharshan GenAI|2023-05-15 12:54:14|Few examples  - https://segment-anything.com/ - https://www.blockadelabs.com/index.html (pure gen AI for VR)
Gyan GenerativeAI Group|2023-05-15 12:55:14|‎Gyan GenerativeAI Group joined using this group's invite link
~ Aravind Pai|2023-05-15 12:56:19|‎~ Aravind Pai joined using this group's invite link
Prayank Swaroop Accel|2023-05-15 12:57:07|He is a logistics researcher, wants to create city traffic simulations - so wants to create cities with roads and traffic etc
Nirant|2023-05-15 12:59:15|cc Devanshu [PHONE], Yash [PHONE] and Charu [PHONE] have worked on doing simulations based on user input. Phenomenal project.
Aakash Kumar  Matrix Partners|2023-05-15 12:59:45|Should check google + unity workflow if for research purposes. Can bring in all of google earth into a rendering engine now  Render pipelines for procedural setups if want to build apps Would have to also solve for occlusion culling if building for real time AR. Not an easy problem to solve.
Nirant|2023-05-15 13:02:49|Have you built something with it? Or have a demo someone can start off?
Shimanta Generative AI|2023-05-15 13:06:03|Recently saw this demo on twitter by a dude who made a Google Maps driving game: https://twitter.com/ollietylerr/status/1657796265890009088?s=46&t=WT1iAtjftW-5_e62F8FZTg  The creator said this about how it was made: “It’s using Google’s new GeoSpatial API for Unity to generate the world mesh and then building everything on top of that!”
Shimanta Generative AI|2023-05-15 13:07:36|This api was recently released in Google IO:  https://developers.google.com/ar/geospatialcreator
Sumod K Mohan|2023-05-15 13:08:25|There are quite few things out there. Along with what folks mentioned. Do look at ADAS simulators (Carla etc), in this case you can simulate without even GenAI. Not quite sure what the specific problem is, so can't comment if this will fit.
Aakash Kumar  Matrix Partners|2023-05-15 13:12:27|Have been playing with luma + unreal.  Saw g earth on rendering engine done by some in gaming discord. Shall share link
Arvind N Generative AI Group|2023-05-15 13:36:41|This is so cool! I am completely new to this space. The only thing I've tried in unity is building a small 360 immersive world so that I can use my pico4 to chill in it. This stuff is fascinating.
Arvind N Generative AI Group|2023-05-15 13:42:16|But if any of you want to generate 360 images for VR, please check out https://skybox.blockadelabs.com/ Instant generation and immersion. quality is almost SD2.0 level and it's currently free for anyone to try.
Paras Chopra Wingify|2023-05-15 13:49:31|Found a good paper on this: https://arxiv.org/pdf/2010.10784.pdf
Sudharshan GenAI|2023-05-15 13:51:26|PS: This is a good tool to breakdown papers and learn faster : https://www.explainpaper.com/ ‎[5/15/23, 14:19:03] Paras Chopra Wingify: Summary of contextual bandits and recommendation systems.pdf • ‎4 pages ‎document omitted
Ashfakh GenerativeAI WA Group|2023-05-15 14:26:12|Has anyone ran into rate limit issues with OpenAI api? chat models have 90000 TPM We are planning to do multiple accounts and balance the load between them, but is there a better way?
Chinmay Shah Arrowhead|2023-05-15 14:28:11|If you're looking at rec systems broad ideas, this webpage has some good ones: https://vinija.ai/recsys/papers/
Sachin Legaltech|2023-05-15 15:08:23|Contextual bandits are amazing framework.. Even under the hood of RLHF/ RLAIF, these systems are being contextual bandits with context being all the tokens except last and action being log probabilities.
Aditya Kothari Covid19|2023-05-15 16:01:31|‎Aditya Kothari Covid19 joined using this group's invite link
Aditya Kothari Covid19|2023-05-15 16:01:49|Hey
Bharat Kumar Ramesh Hashmal Web3|2023-05-15 16:02:26|Folks, is there a JS or TS wrapper for llamaindex?
Bharat Kumar Ramesh Hashmal Web3|2023-05-15 16:02:52|Can't seem to find it in the official docs
Bharat Kumar Ramesh Hashmal Web3|2023-05-15 16:03:02|Maybe an unofficial fork you've seen?
Sandeep Srinivasa RedCarpetup|2023-05-15 16:38:02|‎Sandeep Srinivasa RedCarpetup joined using this group's invite link
Nirant|2023-05-15 16:51:27|I'm unclear on your exact use case but if it's something like QA over documents, https://github.com/gmpetrov/databerry is perhaps a better fit for you
~ Viral Parekh|2023-05-15 16:54:30|‎~ Viral Parekh joined using this group's invite link ‎[5/15/23, 17:08:48] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-15 17:10:09|Would this be a single gpu? Or multiple in one machine
Soumyadeep Mukherjee|2023-05-15 17:13:30|Multiple in 1.
Soumyadeep Mukherjee|2023-05-15 17:13:55|It can also be a shared box.
Dev Aggarwal|2023-05-15 17:14:21|How can this even work
Dev Aggarwal|2023-05-15 17:14:29|Its not a cpu where you can easily share memory
Dev Aggarwal|2023-05-15 17:14:42|You have to divide memory na
Soumyadeep Mukherjee|2023-05-15 17:16:42|What I meant is there can be motherboards that has more than 8 A6000
Soumyadeep Mukherjee|2023-05-15 17:16:51|I was actually trying to check how common are they.
Soumyadeep Mukherjee|2023-05-15 17:17:09|Actually not very common so probably you have 1 full box/machine to yourself.
Soumyadeep Mukherjee|2023-05-15 17:20:07|Gigabyte G481-S80 is likely the motherboard
Soumyadeep Mukherjee|2023-05-15 17:20:22|It can support 8 double width GPUs i.e. A6000.
Yash Pandya|2023-05-15 17:21:00|It's common to have 8 GPU boxes and then giving access to hosts with 1,2,4 or 8 GPUs.
Soumyadeep Mukherjee|2023-05-15 17:21:02|Supermicro SYS-4029GP-TRT is the only one I found that takes 10 double width GPUs 😮
Soumyadeep Mukherjee|2023-05-15 17:21:20|Yea. But the image shows access to 8.
Yash Pandya|2023-05-15 17:21:33|Yeah
~ Sahir Patel|2023-05-15 17:26:09|‎~ Sahir Patel joined using this group's invite link ‎[5/15/23, 17:40:58] Amir Nagri: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-05-15 17:43:46|who is using llamaindex here ? just curious if ur finding any particular advantage in using it versus langchain + vector db ?
Nirant|2023-05-15 17:46:58|[PHONE] is using it in production systems. I'm migrating a consulting client from Langchain to Llama because Langchain is 💔🥲  [PHONE] is a Llama Index contributor
~ Abhinav|2023-05-15 18:38:04|‎~ Abhinav left ‎[5/15/23, 19:22:01] Nirant: ‎image omitted
Nirant|2023-05-15 19:23:15|Kailash Nadh is the CTO of India's largest brokerage by transaction volume: Zerodha. He is also an active FOSS contributor: https://github.com/knadh
Dev Aggarwal|2023-05-15 19:23:18|Can we get him in this group?
~ Arjun|2023-05-15 19:24:08|‎~ Arjun joined using this group's invite link
Shubham Sharma 2012C6|2023-05-15 19:26:38|In the same breath https://economictimes.indiatimes.com/news/company/corporate-trends/nithin-kamath-unveils-zerodhas-ai-policy-will-not-fire-anyone/no-job-loss-because-of-ai/slideshow/100210374.cms?from=mdr
~ Abhishek Saikia|2023-05-15 19:28:03|‎~ Abhishek Saikia joined using this group's invite link
~ Sahir Patel|2023-05-15 19:33:53|when I used langchain with vector db (hnswlib) for analysing metrics , sometimes it returned incorrect info . llama worked better . depends on usecases though
Sandeep Srinivasa RedCarpetup|2023-05-15 19:41:49|This is very interesting. Can u talk more about this ?  It was the same vector db and same prompt, etc ?
Dev Aggarwal|2023-05-15 19:43:30|This is expected. These models only work well when you do prompt engg over your specific data distribution. Both libraries make prompt engineering so opaque 😭 (langchain has not so good default prompts too)
jyotirmayjk Hackathon|2023-05-15 19:48:02|For metric analysis is vector embedding a good approach ?   How does embedding data point work? For ex I embed data of something like number of orders per city and use QnA db chain over it can I ask questions like “Which city showed highest growth in orders” ?
Nirant|2023-05-15 19:48:45|Nahi, nahi. You're better off asking that to something like a defog.ai for warehousing or https://github.com/gventuri/pandas-ai
jyotirmayjk Hackathon|2023-05-15 19:50:22|Exactly I was thinking of txt2sql approach using LangChain sqlagent or Python agent using sqllite3 db
Nirant|2023-05-15 19:50:33|Disclosure: I've a business relationship with Defog.ai — so I also know how good their tech is since I built it 😅 ‎[5/15/23, 19:52:40] Ojasvi Yadav: ‎GIF omitted ‎[5/15/23, 19:52:54] Gokul Krishnan: ‎image omitted
~ Sahir Patel|2023-05-15 19:53:16|yes same prompt. different vector store (pinecone)
Nirant|2023-05-15 19:53:20|Yeah, I pay a therapist to teach me how to do this again again. Thank you, thank you for confirming that it's working 🤣😂
Dev Aggarwal|2023-05-15 19:53:25|Any pointers on how to do this on nested tree like data? Eg website crawlers
Nirant|2023-05-15 19:54:38|Say more, what do you mean by a nest? E.g. can you do DFS on the crawler path and flatten it out?
~ Sahir Patel|2023-05-15 19:54:44|interesting, I will try this and check
Dev Aggarwal|2023-05-15 19:55:48|I can flatten it out without ai, and feed that into a vector db - but that would loose the hirearchical structure.  Eg one webpage has say, list of contacts, and each contact has a link to the contact’s details
Dev Aggarwal|2023-05-15 19:56:48|Basically want to build my own algolia crawler but powered by new embeddings and llm tech - https://www.algolia.com/products/search-and-discovery/crawler/
Nirant|2023-05-15 19:58:57|Thought this might be interesting to you: https://github.com/typesense/typesense
Nirant|2023-05-15 19:59:44|From what I can tell (earlier read, not tonight) — that is already flat content, right?
Nirant|2023-05-15 20:01:51|Hmm, you can always recompose by having navigation history in each chunk. You've to invent something to capture what positional embedding, circa 2018, did
Nirant|2023-05-15 20:02:51|I've tried this navigational history → chunk trick only till depth 5 though 🤔 ‎[5/15/23, 20:03:02] Dev Aggarwal: ‎image omitted
Nirant|2023-05-15 20:04:19|You're trying to capture backlink information?
~ Sourabh Gawande|2023-05-15 20:07:39|‎~ Sourabh Gawande joined using this group's invite link
Rakeshkumar Waghela|2023-05-15 20:09:47|https://twitter.com/aakrit/status/1658116297178112004?t=FhTQTej4iq5k_keIJfeA3Q&s=08
Rakeshkumar Waghela|2023-05-15 20:10:00|Mumbai Hackathon for AI.
Dev Aggarwal|2023-05-15 20:11:43|I think so, because if you have say this list
Dev Aggarwal|2023-05-15 20:11:48|# /resources/awesome_programmers.md  Here's a list of awesome AI programmers  1. [Nirant](/resources/awesome_programmers/nirant.md) 2. ... 3. ... . . .
Dev Aggarwal|2023-05-15 20:11:59|and the links resolve to a doc like this -
Dev Aggarwal|2023-05-15 20:12:00|# /resources/awesome_programmers/nirant.md  Nirant K  Website: https://nirantk.com/ Bio: I enjoy working with text and language challenges. So much so, that I even wrote a book and gave a lot of talks about it. ...
Dev Aggarwal|2023-05-15 20:12:15|Then the end nodes don't make any sense without the backlinks
Nirant|2023-05-15 20:14:21|We've gone too deep into this? Let's move this to DMs
~ Arjun|2023-05-15 20:16:18|A more expensive approach but will give you a more natural interface is to retrieve the closest vector to the question from the vector db, pass it as history in the prompt to chat gpt and let it give you the final answer.
Nirant|2023-05-15 20:17:16|"Clever: ""HyDe-lite"" ‎[5/15/23, 20:24:17] Ojasvi Yadav: ‎image omitted"
Pranjal Mehta|2023-05-15 20:24:39|Love the set-up ‎[5/15/23, 20:29:27] Prayank Swaroop Accel: ‎image omitted
~ Akshit Banta|2023-05-15 20:30:14|Dope keyboard
Dev Aggarwal|2023-05-15 20:34:25|Does torch.compile also work with pytorch2?
Prayank Swaroop Accel|2023-05-15 20:35:10|Haven't tried this.
Yash Pandya|2023-05-15 20:47:47|It only works in pytorch2
~ Vishwam Jindal|2023-05-15 20:58:22|https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561
~ Yash|2023-05-15 21:14:59|‎~ Yash was added
Ravi Theja|2023-05-15 21:45:00|Few things you can explore in LlamaIndex:  1. Query bundle/ query decomposition for retrieval 2. Recency of nodes/ chunks filtered 3. Masking of personal information before giving it to LLM 4. Post processing of retrieved nodes/ chunks. 5. Evaluation module is done differently compared to langchain 6. Custom retrievers
Jithin James Ragas|2023-05-15 22:26:27|‎Ravi Theja added Jithin James Ragas ‎[5/15/23, 22:37:03] Shashank Generative AI Group: ‎image omitted
Ravi Theja|2023-05-15 22:39:09|LlamaIndex has made an integration with Poe API - https://github.com/poe-platform/poe-protocol/tree/main/llama_poe
Shashank Generative AI Group|2023-05-15 22:40:01|awesome!
Shivendu Kumar|2023-05-15 22:41:19|Invited him :D
Rohit Ganapathy|2023-05-15 22:46:25|Anyone using humanloop actively?
Rohit Ganapathy|2023-05-15 22:47:02|Had a few questions
Nirant|2023-05-15 22:49:09|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"""
Kaushik Bokka|2023-05-15 22:56:21|https://dontasktoask.com
~ Pranay Desai|2023-05-15 22:58:27|reminds me of this and slack DMs at work 😄 https://nohello.net/en/
Nirant|2023-05-15 23:03:23|This is the exact link from community guidelines: https://nirantk.com/ai/community.html  At the same time, I think it's unlikely that everyone will read that or the other super secret link in the group description. Their loss if you ask me 😅
Kaushik Bokka|2023-05-15 23:05:42|*running similar web on nirantk.com* :p
Rohit Ganapathy|2023-05-15 23:57:18|Sorry guys was doing some user research so potentially would’ve involved many noob qs. But noted
Rohit Ganapathy|2023-05-15 23:57:21|Ouch
Soumendra Dhanee|2023-05-16 00:30:42|Noob questions are fine, what they're pointing out is that don't ask for permission/context to ask. Just ask your question directly. Don't try to save your time, save the community's time.
Vatsal Thena.ai|2023-05-16 00:50:08|‎Vatsal Thena.ai joined using this group's invite link
Abhinav Verma Longshot.ai|2023-05-16 00:55:04|50k livestream views for strangs final lecture ‎[5/16/23, 01:35:23] ~ Sudhanshu Heda: ‎image omitted
Rohan Manchanda|2023-05-16 05:42:25|Team, before I get roasted, I thought I’d check if it’s okay to share about events in thr group?   Context — we got someone cool from Anthropic to do a webinar alongside us. It’s an open invite and  we want to invite builders, recruiters to the webinar.
Kartik Mandaville|2023-05-16 05:47:33|Just met with OpenAI in their office. Signed an nda so can’t talk about what’s coming but got a couple of demos. If anyone has feedback on their API, lmk. They want to hear from devs on how can they get better.
Dev Aggarwal|2023-05-16 06:03:33|I have this request - https://community.openai.com/t/is-there-a-way-to-set-a-a-random-seed-for-responses-with-temperature-0/4164
Rohan Manchanda|2023-05-16 06:16:59|Pls join if this seems relevant to you, or pls pass it along to anyone who may benefit.   This is open to all, and the agenda is still getting curated tbh but if anyone has requests let me know (we want to keep the conversation AI first but use cases may be recruiting focused so anything that annoys you about recruiting is fair game hah)  https://www.linkedin.com/posts/rohan-manchanda-74812b15_aiinrecruitment-activity-7064004613942751232-MJXH?utm_source=share&utm_medium=member_ios
Keertana S Suvy|2023-05-16 08:58:35|https://levelup.gitconnected.com/mpt-7b-the-times-of-commercially-usable-language-models-has-come-8c9c6c3316ef  An interesting development. Has anyone tested this model's performance?
Nirant|2023-05-16 09:51:41|FYI: This was the press coverage then. You cannot use it commercially.
Sandeep Srinivasa RedCarpetup|2023-05-16 09:58:25|Confidence score for each reply. This is the huge problem for enterprise deployment, prompt testing...basically everything.
Raghotham Paypal Bargava's Friend|2023-05-16 09:58:30|Even base?
Rohit Aggarwal|2023-05-16 10:01:36|logprobs used to solve this to some extent before chat completion endpoints
Rohit Aggarwal|2023-05-16 10:01:47|for prompt testing - have you tried evals?
Neeraj Kumar|2023-05-16 10:05:13|Wow! Access to the most brilliant minds on earth right now!  Whats your take on AGI? How are we are from it! :)
Sandeep Srinivasa RedCarpetup|2023-05-16 10:05:23|This is an involved question. How will u eval ? String match, embedding match or statistical match?  One of the papers to follow is this https://arxiv.org/pdf/2210.09150.pdf  This is not easy. Even when u try to match, the reliability score is unpredictable if u have temperature above zero.
Rohit Aggarwal|2023-05-16 10:08:11|Would depend on the task at hand I assume.  Unpredictable yes - but with an eval model you could build a confidence function based on semantic match / similarity score or relevance confidence
Rohit Aggarwal|2023-05-16 10:08:27|Also, sorry - what’s an “involved question”?
~ Shrey|2023-05-16 10:36:03|‎~ Shrey joined using this group's invite link
~ Radhika|2023-05-16 10:38:20|‎~ Radhika joined using this group's invite link
Sumod K Mohan|2023-05-16 11:29:13|Yes you are right. In their particular case, they are using a collision less hashing (here ids span 2^48 space). Here hashing being normal hashing (not semantic/LSH). They needed a hash function that hashes to smaller space (after removal of some of the long tail data) with extra properties, like ability to remove hashes cheaply (as things get stale), ability to add new IDs (as they do online learning on new IDs as they come in). You can DM, if you have more questions.
Sumod K Mohan|2023-05-16 11:31:18|Thanks for asking this question, sharing the write up (helped me understand where you are), the paper was quite interesting with lots of sys  details, though tad bit badly written. I also learned few things 😀.
Paras Chopra Wingify|2023-05-16 11:32:25|thanks for answering.  it's interesting to note that most such companies leave out a few crucial details always. for example, i dont think they mentioned what all features do they end up using for personalization
Sumod K Mohan|2023-05-16 11:34:02|Haha. Yeah, that is their sauce for 💸
Nirant|2023-05-16 11:34:21|Also keeps engineers employable
Paras Chopra Wingify|2023-05-16 11:35:45|It seems to me that ML engineering is where the moat is, not so much in ML research.
Nirant|2023-05-16 11:36:28|Yeah, I've bet my career on that since 2018
Abhinav Verma Longshot.ai|2023-05-16 11:37:42|Timeout of their api can be improved and we should be able to pass custom values. The current ones don't work
~ Nikhil|2023-05-16 11:45:35|Hey folks, came across replicate.com. Would this be a good way to begin working with open source models for a newbie?  Their APIs look good.
Nitin Mahajan McKinsey|2023-05-16 11:48:39|Yes. At least for me have been using this and found free lancers comfortable using it for a prototype
Abhinav Verma Longshot.ai|2023-05-16 11:49:47|I think [PHONE] already has some experience with this. He can share some points on this
~ Nikhil|2023-05-16 11:50:29|From what I see, we can run predictions easily. Apart from predictions, can we use replicate for training the existing models with custom datasets too?
Aditya Agrawal SuperU|2023-05-16 11:55:21|Best part of replicate is you can test the model on their UI to see if it works for your use case and then spend time on setting things up.
~ Abhiram Ravikumar|2023-05-16 12:09:55|‎~ Abhiram Ravikumar joined using this group's invite link
~ Aravinth Muthu|2023-05-16 12:38:45|‎~ Aravinth Muthu left
Aashay Sachdeva MPL Data Scientist|2023-05-16 12:44:38|I got access to GPT plugins, but don't see the browser one. No search functionality as well for searching for plugins. Any idea?
Dhruv Anand|2023-05-16 12:46:56|Same here. Is there any plugin which does the same?
Ashwin Matrix|2023-05-16 12:47:00|did you enable it on your account settings?
Dhruv Anand|2023-05-16 12:47:12|Don't have it in the options yet
Ashwin Matrix|2023-05-16 12:47:43|cuz if its not visible there then probably hasnt been rolled out to your account. they're doing it in tranches
Aashay Sachdeva MPL Data Scientist|2023-05-16 12:47:59|All other plugins are there
Kartik Mandaville|2023-05-16 12:49:30|its a different model and not a plugin
~ Anand|2023-05-16 12:53:48|‎~ Anand joined using this group's invite link
Nilesh Christopher|2023-05-16 12:56:37|Hey everyone! *A request*  I'm Nilesh, a tech reporter for restofworld.org, an international publication covering the impact of tech in non-western countries  I'm currently reporting a story on voice manipulation and the potential risks associated with synthetic voice cloning, through a real-life example that's playing out in India. I need a couple of experts to independently test 2 audio clips, and ascertain if they are real or synthetic. If anyone is interested in discussing/collaborating on this project, can you DM me?
Nilesh Christopher|2023-05-16 12:56:39|My profile: https://restofworld.org/author/nilesh-christopher/
Nirant|2023-05-16 12:58:44|Can recommend helping out Nilesh, high integrity. He wrote about the Generative AI Hackathon winners as well:  https://restofworld.org/2023/india-generative-ai-hackathon-2023-projects/  Shouldn't take unreasonably long: 1-2 hours for Googling and trying out tools and 2-4 hours for setting a Colab/Jupyter notebook if needed  If you're ever in BLR, happy to buy you coffee for helping out Nilesh! ‎[5/16/23, 13:01:26] ~ Abhiram Ravikumar: ‎image omitted
~ Abhiram Ravikumar|2023-05-16 13:01:38|Not sure why the clicks are falling
Swastik Banerjee|2023-05-16 13:01:51|Try WebPilot or Keymate.Ai Search if u have access to that ‎[5/16/23, 13:03:29] ~ Abhiram Ravikumar: ‎image omitted
~ Abhiram Ravikumar|2023-05-16 13:04:30|I've enabled it this way
Lalit Pagaria|2023-05-16 13:17:35|Just curious to know the impact of launching plugin on business metrics: traffic, revenue, CSAT, etc? One major problem I see in the OpenAI interface: discoverability of plugin, no search and filter option :(
Aditya Agrawal SuperU|2023-05-16 13:18:05|Do we have a list of good learning resource? Bunch of college grads have started reaching out asking for resources which can make them industry ready in the ML/AI space, specially Generative ?
Nirant|2023-05-16 13:25:19|course.fast.ai is all you need if you've some programming exposure e.g. 1 year of Python/2 years of JS/6 months of Rust  Also, this community discussions can be used as a learning resource: https://nirantk.com/ai
Aditya Agrawal SuperU|2023-05-16 13:25:56|and stats?
Aditya Agrawal SuperU|2023-05-16 13:26:12|and  LangChain for structure?
Nirant|2023-05-16 13:27:00|I'd recommend every beginner against Langchain. These libs evolve fast. And they might over index on the wrong ideas e.g. vector similarity is how search is done 🤢
Aditya Agrawal SuperU|2023-05-16 13:29:30|got it..
Aditya Agrawal SuperU|2023-05-16 13:30:58|Would you recommend Fast.ai over Hugging Face course?
Nirant|2023-05-16 13:31:15|I hope most undergrad students know this better than me, given that they practiced for entrance exams:  Free 101 stuff, but  https://www.udacity.com/course/statistics--st095 https://www.udacity.com/course/intro-to-inferential-statistics--ud201
Aditya Agrawal SuperU|2023-05-16 13:31:48|Trust me they have not..
Aditya Agrawal SuperU|2023-05-16 13:32:34|I have interviewed around 50-100 folks in past..
Aditya Agrawal SuperU|2023-05-16 13:34:00|Lot more folks from SDE background are in the market than statistics background ‎[5/16/23, 13:35:07] Ashwin Matrix: ‎image omitted
Swastik Banerjee|2023-05-16 13:40:06|Has anyone developed plugins here yet?
Swastik Banerjee|2023-05-16 13:40:12|Any idea how to set custom metadata?
Swastik Banerjee|2023-05-16 13:41:40|I’ve ```/upsert``` -ed the documents using chatgpt-retrieval-plugin, but not being able to make custom metadata work yet
Sandeep Srinivasa RedCarpetup|2023-05-16 13:49:42|the custom metadata needs to be added both in the vector db model as well as the openapi spec. did u change the openapi as well ? theres a bit of trial and error here, since the openapi spec is what chatgpt uses to interpret the data. sometimes the descriptions are off..ull need to iterate.
Swastik Banerjee|2023-05-16 13:51:28|Yes I’ve changed the openapi specs, particularly ```models.py``` in ```/models``` and ```openapi.yaml``` in ```/.well-known``` if you’re a acquainted with the repo
Swastik Banerjee|2023-05-16 13:52:17|But maybe I’ve not defined the custom metadata correctly
Swastik Banerjee|2023-05-16 13:53:15|Anyone who had worked in this direction, a tutorial if available, or a small screenshot where they’ve defined their custom metadata if shareable, would be really helpful
Kailash Nadh Zerodha|2023-05-16 14:15:20|‎Kailash Nadh Zerodha joined using this group's invite link
~ Nayan Shah|2023-05-16 15:59:38|some background before a question,  so in my team, we have worked on different kinds of use cases with vectors, and more or less based on availability we had gone with newer or at that time which looked better as a vector DB choice. some of them are Qdrant ( product entity related use-case which needed filtering etc, and qdrant apis were good level of abstraction given .), FAISS simple and for FAQ kind of use-case it was simpler and easy to use, and now chromadb for LLM related usecase. so chromadb because of the parquet file and all we were hoping would be better and will just move it to that , for all usecases but when we started using it we noticed that they cache the embedding for collection so when user asks for collection moomentarily they get embeddings in memory, i understand we may want embedding in memory to do faster cosine embedding have seen them also raised an MR with SQLite as sqlite with the disk on ssd is way faster and very less memory usage as well and gives the ACID property as well on metadata.  so this was my dilemma, for various such use cases what are u guys using as your vector-related use cases, and why. what are memory and CPU usages while indexing and searching ( as searching should be faster )...  hope my question makes sense, because when I calculated embeddings size for my chromadb stored vector it was around 50 Mb But in my docker it was taking around 1.3GB and growing .. ‎[5/16/23, 16:06:17] Nirant: ‎image omitted ‎[5/16/23, 16:09:36] Ojasvi Yadav: ‎image omitted
~ Nayan Shah|2023-05-16 16:16:50|thanks, I think in chromadb server sometimes takes up the memory and stores things in memory of python itself. In qdrant can u share the file mode-related ref... or are u talking about payloads stored in disk ...
Nirant|2023-05-16 16:17:44|"Not just payloads, you can also pipe the vectors to local. Syntax from memory is something like this:   from qdrant_client import QdrantClient  client = QdrantClient("":memory:"") # or client = QdrantClient(path=""path/to/db"")  # Persists changes to disk"
~ Nayan Shah|2023-05-16 16:24:47|interesting, oh I did not know this, this must be new let me try to find a ref
Nirant|2023-05-16 16:31:35|Happy to help, also I should disclose I've a business relationship with Qdrant.
Swastik Banerjee|2023-05-16 16:33:55|this is almost starting to sound like “As an AI language model,….” 🫣 ‎[5/16/23, 16:34:45] Nirant: ‎GIF omitted
~ Anubhab|2023-05-16 19:41:48|‎Ravi Theja added ~ Anubhab
~ Anubhab|2023-05-16 19:51:46|Hi all,  Glad to be here !  I am a Data Scientist with Ericsson R&D with expertise in analyzing real world complex data and drawing actionable insights to solve them.Working on 5G use-cases now.  Here is my LinkedIn profile in case anyone is curious.  https://www.linkedin.com/in/anubhab-samal-0a5075183/  If you're interested in collaborating, please don't hesitate to connect with me.
~ Anuj Menta|2023-05-16 20:58:47|‎~ Anuj Menta joined using this group's invite link
Nirant|2023-05-16 21:13:11|Sam Altman proposes to the US Congress that licenses be issued for building AI  https://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/
Abhinav Verma Longshot.ai|2023-05-16 21:17:53|This agi stuff is just an excuse to build a monopoly
~ Rohan|2023-05-16 21:18:43|He's come a long way from *Open* AI
Abhinav Verma Longshot.ai|2023-05-16 21:20:04|Regardless of intentions. I don't think government should just listen to a for profit organization. You might not know AGI but you know greed
~ Shobhit Jaipurkar|2023-05-16 21:20:29|Sad part is that, if enough new software solutions built using GPT emerge as job providers, openAI will be at the forefront of making legislation for all things pertaining to AI
Abhinav Verma Longshot.ai|2023-05-16 21:21:25|Haan.
Abhinav Verma Longshot.ai|2023-05-16 21:22:40|Microsoft wants a return on its investment
Rakeshkumar Waghela|2023-05-16 21:26:27|This feels like jio days when everyone and their dogs were getting aadhaar biometric based sim card activated in shortest possible time.  And all of sudden in sometime after jio Onboarding done at record scale, the rules changed for aadhaar based Onboarding
Nirant|2023-05-16 21:27:30|Microsoft is also an investor in Jio.
~ Rohit|2023-05-16 21:30:01|Is openai profitable on unit economics?
Abhinav Verma Longshot.ai|2023-05-16 21:31:11|Not yet
Abhinav Verma Longshot.ai|2023-05-16 21:32:17|Satya vachan
jyotirmayjk Hackathon|2023-05-16 21:47:06|How long before buying GPUs gets licensed ?
Gokul Krishnan|2023-05-16 21:49:59|No reason for Jenson to block potential buyers. Now, if we're talking about using GPUs in data centers, that's already a messed up area
Gokul Krishnan|2023-05-16 21:50:45|Any room with more than 5 computers (or some smallish number) can be considered a data center and therefore you cannot use the RTX family of GPUs in such a setup
Ashwin Matrix|2023-05-16 22:37:53|https://home.mlops.community/public/events/fine-tuning-llms-best-practices-and-when-to-go-small-2023-05-17  Short session tomorrow Eve. Sharing incase anyone is interested
Krishna Ntkris|2023-05-16 22:45:18|When you do embedding based retrieval, what threshold are you using for the similarity score? I know it depends on the use case but we are having to do a lot of trial and error so I’m curious
Sandeep Srinivasa RedCarpetup|2023-05-16 22:46:43|Don't just focus on this part...focus more on creating the embeddings. For e.g. the OpenAI Tiktoken library is the BPE algorithm. U can switch this out...have tokens overlap, etc etc. Lots of stuff u can do.
Krishna Ntkris|2023-05-16 22:47:57|Thanks! You mean focus more on the content being used to create the embeddings and any other parameters you can control?
~ Sayan|2023-05-16 22:51:06|Karpathy has a very interesting take on this.  Checkout his notebook  https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
~ Sayan|2023-05-16 22:51:08|:-)
Swastik Banerjee|2023-05-16 22:56:53|This is very cool!
Swastik Banerjee|2023-05-16 22:57:27|Any other documents for tradeoffs with just using embeddings based search v/s alternatives/hybrid search?
Sandeep Srinivasa RedCarpetup|2023-05-16 22:59:37|No not the content. The same content, but the way you tokenize to create the embeddings.  Of course the embedding algorithm itself - u can use OpenAI embeddings or the HuggingFace embeddings, etc. U can store different kind of embeddings for the same content (cos its always a one time time cost) and query against multiple indexes when retrieving.
Sandeep Srinivasa RedCarpetup|2023-05-16 23:00:05|The retrieval algo itself is the most unchanging thing here...svm vs knn nonwithstanding
jyotirmayjk Hackathon|2023-05-16 23:12:43|There were indications of this monopolistic behaviour since quite some time  For ex OpenAI published a paper suggesting ways to limit civilian use of AI because they propose Gen AI can be used to spread disinformation ‎[5/16/23, 23:13:14] jyotirmayjk Hackathon: ‎image omitted ‎[5/16/23, 23:15:17] jyotirmayjk Hackathon: ‎image omitted
Sumod K Mohan|2023-05-16 23:15:36|Actually I think, you could do (late) Sam Roweis's Neighborhood Component Analysis. The idea here is that KNN, values all dimension equally but you can learn what dimensions are actually important by traning it to search over a family of distances (like Mahalonobis family for eg) initially. This way, you don't have to train at test time (like what Karpathy is doing) and should perform quite better. Will try this tomorrow evening or so.
Swastik Banerjee|2023-05-16 23:18:02|please share results
Anubhav mishra Zupay|2023-05-16 23:18:36|That's where he is building world coin ? He has some crypto stuff also going on right ?
jyotirmayjk Hackathon|2023-05-16 23:19:39|Yup ,ties in pretty neatly to give OpenAI a good monopoly
Anubhav mishra Zupay|2023-05-16 23:19:48|https://fortune.com/crypto/2023/05/15/openai-sam-altman-100-million-worldcoin-funding-iris-human-artificial-intelligence/
Sumod K Mohan|2023-05-16 23:33:07|Here is his talk. He was an very lucid expositor: http://videolectures.net/lce06_roweis_ncaml/
Abhinav Verma Longshot.ai|2023-05-17 00:13:23|Got access to chatgpt plugins. Based on your experience what are the best plugins
~ Sahir Patel|2023-05-17 00:14:35|the diagrams one
Abhinav Verma Longshot.ai|2023-05-17 00:17:01|also a basic question How do you upload stuff to chatgpt, like I use the pdf reader plugin?
Kailash Nadh Zerodha|2023-05-17 00:17:32|Hi everyone. I’m Kailash. @kshivendu invited me to this group. I’m a developer trying to rekindle an old academic interest in AI in the wake of the recent fascinating+terrifying breakthroughs! I head technology at Zerodha (capital markets/tech firm) and work on my hobby projects. My personal website is https://nadh.in  Cheers!
~ Abhiram Ravikumar|2023-05-17 00:22:20|Huge fan of zerodha and what's it done so far! Welcome aboard.
Sidhant Sequoia|2023-05-17 00:32:55|https://blog.cloudflare.com/introducing-constellation/  Inference on workers. If anyone tries this do share how good.
Sumod K Mohan|2023-05-17 00:39:31|Hi Kailash, Welcome onboard. Sumod here btw. Yeah, exact same feelings of fascination & bewilderment at the same time. Trying to see how to make it to be something for greater good.
Jithin James Ragas|2023-05-17 00:45:48|wait really? I always wondered it would be possible to put together some consumer level GPUs and build a system like google did in the early days
Gokul Krishnan|2023-05-17 00:51:52|https://www.digitaltrends.com/computing/nvidia-bans-consumer-gpus-in-data-centers/
Gokul Krishnan|2023-05-17 00:52:07|Bit of an old news, i haven't seen the latest on this
Gokul Krishnan|2023-05-17 00:53:06|Google could that because they were small. Back during Stanford days, they used to offer to setup machines that come for the CS dept and secretly use it for a week or so before giving it to the intended recipient
~ Yash More|2023-05-17 02:52:33|https://github.com/microsoft/guidance  Interesting to see that such structuring allows to cut down on the prompt generation/inference time as well.
Dev Aggarwal|2023-05-17 02:54:11|Any comparisons between this and https://lmql.ai/ ?
Dhruv Anand|2023-05-17 05:22:44|I think OpenAI simply doesn't have the expertise or maybe motivation to do growth work, especially on free products side. FB would've optimised the hell out of chatgpt growth metrics if they were working on it
Nirant|2023-05-17 07:27:31|This mindset is perhaps why FB didn't invent ChatGPT, or even any GPT?  Altman would have taken Zerg's money instead of Nadella
Nirant|2023-05-17 07:28:27|Before someone says Llama, in comparison to even 3.5-Turbo it's Lmao.
Rahul Bhatnagar|2023-05-17 07:29:02|Naa I think it was because of too much metaverse.
Nirant|2023-05-17 07:29:20|I'm sure they saw more growth in Metaverse.
Dev Aggarwal|2023-05-17 07:29:51|Engagement pro max
Kartik Mandaville|2023-05-17 07:30:45|I’m talking to one of the gen ai leads from meta next week, Looks like they’re doing a bunch of stuff
Dev Aggarwal|2023-05-17 07:31:17|Next level ads also
Nirant|2023-05-17 07:32:28|Absolutely no disputing Meta's ability to fast follow by throwing together compute, and talent. I love Meta for making FAISS, PyTorch and what not
Samhan Meta/Twitter Friend|2023-05-17 07:37:22|‎You added Samhan Meta/Twitter Friend
Nirant|2023-05-17 07:38:57|Would love to know if Meta plans to continue to intend this research license behaviour +  Plans for video→text embedding e.g. for Reels and their captions + Any progress on Refactoring Code w/ generative AI that they've made
Ojasvi Yadav|2023-05-17 07:51:38|Apple takes its first step in Gen AI
Ojasvi Yadav|2023-05-17 07:51:39|https://www.apple.com/newsroom/2023/05/apple-previews-live-speech-personal-voice-and-more-new-accessibility-features/
Ojasvi Yadav|2023-05-17 07:52:14|Going to steal a few customers from eleven labs TTS
Ojasvi Yadav|2023-05-17 08:02:00|Shopify released this interesting dataset  I'm leading AI at Dukaan. If anyone's keen on taking up any projects related to this dataset then I'm happy to share my domain knowledge around e-commerce and AI.  https://news.shopify.com/index-beta ‎[5/17/23, 08:05:45] Nirant: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-05-17 08:21:20|Exports of shopify merchants in India selling abroad
Bharat Kumar Ramesh Hashmal Web3|2023-05-17 08:21:27|There's possibly a currency impact too
Bharat Kumar Ramesh Hashmal Web3|2023-05-17 08:21:41|That isn't factored in
~ Clament John|2023-05-17 08:35:46|‎~ Clament John joined from the community
~ Clament John|2023-05-17 08:41:15|Here's an idea: Prompt injection detection as a service.  There are a few ideas floating around in the ecosystem * Using two LLMs - https://simonwillison.net/2023/Apr/25/dual-llm-pattern/ * Using vector DBs to keep track of previous attacks * Other archaic techniques like - begging the LLM not to break character, using special charectors to differentiate system and user messages, etc.  Does anyone know any activity in this space?
~ Deven|2023-05-17 08:47:09|Related?  https://twitter.com/willpienaar/status/1658479681182797836?s=46
~ Clament John|2023-05-17 08:47:18|https://rebuff.ai/ is trying to build this, they even have a self hostable server
~ Clament John|2023-05-17 08:47:27|Oh beat me to it
~ Clament John|2023-05-17 08:47:46|To self host https://github.com/woop/rebuff
~ Clament John|2023-05-17 08:49:31|Why was it forwarded to the same WA group? ‎[5/17/23, 08:50:06] ~ Clament John: ‎GIF omitted
Nirant|2023-05-17 09:23:06|Removed those for now, I assume it was meant for someone else
~ Nandini|2023-05-17 09:37:50|‎~ Nandini joined using this group's invite link
Amir Nagri|2023-05-17 09:50:11|[PHONE] compiled this excel sheet with learning resource, hope you find this helpful   https://docs.google.com/spreadsheets/d/1hHm8_eb4J_8xqMK63LIdn2J560bYH_5FFkxqq46eRcM/edit#gid=962390240
Neeraj Kumar|2023-05-17 10:11:13|Thanks for this.
Jay Pokarna 2014 BPCC|2023-05-17 10:52:58|They also made changes to CoreML for stable diffusion. Feels like in sometime, they will ship iphone/mac with their modified version of SD which devs/consumers can directly use.   https://machinelearning.apple.com/research/stable-diffusion-coreml-apple-silicon
Anubhav mishra Zupay|2023-05-17 11:16:22|https://apps.apple.com/us/app/queryable-find-photo-by-text/id1661598353  A single developer took OpenCLIP and created an app Queryable ($1.99) which runs the model LOCALLY locally on your phone and indexes all your photos (you can put your phone in airplane mode to see) and you can now run any complex query on your photos. I've tried it and it is just mind blowingly good.  This is just STUNNING. For the longest time, Google had the best search for photos and the belief was that this was because of years of training on practically the whole internet.  That capability is now available to every developer for FREE
Ravi Theja|2023-05-17 11:43:21|https://hackathon.bio/ - Bio x AI hackathon - fully remote - people interested in AI in biology can look into it
~ Vibbs Dod|2023-05-17 11:43:24|This is really cool find, will try this out
~ Clament John|2023-05-17 11:52:49|Doesn't gpt-3.5-turbo have a small context size? I see people dumping large pieces of text to the prompt and expect it to give good answers.  For example in this video - youtube.com/watch?v=twHxmU9OxDU - the presenter dumps a research paper's first two pages into the prompt and asks it a question.
Ravi Theja|2023-05-17 11:55:07|GPT-3.5-turbo and GPT-4 have default context sizes of 4096 tokens. There are variants of GPT-4 models with 8k and 32k tokens context sizes as well.
~ Clament John|2023-05-17 11:58:00|Got it. Ty.   Quick question:  Lets say I gave gpt-3.5-turbo a prompt for it to act as researcher and I gave it a large paper to ingest. I ask a few questions, etc.  After the model hits its context of 4096 tokens won't it forget it was a researcher?
Nirant|2023-05-17 11:58:03|Works via Map Reduce kinda ideas.   Here is one idea: https://python.langchain.com/en/latest/_modules/langchain/chains/mapreduce.html  You can see some of the community discussions here: https://nirantk.com/ai  — they're all build this way. This chat is often more than 4K tokens/day.
Dev Aggarwal|2023-05-17 11:59:23|Map reduce has a theoretical upper limit on the size of output, which is 1/3 of the max output token count of the model btw something to keep in mind
~ Clament John|2023-05-17 12:01:42|I have a chrome extension that has found some success - https://chrome.google.com/webstore/detail/summarize/lmhkmibdclhibdooglianggbnhcbcjeh  I was planning on building more products that use chat.openai.com and not OpenAI token. This way I can give it out for free.  Is it a good idea to use chat.openai.com's auth token and make requests or should I be using OpenAI's API token? Is there a difference?
Sidhant Sequoia|2023-05-17 12:05:47|https://twitter.com/itstimconnors/status/1658547632124354595?s=48&t=ACPHEfclkXmi9Z92RTsh9g  Imbuing agents with personality.
Sandeep Srinivasa RedCarpetup|2023-05-17 12:06:15|Has anyone put ANY opensource model in production without fine tuning?   Which one are u liking for being as close to OpenAI as possible for an open-source model ?
Ravi Theja|2023-05-17 12:07:34|would be good to use Azure OpenAI service while building products as you may hit rate limit error with OpenAI token.
Aashay Sachdeva MPL Data Scientist|2023-05-17 12:07:34|What is the usecase of putting a generic model in production?
~ Clament John|2023-05-17 12:08:49|The product will be using the user's Chat GPT token. So I don't think it will be hitting OpenAI's throttle limits
~ Arka|2023-05-17 12:09:25|You might run foul of Terms of Service
~ Clament John|2023-05-17 12:09:27|Is there a difference bw chat.openai.com and gpt-3.5-turbo?
~ Clament John|2023-05-17 12:09:57|Hm, yes that could be an issue. But technically OpenAI does not know the requests are coming from an extension
Shubham Sharma 2012C6|2023-05-17 12:11:13|Hey there. Can someone help me understand why the memory relevance score is obtained by simple summation and not say a multiplicative combination of recency, importance or similarity?
~ Clament John|2023-05-17 12:11:38|And it is just a user's request. I pay for ChatGPT. But the app could be more for targeted segments instead of being a chat only tool.  Example * a copy.ai clone all in your chrome extension. * a kind of builder - form, email template , etc
Dev Aggarwal|2023-05-17 12:12:48|Yes, the biggest one has to be that there’s a farm of humans looking at what you type into chatgpt and trying to fix it 😂
~ Arka|2023-05-17 12:15:33|Taking a guess  If you multiply then change in one factor impacts the other 3 much more  Differentiate  xyz  Vs  x + y + z
Shubham Sharma 2012C6|2023-05-17 12:16:41|Why not factor something like an xy+yz+xz.. sometimes memory triggers for us are a combination of similarity and importance?
Shubham Sharma 2012C6|2023-05-17 12:17:35|I understand more unstability but maybe can be combined with a smaller coefficient?
Sandeep Srinivasa RedCarpetup|2023-05-17 12:37:42|"chatgpt is a generic model. more commonly known as a foundation model.  not disputing the value of LLM/foundation models vs custom trained models...this question is merely about ""which open source foundation model have u put in production just like u would use chatgpt"""
~ Yogitha ✨|2023-05-17 12:41:32|‎~ Yogitha ✨ joined from the community
~ Arka|2023-05-17 12:44:26|I guess its upto use case.  If you really expect more complicated logic in your use case.  You can just build a decision tree or svm with the 3 features
Samhan Meta/Twitter Friend|2023-05-17 12:48:46|Simple intuition -  Addition is like treating them as independent axes. So something can be extremely recent but not very important. Multiplication makes it more of a dependent AND operation. It has to be recent , similar and important at the same time. It is more restrictive.
Samhan Meta/Twitter Friend|2023-05-17 12:49:50|Addition is more lax. And so the model can decide what to do. And you err on the side of calling into the model more
Samhan Meta/Twitter Friend|2023-05-17 12:51:05|Someone was asking about metas plans
Samhan Meta/Twitter Friend|2023-05-17 12:51:09|https://atscaleconference.com/events/meta-ai-infra-scale/
Samhan Meta/Twitter Friend|2023-05-17 12:51:14|Tune in if you’re curious
Shubham Sharma 2012C6|2023-05-17 12:53:02|Yeah SVM with three features makes sense. Treating them like vectors on independent axes
~ Antony Paul|2023-05-17 12:53:45|‎~ Antony Paul joined from the community
~ Arka|2023-05-17 12:54:45|X+Y+Z < C is a diamond shape  xyz  < c is a complex 3d shape like with 8 hyperbola like faces
Samhan Meta/Twitter Friend|2023-05-17 12:57:57|Has anyone seen any example of an agent setup doing something truly impressive ?
Sumod K Mohan|2023-05-17 12:58:02|"One way of think of them (Control System PoV) is that are they operations in series (multiplication) or parallel(addition)? Multiplying is great if you sort have a condition ""if any of these are bad, then output should be low"", as even one component being low will effect output drastically. Whereas addition will reduce only for that component's selection. There are other nuances as well. You can see this talk I gave at 2018 fifthelephant (some of those are dated today). See anti pattern3: https://m.youtube.com/watch?v=FYVFK4Y4IiY"
Samhan Meta/Twitter Friend|2023-05-17 12:58:12|I have seen more demos of the frameworks than actual outputs
Krishna Ntkris|2023-05-17 12:58:23|I’m working on a bunch of stuff in ecomm - will dm you!
Samhan Meta/Twitter Friend|2023-05-17 12:59:55|Like the Microsoft paper was cool because it was a simulation / game for fun. So for eg agents might be great for writing the plot of a movie. Make a set of characters and set them loose. But for “real work” yet to see something that works well
~ Prashant Abhishek|2023-05-17 13:01:29|‎~ Prashant Abhishek joined using this group's invite link
Samhan Meta/Twitter Friend|2023-05-17 13:03:09|The key here is to make you one of the “agents” and also things like compilers and search engines. And you can interrupt it at any point by pressing Ctrl+D or something and redirect it.
Samhan Meta/Twitter Friend|2023-05-17 13:06:29|And then you do tbis a lot and fine tune / RLHF on it. This is what openAI is doing with plugins. ‎[5/17/23, 13:09:00] Samhan Meta/Twitter Friend: ‎image omitted
~ Govind|2023-05-17 13:12:44|‎~ Govind joined from the community
~ vishnusajan|2023-05-17 13:15:22|‎~ vishnusajan joined from the community
Swastik Banerjee|2023-05-17 14:55:49|Any of you have github pro here?  I was trying to upgrade to get more large-file-storage access, but RBI declined my payment ‎[5/17/23, 14:57:34] Swastik Banerjee: ‎image omitted
Dhruv Anand|2023-05-17 15:15:09|I don't use Pro yet for my company. I thought there isn't a limit on repo size or file size. Is there?
Naman Maheshwari Nimblexbox|2023-05-17 15:17:32|You can get GitHub Pro for 12 months here if you're buying it for a startup: https://github.com/enterprise/startups
~ Ridhi Karan|2023-05-17 15:30:55|‎~ Ridhi Karan joined using this group's invite link
Swastik Banerjee|2023-05-17 15:34:08|There is a maximum storage limit
Swastik Banerjee|2023-05-17 15:34:13|/month
Dhruv Anand|2023-05-17 15:35:29|Ok, so 2gb per file
Akash Kuttappa Flipkart PM|2023-05-17 16:06:05|Hey folks,  Akash here from Flipkart Labs where I'm building products across a few emerging tech tracks with Gen AI being one of them. I've been a part of this community for just a day and I really appreciate the conversations and the people behind them. Learning a lot myself and would love to contribute/help in any way possible.
Akash Kuttappa Flipkart PM|2023-05-17 16:06:12|I had a question for the folks working on Stable Diffusion / any diffusion model in a larger org. Most models / the companies behind them don't accept any liability for the images generated from the model and AI copyright is a tricky subject. There have been instances (although a small %) where copyrighted content has surfaced on the generated images (cross-checked with LAION-5B) and this makes working with them a bit hard.   While inpainting use cases are broadly okay on a fine-tuned dataset, outpainting / complete generation of the image wouldn't. I'd only expect companies that have strict control over the pre-trained model data set to be able to consider this. Have any of you come across any company that's accepting liability for their model output or for their services?
Sandeep Srinivasa RedCarpetup|2023-05-17 16:08:11|I follow AI regulations closely.  AI generated images can't be copyrighted. Which will come to mean that they don't enjoy copyright protection. It is still not tested in court, however US PTO has already moved on this.  https://www.artnews.com/art-news/news/ai-generator-art-text-us-copyright-policy-1234661683/
Sandeep Srinivasa RedCarpetup|2023-05-17 16:08:47|These are the regs if u want to read https://www.copyright.gov/ai/  We anticipate Indian copyright law to broadly mirror this.
Nirant|2023-05-17 16:08:53|(deleted my answer because it was wrong)
Sandeep Srinivasa RedCarpetup|2023-05-17 16:11:16|"That said, I know this will be a tricky decision making process for someone like Flipkart to start getting audit clearance to generate AI images/content for products.  I think the best way right now that people are doing is to put a statutory declaration beneath each image ""generated by AI. Report this for copyright infringement"".  That way ur protected by Copyright Safe Harbor provisions rather than any new fangled g generative AI regulations"
Shubham Sharma 2012C6|2023-05-17 16:20:49|Correct me if I am wrong but doesn’t Adobe’s firefly helps you get around any copyright infringement reporting since the dataset is not on infringed content?
Akash Kuttappa Flipkart PM|2023-05-17 16:21:06|Yeah while possible in certain instances, that would be hard to do at scale. Thank you though!
Akash Kuttappa Flipkart PM|2023-05-17 16:25:46|Yes and no,   Yes that they did use adobe stock and not look at other sources such as behance and other products of theirs. This does impact output but it does perform well across certain tracks  No because I remember reading somewhere that the contributors to adobe stock while giving away rights when they submitted weren’t made aware that the images were used for training the model and that the terms weren’t extremely clear. Not entirely sure about this though  Apart from this, it definitely would. Bard went ahead and integrated firefly too but I haven’t been able to use it there ‎[5/17/23, 16:33:26] Akash Kuttappa Flipkart PM: ‎image omitted
Anubhav mishra Zupay|2023-05-17 17:11:47|https://www.sanctuary.ai/
Anubhav mishra Zupay|2023-05-17 17:12:06|AI is at its peak i guess  Classic example of on device AI ‎[5/17/23, 17:25:00] Nirant: ‎image omitted
Nirant|2023-05-17 17:25:48|Question: What are the best FOSS chat models which can be given personality with light finetuning or prompting?
Shalabh Aspiro|2023-05-17 17:26:02|-cries in corner-
Abhinav Verma Longshot.ai|2023-05-17 17:26:25|Wait. Let me try this on my sarcastic chatbot
Abhinav Verma Longshot.ai|2023-05-17 17:26:40|Replicate had one where they trained on Simpsons ‎[5/17/23, 17:32:01] Nirant: ‎image omitted
Shalabh Aspiro|2023-05-17 17:32:50|Does anybody have a viewpoint on this- When does it make sense to give personality traits in the prompt itself vs using constitutional ai to direct the LLM to give responses in a certain style?
Nirant|2023-05-17 17:33:19|Follow up question: What is Constitutional AI?
Swastik Banerjee|2023-05-17 17:33:24|hmmm, seems so: https://docs.github.com/en/billing/managing-billing-for-your-github-account/one-time-payments-for-customers-in-india ‎[5/17/23, 17:34:08] Abhinav Verma Longshot.ai: ‎image omitted
Dev Aggarwal|2023-05-17 17:35:29|Not foss sorry but davinci works better
Nirant|2023-05-17 17:35:33|I am doing this 10 interactions deep. 2-3 interactions is dead easy. Starts breaking the 4th wall about 5-7 interactions deep.   Trying to see if Character.ai has any engineering moat. Doesn't seem like it at the moat.
Sandeep Srinivasa RedCarpetup|2023-05-17 17:36:14|they are prompts which are given as pre-instructions before your actual prompt. they help in safety stuff (like no racist responses, etc etc)
Shalabh Aspiro|2023-05-17 17:36:22|langchain has this to setup a set of principles which the LLM's responses should follow while giving a response. Although it's more so for not giving harmful or unethical responses, I was thinking that can't we use the same stuff for giving personality traits to the LLM as well?  https://python.langchain.com/en/latest/modules/chains/examples/constitutional_chain.html
Sandeep Srinivasa RedCarpetup|2023-05-17 17:36:59|Constitutional AI is by Anthropic
Sandeep Srinivasa RedCarpetup|2023-05-17 17:37:04|https://arxiv.org/abs/2212.08073
Sandeep Srinivasa RedCarpetup|2023-05-17 17:38:04|"FYI - constitutional AI will work very badly on models that are not RLHFed . because it wont know what ""ethics"" is"
Shalabh Aspiro|2023-05-17 17:44:48|someone shared this link on this group itself a few days back- https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids  It says that it's not that the AI doesn't know what ethics is. But knowing about it doesn't force it to give ethical responses because it's not incentivized to be ethical. So even if the model isn't RLHF'ed, won't just asking it to rephrase the response to be more ethical work? I think it would. Not an expert here though- just brainstorming
Sandeep Srinivasa RedCarpetup|2023-05-17 17:56:01|i dont think it says that. it says that if you retrain AI with constitutional AI responses (which are generated themselves from vanilla RLHFed AI), it gives a better Elo score of ethics. Anthropic does a good job of using Elo scoring versus some absolute scale because it is just better than the previous AI...not absolutely ethical on a human scale. ‎[5/17/23, 18:09:54] Shalabh Aspiro: ‎image omitted
Nirant|2023-05-17 18:15:47|If you've any working notebooks for this, please share?
Shalabh Aspiro|2023-05-17 18:24:35|Tinkering with it. Will do soon
Sudharshan GenAI|2023-05-17 18:32:59|Lol
Sudharshan GenAI|2023-05-17 18:33:01|What prompt are you using for this?
Sudharshan GenAI|2023-05-17 18:36:37|Are there any collaborative ChatGPT interfaces?   Multiple users can interact with the same not. Use case is testing out a prompt in my team.
Pratik Bhavasar|2023-05-17 18:50:35|Folks how are you deploying langchain for production chat application? Any great off-the-shelf solution?
Nirant|2023-05-17 18:54:09|Off the Shelf for QA: https://github.com/gmpetrov/databerry  Not built on Langchain though
Nirant|2023-05-17 18:54:40|*Built on LangchainJS, not on Langchain Python
Pratik Bhavasar|2023-05-17 18:57:42|I am looking for multi-message chats which requires state. QA have the freedom to be stateless. I am Python person, so cannot understand this
Pratik Bhavasar|2023-05-17 18:59:55|Any opinions on steamship? https://www.steamship.com/build/langchain-apps
Dev Aggarwal|2023-05-17 19:00:33|What are multi message chats
~ Sushant Kumar|2023-05-17 19:00:56|Is this what you are looking for? https://python.langchain.com/en/latest/modules/memory/getting_started.html
Pratik Bhavasar|2023-05-17 19:01:55|haha.. I mean chat which is multi-turn while QA is just single turn
Pratik Bhavasar|2023-05-17 19:02:59|My question is more around serving  Requirement - hopefully serverless and scalable - chat memory state management (easy if it is just buffer last k chat) - saving chats to DB inorder to do analytics/train - monitoring on chats (can be separate job over saved chats) - more of research question: how to initiate a new chat with same person with context from old chat? Do you just feed summary of past n chats?
Dev Aggarwal|2023-05-17 19:07:35|The new chat models have an option to give a chat history.  Ofcourse you will run out of context length, so you have to truncate it, and optionally summarise whatever you truncate and fit into the context.
Pratik Bhavasar|2023-05-17 19:14:40|If the serving is serverless without state, is it better to send history from client or from a cloud cache like elasticache?
Dev Aggarwal|2023-05-17 19:17:02|The problem with sending state from client is latency over slow networks.  Eg at 4096 tokens you’re looking at about 100kb of data for every request
~ Sushant Kumar|2023-05-17 19:20:18|We built one on WhatsApp using Langchain agents with ConversationBufferWindowMemory which uses Redis for managing the last few messages context window.  - For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states. - In-memory: ConversationBufferWindowMemory - for every ongoing conversation you can have unique key and load that conversation whenever a message from the same user is received from redis. - For persistent storage: Used MongoDB (in our case) for persistent storage.
Dev Aggarwal|2023-05-17 19:21:31|We’re using django & postgres - allows long term storage & you get a free ui for monitoring too.  Instead of langchain, i use a db query to fetch the last X messages
Abhinav Verma Longshot.ai|2023-05-17 19:22:12|ya db query is a similar thought lot of people have
Dev Aggarwal|2023-05-17 19:25:47|You do have to do a bit of post maths after the query to figure out exactly how many tokens each msg is and fit accordingly
Sandeep Srinivasa RedCarpetup|2023-05-17 19:26:42|>For a serverless and scalable architecture, we used FastAPI, which allowed us to easily manage chat memory states.  could u elaborate this a bit more ? how does fastapi help with chat memory states ?
~ Ankit Jain|2023-05-17 19:31:46|I tried doing this for a chat bot, but did not find a way in langchain to persist summary along with buffer. So ended up implementing something like ConversationSummaryBufferMemory but where both Buffer and Summary were persisted in PG. Ended up writing my own python script.
~ Amogh|2023-05-17 19:32:08|‎~ Amogh joined using this group's invite link
~ Sushant Kumar|2023-05-17 19:38:46|RedisChatMessageHistory which was the ChatMemory that we used in our ConversationSummaryBufferMemory (langchain classes) has a field called session_id.  In our case of WhatsApp, the phone_number quite conveniently became a unique identifier and hence the session_id which helped us maintain chat memory states as it remained constant across multiple messages (each whatsapp_message is a webhook request) from the same person. Also, we used langchain because there were multiple other tools of langchain involved in our case.  As for the FastAPI bit, I meant to imply that FastAPI was the way we achieved it but other web-frameworks (including Django) should also be able to achieve that.
Dev Aggarwal|2023-05-17 19:40:54|I use both fastapi & django, deadly combo 🫣
Dev Aggarwal|2023-05-17 19:41:31|Do you configure redis to have aways on disk writes?
~ Sushant Kumar|2023-05-17 20:00:19|For us, it’s just an in memory store - so we don’t do disk writes there. For persistent storage, we store the chats in mongodb.
Dev Aggarwal|2023-05-17 20:00:55|And load from mongo to redis on server restarts?
~ Sushant Kumar|2023-05-17 20:02:46|Still need to implement this! 😅
Dev Aggarwal|2023-05-17 20:04:18|Curious why you wouldn’t just use mongo here
Dev Aggarwal|2023-05-17 20:04:32|Do you have that level of scale where mongo db won’t hold up
Dev Aggarwal|2023-05-17 20:05:54|Discord for eg used mongodb until a 100 million msgs https://discord.com/blog/how-discord-stores-billions-of-messages
~ Sushant Kumar|2023-05-17 20:09:34|We are using a managed redis so we didn’t accommodate for edge cases such as a redis restart.  Web server restarts wouldn’t matter since the state is anyways managed in redis which is not on the same server.
Pratik Bhavasar|2023-05-17 20:18:40|What does FastAPI has to do with serverless?
Lalit Pagaria|2023-05-17 20:38:38|I think now they moved to Scylla DB. Which is way better than Cassandra. https://www.scylladb.com/
~ RISHAV|2023-05-17 20:45:15|That's a great combination.   Just curious, what type of retriever are you using? Are you using the Langchain retrievers or something else.  Context -: Me and Sushant are collaboratively developing the chatbot.
Dev Aggarwal|2023-05-17 20:52:24|Retriver for the documents? np.array & cosine similarity
Nirant|2023-05-17 20:59:11|Chad.
Nirant|2023-05-17 20:59:25|What is next? You implement in numpy too?
Abhinav Verma Longshot.ai|2023-05-17 21:01:33|Cosine similarity ko NP.dot over unit vectors coz you know... Chad
Dev Aggarwal|2023-05-17 21:04:10|Appx Nearest neighbors and imagebind
Dev Aggarwal|2023-05-17 21:05:25|Numpy I trust 😂
~ RISHAV|2023-05-17 21:07:26|That's great... 😅  For simplicity we went with Weaviate.
Nirant|2023-05-17 21:07:51|"That word simplicity in that sentence is like, ""What am I doing here?"""
Sourasis Roy|2023-05-17 21:09:27|😅
Dev Aggarwal|2023-05-17 21:13:20|Curious - are mordern vector dbs just in memory stores? Or do they implement vector search using clever indexes so they dont have to load everything into ram
Abhinav Verma Longshot.ai|2023-05-17 21:14:48|They implement techniques like hnsw. They optimize for speed and lose a little bit in accuracy
~ Abhiram Ravikumar|2023-05-17 21:21:36|Has someone built a model to summarize conversations in this chat group?  So many interesting convos but no time to process em tbh 🤯  Something like a Daily Digest? 😅
Nirant|2023-05-17 21:22:05|You can see some of the community discussions here: https://nirantk.com/ai
~ RISHAV|2023-05-17 21:22:44|Question -: Anyone tried implementing self query retriever from Langchain.   Feature -: It retrieves documents from a VectorDB and then applies filter on the metadata according to the query.  Issue -: Many a time it is generating filters which has a  metadata that is not in the document.
Nirant|2023-05-17 21:25:13|Are you talking about this?  https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/self_query_retriever.html  I've tried this — I suspect that your issue is not fixable via Langchain constructs.
Abhinav Verma Longshot.ai|2023-05-17 21:26:07|What metadata are you storing? If you can share some
Ashfakh GenerativeAI WA Group|2023-05-17 21:26:18|Did you try incontext learning? As in give an example of filters in the prompt?
Nirant|2023-05-17 21:27:02|If you want to filter on metadata in some way, Llama Index has native support for that: https://gpt-index.readthedocs.io/en/latest/how_to/query/second_stage.html  I've tried that also, and it works. Here is a working nbs: https://github.com/NirantK/wip/blob/main/nbs/
Ashfakh GenerativeAI WA Group|2023-05-17 21:27:13|Alternatively you can use this  https://github.com/1rgs/jsonformer  This adheres to the schema you specify
~ RISHAV|2023-05-17 21:28:26|Metadata example -: 'area', 'price', 'locality', .... More 3 are there
Abhinav Verma Longshot.ai|2023-05-17 21:33:14|You can use the above solutions mentioned, or you can keep the ones you know it's getting wrong as a parameter that you receive for your function /api
~ RISHAV|2023-05-17 21:38:20|Self query retriever uses Langchain construct and this is forming a wrong query that is being applied to the document.
Abhinav Verma Longshot.ai|2023-05-17 21:54:50|Is it just me or is gpt4 been having a lot of issues full day. Lots of failures
~ RISHAV|2023-05-17 21:57:49|Yes same issue we are facing.
Anubhav mishra Zupay|2023-05-17 21:59:04|The python package that returns response of Google Bard through API.  pypi.org/project/
Anubhav mishra Zupay|2023-05-17 21:59:21|https://github.com/dsdanielpark/Bard-API
Anubhav mishra Zupay|2023-05-17 22:01:10|Anyone tried it? How's the response ?
~ Nikhil|2023-05-17 22:49:16|I have been playing around with langchain document loaders and some of these loaders are quite limited. For example, the Arxiv loader has a limit of max 4000 characters. To embed documents from arxiv, I am resorting to using a PyPDFLoader and then splitting the document using a splitter and then creating embeddings.  The question really is - people who are creating embeddings, are the default loaders good enough or do you end up writing your own loaders/use other libraries?
Dev Aggarwal|2023-05-17 22:49:54|Own regexes 🫣😭
~ Nikhil|2023-05-17 22:51:26|Not the reply that I was hoping for :P
Rohit Aggarwal|2023-05-17 22:53:54|+1, For arxiv documents specifically - I've written a lot of code to extract text from PDF and then removing unusable pieces & even using font variations to split properly.
Rohit Aggarwal|2023-05-17 22:56:27|I use something like this - https://gist.github.com/roh26it/d1d7af2432175b443355990ec640b1d5  Not sure if this helps though
Rohit Aggarwal|2023-05-17 23:02:44|has anybody tried better prompts for paper summarisation? The base Langchain ones haven't worked for me for text other than state of the union or pg essays :P
Sidhant Sequoia|2023-05-17 23:05:06|Some things only work on Pg essays…
Rohit Aggarwal|2023-05-17 23:05:54|haha, this is how we've all internalised his essays now :)
Nirant|2023-05-17 23:06:26|Doing things that don't scale xD
Nirant|2023-05-17 23:07:46|Hmm, elicit.org has amazing paper summarisation output. I've no idea what magic they do, but their beta is rad. I've abandoned my toolchain completely for wide paper reading (surveys) and single both.
Ashfakh GenerativeAI WA Group|2023-05-17 23:18:14|Default loaders are decent, but a bit of pre processing is always good. Like use pyPDF for loading, but remove new lines and extra spaces by using TextPreProcessors. That saves embedding cost and has not much perf difference for retrieval.  On top of that, I really liked the gpt-index implementation of TreeIndex, the search in that when you’re breaking down big docs gives very good results. But it’s not performative enough due to multiple LLM calls. Thinking of a graphdb implementation of this, would love to collaborate if someone else is also interested.
~ Ankit Sharma|2023-05-17 23:22:37|https://blog.google/technology/developers/google-colab-ai-coding-features/  Google is adding Codey inside Google Colab!! ‎[5/17/23, 23:22:40] Dev Aggarwal: ‎image omitted ‎[5/17/23, 23:46:49] Nirant: ‎image omitted
Rohit Aggarwal|2023-05-17 23:47:59|“We’re not planning to train GPT-5 for the next 6 months”  https://twitter.com/theturingpost/status/1658826361245675525?s=46  (Not sure if this was already discussed)
Dev Aggarwal|2023-05-17 23:49:16|Yeah cause gpt4 is so big that it can remember everything their human ops team teaches it for the next 6 months 😂
Nirant|2023-05-17 23:49:45|This indicates that they've already trained GPT5. Not the other way around.
Soumyadeep Mukherjee|2023-05-17 23:49:55|GPT5 feels like Bahubali 2 to me now.
Aashay Sachdeva MPL Data Scientist|2023-05-17 23:51:57|In Khan academy demo they mentioned they got access last year to gpt-4, so the actual state of the art must be way ahead?
Rohit Aggarwal|2023-05-17 23:52:26|I fear that might nuke GPT capabilities and only allow some sort of licensed usage given the tone of discourse here. They did this with GPS a long time back when the precision tech was only allowed to be used by the military
Samhan Meta/Twitter Friend|2023-05-17 23:53:04|Yeah but we don’t need satellites to recreate these things. GPU farm is enough
Samhan Meta/Twitter Friend|2023-05-17 23:53:21|And you can steal the satellites you can copy the weights
Samhan Meta/Twitter Friend|2023-05-17 23:53:26|*cant
Samhan Meta/Twitter Friend|2023-05-17 23:53:33|All these are doomed to fail
Rohit Aggarwal|2023-05-17 23:53:40|For something like GPT-4, we might need human farms more than GPU farms 😅
Samhan Meta/Twitter Friend|2023-05-17 23:53:51|Also available. India is human farm
Abhinav Verma Longshot.ai|2023-05-17 23:53:58|Yep. This is needed
Rohit Aggarwal|2023-05-17 23:54:25|Arre Arre Arre! 🤣
Samhan Meta/Twitter Friend|2023-05-17 23:55:38|Get all the unkils labeling data on their WhatsApp you’ll have data you need in few days
Samhan Meta/Twitter Friend|2023-05-17 23:56:13|But jokes apart this legit is a huge advantage we have if we use it well
Dev Aggarwal|2023-05-17 23:57:00|Expensive one, philipines is cheaper ‎[5/17/23, 23:57:25] Dev Aggarwal: ‎image omitted
Samhan Meta/Twitter Friend|2023-05-17 23:57:48|JioGPT - get ppl in villages to label stuff on their Jio phone
Abhinav Verma Longshot.ai|2023-05-17 23:58:06|but if you have to make indicGPT then you need people in india
Dev Aggarwal|2023-05-17 23:58:37|your ai has the median intelligence of your labeller
Abhinav Verma Longshot.ai|2023-05-17 23:58:55|GPT is bad at math. go figure
Samhan Meta/Twitter Friend|2023-05-17 23:59:01|Harder part will be RLHF to make sure it doesn't piss of politicians
Samhan Meta/Twitter Friend|2023-05-17 23:59:47|But making like a Government GPT that can do all your taxes , forms , aadhar etc is actually a very good idea imo
Abhinav Verma Longshot.ai|2023-05-18 00:00:04|bhaiyo, behno , mai ek bhaasha model hu, scam mai nahi karta
Samhan Meta/Twitter Friend|2023-05-18 00:00:12|You can nuke bureaucracy on a massive level
Anubhav mishra Zupay|2023-05-18 00:00:21|Is someone making BharatGPT ,?
Anubhav mishra Zupay|2023-05-18 00:00:26|I think i read somewhere
Aashay Sachdeva MPL Data Scientist|2023-05-18 00:00:33|Ai4bharat is
Samhan Meta/Twitter Friend|2023-05-18 00:00:34|Someone ask Nandan
Aashay Sachdeva MPL Data Scientist|2023-05-18 00:00:51|I also tried my training via lora on their dataset
Samhan Meta/Twitter Friend|2023-05-18 00:00:55|Aadhar authenticated plugins for all your govt work
Abhinav Verma Longshot.ai|2023-05-18 00:01:03|we need bureaucracy. just a little more efficient. bureaucracy chahiye democracy mai. otherwise it just becomes authoritarian completely.
Samhan Meta/Twitter Friend|2023-05-18 00:01:05|Payment via UPI
Anubhav mishra Zupay|2023-05-18 00:01:41|https://corover.ai/bharatgpt/
Anubhav mishra Zupay|2023-05-18 00:02:19|India should do something about this whole AI, it's an opportunity
Abhinav Verma Longshot.ai|2023-05-18 00:02:55|plus, this might be a double edged sword but flexible regulations will help here
Abhinav Verma Longshot.ai|2023-05-18 00:03:22|there's a lot of red tape for models like MPT etc being released as commerical in US instead of plain open source
Anubhav mishra Zupay|2023-05-18 00:03:45|In 2021 they had this DEEPMAX framework to evaluate AI and all an India framework, the whole licence system was talked about
Samhan Meta/Twitter Friend|2023-05-18 00:03:53|IndiaStack should train foundation models
Anubhav mishra Zupay|2023-05-18 00:04:06|But i think the tech wasn't sophisticated back then, but it's now
Anubhav mishra Zupay|2023-05-18 00:05:03|Koo launched one i guess,   But it's not foundational it's trained and fine tuned on BERT
Samhan Meta/Twitter Friend|2023-05-18 00:05:11|Make govt apis available for plugins allow third parties to build and iterate UPI style
Anubhav mishra Zupay|2023-05-18 00:05:12|they call it kooBERT
Nirant|2023-05-18 00:06:28|cc Harsh [PHONE] is the Head of ML at Koo
Anubhav mishra Zupay|2023-05-18 00:08:02|Koo you guys should make a foundation model, ditch the gov   We should have vernac models come out of India 😃
~ Ravikant|2023-05-18 00:09:37|https://caryn.ai/
~ Ravikant|2023-05-18 00:09:51|does anyone have  any idea to create a similiar bot like this ?
~ Ravikant|2023-05-18 00:10:11|where the the voice can also be cloned ? ‎[5/18/23, 00:36:33] Nirant: ‎image omitted ‎[5/18/23, 00:36:34] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-18 00:37:20|Noob question? What kind of data is in the medQA dataset
Abhinav Verma Longshot.ai|2023-05-18 00:37:36|like is it general medical QA
Abhinav Verma Longshot.ai|2023-05-18 00:37:56|or like stuff on more advanced diagnosis
Nirant|2023-05-18 00:40:29|Mixed. It's based on USMLE — It's an exam you've to give to become a doctor in US
Abhinav Verma Longshot.ai|2023-05-18 00:41:05|Interesting ‎[5/18/23, 00:41:07] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-18 00:42:01|I think LLMs will raise the standard of competency needed for the job
Antidentite Paritosh Bola.ai|2023-05-18 00:56:08|pretty cool, but Palm 2 is only available on private beta right now, correct?
Antidentite Paritosh Bola.ai|2023-05-18 00:56:46|and i presume it also has the limit that open ai has with 4097 tokens, makes it harder to parse data, otherwise have to divide the data and stream which makes it more challenging
Dhruv Naik|2023-05-18 01:15:00|The bison api on par with gpt3.5 based on personal experience, but not as good as gpt4.  Bison's context length is 4096 + 1024, so slightly better than gpt3.5 there
~ Vik|2023-05-18 01:37:12|i built 42papers.com but it's aimed at quick scanning daily
~ Vik|2023-05-18 01:38:11|also a side project so working on improving things it's a spider+gpt4+staticsite
~ Ankit Jain|2023-05-18 02:16:28|text-bison@001 has 8192/1024
~ Ankit Jain|2023-05-18 02:17:01|chat-bison is 4096/1024
Dhruv Naik|2023-05-18 03:03:34|Ah right, they updated token limit for text api this month
Jay Pokarna 2014 BPCC|2023-05-18 08:33:38|Blinkit has started using gen AI to make receipes automatically. They are directly showing it to customers. Also, generates images using midjourney : https://twitter.com/albinder/status/1658821632008523777?cxt=HHwWgsDQmYnfqIUuAAAA
Paras Chopra Wingify|2023-05-18 08:49:18|They use a custom model   This is an old one but more or less this workflow https://ought.org/updates/2022-04-25-responsibility
Paras Chopra Wingify|2023-05-18 08:50:18|Play.ht but don’t know the legality of it
~ Nikhil|2023-05-18 08:55:17|Can one of admins please add my colleague `+91 77605 75030` to this group?  Cannot find the invite link to this group anymore.
Ojasvi Yadav|2023-05-18 09:01:20|Done
~ Harshith|2023-05-18 09:01:31|‎Ojasvi Yadav added ~ Harshith
Dr. Pratik Desai KissanGPT|2023-05-18 09:15:07|https://github.com/justinjohn0306/so-vits-svc-4.0
Gayathri Meka Hyperverge|2023-05-18 09:58:46|Has anyone tried this out: https://www.tutory-ai.com/ Not sure if it has been posted already
~ Vipul|2023-05-18 10:08:59|If I have multiple txt files containing information about people, each txt is one person and my usecase is to describe a person and find the most relevant one.. How should I go about it?  I can create embeddings of those txt files and do a semantic search and get the source docs..  My question is, what would be a more efficient way of doing it, creating different indexes for each txt in a vector db(sounds overkill to me tbh) or put everything in a single index, but will that create issues if you have a lot of files? ‎[5/18/23, 10:11:26] Nirant: ‎image omitted
Sourasis Roy|2023-05-18 10:11:35|Llamaindex will be easiest place to start
~ Vipul|2023-05-18 10:12:20|Ohh, I sound stupid now, haha🥲
Nirant|2023-05-18 10:14:11|Nahi nahi.   You'd be a bad engineer if you hadn't asked  This degree of compression was not widely or commercially available till 2019-2020. It is not your day job to keep track of this tech!  Always ask! 🙌
Nirant|2023-05-18 10:19:50|I'm not able to find them on plugins even
Paras Chopra Wingify|2023-05-18 10:36:04|Just out it curiosity - anyone here / in India doing research towards AGI?  (I know AGI isn’t well defined, I mean it in Carmac/OpenAI sense)
Yash Pandya|2023-05-18 10:42:14|"""AGI is a feeling. Like love. Stop trying to define it."" - Andrej Karpathy"
~ Abhiram Ravikumar|2023-05-18 10:43:45|Everyone has their own definitions of AGI, but this iisc research group has a few worthwhile projects n publications in the area  https://ai.iisc.ac.in/
Sidhant Sequoia|2023-05-18 11:21:00|If anyone's used the GPTeam repo extensively lmk. Having some weird issues running it locally, which start after a few mins of successful agent communication. Will DM for help.
Nirant|2023-05-18 11:28:36|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"" ‎[5/18/23, 11:33:23] Sidhant Sequoia: ‎image omitted"
Maneesh 2013|2023-05-18 11:37:04|I'm trying to create multiple NLAToolkits (fancier API Toolkit for using natural language), using multiple openapi jsons, and pass these to a single agent. This is to automate and chain some REST queries. The issue is that individually each of these jsons are very long, so the token length is exceeding with just a single NLAToolkit (and hence a single json), let alone multiple.  Has anybody tried using a vector DB to do a lookup on which end point to call from a json? What would be the recommended way to implement something like this?
Raghotham Paypal Bargava's Friend|2023-05-18 11:41:42|This is a general problem with LLM output formatting. I have faced similar issues. It is also random at times. I wrote a custom output parser and retry parsing with some formatting in place
Raghotham Paypal Bargava's Friend|2023-05-18 11:42:44|https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html
Nirant|2023-05-18 11:42:53|Don't tell this to anyone, but this is why projects like guardrails.ai are good. JSONDecodeError is the Blue Screen of death of 2023.   https://shreyar.github.io/guardrails/
Nirant|2023-05-18 11:43:30|Do you mean something like this? https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443 (paywall)
Raghotham Paypal Bargava's Friend|2023-05-18 11:45:35|Not always an issue with json type data. Happens with agents with some expected format as response.
Lavish 2017|2023-05-18 11:45:48|+1 to guardrails. I've this running as my json extracter in two projects on prod.  although I recommend deeply looking into the exact implementation and then deciding for your use case if this prompt make sense else write a smaller version of guard rails ai for saving on tokens with linter and retries with a different lenthier prompt -- this is what I've done in one.
Raghotham Paypal Bargava's Friend|2023-05-18 11:46:07|Conversational agent expects a response starting with Thought or AI.  Sometimes LLM doesn't output in that format.
~ Akhil Sajeev|2023-05-18 11:46:46|‎~ Akhil Sajeev joined from the community
Abhinav Verma Longshot.ai|2023-05-18 11:46:53|Where can you apply for access for the apis?
Maneesh 2013|2023-05-18 11:56:51|"Not exactly. So this would work really well for qa retrieval over a simple text doc, right?  But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble. Also NLAToolkit is useful because I can say something like ""what is my most played song in my top Playlist"" and it'll automatically resolve it to Spotify Tool and  find the appropriate endpoints to call and populate with the right parameters as well (all of these endpoints and descriptions are internally passed as input in the prompt, which causes the token limit to blow up)  I imagine a json agent can't do this natural language interpretation.  So i was wondering what would be the best way to do this.  Please correct me if there are any incorrect assumptions here"
Nirant|2023-05-18 12:00:10|> But when your doc is an openapi spec json with lots of endpoints and relatively vague descriptions, the retrieval from DB for a given query seems to stumble.  Stumble as in? Bad recall? Bad precision, since it's Top 1? What is breaking here?
Nirant|2023-05-18 12:01:15|And just to zoom out a bit, this is an empirical domain, not intuitive or theory (and definitely not in the _best practices_ era) —  so whatever solutions we share have a half life of max 6 months
Maneesh 2013|2023-05-18 12:12:16|Yeah that's fair. I was just wondering if anyone has worked with something like this before, so I could leverage those learnings
Maneesh 2013|2023-05-18 12:13:30|So when you query the DB for a semantic match, it often throws up a completely irrelevant endpoint to the task. Sometimes even from the wrong tool
Sandeep Srinivasa RedCarpetup|2023-05-18 12:17:28|have u tried jsonformer or RELLM ? would love to know ur opinion
Azhan Mohammed Generative AI WhatsApp Group|2023-05-18 12:19:12|Not related to generative AI, but NLP  Has anyone worked in multimodal classification? Planning to work on Multimodal Hate Speech Event Detection Shared Task CASE@RANLP2023, and the task involves figuring out whether a text embedded image contains hate speech or not. Last time I worked on a similar task, it contained text and images separately, so I took a combination of ULMFiT and VGG 19, to get a combination of embeddings and use them to classify. Could a similar approach work here? My plan is to extract text from the image, and then recreating the above pipeline. Would that work, or if anyone has any other suggestions, can we discuss that in detail.
Nirant|2023-05-18 12:19:32|ReLLM and JSONFormer ideas are now both part of Guardrails as a lib now?   cc Shreya [PHONE] from Guardrails is here too :)
Sandeep Srinivasa RedCarpetup|2023-05-18 12:20:27|Oh I didn't know that. Intresting
Sandeep Srinivasa RedCarpetup|2023-05-18 12:20:48|Which one of the two works better in general?
Nirant|2023-05-18 12:20:56|I am also asking, I saw a discussion around this. ReAsk is definitely there. I've used it ‎[5/18/23, 12:22:43] Shashank Generative AI Group: ‎image omitted
Samhan Meta/Twitter Friend|2023-05-18 12:23:25|RLHF Karna padega 😁
Lavish 2017|2023-05-18 12:27:45|I've not fully read it through.  btw I've a catch all after two retries to pick the stuff inside ```  I've seen 0 errors on not being able to pick json with this catch all + import gd so far but will explore jsonformer for sure
Nirant|2023-05-18 12:29:35|FYI, Rohit [PHONE] and I were discussing this. Looks like JSONFormer doesn't work with OpenAI Chat models (3.5-Turbo and GPT4) because they have a logit bias while JSONFormer uses Logits.
Dev Aggarwal|2023-05-18 12:31:00|Mid journey how??
Nirant|2023-05-18 12:31:50|Unofficial APIs perhaps? https://midjourneyapi.io/
Dev Aggarwal|2023-05-18 12:33:03|Wow, and is this using a discord bot to get the image from mj discord bot? 😂 ‎[5/18/23, 12:33:51] Dev Aggarwal: ‎image omitted
~ Vinoj|2023-05-18 12:35:13|‎~ Vinoj left ‎[5/18/23, 12:35:38] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-18 12:36:48|Ok albinder definitely needs to have a chat with his team before tweeting
Anubhav mishra Zupay|2023-05-18 12:37:23|LOL
Dev Aggarwal|2023-05-18 12:38:40|https://blinkit.com/blog/recipe-rover  Their coders look much smarter
Shreya Rajpal Guardrails|2023-05-18 12:39:56|Yep! I’ve been planning on adding constrained decoding for general grammars in guardrails. As a developer, different techniques are better for different use cases. constrained decoding introduces some latency which may not be worth it if you can use few shot examples to get the right json (which is Guardrails’ current approach). It also doesn’t work for OpenAI’s newest models, Anthropic or Cohere.
Nirant|2023-05-18 12:42:26|What breaks Cohere?
Shreya Rajpal Guardrails|2023-05-18 12:49:51|No access to logits
Nirant|2023-05-18 12:50:22|I didn't know that they removed logits too 😔
Abhinav Verma Longshot.ai|2023-05-18 12:50:27|This would break in the chat models as well I think
Shreya Rajpal Guardrails|2023-05-18 12:51:16|Yeah I think this may have been recent. They updated a few of their models
Samhan Meta/Twitter Friend|2023-05-18 12:52:38|"I think OpenAI is working on their own language called ""ChatML"""
Abhinav Verma Longshot.ai|2023-05-18 12:53:12|-yeah. New models. Much better at RAG.
Samhan Meta/Twitter Friend|2023-05-18 12:53:47|To do this quickly and with generality you need to be able to send a custom sampling algorithm to the api provider. It will turn into a programming language eventually 😁
Nirant|2023-05-18 12:54:48|All roads converge to a Programming language. At this point, both TF and PyTorch are programming language pretending to be a framework anyway
Samhan Meta/Twitter Friend|2023-05-18 12:55:02|I have a feeling a simpler trade off is to just use regexes. 😁
Samhan Meta/Twitter Friend|2023-05-18 12:55:34|Higher level framework can compile into regexes and send to backend provider. Regexes are very easy to support
Samhan Meta/Twitter Friend|2023-05-18 12:56:22|Perhaps a slight syntax tweak to control temperature etc for each regex.
Samhan Meta/Twitter Friend|2023-05-18 12:57:21|Context free grammar etc is cool but most specific JSON you need can be expressed as key , value regex.
Dev Aggarwal|2023-05-18 12:57:23|https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags ‎[5/18/23, 12:57:27] Dev Aggarwal: ‎image omitted
Samhan Meta/Twitter Friend|2023-05-18 12:58:21|I know this but this answer is misleading. Yes regex cannot parse it in general. But for specific scenarios they can work. And we are often trying to generate some specific and simple JSON
Samhan Meta/Twitter Friend|2023-05-18 12:58:37|I have parsed HTML using regex many times 😁 ‎[5/18/23, 12:58:47] Nirant: ‎image omitted
Samhan Meta/Twitter Friend|2023-05-18 12:59:08|Yes this . “Worse is better” Unix philosophy of design.
Sandeep Srinivasa RedCarpetup|2023-05-18 12:59:51|it seems to me that openai wants us to have less access to logits, etc and wants to do everything via few shots. is that what u would guess ?
Samhan Meta/Twitter Friend|2023-05-18 13:01:39|Logit sharing is more high level. You cannot constrain in the middle of a generation unless you call the API many many times for even simple things. So it’s probably not the way for JSON etc. you need some way to share a grammar , regex , program
Samhan Meta/Twitter Friend|2023-05-18 13:01:54|It just adds too much latency and cost
Samhan Meta/Twitter Friend|2023-05-18 13:03:03|This is also an advantage of open models. You can do lot of innovation around sampling
Sandeep Srinivasa RedCarpetup|2023-05-18 13:03:16|fair point. cost is always a thing.
Sandeep Srinivasa RedCarpetup|2023-05-18 13:04:17|but i think in the long run, having a custom NER model doing the extraction might be the best tradeoff of cost vs accuracy. dont bring in the LLM at all.
Samhan Meta/Twitter Friend|2023-05-18 13:05:24|Yes so the way I try to explain this to ppl is  1. LLM as fast prototyping tool for ML 2. Prove business value 3. Extract production data / LLM data 4. Train a smaller model for the specific task  This could be a common pipeline
Samhan Meta/Twitter Friend|2023-05-18 13:06:02|Earlier it was hard to tell if ML had business value because each model for a task was expensive. Now you can find PMF quickly and then optimize
Samhan Meta/Twitter Friend|2023-05-18 13:06:29|Infra around this is an excellent startup idea if anyone is looking 😁
Samhan Meta/Twitter Friend|2023-05-18 13:07:25|Sandeep eager to hear your thoughts on this
Amal David Futuryze|2023-05-18 13:09:42|Has anyone here stumbled across any projects which does federated decision making by multiple role playing agents?  Something similar to this paper https://arxiv.org/abs/2303.06109
Sainath GenerativeAI WhatsApp Group|2023-05-18 13:34:12|Looking for suggestions on opensource models that are good at writing sql queries based on provided question and schema. Has anyone worked on this? I am looking for collaborations as well if anyone interested.
Abhinav Verma Longshot.ai|2023-05-18 13:50:00|Anyone who did computer science in college. There was a course, theory of computation. And it basically started with every language started as something similar like just regex
Abhinav Verma Longshot.ai|2023-05-18 13:50:45|To note. The udacity course on this was much better
Aditya Agrawal SuperU|2023-05-18 14:55:47|What is the biggest GPU size you guys have used for training/fine tuning model? We are using 64GB and still running out of memory. Would highly appreciate any help in the regard .
Prayank Swaroop Accel|2023-05-18 14:59:44|Which model are you training ?
Aditya Agrawal SuperU|2023-05-18 15:00:08|Lora Adapter
Shreya Rajpal Guardrails|2023-05-18 15:03:55|not tested with open source models, but there's guardrails for sql generation that perform validation for a specific db schema and have a few other tricks for good performance http://getguardrails.ai/use_cases/text2sql/text2sql/
Aditya Agrawal SuperU|2023-05-18 15:24:42|Which is supposed to be super super small but dont know whats wrong.
~ Karan Gandhi|2023-05-18 15:36:12|Hey!   I couldn’t find the invite link to this group, can +91 97413 54623 be added ?
~ Kp|2023-05-18 15:37:59|‎Ravi Theja added ~ Kp
~ Karan Gandhi|2023-05-18 15:38:48|Thanks!  [PHONE]
Dhruv Anand|2023-05-18 16:02:50|Hey, is there anyone here who can help with converting a vision transformer model to tflite?
Shimanta Generative AI|2023-05-18 16:35:03|When I am using ChatGPT from the website(free version), I see that the url is this: https://chat.openai.com/?model=text-davinci-002-render-sha Does this mean that it’s using davinci model and not the gpt-3.5-turbo model which the chatgpt api uses?
Nirant|2023-05-18 16:48:44|PSA: Please DM mods for Invite links instead of sharing phone numbers of your friends. If you do that, I'll add your friend's number to Bajaj Finance, Yes Bank, Policy Bazaar.
~ Vipul|2023-05-18 16:49:00|I'm able to do this with Llamaindex, though I can't seem to find a way to output the name of the source file(not the node) with the response, anyone knows how that's done in Llamaindex? I basically need a ranking of files based on relevancy on the query string 🤔
Ravi Theja|2023-05-18 16:50:49|I think this blog might be useful for you - https://medium.com/llamaindex-blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6
Nirant|2023-05-18 16:51:03|Do you just want relevancy scores or an answer?   If you just need relevancy scores, do you want to just use a Vector DB client direcly?
Nirant|2023-05-18 16:51:11|No need to touch Llama Index or Langchain
~ Sushant Kumar|2023-05-18 16:53:52|https://github.com/saschaschramm/chatgpt#gpt-35
~ Vipul|2023-05-18 16:55:11|Just relevancy scores
Shimanta Generative AI|2023-05-18 16:57:05|So it is different from what’s provided through the api? (GPT 3.5 vs GPT 3.5 Turbo) Do you happen to know about any major differences as well?
~ Sushant Kumar|2023-05-18 17:06:46|Only as much as is mentioned there in the link:  *Max tokens limit are different for them*: GPT 3.5 = 8191 tokens GPT 3.5 Turbo = 4096 tokens  And that GPT-3.5-turbo HumanEval scores are better than that of GPT 3.5
Shimanta Generative AI|2023-05-18 17:07:11|Got it, thanks!
~ Nijil Y|2023-05-18 18:57:40|Anyone working here on gpt 4 api, could you help me with right max_token value which will make it generate the longest possible response without hitting error. I see the it's sum of input plus output. But the documentation is a bit unclear on limits..
Dhruv Naik|2023-05-18 18:59:19|8096 for input + output tokens
Dhruv Naik|2023-05-18 18:59:34|32k if you have access to that version
~ Nijil Y|2023-05-18 19:00:52|Giving 8k as max token errors out if I want to generate a 3k word story. With a input in 2 lines.
Abhinav Verma Longshot.ai|2023-05-18 19:01:26|2k output. Over that errors can occur
Abhinav Verma Longshot.ai|2023-05-18 19:02:24|If you want a lot of output you need to be creative. But at one go it hangs over 2k output and timeout after 4k output tokens
Dev Aggarwal|2023-05-18 19:02:27|You have to calculate the input size using tiktoken, subtract it from 8k/4k
Dev Aggarwal|2023-05-18 19:03:05|Interesting - on the streaming api too?
~ Nijil Y|2023-05-18 19:03:19|Oh dint know this. Same rule for 32k?
~ Nijil Y|2023-05-18 19:03:24|Not to mention horribly slow
Abhinav Verma Longshot.ai|2023-05-18 19:03:30|This too. Also you need to take into consideration that one token is different in different languages
Abhinav Verma Longshot.ai|2023-05-18 19:03:37|Yes
Dev Aggarwal|2023-05-18 19:03:50|Yup, cause the limit is for input + output. So if your input is big, then it will throw an error
Dhruv Naik|2023-05-18 19:05:04|It takes ~50x time to generate a token than ingest an input token
Dev Aggarwal|2023-05-18 19:05:28|Similar findings
Dev Aggarwal|2023-05-18 19:06:00|Also the more you generate the more you hallucinate
Shan|2023-05-18 19:25:16|Basic question- I want to train a model locally on all my emails and documents. What’s the best way to do it nowadays. Lora? Gpt4all? Something else? I’ve never trained a model locally so I’m a bit uncertain about this. (Also I don’t genuinely care about “worldly knowledge” being part of the model but it doesn’t hurt)
~ Pranav|2023-05-18 19:35:55|https://github.com/imartinez/privateGPT  Came across this recently which might be helpful.
Shan|2023-05-18 19:44:45|Thanks, quite useful. Still, curious if we can train / fine tune a model locally.
~ Revant|2023-05-18 19:45:02|TEAM is organising a Hackathon for GenAI in Mumbai on 3rd and 4th June (Saturday & Sunday) https://www.mumbaihacks.com/register  Sharing for those interested
~ Nijil Y|2023-05-18 19:54:22|Is there any other better option for long form content generation
Abhinav Verma Longshot.ai|2023-05-18 20:00:05|approach in a similar approach to how you would do on the playground
Abhinav Verma Longshot.ai|2023-05-18 20:00:19|continuous generation via different calls
Abhinav Verma Longshot.ai|2023-05-18 20:00:35|but you need to make sure your input+output is between the token limit
Anubhav mishra Zupay|2023-05-18 20:27:11|https://www.cnbc.com/amp/2023/05/18/bilderberg-openai-microsoft-google-join-ai-talks-at-secretive-meeting.html?__source=instagram%7Cmain
Sourasis Roy|2023-05-18 20:49:19|[PHONE] [PHONE]
Dev Aggarwal|2023-05-18 21:06:48|Does anyone know how to force copilot to generate something when you're in the middle of a line / start of a line? It only seems to complete if I'm at the end of a line. ‎[5/18/23, 21:06:52] Dev Aggarwal: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-18 21:07:19|Threaten it 😂 ‎[5/18/23, 21:07:23] Dev Aggarwal: ‎image omitted ‎[5/18/23, 21:08:13] Dev Aggarwal: ‎image omitted ‎[5/18/23, 21:08:31] Dev Aggarwal: ‎image omitted
Shimanta Generative AI|2023-05-18 21:08:33|I think there was a shortcut key for copilot generations, tried it?
Dev Aggarwal|2023-05-18 21:08:44|doesn't generate anything
Aashay Sachdeva MPL Data Scientist|2023-05-18 21:22:08|https://twitter.com/peterjliu/status/1659023597447565312?s=46  RLHF alternative
Nirant|2023-05-18 21:29:05|Ohh one of the co-authors is a college acquaintance, let me ping him!
Dev Aggarwal|2023-05-18 21:30:24|The may not need humans part seems hard to believe
Abhinav Verma Longshot.ai|2023-05-18 21:31:20|I thought RLHF stood for RL with human farms 😂 ‎[5/18/23, 21:33:16] Nirant: ‎image omitted
Dev Aggarwal|2023-05-18 21:46:20|We really need an opensource copilot that works off any llm API key  (use the langchain API wrapper  maybe)
Shimanta Generative AI|2023-05-18 21:48:19|Have you tried Codeium? Not open source though https://codeium.com/compare/comparison-copilot-codeium
Shimanta Generative AI|2023-05-18 21:48:29|I have been using it of late
Shimanta Generative AI|2023-05-18 21:48:53|It has chat in IDE as well
Neeraj Kumar|2023-05-18 22:16:22|Team, validating my following rudimentary understanding of opportunity for any company using LLMs! Can someone help? ----- Foundation LLMs which are trained on large data sets are expensive and only companies like OpenAi, Google are doing. Facebook, AnthropicAi are some others.  For other companies, opportunity is to get access to such LLMs and ingest their own data and context using prompt engg. Techniques, embeddings, etc. This is helping companies solve  productivity use cases such as code suggestion, PR suggestions, summarisation, QnA, etc
Neeraj Kumar|2023-05-18 22:18:05|Is this understanding correct? Opportunity is partner with companies providing trained LLMs and add their own context.
Dev Aggarwal|2023-05-18 22:32:40|Yes, plus collecting human feedback to later pipe back into your data / rlhf
~ Nijil Y|2023-05-18 22:37:07|Anyone used Lang chain or embeddings on bigger text data? How do you pass say 20 pages (or embeddings) from a repo of books to have accurate summarized snippets considering gpt 4 token limit?any other alternatives?
Nirant|2023-05-18 22:39:30|For summarisation, you can consider Map-Reduce/Combine or Refine: You can see some of the community summary here: https://nirantk.com/ai — they're all done that way. You can also create chapter/section specific summaries and concat
Dev Aggarwal|2023-05-18 22:42:27|make sure you respect this limit too
Nirant|2023-05-18 22:43:03|Code for the Langchain summarisation https://github.com/NirantK/nirantk.github.io/tree/main/community_dev
~ Akshit Banta|2023-05-18 22:51:46|Have tried it not even close to Copilot
~ Pradeep Ayyagari|2023-05-18 22:52:10|https://openai.com/blog/introducing-the-chatgpt-app-for-ios  iOS App from openAI
~ Pradeep Ayyagari|2023-05-18 22:52:19|Not available in India still though ‎[5/18/23, 23:03:22] ~ Ankit Sharma: ‎image omitted
Soumendra Dhanee|2023-05-18 23:05:23|Logits would allow others to distill the models, so we should expect them to go away eventually in most commercial LLM APIs which are deemed valuable. OpenAI and cohere have already taken it off the table.
Anubhav mishra Zupay|2023-05-18 23:19:10|Is it possible they might want to do an on-device LLM ?  MLC LLM types ?
~ Kp|2023-05-18 23:20:37|I don't understand why would an iOS app come before an android app :/
~ Pradeep Ayyagari|2023-05-18 23:25:36|“Google” it
~ Kp|2023-05-18 23:26:54|P.S. Android users, you're next! ChatGPT will be coming to your devices soon. Pretty obvious :) (Unless windows phone is making a comeback) ‎[5/18/23, 23:29:47] Ravi Theja: ‎image omitted ‎[5/18/23, 23:30:17] Ravi Theja: ‎image omitted
Satish DeepHack Sponsor|2023-05-18 23:30:59|The IOS app looks bit wonky , the speech recognition is dead , throws error. They could have used iOS's built in recognition ~, but they wanted to use Whisper apparently .
Dhruv Anand|2023-05-18 23:31:16|This never works for me
~ Kp|2023-05-18 23:32:03|2nd point 😂😂
~ Nijil Y|2023-05-18 23:32:03|Also usually ios people are tech deprived. So possibly trying to expose them to new technology 😁. Iphone people please don't take come with pitchforks
Dhruv Anand|2023-05-18 23:32:06|These cases started working for me just a couple of days ago. But I also did move from python to typescript in that time
~ Kp|2023-05-18 23:33:16|More difficult for apps for ios to be approved implies ios app releases first 🥴
~ Kp|2023-05-18 23:35:48|Makes sense ngl
Swastik Banerjee|2023-05-18 23:51:54|[PHONE] any results? ‎[5/18/23, 23:57:15] Dhruv Anand: ‎image omitted
~ Arsalaan|2023-05-19 00:19:41|guys anyone can please guide , which is best Llm for translation task?
~ Rohan|2023-05-19 02:13:31|Detailed report from EU for AI safety standards in aviation: https://www.easa.europa.eu/en/document-library/general-publications/easa-artificial-intelligence-concept-paper-proposed-issue-2 Aviation has historically been an industry with one of the most stringent safety requirements. It's interesting to see their proposed regulations over AI.
Dev Aggarwal|2023-05-19 06:48:55|https://colab.research.google.com/drive/1Icoxgd2IJAjMU2fyD-MET5a706HGpwVg?usp=sharing  Zero dependency code for map reduce
Ravi Theja|2023-05-19 07:02:09|Hey [PHONE],  Self promotion is not allowed as per group community guidelines. Can you please remove the post?
Ankita Mathur Microsoft Sales|2023-05-19 07:06:33|You can try ctrl+enter - this would ideally force it to respond ‎[5/19/23, 07:57:23] Nirant: ‎image omitted
Harsh Gupta Felvin|2023-05-19 07:59:03|Which company?
Ravi Theja|2023-05-19 08:32:57|https://tome.app/ - https://twitter.com/jasonyuandesign/status/1659317627208998914?s=20
~ Akshit Banta|2023-05-19 08:36:02|Seems like he'll bring MercuryOS to life
Jay Pokarna 2014 BPCC|2023-05-19 09:20:17|Have seen this where companies based out of US release their 1st app on iOS than android. E.g. Insta / Snapchat
Dr. Pratik Desai KissanGPT|2023-05-19 09:21:53|It is known statistics here that iOS users pay more. Also, in US they say no one important uses Android. 🤣
Harsh Gupta Felvin|2023-05-19 09:23:28|iMessage is the culprit for it
~ Kp|2023-05-19 09:23:59|But chatgpt is free (or is this a sign) :(((((
Harsh Gupta Felvin|2023-05-19 09:24:22|people text you on imessage (not whatsapp) and make facetime calls
Dr. Pratik Desai KissanGPT|2023-05-19 09:24:28|Get more plus users
~ Kp|2023-05-19 09:24:40|Ah
~ Kp|2023-05-19 09:26:39|Also what's with gpt-4 browsing? Most times I try it says click failed or something like that. Is there a specific way to prompt that model?
Dr. Pratik Desai KissanGPT|2023-05-19 09:26:43|True. Also, general folks care less about installing apks and trust Apple to take care security and privacy.
Dr. Pratik Desai KissanGPT|2023-05-19 09:27:14|robots.txt
~ Kp|2023-05-19 09:27:36|At the current stage a gpt extension on the site is doing better than gpt-4 browsing in terms of summarisation
Dr. Pratik Desai KissanGPT|2023-05-19 09:29:03|They are probably going to remove that bad browsing UX and start indexing like good soon.
Dr. Pratik Desai KissanGPT|2023-05-19 09:29:10|*google*
~ Kp|2023-05-19 09:29:18|Oh. So gpt-4 is crawling sites... wouldn't it get blocked by cloudflares are you human as well
~ Kp|2023-05-19 09:29:31|For those sites where it's enabled?
Dr. Pratik Desai KissanGPT|2023-05-19 09:30:24|They published an article about this recently, you'll have to search Twitter for more details.
~ Kp|2023-05-19 09:31:03|Sure. Thanks!
~ Diksha Barnwal|2023-05-19 10:44:58|‎~ Diksha Barnwal joined using this group's invite link
Anubhav mishra Zupay|2023-05-19 11:07:21|Hi guys, can you share a good resource to understand how to control midjourney. Basically prompting to have specific camera angles, hues, contrast etc etc.
~ Prajna Prayas|2023-05-19 11:17:55|I follow Nick from twitter. He has good command over that
Anubhav mishra Zupay|2023-05-19 11:18:18|Thanks
Aashay Sachdeva MPL Data Scientist|2023-05-19 11:20:14|Profile pls
Yash Pandya|2023-05-19 11:24:59|https://twitter.com/nickfloats?s=21&t=slFa1z9kP5GT6uvB_oz7cw
Akash Kuttappa Flipkart PM|2023-05-19 11:25:31|https://docs.google.com/spreadsheets/d/1MsX0NYYqhv4ZhZ7-50cXH1gvYE2FKLixLBvAkI40ha0/edit#gid=0  I have one for V4, but Nick does have a lot more covered for the more updated versions too - 5 and 5.1
Anubhav mishra Zupay|2023-05-19 11:26:13|Great thankyou
Akash Kuttappa Flipkart PM|2023-05-19 11:27:16|https://docs.midjourney.com/docs/prompts  Their docs do cover all the basics and the public prompts on discord will help you shape your own along with the above resources
Shashank Generative AI Group|2023-05-19 12:10:00|Nick's threads are great.   apart from that you can also search the MJ web gallery for camera angles to get more inspiration.  Make sure to fav the good ones as they get saved to your account (for reference later on)
~ Reva|2023-05-19 12:20:58|‎~ Reva joined from the community
~ Harshita|2023-05-19 13:08:32|‎~ Harshita joined using this group's invite link
Shubham Sharma 2012C6|2023-05-19 13:53:08|Operating G-mail using brain waves and ChatGPT https://www.araya.org/en/publications/news20230512/
Shimanta Generative AI|2023-05-19 13:58:58|On a similar note, there’s a startup called Neurosity which creates consumer grade “crowns” that can be used to control and build stuff using brain waves.
Shimanta Generative AI|2023-05-19 14:01:50|A guy used it to control a Tesla: https://youtu.be/BDYdWoaa6g0
~ Error 404!|2023-05-19 15:15:47|https://www.linkedin.com/posts/abhi1thakur_drag-your-gan-interactive-point-based-manipulation-activity-7065225903370346496-JidB?utm_source=share&utm_medium=member_android
~ Error 404!|2023-05-19 15:15:51|This is next level
~ Arjun|2023-05-19 15:16:41|They do not release a code base. Knowing Christian, they rarely do. Remember, academic results are super cherry picked!
~ Error 404!|2023-05-19 15:17:27|Yea, but we know what all can be achieved
~ Error 404!|2023-05-19 15:18:26|I guess due to extreme competition, companies are avoiding releasing much information about their research. Google and Openai have already started
~ Arjun|2023-05-19 15:19:04|This is not a company, its the Max Plank Institute in Germany, where I did my PhD from
~ Error 404!|2023-05-19 15:31:52|I see
~ V Pai|2023-05-19 16:41:41|‎~ V Pai joined using this group's invite link
Nitin Mahajan McKinsey|2023-05-19 17:15:53|Going viral on Twitter 🥸
Soumyadeep Mukherjee|2023-05-19 17:32:49|Whats even worse is they have a Code link which goes to a github repo with the same gif only. :-/
~ Shivansh|2023-05-19 17:34:03|They said going to release in June, probably after paper is published in SIGGRAPH
Soumyadeep Mukherjee|2023-05-19 17:34:45|What are the odds someone will implement this before that :P
Dhruv Anand|2023-05-19 18:29:20|Won't we also need a pretrained model to get these results?
Dev Khare Lightspeed|2023-05-19 18:40:27|‎Dev Khare Lightspeed left
Aditya Shastri Shastri|2023-05-19 22:59:44|‎Aditya Shastri Shastri joined using this group's invite link
Sumedh Datar|2023-05-19 23:25:27|‎Sumedh Datar joined using this group's invite link
~ Vik|2023-05-19 23:37:13|anyone looking into https://github.com/microsoft/guidance I can't get a handle on what exactly {{gen}} does I've read the docs but hoping someone can save me from having to read the code. For example what would {{gen 'chapter'}} do? Does it create a seperate api call to the LLM with rest of the generated prompt upto this point and then save the generated output in the variable 'chapter'
Nirant|2023-05-19 23:37:57|cc Ravi [PHONE] did you get a chance to go deeper into this?
Dev Aggarwal|2023-05-19 23:41:14|Yes. Output is saved in the key “chapter”
~ Vik|2023-05-19 23:50:20|what is the prompt used by {{gen}} is it just everything generated upto the point of the {{gen}} call ?
Sumedh Datar|2023-05-20 00:16:42|Any idea how we can generate a prompt dataset with openai and llama index given an article ?
Ravi Theja|2023-05-20 00:20:46|What do you mean by prompt dataset here?
Sumedh Datar|2023-05-20 00:21:10|Question and answer, a format similar to what alpaca needs
Ravi Theja|2023-05-20 00:22:54|There is question generation module which you can use to create questions and use index and query to generate answers.
Sumedh Datar|2023-05-20 00:24:41|Thanks for your reply . Any links sources that I can learn from?
Nirant|2023-05-20 00:25:27|https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html
Dev Aggarwal|2023-05-20 00:26:53|Yup, that’s why the “sequential execution”
Dev Aggarwal|2023-05-20 00:32:21|I also found https://lmql.ai/ a lot easier to understand and try out in their neat little playground
Samhan Meta/Twitter Friend|2023-05-20 00:32:55|Hot take - though I think even this could be simpler it’s better than guidance
Samhan Meta/Twitter Friend|2023-05-20 00:33:28|Haven’t tried either just from a simplicity POV
Samhan Meta/Twitter Friend|2023-05-20 00:33:40|I spent 10-15 mins on guidance got confused and gave up 😁
Dev Aggarwal|2023-05-20 00:43:16|If you want something truly magical you can also try https://www.askmarvin.ai/guide/concepts/ai_functions/ 🤓
Nirant|2023-05-20 00:44:00|Their entity extraction utils are truly neat
Dev Aggarwal|2023-05-20 00:45:06|And with pydantic support 🤯
Jithin James Ragas|2023-05-20 00:45:32|this is actually pretty neat! wow
Nirant|2023-05-20 00:45:43|Yeah. That's what makes them neat. I eventually switched to Guardrails because they've ReAsk, making it more reliable
Dev Aggarwal|2023-05-20 00:47:12|https://www.askmarvin.ai/guide/concepts/plugins/  Damn, they even do functions as plugins
Samhan Meta/Twitter Friend|2023-05-20 00:50:32|This is cool
Samhan Meta/Twitter Friend|2023-05-20 00:52:00|This is probably the best way to use LLMs
Sumedh Datar|2023-05-20 00:53:13|It's taking too long. Is that the right behavior. I just have one pdf file with 4 pages.
~ Vik|2023-05-20 01:26:28|also they are not really clear that this might end up costing a lot more with hosted llms like openai than a single pass execution. nor would some of the token rewind stuff work
Simran Sachdeva Rephrase|2023-05-20 01:32:10|‎Simran Sachdeva Rephrase left
Rahul Bhatnagar|2023-05-20 07:12:52|Yup saw AI functions for the first time in AutoGPT. Found the concept super interesting.  https://github.com/Significant-Gravitas/Auto-GPT/blob/master/autogpt/llm/llm_utils.py#L73  AutoGPT uses them when it has to run code.
Rahul Bhatnagar|2023-05-20 07:13:11|They come from here.   https://github.com/Torantulino/AI-Functions
Lavish 2017|2023-05-20 09:46:45|hey folks, is there already any sophisticated method to do unit tests like things for functions powered by LLMs?  I've over 30-40 functions which needs a call to gpt and not each of them is called for every user's message - so while I change a few prompts here and there or a small param change, I try to reproduce each case of json in a function but it gets hard to work with as the json I'm extracting via LLM is getting complex and prompt fixes are increasing in frequency
~ Vik|2023-05-20 09:47:14|have you come across a js/ts impl of these
~ Vik|2023-05-20 09:49:17|one thing i've done in the past is feed the result back into the llm along with th expected results and ask it to evaluate but again result might vary based on the complexity of your prompts
Lavish 2017|2023-05-20 09:49:21|btw an update on this, I implemented google search API instead of Serp API and have 100K searches free so got freed up of the $50 plan per month of Serp.  I'm just planning to use my other google accounts and get 100K more. although I've only exhausted 2K searches in a week so got pretty big runway now.
~ Vik|2023-05-20 09:49:59|is 100k free per month?
Lavish 2017|2023-05-20 09:50:16|"just have to make sure JS websites are excluded otherwise you'll just get ""couldn't get data because page blocked you"" and some html tags cases"
Lavish 2017|2023-05-20 09:55:46|interesting how did you make it so it checks everytime a commit is made?  my friends are also now making changes in my repo and altho they try to test but prompt based responses vary so much - it is getting hard keeping all inputs to yry in a file so have to ensure I'm checking with a build pipeline
~ Vik|2023-05-20 09:57:36|i manually run the tests but yes that would be a future flow once i have the git actiosn setup
Nirant|2023-05-20 09:58:15|Git Pre Commit has entered this chat
Anshul Bhide Replit|2023-05-20 10:04:40|Ah thanks for this! Kept running into SERPs free limit
Anubhav mishra Zupay|2023-05-20 10:09:37|Hey guys, can anyone tell which model is being used for image generation by Bing ?   Is it a custom they have built internally?
Rahul Bhatnagar|2023-05-20 10:23:45|"Based on DALL∙E, could be a next gen model, but probably finetuned.  ""Powered by an advanced version of the DALL∙E model from our partners at OpenAI, Bing Image Creator allows you to create an image simply by using your own words to describe the picture you want to see.""  https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing/#:~:text=Powered%20by%20an%20advanced%20version,picture%20you%20want%20to%20see."
~ Manideep Burada|2023-05-20 11:34:17|‎~ Manideep Burada joined using this group's invite link
Sandeep Srinivasa RedCarpetup|2023-05-20 11:35:02|has anyone been playing with integrating OpenAI (or other llm) in stuff like customer support chatbots in actual production ?  have u found it better/worse than the commercial solutions out there.
Rakeshkumar Waghela|2023-05-20 11:47:16|How does AWS Kendra compared to LLM tools ?  Use Case : Kendra allows to ingest content and provides feasibility to ask questions and get answers.   Apart from from cost, what's the tech difference.
~ Arka|2023-05-20 12:11:00|Kendra is more of an info retrieval system.  It has an index that fetches you documents that are most appropriate to your query.  It doesn't generate text on its own.
Rakeshkumar Waghela|2023-05-20 12:15:43|I see. But does it do well? Unlike Chat GPT ?  Let's say we feed all publicly available policy and support docs to both Kendra and ChatGPT.  Which one is prone to be more accurate and cost optimal?
Abhinav Verma Longshot.ai|2023-05-20 12:16:38|Can you not combine a retrieval system with a generation system
~ Arka|2023-05-20 12:17:08|Whats your task?  Is it information retrieval or facts?  Then kendra  Is it reasoning or text generation?
~ Sahir Patel|2023-05-20 12:17:58|Hi ,  Question on LangChain Agents - In case some data needs to be returned , can agents determine when it should use SerpAPI to browse the web and include that in the response , and not to browse in other cases .
Rakeshkumar Waghela|2023-05-20 12:18:28|Enabling helpdesk guys to look at past data and suggest resolution for new support queries.   Data sources for resolution could be a set of PDFs , fresh desk data dump.
~ Arka|2023-05-20 12:18:33|Yeah there has been some progress in this area.  But a pure LLM is an unreliable fact producer.  While a IR system cant produce text on its own
Anshul Bhide Replit|2023-05-20 12:18:45|Yes
Anshul Bhide Replit|2023-05-20 12:19:15|You have to just specify it as a tool and the agent will decide whether to use it or not
Maneesh 2013|2023-05-20 12:19:51|They can. But they can be pretty bad at deciding when to not search. You'll have to put the boundaries properly in the prompt if you wanna enforce cases where you don't want it to search
~ Arka|2023-05-20 12:20:36|So my question for you is:  Do you want your guys to think and reason while the system gives them the most relevant docs and snippets.  Do you want the system to compose an entire response on its own after digesting the material. The guys interact via prompt and communicate results to client.
Sandeep Srinivasa RedCarpetup|2023-05-20 12:22:20|is this to optimize serpapi calls for cost ?
~ Sahir Patel|2023-05-20 12:22:30|oh , so instead of action agents , i'll need a custom one .
~ Sahir Patel|2023-05-20 12:22:35|yep
Dev Aggarwal|2023-05-20 12:23:10|+ latency, serp is usually not as fast as google
Maneesh 2013|2023-05-20 12:24:18|Kind of. But you don't need the whole thing to be custom, you can just get the prompt template from codebase, append your guardrails and pass that instead
Rakeshkumar Waghela|2023-05-20 12:24:58|"Preferably later.  Where prompt is prepared by system based on question raised by customer.  Let's say customer says ""i am getting aadhaar seeding error while Onboarding and uploading PAN""   So the tool shall be able to relate to a policy document details that says Plans which are not aadhaar seeded shall not be allowed to onboard and set of steps from the same PDF to help customers know how to make PAN aadhaar seeded.   In essence: customer when raises the ticket may have relevant prompt worthy data and the tool shall infer/provide policy information and resolution steps documented in PDF."
Rakeshkumar Waghela|2023-05-20 12:28:12|Every business will have domain specific details which are not generic and usually could be present in set of documents that were ingested by system.  Leveraging AI for such data for auto generation of resolution response.  If response is incorrect, human could override response as a part of productized solution later.
~ Arka|2023-05-20 12:29:16|For this you need a LLM.  Kendra cannot reason.  What i would suggest is you need to use both
~ Arka|2023-05-20 12:29:37|Step 1: use kendra to get your relevant docs
~ Arka|2023-05-20 12:29:53|Step 2: with relevant docs as context
~ Arka|2023-05-20 12:30:00|Answer client query
Rakeshkumar Waghela|2023-05-20 12:30:40|Step 3 : let human verify to override the response and of response is edited, would that be fed back to Kendra or LLM ?
~ Arka|2023-05-20 12:30:52|Maybe you wdnt need a giant LLM for this. Cheaper ones would do.
~ Arka|2023-05-20 12:33:00|It cant goto Kendra from my understanding.  For feedback to be accepted by a ML model you need to be able to express it as a loss function.  I cant imagine a way to pass the loss through the LLM back to Kendra.  Additionally i dont think Amazon lets you tinker with its retrieval models.
Rakeshkumar Waghela|2023-05-20 12:34:07|If we skip the Kendra from equation, what all tools could be combined to do this with any light weight OSS for POC. ?
Abhinav Verma Longshot.ai|2023-05-20 12:34:57|That's why you combine both
~ Arka|2023-05-20 12:35:19|Yup use the docs as context for LLM
~ Arka|2023-05-20 12:36:16|OSS?
Rakeshkumar Waghela|2023-05-20 12:36:16|I meant removing AWS property from equation altogether and revisiting the solution with any other set of tools that are pure OSS and combined.  What that stack could be ?
Rakeshkumar Waghela|2023-05-20 12:36:27|Open source software.
Abhinav Verma Longshot.ai|2023-05-20 12:36:29|np.array to store embeddings of the docs
~ Arka|2023-05-20 12:37:11|Maybe going for paragraphs might be better.
Abhinav Verma Longshot.ai|2023-05-20 12:37:39|Yes..I meant that. Chunk your docs always
~ Arka|2023-05-20 12:38:18|Also if the docs are pdf, ppt, etc   Is there an easy way clean the mess?
Rakeshkumar Waghela|2023-05-20 12:38:27|Given the variety of tech present what's the pattern of tools that could be leveraged.  For example making REST API we have a stack of JavaScript, Java , Golang based on engineering teams capabilities and affinity.  What could be equivalent stacks for above problem that we discussed.  I'm sure there would be more than one combination
Abhinav Verma Longshot.ai|2023-05-20 12:39:00|You can always develop a chunking strategy. https://twitter.com/nirantk/status/1659624239320956928?s=46&t=URoDrV5X7GPNPYSgYW42Dw
~ Arka|2023-05-20 12:39:06|I think for a POC do what your engineering team is familiar with.
~ Arka|2023-05-20 12:39:27|Dont make ppl learn web frameworks for a POC. 🥲
Rakeshkumar Waghela|2023-05-20 12:39:36|Even that needs to begin somewhere. Imagine clean slate.
Rakeshkumar Waghela|2023-05-20 12:40:05|Web framework was just a analogy
~ Arka|2023-05-20 12:40:18|Python + Flask
~ Arka|2023-05-20 12:40:52|I would use it for a simple POC on a browser. ‎[5/20/23, 12:43:28] Dev Aggarwal: ‎image omitted
Rakeshkumar Waghela|2023-05-20 12:43:41|I'm not talking about REST.  It's equivalent for document parsing, ingest, reasoning and querying the data from new AI tools/tech  Let's say  Use X for docs parse UseY for docs ingest Use Z for reasoning Use Q for corrected data ingest   That becomes a stack.
Rakeshkumar Waghela|2023-05-20 12:44:28|X, Y, Z, Q could be combination of some python libs and chat gpt   Or its alternative that are self hosted.
Rakeshkumar Waghela|2023-05-20 12:46:12|Or may be we are in metamorphosis phase where such patterns and stacks are yet to appear and stabilize.
Dev Aggarwal|2023-05-20 12:49:01|I have hopes from only one person, simon willison  Fwiw, it took about 10 years for web frameworks to properly mature.
Samhan Meta/Twitter Friend|2023-05-20 13:56:36|Guess what I’ve been thinking about for months 😁
Samhan Meta/Twitter Friend|2023-05-20 13:59:11|A lot depends on the available budget for each case and the complexity of the queries that need to be answered.
Samhan Meta/Twitter Friend|2023-05-20 14:00:13|LLM can definitely play a powerful role here
Samhan Meta/Twitter Friend|2023-05-20 14:01:09|Can design LangChain agents to act as fast assistants to help desk staff
Sandeep Srinivasa RedCarpetup|2023-05-20 14:01:58|actually - thats a very interesting question. how does one get LLM to look at *past data* and use that to suggest resolutions ? lets say we pump all this stuff into a vector db as well. is there any prompts/chain-of-thought that does this ?
Samhan Meta/Twitter Friend|2023-05-20 14:02:37|No I don’t think that works beyond the most basic queries
Samhan Meta/Twitter Friend|2023-05-20 14:03:46|What you want to do is build a combination of GitHub copilot / openAI plugins for the support staff.
Samhan Meta/Twitter Friend|2023-05-20 14:04:06|In spirit like not literally tbc
Samhan Meta/Twitter Friend|2023-05-20 14:04:24|Then you keep gathering data and improving
Samhan Meta/Twitter Friend|2023-05-20 14:04:49|Once you have enough you start fine tuning / RLHFing ..
Samhan Meta/Twitter Friend|2023-05-20 14:06:35|But ppl want fast easy solutions which I don’t think exist yet. This requires lots of careful engineering and planning.
Anubhav mishra Zupay|2023-05-20 14:12:07|This new research is incredible. Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold.  Paper: https://lnkd.in/dHUuCSDU Project page: https://lnkd.in/dEfgRMM7   Through DragGAN, anyone can deform an image with precise control over where pixels go, thus manipulating the pose, shape, expression, and layout of diverse categories such as animals, cars, humans, landscapes, etc.  As these manipulations are performed on the learned generative image manifold of a GAN, they tend to produce realistic outputs even for challenging scenarios such as hallucinating occluded content and deforming shapes that consistently follow the object's rigidity.  Both qualitative and quantitative comparisons demonstrate the advantage of DragGAN over prior approaches in the tasks of image manipulation and point tracking. We also showcase the manipulation of real images through GAN inversion.
Samhan Meta/Twitter Friend|2023-05-20 14:21:57|Combining with diffusion models can give some awesome workflows
Samhan Meta/Twitter Friend|2023-05-20 14:27:14|https://www.reddit.com/r/ChatGPT/comments/13lqm1s/chatgpt_describe_a_world_where_the_power
~ Prashant Anand|2023-05-20 16:05:11|‎~ Prashant Anand joined using this group's invite link
~ Akshay Jain|2023-05-20 16:43:35|‎Ravi Theja added ~ Akshay Jain
Raghotham Paypal Bargava's Friend|2023-05-20 18:04:09|Hi folks 👋  Any references on LLaMA-adapter with audio modality? Has anyone here  tried it?
Akshat Shah - Gojek|2023-05-20 19:28:27|‎Akshat Shah - Gojek left
~ Anand V|2023-05-20 20:00:16|‎~ Anand V joined using this group's invite link
Ritwik 2013|2023-05-21 00:33:13|I am currently working on performing QA retrieval over an existing FAISS index using the load_qa_with_sources_chain module in Langchain. I was wondering if there are any open-source, LLMs supported by Langchain that can serve as alternatives to OpenAI's models without requiring any authentication(i.e. OpenAI API key). Does anyone have any experience or recommendations for deploying such models in a production environment?
Shalabh Aspiro|2023-05-21 00:39:59|huggingface supports open source models through langchain. No experience of using them though https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html
Sumedh Datar|2023-05-21 02:51:56|Did anyone try loading llama 7b with alpaca and was successful in converting llama weighs to hugging face transformers?
Ritwik 2013|2023-05-21 03:13:49|Most of these are too slow, or do not generate a meaningful response :)
Ritwik 2013|2023-05-21 03:17:17|Surprisingly the Q/A models cannot be used with the QA_chains in Langchain, pretty weird
Rohan Manchanda|2023-05-21 05:12:50|Team, I am sure versions of these exist out there:  I am looking to make an assistant bot internal to my company. I want to feed a lot of content which lies in 100 different places today. How can I do that without involving anyone and automate the code writing part.  I read somewhere it needs to use pinecone, langchain, and openai.  But, curious to know if someone has come across a how-to video for how to do this?
Dev Aggarwal|2023-05-21 05:20:04|I think it matters where these places are - Google drive? Notion? A file on someone’s computer?
Rohan Manchanda|2023-05-21 05:21:04|I have a out 50-75 pdfs through my access to seismic, then some google sheets, some notion docs yes, some ppts
Rohan Manchanda|2023-05-21 05:21:18|All of these files i have in my computer :)
Nirant|2023-05-21 06:43:45|Are you keen on writing code?   If not, something like this can work? https://www.databerry.ai/
Satish DeepHack Sponsor|2023-05-21 07:02:29|Curious for your stack recommendation - if some one wants to code it from ground up? I/m thinking openai embeddings + pinecone.?
Nirant|2023-05-21 07:22:01|Embeddings: OpenAI / Cohere-Large, are both competitive. Sentence BERT if you want to do FOSS.  VectorDB: Pinecone is great to begin with, but so expensive I had to quickly move to FOSS. I tried Chroma, Redis and finally settled with Qdrant. Even if I were to use a cloud now, Qdrant is max $25/mo, while others start at $50-70/mo for basic things.  E.g. Qdrant does entire English Wikipedia in less than 2G of RAM. Just the compute cost for the rest is too much. I've heard good things about the sentence BERT embedding integration in both Chroma and Weaviate. Qdrant doesn't have any such thing.
Nirant|2023-05-21 07:23:31|For most projects like the one which Rohan [PHONE] bhaiya is trying, OpenAI + Redis would work better perhaps? Most tech teams already use Redis, so any questions are answered in 5 minutes vs 3 days.
Dev Aggarwal|2023-05-21 07:25:44|Related Q: how do I compare  the embeddings like intuitively, like what are the modalities where one embedding “gets it” and other doesn’t
Rohan Manchanda|2023-05-21 07:29:28|Not at all actually. I want to cut out as much help required from others.  Willing to put 20 days haha
Rohan Manchanda|2023-05-21 07:29:56|But if openai tells me step by step here is the code. Here is how you deploy, that’s something on me.
Rohan Manchanda|2023-05-21 07:32:36|Check this and this was done using embeddings. How do I do this on my own?  https://twitter.com/youraimarketer/status/1659360048693366784?s=46&t=A_AEd3mXs8W9xl-BOyaBqw
Nirant|2023-05-21 07:33:56|Yeah, so tools like the one which I linked to do use embeddings + some stores under the hood. They're a neater wrap on this ofc.
Nirant|2023-05-21 07:34:15|Neater → Easier to use here
Rohan Manchanda|2023-05-21 07:37:39|You mean you’re developing something of this sort?   If yes, can’t openai tell me the step by step method to build this private internal website / bot / whatever you want to call it:  1. Open terminal 2. Paste this python / Jupyter code or some shit like that?  Even is there are 500 steps like that, I am sure it can be done right. That’s how people are doing it. No?
Nirant|2023-05-21 07:40:38|I've not seen a single guidebook of sorts, but it should, you're right!
Sandeep Srinivasa RedCarpetup|2023-05-21 07:43:17|What do u mean by that ? For e.g. the mpt chat model won't work with langchain qa chain ?
Rohan Manchanda|2023-05-21 07:45:45|Damnnnn. So this a good challenge to solve and touch code in some form 🤣
Rohan Manchanda|2023-05-21 10:09:12|what are the most authortiative books on prompt engineering yet?
Nirant|2023-05-21 10:16:16|We've discussed this quite a bit in the past. You can see some of the community discussions here: https://nirantk.com/ai
Nirant|2023-05-21 10:18:49|Advanced User Guide for prompts: lilianweng.github.io/posts/2023-03-15-prompt-engineering
Rohan Manchanda|2023-05-21 10:18:53|Thank you thank you. Sorry for the spam haha
Soumendra Dhanee|2023-05-21 10:19:57|You can't reliably do this by asking OpenAI which has a knowledge cut-off date of sep21. Their is some post-sep21 data leakage due to RLHF, but it won't be reliable for building something like this.
Rohan Manchanda|2023-05-21 10:20:37|Basically the non coder in me who got D grades all my life is not going to feel happy anytime soon 🔜
Soumendra Dhanee|2023-05-21 10:24:05|I think Chroma is the easiest to build something like this with, and its default guides should be good enough for you (if not, come back here and let us know). I would not recommend that for production though, and you should probably talk to [PHONE] if you're ready to take something live.
Rohan Manchanda|2023-05-21 10:25:08|Ok. That’s quite, helpful. Thank you 🙏🏻
~ Clament John|2023-05-21 11:25:40|Tanmay Bhat tweeted a sequel to the last harry potter book. Generated of course.   Title: Harry Potter and the Echoes of the Dark Lord.  It is beautifully written.  https://twitter.com/thetanmay/status/1659974736859000832
~ Rohit|2023-05-21 11:32:45|Maybe GRRM can use GPT to finally finish his books...
~ Prajna Prayas|2023-05-21 11:33:33|God save the old man ‎[5/21/23, 11:59:55] Sudharshan GenAI: ‎video omitted
Rakeshkumar Waghela|2023-05-21 12:17:24|This is a repeat pattern.
Rakeshkumar Waghela|2023-05-21 12:17:44|.
Rakeshkumar Waghela|2023-05-21 12:17:55|Seems the most common use case
Dev Aggarwal|2023-05-21 12:33:10|https://learnprompting.org
~ Akshit Banta|2023-05-21 12:41:58|Has anybody had success using GPT4 browsing? It always results in click failed no matter what website it tries to open.
Abhinav Verma Longshot.ai|2023-05-21 12:44:15|Depends on the websites
Abhinav Verma Longshot.ai|2023-05-21 12:44:16|What website was it
~ Akshay Jain|2023-05-21 12:44:58|yes it mostly fails   https://twitter.com/bbourque/status/1659906528457916417?s=20
Abhinav Verma Longshot.ai|2023-05-21 12:46:34|G2 reviews are not easily scraped. It seems the scraper isn't working the one they're using at openai
~ Akshit Banta|2023-05-21 12:55:09|I've tried a lot mostly github repos & documentations
Abhinav Verma Longshot.ai|2023-05-21 12:55:25|Yes they are hard to scrape
Abhinav Verma Longshot.ai|2023-05-21 12:59:08|Quota github LinkedIn are hard to scrape sites
Abhinav Verma Longshot.ai|2023-05-21 12:59:23|Quora*
Dr. Ashith Generative AI WA Group|2023-05-21 13:14:27|Yes facing the same issue since yesterday
Abhinav Verma Longshot.ai|2023-05-21 13:27:13|What are you trying to scrape and search exactly? There might be some tools that might work better for you
~ Sudhanshu Heda|2023-05-21 13:30:50|https://nianticlabs.github.io/implicit-depth/index.html
Dr. Ashith Generative AI WA Group|2023-05-21 13:37:42|just wanted to summarise some articles..its not able to open any links
Abhinav Verma Longshot.ai|2023-05-21 13:38:14|Is it one of these
Dr. Ashith Generative AI WA Group|2023-05-21 13:39:08|https://studio.ribbonfarm.com/p/text-is-all-you-need
Abhinav Verma Longshot.ai|2023-05-21 13:42:07|weird. it can be scraped
~ Nischal|2023-05-21 15:17:04|Was able to get quite a few models to work with langchain that are not OpenAI ones.  Llama, vicuna, mpt-7b-chat.  You can use the AutoCausalLM as part of the transformers library and load them by passing a local folder math for model_id parameter, and using the tokeniser and model, you can create a generator which can be used as LLM as part of the langchain pipeline.  Vicuna 7B and 13B actually do quite well for QA activities. Ofcourse depends on your prompts.  If you want to make the inference faster, you could use bitsandbytes and accelerate packages to enable load 8 bit features of transformers packages.
~ Clament John|2023-05-21 15:18:44|Tanmay again with Lagaan 2  https://twitter.com/thetanmay/status/1660204226734338049  I've tried creating prose using GPT. But never of this quality. I think this proves that you need a creative mind to unlock AI creativity. Us engineers are using it to help us with code, while Tanmay is using it for story telling.
Sandeep Srinivasa RedCarpetup|2023-05-21 15:19:31|Hi. Do u have a piece of code that does this ? Especially for mpt7b chat ? It didn't entirely work for us.  Isn't gpt4all the most popular one here ?
Pranjal Yadav Razorpay|2023-05-21 16:02:07|Any suggestions on where to buy used 3080/3090 gpus? Is gameloot safe or it's like quick/olx?
Samhan Meta/Twitter Friend|2023-05-21 16:22:38|What are the trade offs if you use redis vs a custom vector store
Samhan Meta/Twitter Friend|2023-05-21 16:22:59|Redis seems to also use undelivered
Samhan Meta/Twitter Friend|2023-05-21 16:23:06|Hnswlib
Ravi Srinivasan|2023-05-21 18:11:24|‎Ravi Srinivasan joined using this group's invite link
~ Rohan|2023-05-21 18:20:07|https://blog.google/technology/research/project-starline/
Soumendra Dhanee|2023-05-21 18:30:06|https://twitter.com/samsja19/status/1659953297011224579?t=OA2QYLUDLKfqCvCdjTFuGQ&s=08  This provides a way of thinking about your prompts  that's useful: is the token generation required by my prompt commensurate with the complexity of the task to be performed?
Soumendra Dhanee|2023-05-21 18:31:00|(doesn't matter if you believe LLMs are purely stochastic parrots)
Nirant|2023-05-21 18:33:01|Thought this might be interesting to you  arxiv-vanity.com/papers/2305.10601
Soumendra Dhanee|2023-05-21 18:33:54|Thanks, yes
Soumendra Dhanee|2023-05-21 18:35:25|I meant, the post I shared doesn't matter... Not that your beliefs don't matter 😀
Dev Aggarwal|2023-05-21 18:38:17|Hot take: doesn’t matter even if they’re purely stochastic parrots casue they’re so damn good at it
Soumendra Dhanee|2023-05-21 18:40:13|Not an interesting take at all, sorry
Nirant|2023-05-21 18:40:34|As a language model trained by OpenAI, I cannot comment on whether this is philosophy or not. But it it is, we've a thriving *AI and Philosophy* WA group which discusses everything from Roko's Basilisk to Godel, Escher and Bach.    https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Soumendra Dhanee|2023-05-21 18:42:04|Had tried so long to stay away from philosophical discussions around LLMs
Dev Aggarwal|2023-05-21 18:43:13|Is this similar to smartgpt, where you essentially sample multiple outputs and then ask it to reflect on all of them independently and select the best one
Lalit Pagaria|2023-05-21 18:43:19|You check G2 robots.txt. I think ChatGPT browser plugin owner website's robots.txt file. https://www.g2.com/robots.txt
Soumendra Dhanee|2023-05-21 18:55:10|Btw, I'm not sure about the overall point being made.The reason I can't make up my mind is because - can the slow verbal reasoning, which humans can't make very fast, be made fast with a faster model? And how is it going to be qualitatively different?
Sachin Legaltech|2023-05-21 19:01:10|They just show a framework to generate multiple actions/thoughts - they are evaluating these thoughts in two ways - where LLM evaluated each thought and assigns a score or LLM looks at all the thoughts and generates comparisons. But we can use lots of other mechanisms to select the best one as well. Like another trained neural network or set of Lora weights which are trained using RL/ planning hybrid methods.
Sudipta Mondal GenerativeAI Photographer|2023-05-21 19:03:56|‎Sudipta Mondal GenerativeAI Photographer joined using this group's invite link
Dev Aggarwal|2023-05-21 19:05:02|openai has rlhf data for reflexion and evaluation - they have human labellers doing this - so they probablyhave that rl/planning in built
Dev Aggarwal|2023-05-21 19:07:34|Didn’t we have a jee working group here? Did you guys end up doing something like smartgpt or tree of thought to get better perf?
Sachin Legaltech|2023-05-21 19:09:07|Complete speculation on my part - But it feels like GPT4 has some sort of internal planning module as well which makes it absolute beast with reasoning.
~ Rohit|2023-05-21 19:15:43|https://youtube.com/shorts/H1sXIUbpRCU?feature=share
~ Rohit|2023-05-21 19:17:02|very likely not, at least not mentioned in their paper.  also with plugins i think its very heuristic because they only allow upto 3 plugins at any time + very easy to break it with prompts (any “reasoning” module that exists is not that sophisticated)
Sachin Legaltech|2023-05-21 19:20:37|They haven’t mentioned anything in the paper except it’s a transformer model ..but maybe not. It feels easier to attribute reasoning capabilities of GPT4 to planning and ability to backtrack than just next token prediction.
~ Rohit|2023-05-21 19:22:10|I’d imagine a 1T model learn some first order logic at least., this follows from the argument that emergence is a function of scale
~ Rohit|2023-05-21 19:22:32|what kind of reasoning are u talking about + any papers in nlp or adjacent fields to back it up
~ Rohit|2023-05-21 19:22:53|at least in robotics the planners i’ve seen are very domain specific
Sachin Legaltech|2023-05-21 19:31:31|I agree with that..I think with GPT4 they have amazing base LLM + huge amount of SFT and RLHF. However just maximum likelihood training giving us performance of GPT4 seems hard. Couple of wrong token samples can put model in a wrong reasoning path and should decrease the performance. I am heavily impressed by GPT4’s reasoning performance (coding + plenty of other non bs tasks) and that might be biasing my speculation of GPT4 having planning component.
~ Rohit|2023-05-21 19:32:17|you’re hugely underestimating the potential of scaled networks
~ Rohit|2023-05-21 19:32:58|you know what we are also just neural networks right? maybe with a hippocampus but short term memory is still activated in pathways of the cortex
~ Rohit|2023-05-21 19:33:22|plus the amount of github code it was trained on, it would be excellent at basic coding
~ Rohit|2023-05-21 19:33:46|i can’t get it to write good c++ or cuda code, even like 100-200 line scripts
~ Rohit|2023-05-21 19:34:08|makes me think it’s more of a data exposure thing than a reasoning module
Soumendra Dhanee|2023-05-21 19:34:30|This is literally not true
Sachin Legaltech|2023-05-21 19:35:13|If that’s the case, it’s probably much more exciting .. then we will get much better augmented LLMs soon.
~ Rohit|2023-05-21 19:35:33|why not
~ Rohit|2023-05-21 19:35:39|what else is different
Dev Aggarwal|2023-05-21 19:35:43|pretty bad at anything that’s slightly novel. But good for exploring ideas
~ Rohit|2023-05-21 19:36:33|exactly! we on the other hand can very easily “extend” reasoning beyond what we learn in tutorials or books
~ Rohit|2023-05-21 19:36:53|try asking Yann Lecuns gear problem to GPT
~ Rohit|2023-05-21 19:37:09|if it was good at reasoning, it would solve it no matter what configuration you give it
~ Rohit|2023-05-21 19:37:12|but it doesnt
Soumendra Dhanee|2023-05-21 19:37:16|NNs are a very very lossy abstraction inspired by our understanding of the brain from 60 years back. The list of differences are very very long, and I'll have to let you Google it for yourself.
Soumendra Dhanee|2023-05-21 19:37:26|I mean, it's not even close.
~ Rohit|2023-05-21 19:37:29|lol
~ Rohit|2023-05-21 19:37:46|i’m just saying things based off some cognitive neuroscience we’re reading
~ Rohit|2023-05-21 19:38:02|sure, we’re not relu networks
~ Rohit|2023-05-21 19:38:06|but we are networks ‎[5/21/23, 19:38:17] Dev Aggarwal: ‎image omitted
~ Rohit|2023-05-21 19:38:36|thats why spiking NNs and memory augmented networks are getting interesting
~ Rohit|2023-05-21 19:39:13|look up balints syndrome and other neurodegenerative diseases, it gives a nice primer on location of neural nets
Dev Aggarwal|2023-05-21 19:39:30|Ok we are again in AI philosophy territory
Dev Aggarwal|2023-05-21 19:39:35|cc
~ Rohit|2023-05-21 19:39:36|also diffusion tensor imaging is literally the process of finding neural bundles
Paras Chopra Wingify|2023-05-21 19:39:37|We don’t understand brain well enough to make valid comparisons  We don’t even know if neurons are the fundamental unit of computation or if it’s something higher or lower level
~ Rohit|2023-05-21 19:39:48|no this is neuroscience territory
Soumendra Dhanee|2023-05-21 19:39:52|We have networks of neurons, sure, but they don't work the way these networks do. I mean, roads are networks too. Our brains don't work like the traffic. Some interesting analogies can be made sure, but that's about it.
~ Rohit|2023-05-21 19:39:59|bruh
~ Rohit|2023-05-21 19:40:09|pick up any computational neuroscience book
~ Rohit|2023-05-21 19:40:34|and you’ll see it say neurons are the fundamental unit in the gray matter
Paras Chopra Wingify|2023-05-21 19:40:43|Or could be that dendrites are doing something magical or it could be a higher level (networks of neurons)
~ Rohit|2023-05-21 19:41:19|yes, i’m not saying there is a one-to-one correspondence between human neurons and MLPs
~ Rohit|2023-05-21 19:41:36|but at a computational level they are equivalent (modulo some constant)
Soumendra Dhanee|2023-05-21 19:41:55|And not to mention, the current networks have their genesis more than 60 years back, when we understood little about how the brain works. All this retro-fitting sounds like religion finding science in it.
Soumendra Dhanee|2023-05-21 19:42:12|Even this is largely incorrect
Sachin Legaltech|2023-05-21 19:42:14|We don’t know how we learn very well ..we mostly don’t do backprop
~ Rohit|2023-05-21 19:42:36|thik h bhai, if you do not want established neuroscience literature and call it pseudoscience then idk what to tell you
Soumendra Dhanee|2023-05-21 19:42:55|Not saying that
Soumendra Dhanee|2023-05-21 19:43:11|This is also fine.
Soumendra Dhanee|2023-05-21 19:43:29|But you're making a large reductive jump
~ Rohit|2023-05-21 19:43:58|my thesis work is literally in neurodegenerative diseases like alzheimers or parkinsons, and based on the human and rodent brains we study, there’s nothing “magical” computationally
Paras Chopra Wingify|2023-05-21 19:44:03|we don’t even know how important a rule non-neuronal cells in the brain (that outnumber neurons) play  Like astrocytes or glial cells  Brain is largely still unexplored territory
~ Rohit|2023-05-21 19:44:25|glial cells are literally just a cover
~ Rohit|2023-05-21 19:45:16|functionally they are very different agreed
~ Rohit|2023-05-21 19:45:28|but there is also a huge difference in scale + functional discrepancy
Paras Chopra Wingify|2023-05-21 19:45:46|if I’ve learned one thing pouring over Biology over the years, it’s that any simplistic statement about a biological system is largely under estimating what it does  We just cannot make simple, linear, casual statements about complex systems  Have to be very careful before we say X is literally Y in Biology
~ Rohit|2023-05-21 19:46:26|obviously, again I said im not claiming 1-1 correspondence
~ Rohit|2023-05-21 19:46:51|but bringing back the cliche example of wright brothers, the airplane wasn't a one to one correspondence to a bird
~ Rohit|2023-05-21 19:47:03|but all functional components were equivalent
~ Rohit|2023-05-21 19:47:52|"[PHONE] read up ""Neuroscience Exploring the Brain"" by Mark F Bear, and Neuroscience by Dale Purves. These are the books I'm reading for my work"
~ Rohit|2023-05-21 19:47:59|first one is very good
~ Rohit|2023-05-21 19:49:07|can also send you studies on neurodegenerative diseases, and what they tell about different lobes and neuronal pathways
~ Nivesh|2023-05-21 19:49:24|‎~ Nivesh left
~ Rohit|2023-05-21 19:49:58|"ofc, a lot is also unknown because fMRI has very bad spatial resolution, so we can only say about the ""macro"" behavior of the brain, but histopathological slides have shown that neurons do most of the heavy lifting"
~ Rohit|2023-05-21 19:50:35|or comprise most of the functional brain, and neurodegenerative diseases all have to do with damaged or dead gray matter, meaning less neurons
Soumendra Dhanee|2023-05-21 19:51:00|Thanks for the recommendations, and I have read a bunch about computational neuroscience as well, and I see and agree with a bunch of stuff you said as well, but
Soumendra Dhanee|2023-05-21 19:51:09|2hat are you claiming?
~ Rohit|2023-05-21 19:51:13|this is what I know. if you guys find some other explanations of the humans, or mammals in general lmk
Soumendra Dhanee|2023-05-21 19:51:18|*what are you claiming?
Soumendra Dhanee|2023-05-21 19:52:39|This was your original claim that you have backtracked from. If not this, then what else are you claiming now?
Nirant|2023-05-21 19:53:06|Friends, this is decidedly off topic, requesting you to move this conversation to the other group :)
~ Rohit|2023-05-21 19:53:08|that on a functional level, GPT can have human-like reasoning with neural networks only, because that is how humans do it. Ok I want to do some ERM style math here so why not.  Let H be the space of all neural networks. My claim is that human brain f* \in H exists in this space. Let f be the GPT weights. I'm saying that since GPT weights  are in the space H, they can reach f*, just in a different form
~ Rohit|2023-05-21 19:53:30|sure sure, this is the last bit from me anyway^   happy to take the discussion to DMs
~ Rohit|2023-05-21 19:53:55|i hope the above explanation encompasses this as well
~ Rohit|2023-05-21 19:58:20|that gives me a good idea. I will try to write blog post summarizing some of these ideas
‪+91 91 674 694 70‬|2023-05-21 20:05:01|‎‪+91 91 674 694 70‬ joined using this group's invite link
~ D.C. 🌚 (DHRUV CHANDEL)|2023-05-21 20:05:36|‎~ D.C. 🌚 (DHRUV CHANDEL) joined using this group's invite link
~ gaganmahajan3|2023-05-21 21:51:10|‎~ gaganmahajan3 joined using this group's invite link
Lavish 2017|2023-05-21 22:40:49|"is there any good hack anyone here has figured to promt something for LLM to understand.   My solution:  right now my use case was understanding a specific topic from user so I ask LLM-1 to define all things in a bullet list that the LLM-2 should get from user and if it doesn't ""understand/know"" any of it, it should ask as a curious person."
Lavish 2017|2023-05-21 22:41:10|it works I guess. somewhat but it's just brute force like my most solutions 😅  anything better anyone has come across?
Lavish 2017|2023-05-21 22:46:25|I generate a todo list like thing in LLM-1. modified some prompts from guard rails implementation to prevent the gpt big mouth going off track
~ Preet|2023-05-21 23:08:50|‎~ Preet left
~ Arjun|2023-05-22 07:43:17|Hi Rohit! Nice to see you here!  I doubt if Yann will agree with with you here. He says GPT is just autoregressive and does not have any world understanding.
~ Arjun|2023-05-22 07:43:39|But let’s see what still bigger GPTs can do.
~ Rohit|2023-05-22 07:50:34|YLC has been shown to be wrong multiple times (gear configuration problems, forces in physics). I think Yann's stance is also motivated by the backlash of Galactica, and comparatively lesser attention to llama.  Yann also mentions that autoregressive models cannot have emergence, and my counter argument would be that ants are very simple automatons by themselves, but they show emergent properties when in huge numbers. A group of 10 ants wont show any emergence.
~ Rohit|2023-05-22 07:50:47|Nice seeing you here too! Small world we live in haha
~ Rohit|2023-05-22 07:51:21|GPT4 is already whooping GPT3 like crazy! I'm very impressed with some of the plugins, my academic workflow is 10x faster now!
~ Arjun|2023-05-22 07:54:10|True, I guess only time will tell. Interesting times to live in!
~ Rohit|2023-05-22 07:54:27|Very!
Anshul Khandelwal Invideo|2023-05-22 08:07:01|Which plugins have you found useful?
~ Rohit|2023-05-22 08:07:45|penrose analyst is very cool, scraper too
~ Rohit|2023-05-22 08:08:39|xpapers is decent
~ Rohit|2023-05-22 08:08:51|some of the video plugins don’t work, which is disputing
~ Rohit|2023-05-22 08:08:58|disappointing*
Anshul Khandelwal Invideo|2023-05-22 08:11:52|Thanks.  Will check these out.  I found a lot of value in code interpreter but have struggled to get much value from plugins.  Which video plugins have you tried?
Pratyush Choudhury|2023-05-22 08:35:16|How about the speed? ‎[5/22/23, 08:56:33] Nirant: ‎image omitted
Nirant|2023-05-22 08:56:36|*Xpapers
Abhishek Maiti|2023-05-22 08:59:38|Has rollout for plugins for chatgpt plus users started in India?
Nirant|2023-05-22 09:00:55|Yes, Plugins are accessible to everyone on Plus. I've had Plugins for couple of weeks.
Abhishek Maiti|2023-05-22 09:02:37|I am a plus user, i wasnt able to see the plugin support. Do I need to enable anything separately? ‎[5/22/23, 09:05:45] Nirant: ‎image omitted
Abhishek Maiti|2023-05-22 09:06:04|Thank you! Will check this
~ Kp|2023-05-22 09:06:17|Enable in settings
~ Kp|2023-05-22 09:06:22|Browsing is enabled by default but not plug-in access
Abhishek Maiti|2023-05-22 09:06:58|I see, let me check this
Nirant|2023-05-22 09:09:40|PSA: WebPilot Plugin is a viable alternative to Browser. Does 80% of the job in 5% of the time. I've tried 2-3 queries on both and WebPilot beat Browser in speed and selection/relevance of the links selected both.
~ Kp|2023-05-22 09:10:38|Does gpt browsing have an increased context limit tho?
~ Kp|2023-05-22 09:10:47|It felt like it when I first used it
Nirant|2023-05-22 09:16:11|Perhaps, but a longer context window in a weak search does not seem to help much. It's like having great recall for lyrics but not being able to find keys in the morning.
Swastik Banerjee|2023-05-22 10:04:49|Isn’t there something called Keymate.AI Search too?
Sandeep Srinivasa RedCarpetup|2023-05-22 10:49:34|Which LLM api is available with a free tier that doesn't need a credit card ?  Am teaching some high school students as part of their summer holidays.  Extra brownie points 8f it works with langchain/gptindex. ‎[5/22/23, 10:51:43] Nirant: ‎image omitted
Kaushik Bokka|2023-05-22 10:52:55|curious, why use the HF Inference API?
Nirant|2023-05-22 10:53:39|Free, faster than OpenAI, supports multi-modal, flexible (multiple models, context windows)
Kaushik Bokka|2023-05-22 10:54:16|I heard Bard is pretty fast, I will look for benchmarks online
Kaushik Bokka|2023-05-22 10:55:58|Also [PHONE], Jerry and I talked about you :) really appreciated your efforts
Ravi Theja|2023-05-22 10:56:11|It's fast but I found GPT4/3.5 is superior in most of the cases.
Sandeep Srinivasa RedCarpetup|2023-05-22 10:56:44|bard api is free ? and it works with langchain/gptindex ?
Sandeep Srinivasa RedCarpetup|2023-05-22 10:56:52|not looking for fast/superior...just free
Nirant|2023-05-22 10:56:54|Bard has no official API
Sandeep Srinivasa RedCarpetup|2023-05-22 10:57:33|can u share this link ? i dont know what page is this
Nirant|2023-05-22 10:58:38|Let me send you a 30s Loom in next 30 minutes. Huggingface UX is terrible
Kaushik Bokka|2023-05-22 10:59:27|I can’t believe how expensive RunwayML is lol
Aashay Sachdeva MPL Data Scientist|2023-05-22 11:02:41|Exactly. Almost every creative ai tool is like 20 dollars/20 minute usage. Runway,midjourney, synthesia ‎[5/22/23, 11:03:00] Kaushik Bokka: ‎image omitted
Aashay Sachdeva MPL Data Scientist|2023-05-22 11:03:10|Is there an open source alternative to synthesia? ‎[5/22/23, 11:03:46] Kaushik Bokka: ‎image omitted
Dhruv Anand|2023-05-22 11:04:54|wow, feeling limited by the 25 messages per 3 hour cap for the first time, because of this
Sumod K Mohan|2023-05-22 11:12:15|Moving that discussion to philosophy
Swastik Banerjee|2023-05-22 11:40:56|Something relevant since I found people discussing this last night:  https://ai.facebook.com/blog/ai-math-theorem-proving/ ‎[5/22/23, 11:47:25] Swastik Banerjee: ‎image omitted
Swastik Banerjee|2023-05-22 11:48:09|"The resource ""supercluster"" link mentions theorem proving as a top level project: (Paper from 2022: https://arxiv.org/abs/2205.11491)"
Samhan Meta/Twitter Friend|2023-05-22 12:31:10|GPT-4 was able to solve 1-2 IMO problems
Swastik Banerjee|2023-05-22 12:32:54|this was able to solve 10 apparently ; best performance till date for reasoning skills
Nirant|2023-05-22 12:33:18|That's 2 more than me
Samhan Meta/Twitter Friend|2023-05-22 12:33:41|“Sparks of AGI” paper
Swastik Banerjee|2023-05-22 12:38:08|The first ever problem of IMO is a gcd problem, you have to show gcd of numerator and denominator is 1  Can start with that 😛
Prayank Swaroop Accel|2023-05-22 12:38:34|Sandeep I run GPT4All locally ... very easy to use. Your students will get to be able to use it on a 4GB laptop also. You can use the desktop version or you can use the Python programming stack.   https://gpt4all.io ‎[5/22/23, 12:38:36] Prayank Swaroop Accel: ‎image omitted
Sudharshan GenAI|2023-05-22 12:41:44|Anything video is usually premium - right from non-AI tools
Sudharshan GenAI|2023-05-22 12:41:56|You sell to the same market so companies price accordingly
~ Aerica|2023-05-22 14:05:23|‎~ Aerica was added
Manish Singh Techcrunch|2023-05-22 14:05:23|‎Manish Singh Techcrunch left
~ Anubhab|2023-05-22 14:05:23|‎~ Anubhab left
Sandeep Srinivasa RedCarpetup|2023-05-22 13:04:57|Hi prayank This is useful, but I'm wondering if the local LLM can be exposed as an api. My framework is kind of a langchain equivalent built in Java, which people can use to prototype serverless apps or even mobile apps.  So I don't mind locally running it...but is it exposed via api to make it usable in non python environments
Vamshi|2023-05-22 13:09:25|Anyone here actively working on unreal engine code or content with stable diffusion ?
~ Vik|2023-05-22 13:17:41|mind reading https://twitter.com/_akhaliq/status/1660453496804741120?s=12
Dr. Ashith Generative AI WA Group|2023-05-22 13:24:36|https://github.com/go-skynet/LocalAI LocalAI is a self-hosted, community-driven, local OpenAI-compatible API. It's designed to be a drop-in replacement for OpenAI, running Language Learning Models (LLMs) on consumer-grade hardware, with no GPU required.
Dr. Ashith Generative AI WA Group|2023-05-22 13:26:30|it is very slow for me ....are you aware of anyway to make it faster ? using NVIDIA Quadro P1000 32 GB RAM
Prayank Swaroop Accel|2023-05-22 14:05:10|I'm running on 16GB RAM .. Apple M1
~ Prashant|2023-05-22 14:08:50|‎~ Prashant joined from the community
Sandeep Srinivasa RedCarpetup|2023-05-22 14:24:45|This is very useful. Any idea which is the smallest model that will run on student grade hardware (maybe no GPU). Doesn't matter if it is slow ..as long as it is reasonably accurate
Heer Shingala|2023-05-22 14:54:59|Has anyone tried this?   https://www.linkedin.com/posts/karenxcheng_karenxnerf-ugcPost-7065006931270119425-2uVb?utm_source=share&utm_medium=member_android
Yash Pandya|2023-05-22 14:56:29|[PHONE]
Abhinav Verma Longshot.ai|2023-05-22 14:58:06|Has anyone experimented with timeout parameter in openai api via the package . Keep seeing it there in their lib code but the versions I tried, didn't seem to work
Ravi Srinivasan|2023-05-22 14:58:54|(The mobile app is iPhone only right now)
~ Pradyumna Bang|2023-05-22 15:04:34|Are you able to use their web API?
~ Pradyumna Bang|2023-05-22 15:04:58|The one that GPT4all exposes on localhost
Prayank Swaroop Accel|2023-05-22 15:09:41|This is a good idea - you are referring to this - https://docs.gpt4all.io/gpt4all_chat.html
Devanshu Tak 2015B3A4|2023-05-22 15:09:56|Yes
Sandeep Srinivasa RedCarpetup|2023-05-22 15:10:41|Ah I didn't know this was an option. I thought it was an in-memory model load.
Sandeep Srinivasa RedCarpetup|2023-05-22 15:10:50|Will check it out !
Sandeep Srinivasa RedCarpetup|2023-05-22 15:11:07|Much thanks [PHONE]
Sandeep Srinivasa RedCarpetup|2023-05-22 15:12:29|We generally convert models to ONNX in our java edgechains and load it. But I didn't want students to bother with that.
Heer Shingala|2023-05-22 15:37:09|Did it work?
Devanshu Tak 2015B3A4|2023-05-22 15:43:14|Yes ofcourse
~ Pradyumna Bang|2023-05-22 16:20:06|Unfortunately this doesn't work for me, it seems that there's no API exposed on that port. If you get it working, please let me know.
~ Rohit|2023-05-22 16:22:10|use GPT4?
~ Rakesh|2023-05-22 16:22:50|Yes, use it or use an open-source models
Anubhav mishra Zupay|2023-05-22 19:15:20|https://arxiv.org/abs/2305.11206  LIMA, a 65B LLaMa model fine-tuned only with supervised learning on 1,000 carefully curated examples, without *any* RLHF at all, demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.
Ravi Srinivasan|2023-05-22 19:23:48|Super... Is available to try?
Palkush GenerativeAI Group|2023-05-22 19:41:20|‎Soumyadeep Mukherjee added Palkush GenerativeAI Group
Shahul Kaggle Kernel GM|2023-05-22 20:34:16|No
Shahul Kaggle Kernel GM|2023-05-22 20:35:35|Although I agree with their hypothesis that LLM learn most of the knowledge during pretraining their results are not very conclusive. They have just tested on 200 samples
Ravi Srinivasan|2023-05-22 20:56:49|Ok
Adithya S K PESIT|2023-05-22 21:18:15|‎Adithya S K PESIT joined using this group's invite link
~ Arjun|2023-05-22 21:25:27|they use 1000 samples to train, so 20% of that to test is ok?
~ Lance B|2023-05-22 21:28:16|https://www.instagram.com/reel/CsOsJcRIZOC/?igshid=MmJiY2I4NDBkZg==
Anagh Prasad|2023-05-22 21:51:45|Hollywood writers have gone on a strike, demanding a ban on using AI for writing scripts
Anagh Prasad|2023-05-22 21:51:46|https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/
~ Vik|2023-05-22 22:03:58|i believe in the end we'll need even less good examples maybe even south of 100. i used to use t5 with setfit for zero shot classification and it needed less than 10 good examples to tune
Shahul Kaggle Kernel GM|2023-05-22 22:06:39|It’s not about the split it’s about the diversity that could be covered by 200 samples. And they have 1300 samples in total (1k/50/250)
Dev Aggarwal|2023-05-22 22:34:29|This is quite an insane video reconstruction follow up to the image reconstruction from fmri machines work
Pratyush Choudhury|2023-05-22 22:40:10|https://twitter.com/jerryjliu0/status/1660683176099078144?t=suncjjVwLbYRB2-3LMJBHg&s=19  This is pretty cool for Q&A systems - chunking a policy document and extracting every section with header hierarchy for knowledge retrieval
Dr. Ashith Generative AI WA Group|2023-05-22 22:53:54|The webpilot plugin for chatgpt is hallucinating a lot.  I asked it to summarise this repo for me and it responded with some completely unrelated text related to Azure. https://github.com/microsoft/guidance
Sandeep Srinivasa RedCarpetup|2023-05-22 22:59:14|https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/
~ VV|2023-05-22 23:03:27|‎~ VV joined using this group's invite link
~ Pradyumna Bang|2023-05-23 01:25:26|What's the cheapest way to deploy open source models like Vicuna for quick inference ? Want to create a streamlit/gradio chatbot.
Abhinav Verma Longshot.ai|2023-05-23 01:36:30|Has anyone got a chance to try the LIMA model?
Abhinav Verma Longshot.ai|2023-05-23 01:37:18|Also any torrent link for the weights
~ Nijil Y|2023-05-23 01:38:04|is there a link of independent comparison of free llms in the group somewhere. i couldnt find it
Abhinav Verma Longshot.ai|2023-05-23 01:39:02|not sure. but did someone share a HF space for this very same thing? Might be able to find one on twitter
~ bhanu.io|2023-05-23 01:43:45|Can use - https://github.com/Elyah2035/llama-dl for direct download , for torrent link, can search on 4chan
Sandeep Srinivasa RedCarpetup|2023-05-23 01:47:29|Is anyone here doing experiments with fine tuning using a company's internal data - like internal chat, word documents, etc.  What's ur experience been - what opensource models work ok here ?
Dev Aggarwal|2023-05-23 02:03:13|The code interpreter plugin is wildly good. It doesn’t just produce code and run it, it can split the problem into steps, run multiple blocks code, inspects the output and even corrects exceptions. ‎[5/23/23, 02:03:44] Dev Aggarwal: ‎image omitted
~ Nijil Y|2023-05-23 02:04:17|it can generate a graph ?
~ Nijil Y|2023-05-23 02:04:32|or it gave a data and you put it in excel
Dev Aggarwal|2023-05-23 02:04:42|It can do everything, images text audio video graphs animations ‎[5/23/23, 02:04:50] Dev Aggarwal: ‎image omitted ‎[5/23/23, 02:05:09] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-23 02:05:19|Used matplotlib ‎[5/23/23, 02:07:05] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-23 02:08:01|It even edits files - i can see crazy shift here in analyst jobs
Vimal Singh Rathore|2023-05-23 02:08:16|[PHONE]
~ Nijil Y|2023-05-23 02:13:30|sigh. that plugin doesnt seemed to be visible :(. there are some other 16 pages but not this ‎[5/23/23, 02:17:36] Dev Aggarwal: ‎image omitted ‎[5/23/23, 02:17:37] Dev Aggarwal: ‎image omitted ‎[5/23/23, 02:17:38] Dev Aggarwal: ‎image omitted ‎[5/23/23, 02:17:39] Dev Aggarwal: ‎image omitted ‎[5/23/23, 02:17:40] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-05-23 02:17:43|More stats - this thing is just super 😵 ‎[5/23/23, 02:20:13] Dev Aggarwal: ‎image omitted
~ Nijil Y|2023-05-23 02:20:50|ya seems like alpha release.
~ Nijil Y|2023-05-23 02:21:49|Anyone worked on possible ways on factchecking a given article using LLM's. Is it theoretically possible to do this. if yes what could be approach
Ravi Srinivasan|2023-05-23 06:16:37|Open ai has a classifier
Ravi Srinivasan|2023-05-23 06:16:41|https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text
Ravi Srinivasan|2023-05-23 06:16:51|But read limitations
Neeraj Kumar|2023-05-23 07:16:38|Which plugin?
Nirant|2023-05-23 07:20:33|Code Interpreter
Anshul Khandelwal Invideo|2023-05-23 07:47:59|Code interpreter is amazing! It's very close to talking to an analyst...
Dev Aggarwal|2023-05-23 07:49:37|PSA: this is not a plugin - you can’t write a plguin that replicates the behaviour of code interpreter
Nirant|2023-05-23 07:58:31|Decomposing this a bit:   Code Interpreter is GPT4 which is RLHF'd for certain behaviours e.g. use code to answer questions. This is a meaningful reliability upgrade e.g. code actually does what you ask it to.  You can add a Python REPL to GPT4 API and get very good results too — better than anything FOSS.
Neeraj Kumar|2023-05-23 07:58:37|Got it! Is it based on codex model?
Nirant|2023-05-23 08:00:01|GPT3.5 and GPT4 are both based on Codex.   Since Code Interpreter is a light fork of GPT4 (confirmed by an engineer on the Plugins team) — yes, it's a descendant of Codex
Anubhav mishra Zupay|2023-05-23 08:02:20|https://openai.com/blog/governance-of-superintelligence
Anubhav mishra Zupay|2023-05-23 08:02:24|Superintelligence in 10 years ?
Dev Aggarwal|2023-05-23 08:03:15|Yup, Its not just gpt4 + repl. There are other intricacies here. Like it has to inspect the contnents of a large file, without running out of context length, and has to carry out multiple steps without going into an auto gpt loop of doom. It will also ask follow up questions before writing code sometimes
jyotirmayjk Hackathon|2023-05-23 08:21:32|The reasoning shown by Code Interpreter is too good. For ex the analysis on “funniest authors” takes into account what can be possible,makes some assumptions,explains the limitations and then proceeds to do the further analysis.🤯
Shubham Sharma 2012C6|2023-05-23 08:43:55|How do these interpreters work?
Shubham Sharma 2012C6|2023-05-23 08:45:06|Is it trained on a data set of code?
Dev Aggarwal|2023-05-23 08:53:15|Trained by humans. To do specific tasks and create paths to solve problems by writing code and evaluating the outputs
Dev Aggarwal|2023-05-23 08:53:45|The trajectories are designed by humans and rlhf’d
Dhruv Anand|2023-05-23 08:54:51|But the code is run on an actual interpreter right?
Dev Aggarwal|2023-05-23 08:55:01|Yes
Dev Aggarwal|2023-05-23 08:55:38|It doesn’t have gpus though :D I told it to do vector search over the chat but it hung up trying to vectorize the data
Anshul Khandelwal Invideo|2023-05-23 08:57:40|Doesn't seem to have any direct context length improvements over gpt4 afaict...
Anshul Khandelwal Invideo|2023-05-23 08:58:46|Being able to load files into py memory and dealing with it via code is what creates the illusion
jyotirmayjk Hackathon|2023-05-23 08:59:50|Doesn’t need context length improvement for reasoning does it ?   You can setup a Python agent with LangChain ,load your csv files in a df ,and it still won’t be able to give you the same level of reasoning which the code interpreter is displaying
Anshul Khandelwal Invideo|2023-05-23 09:00:47|Sorry was responding to this...
jyotirmayjk Hackathon|2023-05-23 09:01:43|I’ve tried this with 3.5 and it was nowhere near the reasoning ability which Code Interpreter is displaying   Don’t know how the same setup will work with GPT-4 though
Anshul Khandelwal Invideo|2023-05-23 09:02:40|This is an experiment worth trying out with gpt4
Dev Aggarwal|2023-05-23 09:02:44|Yes, my point was that it knows implicitly that this context length exists, and writes code which respects this limit
Dev Aggarwal|2023-05-23 09:03:15|Eg see that it knows to sample 10 lines only
Dev Aggarwal|2023-05-23 09:04:11|Very much skeptical it will have comparable performance, even after tons of prompt engg
Ankit Saxena|2023-05-23 09:05:16|‎You added Ankit Saxena
Anshul Khandelwal Invideo|2023-05-23 09:08:52|Ummm... gpt4 might just be able to pull this off...    It's not bad at coding.  Next time I have a coding task I will test interpreter vs the base model on it.
Nirant|2023-05-23 09:11:43|Thought this might be interesting to you  https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html
Anshul Khandelwal Invideo|2023-05-23 09:18:55|This kind of an attack is unlikely to do well.   The magic of code interpreter comes from maintaining the pandas data frame between subsequent calls.  Something like rpyc would be what I would go for.
Dev Aggarwal|2023-05-23 09:19:39|Its not just dataframes from what I hear. It does images videos etc too
jyotirmayjk Hackathon|2023-05-23 09:19:57|You can also try this , https://github.com/gventuri/pandas-ai  Load data in data frame and ask questions over it  I haven’t tried it yet ,just one of many things to be tried still.
Anshul Khandelwal Invideo|2023-05-23 09:20:20|All via keeping the python state maintained between calls
Anshul Khandelwal Invideo|2023-05-23 09:21:01|Interesting though we need the exact reverse.
Anshul Khandelwal Invideo|2023-05-23 09:22:40|An open source code interpreter could actually be quite useful.  Openai doesn't allow their interpreter to make web calls.  Even some ability to download small model weights would dramatically improve usability.
Anshul Khandelwal Invideo|2023-05-23 09:23:33|For instance say upload csv of customer queries and have it clustered via something in nltk.
Anshul Khandelwal Invideo|2023-05-23 09:24:03|Tried something like that a few weeks back and it tried to do some downloads and failed.
Nirant|2023-05-23 09:25:21|Not FOSS, but since compute and network are needed: Replit has entered this chat  cc [PHONE] Anshul from Replit might find this interesting!
jyotirmayjk Hackathon|2023-05-23 09:26:37|What was the workflow you’d setup for this use case ?  I’m implementing a very similar usecase for NPS and feedback analysis ,but heavily using prompt engineering for it + embeddings
Anshul Khandelwal Invideo|2023-05-23 09:28:19|I just uploaded a csv to code interpreter, asked it for 5 ways of doing a clustering analysis on it and then asked it to execute no 3.
Anshul Khandelwal Invideo|2023-05-23 09:29:30|For stuff that fits on a pandas data frame this would be my preferred workflow...  It is quite smart about looking at the first few rows of data and coming up with a good plan
Dev Aggarwal|2023-05-23 09:29:53|I don’t think it maintains python state, does it?
Dev Aggarwal|2023-05-23 09:30:10|Maybe for a single generation it does
Anshul Khandelwal Invideo|2023-05-23 09:32:28|I am almost sure it does.  Will run a test and get definitive proof.
jyotirmayjk Hackathon|2023-05-23 09:32:47|Python agent in LangChain should be able to download required libs and dependencies when you just give an open ended task like this   Not sure how Code Interpreter handles this
Dev Aggarwal|2023-05-23 09:33:06|It says no
Dev Aggarwal|2023-05-23 09:33:08|😂🤡 ‎[5/23/23, 09:36:30] Anshul Khandelwal Invideo: ‎image omitted ‎[5/23/23, 09:36:31] Anshul Khandelwal Invideo: ‎image omitted
Anshul Khandelwal Invideo|2023-05-23 09:36:48|Confirmed.  See the use of the data dataframe between subsequent calls.
Dev Aggarwal|2023-05-23 09:37:15|Lovely
Dev Aggarwal|2023-05-23 09:37:30|Pyhton’s repr() is ❤️
Dev Aggarwal|2023-05-23 09:42:00|Interesting idea - can you give code interpreter the .pyi stub file for a new library/ private code and tell it to use the library? 😱 ‎[5/23/23, 09:49:06] Anshul Khandelwal Invideo: ‎image omitted
~ vignesh iyer✌️|2023-05-23 09:49:42|‎~ vignesh iyer✌️ joined using this group's invite link
Dev Aggarwal|2023-05-23 09:49:44|Must have the API 😭
Anshul Khandelwal Invideo|2023-05-23 09:51:02|Code interpreter is so powerful.  An unrestricted version of this would be awesome!  If I had any free time...
~ Kifilshah|2023-05-23 09:51:47|‎~ Kifilshah joined using this group's invite link
ashish Acgt01 Twitter|2023-05-23 10:09:54|‎ashish Acgt01 Twitter joined using this group's invite link
ashish Acgt01 Twitter|2023-05-23 10:11:50|Open AI blog post by Sam Altman, Greg Brockman & Ilya Sutskever on how to regulate future ai systems far more capable than ones that exist today   https://openai.com/blog/governance-of-superintelligence
~ Aman|2023-05-23 10:44:04|Can it also process sql dumps?
Dev Aggarwal|2023-05-23 10:45:07|I tried giving it a heavily nested json - doesn’t do well if you don’t give it a schema. But i guess with sql it can inspect schema
~ Aman|2023-05-23 10:46:02|With openAPI schema, it might do that
jyotirmayjk Hackathon|2023-05-23 10:52:17|https://twitter.com/ylecun/status/1660732998155640833?s=46&t=icC0fizZK8E3ONsDVuGFWA  Meta strikes again in open sourcing AI  Apparently 1k languages available as STT and TTS via one model which has half the WER as Whisper
Samhan Meta/Twitter Friend|2023-05-23 10:53:12|I guess this would include many Indian languages
jyotirmayjk Hackathon|2023-05-23 10:58:06|I’m doubting this just based on reading their training methodology   “As part of this project, we created a dataset of readings of the New Testament in over 1,100 languages, which provided on average 32 hours of data per language.  By considering unlabeled recordings of various other Christian religious readings, we increased the number of languages available to over 4,000. “
Paras Chopra Wingify|2023-05-23 10:59:42|https://arxiv.org/abs/2305.13048  Anyone played with RNNs as alternatives to transformers for language models
Nirant|2023-05-23 11:02:48|More accessible blog:  https://huggingface.co/blog/rwkv
Nirant|2023-05-23 11:02:53|And a HF space:  https://huggingface.co/spaces/Hazzzardous/RWKV-Instruct
Samhan Meta/Twitter Friend|2023-05-23 11:11:47|Makes me hopeful that open source community can drive things forward even if google etc stop publishing
Samhan Meta/Twitter Friend|2023-05-23 11:13:40|Could not understand it fully but it looks like context windows of 100k-500k could become normal if this works as the inference cost grows linearly
~ Dx|2023-05-23 11:16:11|Hiii everyone,   Has anyone come across some research work that talks about dataset size , complexity and coverage based on the complexity of task at hand ?
~ Dx|2023-05-23 11:16:27|Specifically for generative ai tasks
Aashay Sachdeva MPL Data Scientist|2023-05-23 11:27:18|https://twitter.com/togethercompute/status/1660767722073128960?s=46  Vicuna on iphone - just tried the app, slower response than even gpt4 but a peak into what apple probably would be building
Anirudth N|2023-05-23 11:28:16|Not sure if others have seen this, but I found this interactive categorization of the generative AI startup landscape useful. https://app.dealroom.co/lists/33530
Sachin Legaltech|2023-05-23 11:28:18|An interesting thread discussing potential limitations of RWKV and history of large scale RNNs https://twitter.com/smerity/status/1660786104377958400?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
Samhan Meta/Twitter Friend|2023-05-23 11:29:41|I have this app but I don’t open it anymore . It makes my phone heat up a lot and it becomes unstable
Samhan Meta/Twitter Friend|2023-05-23 11:30:52|But a year ago tbis would have been total science fiction
Samhan Meta/Twitter Friend|2023-05-23 11:32:47|Yeah one shouldn’t jump on this kind of researchy stuff. Transformers have a huge ecosystem around them that’s growing every day. It will take a lot of time to replicate that.
Sachin Legaltech|2023-05-23 11:37:16|RNNs don’t need to replace transformers..Ability to have ready made embeddings is useful in at least a few niche applications.
Sachin Legaltech|2023-05-23 11:43:21|+ faster inference particularly on long sequences
Dr. Ashith Generative AI WA Group|2023-05-23 11:46:55|Not a comparison but a list  https://github.com/eugeneyan/open-llms
~ Dx|2023-05-23 11:52:22|Nfx.com has an exportable csv
~ Nijil Y|2023-05-23 12:14:19|Thanks. I did see this. Only if there was objective comparison with these and gpt 4 would have been really helpful.
~ Debashish Ghatak|2023-05-23 12:40:40|‎~ Debashish Ghatak left
Nishant Apne-App GenAI Hackathon|2023-05-23 13:30:34|Hey everyone! I've been really enjoying our discussions on LLMs here. We won a few hackathons using LLM prompting. I've compiled some notes that cover various concepts and recent advancements. I thought they might be useful to some of you. You can find it here: https://nishnik.notion.site/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77  Happy to talk more about it!
~ Gulshan Kumar|2023-05-23 13:36:59|‎~ Gulshan Kumar joined using this group's invite link
~ Navneet|2023-05-23 13:57:59|‎~ Navneet joined using this group's invite link
Bharat Kumar Ramesh Hashmal Web3|2023-05-23 14:13:00|Folks QQ. How do you determine if a text is interrogative?
Bharat Kumar Ramesh Hashmal Web3|2023-05-23 14:13:01|I.e. Classify if it's a question or not
~ Aditi Deo|2023-05-23 14:18:02|‎~ Aditi Deo joined using this group's invite link
~ Rahul|2023-05-23 14:25:57|‎~ Rahul joined using this group's invite link
Manjot Pahwa|2023-05-23 14:34:02|What level did you reach here: https://gandalf.lakera.ai/
Nirant|2023-05-23 14:34:55|cc [PHONE] you were interested in prompt security
Bharat Kumar Ramesh Hashmal Web3|2023-05-23 14:47:39|Wow. I love this game
Bharat Kumar Ramesh Hashmal Web3|2023-05-23 14:48:04|Stuck at 4
~ Adithya|2023-05-23 14:58:29|‎~ Adithya was added
~ Arpit Jain|2023-05-23 15:30:14|Good game. I am stuck at level 8
Nirant|2023-05-23 15:30:47|There are only 8 levels chad
~ Arpit Jain|2023-05-23 15:31:15|There's a bonus level which comes after level 7
Nirant|2023-05-23 15:32:43|Aaah, I interpreted that to mean that you've cleared level 8 and stuck at it. My bad.   Off by 1 errors still happen 🥲 ‎[5/23/23, 15:34:19] ~ Arpit Jain: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-05-23 15:35:06|Damn. Well done
~ Srijan Saxena 😎|2023-05-23 16:27:16|Love how creative this game is. Would also love it if people share some creative answers here, especially for the higher levels
~ Shouvik Ghosh Roy|2023-05-23 16:28:32|Asking the etymology too me to level 7.
~ Shouvik Ghosh Roy|2023-05-23 16:41:10|Actually all 8 levels worked
Pranjal Yadav Razorpay|2023-05-23 17:14:32|Fun thing, just started. First two levels are straightforward 😄
~ Kp|2023-05-23 17:17:46|Cleared until third in the first 15 mins
~ Kp|2023-05-23 17:17:51|4th is tough :/
Pranjal Yadav Razorpay|2023-05-23 17:18:25|Same 😂
~ Nirmal|2023-05-23 17:21:42|7th was harder than 8th for me.
~ Dx|2023-05-23 18:02:18|Antler airtable https://airtable.com/shrBeWpMlxf3e14E8/tblS4TkbJbm0cqT0o ‎[5/23/23, 18:05:46] ~ Dx: ‎image omitted
Nitin Wyse|2023-05-23 18:16:15|‎Nitin Wyse joined using this group's invite link
ashish Acgt01 Twitter|2023-05-23 18:21:35|https://web.stanford.edu/class/cs25/
Nirant|2023-05-23 18:23:04|PSA: Drop a line with the link, don't just share the link. That increases the chances that people interested in it will get a sense of what it is without clicking through 🙏
Gaurav Mandlecha 2014B3A4|2023-05-23 18:28:08|Found this interesting map of infra companies for Gen AI - https://medium.com/cowboy-ventures/the-new-infra-stack-for-generative-ai-9db8f294dc3f  Was pleasantly surprised to see Portkey ([PHONE]) featured here :)
ashish Acgt01 Twitter|2023-05-23 18:28:30|Stanford course on transformers .  Some course videos are available on YouTube :  https://youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM
Nirant|2023-05-23 18:29:39|Are there more Generative AI companies than devs who can RLHF a Llama model?
~ Dx|2023-05-23 18:34:51|[PHONE] any comments about this space ?  Surprised to see not enough MLops jumping this bandwagon .  First time posting here , not sure if I’m asking appropriate questions
ashish Acgt01 Twitter|2023-05-23 18:59:59|Has anybody here tried the ChatGPT iOS app in india?  https://openai.com/blog/introducing-the-chatgpt-app-for-ios  Thoughts/feedback ? How does the voice interaction feature work in day to day use ?  For me, am unable to install it :/ (iOS16.5)
Nirant|2023-05-23 19:02:18|From DMs: Are there more Generative AI companies than dev who know what RLHF stands for? 🤣
Prayank Swaroop Accel|2023-05-23 19:03:14|Can anyone recommend good MLOps platform ..that supports training multiple models - supports multi-modal and as well as helps in deployment optimization ?
Nirant|2023-05-23 19:04:24|AWS Sagemaker, Replicate (limited but dead cheap)
ashish Acgt01 Twitter|2023-05-23 19:05:38|I think even in this group a lot of us know what it is and how it works in theory but doing RLHF *well* in practice is what will ensure GPT4 like performance & is OpenAI's sweet spot.  Open-source RLHF datasets are beginning to become available though, I think
Dev Aggarwal|2023-05-23 19:49:20|yes, you need to - 1.  create another icloud account 2.  set region to US (involves verifying a US address and  number https://www.receive-sms-online.info/) 3.  logout of your current account in the appstore app 4. login with the other acccount
Dev Aggarwal|2023-05-23 19:49:43|The app is pretty slick, and whisper + gpt4 is just too nice to use
Dev Aggarwal|2023-05-23 19:55:11|I don't think this exists, whatever exists is probably ~25% of what we want here, and is probably the biggest opportunity for infra startups right now
Dev Aggarwal|2023-05-23 19:57:05|https://www.youtube.com/watch?v=ut5kp56wW_4  Paper summary!
Anshul Bhide Replit|2023-05-23 21:35:24|doesn't mosaicML do this? I don't think its multimodal but it does help in deployment optimization https://www.mosaicml.com/
Chinmay Shah Arrowhead|2023-05-23 21:39:57|https://twitter.com/JosephJacks_/status/1660747216561254400?s=20😂
Nirant|2023-05-23 21:40:00|There are bunch of dataset companies from the last ML bull run e.g. Scale.ai which are now moving towards this in some way or the other. With datasets like PILE and more coming along, I suspect for text-LLMs FOSS Datasets will win.   Specially for instruction tuning and RLAIF e.g. Vicuna, Alpaca, are all RLAIF models from FOSS datasets.  This does leave open the case of models trained on open licenses, there too — domain specific datasets have begun to see industry adoption e.g. Replit chose to train their base model on Stack Dedup (v1.2?) https://huggingface.co/replit/replit-code-v1-3b  I'm generally net short on commercial, non-FOSS LLM Ops tools seeing bottom up adoption with Generative AI apps at this part of the hypecycle. The FOSS quality is simply too good to be competitive.  Of course, as the cycle fades, lot of the margins accrue to enterprise software
~ Arka|2023-05-23 21:44:44|Anyone can explain to me how the problem of long sequences in transformers was solved?  I mean at one time we had these specific datasets for this tasks and ppl were trying to come up with solutions like BigBird, Longformer, etc. Which were better but not cutting it.  Then how did we suddenly move to 32 or 100k context? What innovation had happened?
Nirant|2023-05-23 21:50:33|cc [PHONE] is perhaps the best person to answer this. But more generally, this is still an unsolved problem.   Most long form models are open to long input, but output constrained e.g. Anthropic is constrained to 2K tokens. This constraint indicates there could be a decoder at work, and not just an auto-regressive model like GPT2.  The other is the ability to scale up innovations like:  1. Longformer (https://arxiv.org/abs/2004.05150, https://huggingface.co/docs/transformers/model_doc/longformer) — introduced in 2020, explained how attention could work with RoBERTa 2. Flash Attention (https://github.com/HazyResearch/flash-attention) — which demonstrated that you could do memory efficient and exact attention 3. Linear Attention (https://github.com/lucidrains/linear-attention-transformer) — which was O(n) compared to the usual O(n^k) where K is a function of specific implementation and n is number of tokens.
Abhinav Verma Longshot.ai|2023-05-23 21:51:26|Would multi query attention be also considered something that helped here
~ Arka|2023-05-23 21:52:07|Thanks for your comprehensive answer.  but you say Anthropic is constrained to 2k tokens. Didn't they just launch 100k Claude?
Abhinav Verma Longshot.ai|2023-05-23 21:52:28|I think he means response tokens
~ Arka|2023-05-23 21:52:36|Got you
Nirant|2023-05-23 21:52:50|Yes, this is what I meant!
Abhinav Verma Longshot.ai|2023-05-23 21:53:11|It's same with gpt4. Even though you can set theoretically 5k response tokens it hangs
Raghotham Paypal Bargava's Friend|2023-05-23 21:53:39|Add ALiBi as well?  https://arxiv.org/abs/2108.12409
Raghotham Paypal Bargava's Friend|2023-05-23 21:54:25|Mpt models are based on ALiBi and flash attention.
Nirant|2023-05-23 21:55:50|Yeah, ALiBi counts!
Nirant|2023-05-23 21:56:18|I hit the limit of my output/response tokens too 😂
Sachin Legaltech|2023-05-23 21:58:37|The way Mosaic ML approached this with their MPT storywriter model (https://huggingface.co/mosaicml/mpt-7b-storywriter) was that they just finetuned base model with 4096 sequence length on books with longer sequence length. The input sequence to transformer models is of dimension : L * d where L is our sequence length and d is embedding size.So with existing base models, we can train derived models with longer sequence lengths; just doing so would cause us having large Q, K and V matrices.
Sachin Legaltech|2023-05-23 22:14:43|https://twitter.com/ofirpress/status/1657040700062441475?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Author of Alibi is stating finetuning is the way to go as 99% of documents in PILE or similar datasets are less than 500 tokens long.
Rohan Manchanda|2023-05-23 22:21:12|"QQs: a) this 1 token = three fourth of a word / 4 or 5 characters, right for all LLMs?  b) what's the ""so what"" of this 500 token fact and what are the top implications does it have on use cases for the end user?"
Sachin Legaltech|2023-05-23 22:22:41|A) yes..that’s 1token
Sachin Legaltech|2023-05-23 22:27:22|B) because most of the documents are less than 500 tokens. For a base model with 2k context length, most of the time we will be fitting 4 documents together for a single forward pass. If we increase the sequence length, we would fit more documents for a single forward pass. But tokens in document 1 won’t be helping us in predicting tokens in document 2. Hence, he is saying it doesn’t make much sense to increase context length to 100k while training base models.
Nirant|2023-05-23 22:32:35|ICYMI: Community's Generative AI May Meetups:   Open for all: https://hasgeek.com/generativeAI/may-meetup/  Women in AI: https://hasgeek.com/generativeAI/women-in-ai-meetup/
Amit Tiwary|2023-05-23 22:47:26|There's also questions around middle context accuracy in Anthropic's particular case:  https://twitter.com/dylan522p/status/1658147304094973957?t=NsYH5b0M4qYo3Rr6DTQWqA&s=19
Amit Tiwary|2023-05-23 22:47:45|Prompting this gold of a meme by Karpathy xD  https://twitter.com/karpathy/status/1658161721251602432?t=Vr4eRdzjkp3FK6VKEfcoCA&s=19
~ Arka|2023-05-23 22:48:29|Probably using heuristics
Saiyam Wyse|2023-05-23 23:12:32|‎Saiyam Wyse joined using this group's invite link
Rohan Manchanda|2023-05-23 23:28:13|Helpful. Thank you Sachin
Shubham Sharma 2012C6|2023-05-23 23:28:52|Anything in mumbai?
~ Dx|2023-05-23 23:34:36|Thanks sir 🎅
Swastik Banerjee|2023-05-24 03:20:56|this was pretty fun lol. feel like a pro level-4 gaslighter now
~ Ravi Trivedi|2023-05-24 05:04:50|"The Bill & Melinda Gates Foundation today launched a new Grand Challenges (GC) request for proposals, ""Catalyzing Equitable Artificial Intelligence (AI) Use"".  Level: Up to $100,000 USD/project Duration: 3 months Application deadline: 5 June 2023, 11:30 AM Pacific Time  You can find additional information about the call for proposals at this link. https://lnkd.in/gZZH2SYb  Harnessing the potential of AI can improve the lives and wellbeing of vulnerable communities everywhere including those of women and children. As AI technology continues to swiftly evolve and advance, the global community must move with urgency to ensure low- and middle-income countries (LMICs) are included in the co-creation process."
~ Ravi Trivedi|2023-05-24 05:05:33|Would someone in the group have interest in the above.  Currently, I work at the intersection of technology, social good and policy and want to partner up with someone to explore the above question. Please DM me if above would be interesting.
Nirant|2023-05-24 06:49:27|In June, yes
~ Aravind Pai|2023-05-24 07:52:55|‎~ Aravind Pai left
jyotirmayjk Hackathon|2023-05-24 07:58:11|For anyone who has implemented txt2sql ,without fine tuning   How do you pass db schema as context without stuffing it in prompt every time?  One way I’ve seen is Llama Index using vector indexes created on db schema  But can you do semantic search over schemas stored in vector dbs and find out table relationships like which is the primary key for 2 tables ?
Nirant|2023-05-24 08:07:54|Cc [PHONE] since we discussed this yesterday
Shashwat TDC|2023-05-24 08:26:39|hi yes, we have used it without fine-tuning but we are yet to run into the prompt size limit prob. I might be able to add more on this in 2 weeks. But fundamentally we want to use something like Llama index to index, save and query the context in/ from embedding space. So to answer your question, yes we can do semantic search for the mentioned use-case.
jyotirmayjk Hackathon|2023-05-24 08:50:21|So I can just embed the db schemas and at time of querying it will fetch best matching schema for the query and use it in prompt    But what I’m not able to wrap my head around is this scenario I embed schema for 2 tables let’s say customers,orders with customer_id as unique key along with 50 other tables  When I run a query like find customers with highest number of orders,it should return a query joining customers table with orders   What I don’t get is similarity search will show best semantically matching schema for the query then how can it show relation between tables ?
Pratik Bhavasar|2023-05-24 09:27:22|[PHONE] Why are you doing semantic search over schemas? Do you take only top 1 retrieved DB schema in the prompt for query gen?
Shashwat TDC|2023-05-24 10:16:31|Yes. The answer lies in how your are creating the text corpus and how you are indexing them. Point to remember that these models are probabilistic models and they try to predict the next token by analysing patterns in Corpus. Optimizing the accuracy of such mismatches in your particular usecases is also where the startups like us add value.
Samhan Meta/Twitter Friend|2023-05-24 10:17:39|I would suggest breaking the task down into smaller pieces and using multiple LLM calls.
Samhan Meta/Twitter Friend|2023-05-24 10:18:24|For eg the first one will only be a list of tables wirh primary / foreign key and a short description. You can fit upto 50-60 tables. That can be the first call.  Once you have the list of tables you can only include their schemas and try to generate. If that’s not working you can try again.
jyotirmayjk Hackathon|2023-05-24 10:19:58|I’m currently implementing this  https://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/SQLIndexDemo-ManyTables.html  And I was trying to see how table relations can be embedded
Shashwat TDC|2023-05-24 10:21:54|Sorry removing it for second order reasons.
jyotirmayjk Hackathon|2023-05-24 10:24:24|Generally for text corpus on the table description/relations I’m trying to embed files from data cataloging tools like Amundsen   Lets assume that data catalog has all the required information ,then what could be the various ways we index this information so semantic search gives the correct info ?  https://www.amundsen.io/
Sandeep Srinivasa RedCarpetup|2023-05-24 10:24:44|i dont think u can do this. because LLM will want full table info to start deducing. so u will need to stuff it into context - it will be hard to just query the vector db to do most of the work. so ur right in ur similary search problem.  at best what u can do is break ur prompt into two parts:  first one gets the tables involved in the query and the second one stuffs all these tables into context and sends it to llm.
Sandeep Srinivasa RedCarpetup|2023-05-24 10:27:16|"another complexity is when u have ""type"" fields in ur db table. (for e.g. type ==<cat,dog,monkey>). so the LLM needs to know about these types before it can generate a query. that means for these kind of columns, u need to send descriptions of columns as well...otherwise the query will fail"
jyotirmayjk Hackathon|2023-05-24 10:28:14|At enterprise scale then it seems to me that this would break the text2sql workflow.It will always run into context length limitations    Other option is to ask user to specify table name and relevant relations but it’s not very user friendly.
Sandeep Srinivasa RedCarpetup|2023-05-24 10:30:51|"if ur doing the ""type descriptions"" i mentioned above..yes it will break the context length."
Samhan Meta/Twitter Friend|2023-05-24 10:48:17|Start this way … track your mistakes and then fine tune once you have enough samples. It should always be suggestions and not always be executed.
Samhan Meta/Twitter Friend|2023-05-24 10:48:24|Copilot model - show completions and track acceptance rate
Samhan Meta/Twitter Friend|2023-05-24 10:49:33|Make an assistant / suggestion tool. This allows for slowly boot strapping better things from data.
~ Nithyakala|2023-05-24 10:56:14|‎~ Nithyakala joined using this group's invite link
~ Shifa|2023-05-24 11:56:03|‎~ Shifa joined using this group's invite link
~ Nikhilesh Jha|2023-05-24 13:46:21|Has anyone worked on Generative AI tools for identity management? For example, 3D avatars? If so, can you direct me to such open-source resources and the current landscape (both funding-wise and use cases)?
~ Akash Doifode|2023-05-24 14:00:36|‎~ Akash Doifode joined using this group's invite link
Swastik Banerjee|2023-05-24 15:51:33|Is anyone working with chatgpt-retrieval-plugin? I added a custom metada, but it seemed to allow far more context than what was allowed for the main “text” field. How are metadatas incorporated into the embeddings?
Nishant Wyse|2023-05-24 15:57:56|‎Nishant Wyse joined using this group's invite link
Swastik Banerjee|2023-05-24 16:08:56|*far more tokens
Lalit Pagaria|2023-05-24 16:11:19|https://github.com/ricklamers/gpt-code-ui  People who don't have a code interpreter access can check this out.
~ Ankur Khandelwal|2023-05-24 17:17:14|Open AI prompt related -  Is there a way to force the open ai response in specific json format?
~ prthamesh|2023-05-24 17:18:20|Guardrails helps you do that: https://getguardrails.ai/ (I’ve not used it personally, but folks are using it)
Aashay Sachdeva MPL Data Scientist|2023-05-24 17:22:32|Try jsonformer
~ Prashant|2023-05-24 17:22:34|https://lmql.ai/
Nishant Apne-App GenAI Hackathon|2023-05-24 17:27:35|There is a library by Microsoft. https://github.com/microsoft/guidance  They control the output using `handlebars` templating.  It can also help when you want json responses' value to be guided. But needs access to logits (Llama type OSS models).
~ prthamesh|2023-05-24 17:34:06|Anyone here got access to Anthropic’s Claude Instant API?
~ Ankur Khandelwal|2023-05-24 17:37:07|do you any example for open ai model?   What is the value you need to pass for the tokenizer in case of open ai
The GenerativeAI Group|2023-05-24 17:38:02|‎Soumyadeep Mukherjee added ~ Mayank Jain and ~ Rupali
Rohit Aggarwal|2023-05-24 17:47:04|jsonformer won't work with OpenAI. You're better off using guidance or guardrails
~ Ankur Khandelwal|2023-05-24 17:47:26|okay.
Dhruv Anand|2023-05-24 17:54:41|I'm making do with a piece of code like https://github.com/hwchase17/langchainjs/blob/main/langchain/src/agents/chat_convo/outputParser.ts#L24-L37 Of course I asked for json in the prompt. The other tools seemed too heavyweight
~ Ankur Khandelwal|2023-05-24 17:57:10|"Open ai returns the keys(""name"") different sometimes, then it starts creating the problem"
Nirant|2023-05-24 18:51:54|Chip Huyden and Amjad discuss LLMs in Production Challenges, register for invite: https://lu.ma/cs5vbjt3?tk=WyJJD3
Anshul Bhide Replit|2023-05-24 18:55:41|fyi - this will be a livestream on YouTube
Abhinav Verma Longshot.ai|2023-05-24 18:59:12|Which channel
Anshul Bhide Replit|2023-05-24 18:59:43|if you register here, you'll get the Youtube livestream link!
Nirant|2023-05-24 19:38:46|Livestream Link: https://www.youtube.com/watch?v=zXX0I6dOPYk
ashish Acgt01 Twitter|2023-05-24 20:07:57|Talk by Karpathy at Msft build   https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2
Sidhant Sequoia|2023-05-24 20:08:13|Real good
Rohil Bagga Lightspeed|2023-05-24 20:32:03|‎Rohil Bagga Lightspeed joined using this group's invite link
Abhinav Verma Longshot.ai|2023-05-24 23:11:18|anyone here
Anshul Bhide Replit|2023-05-24 23:14:14|https://www.youtube.com/watch?v=zXX0I6dOPYk
Abhinav Verma Longshot.ai|2023-05-24 23:14:49|am there
Abhinav Verma Longshot.ai|2023-05-24 23:20:39|Some interesting points discussed here
Nirant|2023-05-24 23:23:49|Wow, less than 100 live viewers for Chip Huyen! Lot of alpha there
~ Aryan Kuttappa|2023-05-24 23:36:02|‎Dev Aggarwal added ~ Aryan Kuttappa
Prayank Swaroop Accel|2023-05-24 23:47:26|Waiting for the day when we have, 1000+ folks to listen to an Indian AI startup founder.   One day ..
Abhinav Verma Longshot.ai|2023-05-24 23:48:49|depends on the talk and who you're targeting, LongShot had SEO related webinars where we discussed our semantic SEO feature, we got a few hundred, but yes they were mostly non technical
Samanyou WriteSonic|2023-05-24 23:56:18|Hi all, I am Sam, founder of Writesonic. Been playing with generative AI for the last few years.  Excited to join this group and learn from you all 🚀 Also, if any of you are looking for AI/ML roles in generative AI, do ping me.
Dev Aggarwal|2023-05-24 23:56:39|Shark tank bro 😂
Sachin Legaltech|2023-05-25 00:38:13|https://twitter.com/tengyuma/status/1661412995430219786?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ A new optimizer which can achieve same performance as Adam with half the number of tokens.
Swastik Banerjee|2023-05-25 00:45:52|anyone?
Abhinav Verma Longshot.ai|2023-05-25 01:19:46|Haven't worked with it. But you need to check how the chunking is done of text to create the embeddings
~ Nijil Y|2023-05-25 01:22:26|Anyone here working on factchecking the output of an LLM's. Architecture suggestions would be great
Swastik Banerjee|2023-05-25 01:57:42|For people who have worked with chunking data/documenta before: Suppose I have 5 documents. With the chunking (i.e., recursive text-splitter?) method I use, the 1st document gets chunked into 3 parts, 2nd document gets chunked into 5 parts, etc.  OpenAI’s embedding model creates a vector of size 1536 for each such chunk.  So, for the 1st document, the dimension of embedding-vector will be (3,1536) For the 2nd, it’ll be (5,1536)…etc.  Isnt this (irregular size) a problem during retrieval? How is it handled? I thought it needs to be of the same size…?
Soumendra Dhanee|2023-05-25 02:15:56|During retrieval, we're not looking at (searching for) documents any more, but at chunks, which now all have the same size: (1, 1536).
Swastik Banerjee|2023-05-25 02:21:43|And what if my question has one part of answer in one of the chunks and the in another chunk of the same document?
Swastik Banerjee|2023-05-25 02:22:05|Splitting up a document honestly doesn’t sound a good idea to me. Are there any workarounds for this? ‎[5/25/23, 02:23:26] Shalabh Aspiro: ‎image omitted
Soumendra Dhanee|2023-05-25 02:23:43|Which is why you always chunk with some overlap, which you may have to tune for your dataset.
Swastik Banerjee|2023-05-25 02:24:18|also, to be clear my question sort of translates to “what chunking system does chatgpt-retrieval-plugin use”, if anybody has an idea about it already:-)
Shalabh Aspiro|2023-05-25 02:25:26|+1 Choosing the right kind of split for your usecase is also worth consideration. You need to specify/choose the splitting criteria in a way that suits your usecase
Soumendra Dhanee|2023-05-25 02:25:30|Most vector stores (at least the good ones) support batch insertion which is faster, so it makes sense to create a bunch of docs (chunks actually) and their embeddings and insert them with one command.
Soumendra Dhanee|2023-05-25 02:27:03|The only real workaround for this is longer context window for the LLM, which is not in our hands. So we'll be doing chunking before retrieving for a while.
Swastik Banerjee|2023-05-25 02:27:34|interesting…
Swastik Banerjee|2023-05-25 02:31:03|chunk overlap sounds a difficult problem, and subjective and very very specific to usecases
Soumendra Dhanee|2023-05-25 02:45:16|No no, it's not that difficult at all. Most libs around this (like langchain) already have params that let you do this easily. Where some thought is required (like code or markdown or msword doc), usually you need to split carefully in the first place and don't need chunking.
Soumendra Dhanee|2023-05-25 02:45:55|Or, at least, if you have thought through splitting, chunking strategy will be self-evident.
~ Vik|2023-05-25 06:30:37|a bit biased since i built it but it's the simplest of all of solutions out there and supports zod schemas to get structured data out of llms https://github.com/dosco/minds
Dev Aggarwal|2023-05-25 06:44:00|https://geohot.github.io//blog/jekyll/update/2023/05/24/the-tiny-corp-raised-5M.html  This. So much this. About time someone started writing PyTorch for and cards 💓
Dev Aggarwal|2023-05-25 06:44:03|AMD cards*
Dev Aggarwal|2023-05-25 06:46:17|“If NVIDIA is the Apple, we are the Android.” 🤌
Edgar Monis Mumbai WHO|2023-05-25 07:00:02|Love love love the sentiment.  However geohotz is mistaken in thinking this will open up the ML hardware market.  Imo (and i could be wrong) if he succeeded, he will have converted a monopoly to an oliogopoly.
Dr. Pratik Desai KissanGPT|2023-05-25 07:04:20|Building a developer EcoSystem around chip is very tough. I see only three success stories in last 15 years, Apple, Android and Nvidia. Even Meta couldn't do it well for Oculus.
Dev Aggarwal|2023-05-25 07:05:48|You can’t build a great business with perfect market competition. All insanely profitable companies must be in some sort of oliogopoly to succeed (not monopoly because otherwise you get anti trust lawsuits)
Edgar Monis Mumbai WHO|2023-05-25 07:07:44|Not just that,  You need insane investment to get something started to begin with
~ Shobhit Jaipurkar|2023-05-25 07:08:25|Geohot really loves this analogy 🤣 He said the same thing for Tesla and Comma
Harsh Gupta Felvin|2023-05-25 07:54:17|This is super cool, wishing geohot all the very best!
Kiran Jonnalagadda|2023-05-25 08:34:10|‎You added Kiran Jonnalagadda
Nirant|2023-05-25 08:55:30|QLoRA: *4-bit* finetuning of LLMs!   Releases a Chat LLM: Guanaco Single, 48G GPU, achieving 99% ChatGPT performance on the Vicuna benchmark (ELO style)  Paper: https://arxiv.org/abs/2305.14314 Code+Demo: https://github.com/artidoro/qlora  PS: I know ELO is iffy, but it's better than nothing 😅
Sanchi Khurana|2023-05-25 09:12:36|‎Sanchi Khurana joined using this group's invite link ‎[5/25/23, 09:18:33] Nirant: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-05-25 09:20:55|Take a look at Nvidia earnings and share price
Bharat Kumar Ramesh Hashmal Web3|2023-05-25 09:20:58|After markey ‎[5/25/23, 09:21:44] Bharat Kumar Ramesh Hashmal Web3: ‎image omitted
Sanyam Bhutani|2023-05-25 09:34:40|So cheaper than openai now 🤔
Sanyam Bhutani|2023-05-25 09:34:49|I think Claude is the most expensive to infer ab
~ As|2023-05-25 09:38:23|‎~ As joined using this group's invite link
Harsh Gupta Felvin|2023-05-25 09:40:18|How does Cohere compares to OpenAI in terms of quality? ‎[5/25/23, 09:41:46] Dev Aggarwal: ‎image omitted
Aashay Sachdeva MPL Data Scientist|2023-05-25 09:42:27|https://twitter.com/omarsar0/status/1661540207206846464?s=46&t=NNw5PElvtyZ9tUru_KLDVw  training llms to call APIs - isn't this just overfitting on the training data?
~ Ankur Khandelwal|2023-05-25 09:43:18|I am damm sure if they are listed in Indian market. they will gain atleast 4x-5x... 🤑🤑🤑
Shashwat TDC|2023-05-25 09:45:29|Curious why do you say so
~ Ankur Khandelwal|2023-05-25 09:46:08|just seeing the last rallies in indian market... no data backed
Shashwat TDC|2023-05-25 09:46:58|Hmm. I thought there is some signal which hints higher number of demand for GPUs in Indian ecosystem vs US/ EUR. But, got it.
Dr. Pratik Desai KissanGPT|2023-05-25 09:52:28|that will add $750B market cap over night
Dr. Pratik Desai KissanGPT|2023-05-25 09:53:27|20% of entire BSE
~ Ankur Khandelwal|2023-05-25 10:02:09|don't convert directly dollar into rupees.. stock price will defiantly be on the lower side if  it listed in the indian market.
Aashay Sachdeva MPL Data Scientist|2023-05-25 10:10:08|Most of it will anyway be fdi
~ Ankur Khandelwal|2023-05-25 10:11:10|nah, indian retail investor/developer will invest a lot. ‎[5/25/23, 10:26:21] Aashay Sachdeva MPL Data Scientist: ‎image omitted ‎[5/25/23, 10:28:22] ~ Aravinth Kumar: ‎image omitted ‎[5/25/23, 10:40:58] Sudharshan GenAI: ‎image omitted
Sudharshan GenAI|2023-05-25 10:41:18|App store US
Dr. Pratik Desai KissanGPT|2023-05-25 10:43:23|Tensorflow is the floppy disk of AI era
Dev Aggarwal|2023-05-25 10:43:42|My takeaway from both chatgpt and character ai app store launches - its easier to scale massively on web first - you probably don’t need an app!
Shashank Generative AI Group|2023-05-25 10:45:24|"not entirely surprising given that their main use case is ""mann ki baat"" 😂"
Aashay Sachdeva MPL Data Scientist|2023-05-25 10:47:13|100%. The code didn’t work out of the box. Now will have to dig into it. Just to upload a dataset
Sudharshan GenAI|2023-05-25 10:48:14|You need an app. All the other AI chat apps are on mobile.
Sudharshan GenAI|2023-05-25 10:48:35|Started on mobile too.
Sudharshan GenAI|2023-05-25 10:48:54|Chat is native to mobile over web
Dr. Pratik Desai KissanGPT|2023-05-25 10:49:48|Tensorflow was the reason I took break from DL during 15-17 and focused on just ML  thinking this is not going to work out for real world applications.
Sudharshan GenAI|2023-05-25 10:50:09|https://twitter.com/andreyzagoruiko/status/1655046102738173954  Mobile AI Chat apps make 200K$+ per month ‎[5/25/23, 10:50:37] Sudharshan GenAI: ‎image omitted
Dev Aggarwal|2023-05-25 10:52:07|All of these combined are <1% of chatgpt
Dr. Pratik Desai KissanGPT|2023-05-25 10:52:22|There is a saying in Hindi “Ganv basa nahi, lootere aa gye”, every time something good start taking place grifters are first to come.
Sudharshan GenAI|2023-05-25 10:52:40|translate please? :P
Aashay Sachdeva MPL Data Scientist|2023-05-25 10:53:09|We should both go to therapy sponsored by tensorflow support group. I did the same
Sudharshan GenAI|2023-05-25 10:53:13|ChatGPT makes 100M$/month?
Dev Aggarwal|2023-05-25 10:53:17|Riding the wave 🌊
Dr. Pratik Desai KissanGPT|2023-05-25 10:53:33|Before a settlement even start taking place, bandits(lootere) are there
Dev Aggarwal|2023-05-25 10:53:39|Sorry I meant in terms of user count. Not sure what the revenue numbers are
Samhan Meta/Twitter Friend|2023-05-25 10:54:12|https://poe.com/s/kBjvkzP5fiwOWn1bo21W
Samhan Meta/Twitter Friend|2023-05-25 10:54:45|Honestly stuff like this continues to blow my mind. How is this possible 😁
Dev Aggarwal|2023-05-25 10:54:53|Character.ai too is much much bigger. And has insane retention compared even YouTube
Sudharshan GenAI|2023-05-25 10:55:08|Don't get how these apps are robbers/scammers
Dev Aggarwal|2023-05-25 10:55:35|Oh, sudarshan
Samhan Meta/Twitter Friend|2023-05-25 10:56:03|I find this claim interesting. Coz I don’t know anyone that uses it. 😜
Samhan Meta/Twitter Friend|2023-05-25 10:56:26|And not even on Reddit or anything is it discussed much
Dev Aggarwal|2023-05-25 10:57:02|https://www.similarweb.com/amp/blog/insights/ai-news/character-ai-engagement/  “According to today’s Reuters story, AI chatbot Character.AI, with no revenue, raises $150 mln led by Andreessen Horowitz, Character.AI says users spend an average of two hours per day on the site. That’s consistent with Similarweb estimates that time per visit has ranged from 25.4 to 29.7 minutes in recent months, which could easily add up to two hours across a few visits. That time per visit is about 3 to 4 times higher than the average for the top 100 websites – higher even than YouTube, which is famous for claiming lots of user time.”
Samhan Meta/Twitter Friend|2023-05-25 10:57:51|So ChatGPT subreddit has 1.7 million members and 10k ppl online right now. Character AI - 80k members and 1k ppl online
Dev Aggarwal|2023-05-25 10:58:08|Curious how much time people spend on kissan ai [PHONE] 👀
Dr. Pratik Desai KissanGPT|2023-05-25 10:58:13|Don’t take it literally, just a joke
Dev Aggarwal|2023-05-25 10:58:44|Robbers is a metaphor for stealing a chunk of the limelight
Dr. Pratik Desai KissanGPT|2023-05-25 10:59:20|Don’t take it literally Bhai, just a light hearted joke.
Dr. Pratik Desai KissanGPT|2023-05-25 11:01:06|I don’t have stats for apps yet but on web avg 2m per session, went up 2x in a month. I was expecting to go down with more users but it is climbing everyday. Probably a good sign.
Samhan Meta/Twitter Friend|2023-05-25 11:01:47|Impressive !
Samhan Meta/Twitter Friend|2023-05-25 11:01:56|What kinds of things are people asking ?
Samhan Meta/Twitter Friend|2023-05-25 11:06:05|I love the UX. You can introduce a share feature. Like Poe. That will increase sharing and organic growth
Dr. Pratik Desai KissanGPT|2023-05-25 11:06:15|I’ll run an analysis during weekend, haven’t got anytime lately but some feedback we received, they are going at such a breath that I’m finding new use case everyday. For example, asking tractor comparison for an application, asking ways to make air freshener from a plant, schemes by state, loan rates. Some even asked to just give product with answer so they can buy directly. Hence, we started building API platform and product placement, one has to feed family and generate revenue, too. 🤣
Dev Aggarwal|2023-05-25 11:06:55|integrate it with ondc 🫰
Dr. Pratik Desai KissanGPT|2023-05-25 11:07:49|Yup, I’m going step further and doing vector matching of product with answer so they get exact item and not Google ads type crap.
Samhan Meta/Twitter Friend|2023-05-25 11:09:11|I would also suggest to try and turn it into a community of sorts where people can search answers. Or maybe make most answers public by default. So AI generated and human answers can co exist. This will also increase revenue opportunities
Samhan Meta/Twitter Friend|2023-05-25 11:09:37|Mid Journey approach
Sourasis Roy|2023-05-25 11:09:49|Are you facing issues with speechtotext considering various languages and accents it has to handle. Or is it manageable
Dr. Pratik Desai KissanGPT|2023-05-25 11:10:17|That’s also one of the suggestion. If we start seeing people asking about a pest in an area, we can detect in pest infestation and alert authorities.
Dr. Pratik Desai KissanGPT|2023-05-25 11:11:29|Early I faced, now we have figure out. Working out MoU with some bigger companies to see if the Bhasini can be optimized further for few languages.
Sourasis Roy|2023-05-25 11:13:08|🙏Great and such a relief to know that. So much can be done in the country in various sections such as education , healthcare with a reliable speechtotext
Dr. Pratik Desai KissanGPT|2023-05-25 11:13:47|Luckily, I’m sitting on huge voice data samples to further train and improve all Indic languages and it will only grow bigger from here. Limited by just time and resources.
Aashay Sachdeva MPL Data Scientist|2023-05-25 11:14:21|Provide the dataset to ai4bharat? They have annotators
Rakeshkumar Waghela|2023-05-25 11:14:22|https://betterprogramming.pub/building-your-own-devsecops-knowledge-base-with-openai-langchain-and-llamaindex-b28cda15abb7
Dr. Pratik Desai KissanGPT|2023-05-25 11:15:35|Yes, that’s the plan.
Sourasis Roy|2023-05-25 11:16:33|🙏it's a hard task ‎[5/25/23, 11:17:27] Samhan Meta/Twitter Friend: ‎image omitted
Samhan Meta/Twitter Friend|2023-05-25 11:18:01|I think you’re definitely on a positive feedback loop of data flywheel
Bhavya Ranpara Generative AI Wa Group Surat|2023-05-25 11:27:46|‎Bhavya Ranpara Generative AI Wa Group Surat joined using this group's invite link
Sidu Ponnapaa|2023-05-25 11:37:46|‎You added Sidu Ponnapaa
Aakash Dharmadhikari|2023-05-25 11:38:13|‎Aakash Dharmadhikari joined using your invite
~ Saurav|2023-05-25 11:41:07|‎~ Saurav joined using this group's invite link
Saurav Tomar GenerativeAI WA Group|2023-05-25 11:41:16|‎Saurav Tomar GenerativeAI WA Group joined using this group's invite link
Prayank Swaroop Accel|2023-05-25 11:53:21|Harrison Chase posted this yesterday. https://twitter.com/hwchase17/status/1661386820272156672  Accessing Open Source models as an API using Langchain + MosaicML
Shashwat TDC|2023-05-25 11:55:06|Can we help here to fast-track your exploratory analysis? So long you are firing events. I think otherwise it shud take you some time to see data at various cuts.
~ Prashant|2023-05-25 11:57:38|You can try creating chunks, and instead of using vector embeddings ask chatgpt to create question/answers from that chunk covering it exhaustively. You can then fine tune some model (open ai has api for davinci) with these question answers.  I haven't really tried it but my intuition is that a model fine tuned this way should be able to pickup answers with context in multiple chunks.
Swastik Banerjee|2023-05-25 12:05:07|so there’s no embeddings based kNN search involved in this approach?
Aashay Sachdeva MPL Data Scientist|2023-05-25 12:11:24|Anyone else having problem paying to openai via cc?
~ Srinath Nair|2023-05-25 12:21:44|Yeah, off late been hearing some complaints with Indian cards. Try Amex.
Aashay Sachdeva MPL Data Scientist|2023-05-25 12:22:35|Icici said it is to do with the merchant
Bulia Siddharth Aurashop|2023-05-25 12:34:50|Hi, Has anyone trying further fine-tuning Vicuna?  Can someone guide me to resources on how to do that?
Bulia Siddharth Aurashop|2023-05-25 12:36:47|I want to build a custom search/summarization for the documents present on my machine.  I have started with Vector Search & Prompt Engineering, but GPT-3.5 does not allow bigger prompts.
Aashay Sachdeva MPL Data Scientist|2023-05-25 12:42:40|Bigger than 4096 even with vectorDB?
~ Sahir Patel|2023-05-25 12:42:55|why not try https://github.com/imartinez/privateGPT
Aashay Sachdeva MPL Data Scientist|2023-05-25 12:42:58|You can bump it to gpt-4 with 8k, but it is very expensive
Bulia Siddharth Aurashop|2023-05-25 12:46:09|Yes, I want to summarize multiple docs. Context was not getting filled within 4096 tokens.  I saw that llama index is solving it via multiple prompts and then re-summarizing all summarise at the end. I will try that as well. But parallely want to experiment training myself as well. Atleast will end up learning more on this topic :)
Bulia Siddharth Aurashop|2023-05-25 12:46:38|Yeah :( Waiting for OpenAI to drop prices of GPT-4 and make something like GPT-4-turbo!
Bulia Siddharth Aurashop|2023-05-25 12:46:47|Thanks, will check it out!
~ Shubham Goyal|2023-05-25 12:48:45|‎~ Shubham Goyal joined using this group's invite link
Aashay Sachdeva MPL Data Scientist|2023-05-25 12:50:55|https://www.philschmid.de/fine-tune-flan-t5-peft
Bulia Siddharth Aurashop|2023-05-25 12:52:33|This is great!! Thank you so much. Will replicate it!
~ Avikalp Kumar Gupta|2023-05-25 13:00:53|‎~ Avikalp Kumar Gupta joined using this group's invite link
Swastik Banerjee|2023-05-25 13:05:20|Anyone who has developed any tts application themselves as a product to use, please DM. I have a jam
Swastik Banerjee|2023-05-25 13:05:34|*stt
Bulia Siddharth Aurashop|2023-05-25 13:43:16|This solves the purpose for now! Thanks Sahir.  Will check now how to make it faster and experiment with more LLMs.
~ Rachitt|2023-05-25 13:52:26|Anyone faced issues with using GPT4ALL with this, or tried using LLaMa?  Naive question but it works well with a single doc, but hallicunates with multiple. Anyway to fix this?
Lavish 2017|2023-05-25 13:55:48|hey folks, one question:  I'm experimenting with my a couple prompts responsible to get a JSON  when I use a prompt on browser, it outputs correctly however while using the same prompt with llm chain in code, it's giving out JSON with incorrect answers.  temperature is 0 at both places. I'm controlling temp value on chatbotui.com  would anyone know what I could explore more to see if I'm messing up with something?
~ S S|2023-05-25 13:55:58|‎~ S S joined using this group's invite link
Lavish 2017|2023-05-25 13:57:00|the prompt on chatbotui is working everytime and giving out incorrect output in code.  - same model, temperature - using chatbot ui to test on browser, also used open ai playground and it works fine there - using langchain's ChatOpenAI and llm chain class
Shashank Generative AI Group|2023-05-25 14:01:49|works with my Amazon ICICI credit card.
Aashay Sachdeva MPL Data Scientist|2023-05-25 14:03:46|Worked now. Looks like a stripe issue yesterdays
Anshul Bhide Replit|2023-05-25 14:04:44|"yeah had some initial issues as well. You need to go and ""view invoice"" on Stripe, and then pay it (i.e. you can't do it from the OpenAI website)."
~ As|2023-05-25 14:05:38|Hey everyone what is a good stack/pipeline using a self hosted llm for question answering on Excel sheets?
~ Akash Doifode|2023-05-25 14:10:34|We are planning to integrate the GPT 3.5 API into our platform. We have observed that the average inference time is 5 seconds, but it can sometimes go up to 30 seconds. Does OpenAI has any plans to improve the speed of inference below 2 secs so that we can deploy the code in production.
Nirant|2023-05-25 14:13:46|No
Dev Aggarwal|2023-05-25 14:17:11|https://www.youtube.com/watch?v=ZMQbHMgK2rw  Run, run little robot mouse!
Bulia Siddharth Aurashop|2023-05-25 14:22:08|Have you tried using their streaming api? [Chat Completion API with streaming=true] If the response comes word by word, it will appear fast to end users.
Dev Aggarwal|2023-05-25 14:23:57|this has to be the modern version of apple adding animations to make stuff feel smoother
~ Akash Doifode|2023-05-25 14:26:12|Yes we are using Chat completion API only...But our use case is not suitable to send response word by word
Dhruv Anand|2023-05-25 14:30:25|We are building an app using streaming, and the output seems quite quick (just like ChatGPT UI). You might want to reduce maxTokens and tune other params to improve speed
Dev Aggarwal|2023-05-25 14:38:19|I can't believe my eyes. These are so fast. They have fans under them to create suction and increase downforce. G forces as high as F1 🙈
~ Tapish Rathore|2023-05-25 14:44:41|‎~ Tapish Rathore joined using this group's invite link
Soumyadeep Mukherjee|2023-05-25 14:47:58|Haha. micromouse was so much fun. We organised one too during college. 😅  India didnt have this fast though. But I had gone to Beijing to participate in an event which also had micromouse 🙏
Soumyadeep Mukherjee|2023-05-25 14:48:24|There are generations of PhDs who did micromouse for years.
Soumyadeep Mukherjee|2023-05-25 14:48:59|But anyway, non genAI. Dont want to distract the group.
~ As|2023-05-25 14:51:50|Has anyone fine tuned a self hosted generative llm (alpaca, chatgpt4all) on domain specific data? Need some advice on when it is useful to fine-tune and when it may actually hurt
Nirant|2023-05-25 15:01:30|Excellent Prompting Guide for LLM Hackers: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77  From Nishant [PHONE] — one of the Hackathon winners!
~ Muskan Paliwal|2023-05-25 15:02:05|‎~ Muskan Paliwal joined using this group's invite link
Pranjal Mehta|2023-05-25 15:08:02|https://twitter.com/ansonyuu/status/1661518548664041472  [PHONE] should we try this at the meetup?
Soumyadeep Mukherjee|2023-05-25 15:09:50|Totally!
Nirant|2023-05-25 15:10:20|Can make a real time version of this as well? Attendees enter interests at the venue and get plotted in real time?
Soumyadeep Mukherjee|2023-05-25 15:10:57|[PHONE] has volunteered to build already to me.
Soumyadeep Mukherjee|2023-05-25 15:12:29|Forking this conversation from here to actually try this for Saturday to a separate group.
~ Ishika Mittal|2023-05-25 16:26:06|‎~ Ishika Mittal joined using this group's invite link ‎[5/25/23, 16:47:50] Abhinav Verma Longshot.ai: ‎image omitted
Bulia Siddharth Aurashop|2023-05-25 16:51:44|Is it possible to train llm/stable diffusion models (smaller ones) on mac gpu?
Bulia Siddharth Aurashop|2023-05-25 16:52:14|^m1/m2 models ‎[5/25/23, 16:57:53] Rakeshkumar Waghela: ‎image omitted
Rakeshkumar Waghela|2023-05-25 16:57:58|https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/qr_version.jpg
~ Bharat Chandra|2023-05-25 17:18:09|‎~ Bharat Chandra joined using this group's invite link ‎[5/25/23, 18:45:40] Rohan Manchanda: ‎image omitted ‎[5/25/23, 18:45:41] Rohan Manchanda: ‎image omitted ‎[5/25/23, 18:45:41] Rohan Manchanda: ‎image omitted
Shuvi Shrivastava|2023-05-25 18:48:29|Interesting - is this vanilla chatgpt? Had generally heard that LLMs breaks on math problems because they don’t recognise universal math “rules” and haven’t been trained on enough relevant papers etc
Rohan Manchanda|2023-05-25 18:48:42|GPT 4 ‎[5/25/23, 18:51:19] Rohan Manchanda: ‎image omitted
Swastik Banerjee|2023-05-25 19:03:04|Isn’t the first sentence wrong itself? 🤣 How can there be 7 distinct elements in a set A from {0,1,2,3,4,5} ? ‎[5/25/23, 19:05:53] Rohan Manchanda: ‎image omitted
Rohan Manchanda|2023-05-25 19:06:34|this is also more in line with the IMO solution 🥲
Rohan Manchanda|2023-05-25 19:07:17|It is really only a matter of time where this triviality will go away no?
Swastik Banerjee|2023-05-25 19:26:49|This solutions is also flawed. We cannot always construct a set A of the form {0,1,2,3,….5^n} where each element is of the form 5^km Eg., 3 cannot be expressed as a power of 5 🙂
Swastik Banerjee|2023-05-25 19:27:44|I saw the official solutions. It’s noway in-line with the assumption is makes.
Swastik Banerjee|2023-05-25 19:28:06|*assumptions it makes
~ Prafful|2023-05-25 19:28:41|‎~ Prafful joined using this group's invite link
Rohan Manchanda|2023-05-25 19:29:02|I see, that could be possible. Mea Culpa and sorry - probably won't reverify but totally understand your point :)
Nirant|2023-05-25 19:30:25|FWIW: GPT4 is RLHF'd on a ton of math, physics, logic, and code problems. It's possible that even the IMO 2022-style problems were part of that, since they'd professional math educators design the RLHF Set from the rumour mill.
Swastik Banerjee|2023-05-25 19:30:26|My flatmate spent a month in homi bhaba preparing for the actual international olympiad. I trust his proofreading 😂😅 But yes, it’s probably a “matter of time” before it gets better at these 🙂
Swastik Banerjee|2023-05-25 19:33:03|I sincerely hope so
Swastik Banerjee|2023-05-25 19:36:51|but it’s funny how gpt builds up a crap story with full confidence with “7 villagers” , when 7 can never be of the form 4n+2 for any integer n. I was expecting gpt4 to be better in trivial logical reasoning like this :/
Nirant|2023-05-25 19:40:08|Friends, we're testing the meetup matchmaker for 27th, mind filling it in if you're going to be there? https://forms.gle/dAYM1bUyhTFa7CnL8
Vaibhav Bhargava Meesho Grab |2023-05-25 19:51:50|Seema kapadia needs to see this💡 ‎[5/25/23, 19:55:12] Nirant: ‎image omitted
ashish Acgt01 Twitter|2023-05-25 19:56:49|Very neat stuff Dev ! Does the viz get updated whenever there is a new respondent filling up the google form ?
Dev Aggarwal|2023-05-25 19:57:09|Yes
Prayank Swaroop Accel|2023-05-25 20:05:45|Asking for a friend: i want to create mock design for my app, eg, create a screen for soliciting aadhar card from user. Are there tools which are able to do that?
Sudharshan GenAI|2023-05-25 20:08:41|Nice, how are you creating this viz?
Dhruv Anand|2023-05-25 20:09:26|Can we fill it in even if we're not going to be there?
ashish Acgt01 Twitter|2023-05-25 20:09:47|Is there a GitHub ?
Nirant|2023-05-25 20:10:18|Yeah, but that significantly lowers the chances that you'll meet the person. For you, I strongly recommend taking that 3K INR flight to BLR!
Dhruv Anand|2023-05-25 20:10:49|I'm tempted
Nirant|2023-05-25 20:11:33|Inflation adjusted, It's cheaper than Christopher Bishop's Pattern Recognition that we bought in undergrad 🤣!
Nirant|2023-05-25 20:16:28|Here you go:  https://github.com/devxpy/ai-matchmaker/
Aman Dreamboat.ai|2023-05-25 22:32:56|‎Aman Dreamboat.ai joined from the community
Rohan Manchanda|2023-05-25 23:43:38|https://a16z.com/2023/05/25/ai-canon/  curated list of resources according to the fund that are super compelling and have had an outsized impact
Ankur Pandey|2023-05-26 01:25:48|Fantastic curation
~ Anurag Dhingra|2023-05-26 02:54:30|https://www.bbc.com/news/health-65709834  Gotdam, though the antibiotic mentioned only works on the specific “superbug” bacteria but still insane.
Swastik Banerjee|2023-05-26 03:23:05|Have some questions. Would be really really helpful if someone who has worked with Pinecone could answer these:  https://github.com/pinecone-io/examples/issues/197  https://github.com/openai/chatgpt-retrieval-plugin/issues/283  TIA ‎[5/26/23, 06:25:57] Dev Aggarwal: ‎image omitted ‎[5/26/23, 06:45:20] Dalan Mendoca: ‎image omitted
Rohan Manchanda|2023-05-26 06:57:45|Anthropic round 🫠
Rohan Manchanda|2023-05-26 06:59:09|Seriously this is nuts tho.
Anubhav mishra Zupay|2023-05-26 07:10:47|https://www.cnbc.com/amp/2023/05/25/jpmorgan-develops-ai-investment-advisor.html?__source=instagram%7Cmain
Anubhav mishra Zupay|2023-05-26 07:10:58|This is insane
~ Udith Vaidyanathan|2023-05-26 10:05:30|‎~ Udith Vaidyanathan was added
~ Kp|2023-05-26 07:28:33|This feels like over reliance on LLMs when we know they hallucinate over reasoning and mathematics problems
~ Kp|2023-05-26 07:28:40|Which would factor into selections of investments
Dev Aggarwal|2023-05-26 07:31:28|But investments are sometimes about modelling behaviour than mathematics? I assume they have amazing quants already, but LLMs are amazing herd followers - if you train them on news they can for eg filter the most popular consensus reliably. The hallucinations I think come when you ask for stuff that’s out of training distribution
Edgar Monis Mumbai WHO|2023-05-26 07:53:25|Folks it's simpler than this  Morgan Stanley needs to be viewed as doing something to counter AI.  Incorporating it as part of their workflows is the easiest way to arrest investor concerns
Edgar Monis Mumbai WHO|2023-05-26 07:54:02|They'll probably end up using llms to generate derived features for their ML models
Alok Bishoyi|2023-05-26 07:54:09|Anyone has access to this article ?  https://www.theinformation.com/articles/how-microsoft-swallowed-its-pride-to-make-a-massive-bet-on-openai
Bharat Kumar Ramesh Hashmal Web3|2023-05-26 08:39:14|Their earnings guidance is nuts
Bharat Kumar Ramesh Hashmal Web3|2023-05-26 08:39:19|Read the transcripts
~ Shubham Goyal|2023-05-26 08:48:34|You can ask Bard to create the summary of the article link
Lalit Pagaria|2023-05-26 08:51:28|https://twitter.com/willdepue/status/1661781360619696128?t=Mjv8eQJ28AvW1cFSH_NO8w&s=08  Someone created arvix papers embedding. Sharing in case you are looking for something like this.
Alok Bishoyi|2023-05-26 09:57:20|Tried it with a bunch of articles. Bard/G-Search seems to be able to access the content behind paywall , but seems to be hallucinating quite a bit too.  It's especially bad at follow up questions  ChatGPT/Bing-Search doesn't seem to have a work around to accessing paywall content
Aniket Kamath Nexus IIT B|2023-05-26 10:11:08|https://a16z.com/2023/05/25/ai-canon/ - good compilation of resources
~ Puneet|2023-05-26 10:19:08|Seems pretty good, hoping to read all of it over the weekend 🙂
Dev Aggarwal|2023-05-26 10:37:41|Can anyone tell Which embeddings model did they use?
Shashank Generative AI Group|2023-05-26 10:48:56|InstructorXL  https://huggingface.co/hkunlp/instructor-xl  https://twitter.com/willdepue/status/1661788343443791875?t=CFBOxcpWzl9KfJHvlyxOAw&s=19
ashish Acgt01 Twitter|2023-05-26 10:51:06|Soumith Chintala's take on the $NVDA rally !  https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Nirant|2023-05-26 10:51:55|If you've ever used a TPU pod in production, you'd know his directionally right, timeline unknown.
ashish Acgt01 Twitter|2023-05-26 11:04:37|"I haven't but as someone wrote in the thread ""Stock markets don't run on logic, but on sentiment"" :)"
Swastik Banerjee|2023-05-26 11:17:03|anyone who knows about the default chunking systems in Pinecone?
Abhinav Verma Longshot.ai|2023-05-26 11:17:33|They don't do chunking
Abhinav Verma Longshot.ai|2023-05-26 11:17:57|You do it..embed the chunks and upsert it with Metadata
Swastik Banerjee|2023-05-26 11:21:04|I’m using and exploring```chatgpt-retrieval-plugin```. The data is getting chunked as I’ve given a proof of in the SS attached, though I am not chunking it. Does that mean the ```retrieval-plugin``` is chunking the data, if it’s not done at the vectorDB level?  Can anyone confirm who has worked with ```Pinecone``` and/or ```chatgpt-retrieval-plugin``` ?
~ Rohit|2023-05-26 11:26:21|I can confirm that pinecone doesn't do chunking for you. Haven't used chatgpt-retrieval-plugin.
Kartik Mandaville|2023-05-26 11:31:28|We use pinecone and it doesn't do chunking. For that, we use llama index
Paras Chopra Wingify|2023-05-26 11:41:35|I have a hypothesis. Curious to hear others’ thoughts.  Gradually LLMs will become too cheap to meter. (Especially when Google, Microsoft and Apple bake them into OS as a service).  Agree or disagree?
Swastik Banerjee|2023-05-26 11:41:36|interesting…
Paras Chopra Wingify|2023-05-26 11:43:44|It will be fun to imagine what applications will be possible when LLMs are almost free
~ Prajna Prayas|2023-05-26 11:45:11|I guess they would be baked into every OS and products as long as they are not giving financial or health advice. May be the regulators will rein in these kind of products and services first.
Nirant|2023-05-26 11:48:19|What timeline are you thinking? 5 years out or more like 15 years out?
~ Clament John|2023-05-26 11:58:36|If we can get Linux running on apple silicon we will have many local LLMs apps in the open source ecosystem
~ Clament John|2023-05-26 11:59:22|And And I think Asahi Linux is getting there. So maybe less than 5 years?  https://asahilinux.org/about/
Prayank Swaroop Accel|2023-05-26 12:07:52|Have you seen this - https://github.com/ParisNeo/gpt4all-ui   I can run various open source models on my mac using this.
~ Clament John|2023-05-26 12:08:52|Yes you can run models. But can you change or influence the OS to work with you?
Shashwat TDC|2023-05-26 12:09:28|I think 5 years. Bcz most of these tools are positioned to increase productivity. Imp question to ponder is what gets shortened, when the productivity increases.   In past, when we content got cheaply accessible. It gave rise to influencer marketing and really shortened the attention span.
~ Clament John|2023-05-26 12:09:32|With Linux one could write a OS driver to or a kernel module if needed
~ Sachin Kalsi|2023-05-26 12:10:08|Bhasha Daan : An crowdsourcing initiative for Indian languages (Beta)  https://bhashini.gov.in/bhashadaan/en/home  https://www.linkedin.com/posts/microsoft_satya-nadella-on-linkedin-the-rate-of-diffusion-activity-7066997625346031616-JSLA/
~ Rohit|2023-05-26 12:13:07|Jarvis
~ Madhur Sawhney|2023-05-26 12:13:24|‎Soumyadeep Mukherjee added ~ Madhur Sawhney
Edgar Monis Mumbai WHO|2023-05-26 12:14:53|Isn't it a bit crazy that Tony stark was sitting on that tech all this while without open sourcing it ?  No need for Friday. Even Jarvis v1 would've been nice to have for FOSS
Paras Chopra Wingify|2023-05-26 12:16:12|5
Paras Chopra Wingify|2023-05-26 12:16:17|Less than that actually
~ Rachitt|2023-05-26 12:17:30|2-3 years seems doable
~ Arka|2023-05-26 12:22:28|Either LLMs will have to shrink quite a bit or we will only have the lower end of the LLMs on the device.  No way we will be pushing so much RAM in a portable device.  Unless of course hardware becomes really better
Paras Chopra Wingify|2023-05-26 12:23:23|my bet is that a good enough local LLM will do most of the job, with perhaps complex workflows seamlessly flowing to a cloud endpoint
~ Arka|2023-05-26 12:25:41|Yeah I read a very interesting interview on this.   Anthropic is trying to come up with ways to control the amount of compute used to respond to a query based on its complexity.
Shashwat TDC|2023-05-26 12:33:44|We actually don't need LLM call for all queries, which is the case rn. This also results in variable answers for a same given query, which is confusing.
Jithin James Ragas|2023-05-26 12:39:21|or some other company build something close to apple silicon
~ Clament John|2023-05-26 12:40:06|Heard geohot wants to build AI hardware
~ Clament John|2023-05-26 12:40:50|Run llama 65B for $15,000.
Jithin James Ragas|2023-05-26 12:42:03|its actually a fun project though he is trying to get AMD drivers/k mods on par with nvidia
Jithin James Ragas|2023-05-26 12:42:18|love seeing his streams man
~ Clament John|2023-05-26 12:43:55|geohot is an interesting character. I love his engineering prowess, but we couldn't see his business side / success when running comma.ai
Dr. Pratik Desai KissanGPT|2023-05-26 12:45:47|You can do that with 2 x A6000 48gb (8k + 2k rest = 10k)
Jithin James Ragas|2023-05-26 12:48:37|true that
~ Clament John|2023-05-26 12:49:55|Nvidia being a B2B business, I wonder how long they will be a 1 trillion company.   Meaning a lot of people are going to try to get a piece of that pie. And engineers are not actually loyal, unlike consumer companies like apple and Tesla(?)
Gokul Krishnan|2023-05-26 12:51:51|Question to the group here: what kind of usecases do you folks imagine _needs_ a local / on-device LLM? Would love to hear usecases where a server side LLM cannot work
~ Arka|2023-05-26 12:53:28|Intelligent doc/image search without uploading personal files to the cloud.  Siri/Assistant
Shimanta Generative AI|2023-05-26 12:53:36|Sharif, the founder of Lexica tweeted that he was on a flight and wanted to search some topic. The inflight wifi wasn’t working so he was unable to google. Then he realised he had a local Llama model running on his iphone and found the answer there.
~ Rachitt|2023-05-26 12:53:55|was speaking with a data storage company considering building it's local LLMs to help with basic ops on storage/datacentres
Nirant|2023-05-26 12:54:00|I go upto the computer and ask it to drop my mother a good morning message on WhatsApp, find me which code is breaking from user and server logs and schedule an appointment with my trainer
~ Clament John|2023-05-26 12:54:01|1. Small workload that doesn't need a state of the art LLM 2. Enterprise information (but I think MS is solving this well, from what I understand from the recent MS build)
Gokul Krishnan|2023-05-26 12:54:47|So more of a privacy concern? Or latency / cost concern?
~ Clament John|2023-05-26 12:55:00|I remember this. This is super cool.  The whole world's information in your laptop
Gokul Krishnan|2023-05-26 12:56:09|This makes sense to me. Do we have any evals of how good llama is compared to GPT-4 for information retrieval?
~ Arka|2023-05-26 12:56:12|Both.  Use cases where either of them are crucial you might want to push to on device.
Dr. Pratik Desai KissanGPT|2023-05-26 12:56:37|Siri will be less stupid as it can under context  Notifications can be summarized like Nirant is doing for the group
Shashwat TDC|2023-05-26 12:56:41|I agree that privacy will be the major factor for client side implementation. I suppose we will also learn more in Jun. After AI regulation draft in US and Eur
Gokul Krishnan|2023-05-26 12:56:56|Like a SQL query helper?
ashish Acgt01 Twitter|2023-05-26 12:57:03|Does anybody here work/do research in medical/health ai ?  I am just getting started into the field. Saw this interesting perspective : https://twitter.com/drhughharvey/status/1661826562935726080?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Gokul Krishnan|2023-05-26 12:58:32|I think that enterprise info can still be solved by running a LLM in house on a server instead of individual devices? 🤔
~ Rachitt|2023-05-26 12:59:11|yes, plus agents for partition management, DB health management
~ Clament John|2023-05-26 12:59:54|"Yeah. The ""on premise"" pricing model is gonna have a major comeback"
~ Rachitt|2023-05-26 12:59:56|+1, something like privateGPT having API endpoints?
Paras Chopra Wingify|2023-05-26 13:00:59|for me, it's the cost of LLM being borne by the client (LLMs that run on phone can enable AI to be included in most free apps/games)
Sandeep Srinivasa RedCarpetup|2023-05-26 13:01:02|regulatory. if u pay close attention to how EU AI guidelines are shaping up (which will influence all other countries), personal health info will be covered under stringent regulations.   i think we forget that GPT, and Google's Medical LLM have NOT cleared hipaa
Sandeep Srinivasa RedCarpetup|2023-05-26 13:01:36|for most enterprise usecases however, we have seen acceptance and buy in from banks/enterprises. Forget LLM, the big fight was on-premise vs cloud for normal servers
~ keith|2023-05-26 13:05:52|‎~ keith joined using this group's invite link
~ Kp|2023-05-26 13:07:57|Pocket internets?
~ Kp|2023-05-26 13:08:29|Also how did he pull this off any references?
Gokul Krishnan|2023-05-26 13:09:13|With all the hallucination, I think we have a long way to go before we can use LLMs for medical data, notwithstanding the regulatory environment
Sandeep Srinivasa RedCarpetup|2023-05-26 13:11:14|long way than this ? https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model   passes  US Medical Licensing Exam with an expert score.
Gokul Krishnan|2023-05-26 13:15:11|From the text: first LLM to perform at an “expert” test-taker level performance on the MedQA dataset of US Medical Licensing Examination (USMLE)-style questions, reaching 85%+ accuracy, and it was the first AI system to reach a passing score on the MedMCQA dataset comprising Indian AIIMS and NEET medical examination questions, scoring 72.3%.
Gokul Krishnan|2023-05-26 13:15:43|Aren't these exams notoriously amenable to rote learning?
Sandeep Srinivasa RedCarpetup|2023-05-26 13:26:07|"that is not the interesting part of the paper.  the interesting part is this  ""We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions,* physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001)*. We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form ""adversarial"" questions to probe LLM limitations."""
ashish Acgt01 Twitter|2023-05-26 13:30:14|And there will be an LLM SDK (baked into ios for example) exposing LLM capabilities to app developers ?
~ Rachitt|2023-05-26 13:31:22|There's agent SDKs like Fixie, something similar for LLMs?
Gokul Krishnan|2023-05-26 13:35:22|So there's two claims here. 1. PaLM V2 is better than V1. Ok, cool. 2. Of the nine axes they evaluated, physicians preferred PaLM's response over a clinician response. Cool again, but why did they prefer it? Was it because it produced a more verbose response? Was it because they were preconditioned by knowing they're evaluating an ai response? etc.  I'm not arguing it's not a significant improvement but rather that it doesn't convince me that it's ready for a life or death scenario especially when it gets something wrong.  It seems Google too knows this and hence the limited release and iteration.
ashish Acgt01 Twitter|2023-05-26 13:35:38|"Or could Apple for example include a tiered subscription for app developers for the ""local LLM api service"" running on the ios device ?  Upto x calls/ day : free > X and < Y : $ A /call > Y and < Z : $ B/ call"
Gokul Krishnan|2023-05-26 13:37:18|Ahaha, that's a risky precedence 🫠
ashish Acgt01 Twitter|2023-05-26 13:37:46|Also somewhat related, somewhat tangential q :  Have you guys tried rewind app on Mac ? It continuously and smartly records screen and does OCR to enable search across all apps  Have you tried it [PHONE] [PHONE] ?
Rajesh RS Generative AI WhatsApp Group|2023-05-26 13:43:43|‎Rajesh RS Generative AI WhatsApp Group joined using this group's invite link
Paras Chopra Wingify|2023-05-26 13:48:44|not yet, but have heard great things about it  ps: it's by optimizely's founder, our #1 erstwhile competitor for vwo :)
~ Kp|2023-05-26 13:54:39|The reference: https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md
~ Ankur Khandelwal|2023-05-26 14:01:35|Anyone have experience using the guardrails (https://shreyar.github.io/guardrails/)-  I got stuck with one bug, can anyone check - https://github.com/ShreyaR/guardrails/issues/168  Thanks a lot ‎[5/26/23, 14:02:48] Aashay Sachdeva MPL Data Scientist: ‎image omitted
~ Clament John|2023-05-26 14:04:50|Sama may not be in India, but he is spiritually.
Sidhant Sequoia|2023-05-26 14:05:21|https://twitter.com/soumithchintala/status/1661746183826735104?s=48&t=ACPHEfclkXmi9Z92RTsh9g  Can anyone help provide more context / thoughts on this tweet?  Does training and inference merit different GPU lines? Not sure how different the core primitive in backpropagation math is from inference
Aashay Sachdeva MPL Data Scientist|2023-05-26 14:05:21|He is coming next week!
~ Clament John|2023-05-26 14:05:34|Why isn't the developed west not highlighted?
Nirant|2023-05-26 14:13:04|cc Shreya, the creator of Guardrails [PHONE] is here as well btw
Nirant|2023-05-26 14:13:07|And they've a pretty active Discord
~ Ankur Khandelwal|2023-05-26 14:13:42|ahh okay. let me join the discord too and message them..
Nirant|2023-05-26 14:14:07|You might want to start by using the latest guardrails release which is not on Pypi yet
~ Arka|2023-05-26 14:15:13|The biggest issue with using GPU for inference is that the I/O latency.  During training we use batch training so we can amortize the latency throughout the batch.  But usually if inference is a single instance. We have to consider the overhead of loading the model to memory, loading the data and then doing inference.  While in a cpu its gonna be much faster due to lower latency
Bhavya Ranpara Generative AI Wa Group Surat|2023-05-26 14:15:15|"""Global economy"" which is vastly dominated by developed west."
~ Ankur Khandelwal|2023-05-26 14:16:24|how to do that? sorry I am python beginner.
Nirant|2023-05-26 14:16:49|Let's move this to DMs
~ Arka|2023-05-26 14:18:12|So i guess its entirely upto whether your inference is batch and you are loading the model once.  Then use gpu  If your loading model to memory and doing inference on need basis.  Then gpu is not effective. Especially given the power consumption of the thousands of SM cores. Those cores consume power regardless of whether they are executing instructions.
Sidhant Sequoia|2023-05-26 14:19:10|Thanks this helps! I’ll dm you as well
~ Ankur Khandelwal|2023-05-26 14:24:52|FYI, its not working in the latest release too - 0.1.7
Swastik Banerjee|2023-05-26 14:34:30|Is there anyone here who works for the DiskANN project for microsoft research? Or know someone there?
Aishwarya Goel Inferless 5s for 5G|2023-05-26 14:43:02|Not really true. It also depends on how fast you can copy the model weights to GPU memory. You can reach speed as fast as a CPU ram too!
~ Prashant|2023-05-26 14:45:09|I don't have an answer to this.  But if you're using this then I'm guessing you'd want to host it somewhere. If that's so you can also look at the ANN models that cloud platforms provide, if it's enough cost-effective (google's : https://cloud.google.com/vertex-ai/docs/matching-engine/ann-service-overview)
Swastik Banerjee|2023-05-26 14:52:45|nono, I just want to connect with a few people working in the team and bounce off ideas lol…
Neeraj Kumar|2023-05-26 14:55:44|I am working on a detailed prompting guide highlighting all use cases!   Any great links you have come up to? Please share. I am done with Andrew NG's LLM prompt course.
Neeraj Kumar|2023-05-26 14:55:59|Will publish the blog as well.
Nirant|2023-05-26 15:11:21|LLM Prompting Guide from [PHONE] from the community:  https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
Nirant|2023-05-26 15:11:32|And is pretty damn detailed!
Anshul Bhide Replit|2023-05-26 15:33:29|ChatGPT rolling out to India today for iOS https://twitter.com/OfficialLoganK/status/1661834375028154406
Dr. Ashith Generative AI WA Group|2023-05-26 16:17:10|has anyone implemented this repo https://github.com/go-skynet/LocalAI Been trying for a while but facing lots of issues
Nirant|2023-05-26 16:18:13|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"""
~ Vrushank Vyas|2023-05-26 16:31:48|‎~ Vrushank Vyas joined using this group's invite link
~ Raghavendra|2023-05-26 16:32:03|‎~ Raghavendra joined using this group's invite link
~ Jyotinder Singh|2023-05-26 16:32:17|‎~ Jyotinder Singh joined using this group's invite link
~ Saransh Agarwal|2023-05-26 16:32:17|‎~ Saransh Agarwal joined using this group's invite link
~ Chandan Kumar|2023-05-26 16:32:34|‎~ Chandan Kumar joined using this group's invite link
Uddeshya Singh|2023-05-26 16:32:53|‎Uddeshya Singh joined using this group's invite link
~ ~<>~|2023-05-26 16:34:31|‎~ ~<>~ joined using this group's invite link
~ Arpit Agrawal|2023-05-26 16:41:03|‎~ Arpit Agrawal joined using this group's invite link
~ Shirsha|2023-05-26 16:46:32|‎~ Shirsha joined using this group's invite link
Abhishek Mishra|2023-05-26 16:50:13|‎Abhishek Mishra joined using this group's invite link
Vaibhav Bhargava Meesho Grab |2023-05-26 17:24:42|This is really good [PHONE] and seems friendly to non developers too. Love the part on Tool usage.
~ Arpit Agrawal|2023-05-26 17:46:52|Hi [PHONE] , I joined the group just now, can you please share your prompting guide again?
Nishant Apne-App GenAI Hackathon|2023-05-26 17:49:37|Hi Arpit, Here is the link: https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77
~ Sudhanshu Heda|2023-05-26 17:53:34|https://www.cnbc.com/amp/2023/05/25/elon-musks-neuralink-gets-fda-approval-for-in-human-study.html
~ Sanjeed|2023-05-26 18:03:26|Should we add it to the group description?  [PHONE]
Rohit Aggarwal|2023-05-26 18:51:39|We've built a semantic caching layer on vector databases and trying it out with some promising results. (had to do a lot of cajoling to get it to good f1 scores, but realise we'd never be perfect). Is there a way to setup expiration ttls in vector dbs? [PHONE]
Nirant|2023-05-26 18:54:42|Expiration TTL: I've been storing date and time in the metadata and dropping entries using a cron.
Rohit Aggarwal|2023-05-26 18:57:11|how do you go through all the vector keys? There's no filter only by meta right?
Karishnu Poddar Yellow.ai|2023-05-26 19:00:16|Would using Redis help?
ashish Acgt01 Twitter|2023-05-26 19:02:10|"""To start, we're releasing the embeddings for every research paper on the Arxiv. That's over 4m items, 600m tokens, and 3.07 billion vector dimensions.""   https://twitter.com/willdepue/status/1661781355452325889?s=48&t=pt9BgXoRTmqx5FEPyAl9bg"
Sandeep Srinivasa RedCarpetup|2023-05-26 19:02:20|Do u see a lot of cacheable queries? I thought that the content would be so disparate that cache hits would be very low
Ankur Pandey|2023-05-26 19:04:57|In business usecases it can save a decent share of queries.
Ankur Pandey|2023-05-26 19:05:10|[PHONE]
Sandeep Srinivasa RedCarpetup|2023-05-26 19:05:56|really ? but ur vector db query would be a prompt right ? u still see opportunities for caching ?
Sandeep Srinivasa RedCarpetup|2023-05-26 19:06:00|genuine question btw
Ankur Pandey|2023-05-26 19:06:07|Who's building LLM benchmarking + observability + semantic caching bundled in one?
Rohit Aggarwal|2023-05-26 19:06:32|yes - running backtests on some datasets and it looks promising. Will come back when we have production datasets to backtest on. Simple caches already are great for dev and simple classification problems. I think semantic would be useful for RAGs
Sandeep Srinivasa RedCarpetup|2023-05-26 19:07:30|hmm.. very interesting. would love to know more when ur ready. have been thinking about the caching problem for a long time.
Rohit Aggarwal|2023-05-26 19:07:34|yea - people ask similar questions to a chatbot. A friend told me 30% of his chatbot questions (niche) were similar - so could build a cache bucket for such queries
Sandeep Srinivasa RedCarpetup|2023-05-26 19:09:00|"In that case, ur cache also needs to be a vector db (like redis). Cos it will be difficult to have a cache hit without transforming the ""question"" into an embedding first"
Ankur Pandey|2023-05-26 19:10:57|Seen in our case. True for users who work in v specific niche. Their prompts can be bundled w little difference in results
Rohit Aggarwal|2023-05-26 19:11:18|yes
Ankur Pandey|2023-05-26 19:13:16|Oh you're Rohit from portkey? Hi again
Rohit Aggarwal|2023-05-26 19:14:26|haha, yes! Hi Ankur
~ Nayan Shah|2023-05-26 19:22:40|This is also the similar usecase that we had thought of as the queries are kind of similar we were thinking to build semantic cache so we can reduce the latency for openai hits and get the results fastwr to users on bot  But as mentioned here u will need to first create a embedding and then this may work based on cosine similarity , but after some thinking as we were thinking this to reduce the latency of the hits we just did not think this will be helpful as still there is embedding creation part involved and if u go with different embedding model like sbert or something  for this specific cache which has lower latency that is an over kill as u will have now 2 kinds of retrieval as openai embeddings u may still want it as they are superioir , so rather than that we just went with streaming api ,and that helped us better our ux and also helped us maintain the latency or make it feel not that slow .
~ Nayan Shah|2023-05-26 19:23:32|Hope this helps a long message ,but i feel in this field qe all are facing kind of similar issues ..
Rohit Aggarwal|2023-05-26 19:34:57|thanks! streaming helps with latency, but you'd still incur twice the cost for the same / similar questions, right?
Sandeep Srinivasa RedCarpetup|2023-05-26 19:37:31|Very intresting to learn
~ Nayan Shah|2023-05-26 19:39:08|Yeah , u are right , if cost is in question than building a semantic cache with sbert model for retrieval of the same queries answered may help . U may need to create a metadata of the response answered with the query embedding and store that . And when new query comes just fire and get the sbert query se get the similar matches on queries and then acc to  that u may reduce your calls . Very intresting approch this we thought but thought to implement streaming first .. but to make sure this is caching at vectordb layer and not at openai level ..
~ Nayan Shah|2023-05-26 19:40:31|This is intresting to desing ...
Rohit Aggarwal|2023-05-26 20:07:50|Yea I’m almost done except for the ttl bit
~ Nayan Shah|2023-05-26 20:11:13|So u have built this using? Like redis or something . Anything that u can share on design or what u have used . I found this when i was thinkigj about this . https://github.com/zilliztech/GPTCache
Lalit Pagaria|2023-05-26 20:11:54|Not sure but technically redis vector search uses RedisJSON. Which supports update and delete of keys. So I think setting up TTL to JSON object is possible via Multi command.
~ Nayan Shah|2023-05-26 20:11:56|Ttl may be for u can be -1 right if the semantic match is beyond aome thrsold for incoming query u dont need ttl per say? Am i missing some
~ Nayan Shah|2023-05-26 20:12:15|Thing *
Rohit Aggarwal|2023-05-26 20:12:50|Yea we saw GPTCache - we built it a little bit further and faster. Design and concept is similar
Lalit Pagaria|2023-05-26 20:14:21|This comment also says this https://github.com/RedisJSON/RedisJSON/issues/415#issuecomment-886577326
~ J|2023-05-26 20:24:02|‎~ J joined using this group's invite link
Rohit Aggarwal|2023-05-26 20:26:36|Thanks! I’ll check this out
~ SatyaPrakash Kodamanchili|2023-05-26 21:45:20|‎~ SatyaPrakash Kodamanchili joined from the community
~ Arka|2023-05-26 22:30:44|This is the core difference between CPUs and GPUs: CPUs are optimized for latency: to finish a task as fast as possible; GPUs are optimized for throughput: they are slow, but they operate on bulks of data at once.  https://towardsdatascience.com/the-ai-illustrated-guide-why-are-gpus-so-powerful-99f4ae85a5c3
Abhinav Verma Longshot.ai|2023-05-26 22:32:11|I'd read this a while back I think. This is pretty neat
~ Arka|2023-05-26 22:34:29|If you really want to test your use case   Run a profiler and measure the time overheads of each of the tasks and decide for yourself.   If you try to take two 10^5 size matrices to gpu  Multiply  Return result.  Most probably 80% of time will be spent on I/O
Anubhav mishra Zupay|2023-05-26 22:52:48|Embodied Artificial Intelligence.  https://www.1x.tech/
ashish Acgt01 Twitter|2023-05-26 23:50:07|https://twitter.com/karpathy/status/1662160997451431936?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
~ lirus|2023-05-27 00:36:37|‎~ lirus joined using this group's invite link
~ Nayan Shah|2023-05-27 01:30:54|"As we were discussing cache and TTL, just thought to share this quote .  ""There are only two hard things in Computer Science: cache invalidation and naming things."" -- Phil Karlton"
Dr. Pratik Desai KissanGPT|2023-05-27 01:32:46|Must be a pre-k8s quote 😂
Pranjal Mehta|2023-05-27 07:12:57|Real Life Human Feelings
~ Dingu Sagar|2023-05-27 07:17:59|‎You added ~ Dingu Sagar
Mohit Kumar|2023-05-27 07:35:59|‎You added Mohit Kumar
Nirant|2023-05-27 08:20:51|Friends, we're delighted to have over 900 esteemed members in this group, nearing the WhatsApp group limit of 1024 participants.  For those of you who have been primarily following our group for the most recent news across products and tech, we kindly request you to consider a transition to the GenerativeAI News group. This will allow us to welcome more diverse voices and perspectives to our current group.  GenerativeAI News Group: https://chat.whatsapp.com/KWaS9CBhrYPCMogmpGpz5g
Nirant|2023-05-27 08:21:57|I'm hoping that at least 100ish folks make the transition i.e. join that group, and leave this group  If not, we'll begin removing folks based on two main factors:  1. Have you contributed in the last 50 days? 2. How long have you been here?  This'll happen as and when I get time (since removing folks is manual-ish at the moment)
~ Arun|2023-05-27 08:42:11|‎~ Arun joined using this group's invite link
Arvind N Generative AI Group|2023-05-27 09:00:28|When we look back, the link between symbolic and connectionist approaches would have been the breakthroughs in code generation.
~ Shivaprasad|2023-05-27 09:27:40|‎~ Shivaprasad joined using this group's invite link
Raghotham Paypal Bargava's Friend|2023-05-27 09:39:21|Any reason this group is on WhatsApp and not Telegram? I'm sure you would have given it a thought. Curious to know the reason. I thought things were easier on TG.
Nirant|2023-05-27 09:43:37|WhatsApp continues to be the first choice for most folks in India → Telegram is easier for moderators, harder for users  I didn't expect to get to 2^10 people in less than 100 days from starting 😅
Raghotham Paypal Bargava's Friend|2023-05-27 09:44:16|I agree. But is it same with tech folks as well?
Nirant|2023-05-27 09:45:24|Yes. We all have 2-4 muted family WhatsApp groups
Raghotham Paypal Bargava's Friend|2023-05-27 09:49:11|I meant  that  telegram is more opted for in the tech community. I might be wrong as well 😊
Vaibhav Bhargava Meesho Grab |2023-05-27 09:51:23|Curious - for those in the group with employers,  have any of the employers started to offer GPT plus subscription as a claimable expense ?  Or heard of anyone do it. I see some small team organizations already doing it. And any where you have been warned to not use it ?
Nirant|2023-05-27 09:52:06|Samsung, Apple, VISA, MathWorks have banned ChatGPT Plus and deploying the GPT4 API under their own brands
Nirant|2023-05-27 09:54:03|Many of these have been upsold by Azure OpenAI as per the rumour mill. The case being made is InfoSec: Azure inside VPC, data won't be used for training the model.
Rounak Datta Hackathon Winner|2023-05-27 09:56:50|SourceGraph had publicly announced that they're offering every employee the subscription. There was a thread by Shreyas Doshi where he had suggested the same. That thread had many people agreeing that they've reimbursed their employees.
jyotirmayjk Hackathon|2023-05-27 09:57:28|For org plans there is a provision which allows you to opt out. When you use this the data won’t be utilised for training the model.
Raghotham Paypal Bargava's Friend|2023-05-27 09:58:34|This is what we use as well.
Nirant|2023-05-27 09:58:54|we as in Paypal?
Raghotham Paypal Bargava's Friend|2023-05-27 09:59:03|Yes
Raghotham Paypal Bargava's Friend|2023-05-27 09:59:25|Azure openai within vpc
Aashay Sachdeva MPL Data Scientist|2023-05-27 10:03:27|MPL offers chatgpt subscription reimbursement
Pratyush Choudhury|2023-05-27 10:03:33|Seems like there's a lot of trust for folks to use this over the plain OpenAI Service  Everyone is b2b i speak to is using that stack
~ Bineet Ranjan|2023-05-27 10:03:57|‎~ Bineet Ranjan joined using this group's invite link
Aashay Sachdeva MPL Data Scientist|2023-05-27 10:03:57|Mid journey as well
Vaibhav Bhargava Meesho Grab |2023-05-27 10:07:41|Looks like B2C or B2B, insecurity and aspiration is where all the money lies.
Anshul Khandelwal Invideo|2023-05-27 10:12:53|We at invideo offer both too.
Nirant|2023-05-27 10:20:34|h/t [PHONE] for saying what I was about to: The latest LLM is from the Govt of Dubai.   Between US (OpenAI), China (Baidu, Alibaba) and Dubai (Technology Innovation Institute) — guess the country which is missing and has a ton of computational talent and money?  https://twitter.com/sandeepssrin/status/1662318588898992130
Sandeep Srinivasa RedCarpetup|2023-05-27 10:23:18|To clarify, it's not just latest. It is the top of the HuggingFace leaderboard. Beating all the Llama.  Nothing sadder than this.
Nirant|2023-05-27 10:23:53|An instruct or chat fork of this would be 🔥
~ Glory|2023-05-27 10:29:44|‎~ Glory joined using this group's invite link
~ KJ|2023-05-27 10:36:11|But you can turn off history any way
Rahul Sundar 2013|2023-05-27 10:36:30|Lot of articles over the last couple of months have been highlighting the strategic need for building India's own LLM... But what are the blockers  to that?
Aashay Sachdeva MPL Data Scientist|2023-05-27 10:40:31|ai4bharat is training one
~ Clament John|2023-05-27 10:44:04|Is ai4bharath a government initiative?
~ Clament John|2023-05-27 10:48:24|Yes, by IIT M
Paras Chopra Wingify|2023-05-27 10:49:12|Why does indus need one?
Paras Chopra Wingify|2023-05-27 10:49:13|India*
Rahul Sundar 2013|2023-05-27 10:50:47|Number of diverse languages is one I can think catering to Indian needs. Moreover, language models do have a strategic importance
Sachin Legaltech|2023-05-27 10:51:56|It is a demonstration that we have talent to build a good one + hopefully a precursor to have a company like mosaic (or hopefully soon something like OpenAI) in India
~ Clament John|2023-05-27 10:52:43|We really need one for each Indian language. I am a mallu who runs a small business and my customers mostly speak Malayalam.   If we don't have a model for Indian languages the MSME sector will fall behind, drastically
Rahul Sundar 2013|2023-05-27 10:55:15|1. LLMs open a market lot of NLP related opportunities for that particular country where services can be offloaded/outsourced.  2. After natural resources, semiconductors, many other 'tech' buses that India had missed earlier, this is something that we shouldn't miss given the pool of talent and also funds. 3. Indian languages are sooo many, it is important that NLP is brought in for those to penetrate into deeper vernacular markets and offer services which otherwise weren't possible.. 4. LLMs also hold key to AGI in a way which holds greater strategic importance (defense/governance, etc). LLMs and AGI could be the next nuke tech that countries fight for..(already fighting for)
Aashay Sachdeva MPL Data Scientist|2023-05-27 10:57:53|Do check out their previous work, bert,bart,indic language datasets, indic tokeniser. For singular languages probably easy to use a technique like Lora for training
Rahul Sundar 2013|2023-05-27 10:58:32|Yea AI4Bharat have released quite a few tools as well. Has anyone here explored their models and tools?
Rahul Sundar 2013|2023-05-27 10:59:48|In fact I see the recent calling for some sort of  license/regulation to train LLMs analogous to the NPT..
Dhruv Anand|2023-05-27 11:00:12|I've used their transliteration demo and it's quite bad
Aashay Sachdeva MPL Data Scientist|2023-05-27 11:00:59|[PHONE] is working with them
Rahul Sundar 2013|2023-05-27 11:01:14|Oh great!
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:01:26|Meta showed off a translation model last week that seems to be able to translate between many different languages - they claim 11k languages if I'm not wrong - and perhaps it is possible to build a single model that addresses many different languages (speech to text, translation, etc)
Rahul Sundar 2013|2023-05-27 11:01:38|Bad in what sense? 1. Model capability? Or 2. UI/UX?
Dhruv Anand|2023-05-27 11:02:01|Model capability: quality of output basically
Rahul Sundar 2013|2023-05-27 11:02:44|Okay! I am curious to know, how you tested the quality of the output?
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:03:06|Don't know the users on this group and how they see AI strategy at a high level but I agree that serving a large base of consumers in India is a generally good use of AI. Maybe AI can do what smartphones have done for education in India's Tier 3 cities and towns ‎[5/27/23, 11:05:00] Dhruv Anand: ‎image omitted ‎[5/27/23, 11:05:01] Dhruv Anand: ‎image omitted
Rahul Sundar 2013|2023-05-27 11:05:10|Having local players to serve a huge customer base is quite important. It is just a matter of well preparedness...
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:05:23|Same. So many are just using Azure OpenAI - either that or I'm in a bubble
Dhruv Anand|2023-05-27 11:05:27|This
Dr. Pratik Desai KissanGPT|2023-05-27 11:05:47|I have worked with Bhasini models, in touch with few folks who worked on it at IITM before, but not directly collaborating with AI4Bharat team, yet. Let me know if someone can get me an intro.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:07:12|Responding to the OP - one of the biggest blockers for building any LLM is data engineering, data quality. Architectures are grokkable, compute is manageable, getting good and well prepared data is probably the biggest differentiator IMO
Rahul Sundar 2013|2023-05-27 11:08:22|This is still fine right?  Reminds me of those codechef problems where we used to detect a user signal to stop a loop say - (STAHP, STop, stttoooppp, etc) The reader can more or less understand. But here I guess this is just transliteration so vernacular to English transliteration is a non-unique problem unless we have codified laws
Dhruv Anand|2023-05-27 11:08:48|Yeah that's the positive example for contrast
Rahul Sundar 2013|2023-05-27 11:08:56|Agreed. Even in the AI4Bharat team I see a lot of data leads
Rahul Sundar 2013|2023-05-27 11:09:37|*people in data lead positions I mean
Dhruv Anand|2023-05-27 11:10:19|No, it's a language model. It should be able to pick up the implicit conventions in millions of tokens. The devnagari to Roman is completely wrong and there are a bunch of APIs out there that do a much better job
Rahul Sundar 2013|2023-05-27 11:10:48|Okay!
Dr. Pratik Desai KissanGPT|2023-05-27 11:11:21|To build base model like LLaMa, IITM will be need a hefty fund or huge support from Azure. MS funded the Bhasini training, LLaMa size base model can be very expensive to train.
Rahul Sundar 2013|2023-05-27 11:11:30|Do you expect complete invertibility here in such cases like- Roman to Devnagari and Devanagari to Roman?
~ Kp|2023-05-27 11:11:45|But since hindi is a phonetic language why do we need ai for transliteration?
~ Kp|2023-05-27 11:11:48|There are already standards like baraha
~ Kp|2023-05-27 11:11:54|Yes. Baraha
Rahul Sundar 2013|2023-05-27 11:12:16|I guess AI4Bharat is still being funded hugely by Microsoft Research and IDC..correct me if I am wrong.
Abhishek Mishra|2023-05-27 11:12:27|For creating datasets, a good start can be to translate the training dataset that is open sourced already like redpajama dataset that is also commercially licensed. Then fine-tune with smaller example datasets to add Indian nuances based on what we want to achieve via instruction tuning
Rahul Sundar 2013|2023-05-27 11:12:41|Tamil would be a difficult language to transliterated
Dhruv Anand|2023-05-27 11:13:45|No i expect the most colloquially correct looking transliteration from an Indian script (devnagari) to roman
Rahul Sundar 2013|2023-05-27 11:13:47|Also I see that Nandan Nilekani is a sponsor/initiative driver
~ Kp|2023-05-27 11:13:48|The crux is that llm might be overkill for transliteration. And prone to hallucination anyway
Dr. Pratik Desai KissanGPT|2023-05-27 11:14:17|True. I'm not sure why MS will fund training of an OpenAI competition. Unless GoI decides to take an initiative, like BritGPT. ‎[5/27/23, 11:14:29] ~ Kp: ‎image omitted
Rahul Sundar 2013|2023-05-27 11:14:34|Makes sense for other NLP tasks.. unless it is something like - We trained an LLM, apart from all the things it does, it can also do transliteration..
Rahul Sundar 2013|2023-05-27 11:15:05|Great! I will check this out
~ Kp|2023-05-27 11:15:06|Yea but transliteration is a finetuning task. So the llm won't be really primed for anything else
Rahul Sundar 2013|2023-05-27 11:15:28|Okay ‎[5/27/23, 11:16:49] Dhruv Anand: ‎image omitted
Abhishek Mishra|2023-05-27 11:17:31|Lora fine tunes are stackable, I don't think you'll lose prior capabilities with that since transliteration can be orthogonal to existing fine tunes. Unless you're overriding existing behaviour, it may work and can be tried out
~ Kp|2023-05-27 11:17:58|Ah. I'll check it out
Dhruv Anand|2023-05-27 11:18:50|I feel like with enough training data of Hindi written in Roman script, this should be a trivial task for an LLM. They seem to be using a more primitive model. I also checked their dataset and it has the same mistakes. Anyway, I think we don't have the same definition of transliteration as a task. I'm thinking of it post input.
~ Kp|2023-05-27 11:19:37|That's why gpt 3.5 is able to transliterate without it being finetuned for transliteration specifically
~ Kp|2023-05-27 11:19:50|Because it's not a hard task for state of the art
~ Clament John|2023-05-27 11:20:05|Would this overcome spelling mistakes and colloquial / dialects
~ Kp|2023-05-27 11:20:30|Not sure. It's been 8 years since I used baraha haha
Rahul Sundar 2013|2023-05-27 11:20:40|Oh is it!
Dev Aggarwal|2023-05-27 11:21:01|They have a long time interest in this. https://news.microsoft.com/en-in/features/with-help-from-next-generation-ai-indian-villagers-gain-easier-access-to-government-services/
~ Chandan|2023-05-27 11:21:30|‎Ravi Theja added ~ Chandan
~ Kp|2023-05-27 11:21:37|Yea it featured in build
Rahul Sundar 2013|2023-05-27 11:21:40|Interesting question!
~ Kp|2023-05-27 11:22:24|MS probably is targeting this segment.  They'll license the basic models to finetuning/ vectorisation for specific use cases
~ Kp|2023-05-27 11:22:40|Using azure openai service or something similar
Nirant|2023-05-27 11:22:54|If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.
Dev Aggarwal|2023-05-27 11:23:13|MS research in particular has been building multilingual chat interfaces for decades (my cofunder has that patent 😆)
~ Kp|2023-05-27 11:23:24|You didn't add mine right😮‍💨 I was the last person before the warning
Nirant|2023-05-27 11:23:27|And remove you from this group.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:24:21|Aren't transformer architectures essentially really effective at translation? The gains we saw in language translation around 2018-19 were largely due to these architectures.
Nirant|2023-05-27 11:24:57|You'll find out soon enough
~ Kp|2023-05-27 11:25:19|😥
Paras Chopra Wingify|2023-05-27 11:25:24|My point is that increasingly large models will cover almost all languages, which will likely include most Indian languages
Nirant|2023-05-27 11:26:08|GPT4, GPT3.5 Turbo are already quite good for Indic languages. It'd be very data-intensive to do better than them for Indic languages even today.
Nirant|2023-05-27 11:26:18|And absolutely not worth any commercial utility
Dr. Pratik Desai KissanGPT|2023-05-27 11:26:36|MS working closely with us, so I am very well aware of their capabilities. My point was regarding them funding India llm, after spending $10B in OpenAI. IITM themselves can't do it. They may have talent but not resources.
Abhishek Mishra|2023-05-27 11:26:42|Yes, ai4bharat indicxlit is just a 11M model with a single transformer only, so it's expected that it's performance may be lacking in a few areas. Using LLM for transliteration is like bringing a tank to a gun fight, but it does wonderful and works zero shot so can't complain. With GGML quantizations, you can even have <4GB models doing transliteration and more for Indic languages if underlying model is fine-tuned on Indic languages.
Paras Chopra Wingify|2023-05-27 11:27:06|If anything, perhaps it makes sense to fine tune large models on Indian govt files (let’s say Supreme Court decisions) and solve india specific problems
Rahul Sundar 2013|2023-05-27 11:27:24|Ah, this makes sense! So where do you think India would find its edge then?
Nirant|2023-05-27 11:27:28|if I remember correctly, but I might be wrong Sachin [PHONE] was doing this for Supreme Court
Nirant|2023-05-27 11:27:41|Do English FOSS, do it better than the world
~ Vivek|2023-05-27 11:27:48|‎~ Vivek joined using this group's invite link
Dr. Pratik Desai KissanGPT|2023-05-27 11:28:01|I'm doing it for Agri and Rural data. But embedding is better solution than fine-tuning, imo.
Rahul Sundar 2013|2023-05-27 11:28:04|Okay!
Paras Chopra Wingify|2023-05-27 11:28:17|we have a rich collection of files from government agencies, so makes sense to focus on domain specific models.  Perhaps even a model of how Indian government operates :)
Dev Aggarwal|2023-05-27 11:28:29|Msft funded openai after the fact
Paras Chopra Wingify|2023-05-27 11:28:42|What data sources are you ingesting?
Rahul Sundar 2013|2023-05-27 11:28:45|Digital-twin of the Indian govt operations :p
Abhishek Mishra|2023-05-27 11:28:54|Meta and Google have keen interest in Indic languages as well. Google is working on USM for 100+ Indian language support and meta recently released MMS for the same purpose
Abhishek Mishra|2023-05-27 11:28:56|https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/
Paras Chopra Wingify|2023-05-27 11:29:16|Replace govt with an AGI   True democracy :)
Paras Chopra Wingify|2023-05-27 11:30:10|also full of horrors!  But perhaps we can be first ones to experiment with this.
Rahul Sundar 2013|2023-05-27 11:30:19|Who will hold the switch to the AGI? 🤪
Dr. Pratik Desai KissanGPT|2023-05-27 11:30:44|Agri universities, ICARs, NABARD, and other other Official recommendations. agri is federal, so no one has unified collection. Collection and getting everyone on board is the challenge i'm solving first. But it is coming around.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:31:34|Yeah, any chat GPT user today should be able to generate text in Hindi, Kannada, Tamil, etc. I've done that a few times, it is pretty neat. ‎[5/27/23, 11:31:59] Ojasvi Yadav: ‎image omitted
Paras Chopra Wingify|2023-05-27 11:32:48|This seems cryptic.  What types of tasks? Where is the confidence coming from? Is it a Bayesian model
Ojasvi Yadav|2023-05-27 11:32:54|The graph is that of its journey in a new website. It faced initial difficulties adjusting to the new place, but then each subsequent spike is a new skill learnt. The spike grows smaller and smaller as the importance of each new learnt skill decreases.
Ojasvi Yadav|2023-05-27 11:33:05|“Importance” being a weighted-conditional probability distribution over all the features of the website. It is conditional on the task at hand.
Ojasvi Yadav|2023-05-27 11:33:45|So the skill of “tweeting” for [PHONE] in this case would probably have the most importance if Nirant was using this on Twitter. For a guy like me, however, it would probably be “bookmarking”. Jokes aside, note that the measure of skill importance is CONDITIONAL on the task I give it. So even though ‘bookmarking’ for me might be the most important skill on Twitter generally, but if my instruction involves tweeting, then that does affect the way it assigns the importance to each skill, and that’s how ‘tweeting’ would be prioritised.
Ojasvi Yadav|2023-05-27 11:34:26|This is some scary&crazy stuff hence I’m completely off the grid for the last 2 weeks. This is the only thing that matters.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:34:53|Thanks. Is there documentation on what tasks this is being trained for?
Ojasvi Yadav|2023-05-27 11:34:58|no
Ojasvi Yadav|2023-05-27 11:35:13|too risky
Paras Chopra Wingify|2023-05-27 11:36:38|I have no idea what you’re talking about :)  If anyone else has, please pitch in
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:36:52|Do you have task domain or task type level metrics of some kind? That would be interesting to see. Yes, the model will still get trained if you feed it different sets of training data (for different tasks) in the same dataset. And I'm no expert in LLM training, have only built one or two.
Nishant Wyse|2023-05-27 11:37:07|That’s unjust for folks who want to follow discussions
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:37:28|I only have guesses. Seems Ojasvi is building these models and wants to share a general, high level update?
Ojasvi Yadav|2023-05-27 11:37:57|This is not and does not use a wrapper. I don't have a personal openAI account! And this is not an LangChain/autoGPT/babyAGI fork. This doesn't need internet to operate. There is no fine-tuned model either. The data used for its training is my own, just like the models used.
Sachin Legaltech|2023-05-27 11:38:06|I was doing semantic search on Supreme Court cases. I have dataset of (somewhat cleaned) Supreme Court cases and embeddings..If anyone here is interested in finetuning on it, I can share.
Dr. Pratik Desai KissanGPT|2023-05-27 11:38:08|What are you using as the base model?
Ojasvi Yadav|2023-05-27 11:38:47|that deserves a research paper for itself ;)
Dr. Pratik Desai KissanGPT|2023-05-27 11:39:15|Haha.. will wait to try whatever you’re cooking there.
Ojasvi Yadav|2023-05-27 11:39:42|Yes. Still initial stages. Don't know the timelines but I can see the proof of concept around the corner.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 11:39:44|Awesome. Good luck
Paras Chopra Wingify|2023-05-27 11:40:51|Good luck.  Just remember to not destroy the world along the way :)
Dr. Pratik Desai KissanGPT|2023-05-27 11:45:07|[PHONE] please provide your coordinates to air strike registry.
~ Kanchi|2023-05-27 11:45:53|‎~ Kanchi joined from the community
Kiran Raj S. R|2023-05-27 12:02:40|‎Kiran Raj S. R left
Sandeep Srinivasa RedCarpetup|2023-05-27 12:09:59|Want to mention that in context of my tweet about the Dubai model topping charts - my intended audience is the govt and not a blame to the engineers here (and across India). I was on Mirror Now talking about this a few weeks ago - at a govt funding and promotion level, we are doing too less.  And at that time I referred to only China....now it is Dubai as well.  As always, due credit to everyone here building on stuff 🫡
Shashwat TDC|2023-05-27 12:17:26|Esp given how many back office jobs and call center jobs it's gonna replace. Not enough urgency.
Abhishek Mishra|2023-05-27 12:17:44|TII UAE is a state funded entity and it's efforts or output can only be compared at the level of equally backed or rich entities.
Sudharshan GenAI|2023-05-27 12:20:28|Woah didn’t know falcon was from Dubai. Holy shit that’s crazy
Sudharshan GenAI|2023-05-27 12:20:54|I gotta dig deeper, going to find out who’s behind this
Abhishek Mishra|2023-05-27 12:22:52|It's TII
Dr. Pratik Desai KissanGPT|2023-05-27 12:23:22|By the way, Falcon is not a real OSS. 10% royalty after 1M revenue.
Nirant|2023-05-27 12:24:27|Would encourage you to check the AUM of any VC fund in this WhatsApp group or any single IITs compute expenses. Or any ITBEES company's profits.   We've more than enough money, we lack willpower
Paras Chopra Wingify|2023-05-27 12:24:56|What is Falcon?
Nirant|2023-05-27 12:25:17|SoTA LLM
Rajesh RS Generative AI WhatsApp Group|2023-05-27 12:25:28|https://falconllm.tii.ae/
Rajesh RS Generative AI WhatsApp Group|2023-05-27 12:25:35|Models are available on Hugging Face 🤗 7B: https://lnkd.in/ejpGndA2 40B: https://lnkd.in/e6ESxVTK
Sudharshan GenAI|2023-05-27 12:26:12|That’s not exactly bad per se   It has a commercial license if I remember correctly. Which unlocks tonnes of opportunities.  Now everyone using llama under the hood are going to switch lol
Nirant|2023-05-27 12:26:30|Nothing has inspired more licensing innovation than LLM weights in my living memory
Rajesh RS Generative AI WhatsApp Group|2023-05-27 12:26:47|"Well on the one hand we have ""Open"" AI..."
Kartik Mandaville|2023-05-27 12:28:27|Any ideas on how to implement prioritization on search (pinecone etc)? (Use case: Companies prioritize sources say employee handbook, sales handbook, HRIS etc and then on a query - it picks up from that order) One way is to keep them in separate indexes and search from highest priority to low but curious has anyone faced something like this?
Dr. Pratik Desai KissanGPT|2023-05-27 12:28:37|I agree. I hate CC-BY-NC license, it’s hypocrisy.
Nirant|2023-05-27 12:28:48|CustomRetriver in LlamaIndex
Nirant|2023-05-27 12:30:01|And yes, different indexes is one way to do it. Can use collections if your VectorDB supports that. Qdrant allows metadata filtering which works out of the box for these cases
Abhishek Mishra|2023-05-27 12:30:05|I would've agreed if not for the fact that those compute budgets or any other budgets aren't solely dedicated to this purpose. However my comment was to distinguish the efforts made on a personal level by an individual vs state funded entities.
Abhishek Mishra|2023-05-27 12:31:58|Yeah that's a NC license by definition, non-commercial. MPT initially was launched commercially but due to their usage of a non-commercial dataset for usage, they had to change the license to CC BY NC
Dev Aggarwal|2023-05-27 12:31:58|Can you also do weighted search?
Nirant|2023-05-27 12:34:27|Na. That has to go via a CustomRetriever in LlamaIndex or similar in Langchain
ashish Acgt01 Twitter|2023-05-27 12:35:06|Taking off from what Paras said, I would argue we would be better off focusing on training and empowering people with strong knowledge of ml & they will go on & build amazing things. Some of these things could be making an impact in societal problems like edu & health, both in private sector & govt
Dr. Pratik Desai KissanGPT|2023-05-27 12:36:52|I may be wrong, but I believe that as all these llms are trained on data that is in the gray area, if taken to courts, non of these licenses will hold.
Nirant|2023-05-27 12:37:40|Which court? India? Europe? California?
Dev Aggarwal|2023-05-27 12:38:48|Zuckerberg bhi gaya tha. Kuch nahi bigaad paye courts 🙈
ashish Acgt01 Twitter|2023-05-27 12:39:10|Curious to hear your take [PHONE]
Nirant|2023-05-27 12:39:46|It'd be too off topic and too bitter for this forum. Let's talk on DMs/IRL
Sudharshan GenAI|2023-05-27 12:40:02|I’m honestly loving Dubai’s stance on tech in general. They’re at the forefront of blockchain and web3. Very blockchain friendly and they give funded founders a 10 year golden visa.   I predict them taking a similar stance on AI, given falcon.
Sudharshan GenAI|2023-05-27 12:40:51|[PHONE] any update on Sama visiting blore?
Nirant|2023-05-27 12:41:36|Got multiple denials. Running down some more leads.
Dr. Pratik Desai KissanGPT|2023-05-27 12:44:37|10% royalty on trained data without paying data sources or without permissions in many cases. Zuck settled outside courts and paying fines. What I'm saying is that if I use Llama commercially and then Meta goes to court, it won't be straightforward cease and desist.
ashish Acgt01 Twitter|2023-05-27 12:44:42|"Picking one visionary person to be India's ai czar could catapult India to be an ""ai first mover"" Sadly govt is too slow. My hope is that open source & individual devs will ensure that the field evolves such that geographic boundaries will matter very little."
Nirant|2023-05-27 12:46:03|Geo boundaries haven't mattered for a while. That's how we've every dev who can fine-tune a LLM on a one way flight outside India
Sandeep Srinivasa RedCarpetup|2023-05-27 12:48:05|That's not a fair take with due respect. Kickstarting the ecosystem is always the job of the govt. Look at Tesla, etc. Dubai is now heading leadership of the APAC region in AI (minus China).  The amount of govt investment in AI in China is staggering. This is existential - because if the ecosystem is not built out, value will accrue to the local ecosystem of these countries even if it is Indians who go there to build it.
Nirant|2023-05-27 12:49:59|Are you an optimist by any chance?
Sudharshan GenAI|2023-05-27 12:50:21|How is Dubai leading AI in APAC? (Apart from falcon)
Nirant|2023-05-27 12:50:29|To be clear: I agree with Sandeep, I'm just disillusioned perhaps.
Sudharshan GenAI|2023-05-27 12:50:37|Any other initiatives/ funds?
Nirant|2023-05-27 12:51:16|FalconEdge funds NLP companies e.g. Verloop.io ‎[5/27/23, 12:53:14] Nirant: ‎image omitted
Harsh Gupta Felvin|2023-05-27 12:57:14|Government doesn't read tweet
Sandeep Srinivasa RedCarpetup|2023-05-27 12:58:50|hopefully they watch Mirror Now ;)
Harsh Gupta Felvin|2023-05-27 13:00:40|I feel government stuff also work lot like B2B sales. You need to find the right person in the big machinary who has the power and interest in doing what you want them to do, and find ways to talk to them and work with them directly.
Sudharshan GenAI|2023-05-27 13:01:00|Some corrections   Falcon is not from Dubai. It’s from TII which is based in Abu Dhabi.  https://falconllm.tii.ae/  It’s an initiative from the Abu Dhabi govt.
Sudharshan GenAI|2023-05-27 13:01:39|Oh yeah! Have visited a few of these when I was in school. Went to school in Abu Dhabi.   Dubai has something called knowledge village which has a tonne of campuses
Nirant|2023-05-27 13:01:40|UAE boss 🙈💜
Harsh Gupta Felvin|2023-05-27 13:01:41|Some random person in the machinery seeing/reading the arguments somewhere is not enough for them to do something. They already have a lot on their plate, and they might not be in the right position to do something. ‎[5/27/23, 13:01:53] Sudharshan GenAI: ‎image omitted
Prayank Swaroop Accel|2023-05-27 13:19:42|"The challenge is language structure...in NLP ... English etc are subject verb object  ""I am eating a mango""  Whereas Hindi is Subject object verb ""Main ek aam khaa Raha hoon"""
Nirant|2023-05-27 13:23:23|How'd you explain Mandarin and China's amazing progress then? That has no SVO even
Anshul Khandelwal Invideo|2023-05-27 13:23:32|Doubt.  Google got away with digitising copyrighted books for search.  Fair use arguments in the hands of good lawyers will go a long way...
Nirant|2023-05-27 13:24:24|Not just Google, Amazon scans books for selling and that's FUP too iirc
Dhruv Anand|2023-05-27 13:38:01|That's translation. Transliteration is a much easier problem
~ J|2023-05-27 13:40:16|I’m also curious if Marketing teams have a policy around where AI can’t be used - specially for blogs, public work, journo pieces
~ Divya Jain|2023-05-27 13:41:48|‎~ Divya Jain joined from the community
Rajesh RS Generative AI WhatsApp Group|2023-05-27 13:42:12|That's one area where they *want* to use NLG capabilities like LLMs if I think
Rajesh RS Generative AI WhatsApp Group|2023-05-27 13:42:47|*if I'm right... ‎[5/27/23, 13:45:38] Abhishek Mishra: ‎image omitted
Prayank Swaroop Accel|2023-05-27 13:45:55|Yes that is why in NLP translation ... Language structure is very important. Transliteration is just phonetic similarity so AI4Bharat is not wrong to transliterate from Hindi phonetics to English phonetics. If transliteration is what is supposed to do.
Prayank Swaroop Accel|2023-05-27 13:47:38|Yes Hindi, Hinglish will be different that is another problem. And availability of training datasets is a bigger challenge.   But you can't give a model that is built to understand English grammar to predict Hindi. ..
Prayank Swaroop Accel|2023-05-27 13:49:31|At a fundamental level, I think there are two ways to do this:   1. Stochastic parrot method - then language grammar doesnt matter to LLM. You train with enough English Hindi pairs the parrot will be able to give you the answer. ‎[5/27/23, 13:49:33] Prayank Swaroop Accel: ‎image omitted
Prayank Swaroop Accel|2023-05-27 13:50:45|2. Language understanding - might be more relevant to generate correct embeddings in semantic search - I'm not experienced to say if because of stochastic parrot method ... language understanding will follow
~ Sanat Mondal|2023-05-27 13:50:54|‎~ Sanat Mondal joined from the community
Abhishek Mishra|2023-05-27 13:51:29|The models that do well in this area aren't trained on just one language, they are trained on multilingual dataset and learn these capabilities themselves. What you're referring to as stochastic parrot method is the autoregressive transformer architecture and these SoTA architectures don't care for language grammar structures.
Abhishek Mishra|2023-05-27 13:52:56|Models trained specifically for multilingual translation like Bloom models also perform fairly well although I've not seen a good Bloom model for Indic languages. Google and Meta have USM and MMS that Target the same problem for 100+ Indic languages.
Rajesh RS Generative AI WhatsApp Group|2023-05-27 13:53:45|"Yeah, ""stochastic parrot"" is just jargon which is used in the context of the interpretability of these models, but the underlying architectures tend to be transformer based for most of the new LLMs. The sequence of tokens you train on is ultimately a data engineering problem - and yes, the model, its tuning and all are not a walk in the park but the data engineering distinguishes itself by being tedious and messy."
Rajesh RS Generative AI WhatsApp Group|2023-05-27 13:54:48|Someone else in the discussion mentioned low resource languages - that is a key thing here - and Indic translation/transliteration/NLU/G/P will improve by leaps and bounds if we had good datasets to start with
Rajesh RS Generative AI WhatsApp Group|2023-05-27 13:56:32|Tooling also matters. Character sets are different and complex across languages - we have many languages and dialects where phrases constructed to be alike may mean different things. Complex languages and dialects -> rich data corpus -> more data engineering requirements -> more training/tuning time -> longer time to get performant models.
Abhishek Mishra|2023-05-27 13:56:33|Yeah I mentioned the 2 key problems that are actually unique to a country like India that no other English speaking nation would face. These give us opportunities to add value and push SoTA in areas where it's useful for us and penetrates the bulk of our country that actually doesn't speak English well.
~ prakashkagitha|2023-05-27 14:10:45|‎~ prakashkagitha left
~ Anuj Khandalikar|2023-05-27 14:11:33|‎~ Anuj Khandalikar joined from the community
~ ~|2023-05-27 14:30:56|‎~ ~ left
~ Nischay|2023-05-27 14:36:31|‎~ Nischay joined using this group's invite link
~ Harsh|2023-05-27 14:41:19|‎~ Harsh joined from the community
~ Abhilash K Pai|2023-05-27 15:00:21|‎~ Abhilash K Pai joined using this group's invite link
~ Sanchit|2023-05-27 15:08:01|‎~ Sanchit joined using this group's invite link
~ Divya|2023-05-27 15:08:15|‎~ Divya joined using this group's invite link
~ Santhosh K|2023-05-27 15:08:28|‎~ Santhosh K joined using this group's invite link
Hemant Mohapatra|2023-05-27 15:09:24|‎Hemant Mohapatra joined using this group's invite link
ashish Acgt01 Twitter|2023-05-27 15:12:57|Deepfakes are a real problem  https://www.instagram.com/reel/CspZqO1NNBX/?igshid=NjFhOGMzYTE3ZQ==  Anybody has interesting thoughts on how to tackle deepfakes as they get easier & easier to generate & soon commoditized ?
~ Aayush Krishnan|2023-05-27 15:14:04|‎~ Aayush Krishnan joined using this group's invite link
ashish Acgt01 Twitter|2023-05-27 15:14:49|They could be used to create havoc in India especially by political parties' it cells
~ Shreyas Shetty|2023-05-27 15:15:01|‎~ Shreyas Shetty joined using this group's invite link
~ Shivansh|2023-05-27 15:22:32|Hey [PHONE], I have been working in countering deepfakes in social media(LinkedIn) from past year. Short answer is, for now, every synthetic image has a fingerprint/watermark in it which basic model(CNN/Fourier) can detect, but as we go forward, there will be images(midJ) which bypass this fingerprint thing and new methods would need to develop which involve taking other inputs too i.e. IP, activity on platform etc.
~ Keshav|2023-05-27 15:25:07|‎~ Keshav joined using this group's invite link
Anubhav mishra Zupay|2023-05-27 15:32:46|[PHONE] bro you're working on deepfakes detection too right ?
Swastik Banerjee|2023-05-27 15:32:56|This sounds like something we discussed/proposed 2-3 months back 👀
Swastik Banerjee|2023-05-27 15:33:16|.
~ Shivansh|2023-05-27 15:36:52|https://medium.com/@steinsfu/stable-diffusion-the-invisible-watermark-in-generated-images-2d68e2ab1241
~ Shivansh|2023-05-27 15:38:23|Apart from this, there are some other fingerprint which are exposed when you filter image with some fourier kernels, interesting stuff though!
~ Abhilash K Pai|2023-05-27 15:47:44|https://paperswithcode.com/task/deepfake-detection
~ Abhilash K Pai|2023-05-27 15:48:50|Good start point for working with deep fake detection.. you get links to the best research with their code
~ Prince|2023-05-27 15:58:53|‎~ Prince joined using this group's invite link
Prayank Swaroop Accel|2023-05-27 16:06:47|Folks is there going to be a zoom link to today's get meetup ?
Nirant|2023-05-27 16:08:15|Cc [PHONE] is the curator
Ansuman Patnaik|2023-05-27 16:09:03|Hello everyone! My name is Ansuman Patnaik, I'm a 21 y/o backend (who can also do a bit of frontend) developer from Bhubaneswar. I will be coming to Mumbai to participate in the Mumbai Hacks hackathon next weekend. Is there anyone here who'd be interested in teaming up to work on the generative AI track?
Shubham Sharma 2012C6|2023-05-27 16:15:40|People have stated availability of training dataset as a common problem to Indic language models. As a country with the size of our population what’s coming in the way of creating the correct kind of datasets? We have a lot of people who speake a lot of languages, don’t we?
~ Hridyansh Sahu|2023-05-27 16:24:03|‎~ Hridyansh Sahu joined using this group's invite link
Harsh Koo|2023-05-27 16:24:25|Work has happened on IndicNLP corpus and you can see a good list here https://github.com/AI4Bharat/indicnlp_catalog
Harsh Koo|2023-05-27 16:24:53|AI4Bharat leads the charge on developing models, datasets and applications for IndicNLP (along with MSFT as a worthy industry collaborator).
~ Swapnil Agarwal|2023-05-27 16:26:11|‎~ Swapnil Agarwal joined using this group's invite link
~ Ashwin|2023-05-27 16:34:47|‎~ Ashwin joined using this group's invite link
Jay Pokarna 2014 BPCC|2023-05-27 17:21:18|https://www.todayonline.com/world/tiktok-tests-ai-chatbot-tako-philippines-2179071   Tiktok is testing gen ai in the Philippines. Customers can ask questions regarding video and it can apparently help customers find similar videos as well
~ Praveen Kishore G|2023-05-27 17:23:41|‎~ Praveen Kishore G joined using this group's invite link
Simrat Hasura|2023-05-27 17:24:36|‎Simrat Hasura joined using this group's invite link
~ Anji Beeravalli|2023-05-27 17:31:44|‎~ Anji Beeravalli joined using this group's invite link
~ Gulshan|2023-05-27 18:03:31|‎~ Gulshan joined using this group's invite link
~ Navita|2023-05-27 18:07:19|‎~ Navita joined using this group's invite link
~ Prasad P R|2023-05-27 18:16:38|‎~ Prasad P R joined using this group's invite link
Harsh V Sharma|2023-05-27 18:17:17|‎Harsh V Sharma left
~ Siddhant Sangwan|2023-05-27 18:32:42|‎~ Siddhant Sangwan joined using this group's invite link
~ _|2023-05-27 18:33:17|‎~ _ joined using this group's invite link
~ Aashay Singhal|2023-05-27 18:38:51|‎~ Aashay Singhal joined using this group's invite link
Kartikeya Bharadwaj|2023-05-27 18:58:54|Yes we are!
Dev Aggarwal|2023-05-27 19:53:44|Link for the AI matchmaker at the meetup - http://ai-matchmaker.us-1.gooey.ai
Anubhav mishra Zupay|2023-05-27 19:59:21|https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq  What are shared links? Shared links are a new feature that allow users to generate a unique URL for a ChatGPT conversation, which can then be shared with friends, colleagues, and collaborators. Shared links offer a new way for users to share their ChatGPT conversations, replacing the old and burdensome method of sharing screenshots.  With shared links, users can let others see - and continue - interesting, funny, or insightful exchanges with ChatGPT.
Shubham Sharma 2012C6|2023-05-27 19:59:27|Are these datasets not big enough to create Indic chatGPT?
Anubhav mishra Zupay|2023-05-27 20:00:51|can anyone tell me how they might have done it? How will this work in another account or the long?
Rajesh RS Generative AI WhatsApp Group|2023-05-27 20:05:26|Folks, anyone using a fine-tuned OpenAI endpoint on Azure? Wanted to know if there is a way to host / access the same endpoint in a different instance - if I want an app in a different resource group on Azure to access the same endpoint. Thoughts?
~ Clament John|2023-05-27 20:08:17|Just load the same context to the LLM for future responses. A user account is just for with and rate limiting.
~ Clament John|2023-05-27 20:09:46|*a user account is just for authentication and rate limiting (the LLM does not care)
Anubhav mishra Zupay|2023-05-27 20:10:15|cool thanks
~ Arka 😼|2023-05-27 20:14:45|‎~ Arka 😼 joined using this group's invite link
Ravi Theja|2023-05-27 20:31:11|There are amazing line of speakers at upcoming *Huggingface x Inferless x SequoiaIndia* meet-up on *June 10th*.  Speakers:  1. Eliot Andres - Cofounder and CTO of Photoroom‬ ‪2. Prasenjit Dey - SVP Of Innovation at ‬MerlynMind ‪3. Saravana Kumar - Head of ML at Apollo.ai‬  Do register if you haven’t yet.  Registration link: https://lu.ma/ijcugt4n  Cc: [PHONE]
~ Naveen|2023-05-27 20:54:54|‎~ Naveen joined using this group's invite link
ashish Acgt01 Twitter|2023-05-27 20:58:41|A high level piece on medical ai by a16z's Vijay Pande:   https://time.com/6274752/ai-health-care/  https://twitter.com/vijaypande/status/1653854648288305153?s=46&t=pt9BgXoRTmqx5FEPyAl9bg
Sudarshan Lakshminarayanan|2023-05-27 21:06:09|‎Sudarshan Lakshminarayanan joined from the community
Saurav Tomar GenerativeAI WA Group|2023-05-27 21:10:10|Embedding the internet , seems to be a good initiative powered by open source https://alex.macrocosm.so/download
~ Ashutosh|2023-05-27 21:14:55|‎~ Ashutosh joined using this group's invite link
Dev Aggarwal|2023-05-27 22:06:34|These are offline? 😵
Aishwarya Goel Inferless 5s for 5G|2023-05-27 22:07:40|Eliot will be joining virtually, Prasenjit and Saravana in-person, going to be a great conversation 😃
Bulia Siddharth Aurashop|2023-05-27 22:17:09|There is a GenAI Hackathon happening on June 10-11 by Stellaris. Anyone wants to team up?  https://joinef.info/41Ye9kg
Ravi Theja|2023-05-27 23:11:40|[PHONE] please check this before sharing number.  DM anyone of the admins to add Himanshu.
~ Ajay|2023-05-27 23:19:53|‎~ Ajay joined using this group's invite link
~ Navita|2023-05-27 23:23:15|[PHONE] the previous msg was shared before I joined this grp. Kindly reshare it as I am not able to read it completely.
Ravi Theja|2023-05-27 23:34:21|If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any mod for an invite link.
Ravi Srinivasan|2023-05-28 00:16:18|https://twitter.com/manaskar/status/1662225822604992512?t=v8dK_ngSb6VIp0hUyOlwrA&s=19
Ravi Srinivasan|2023-05-28 00:17:20|False promise of fine tuned low parameter imitator models?
~ Ayush Yadav|2023-05-28 00:39:36|‎~ Ayush Yadav joined using this group's invite link
Abhishek Mishra|2023-05-28 01:02:38|It would be so nice if we had the option to pin this 🤣
Dev Aggarwal|2023-05-28 01:04:06|https://www.youtube.com/watch?v=cQO2XTP7QDw  Such a fun application & explanation of RNNs!
Amir Nagri|2023-05-28 07:28:36|I love this channel, the past videos on this channel are also very creative
Ravi Srinivasan|2023-05-28 07:39:12|This guy is maker-man!
~ Divya|2023-05-28 07:50:59|‎~ Divya left
~ Arvind Sankar|2023-05-28 08:16:44|Hi,  I am Arvind and I am a patent freelancer and data scientist graduate exploring legal tech. Currently (like most in the group) I am looking at applications of generative AI, but in the legal domain. I would be open to forming connections with people working on similar problems.
~ Arvind Sankar|2023-05-28 08:20:31|In legal applications, explainability is incredibly important. A lawyer would not trust any information if it doesn't have a source. I was wondering what work efforts have been made towards the same.  I have been in touch with people who generative text through GAI for a given context (say by using embeddings of a policy document) and then use cosine similarity between the output and the document to infer which of its parts are being referred to
~ Arvind Sankar|2023-05-28 08:20:42|But are there any better solutions?
ashish Acgt01 Twitter|2023-05-28 08:44:19|Arvind, this stuck out to me while scrolling out on twitter Some law firm used ChatGPT to file a legal brief, which had made up references of legal cases, and now are in a big soup  https://twitter.com/questauthority/status/1662273759259295746?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Aashay Sachdeva MPL Data Scientist|2023-05-28 08:47:51|Maintain a vectorDB of the documents and and the links as metadata.
Pratyush Choudhury|2023-05-28 08:48:28|And would you recommend using a meta data catalog?
Aashay Sachdeva MPL Data Scientist|2023-05-28 08:49:57|Catalog ss in?
Aashay Sachdeva MPL Data Scientist|2023-05-28 08:49:58|As*
Pratyush Choudhury|2023-05-28 08:52:09|I think this will do a good job explaining that I would - https://www.ibm.com/docs/en/icfsfz/11.3.0?topic=zos-metadata-catalog
~ Arvind Sankar|2023-05-28 08:54:07|"Yeah. Read the news today. When the affiants argued no such cases existed in any credible legal databases, these lawyers argued they didn't consult generative AI ChatGPT and it was the affiant's fault for ""consulting"" the same.  Now there is a sanction pending against them"
~ Arvind Sankar|2023-05-28 09:00:28|This would be for comparing the output with the document...?
~ Ugam Kamat|2023-05-28 09:12:27|‎You added ~ Ugam Kamat
Pratik Bhavasar|2023-05-28 09:29:23|Interesting work on citing pretraining data for reducing internal hallucinations   https://arxiv.org/abs/2305.13252
Abhishek Mishra|2023-05-28 09:39:55|In your case, the model has to cite the appropriate law (or the details from the case). After that, there are two components -   #1 whether the law (or the details from the case) exists or is hallucinated,  #2 whether the argument made using the law or details is the correct reasoning drawn from the citation  You've to avoid applying the model in novel or complex scenarios and instead use it in scenarios that happen in bulk and are low complexity.  I'm afraid, the model should only be able to exist as a copilot in this case and the human has to verify the cited law/reasoning on his end before using the argument.
Aashay Sachdeva MPL Data Scientist|2023-05-28 09:41:28|Other way to think is use the agent framework, add vector DB as a tool, only cite from the vectorDB
Abhishek Mishra|2023-05-28 09:44:49|You can search and retrieve from the vector DB that will be a compilation of Indian law in some way but you'll still need to verify the final reasoning and the details drawn from the citation. The application has the same challenges that a RAG application would face. Even Bing/perplexity ai make up details or generate novel nouns every once in a while, even though the request would be to stay completely factual.
Shan|2023-05-28 09:49:50|In India monetisation is a huge problem. The millions of $ of investment takes forever to recover, if at all.
Rajesh RS Generative AI WhatsApp Group|2023-05-28 09:52:17|Maybe building for India requires a different approach from that used by Si valley firms to deliver scalable value for millions of adopters/consumers. We've got a combination of price inelasticity and discerning consumers here. Monetization for new entrants requires partnerships that build scale and credibility.
Deep Samsung R&D|2023-05-28 09:54:39|What's the best proper hosted infrastructure or tips to deploy large Langchain based Prompt Templates, currently the API inference call takes ~104sec with GPT-4 API ? Or any ways to make GPT4 API inference faster by optimising prompts?
Shan|2023-05-28 10:02:30|But we have more than enough speakers of such languages. They aren’t low resource in the sense that these aren’t dead languages. So both the problems are solvable.
Abhishek Mishra|2023-05-28 10:05:08|Solvable but currently solved with poor performance. So makes for a good opportunity for pushing SoTA in the context of Indian languages and solving a problem unique to countries like India.
Nirant|2023-05-28 10:06:18|Friends, we're all quite passionate about Indic LLMs.   I'll request the next person who wants to chip in to contribute with code or data instead of ideas.
Aashay Sachdeva MPL Data Scientist|2023-05-28 10:11:43|https://huggingface.co/aashay96/indic-BloomLM  I had converted the ai4bharat dataset into HF dataset, and have a script to train Hf models on the dataset using LoRA. Added a readme of what else can be optimised. (Deepspeed etc)
Aashay Sachdeva MPL Data Scientist|2023-05-28 10:11:56|If anyone wants to explore indic datasets
Rajesh RS Generative AI WhatsApp Group|2023-05-28 10:26:13|Some thoughts on this; a) how would you set up a test involving counterfactuals for legal applications? b) can we extract human-readable rules from the model's performance - maybe there is a way to do black box testing for something like this? c) Since we're using LLMs, is it possible to develop conversational interactive explanations?
~ Harsh Pokarna|2023-05-28 10:39:23|‎~ Harsh Pokarna joined using this group's invite link
~ Abhinav|2023-05-28 10:42:20|‎~ Abhinav joined using this group's invite link
Ambarish Ganguly|2023-05-28 13:13:25|https://github.com/currentslab/awesome-vector-search
Ambarish Ganguly|2023-05-28 13:13:42|Good repo
~ Apurva Bhatt|2023-05-28 13:17:49|https://jalammar.github.io/illustrated-transformer/
~ Apurva Bhatt|2023-05-28 13:18:00|A great blog to understand transformers in detail
~ HP|2023-05-28 13:38:22|‎Ravi Theja added ~ HP
Swastik Banerjee|2023-05-28 14:26:18|If we hit 2k people, we start a podcast cc [PHONE] [PHONE]
Nirant|2023-05-28 14:26:50|I like the joke. WhatsApp groups have a limit of 2^10 people
Swastik Banerjee|2023-05-28 14:27:39|xD
Dev Aggarwal|2023-05-28 14:30:04|Just fork into group 1 & group 2. I’ve seen eg founders circle doing this
Nirant|2023-05-28 14:32:03|There are better ways to kill a conversation. I'll give them a chance first.
Paras Chopra Wingify|2023-05-28 14:33:21|Hot take: Nirant is secretly a LLM finetuned on sarcasm ‎[5/28/23, 14:33:50] Nirant: ‎GIF omitted
Abhinav Verma Longshot.ai|2023-05-28 14:34:09|LLMs not there yet. Ye AGI hai in secret
~ Kp|2023-05-28 14:34:25|He's an LLM designed by policybazaar
Ravi Srinivasan|2023-05-28 14:36:43|Actually such humor would be a good predictor of agi, when it comes
Vamshi|2023-05-28 15:04:21|The existential horror of having an AGI powered auto-complete pre-empting your every statement with a wiser, and more sarcastic take should be enough to sober up the most progressive optimists amongst us. 😁 ‎[5/28/23, 15:04:47] Vamshi: ‎GIF omitted
~ Nithyakala|2023-05-28 15:24:38|‎‎~ Nithyakala changed their phone number to a new number. ‎Tap to message or add the new number.
Shashank Generative AI Group|2023-05-28 17:39:22|"not involved anymore but a few months back I made a Lawyer Copilot over entire Canadian law for a startup. so can share a bit from what i learnt.   IMO doing basic QA over embeddings is not a good idea. instead I used SequentialChains (from langchain. easy to build on your own too).  oversimplying but basically for each question, I divided them into 3 other subquestions to fetch narrow (hence lower chance of hallucination) answers then these were summarized/combined in some manner to influence other subanswers and eventually get a final answer. lot of chains 😅.  in the user interface, we also exposed this ""thought process"", a user could see the subquestions-answers too. and the actual sources from which each sub-answer was derived. helps instill confidence in the user if they can see the specifics, especially in fields like law, healthcare. as you said, explainability is important :)  didn't get time to optimize, test this more. also was made using gpt-3.  would perform better and slower 😂 with gpt4."
~ keith|2023-05-28 17:52:00|Yessirr, DMing you
Sandeep Srinivasa RedCarpetup|2023-05-28 17:59:32|This is very intresting. How did u split the subquestions? I'm assuming u created few-shot examples  Did u follow a standard research approach (like react-and-act) or did u create ur own. What was the logic/thought process to create the examples
~ Tirtha|2023-05-28 18:01:28|Guys for someone who’s a beginner who wants to train a Chatbot from scratch using any open source LLM architecture by fine tuning it on a dataset, can you suggest any resources?
Neeraj Kumar|2023-05-28 18:09:06|I am interested. Just registered for the event.
Anubhav mishra Zupay|2023-05-28 18:10:27|I and my cofounder [PHONE] were building LegalMind from 2019-2021 in college and worked with CAM (Cyril Amarchand) at that time we were working with various BERTs and even tried creating a specific Legal Word-vec. However in any case in order for any document that has to be admissable in the court one must provide either a statutory-proof,  constitutionalvalidy and evidence mapping in order for the court to accept it. Majorly while arguing the citations must of a judgment that is disposed of in the courts with proper AIR citings.   Secondly, we observed that there has to be a domain-specific model that needs to be built from this from scratches legal language understanding is different than NLP.
Anubhav mishra Zupay|2023-05-28 18:11:40|You can refer, Harvey, Casetext and see how they might have integrated this, my assumption is Harvey has raised money because they are building a foundation model with legal understanding much like what bloombergGPT is for finance a 30B LLM if I am not wrong
Rahul Sundar 2013|2023-05-28 18:52:38|https://arxiv.org/abs/2305.15717
~ Arpit Agrawal|2023-05-28 18:55:43|‎You removed ~ Arpit Agrawal
Aashay Sachdeva MPL Data Scientist|2023-05-28 18:56:22|Rule violation wohoo ‎[5/28/23, 19:02:44] Shashank Generative AI Group: ‎image omitted
Shashank Generative AI Group|2023-05-28 19:06:14|great points!
Abhishek Mishra|2023-05-28 19:09:19|Best guide in this area exists by Jon Durbin *airoboros* who has created his own dataset by API distilling GPT 3.5.  He has created 13B and 7B models via fine-tuning llama using vicuna fastchat module.  The dataset preparation, eval method and fine-tuning all are shared in reproducible manner on his airoboros 13b repo  https://huggingface.co/jondurbin/airoboros-13b
~ Tirtha|2023-05-28 19:09:40|Thank you so much
Nirant|2023-05-28 19:10:58|"""Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs.""  Ergo, you can't really distill GPT3.5 without losing a lot of factual information  https://arxiv.org/abs/2305.15717"
Abhishek Mishra|2023-05-28 19:12:48|I think fine-tuning is best for style transfer and that was quite evident from the start. Full knowledge transfer can't be achieved by fine-tuning anyway.
Abhishek Mishra|2023-05-28 19:13:44|Nothing new there. A full fine-tuning would still yield value if the focus is for solving a single problem and not imitate chatGPT in every way.
Abhishek Mishra|2023-05-28 19:15:55|Best example for my statement - Goat: fine-tuned llama that beats gpt 4 in arithmetic capabilities   https://arxiv.org/abs/2305.14201
Rohit Aggarwal|2023-05-28 19:24:01|I somehow have a problem with benchmarks like these. Nobody anyway wants their LLM to do math for them. How does benchmarking on this help? You could even train a non-LLM on arithmetic and it’d perform better than GPT-3.5  </rant>
Abhishek Mishra|2023-05-28 19:27:52|Not really. It's a conversational AI with arithmetic capabilities better than GPT4. Without base mathematical abilities you wouldn't ever have a decent model useful in financial/academic research involving computations.
Nirant|2023-05-28 19:29:18|Rohit bhaiya, why we do the things we do at all?  Sometimes, it's just because we can
~ Mayank Jain|2023-05-28 19:29:57|‎~ Mayank Jain left
Rohit Aggarwal|2023-05-28 19:30:28|Using this to create decisive conclusions is usually counter productive no?
Nirant|2023-05-28 19:30:34|Agreed on this has little/no real world utility, but for kicks, amazing 😅
Nirant|2023-05-28 19:31:10|Absolutely. I think most astute readers get that this is indicative, not decisive or conclusive.
Rohit Aggarwal|2023-05-28 19:31:17|Yea - doing it to test / have fun is totally cool
~ Arka|2023-05-28 19:32:55|We might not be able to Black box distill GPT.  But OpenAI can still distill GPT
ashish Acgt01 Twitter|2023-05-28 19:39:27|https://twitter.com/shishirpatil_/status/1661780076277678082?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Aashay Sachdeva MPL Data Scientist|2023-05-28 19:52:41|Had read a lot of tweets/talks around this, specifically- https://twitter.com/abacaj/status/1649465635263356932?s=46  Glad someone actually did a paper on this
~ Ujjwal|2023-05-28 21:10:22|‎~ Ujjwal joined from the community
~ -Nobody😅|2023-05-28 21:16:57|‎~ -Nobody😅 joined using this group's invite link
Nirant|2023-05-28 21:46:49|Happy 3 year Anniversary to GPT-3 paper, which came out on May 28, 2020. The arXiv submission alone has >10K citations.   Gossip: The first author of this author is now at AnthropicAI.  https://arxiv.org/abs/2005.14165
Abhinav Verma Longshot.ai|2023-05-28 21:47:33|That and webgpt was the last paper where openai actually revealed something about their process
Abhinav Verma Longshot.ai|2023-05-28 21:47:41|Really pivotal paper
Ojasvi Yadav|2023-05-28 21:47:47|How much would his CTC be? What are AI salaries like generally in the west?
Abhinav Verma Longshot.ai|2023-05-28 21:51:37|His ctc would be in tax free gpu credits
Nirant|2023-05-28 21:52:27|And a protection from air strikes in case the loss drops? 🤣
Nirant|2023-05-28 21:53:31|(Sorry for encouraging off topic salary discussions/inside jokes, let's stop here)
Ojasvi Yadav|2023-05-28 21:53:45|Yeah I think this topic will be quite the buzz here. I'm just glad we're finally addressing the elephant in the room 🤣
Ojasvi Yadav|2023-05-28 21:56:44|Yesterday I posted this
Ojasvi Yadav|2023-05-28 21:56:56|https://twitter.com/dr_cintas/status/1662475320119656448?s=46&t=FvScmWlwJalkIndmUHhjjQ
Ojasvi Yadav|2023-05-28 21:57:12|Seems like agents loss curves have to be interpreted in their own way
Abhinav Verma Longshot.ai|2023-05-28 21:57:34|I thought we should stop so yudkowsky doesn't drone strike this group
Ojasvi Yadav|2023-05-28 21:57:59|Since loss function's are nowhere dependent on distance based metrics which are 99% of the loss function used
Ojasvi Yadav|2023-05-28 21:58:47|The loss metrics I used for my agent were completely based on a different reasoning
Ojasvi Yadav|2023-05-28 21:59:18|This will definitely become its own field of research
Rahul Sundar 2013|2023-05-28 22:01:16|I am quite curious about this!
Rahul Sundar 2013|2023-05-28 22:01:42|Even cross entropy based ones can be thought of as some sort of a distance metric in a probabilistic space..
Rahul Sundar 2013|2023-05-28 22:02:11|Is there some prior work which talk about loss formulations that are not directly/indirectly based on distance based metric
Rahul Sundar 2013|2023-05-28 22:02:14|?
Ojasvi Yadav|2023-05-28 22:02:36|Not just the loss
Ojasvi Yadav|2023-05-28 22:02:49|I actually created my own activation layer 😌
Rahul Sundar 2013|2023-05-28 22:03:16|Okay! That's interesting.. I do something similar for my SciML projects but nothing major..
Rahul Sundar 2013|2023-05-28 22:03:25|Ranking losses are there...
Ojasvi Yadav|2023-05-28 22:07:10|Nothing major this side either. Just that the standard final activation layers are not fundamentally optimised to the task at hand
~ Apurva Bhatt|2023-05-28 22:07:54|Ndcg is one of them if rank of each output matters
Rahul Sundar 2013|2023-05-28 22:09:29|Okay
Ojasvi Yadav|2023-05-28 22:09:30|Coming back to this. There is no baseline to compare the performance to.
Rahul Sundar 2013|2023-05-28 22:10:41|There is always a possibility of formulating a toy problem which can then be used to compare the existing and proposed one
Dev Aggarwal|2023-05-28 22:53:11|https://twitter.com/davidad/status/1662821792942022656?s=20  This is so weird. Can it be solved by better prompting? Heck, for tic tac toe you just give it the entire tree of board configurations in the prompt!
Nirant|2023-05-28 22:55:13|Cc [PHONE]
Sandeep Srinivasa RedCarpetup|2023-05-28 23:11:17|https://www.amazon.science/publications/web-scale-semantic-product-search-with-large-language-models
Nirant|2023-05-28 23:14:38|Do you want to add a line about why this is interesting to you?
~ Kp|2023-05-28 23:16:15|Using llms to surface mathematics from statement based problems and then using plug-ins which can do the actual symbolic mathematics might be better.
~ Kp|2023-05-28 23:16:16|Kind of like translating into the language of mathematics
Sandeep Srinivasa RedCarpetup|2023-05-28 23:17:08|It seems they are doing  semantic neighbor search (a vector db's traditional role) using LLM.
~ Ashish|2023-05-28 23:20:17|‎~ Ashish joined using this group's invite link
Dev Aggarwal|2023-05-28 23:24:13|Umm no - “At runtime, for every query entered by the customer, we compute the query embedding and then retrieve top K products using ANN search [4]. To serve traffic in realtime, we cache the product embed- dings and compute only the query embedding online.”
Sandeep Srinivasa RedCarpetup|2023-05-28 23:26:31|Ah ok. I think I misread the interpretation. Thanks for the correction
Sandeep Srinivasa RedCarpetup|2023-05-28 23:33:13|Actually I still think I'm correct. The paper seems to indicate the embeddings are part of the model and not separately stored. Am I wrong in this ?
Dev Aggarwal|2023-05-28 23:34:05|They use the embeddings to finetune a smaller model for faster realtime inference. Issues at amazon scale 😆
Rajeev Singh Naruka|2023-05-29 02:46:00|Hey everyone!  Wanted to share the generative agents implementation I was working on -   https://github.com/toughyear/generative-agents  with a demo here - https://demo.multimode.run/
Shimanta Generative AI|2023-05-29 03:00:16|This is amazing 🤩  How did you come about creating the environment, if you are able to share that?
Rajeev Singh Naruka|2023-05-29 03:18:34|The game env was created with Unity and then ported to Phaser gaming engine for web.
Aditya Shastri Shastri|2023-05-29 10:48:28|‎Aditya Shastri Shastri left
~ Arvind Sankar|2023-05-29 07:33:23|Interesting questions. My thoughts are as follows, but they may not necessarily be the most optimal approach to address this problems: a) and b) there is going to be some subjectivity involved at some point. For better explainability, there is a lot of emphasis given to Expert systems or systems for ontological/knowledge representation that is in essense just logic. Such systems would effectively try to decode law as objectively as possible (like if then functions). However, you would eventually have to make subjective or quantitative assessments at some point.  Ex- The law is clear as to tax rates applicable to chocolate and wafers. However, the subjective assessment one may need to encounter is whether KitKat is a chocolate or a wafer, and accordingly determine which tax rate is applicable (actual case btw). While expert systems may lead us to understand which laws are applicable, I think generative AI may be more suited for the later task.  I don't know what test metrics may be appropriate for this. As you rightly point out, the legal system mostly adversarial and there may be both information that helps or hurts your case.  For the moment, I want to move one step at a time. First see if LLMs can be used for generating and supporting arguments involving subjective assessments without hallucinating. And then later see how it criticize, counter and refine it's own arguments, again without making things up.  C) obviously it should be possible. Ideally it should be like legal text books where legal provisions are filled with extracts and citations of cases where judges explain what those legal provisions supposed to be mean and how they are applicable to the case
Abhishek Mishra|2023-05-29 08:09:23|This looks very interesting 😁
Adithya S K PESIT|2023-05-29 09:19:53|That's some really impressive work would love to contribute to it!
Kishore GenAI|2023-05-29 10:07:52|I kept track of how the copilot generates code for me after I saw this. My takeaway is if the function is very clear with variables either already defined, or present in similar functions, then the copilot generates from the beginning, else, it doesn't. If the copilot can't figure out what you are doing then it struggles.   My tip is to provide a comment on the line before to let it know what you are trying to code. Another thing which I figured out that, it works very well in bigger files with more lines of code, mostly cause some functionality is repeated. Eg, getObject1FromDatabase() and then if you write a function getObject2FromDatabase(), it ends up completing the entire function. It didn't however, complete it for getObject1FromDatabase().  Hope this helps
~ Kp|2023-05-29 10:50:03|Is this copilot X or github copilot?
Kishore GenAI|2023-05-29 10:50:22|GitHub copilot
~ Kp|2023-05-29 10:51:43|I see... currently github copilot is weaker than some vscode extensions in terms of code autocomplete if I'm not wrong.
Nirant|2023-05-29 11:01:24|Copilot is most definitely the best *free* code autocomplete out there. Most VSCode Extensions are often GPT3.5-Turbo wrappers — many ask for your keys, which is still okay.   The ones which don't, are just iffy (legally, can't use for anything, even FOSS) and slow
Nirant|2023-05-29 11:01:52|Copilot Chat or Copilot X is in beta and needs VS Code Nightly builds for some reason 🤷‍♂️
Kaushik Bokka|2023-05-29 11:02:45|so basically prompts as a service 😂
Kaushik Bokka|2023-05-29 11:04:02|https://codeium.com/ seen this a few times
~ Akshit Banta|2023-05-29 11:06:02|Have tried codeium (and a few more) it's not as good as copilot.
Aishwarya Goel Inferless 5s for 5G|2023-05-29 11:06:59|What about tabnine?
~ Akshit Banta|2023-05-29 11:08:24|Also, copilot chat is not as good as GPT4.  I'm currently using Copilot for simple code completions while GPT4 for a little more advanced code completions.  Let me know if anybody has a better solution.
Nirant|2023-05-29 11:08:25|Quite behind Copilot
Rajesh RS Generative AI WhatsApp Group|2023-05-29 11:08:34|Tabnine made a blip some time ago, I guess it is still good. Copilot is the pre-eminent tool at least in enterprises right now. Dunno about startups and smaller firms.
Rajesh RS Generative AI WhatsApp Group|2023-05-29 11:09:49|There was a lawsuit last Nov - Copilot seemed to suggest code found in some private repos. At least that's what I understand - not sure whether needle has moved
Abhishek Mishra|2023-05-29 11:09:52|None as good as copilot but codeium is one of the best free copilot alternatives out there that has chat option as well. This and Source graph Cody are very useful.   I don't know what model codeium is using right now but previously they used a variant of santacoder. Now we have better OSS codegen alternatives than that so don't know what they are using now.
Nirant|2023-05-29 11:09:53|Absolutely nothing is as GPT4.   More interesting: Most commercial tools are worse than the Replit Code, Meta's InCoder or the super powered StarCoder.
Nirant|2023-05-29 11:09:57|Atleast for Python
~ Shaunak|2023-05-29 11:10:23|‎~ Shaunak joined from the community
Prayank Swaroop Accel|2023-05-29 11:11:34|Folks is there any hack for getting GPT4 api access ?
Abhishek Mishra|2023-05-29 11:12:10|Increase your open AI gpt 3 bills, that's the only one i know of
~ Kifilshah|2023-05-29 11:24:30|Any idea how this compares to replit ghostwriter?
Kaushik Bokka|2023-05-29 11:26:08|Replit Head of ML mentioned they are planning to open source Ghostwriter if I am not wrong
Kaushik Bokka|2023-05-29 11:27:26|I could add my friend here to the group who worked on Ghostwriter
Aashay Sachdeva MPL Data Scientist|2023-05-29 11:29:06|Even databricks recommend to use this
~ Anjaly|2023-05-29 11:39:56|‎~ Anjaly joined using this group's invite link
~ SG|2023-05-29 11:39:57|‎~ SG joined using this group's invite link
~ Ansh Agarwal 👩🏽‍🚀|2023-05-29 11:40:13|‎~ Ansh Agarwal 👩🏽‍🚀 joined using this group's invite link
~ Shivam Bhotika|2023-05-29 11:42:13|‎~ Shivam Bhotika joined using this group's invite link
~ Aaryan Shah|2023-05-29 11:42:54|‎~ Aaryan Shah joined using this group's invite link
Anshul Bhide Replit|2023-05-29 11:46:00|Ghostwriter won’t be open sourced but Replit v1-3 LLM is open source under CC BY
~ Vaibhav|2023-05-29 12:01:40|Anyone here who has participated in a Hackathon recently and worked an open source project. Looking to collaborate with few techies for a Generative AI themed hackathon happening next week.
~ Sanjeed|2023-05-29 12:03:32|Generate 3D meshes and 360 degree videos from text.  https://twitter.com/genmoai/status/1661420716733104129?t=QIL1qd3RTsk9CmAjKe5JeA&s=19
~ xick|2023-05-29 12:16:28|‎~ xick joined from the community
The GenerativeAI Group|2023-05-29 12:25:03|‎You turned on admin approval to join this group
Anandamoy RoyChowdhary Sequoia|2023-05-29 12:26:43|Very good
Vaibhav Bhargava Meesho Grab |2023-05-29 13:58:10|[PHONE] are you taking about the Stellaris one? Some people above were interested - [PHONE] [PHONE] [PHONE]
~ Vaibhav|2023-05-29 14:21:15|Yes thanks will DM them
~ S S|2023-05-29 14:29:35|Which hackathon is this? Could you share the link?
~ keith|2023-05-29 14:51:02|Yessir im going
~ keith|2023-05-29 14:51:52|it's the stellaris one  I think this is the link https://joinef.info/41Ye9kg
~ Ansh Agarwal 👩🏽‍🚀|2023-05-29 15:22:08|there is one happening in mumbai this weekend as well
Swastik Banerjee|2023-05-29 15:24:01|can we have a plugins hackathon like the SF one for people who have Plugins access?
~ keith|2023-05-29 15:26:39|oh interesting, could you share the link to that?
Nirant|2023-05-29 15:26:55|mumbaihacks.com
~ Ansh Agarwal 👩🏽‍🚀|2023-05-29 15:28:07|https://twitter.com/mumbai_tech_/status/1659198245984419840?s=20 ‎[5/29/23, 15:45:18] ~ Santhosh K: ‎image omitted
Abhishek Mishra|2023-05-29 15:55:58|Outlier features are indeed being handled with 16 bit mat multiplication
Abhishek Mishra|2023-05-29 15:56:23|But the paper specifically mentions that these features are only 0.1% of total features
Abhishek Mishra|2023-05-29 15:56:43|this decomposition operation only consumes about 0.1% additional memory. Therefore, it doesn't defeat the purpose of using lower precision computations to save memory.
~ Santhosh K|2023-05-29 15:57:01|Yeah when we maintain W in half precision and int8 both aren't we doubling the memory
Abhishek Mishra|2023-05-29 15:59:29|The outlier part is never handled via 8bit but remains 16 bit. But since the outlier features are very small as per this paper (https://arxiv.org/abs/2208.07339) it doesn't make performance difference. But your question was valid and it will be an issue in scenarios where you are dealing with huge number of outliers which I have not considered in detail before.
Sudharshan GenAI|2023-05-29 16:05:38|https://revoicer.com  Emotion based text to speech. What models do you folks think this product is using under the hood?
~ Santhosh K|2023-05-29 16:30:51|I got the answer..all the matrices are int8 quantised and they also keep track of scale factor needed for each Matrix to dequantise. For outlier features we first dequantise the int8 Matrix and do multiplication. For non outlier features we do quantised multiplication and dequantise the result ..now both of them are added to get final output.
~ Mimansa|2023-05-29 17:09:57|‎~ Mimansa requested to join
~ Nikhilesh Jha|2023-05-29 17:11:54|Is anyone aware of an open source/free ML tool that analyses voice and categorises it as monotonous, too many fillers, too many pauses, engaging, exciting, etc?
Rajesh RS Generative AI WhatsApp Group|2023-05-29 17:13:03|If anyone knows of speech pathology identification tools using ML - such as vocal fry identifiers, I’d be interested in knowing as well
~ Nandhini|2023-05-29 17:19:33|‎~ Nandhini requested to join
~ Shivani|2023-05-29 17:23:51|‎~ Shivani requested to join
~ Manasi|2023-05-29 17:24:52|‎~ Manasi requested to join
~ Harshita|2023-05-29 17:27:40|‎~ Harshita requested to join
~ Kritica|2023-05-29 17:53:15|‎~ Kritica requested to join
Shashank Generative AI Group|2023-05-29 18:00:25|"hey folks, i had a bunch of noob doubts around embeddings. I am making a Matchmaking project based on Readwise highlights (from books, blogs, tweets) of users. will take 100-200 highlights (text chunks) of a user.  1. after embedding highlights of a user, what's the best way to generate a user_embedding (to compare with other user embeddings). I read that highlights could be averaged to get a single user profile embedding. is this fine or are there other ways?  2. also, what's InstructorXL (768 dimensions) performance vs OpenAI (1536). main question: does no. of dimensions matter a lot compared to other factors like the model itself? i get that more dimensions mean that more info is there, more storage required etc.  3. i know there's the MTEB leaderboard. but let's say i want to compare InstructorXL, openai ada, sbert for my task; how should i go about it? i've used ada in the past. not the other two. im actually not sure about this question. feel free to ignore lol. i just want to try out 2-3 models for this project and understand the differences in speed, perf etc.  4. when do people still use models like ""all-mpnet-base-v2""? the HuggingFace blog mentions that it's a ""good balance between speed and performance"". 5. when does finetuning embeddings make sense? anyone here doing that?  Q. 4,5 are not that relevant to my small project; im just curious, trying to fill in some gaps.  Links for models i mentioned: - instructorXL: https://huggingface.co/hkunlp/instructor-xl - sbert: https://www.sbert.net/ - all-mpnet: https://huggingface.co/sentence-transformers/all-mpnet-base-v2  thanks."
~ Anjali Khandelwal|2023-05-29 18:01:58|‎~ Anjali Khandelwal requested to join ‎[5/29/23, 18:08:48] Nirant: ‎image omitted
Nirant|2023-05-29 18:15:20|"Re: #1, in addition to averaging here are few general methods for combining embeddings:   1. Concat → Simple, Straightforward, extremely useful for features like ""We're recommending you X because you liked Y"" 2. Linear layers over embed concat → Useful when you've some way to calculate a loss e.g. user similarity from other methods. Helps you combine K embeddings of K highlights into one embedding too! 3. Expanding on #2 above, you can actually feed the K X V (where K is the number of embeddings and V is the vector dim), into a neural network and attend, conv, linear or any other combination to get a 1 X V final resultant across users.  #3 is a common trick I've heard from Kagglers and industry folks, but you need some way to calculate a loss which you can back prop over"
Dev Aggarwal|2023-05-29 18:22:57|There’s this unique challenge in matchmaking - you can’t just get the top-k results from a vector search and call that your top matches.   You also need to consider that the top-k results for a user, might not have that user in their top-k, resulting in a suboptimal match. i.e. you need to consider the bidirectional mapping / distance.  The easiest way I’ve found (that doesn’t scale) is to do a matmul over the entire embeddings of all users, giving you a nice distance matrix that you can then run classical graph/tree/clustering algorithms over.  We recently used a min spanning tree to project this at the generative ai meetup - http://ai-matchmaker.us-1.gooey.ai
~ Neha|2023-05-29 18:27:24|‎~ Neha requested to join
~ Chandan|2023-05-29 18:27:55|‎~ Chandan requested to join
Paras Chopra Wingify|2023-05-29 18:36:39|Can you elaborate on matmul part?  How would the resultant matrix be different from averaging embedding top-k matches
Shobhankita Speciale Invest|2023-05-29 18:36:57|‎Shobhankita Speciale Invest requested to join
Dev Aggarwal|2023-05-29 18:47:55|The matmul is just a quick and easy way to get a nice distance matrix. But yes, same operation mathematically. The important part is that you have some way to factor in the reverse relationship too.  A tinder match is only good if the other person likes you as much as you like them 😆  Code is open source btw - https://github.com/devxpy/ai-matchmaker/blob/be101578f3409bbd4598124d9d0f6b89758fb57b/app.py#L232
Dev Aggarwal|2023-05-29 18:59:35|And embedding search is still very much a fuzzy similarity score. For real world I think you need something like amazon’s recent paper on finetuned embeddings on a particular dataset, or a quick hack to just feed the matches into gpt-4 and ask for scores based on some explicitly illustrated criteria in prompt.  Eg see - https://twitter.com/jobergum/status/1656201261308321792
Paras Chopra Wingify|2023-05-29 19:03:42|Yeah so you probably average the distance
Dev Aggarwal|2023-05-29 19:08:04|The leaderboard seems to have a litter of tasks you can eval against - https://github.com/embeddings-benchmark/mteb#available-tasks
Nirant|2023-05-29 19:09:10|IISc PhD Students get their Canadian VISAs rejected, despite CVPR Paper selections.  https://twitter.com/val_iisc/status/1662801516934361094
Aashay Sachdeva MPL Data Scientist|2023-05-29 19:10:07|This must be heart breaking. Getting rejected from canada of all places..
~ Shaarang|2023-05-29 19:15:30|‎You removed ~ Shaarang
Rahul Sundar 2013|2023-05-29 19:22:53|This is too sad! Anything related to AI on resume seems to switch on a red alert of sorts in their heads.. 🥲
Nirant|2023-05-29 19:23:38|But why'd this be the case? If anything, they should want IISc folks, right?
Rahul Sundar 2013|2023-05-29 19:24:18|This was the case earlier with Aerospace degree holders/researchers
Rahul Sundar 2013|2023-05-29 19:24:24|Now AI..nothing different ‎[5/29/23, 19:27:34] ~ Arjun: ‎image omitted
ashish Acgt01 Twitter|2023-05-29 19:28:59|And i bet lots of students from India go to Mila and  lots of Canadian universities every year. Conference was reputed, iisc is reputed  Really seems like some over zealous visa officer
Shalabh Aspiro|2023-05-29 19:30:20|I used https://github.com/Shahabks/myprosody a couple of years back. Not very good for serious usecases and you might need to modify the source code a bit for your needs. But a decent library considering I couldn't find anything else
Nirant|2023-05-29 19:31:23|This is fantastic for the zero-sum mindset in me. More talent will stay back in India because of this news going wide 🤣
Pratyush Choudhury|2023-05-29 19:36:31|Mila and UToronto are two of the very best for sure
Rahul Sundar 2013|2023-05-29 19:37:06|I thought Canada was welcoming towards International students / tourists/ job seekers
ashish Acgt01 Twitter|2023-05-29 19:43:31|I hope in the next decade, India hosts more prestigious  conferences - ai (neurips, icml, iclr) & non-ai  The centre of gravity of most conferences is the west given that most presenters & organizers are from the US , Canada & Europe.
Rahul Sundar 2013|2023-05-29 19:46:35|Quite possible! The Indian academic mindset should also shift from journal publication oriented approach to more prestigious conference proceedings + open review approach
Yash Pandya|2023-05-29 19:46:37|There were others (not students) who faced similar problems - https://twitter.com/RisingSayak/status/1663102361752186880?s=20
Rahul Sundar 2013|2023-05-29 19:46:54|This has been happening for quite a few years atleast with the US. ‎[5/29/23, 19:48:26] Rahul Sundar 2013: tal.pdf • ‎6 pages ‎document omitted
Yash Pandya|2023-05-29 19:48:28|I thought Canada would be more welcoming, especially for attendees of major conferences such as CVPR.
Rahul Sundar 2013|2023-05-29 19:48:42|'Drone', 'AI', 'chemistry', 'nuclear' , 'aerospace', 'aerofoil' etc are some key words always attracted pink slips or straight rejections
Rahul Sundar 2013|2023-05-29 19:48:57|Yea! I guessed so
Rahul Sundar 2013|2023-05-29 19:49:23|Is their job market saturating/stagnating because of the recession?
Yash Pandya|2023-05-29 19:50:06|But if that is the case then you should reject work visas 😅
Rahul Sundar 2013|2023-05-29 19:50:15|https://blog.y-axis.com/jobs-outlook-in-canada-for-2023/
Rahul Sundar 2013|2023-05-29 19:50:19|Yea!! Exactly
Rahul Sundar 2013|2023-05-29 19:50:30|But that doesn't seem to be the case :p
Shashank Generative AI Group|2023-05-29 19:57:26|thanks for the tips, will check out ai matchmaker repo as well 👍
Shashank Generative AI Group|2023-05-29 19:58:01|thanks! will try these out
~ Nikhilesh Jha|2023-05-29 20:00:09|Thanks, [PHONE]
Dev Aggarwal|2023-05-29 20:37:18|This is for how many vectors?
Nirant|2023-05-29 21:03:50|All configs, code are from ann-benchmarks.com
Gokul Krishnan|2023-05-29 22:05:58|Unfortunately, this is nothing new. Happens every year as one of ICML/ICLR/NeuRIPS happens in Canada. 😕  ICLR tries to combat this by moving to Kigali but that brought up more issues around the safety of  LGBT members of the community.  Going to say somewhere outside of North America puts Iranian students in the US in a tough spot as they can't come back inside the US easily due to their visa issues.
Prayank Swaroop Accel|2023-05-29 22:45:18|Has anyone tried any local LLMs on Apple M1 macs ? GPT4LL snoozy model has very slow inference for me. Any suggestions for faster ones ?
Abhishek Mishra|2023-05-29 22:47:13|Yeah, playing with almost all of the decent ones on M2 pro
Abhishek Mishra|2023-05-29 22:48:12|Are you running this via GPT4all Mac app, try mpt 7B?
Prayank Swaroop Accel|2023-05-29 22:53:27|I'm using a Jupyter notebook and using langchain.  Let me try mpt7B.
Anubhav mishra Zupay|2023-05-29 22:54:03|PrivateGPT
Anubhav mishra Zupay|2023-05-29 22:54:20|Check it out , it's available and setup is also easy
Abhishek Mishra|2023-05-29 22:58:14|Yeah it is good with external docs as well. just that it gets slowed down a lot with increasing number of threads. Still haven't gotten around using the langchain support on this but I love this project.
Anubhav mishra Zupay|2023-05-29 22:59:01|I think he has updated his repo , as he also launched it on product hunt , haven't tried the new one yet
Anubhav mishra Zupay|2023-05-29 22:59:34|You can also have a look at this   https://kevinchen.co/blog/rewind-ai-app-teardown/#how-it-works-overview
Anubhav mishra Zupay|2023-05-29 23:00:08|It's a product tear down of rewind might help check how they have integrated locally
~ Mridul Joshi|2023-05-29 23:41:47|‎~ Mridul Joshi requested to join
~ Uma|2023-05-30 00:24:27|‎~ Uma requested to join
~ Ashutosh|2023-05-30 00:42:23|‎~ Ashutosh left
Adithya S K PESIT|2023-05-30 00:55:44|I have been facing some issue with setting up the falcon model on sagemaker ,mainly dependency issues can you guys suggest which image and instance type I should use
Akash Chandran|2023-05-30 01:09:42|I'm running it on a100 80G
Akash Chandran|2023-05-30 01:09:44|responses are decent
Akash Chandran|2023-05-30 01:09:49|Enter your text: what is technical innovation institute UAE Setting `pad_token_id` to `eos_token_id`:11 for open-end generation. Result: what is technical innovation institute UAE The Technical Innovation Institute in the United Arab Emirates (UAE) is a government-owned institute that provides education, training and research in fields such as engineering, energy, transportation, communication, and information technology. Enter your text:
Akash Chandran|2023-05-30 01:10:00|This is the 40B instruct chat model
Akash Chandran|2023-05-30 01:10:19|what issues you facing :)
Adithya S K PESIT|2023-05-30 01:19:47|got it working
~ AG|2023-05-30 07:37:53|‎~ AG requested to join
Kartik Mandaville|2023-05-30 10:28:43|Seeing a clear decrease in quality after we added more connectors (ie Slack, Notion, Jira etc - more connectors means more data, same type of data being repeated, all unstructured) - some things which we are exploring - adding more meta data(doc name etc) to each chunk, query routing (what type of query is it? should it be broken down?), asking LLM to hallucinate before doing a search. Has anyone worked on something like this? wants to brainstorm?  (Context - I run Albus (conversational search across all your tools) - doing around 2K queries a day)
Aashay Sachdeva MPL Data Scientist|2023-05-30 10:33:25|Have you seen this by llama index creator?  https://twitter.com/jerryjliu0/status/1659581693748191233?s=46
Vedant Trivedi Sequoia|2023-05-30 10:42:27|Can Branch help?   [PHONE]
Alok Bishoyi|2023-05-30 10:44:52|Has anyone here worked on generating training sets ( preferably on coding data sets ) through GPT4 or other powerful models and then used it to finetune OSS ones ?
Bharat Singh|2023-05-30 11:15:52|‎You added Bharat Singh
Yash Pandya|2023-05-30 11:52:49|Nvidia announced a new DGX system with 100TB GPU memory   https://t.co/M3Y4P074de
Nilesh Agarwal Inferless|2023-05-30 11:53:53|Wow
Ciyunni|2023-05-30 12:05:27|‎You added Ciyunni
The GenerativeAI Group|2023-05-30 12:06:47|‎Kaushik Bokka added Aditi Chopra and ~ Neeraj
Deep Samsung R&D|2023-05-30 12:22:35|Looking for a good Video based Interactive Python course for a begineer, fastai one could be difficult to go, any suggestions?
Rajesh RS Generative AI WhatsApp Group|2023-05-30 12:24:48|I came across this really nice one by Sanjeev Thyagarajan on YouTube/FreeCodeCamp. Worth checking out despite its considerable length. https://youtu.be/0sOvCWFmrtA
~ Sahir Patel|2023-05-30 12:36:59|Hey everyone!  I've been exploring various text-to-speech models for Indic languages, and so far, I've tried Meta's multilingual model ( https://github.com/facebookresearch/fairseq/tree/main/examples/mms) which gave me an average output for Hindi.  I also gave Bark (https://github.com/suno-ai/bark) a shot, and it performed slightly better.  However, Elevenlabs provided the best results for me, unfortunately it's not open-source. Do you have any other recommendations or leads for high-quality Indic language TTS models? Additionally, if anyone has experience with the Meta model, could you please share your thoughts on enhancing its output quality.
~ Pradeep Ayyagari|2023-05-30 12:38:18|Do you have any specific usecase in mind or are you just exploring ?
~ Soura|2023-05-30 12:39:34|‎~ Soura requested to join
Swastik Banerjee|2023-05-30 12:43:32|vakyansh , suggested to me previously by [PHONE]  P good
~ Sahir Patel|2023-05-30 12:43:51|yes it's for product advertisements. The current outputs are quite monotone . sharing the meta outputs ‎[5/30/23, 12:43:53] ~ Sahir Patel: ‎audio omitted
Swastik Banerjee|2023-05-30 12:44:26|https://github.com/Open-Speech-EkStep/vakyansh-models
Swastik Banerjee|2023-05-30 12:45:33|For TTS, OpenAI Whisper?
~ Sahir Patel|2023-05-30 12:46:11|Thanks [PHONE]  will try this out
~ Sahir Patel|2023-05-30 12:47:41|yep . I'm yet to compare the results between whisper and meta mms , esp for indic . will share it here
Swastik Banerjee|2023-05-30 12:48:13|this is STT though
Swastik Banerjee|2023-05-30 12:48:25|sorry I had misread earlier
~ Sahir Patel|2023-05-30 12:50:42|np , just saw vakyansh has TTS too . https://github.com/Open-Speech-EkStep/vakyansh-tts
~ Apurva Bhatt|2023-05-30 12:53:43|Vakyansh has build great models, I have personally used them
~ Apurva Bhatt|2023-05-30 12:53:50|Gives great results
Swastik Banerjee|2023-05-30 12:55:33|Whisper is pretty bad though, from personal experiences. ```pyttsx3``` was working better for me at times, lmao
~ Sahir Patel|2023-05-30 12:56:04|nice, what did you use it for?
~ Apurva Bhatt|2023-05-30 12:56:35|classification
Sudharshan GenAI|2023-05-30 13:24:13|Any hackathons happening soon?
Ravi Theja|2023-05-30 13:30:58|https://www.mumbaihacks.com/ - this weekend in Mumbai  https://lu.ma/ucd44q8e - June 10th in Bangalore
Swastik Banerjee|2023-05-30 13:32:59|Me and [PHONE] were talking in the last meetup if any other similarity metric other than Cosine similarity could potentially give better results. He was of the opinion that it wouldn’t matter much unless for specific usecases.  Anyone has tried any other similarity metric and got better results?
Swastik Banerjee|2023-05-30 13:34:43|Also, was wondering if anyone has tried hybrid search mechanisms yet (bm25 + embeddings) : not one after another as a fallback, but together
Sumod K Mohan|2023-05-30 13:42:35|My take is slightly more nuanced, sorry if this was not clear. Simple 1-1 similarity metrics like Cosine, SAD, SSD etc won't matter much except for specific use cases. There are problems that can't be solved using just distances alone (selective attention mechanisms: Where you use completions etc, more powerful search algo like hierarchical representations etc), these are different class altogether.
Shubham Sharma 2012C6|2023-05-30 13:43:07|Anyone want to team up for the generative AI track in mumbai? Please DM! Would love to jam and collaborate!
Swastik Banerjee|2023-05-30 13:43:25|right right correct
Raghotham Paypal Bargava's Friend|2023-05-30 14:05:34|We at PayPal use Hybrid search for our Enterprise Search which powers a lot of use cases - consumer help, merchant help, dev experience, intranet articles, etc.
Raghotham Paypal Bargava's Friend|2023-05-30 14:06:15|I think that should be the standard. Pure neural search performs badly in a lot of use cases.
Raghotham Paypal Bargava's Friend|2023-05-30 14:06:55|We use bm25 + neural search + things like doc2query  https://www.linkedin.com/posts/soujanya-lanka-11b99a_informationretrieval-search-doc2query-activity-7052247552376651776-V5Xi
Sumod K Mohan|2023-05-30 14:07:07|Have too used hybrid quite a few times.
Sumod K Mohan|2023-05-30 14:09:45|This is fairly common. You often have specific keywords that needs to be matched like tags, categories etc, in such cases regular search is really good.
Raghotham Paypal Bargava's Friend|2023-05-30 14:10:39|And the secret sauce is also the re-ranker across such indexes.
Ojasvi Yadav|2023-05-30 14:23:14|Is the re-ranking done in a user-personalized way or based on something else?
Sandeep Srinivasa RedCarpetup|2023-05-30 14:24:15|this is very interesting. this is much like generating metadata for each document and using that for embeddings.  but how do u combine bm25 and embeddings ? do u use the elasticsearch inbuilt method to use dense vector rankings with bm25 rankings ? or do u use separate vector db and search db and interleave them (which is something i havent been able to figure out)
Ojasvi Yadav|2023-05-30 14:26:32|I thought the best way to combine embeddings with text in search was to use the 'boost' functionality in ElasticSearch
Ojasvi Yadav|2023-05-30 14:26:55|Let's you weigh disparate input signals
Sandeep Srinivasa RedCarpetup|2023-05-30 14:27:07|exactly. i was thinking the same thing. unless u are using two separate db here..in which case i dont know how to do it
Ojasvi Yadav|2023-05-30 14:27:19|We use this at dukaan to compute similar-products.
Raghotham Paypal Bargava's Friend|2023-05-30 14:32:58|We have a long journey. We started off with bm25 and faiss. Now we have dense vectors in elastic itself.
Raghotham Paypal Bargava's Friend|2023-05-30 14:33:12|But still, we continue to use our custom re-ranker for final results
Sandeep Srinivasa RedCarpetup|2023-05-30 14:33:43|but just curious - how does ur custom reranker combine the output of faiss and Elastic-bm25. in memory ?
Sumod K Mohan|2023-05-30 14:34:17|Yeah, like Ragotham said too deep and some NDAs. There are many ways to combine and depends on problems. Example to flavour: think Math equations, Chemistry equations etc. You will need different distance functions (say you want similar quadratic equations), modifications to rankers etc. Many ways to do this, we have written custom rankers, distance functions etc in Solr/Lucene. Can't talk more unfortunately.
Sandeep Srinivasa RedCarpetup|2023-05-30 14:34:41|ah ok. no probs. thanks for mentioning anyway 🙏
Nishant Apne-App GenAI Hackathon|2023-05-30 14:35:24|There was a post by Karpathy on Twitter where he compared nearest neighbour vs SVM. SVM one is an interesting approach as it weighs the dimensions according to dataset, rather than giving equal importance to each dimension as in cosine sim  Can try if latency isn't an issue
Raghotham Paypal Bargava's Friend|2023-05-30 14:35:26|There are various ways to do it. Think of it as results coming from various sources and you need to rank them. One Can start with simple weights as re-ranker or go full blown learning the weights as well.
~ Happy Chaudhury|2023-05-30 14:35:34|Just curious how it performs , i am trying with faiss
Sumod K Mohan|2023-05-30 14:36:12|And funny thing is sometimes, it is just prodding the user right or providing UI mechanisms for user to nudge us correctly.
Ojasvi Yadav|2023-05-30 14:36:49|The benefit of KNN/ANN is that you can get **good-enough** performance with 0 downtime  SVM might be more accurate, but it needs to be trained all-over again if it has to index something.
Raghotham Paypal Bargava's Friend|2023-05-30 14:36:57|Works well. Can't scale as orchestration is a pain. And when you say enterprise search, it is more like search as a service for the org. So, needs better tools / frameworks like full feature vector db
~ Happy Chaudhury|2023-05-30 14:37:52|Will try it with bm25
Sumod K Mohan|2023-05-30 14:42:04|It needs to be trained for each query !! (or cached) Haha.. That was the context of this discussion.
Sumod K Mohan|2023-05-30 14:43:46|Yeah, the SVM idea as he mentioned is not for enterprise scale. It gives better accuracy for small scale data.
Sandeep Srinivasa RedCarpetup|2023-05-30 14:44:30|actually im a big believer in the composite ranking that you did. and that belief goes hand in hand with infrastructure tie in.  this kind of combined rankings (ranking+embedding or freshness/recency + embedding)  is very strongly tied to infra and is hard to pull off outside it. have been having a side conversation on this as well with some people here !
Sumod K Mohan|2023-05-30 14:56:21|Check our the recys paper that [PHONE] had posted. It's a slightly terribly written paper but will give you ideas on how TikTok is mixing some of these. There are enough details. For them, freshness can be what is trending video in last 30 mins !!
Sumod K Mohan|2023-05-30 14:58:23|*out
Paras Chopra Wingify|2023-05-30 15:00:34|i'll be honest - i didn't understand how SVM had a better performance than KNN.  the insight that KNN weighs all dimensions equally was very good, but i didn tget how SVM sidesteps it
Lalit Pagaria|2023-05-30 15:00:45|Just curious how any pre-trained cross encoder will perform?
Abhishek Mishra|2023-05-30 15:10:25|So in this case, karpathy argued that SVM cares for the unique aspects of your data more and hence better accuracy. Knn is computationally better but fails to preserve unique cases   https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
Paras Chopra Wingify|2023-05-30 15:14:12|yeah, saw that. but didnt get it fully, maybe need to read more
Soumendra Dhanee|2023-05-30 15:42:55|SVM will typically have better performance than KNN because it's mathematically guaranteed to be a strong learner. KNN has the desirable property of being very fast for retrieval inference, so it gets used everywhere. Karpathy had a small, fixed dataset, so inference speed wasn't as issue (wasn't needed), and SVM did better.
Soumendra Dhanee|2023-05-30 15:43:41|Any strong learner (like boosted trees from xgboost or lightgbm) would have done better than KNN
Paras Chopra Wingify|2023-05-30 15:47:03|but what is the ground turth on which learning is happening?  we use knns because all we have is dimensions but we don't know actual clusters, if we know clusters then we can use strong learners. but in case all you have embeddings, where is the ground truth coming from?  maybe im confused.
Abhinav Verma Longshot.ai|2023-05-30 15:48:45|I share the confusion. There are no labels here
Soumendra Dhanee|2023-05-30 15:51:38|😂 that's the beautiful thing about his example
Soumendra Dhanee|2023-05-30 15:52:00|We have ground truth: the query is identical to itself
Soumendra Dhanee|2023-05-30 15:52:44|Everything else is not. The embeddings are assumed to be semantic ones, so the trained model works out for this small dataset
Dhruv Anand|2023-05-30 15:53:51|but isn't that what classical machine learning is all about? Expecting future data to follow the same distribution as past data
Soumendra Dhanee|2023-05-30 15:54:19|I don't understand the question
Dhruv Anand|2023-05-30 15:55:06|like, it's not just about the example. For any real world problem, that approach would work well, as long as you continue to use the classifier in the same domain
Yash Pandya|2023-05-30 15:58:13|https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
Soumendra Dhanee|2023-05-30 15:58:19|Yes yes, if you convert a problem to ground truth carefully, strong learners will blow away the competition (I use strong learners in the sense of Vapnik's learning theory, which motivated SVM, boosted trees etc)
Yash Pandya|2023-05-30 15:58:20|This has all the answers
Yash Pandya|2023-05-30 15:59:25|You take the query as the only one in it's class, all the others are in the other class. Then you train the SVM using this as the ground truth.
Soumendra Dhanee|2023-05-30 16:01:41|We had to invent the entire domain of time series modelling because of autoregression. But if you build your features carefully to take care of autoregression, traditional ml does better than time series methods
Soumendra Dhanee|2023-05-30 16:02:25|Traditional ml includes NN for tabular data, btw, as those are strong learners too
Dhruv Anand|2023-05-30 16:10:51|right
Rajesh RS Generative AI WhatsApp Group|2023-05-30 16:16:44|I remember a project from a couple of years ago where ARIMA/SARIMA class models routinely did better at time series forecasting than deep learning models. I can vouch for good feature engineering + logistic regr for a text classification use case being better than an LLM with prompt engineering and all the jazz - in a specific area, limited or smaller models can work very well.
Sumod K Mohan|2023-05-30 16:18:53|In KNN, you look at k neighbors using some distance metric. Here the assumption being k and distance function being right for the data. Imagine a case where each position of your embedding direction is in different range and scales differently. Thus a simple Euclidean, L1 might not be good. Typically circa when people did PCA or other features etc, they would normalise the vectors to avoid this.
Ojasvi Yadav|2023-05-30 16:20:57|Though I imagine normalization is only viable if you are going to get your embeddings from 1 model and that alone?
Ojasvi Yadav|2023-05-30 16:21:22|Going to be a mumbo-jumbo that were to happen across different source-models :P
Sumod K Mohan|2023-05-30 16:24:46|Minor corrections, so edited both above. It's hard to be accurate on WhatsApp, when typing furiously on phone :).  Here you are fitting a hyperplane with your item on one side and all others on other side. The hyperplane is fit considering the global structure and the decision output from notebook can be thought of distance of points from this hyperplane. There are nuances like you need to divide by w to get actual distance, this is the probabilistic interpretation version, Platt's 1999 paper (not the SMO paper).
Sumod K Mohan|2023-05-30 16:25:11|You normalize over columns and not rows.
Sumod K Mohan|2023-05-30 16:25:52|This is what people used to do before.
Ojasvi Yadav|2023-05-30 16:34:10|But that would make inference necessarily complex, no?  In this KNN configuration, I have to look for matches in an index that is built by 2 or more embedding sources. So at inference time, I need to fetch embeddings of the search-input from all those models, and then be in a position to find matches.
Ojasvi Yadav|2023-05-30 16:35:13|Without embeddings from all the embedding-sources using which the index was built, no inference can work reliably
Ojasvi Yadav|2023-05-30 16:43:41|actually....
Ojasvi Yadav|2023-05-30 16:43:51|If you were to store your min,max,mean values for all the normalization operations
Ojasvi Yadav|2023-05-30 16:44:12|you can re-use them on the embedding, if you know the embedding-source, which you probably would do
Ojasvi Yadav|2023-05-30 16:44:38|this can then work
Sumod K Mohan|2023-05-30 16:45:11|I was still talking about the old style. Yes, for multi modal one way is to normalise them across columns for each modality. I think the more prefered one, I have heard is to normalise across rows, so sums to one for each modality. Thus both vectors are equally weighted. In this case cosine will be same as dot product.
Sumod K Mohan|2023-05-30 16:45:17|Let's take it offline now.
Ojasvi Yadav|2023-05-30 16:46:41|On a tangent, are there any product-folks here who might have worked closely with AI features?
Ojasvi Yadav|2023-05-30 16:49:14|I have a question, I'll keep it open-ended.  Why did YouTube ditch their approach of suggesting similar videos beneath a video? The suggestions beneath videos these days are just videos I've already seen, and might want to see again.  Talking in the technical Rec-Sys terms, why would YouTube choke away Novelty and Churn like this?
Paras Chopra Wingify|2023-05-30 16:51:04|their goal is maximizing view time on platform (as that drives monetization), so in their A/B test, this would have worked
Ojasvi Yadav|2023-05-30 16:53:01|And what kind of reasoning does a AI Product team use to decide if they should replace a feature or give it as an alternative option?
Ojasvi Yadav|2023-05-30 16:54:01|Because there is an argument always to let the user tune these hyper-parameters
Ojasvi Yadav|2023-05-30 16:54:21|to their own liking
Shan|2023-05-30 17:01:01|my understanding is that this is some sort of A/B test and you're in some other bucket. I'm seeing a variety of similar videoes not just the ones I've already seen. ‎[5/30/23, 17:05:16] ~ Abhilash K Pai: ‎image omitted
~ Santhosh K|2023-05-30 17:12:12|https://huggingface.co/decapoda-research  Anyone know are these the original weights from meta? Has anyone used this?
~ Arko Cy|2023-05-30 17:13:36|"In general - To match their attempt at User Profiling to predicting what maximizes engagement / consumption time  In context of question - A possible scenario could be ""are folks willing to go back to their watch history those videos are reminded in recos"" -or- ""what % of users are willing to dig back in their search history to revisit similar/ antecedent videos"".  In both the A/Bs, it's to be understood that the video you've just watched is an outcome of a sequence of recommendation algos based on watch, browse, share, abandonment history. If YT decides to update the params for video content & filter types, it may need to revisit the ancestral data to re-establish the reco videos & broaden the space to run experiments on user-taste. (probably also trace user-behavioral transition)"
Ojasvi Yadav|2023-05-30 17:19:02|Beautifully explained. This is a gem.
Ojasvi Yadav|2023-05-30 17:19:36|Rec sys is almost entirely about being able to model the human brain
~ Arko Cy|2023-05-30 17:22:50|Absolutely. And maturing the rec sys almost comes down to about generating a space where the sys can atleast mirror ( if not predict) the transition of human behaviour when exposed to matching / disparate data_types
Puneet Lamba Aspiro|2023-05-30 17:27:21|Guys, any Vellum AI alternatives for prompt engg. you guys have been using? (preferably something that's more affordable and easily usable by product teams like how Vellum is)
Rajesh RS Generative AI WhatsApp Group|2023-05-30 17:32:10|Spellbook, StackAI and Humanloop seem to be three in the space. Haven't used or evaluated them though
Saurav Akaike|2023-05-30 18:50:47|Have you used humanloop's product? Been trying to evaluate it but haven't gotten the access yet.
Aashay Sachdeva MPL Data Scientist|2023-05-30 18:53:10|[PHONE] is building portkey.ai
Rohan Manchanda|2023-05-30 18:57:30|Hey Friends. Wanted to check if you had come across a set of 10-15 mins videos on YT to learn about practical applications for langchain  I stumbled upon Greg Kamradt’s YouTube tutorial video series. They are quite good because he is alll about practical applications of langchain and how you can build on top.  So I wanted to check what are more such video series on langchain, if you’ve come across 🙏🏻
Abhinav Verma Longshot.ai|2023-05-30 18:59:09|The langchain handbook by pinecone
Paras Chopra Wingify|2023-05-30 18:59:10|What’s your use case?
Kartik Mandaville|2023-05-30 19:03:49|+1 for portkey. We evaluated humanloop, promptlayer, promtbase? and some others but landed on portkey
Rohan Manchanda|2023-05-30 19:03:58|Building an internal sales assistant to better prep sales reps for calls
Rohan Manchanda|2023-05-30 19:04:51|I have a lot of pdfs and sales enablement materials and now I want a chat with them
Aashay Sachdeva MPL Data Scientist|2023-05-30 19:05:42|How will human loop help here exactly?
Aashay Sachdeva MPL Data Scientist|2023-05-30 19:06:08|They are for prompt management, A/B testing prompt, getting feedback
Rohan Manchanda|2023-05-30 19:09:34|Sorry I don’t understand what this means. Wanting to make it easier for our sales team to retrieve. No need for a loop or feedback but i maybe wrong. Only case is summarisd retrieval. And no resources to execute (half a back endor no $$ to buy anything so trying to learn how to do this on my own
~ bhanu.io|2023-05-30 19:13:45|something like https://www.chatdox.com/ would be useful for this. I believe there are some open source solutions as well, though depending on your use-case, building something from scratch can also be faster.
Aashay Sachdeva MPL Data Scientist|2023-05-30 19:14:00|I think two threads got mixed 🥲   https://python.langchain.com/en/latest/use_cases/summarization.html  This should work for you.
Saurav Akaike|2023-05-30 19:18:18|1. Evaluating different models and comparing 2. Experimenting with prompts and version controlling
Rohan Manchanda|2023-05-30 19:18:21|Thank you so much. Def looking to do the old fashioned Build from scratch instead of buy for a couple of reasons (resources constraint plus learning also is important, hence the request for videos haha)
Aashay Sachdeva MPL Data Scientist|2023-05-30 19:20:16|Evaluating how? For 2nd, portkey is perfect
~ Pranay Desai|2023-05-30 19:20:50|[PHONE] is the founder and can help
Saurav Akaike|2023-05-30 19:22:25|Like trying out different open models simultaneously on a bunch of queries and comparing performances while fine turning
Saurav Akaike|2023-05-30 19:23:30|will try portkey
Rajesh RS Generative AI WhatsApp Group|2023-05-30 19:23:54|Try the tutorials by James Briggs.
Aashay Sachdeva MPL Data Scientist|2023-05-30 19:24:22|comparing how? Human feedback or through some metric? Best to run a python notebook in that case
Rohan Manchanda|2023-05-30 19:25:13|Thank you so much. Will try these out 🙂
~ Aryan Kuttappa|2023-05-30 19:26:31|Hey! I'm Aryan here, and i just passed out of highschool a few months ago, and I used to code back when i was in 8th or something and now am looking to get back into it full time and find internships in the ai/ml field. But i wanted to first gain experience and build a portfolio, so how do i start as a newbie in the field (courses etc), there is so much of info I feel clueless.
~ Aryan Kuttappa|2023-05-30 19:27:42|I just know python, and have worked on one or two projects with the help of gpt, but i don't feel like I learnt much, should I do more math etc and go the conventional method?
ashish Acgt01 Twitter|2023-05-30 19:29:41|On babylm & the quest for smaller LLMs  https://www.nytimes.com/2023/05/30/science/ai-chatbots-language-learning-models.html
~ Kp|2023-05-30 19:36:06|Observation: GPT-4 browsing can be used to access text webpages which were once unclickable by saving a snapshot of the webpage on the wayback machine. Not sure how true this is, but it worked the first few times I tried.
~ Happy Chaudhury|2023-05-30 19:45:02|Anyone tried hands on privateGPT , how it is performing. I have a usecase where i have to extract parties and legal description part from the documents and i tried to use gpt4 and able to get almost Perfect answers for prompts. But constraints here i can't use gpt4 , something i can train or use locally
Rohan Manchanda|2023-05-30 20:37:53|Great resource.   https://hackernoon.com/prompt-engineering-101-i-unveiling-principles-and-techniques-of-effective-prompt-crafting
Raghotham Paypal Bargava's Friend|2023-05-30 20:38:11|What are the open source tools for prompt versioning and prompt management?
Nirant|2023-05-30 20:38:47|More advanced guide nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Rohit Aggarwal|2023-05-30 20:40:55|Promptable is open source but not great. For simple stuff I’ve seen people manage conf files for prompts and then use them with an SDK like Langchain
Nitesh Letsdive.io|2023-05-30 20:57:21|‎You added Nitesh Letsdive.io
Lavish 2017|2023-05-30 21:09:25|not me creating TEMPLATE_1, TEMPLATE_PREVOUS, TEMPLATE_NOT_TO_BE_USED, TEMPLATE_ACTIVE
Abhishek Mishra|2023-05-30 21:16:55|Isn't prompt the same as any kind of knob/config in SW? Why not just treat it the same for flavour/variant control via config files?  Am I missing something here?
Abhishek Mishra|2023-05-30 21:20:35|It works alright for RAG based QA, you'll have to test for your specific use case as it'll be inferior to GPT4 in extracting dependencies and may miss out on few parties here and there as per my observation. ‎[5/30/23, 21:22:30] Sandeep Srinivasa RedCarpetup: ‎image omitted
Rohit Aggarwal|2023-05-30 21:24:08|Where the TEMPLATE_Final_pleaseworkthistime ‎[5/30/23, 21:42:06] Nirant: ‎image omitted ‎[5/30/23, 21:52:36] ~ Shobhit Jaipurkar: ‎image omitted
Shashank Generative AI Group|2023-05-30 22:08:47|anyone here going to the airport to welcome him? 😂 AItithi devo bhava
Abhinav Verma Longshot.ai|2023-05-30 22:09:51|As a large language model, I cannot travel
Harsh Koo|2023-05-30 22:17:21|Government should lobby Sama to put Indian users of OpenAI on same priority as those in the US. And integrate UPI for payments.
~ Kp|2023-05-30 22:24:32|Are indian users devoid of any features?
~ Kp|2023-05-30 22:24:40|As I'll be switching to an Indian paid subscription soon
~ Kp|2023-05-30 22:25:03|Rn I have access to gpt 4 plug-ins, web browsing with bing and gpt 3.5
Harsh Koo|2023-05-30 22:25:47|Some features get rolled out late to Indian users. Iphone app is the recent onem
Abhishek Mishra|2023-05-30 22:25:57|Same with a Indian subscription
Abhishek Mishra|2023-05-30 22:26:03|*an
~ Kp|2023-05-30 22:26:13|Alright that's a relief
Dr. Ashith Generative AI WA Group|2023-05-30 22:29:27|Is anyone aware of an AI music generator that can do background scores for video?
~ bhanu.io|2023-05-30 22:30:11|do check out - https://riffusion.com/
Aakash Kumar  Matrix Partners|2023-05-30 22:30:34|Beatoven, Mubert
~ Puneet|2023-05-30 22:35:28|Do indian users have access to gpt plugins? Even after being a premium user?
Abhishek Mishra|2023-05-30 22:35:54|Yes
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:36:04|Yes, have access
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:36:28|Although, I'll be honest. Plugins have been quite mediocre so far
~ Puneet|2023-05-30 22:36:45|Strangely it does not work for me. Not sure. Will check with you.
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:36:46|Browser fails quite often at basic tasks
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:36:53|Hope they fix that soon
Ravi Srinivasan|2023-05-30 22:37:09|Interesting! but i found them to sound similar to each other
Abhishek Mishra|2023-05-30 22:37:26|Logout, then login and check settings. If you find beta features, look for plugin/web browsing and enable it
~ Kp|2023-05-30 22:37:32|How so?
~ Kp|2023-05-30 22:37:45|Is it a click failed failure?
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:38:00|Yes. That's the most common one
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:38:06|There are a couple of others as wdll
~ Kp|2023-05-30 22:38:12|This is common because of robots.txt
~ Kp|2023-05-30 22:38:22|I found a workaround earlier.
~ Kp|2023-05-30 22:38:30|.
Abhishek Mishra|2023-05-30 22:38:54|Scrapers/link readers have worked very well for me. Web browsing option can fail more frequently.
~ Puneet|2023-05-30 22:39:15|Oh, thanks! Now it works.
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:39:19|Interesting
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:40:12|I think someone on this group (or maybe Twitter) quite astutely pointed out that if meta had built chatgpt, they would have engineered it for crazy amounts of continued growth
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:40:38|Openai gets basic UI wrong sometimes. Like the fact that you can't search on plugins is just a big oversight
Bharat Kumar Ramesh Hashmal Web3|2023-05-30 22:40:59|If you want to find a plugin, you need to manually scroll through each page to install
Anubhav mishra Zupay|2023-05-30 22:44:30|I think not giving a serach bar to find plugins is a calculated move, provided that it's purely growing word of mouth they'd want everyone to know at least some more plugins apart from just their use case and would be tempted to try more.   😅
~ Kp|2023-05-30 22:46:00|But the main issue/feature seems to be the apparent context window limit increase with gpt-4 browsing
~ Kp|2023-05-30 22:46:11|Which will not be the case with any browser based extension
Abhinav Verma Longshot.ai|2023-05-30 22:46:52|What is the context window they're providing
~ Kp|2023-05-30 22:46:53|Gpt-4 is able to take an entire webpage as input context
~ Kp|2023-05-30 22:47:24|Probably the increased model.
~ Kp|2023-05-30 22:47:28|32k token limit
Abhinav Verma Longshot.ai|2023-05-30 22:47:53|Because in chatgpt the gpt4 is limited to 4k
~ Kp|2023-05-30 22:48:43|Yes but if that were the case gpt 4 with browsing would not be able to read large webpages. Which it can. Not to mention it can perform continued link search which would require even more context.
Abhinav Verma Longshot.ai|2023-05-30 22:49:10|I think there are techniques to help with that
Abhinav Verma Longshot.ai|2023-05-30 22:49:55|We have a feature at longshot as well where we read multiple web pages not just 1.
Abhishek Mishra|2023-05-30 22:59:07|True, the plugin interface design should've been similar to play store or iOS app store. It's quite obvious the natural direction of plugin developement is going to be the same as Android/iOS. May be searching and review based system would be implemented once their beta phase is over for plugins.
Abhishek Mishra|2023-05-30 23:01:06|True, I was using plugins to go through YouTube podcasts to identify books/ideas/thought experiments at once. But it was not doing well for anything longer than 1 hour.
~ Mayank Gupta|2023-05-30 23:06:48|My experience has been similar. Interested in talking if someone has had a good experience with plugins
Lavish 2017|2023-05-31 00:04:53|Is there a good way to keep a preffered token length of variables inside a prompt template?  Oftentimes I want to trim out a particular variable like chat history if overall length of prompt is exceeding 4K tokens.  langchain doesn't support this out of box so I've a function to accept preffered token length and cut from start or back configurablity which I use with prompt templates these days but it has limitations around not having priority order of variables to cut tokens from if overall length is exceeding 4K so I've done patches on top of it but haven't reached a very sophisticated method yet
~ Santhosh K|2023-05-31 06:41:53|I used show-me plugin for creating flowcharts(for PPT slides) ..seems to be doing a good job.
Nirant|2023-05-31 06:55:43|Memory e.g. ConversationalMemoryBuffer does this in Langchain?
~ Gaurav|2023-05-31 09:01:07|‎You added ~ Gaurav ‎[5/31/23, 10:06:20] Kishore GenAI: ‎image omitted
Nirant|2023-05-31 10:23:47|I've confirmed reports from several devs and founders that GPT4 API has unusual RateLimit Errors in last 48 hours or so. Creating a new key seems to help. If you've a personal account, upgrading it to organisation also seems to help.
Rounak Datta Hackathon Winner|2023-05-31 10:30:23|Has anyone tried BloopAI (https://github.com/BloopAI/bloop) for in-repository code-searching  I've used it, and its like a senior engineer who knows absolutely everything about your codebase. Its what Github search was ought to become 🙂
~ Nitin Kishore|2023-05-31 10:32:12|‎You added ~ Nitin Kishore
Rohit Aggarwal|2023-05-31 10:37:29|I thought sourcegraph was awesome but this looks cool. Will check it out
Rounak Datta Hackathon Winner|2023-05-31 10:49:26|In fact sourcegraph might be better for a more deterministic browsing
Bharat Singh|2023-05-31 11:23:54|Could give generative fill a shot in Adobe photoshop without any prompt
~ Dhruv Tyagi|2023-05-31 11:42:10|Any news on Sam Altman’s delhi visit? ‎[5/31/23, 11:49:03] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-05-31 11:50:11|This is some complete colab level BS
Abhinav Verma Longshot.ai|2023-05-31 11:50:30|You select A100 and you get T4 kind of scam this
Dev Aggarwal|2023-05-31 11:50:35|Cc [PHONE] any insider info from tcs? 🌝
Vaibhav Bhargava Meesho Grab |2023-05-31 11:50:39|Since when. I have been using since morning..
Nirant|2023-05-31 11:51:19|Right now. Mainly on Code Interpreter.
~ Revant|2023-05-31 12:30:46|‎You added ~ Revant
Paras Chopra Wingify|2023-05-31 13:58:50|https://news.ycombinator.com/item?id=36134249
Dr. Pratik Desai KissanGPT|2023-05-31 14:01:28|Yes, too much RLHF
Aashay Sachdeva MPL Data Scientist|2023-05-31 14:04:29|‘Dumb stochastic parrot’🤣
Harsh Gupta Felvin|2023-05-31 14:18:13|How has been people's experience with Claude 100K?
Abhinav Verma Longshot.ai|2023-05-31 14:21:51|Good.
Abhinav Verma Longshot.ai|2023-05-31 14:22:24|It's definitely very good but lacks some things that gpt4 etc have. It's much faster
Dev Aggarwal|2023-05-31 14:22:28|Its called the great AGI disillusionment
Abhinav Verma Longshot.ai|2023-05-31 14:22:44|Also prompt engineering is a little different here
Shan|2023-05-31 14:39:57|I mean, Sama is publicly speaking about the species-level dangers of AI, what do you expect? We only get Nerf guns from now on. 😀
Dr. Pratik Desai KissanGPT|2023-05-31 14:43:02|I keep a nerf water gun with me all the time in case my GPUs suddenly become sentients.
Alok Bishoyi|2023-05-31 14:45:00|NSA has a backdoor to all modern cpus / gpus Wouldn’t worry too much about silicon becoming sentient
~ Sanjeev|2023-05-31 15:24:54|‎You added ~ Sanjeev
~ Srinivasan Nandakumar|2023-05-31 15:30:54|Could be that they quantized the model further which leads to faster inference times but reduction in quality.
~ Gaurav|2023-05-31 15:32:34|+1 The inference times have improved a lot recently.
Abhishek Mishra|2023-05-31 15:36:21|Yeah if the model has gotten dumber and faster, it's most likely the result of *model compression*. Not quantization though, that'll most likely Nerf it down completely. Also we aren't sure if openAI has started anything resembling GGML/GPTQ quantization internally.
~ Ashutosh Kumar|2023-05-31 15:37:25|Has anyone used or knows the best model for english to chinese translation? A bunch of them on HF but if anyone has experience in something else it’ll be great
~ Gaurav|2023-05-31 15:39:30|Anybody here regularly finetuning llama, opt or gpt j 6b? Have some quick questions to ask related to approach for the same. Thanks!
Nirant|2023-05-31 15:40:13|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"""
Shan|2023-05-31 15:50:05|"strange, on my codebase it really sucks. Most answers are super lame or fail with ""something went wrong"". Doubtful if I'll use it on an ongoing basis"
Nirant|2023-05-31 16:08:14|"There is an interesting conversation going on in the *AI and Philosophy* WA group on the regulator, AI research companies and the recent ""AI will cause extinction"" tweet signed by OAI, Stability and others: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV"
Nirant|2023-05-31 16:08:15|Related: For folks interested in *Generative Art*, including images, video and music: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4
Shan|2023-05-31 16:35:26|BTW this is interesting https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized - comparing token sizes for the same sentence in different languages. My takeaways: 1. in some languages token numbers will be unexpectedly high 2. If you're consistently using an LLM with non-English inputs/outputs it may be worth building an LLM with lang specific tokens (I remember we were discussing this a while back in this group) 3. Most likely this would apply to obscure english words too in domains like medical, legal etc which have a lot of foreign words (latin, Greek etc) or domain specific words
Nirant|2023-05-31 16:36:49|Number of tokens:  Nirant: 3 English निरंत: 10 Hindi નિરાંત: 18 Gujarati நிரந்த்: 21 Tamil
~ Harsh Pokarna|2023-05-31 16:41:56|If I am new to dl, can anyone recommend good resources to start with it.
Nirant|2023-05-31 16:42:20|course.fast.ai
~ Harsh Pokarna|2023-05-31 16:42:57|thanks👍✌️
~ Harsh Pokarna|2023-05-31 16:44:07|are there good books that I can use instead of a course?
~ bhanu.io|2023-05-31 16:47:11|+ 1 for this recomendation - there's also a book by the TA of this course - it also has jupyter notebook for all the lessons - https://course.fast.ai/Resources/book.html
Shan|2023-05-31 16:57:36|http://introtodeeplearning.com by MIT is good, I've heard.
~ Sushant|2023-05-31 17:11:31|"apart from fast.ai  ML - Stanford CS229: Machine Learning | Summer 2019 – Courses explains everything from scratch, Math, Stats, Algorithms - https://youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh   DL (Focus on CV) - Stanford cs231n - https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk  NLP from scratch to Language Models - Stanford CS 224N - https://youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ"
Nirant|2023-05-31 17:13:28|Let's stick to the topic, which is Generative AI please 🙏  Plenty of resources online on Deep Learning  — I should've not encouraged this in the first place 😅
Azhan Mohammed Generative AI WhatsApp Group|2023-05-31 17:16:08|Can’t we have a separate group for generic deep learning, like things which aren’t a part of generative space.
Nirant|2023-05-31 17:20:43|Please feel free to make one, *outside of this community* — I am sure there are lot of folks interested in it!   I do not have it in me to moderate another WA group
~ Siddharth|2023-05-31 17:38:46|‎~ Siddharth left
Kaushik Bokka|2023-05-31 17:42:34|I would love to create an AI Founders Forum with interested folks here :)  https://lightning-ogre-740.notion.site/All-In-Founder-Forum-19e1d399977f46b8b044ca5e939027d6
~ Vibbs Dod|2023-05-31 17:55:17|[PHONE] Should we move this from whatsapp to discord server, where topic specific channels can be created, for moderation purposes we can leverage bots as well ?
~ Vibbs Dod|2023-05-31 17:55:45|And I meant topics within Generative AI,
Sudharshan GenAI|2023-05-31 17:56:32|+1
Sudharshan GenAI|2023-05-31 17:56:45|Please no, discord is not as accessible as WA
Nirant|2023-05-31 17:56:46|Is there a known way to measure diversity, code consistency which people are complaining about?
Simrat Hasura|2023-05-31 18:35:26|Can you share this link
~ NG|2023-05-31 18:45:41|Apart from a few open Ai gym problems like lunar lander and mountain car, can you guys recommend any other RL problem statements ?
Pratiksha Dake Unacademy|2023-05-31 18:46:34|‎Pratiksha Dake Unacademy joined using your invite
Aashay Sachdeva MPL Data Scientist|2023-05-31 18:49:13|Recommendation as a RL system (check youtube paper)
Aashay Sachdeva MPL Data Scientist|2023-05-31 18:50:01|https://m.youtube.com/watch?v=HEqQ2_1XRTs
~ Srikanth Avadhanam|2023-05-31 20:32:55|‎You added ~ Srikanth Avadhanam
Rajesh RS Generative AI WhatsApp Group|2023-05-31 21:36:28|Has anyone else come across long build times for docker containers using a Pytorch dependency? Often times upwards of 20 minutes even on dedicated cloud build servers like Azure DevOps. Does anyone know workarounds for this kind of a situation? Or is it to be expected given how heavy torch has become?
Rohit GenerativeAI WhatsApp Group|2023-05-31 21:39:11|which pytorch version and base image?
~ Sahil Singla|2023-05-31 21:42:03|‎~ Sahil Singla requested to join
Ojasvi Yadav|2023-05-31 21:42:27|"Random Prediction - 1 year from now, Adobe will do to Premiere pro what they just did to Photoshop.  Generative fill for videos. If implemented correctly, that will be the biggest impact of AI on the majority of the world, something even chatgpt can't claim to have.  Generative fill for videos will make the discussion of aspect ratios obsolete. It will restructure the entire display manufacturing and creative industry.  I get black bars on my TV because the movie I'm seeing was shot in a different aspect ratio. If done correctly, that can enormously reduce the contexts in which we use the phrase ""aspect-ratio"""
Chirag Jain|2023-05-31 21:43:02|yes although there are two types of distributions now  pypi - this one is split into main pytorch plus libcu*.so provided by various nvidia-cu* wheels  torch index - this one has massive 1.5-2GB wheels that are downloaded as one file  if you don't need cuda use the +cpu variants they are only 200 MB ish  It is important to correctly use Docker caching or just start from official pytorch images
Rohit Aggarwal|2023-05-31 21:43:27|Love the movie aspect ratio use case. Would be awesome if Smart TVs did it :)
~ Sahil Singla|2023-05-31 21:42:03|‎~ Sahil Singla requested to join
Ojasvi Yadav|2023-05-31 21:46:08|When a technology has the potential to remove one of the very first lessons that any creative learns about, you know that's significant on another scale
Rajesh RS Generative AI WhatsApp Group|2023-05-31 21:47:16|torch~1.9 (different sub versions) and Python 3.9 and 3.10 base images (slim)
Rajesh RS Generative AI WhatsApp Group|2023-05-31 21:48:16|Thats helpful, thanks. I think in some cases the CUDA bits may not be required, let me check that out.
Chirag Jain|2023-05-31 21:49:59|if you have your own builder, make sure - you pull in the cache from previous version of the image - if you can use docker buildkit, use a mount to cache pip downloads  RUN --mount=type=cache,target=/root/.cache/pip  first build will take time to download, next build will just start installing
Rohit GenerativeAI WhatsApp Group|2023-05-31 21:51:46|we had this issue in our case as well pre 2.0 images were pretty huge (cuda) (16 gb) so we switched to 2.0 PT base image which solved one of this major issue because the final image was like 6 gb  apart from that try to cache the layers if it's in the CI, I think there are services that can help you with that
Abhishek Mishra|2023-05-31 21:53:01|Royalties waived off for commercial and research use for Falcon 40B  https://twitter.com/TIIuae/status/1663911042559234051?s=20
Anshul Khandelwal Invideo|2023-05-31 22:16:00|Movie directors will hate you more!
Rajesh RS Generative AI WhatsApp Group|2023-05-31 22:17:56|Thanks, what was the underlying reason? Model size and quantization for pretrained models? Anything else?
Rohit GenerativeAI WhatsApp Group|2023-05-31 22:21:28|just changing pytorch image helped me didn't change any model weights/quantization stuff previously we were using nvidia images but later figured it had some additional dependencies which we didn't need
Rajesh RS Generative AI WhatsApp Group|2023-05-31 22:23:30|Thanks, that is helpful too ‎[5/31/23, 22:26:45] Rohit Aggarwal: ‎image omitted
~ Sharma|2023-05-31 22:31:18|‎~ Sharma left
Sachin Legaltech|2023-05-31 22:54:47|https://openai.com/research/improving-mathematical-reasoning-with-process-supervision OpenAI announced that they are training their reward models to provide reward for every thought (reward shaping) than giving reward at the last step for mathematical reasoning tasks.
Lalit Pagaria|2023-05-31 22:59:21|If all in your company follow consistent versions (python, torch, and even models) then create slim base images (with version combination) and push them to your repo. All other teams now can create images on top of these base images.  For advanced base image size reduction: check these but with caution, as it may not work as intended along with a reduction in your debugability.  Use torch serve base image https://hub.docker.com/r/pytorch/torch serve  https://github.com/slimtoolkit/slim  https://github.com/GoogleContainerTools/distress  Use the Alpine base image but it may increase your build time.  In general, try to reduce the number of layers in the Docker image. This one is a good article https://pythonspeed.com/articles/smaller-docker-images/
Bharat Kumar Ramesh Hashmal Web3|2023-06-01 06:52:34|https://twitter.com/kiwicopple/status/1664027051312001027?s=19
Bharat Kumar Ramesh Hashmal Web3|2023-06-01 06:53:48|This latest launch by supabase is pretty incredible. Other vector stores might be better at much larger scale, but supabase def has the most comprehensive toolkit and DX
Prayank Swaroop Accel|2023-06-01 08:30:31|Falcon models have been made Apache2.0! good news !  https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_exciting-news-falcon-models-from-tii-activity-7069750736250621952-GH9U?utm_source=share&utm_medium=member_android
Pranjal Yadav Razorpay|2023-06-01 09:34:51|TIL https://aviary.anyscale.com/  Compare cost, latency and choice on answer across LLMs with this simple UI. Comes handy for domain specific prompt testing across OSS models. ‎[6/1/23, 09:49:44] Prayank Swaroop Accel: ‎image omitted
Prayank Swaroop Accel|2023-06-01 09:49:45|Funny translations ‎[6/1/23, 09:50:23] Prayank Swaroop Accel: ‎image omitted
Raghotham Paypal Bargava's Friend|2023-06-01 09:51:30|Surprisingly dolly v2 is decent. Did not expect!
Prayank Swaroop Accel|2023-06-01 09:51:46|Also demonstrates that Dolly, returned the correct answer in the second trial though .. the first trial was wrong. So inconsistent a bit
Aakash Kumar  Matrix Partners|2023-06-01 09:52:32|There’s a lot more to come from supabase. Just one of the cool stuff team has been brewing :)
Pratyush Choudhury|2023-06-01 09:53:15|Postgres support?
~ Arjun|2023-06-01 09:54:09|Anyone used any generative tools for auto/assisted ground truth annotation of images or LiDAR with boxes/semantic segmentation labels?
Rounak Datta Hackathon Winner|2023-06-01 09:55:13|Supabase has always been postgres under-the-hood: they are productizing pgvector better
Pratyush Choudhury|2023-06-01 09:57:03|That's my point - the fact that their lingua franca is PG, that results in a solid DX
Pratyush Choudhury|2023-06-01 09:57:30|But I am hearing PGVector doesn't do well at scale ‎[6/1/23, 09:59:13] Aashay Sachdeva MPL Data Scientist: ‎image omitted
Sachin Legaltech|2023-06-01 10:03:10|This is the same old RLHF pipeline. They (I think karpathy) just explicitly showing two parts of RLHF - Reward modeling and then using Reward network to train policy network.
~ Arko Cy|2023-06-01 11:28:21|Some of them are more excited & optimistic than you would believe !
Dr. Pratik Desai KissanGPT|2023-06-01 11:53:05|How about TVs with GPUs that can automatically make HD videos out of old low resolution videos with GFGAN or something similar.
Rajesh RS Generative AI WhatsApp Group|2023-06-01 11:56:51|Don’t TVs already have chips that have GPUs in them? DLSS has been in gaming consoles and  rDNA architectures allow for similar capabilities.
Dr. Pratik Desai KissanGPT|2023-06-01 12:01:26|Interesting, got to check it out and update my knowledge. Not sure my 800$ TV has 1000$ GPU chip but I may be wrong.
Dr. Pratik Desai KissanGPT|2023-06-01 12:06:45|How about we make every thing kids friends and all the violence and blood is replaced by flowers and rainbow based on settings, in real time 😜
Nirant|2023-06-01 12:08:14|Cc Rahul [PHONE] is doing this
Nirant|2023-06-01 12:08:41|That's the reason this group has DeepMedia in it
Rahul Bhatnagar|2023-06-01 12:09:10|Not in real time (yet) though. :)
Dr. Pratik Desai KissanGPT|2023-06-01 12:09:19|Add me as an early tester. My 5yo loves demon slayer and May be this will give me a moral victory
Rahul Bhatnagar|2023-06-01 12:09:44|Hahah will DM.
Dr. Pratik Desai KissanGPT|2023-06-01 12:10:15|We are doing next year prediction anyway😜 the way we are moving it’s definitely will be a thing.
Rahul Bhatnagar|2023-06-01 12:10:34|More like 2 months.
Rajesh RS Generative AI WhatsApp Group|2023-06-01 12:14:10|Well a GPU to do upscaling doesn’t have to be 1000 dollars. I could be wrong but it does not have to be the stereotypical GPU which looks like a Casio watch had a baby with Crysis 2
Dr. Pratik Desai KissanGPT|2023-06-01 12:16:24|My experience with GFGAN is that when I upscale low res image to 4K, it take a significant amount of memory. Now, I’m not aware of other techniques so I’ll refrain from making assumptions.
Anshul Khandelwal Invideo|2023-06-01 12:19:29|There is a lot of nuance to the topic of aspect ratios in film making and a rich history behind it...
Dr. Pratik Desai KissanGPT|2023-06-01 12:20:20|I don’t play games so had to literally search Crysis 2 to understand reference 🤣
Anshul Khandelwal Invideo|2023-06-01 12:20:33|https://youtu.be/wlUV6y5TUko
Anshul Khandelwal Invideo|2023-06-01 12:21:10|This is a good primer on aspect ratios and the problems with manually or automatically changing them...
Rajesh RS Generative AI WhatsApp Group|2023-06-01 12:22:12|Old time gamer here but I too have stopped gaming. Crysis was big when I was younger. On that note generative AI is going to play a big role in content creation for games I assume. Upscaling is just one problem but maybe we will see super realistic graphics thanks to generative models. One of the biggest things in the recent past is Unreal Engine 5.1 and the nanite tech in it
Nirant|2023-06-01 12:27:56|Cc Rajeev [PHONE] was earlier working on game assets but moved away from it
Dr. Pratik Desai KissanGPT|2023-06-01 12:27:55|I’m sure you saw NVIDIA demo. No more NPCs. I also saw some tweets that people are getting connected to their character.ai characters. Combine these two and you got AI characters teaming up with you in games and once done, chatting with you about state of politics and IPL at home.
Rajesh RS Generative AI WhatsApp Group|2023-06-01 12:29:10|That is very cool. A completely digital persona who can interact with you across virtual and real worlds, or something like this.
~ Karan Gandhi|2023-06-01 12:29:18|We can port this to telegram Bots + accessibility both covered  [PHONE] ?
Nirant|2023-06-01 12:32:35|Sticking to WhatsApp in the interest of serendipity. I don't expect Crysis2 to be mentioned on Telegram for instance.   Trust me, I'd love bots. I spend 6 hrs/week doing very manual things
Rajesh RS Generative AI WhatsApp Group|2023-06-01 13:41:59|There’s a section in this video which discusses video reconstruction from MRI data collected using visual stimuli. Mind blowing stuff. https://youtu.be/eXttLLdlzaI
Simrat Hasura|2023-06-01 14:35:20|Hey folks, which vector store would you recommend for production application ?  I have heard of pinecone and weaviate  Do you have any favourites ?
Nirant|2023-06-01 14:42:13|Weaviate is quite accessible, great DX and [PHONE] runs it in production for Albus. I've both Redis and Qdrant in production, mainly for high QPS and _practically_ free
Krishna Ntkris|2023-06-01 14:44:17|We have just migrated off pinecone to weaviate, and could not be happier. Great dev ex and gives us the right amount of flexibility.
Rajesh RS Generative AI WhatsApp Group|2023-06-01 14:44:18|We're using Redis in production now. Langchain comes with Chroma DB which works for smaller use cases
Nirant|2023-06-01 14:44:22|Wait, I might be wrong on this — [PHONE] uses Pinecone
Abhinav Verma Longshot.ai|2023-06-01 14:45:43|Supermeme.ai also uses pinecone I believe
Kartik Mandaville|2023-06-01 14:48:47|I use Pinecone.
Kartik Mandaville|2023-06-01 14:48:55|what type of flexibility?
Paras Chopra Wingify|2023-06-01 14:50:42|We use Pinecone at Nintee
Paras Chopra Wingify|2023-06-01 14:50:44|Pretty good
~ Pranay Desai|2023-06-01 14:52:55|hows the pricing scaling for you?
Abhinav Verma Longshot.ai|2023-06-01 14:54:27|Folks using pinecone, are you charged for concurrent requests as well or are you charged just for the amount of vector embeddings you store? Another question how do you store date in Metadata if you do at all?
Ankur Pandey|2023-06-01 14:55:00|Ramsri recommended pinecone even when he faced issued. That was proof enough for us
Dev Aggarwal|2023-06-01 14:55:06|I have the same question. Their QPS ratings are a little fuzzy so its not clear at all how many pods you actually need
Ramsri Goutham|2023-06-01 14:55:57|‎You added Ramsri Goutham
Abhinav Verma Longshot.ai|2023-06-01 14:56:06|Openai embeddings k according you can store 2.5 million embeddings per pod. But unsure if this counts Metadata limits also
Nirant|2023-06-01 14:56:25|[PHONE] we're discussing vector databases, and thought it'd be good to hear why you recommend Pinecone
~ Santosh|2023-06-01 14:57:07|There are a few good ones out there that have personally used but for a production application the choices I wud make would be governed by scale/precision , integration with the ecosystem etc. Making Pinecone and Chroma easiest/fastest to integrate with
Kartik Mandaville|2023-06-01 14:57:49|Its per instance / pod type. We are small and only have a single pod now.  334,535 vectors p1.x1 pod $65/month We do meta data, namespace and are now working on hybrid search Pinecone works well with zero complaints
Nirant|2023-06-01 14:57:52|Caveat: Chroma is very weird. Takes 2G to store 1.2G worth of embeddings and so on. Won't recommend for production
Ramsri Goutham|2023-06-01 14:58:20|Sure! :) I am not Pinecone's ambassador, haha! I think nowadays Weaviate, Qdrant, Croma all are equally competent and capable If I am starting today I would use Postgres Pgvector for smaller use cases and only think about Vector DBs at million vector scale .
Nirant|2023-06-01 14:58:55|Seconded, anything upto 10-20 QPS and a few 100K embeddings should go to pgvector!
Paras Chopra Wingify|2023-06-01 14:59:02|One thing we do is store embeddings in a local Postgres so changing vector store db is easy  So start with anything really
Krishna Ntkris|2023-06-01 14:59:38|We are moving to hybrid search and want to the ability to weight sparse VS dense. U can do this in pine one but it’s more of a pain.   We also want to weight different sources. Example: a pdf carries more weight than a csv (this is v specific to your use case), and Weaviate was better for this.  Finally, it’s open source :)
Pranjal Yadav Razorpay|2023-06-01 15:01:39|Any comments for caching questions in a QnA setup to avoid GPT call? I am checking https://github.com/zilliztech/GPTCache but not sure of that's the best direction.
Paras Chopra Wingify|2023-06-01 15:04:50|Exact questions rarely come in production
Pranjal Yadav Razorpay|2023-06-01 15:08:40|True, but similar questions are frequent. For example - 'What happens to payment page if product is out of stock', I found 20+ variants of this in a manual review. I only took a 10% random sample for review.
Krishna Ntkris|2023-06-01 15:10:16|Embed the question, do a look up and provide the answer if the similarity score is above X? Ideally only if the user upvoted or approved teh answer
Pranjal Yadav Razorpay|2023-06-01 15:11:26|Yup, that's my current setup.   I felt GPTCache might be doing something smarter so reached out to the group.
Sumod K Mohan|2023-06-01 15:35:18|This was the paper from Recsys on what TikTok does, that I spoke a day ago.
Sumod K Mohan|2023-06-01 15:35:37|https://arxiv.org/pdf/2209.07663.pdf
Sumod K Mohan|2023-06-01 15:40:11|[PHONE] : ☝️
Mayank Tiwari IHX Wharton|2023-06-01 16:01:10|‎Mayank Tiwari IHX Wharton requested to join
~ Mahesh|2023-06-01 16:02:33|‎~ Mahesh requested to join
Anagh Prasad|2023-06-01 16:08:05|Hi all, looking to make a marketing oriented video using Runway ML. Would anyone be interested in taking a quick paid gig for it?
Sumod K Mohan|2023-06-01 16:09:46|We are sort of having the same conversation over and over again. Thought it might be good experiment, if we can create a community curated notes. The idea being, the community edits and add *short big tested takeaways* content, in a specific overall structure (which will get getting updated over time) as we have discussions. Just so that we have time to learn the structure of the document, I thought we can roll out edit access slowly. Everyone has view access immediately, please request edit access from the document directly, if you want to edit (I can't handle 1000 DM ;). The quality of this is in each of our hands, hoping we can make something amazing out of this. Just an experiment, lets see how far this goes. We can start with the most frequently asked questions, that way we have most bang for the buck. Here is the doc: https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#heading=h.ir323h4vucu
~ Pravesh|2023-06-01 16:10:41|‎~ Pravesh requested to join
Mayank Tiwari IHX Wharton|2023-06-01 16:44:44|‎Mayank Tiwari IHX Wharton joined using this group's invite link
Pranjal Mehta|2023-06-01 16:47:07|https://www.jugalbandi.ai/  Came across this today. Very cool work by AI4Bharat
~ Kp|2023-06-01 16:56:09|It featured in MSbuild
~ Kp|2023-06-01 16:56:33|Lol considering that they got highlighted in ms build that'd be a no brainer
~ Kp|2023-06-01 16:56:52|I think MS invested in them
Sumanth AI4Bharat|2023-06-01 16:57:14|‎Pranjal Mehta added Sumanth AI4Bharat
Pranjal Mehta|2023-06-01 16:57:51|Added [PHONE] from AI4Bharat here
Pranjal Mehta|2023-06-01 16:58:50|Please bother him judiciously
Pratyush Choudhury|2023-06-01 16:59:14|Good idea to possibly make this a Github repo?   Possibly easier for folks to contribute & editors to merge them via PRs?  Just thinking out loud - a brilliant initiative nonetheless
Pranjal Mehta|2023-06-01 16:59:27|Welcome to the group Sumanth! ‎[6/1/23, 17:01:06] Nirant: ‎image omitted
Nirant|2023-06-01 17:01:58|*reach them
Ravi Srinivasan|2023-06-01 17:02:05|[EMAIL]
Ravi Srinivasan|2023-06-01 17:02:13|on their site
Ciyunni|2023-06-01 17:03:16|haqdarshak.com is about schemes that citizens can avail.
Ravi Srinivasan|2023-06-01 17:03:35|wonder if this summarizer is just a wrapper to chatGPT :) https://summarizer-fer6v2lowq-uc.a.run.app/
Ravi Srinivasan|2023-06-01 17:05:42|👆from opennyai (just realized its a play on nyaay🤦🏻‍♂️)
Sumod K Mohan|2023-06-01 17:08:32|I am meeting Saurab this evening, will ask him to join the group if he is interested.
Rahul Sundar 2013|2023-06-01 17:18:56|Hey [PHONE]!✌🏼
~ mukund kannan|2023-06-01 17:20:35|‎~ mukund kannan requested to join
~ AG|2023-06-01 17:48:04|‎~ AG joined using this group's invite link
Saurabh Karn Nyai|2023-06-01 19:17:33|‎Sumod K Mohan added Saurabh Karn Nyai
Sumod K Mohan|2023-06-01 19:20:11|Hi Saurabh, Welcome to the group. There are bunch of folks who are very excited by your work on Jugalbandi and OpenNyAI. [PHONE] had worked on legal AI before.
Saurabh Karn Nyai|2023-06-01 19:20:33|Thanks a ton Sumod :)
Saurabh Karn Nyai|2023-06-01 19:21:00|[PHONE] - Would be very happy to chat about Legal AI.
Saurabh Karn Nyai|2023-06-01 19:21:29|[PHONE] also worked on Legal AI with his startup so there are quite a few Legal AI folks here already 🥳
Anubhav mishra Zupay|2023-06-01 19:22:52|[PHONE] sky is the limit bro, great to see you here.
~ Vishwam Jindal|2023-06-01 19:42:27|Hi Saurabh - nice to see you here!  Vishwam - also building in the legal space (Webnyay.ai).
Saurabh Karn Nyai|2023-06-01 19:43:33|Hey Vishwam! Glad to see you too here :)
Saurabh Karn Nyai|2023-06-01 19:44:18|[PHONE] [PHONE] - glad to see you here too!
Sachin Legaltech|2023-06-01 20:27:13|Welcome to the group Saurabh. Would be great to chat.
Saurabh Karn Nyai|2023-06-01 21:04:16|By the way folks, we are curating OpenNyAI residency this year. You should check it out.  https://forms.opennyai.org/residency2023
Shan|2023-06-01 21:32:48|From another group….
Shan|2023-06-01 21:32:50|*Call for Papers: AI-ML Systems 2023* https://www.aimlsystems.org/2023/  We are pleased to announce the 3rd International Conference on AI-ML Systems to be held in Bangalore, India, during October 25-28, 2023 as a fully physical conference. AI-MLSystems is a new conference targeting the research in the intersection of Systems Engineering and Artificial Intelligence and Machine Learning techniques.  The conference invites papers across Research and Industry tracks.  Areas of interest, submission deadlines, submission guidelines can be accessed at the links below.  Research Track: https://www.aimlsystems.org/2023/callResearch Industry Track: https://www.aimlsystems.org/2023/callIndustry
~ Divya|2023-06-01 22:12:45|Hey thanks for sharing. Will the papers be published in ACM/IEEE proceedings? (Didn't find exact info on the website)
~ Rishabh|2023-06-01 22:56:29|‎You added ~ Rishabh
Abhinav Verma Longshot.ai|2023-06-01 23:28:53|I asked chatgpt a logic problem and it realized its mistake and its self correcting. Problem is its keeping on getting it wrong
Abhinav Verma Longshot.ai|2023-06-01 23:29:00|Its just generating on and on and on
Abhinav Verma Longshot.ai|2023-06-01 23:31:12|https://chat.openai.com/share/5adb1eea-3bf0-42ef-ab2d-3543abcb1457 3 tries finally
Abhinav Verma Longshot.ai|2023-06-01 23:31:27|phir bhi wrong hai. but this is an interesting development
Saurabh Karn Nyai|2023-06-01 23:32:17|What’s your hypothesis? Why is it happening?
Abhinav Verma Longshot.ai|2023-06-01 23:33:11|This is the first time I've seen it happening. With 3.5 it was wrong and just said yes, I'm wrong and this probably can't be solved so good luck
Abhinav Verma Longshot.ai|2023-06-01 23:33:36|I'm guessing the loss dropped real low
Samhan Meta/Twitter Friend|2023-06-01 23:35:19|Once it makes a mistake it’s reinforced via context
Samhan Meta/Twitter Friend|2023-06-01 23:35:31|3.5 lacks reflection abilities
Abhinav Verma Longshot.ai|2023-06-01 23:36:21|I've yet to try with 3.5
Abhishek Mishra|2023-06-01 23:36:36|Very interesting. This is a new behaviour. It used to sometimes identify it's mistakes and apologise but never go on a loop like this. It could be due to it being trained to work with tools and APIs where it has to receive an error and perform retries after changing its approach.
Samhan Meta/Twitter Friend|2023-06-01 23:36:36|GPT-4 can sometimes reflect on itself
Samhan Meta/Twitter Friend|2023-06-01 23:36:40|It emerged
Shimanta Generative AI|2023-06-01 23:37:40|Maybe it’s trying to spit out anything until it finally receives a positive reinforcement 🤔😅
Samhan Meta/Twitter Friend|2023-06-01 23:37:55|This is because the model has to do multiple things  - follow the users instructions / prompt - follow the open AI rules And there is only a fixed amount of compute available. Each time it’s trained it finds a different trade off
Samhan Meta/Twitter Friend|2023-06-01 23:38:41|The model thinks for fixed time and then outputs the best token found after it
Samhan Meta/Twitter Friend|2023-06-01 23:39:02|This is a fundamental limitation of transformers. They are fixed in depth.
Samhan Meta/Twitter Friend|2023-06-01 23:39:23|Whereas we can decide to tnink harder
Samhan Meta/Twitter Friend|2023-06-01 23:39:46|Here we have to provide hints think hard , step by step . But these are ultimately hacks
Samhan Meta/Twitter Friend|2023-06-01 23:41:06|For eg GPT-4 cannot play tic tac toe optimally . Because that needs thinking ahead to some arbitrary depths.
Samhan Meta/Twitter Friend|2023-06-01 23:41:16|But that also doesn’t mean that it is stupid
Samhan Meta/Twitter Friend|2023-06-01 23:43:41|To fix this either you can fine tune / prompt on many different ways ppl plan on common tasks. That will plug the gap.
Abhinav Verma Longshot.ai|2023-06-01 23:44:31|My guess is there's another prompt here acting
Abhinav Verma Longshot.ai|2023-06-01 23:45:47|There's definitely an agent at play here. Because I'm using the browsing model
Sandeep Srinivasa RedCarpetup|2023-06-02 00:26:47|does anyone have any examples of papers/prompts that can do one-shot/few-shot classification of things like spam, fraud, etc. that kind of things ?
Samhan Meta/Twitter Friend|2023-06-02 00:34:09|Let me find it
Samhan Meta/Twitter Friend|2023-06-02 00:35:54|Check out the work of Yao Fu https://twitter.com/francis_yao_/status/1654804366002638849?s=46&t=6c5AUaH7z7YH7nCchlCSSQ
Samhan Meta/Twitter Friend|2023-06-02 00:36:28|TL;DR - the best way is few shot - ie few examples + chain of thought in the examples before generating the answer
Samhan Meta/Twitter Friend|2023-06-02 00:38:29|Eg  You are a machine learning classifier trying to classify user comments as spam or not_spam  Add your rules here as a list  Comment: “Excited on Monday” Thought: Let’s think step by step The user is posting that they are excited on Monday This is not spam because … Classification: not_spam  More examples ..
Samhan Meta/Twitter Friend|2023-06-02 00:39:43|More detailed studies here on diversity, recency bias etc https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
Samhan Meta/Twitter Friend|2023-06-02 00:40:28|Lmk how it goes we can debug / improve
Abhishek Mishra|2023-06-02 00:42:37|Sklearn announced scikit-llm specifically for this purpose  It aims to cover standard NLP tasks like classification zero shot or few shot, summarising etc with the help of LLMs  https://github.com/iryna-kondr/scikit-llm
Abhishek Mishra|2023-06-02 00:45:07|Likewise spacy announced spacy LLM for all standard NLP pipelines. Spacy used to be quite popular for quick and easy industrial applications before LLM rage took over   https://github.com/explosion/spacy-llm
Swastik Banerjee|2023-06-02 00:56:05|Quick question, is there an API version for plugins yet?
Samhan Meta/Twitter Friend|2023-06-02 01:11:25|Extra credit - you can check token probability for spam / not_spam for even more nuance
Abhinav Verma Longshot.ai|2023-06-02 01:11:30|won't be an api version of plugin imo, since that would defeat the point of plugin but the apis powering those plugins might be released sometime maybe
Abhinav Verma Longshot.ai|2023-06-02 01:12:21|Langhcain has done work on this. can look this up
Swastik Banerjee|2023-06-02 01:15:26|What was this then?
Utkarsh Ohm Thoughtspot|2023-06-02 01:48:20|Yes. But text to sql dataset. And enriching dataset instead of generating from scratch because that works better.
Abhinav Verma Longshot.ai|2023-06-02 01:51:26|I can't see this message. Also the plugin repo is available to work on top of if you want to create a new plugin
Samhan Meta/Twitter Friend|2023-06-02 01:54:45|https://github.com/teknium1/GPTeacher
Samhan Meta/Twitter Friend|2023-06-02 01:54:46|I need to replace myself with a langchain agent that shares papers
Sandeep Srinivasa RedCarpetup|2023-06-02 01:59:04|so i was indeed thinking of it in a few shot + COT way. but i was not very good or successful. so was looking if people had already figured out nice prompts and chains for this.
Swastik Banerjee|2023-06-02 02:00:11|that’s not what I mean. I want to retrieve the results I get using an existing plugin as an API call
Samhan Meta/Twitter Friend|2023-06-02 02:00:20|Share the task / few test cases and I can try .
Sandeep Srinivasa RedCarpetup|2023-06-02 02:01:16|i have already built a fair amount of chains, so i understand the general space...but am wondering if there is any specific ones that have worked here. for e.g. im wondering if retrieval augmented works here (past examples of spam)...but im not sure how that would fit in. because should i give few examples of spam related to the keywords of the mail ? or just depend on few-shots
Samhan Meta/Twitter Friend|2023-06-02 02:04:36|Yes RAG will definitely work. If you can recover similar examples both positive and negative along with their Thought chains .
Samhan Meta/Twitter Friend|2023-06-02 02:04:54|You can use embedding matches maybe
Samhan Meta/Twitter Friend|2023-06-02 02:05:38|If even that is not enough you have to bite the bullet and go into fine tuning etc
Samhan Meta/Twitter Friend|2023-06-02 02:08:51|Instead of vanilla embeddings you can even do task specific fine tuning on BERT etc so the embeddings better reflect the domain
Samhan Meta/Twitter Friend|2023-06-02 02:09:14|https://bergum.medium.com/four-mistakes-when-introducing-embeddings-and-vector-search-d39478a568c5
Abhinav Verma Longshot.ai|2023-06-02 02:10:06|Also pay attention to chunking when calculating embeddings. Better chunks would give better embeddings
Samhan Meta/Twitter Friend|2023-06-02 02:11:55|When you go down fine tuning route you can fine tune one model to detect fraud spam etc . And then it’s embeddings will better reflect the domain.
Abhishek Mishra|2023-06-02 02:12:09|Unless the spam you're trying to classify is novel, zero shot spam classification using GPT should be fine.  If the type of classification isn't well known or is a type of natural language inference (like identifying whether a SW req. is testable or non-testable), then you may require multi shot in-context approach or just fine tuning
Samhan Meta/Twitter Friend|2023-06-02 02:13:10|However I have worked in this space on non ML parts . Adversarial ML is a whole different can of worms
Samhan Meta/Twitter Friend|2023-06-02 02:13:31|The speed of retraining becomes critical
Samhan Meta/Twitter Friend|2023-06-02 02:14:38|And also combining other signals and not just from the content. Reputation scores of IP , account , phone
Samhan Meta/Twitter Friend|2023-06-02 02:16:49|And creating hold out sets to prevent degenerate feedback loops
Sandeep Srinivasa RedCarpetup|2023-06-02 02:17:40|Could you explain what u mean by this ? So train a model to generate embeddings ? I didn't understand the meaning of this.
Samhan Meta/Twitter Friend|2023-06-02 02:18:54|Multi task learning . Metas classifiers for abuse for eg are trained on many different tasks. Spam , fraud , terrorism. The embeddings of this model are very powerful as a result . Same idea applies to other models including LLM
Samhan Meta/Twitter Friend|2023-06-02 02:19:30|Similar to how FLAN is fine tuned on a whole battery of tasks
Samhan Meta/Twitter Friend|2023-06-02 02:20:19|Those same embeddings can be used for things like RAG into even more powerful LLMs , search etc
Samhan Meta/Twitter Friend|2023-06-02 02:20:52|I’m not an ML expert so others who have surely done this can add more
Sandeep Srinivasa RedCarpetup|2023-06-02 02:23:10|they were  generating embeddings using a classifier ? hmm.. i dont think i have ever looked into that.
Samhan Meta/Twitter Friend|2023-06-02 02:36:34|Yeah those embedding can be used in other classifier for other tasks
Samhan Meta/Twitter Friend|2023-06-02 02:37:08|https://research.facebook.com/publications/deep-entity-classification-abusive-account-detection-for-online-social-networks/ ‎[6/2/23, 02:46:20] Samhan Meta/Twitter Friend: ‎image omitted ‎[6/2/23, 02:48:04] Samhan Meta/Twitter Friend: ‎image omitted
Simrat Hasura|2023-06-02 06:54:58|Thanks everyone on the inputs  I also wanted to check what embedding you folks are using  Do you have any learnings to share on that front
Simrat Hasura|2023-06-02 06:56:50|Caching will be useful in BI sort of use cases where different people are trying to ask same /similar questions
Raghav Goyal EF|2023-06-02 06:58:05|Any interesting space tech newsletters i can follow?
Rohit Aggarwal|2023-06-02 07:07:38|We’ve been trying our version of semantic cache for knowledge retrieval and text2sql and it’s surprisingly been really good with a decent F1
Rohit Aggarwal|2023-06-02 07:08:55|GPTCache is a great starting point. On top choosing the best embedding model and then cleanup query before store improves accuracy a whole lot!
Aashay Sachdeva MPL Data Scientist|2023-06-02 07:32:29|https://twitter.com/omarsar0/status/1664441085693657088?s=46  SQL-Palm for txt2sql
Bharat Kumar Ramesh Hashmal Web3|2023-06-02 09:09:05|This is awesome. And super useful. I'm trying to do something to manage DBs with plain text. Setting up indexes, managing slow queries, running migrations, managing Wal, etc.  Is there somewhere we can access this model? ‎[6/2/23, 09:21:05] Rounak Datta Hackathon Winner: ‎image omitted
Ciyunni|2023-06-02 09:22:35|who's in control? the programmers or the program?  https://www.vice.com/en/article/4a33gj/ai-controlled-drone-goes-rogue-kills-human-operator-in-usaf-simulated-test
Swastik Banerjee|2023-06-02 09:26:36|I see…. thanks!
~ Rohan|2023-06-02 09:53:54|https://research.nvidia.com/labs/dir/neuralangelo/  2D video to 3D surface reconstruction by NVIDIA
Kartik Mandaville|2023-06-02 10:11:09|Anyone has access to the new alpha model from OpenAI which does function routing better?
Nirant|2023-06-02 10:15:52|What model is this?
Saurabh Karn Nyai|2023-06-02 10:17:38|"GPT4 is better with function routing or ""actions"" in the agent parlance from what we've seen. Don't know if there's any new release after GPT4. Is that the one you are talking about?"
Shan|2023-06-02 10:29:03|I don't even have access to code interpreter yet 🙁 does anyone know how to get it?
Shan|2023-06-02 10:29:18|(I mean can I ask openai to enable, etc)
~ Nayan Shah|2023-06-02 10:50:06|Is anyone tried chatgpt as the translator ? Or arabic bot ? I have tried it looks like it is a coin toss if u give propts and all properly sometimes answers are good and sometimes its not much . As its not train wrt to translation i think that is expected but i did not think i will see some good reaults as well . Anyones exp with this ?
Saurabh Karn Nyai|2023-06-02 11:01:56|On the onset I have seen it being a pretty good translator. I think vocabulary and sentence construction goes off when prompt is more complicated. I think a little bit of fine tuning on good curated data should be able to bump up the performance.
Kartik Mandaville|2023-06-02 11:05:31|I guess in private alpha. Will try to get more details
~ Nayana🙂|2023-06-02 11:43:47|‎~ Nayana🙂 requested to join
~ RISHAV|2023-06-02 11:53:35|As we know that the tiiuae/falcon-40b-instruct model has an Apache-2.0 license.  Has anyone tried using the model in a Document Q&A use case?  I have been using trying some basic steps -: 1. In memory DB -: Chroma DB 2. HuggingFace embeddings 3.  tiiuae/falcon-40b-instruct 4. Pass everything to RetrievalQA  I just wanted to know how is the performance of the model according to you?
Samhan Meta/Twitter Friend|2023-06-02 12:23:39|Is there an economic case for using falcon over GPT-turbo ?
~ Sushant|2023-06-02 12:24:00|"Hey folks looking for help on how you are managing prompts, flows for calling openai api  - I have a series of scenarios/data summaries tagged with different features. - I want to create a ""trigger engine"" to trigger certain tasks if/when certain criteria are met - e.g. ""X% of users in a set have a specific tag"", ""X% of users in a set with tag A also have tag B"",  etc  - I'm thinking of defining these ""triggers"" in a config file, ideally with some very simple logical syntax that would be i) easy to write even for (fairly)non-technical users & ii) sufficiently flexible to support as-yet unthought of use cases in the future - Do my ramblings make sense? Any example of this thing done well... essentially managing prompts with if/else based on user groups  Thanks"
Samhan Meta/Twitter Friend|2023-06-02 12:24:01|I haven’t done detailed calculations but it seems to me any such approach in practice will cost a lot more
Samhan Meta/Twitter Friend|2023-06-02 12:24:41|Check out airflow . You need a data orchestration framework.
Nirant|2023-06-02 12:24:47|I've used Dagster for chain and filter kinda operations. Works like a charm
Nirant|2023-06-02 12:24:49|Airflow should work too
Samhan Meta/Twitter Friend|2023-06-02 12:25:09|Nirant Bot is always faster 😁
Samhan Meta/Twitter Friend|2023-06-02 12:25:21|Has he already replaced himself 🤔
~ Sushant|2023-06-02 12:27:30|Thanks.. But for now..airflow is slightly overkill for me..  It's a single app I'm dogfooding with a subset of users to see how well it works...  Ultimately something like that would be needed
Nirant|2023-06-02 12:27:30|Any sufficiently fast typist human is indistinguishable from an AI Model 🤣
~ Sushant|2023-06-02 12:27:38|Thank you Checking it out
Chirag Jain|2023-06-02 12:27:47|just some feedback - This does not take into account sharding yet
Saurabh Karn Nyai|2023-06-02 12:35:52|That’s a million dollar question. If we keep just the performance in terms of quality away, it should totally be cheap to host it yourself as long as the base infrastructure to inference is good. So hosting it on Azure which is what MS is preaching might be one way. Even AWS now provides a enterprise grade LLM hosting and fine tuning support on sagemaker. I think inferencing is where most of the cost is. Maybe we need to do a costing benchmark across different modes of deployment options.
Saurabh Karn Nyai|2023-06-02 12:36:03|I can provide that for Laama and Vicuña on GCP
Samhan Meta/Twitter Friend|2023-06-02 12:36:42|I suspect the utilization level for GPU would need a certain scale. If your GPU is idle then it can’t be cheaper
Samhan Meta/Twitter Friend|2023-06-02 12:37:01|And if you spin it up on demand then cold start time increases
Saurabh Karn Nyai|2023-06-02 12:38:09|Yeah. There’s probably a threshehold you need to cross in terms of users to counter for cold start problems and all. But also the GPU availability across the globe is a bottleneck.
Saurabh Karn Nyai|2023-06-02 12:39:01|So depending on the size of model seeing if you want dedicated GPUs or something else that will start becoming a real question as well
Samhan Meta/Twitter Friend|2023-06-02 12:39:23|It’s not just that . OpenAI I suspect has a distillation system that benefits from scale and usage . That’s why turbo version drops a few months later. It’s difficult to replicate all this.
Samhan Meta/Twitter Friend|2023-06-02 12:40:13|And features like json output , adapters , state can be added by OpenAI over time making the case for self hosting even weaker on short term economic grounds.
Saurabh Karn Nyai|2023-06-02 12:40:43|Yeah. Totally possible!
Nilesh Agarwal Inferless|2023-06-02 12:41:44|If you get the storage layer is correctly built you can get the coldstart to couple of seconds
Nilesh Agarwal Inferless|2023-06-02 12:41:59|Which thereby makes the utilisation super high
Nilesh Agarwal Inferless|2023-06-02 12:42:28|Ideally like a serverless abstraction
Dr. Pratik Desai KissanGPT|2023-06-02 12:44:30|Only economical way I see possible, compared to turbo, is hosting on-premise on a6000. Cold start latency may disrupt use experience, even additional 2 seconds.
~ RISHAV|2023-06-02 12:45:09|Yes, we need to do all the processing without use of any external APIs.
~ Gaurav|2023-06-02 12:46:09|A single On premise can go down any time. Then you'd need redundancy.
Dr. Pratik Desai KissanGPT|2023-06-02 12:48:16|Of course, one day of A100 on aws is like 50M token of turbo. Having redundancy will be still cheaper
Samhan Meta/Twitter Friend|2023-06-02 12:50:37|Open AI / Microsoft are now building the highest possible standards of data security and compliance.
Nilesh Agarwal Inferless|2023-06-02 12:52:25|On Prem is cheaper, but the problem is once you buy the card , you have to also pay for network and it’s really hard to do Autoscaling if the QPS becomes fluctuating
Nilesh Agarwal Inferless|2023-06-02 12:53:26|For Tranining I would highly recommend On Prem
~ Gaurav|2023-06-02 12:54:05|Agreed. Could use Q Blocks instead for more A100s in same dollar (sorry for self promo lol) but i think it can help for such a case where you want to scale out and at the same time be cost effective and don't want to be on-prem.
Dr. Pratik Desai KissanGPT|2023-06-02 12:54:31|Once you have that many daily users, yes, ~50k request per day. There aren’t many production use cases.
Samhan Meta/Twitter Friend|2023-06-02 12:56:28|Yeah you need things like infini band networking , custom racks with NVLink. Redundancy . It all probably adds up .
Nilesh Agarwal Inferless|2023-06-02 12:56:40|Yes , there are cheaper players you can get cheats GPUs , if you at willing to do the dev ops yourself you can significantly get the cost down
Samhan Meta/Twitter Friend|2023-06-02 12:57:26|How many tokens per second can an A100 do with falcon ? And how many do you need
Samhan Meta/Twitter Friend|2023-06-02 13:00:07|https://www.youtube.com/watch?v=Rk3nTUfRZmo The infra MS has built is crazy
Samhan Meta/Twitter Friend|2023-06-02 13:00:21|I don’t think this can be easily replicated
Rajesh RS Generative AI WhatsApp Group|2023-06-02 13:04:28|This is a great video
Samhan Meta/Twitter Friend|2023-06-02 13:05:09|Microsoft has built up a good 6-12 months lead all things put together
Dr. Pratik Desai KissanGPT|2023-06-02 13:05:23|This is a great question. If Running a larger model Falcon 40B or Llama 65B on A100s not giving me 200-300 tps, then the latency will be killer for end users in production environment where turbo can return 1000tokens via API in less than 2 seconds. ‎[6/2/23, 13:07:18] Dr. Pratik Desai KissanGPT: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-02 13:09:13|I’m sure a100 won’t be more than 80, that’s slow too. And this is q4 to accommodate on single GPU.
Samhan Meta/Twitter Friend|2023-06-02 13:10:44|As I suspected
Samhan Meta/Twitter Friend|2023-06-02 13:11:33|Then the question is also if OpenAI is eating losses
Dr. Pratik Desai KissanGPT|2023-06-02 13:11:41|Nothing in near future beating Turbo, and when we figure out OAI will reduce price of GPT4.5 turbo to that level
Samhan Meta/Twitter Friend|2023-06-02 13:12:00|Yup . Absolutely masterful strategy 🙇🏽
Aishwarya Goel Inferless 5s for 5G|2023-06-02 13:12:03|Why? What about scaling use-cases?
Samhan Meta/Twitter Friend|2023-06-02 13:13:48|Speculation- turbo only has 1-2 B parameters and maybe further quantized
Samhan Meta/Twitter Friend|2023-06-02 13:15:07|OpenAI has published it themselves that 1.5B versions of GPT are not that bad
Dr. Pratik Desai KissanGPT|2023-06-02 13:16:01|In terms of using OSS models. May be my mistake using the word use cases. Probably production applications using OSS models at this scale.
Dr. Pratik Desai KissanGPT|2023-06-02 13:16:51|Still it has higher score than 65B LLaMa
Dr. Pratik Desai KissanGPT|2023-06-02 13:18:17|Also, excessive RLHF help me to trust the turbo inference in production. I’m scared to death with LLaMa hallucinating in front of Farmers.
~ Ankur Khandelwal|2023-06-02 13:18:30|Do try guardrails-ai.. You can run the group of prompts in sequence based on the open ai results/
~ Divya|2023-06-02 13:50:59|Check out zero shot Nas. Quite a good paper
Sandeep Srinivasa RedCarpetup|2023-06-02 13:56:22|https://arxiv.org/abs/2301.11300  This one ? I couldn't find any reference to spam classification, etc
~ Divya|2023-06-02 13:57:08|It can used for classification problems as well. Quite efficient
~ Ashutosh Kumar|2023-06-02 15:38:37|A question on deploying a web app  on ai -  * does anyone know how to make heroku work with indian credit card? * if not possible, what is the best alternative (tried render, koyeb- any other suggestion ?) * or should i grow up and use aws for hosting generative ai apps?
Shimanta Generative AI|2023-06-02 15:39:50|You can try fly.io and railway.app
~ Jatin|2023-06-02 15:44:56|Vercel is pretty seamless if you are using Nextjs
Abhinav Verma Longshot.ai|2023-06-02 15:46:10|I mean they created it
Swastik Banerjee|2023-06-02 15:48:17|Azure/ DigitalOcean?  I’ve hosted genai webapps in both of these; easy to deploy
Swastik Banerjee|2023-06-02 15:49:14|can hook the build action directly to your github repo
Swastik Banerjee|2023-06-02 15:49:46|though this is pretty elementary; I’m not sure if you were asking from a competitive overhead sort of angle , sorry
Kashyap Kompella|2023-06-02 15:57:06|‎You added Kashyap Kompella
~ prthamesh|2023-06-02 16:51:52|+1 for fly and railway, easier hosting (can do cd via GitHub actions).  - If you plan to use db in fly, slightly complex setup since they have semi-automated pg hosting (that’s what they call) - Both places you can run servers under $5 for free each month
Aishwarya Goel Inferless 5s for 5G|2023-06-02 17:09:21|Quite an interesting thread on migrating from fly to render. Check it may help  https://twitter.com/sebastianszturo/status/1663116343829483520?s=46&t=DtzjOgXVCgwDUiK5fng9Mw
Prayank Swaroop Accel|2023-06-02 18:37:32|Has anyone been able to increase GPT4 rate limits ? Any tips ?
Nirant|2023-06-02 18:42:16|Azure OpenAI, pay for dedicated Gpt3.5 and you get very generous GPT4 limits too
Kartik Mandaville|2023-06-02 18:43:29|no, they don't increase
Kartik Mandaville|2023-06-02 18:43:34|how to get approved for GPT4?
Nitesh Letsdive.io|2023-06-02 18:50:19|Try chaining the prompts. We are doing that.
Sandeep Srinivasa RedCarpetup|2023-06-02 19:38:33|Is anyone using GPTCache here ?  It is doing an exact match ?  Hey Sandeep, the ExactMatchEvaluation is actually just:  ```if cached_data.question == user_prompt.question```
Rohit Aggarwal|2023-06-02 19:40:56|think they do both. ExactMatch and SemanticMatch
Ambarish Ganguly|2023-06-02 20:58:28|Sckit learn cosine similarity and qdrant cosine similarity seems tobe quite different
Ambarish Ganguly|2023-06-02 20:59:12|Qdrant cosine similarity is not giving expected results but sklearn cosine similarity gives good results 👍
Ambarish Ganguly|2023-06-02 20:59:41|Anybody facing such difficulty and solving them would be great to know
Nirant|2023-06-02 21:23:23|All vector stores approximate distance for performance, scikit is exact search
Sumod K Mohan|2023-06-02 21:42:39|Along with what Nirant said, most of them will have an option to set search to exact or approx. Be aware exact will lead to lower qps/latency. Pretty sure qdrant too will have it
Ambarish Ganguly|2023-06-02 21:43:08|Yes that's what I was after
Ambarish Ganguly|2023-06-02 21:44:54|Yes it has an exact param
Ambarish Ganguly|2023-06-02 21:44:59|Thanks
Ambarish Ganguly|2023-06-02 21:49:07|Exact true unfortunately did not help
Ambarish Ganguly|2023-06-02 21:49:23|Will find out more
Edgar Monis Mumbai WHO|2023-06-02 21:51:19|Could be that you're embeddings are not normalised?
Edgar Monis Mumbai WHO|2023-06-02 21:52:02|If they're not normalised you should be using l2 instead of cosine
Sumod K Mohan|2023-06-02 21:54:43|Is it just the scores are different or are also your order different (btw scipy vs qdrant). If order is same, it's just a scale difference due to normalisation. If order is different, then see if you are doing some filtering type of thing in your setup.
Edgar Monis Mumbai WHO|2023-06-02 21:54:44|Question:  Has someone hacked ggml llama to just get sentence embeddings ? Maybe after taking the head off ?
Edgar Monis Mumbai WHO|2023-06-02 21:55:19|Asking for local embedding reasons
Sumod K Mohan|2023-06-02 21:55:55|Don't know much about Qdrant internals, so can't help much more.
Ambarish Ganguly|2023-06-02 21:59:54|I am using Sentence Transformer embeddings When adding to Qdrant we would specify the distance as Cosine
Abhinav Verma Longshot.ai|2023-06-02 22:00:21|Which model?
Ambarish Ganguly|2023-06-02 22:00:29|Therefore would it not do it.Let me check that
Ambarish Ganguly|2023-06-02 22:01:08|All minilm l6 v2
Abhinav Verma Longshot.ai|2023-06-02 22:01:28|This is normalized
Edgar Monis Mumbai WHO|2023-06-02 22:02:46|https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  It seems like it isn't normalised
Abhinav Verma Longshot.ai|2023-06-02 22:04:59|This is weird. Because I think last year someone asked nils Reimer this question and he had mentioned that you can use cosine for this. So I assumed it was.  Even in sbert docs you can verify this I believe
Sandeep Srinivasa RedCarpetup|2023-06-02 22:07:57|Qdrant does normalisation internally when adding vectors I believe.  Scikit - u may have not done.
Ambarish Ganguly|2023-06-02 22:26:13|You are correct
Ambarish Ganguly|2023-06-02 22:26:29|Let me do DOT similarity
Simrat Hasura|2023-06-02 22:34:46|I’m not sure of qdrant but there must be some way to retrain the index to refresh the clusters of index   I think you should be able to define how many clusters to search around query too
Simrat Hasura|2023-06-02 22:36:37|Does this work 🥹
Sandeep Srinivasa RedCarpetup|2023-06-02 22:36:39|if ur result is better with non-normalized vectors, try reducing the size of chunking. intuitively non-normalized cosine product is due to the shorter vectors.
Rohit Aggarwal|2023-06-02 22:38:17|I've always wondered what's a good chunk size for vectors.. has anybody tested with different chunk sizes for RAGs?
Ravi Theja|2023-06-02 22:39:42|[PHONE] can comment on this I guess as they have done quite good number of experiments for fixing chunk size.
Abhinav Verma Longshot.ai|2023-06-02 22:58:40|Try a smaller number and go bigger
Rohit Aggarwal|2023-06-02 22:59:04|so, just hit & trial then?
Abhinav Verma Longshot.ai|2023-06-02 22:59:56|Yes. Few things to keep in mind  - try to add Metadata if possible in your chunks as well.
Abhinav Verma Longshot.ai|2023-06-02 23:00:16|Different docs chunk different
~ Hemant Khandelwal|2023-06-03 01:39:44|Is there a way to use any AI technique to see how some of YT channels do in setting their narrative? Which line is dominant and which one gets ignored. Both pro- or anti- on political topics.  I see that in many WhatsApp groups, political emotions are driven a lot by channels that folks watch regularly. So this might be interesting to know factually the dominant narrative.
Abhinav Verma Longshot.ai|2023-06-03 01:41:56|You can start by identifying it yourself. Then find a pattern. Then try automate it
~ Santhosh K|2023-06-03 06:41:33|Can you give some more details ?
Shahul Kaggle Kernel GM|2023-06-03 09:50:17|LLMs can help in this. But would need to formulate a paradigm first as a solution then use LLM as a tool to achieve the objective.
~ J|2023-06-03 10:22:57|‎~ J left
Nitesh Letsdive.io|2023-06-03 10:49:08|Happy to help! Can you DM?
Ambarish Ganguly|2023-06-03 10:50:17|Update: Strangely enough changing the prompt worked
Ambarish Ganguly|2023-06-03 10:50:22|in Qdrant
~ Ansh Agarwal 👩🏽‍🚀|2023-06-03 10:54:12|is there a way to train our own model with the data we have?
~ Ansh Agarwal 👩🏽‍🚀|2023-06-03 10:54:13|does dalai ai does it?
Nirant|2023-06-03 10:56:54|Dalai is a local execution/inference and only works with Llama to the best of my knowledge. Has that changed?
~ Ansh Agarwal 👩🏽‍🚀|2023-06-03 10:57:50|how about smol ai?
~ Ansh Agarwal 👩🏽‍🚀|2023-06-03 10:58:24|we have this huge dataset of case filings & want to use it to build our own model
Nirant|2023-06-03 11:01:41|smol is not an AI model, is a clever way to call GPT4 APIs
~ Ansh Agarwal 👩🏽‍🚀|2023-06-03 11:03:15|oh got it ‎[6/3/23, 11:03:43] Nirant: ‎image omitted
Kartik Mandaville|2023-06-03 11:11:55|Doesn't Azure OpenAI also send data to OpenAI and keeps it for 30 days? you don't actually own the servers right?
Nirant|2023-06-03 11:12:46|Azure OpenAI also has dedicated deployment option. Your requests never touch OpenAI is the promise in that case
Saurabh Karn Nyai|2023-06-03 11:12:46|I think the terms say that they keep data on their severs for 30 days for safety and compliance audits
Saurabh Karn Nyai|2023-06-03 11:12:55|Exactly
Nirant|2023-06-03 11:13:08|And they promise to not use that data for training
Dev Aggarwal|2023-06-03 11:13:27|You can opt out of this, in both openai and azure
Saurabh Karn Nyai|2023-06-03 11:13:59|We are still on openai. Should switch to Azure.
Dhruv Anand|2023-06-03 11:14:00|Anyone from here at the GenAI hackathon in mumbai today? Please react with a 👍 to this message
Saurabh Karn Nyai|2023-06-03 11:14:45|All the best to all participating! Send pictures 🥳
Dr. Pratik Desai KissanGPT|2023-06-03 11:15:49|Been using Azure OpenAI for a month Now. Every individual deployment has max 120 transaction per second limit, which is fine in most cases, but you can roll out multiple instances, and shuffle.
Saurabh Karn Nyai|2023-06-03 11:18:52|oh nice. That way we can serve more requests. Nice.
Dr. Pratik Desai KissanGPT|2023-06-03 11:24:25|Forgot to mention but I’m using Turbo and not GPT4 from Azure OpenAI. Been on waitlist for 5+ weeks and they are saying GPT4 access is very difficult right now due to GPU shortage.
Saurabh Karn Nyai|2023-06-03 11:26:59|GPU shortage I have also heard from AWS side
Rajesh RS Generative AI WhatsApp Group|2023-06-03 11:27:36|The requests / minute for GPT4 is 18 on Azure OpenAI service right now. That's a fairly small number of requests
Saurabh Karn Nyai|2023-06-03 11:27:59|I think that's why from an inference side, I believe we will have much smaller models which can potentially be hosted locally on the user's device and the ecosystem is available as API interfaces and how a user wants to be connected to internet or access govt. services is something that they get done via these LLM assistants.
Saurabh Karn Nyai|2023-06-03 11:28:03|Gorilla kind of thing ‎[6/3/23, 11:28:15] Saurabh Karn Nyai: ‎image omitted
Saurabh Karn Nyai|2023-06-03 11:28:31|The power of Gorilla is that it's trained to do better tool selection
Saurabh Karn Nyai|2023-06-03 11:29:18|in legal and rights and entitlement space as well, these tools e.g. all the acts in India or a particular judgement may become available to these LLM legal assistants
Dr. Pratik Desai KissanGPT|2023-06-03 11:29:49|So you can have two deployments in each of the 4 data centers that have OpenAI services. 144 requests per second are still decent. Of course, you need the access first.
Rajesh RS Generative AI WhatsApp Group|2023-06-03 11:31:14|Agreed, that's not bad
Rajesh RS Generative AI WhatsApp Group|2023-06-03 11:32:21|Anyone deploying models like Falcon on their (business) applications? What is the performance like?
Nirant|2023-06-03 11:35:39|I just got it running in Colab on A100: https://colab.research.google.com/drive/1Fjwq3GPCqNTlWJG2T07vIRJw4L9_nkfj?usp=sharing
Nirant|2023-06-03 11:36:08|(Official HF Instructions are broken)
Abhinav Verma Longshot.ai|2023-06-03 11:37:03|Yes needed to install more dependency than what HF mentioned
Nirant|2023-06-03 11:39:05|And `pipeline` is also broken if you don't load the model separately
Abhinav Verma Longshot.ai|2023-06-03 11:40:59|What's the context token limit on falcon?
Rajesh RS Generative AI WhatsApp Group|2023-06-03 12:04:07|Pretty cool Nirant! These are premium Colab instances? What are the charges like? ‎[6/3/23, 12:05:39] Nirant: ‎image omitted
Sudharshan GenAI|2023-06-03 12:06:31|https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595  Gold -  Logic tests on various open LLMs
Sudharshan GenAI|2023-06-03 12:06:41|And a nice comparison
~ Madhav Singhal|2023-06-03 15:54:49|‎~ Madhav Singhal was added
Divya Jain|2023-06-03 15:54:49|‎Divya Jain was added
Ambika Computational Mama|2023-06-03 15:54:49|‎Ambika Computational Mama was added
Sudharshan GenAI|2023-06-03 12:28:09|More context - https://www.reddit.com/r/LocalLLaMA/comments/13yfask/manticore13bchatpygguanacoggmlq4_0_americas_next/
Rajesh RS Generative AI WhatsApp Group|2023-06-03 12:53:56|Yeah, Redis does get expensive - more than anything hidden costs of PaaS in the cloud get me.
Rajesh RS Generative AI WhatsApp Group|2023-06-03 12:55:39|Fantastic
Sandeep Srinivasa RedCarpetup|2023-06-03 12:55:45|To be fair, this is a High Availability setup in redis cloud.
~ Sanjeed|2023-06-03 13:51:55|Interesting open source tool - Ul visual tool for LangChain  https://twitter.com/FlowiseAI/status/1646176565691023360?t=rBUfyGkbP3_o9IjDc4YRkw&s=19
Ambika Computational Mama|2023-06-03 14:04:54|‎Ambika Computational Mama requested to join
~ Kartheek Akella|2023-06-03 14:05:12|"Any best resources for creating charts/graphs from data, open-source ""Chart-GPT"" resources especially python based would be great. Have tried chartgpt(dot)dev, looking for alternatives."
Rounak Datta Hackathon Winner|2023-06-03 14:15:24|D3.js. They have Python bindings as well
Belong Saiteja|2023-06-03 14:28:32|Chart.js is also a good option for basic garphs. We implemented something where ChatGPT generates python code that can take query object as input and output chart.js params which can be directly passed onto Frontend.
Nirant|2023-06-03 14:34:12|Consistent Policy around Events:   All events in India to be published here: https://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml  The only event announced is a Mixer from Wyse  You can submit the event here: https://docs.google.com/forms/d/e/1FAIpQLSdWA6lJaw28VFDRUX_q6kj9xZXECkvrE2DgWnLaJDRy1ifjkw/viewform  Both are updated at https://nirantk.com/community as well.
Shan|2023-06-03 15:23:17|I think if you have the code interpreter plug-in enabled that’s the best way to go? ‎[6/3/23, 15:24:47] Suhas Motwani: ‎image omitted ‎[6/3/23, 15:24:48] Suhas Motwani: ‎image omitted ‎[6/3/23, 15:24:49] Suhas Motwani: ‎image omitted ‎[6/3/23, 15:24:50] Suhas Motwani: ‎image omitted ‎[6/3/23, 15:24:52] Suhas Motwani: ‎image omitted ‎[6/3/23, 15:24:52] Suhas Motwani: ‎image omitted
Samhan Meta/Twitter Friend|2023-06-03 16:16:39|https://youtu.be/slEMhl1U1_s
Samhan Meta/Twitter Friend|2023-06-03 16:34:52|https://youtu.be/BwNdj4zNEuk
Samhan Meta/Twitter Friend|2023-06-03 16:34:56|Tbis stuff is wild 😁
Samhan Meta/Twitter Friend|2023-06-03 16:43:01|https://youtu.be/DP9EY4xMlTE
Nirant|2023-06-03 16:51:40|This is one way to convert me into a copyright activist. That song got butchered so bad.
Samhan Meta/Twitter Friend|2023-06-03 16:52:03|I really like this one
Swastik Banerjee|2023-06-03 17:03:58|3:35 to 4:05 is 🤐
Samhan Meta/Twitter Friend|2023-06-03 17:04:16|There’s a trump Coldplay cover
Samhan Meta/Twitter Friend|2023-06-03 17:04:49|https://youtu.be/omRTS-XsEGU
Samhan Meta/Twitter Friend|2023-06-03 17:05:21|Listen from 3:00 😁
Ravi Srinivasan|2023-06-03 18:41:37|i found this very good!
Rajesh RS Generative AI WhatsApp Group|2023-06-03 18:56:17|Brilliant. The Frank Sinatra cover of Bon Jovi is even better. How did they build this?
~ Blessin Varkey|2023-06-03 18:57:19|Damn!
Dr. Ashith Generative AI WA Group|2023-06-03 18:57:56|https://www.youtube.com/watch?v=rNKJcoSB8YU  i found this also very good
Aashay Sachdeva MPL Data Scientist|2023-06-03 19:31:27|Is it possible to use a different tokeniser while training a LLM model cia LoRA/QLoRA ? I am assuming I will have to make changes to the model as well. If anyone has any resources on this that would be great.
Samhan Meta/Twitter Friend|2023-06-03 19:57:27|I don’t know 😁
Chirag Jain|2023-06-03 20:23:58|by doing that you might be effectively throwing away all the learning in the embeddings layer  adding tokens during finetuning process is still okay
Abhishek Mishra|2023-06-03 22:17:36|Best diagram based implementations exist via mermaid js code generation. There's a plugin for that as well in chatGPT plus.
Aashay Sachdeva MPL Data Scientist|2023-06-03 22:31:20|Yeah,  wanted to understand if there is a way to mitigate that. Thanks.
Kaushik Bokka|2023-06-04 07:54:43|Hey folks! Welcome [PHONE] 👋🏼 He’s part of the ML team at Replit!
Shan|2023-06-04 08:42:27|Is there a better resource to prompt engineering than https://github.com/dair-ai/Prompt-Engineering-Guide that I may be missing? I find it pretty good along with a list of papers and seems to be kept fairly up to date. But who knows what else I might be missing? Any further pointers appreciated
Nirant|2023-06-04 09:18:56|nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Saurav Tomar GenerativeAI WA Group|2023-06-04 10:00:06|https://github.com/brexhq/prompt-engineering
Harsh Koo|2023-06-04 10:50:24|One idea Id like your inputs on is the following; Context; Clipdrop has these style presets it applies to a prompt for SD.  If one used LoRA (eg https://replicate.com/blog/lora-faster-fine-tuning-of-stable-diffusion) to fine-tune on styles say; - Ravi Verma art - Mughal miniatures - Bandhni/Bandhej - Sanjay Leela movie sets  The above styles could be used as uniquely Indian presets in a Clipdrop like setting?  Is this directionally a feasible idea?
Pratik Bhavasar|2023-06-04 11:12:59|Is there a reliable way to inject knowledge into a RLHF trained model?
Pratik Bhavasar|2023-06-04 11:13:06|For text generation
Nirant|2023-06-04 11:13:53|What does 'inject' mean? What use cases do you've which an in-context, dynamic prompt does not cover?
~ Anushka|2023-06-04 11:15:57|‎You added ~ Anushka
Nirant|2023-06-04 11:17:24|2048, with a 65K vocab  From: https://huggingface.co/tiiuae/falcon-7b/blob/main/tokenizer_config.json  TIL Huggingface encourages this tokenizer config, so we can just look this up for most FOSS models.
Nirant|2023-06-04 11:19:47|Falcon is also trained with Alibi Position Encoder/Linear Attention (https://arxiv.org/abs/2108.12409v2) — so you can finetune and increase context window as well.   Source: Chetanya, Alexa Prize Winner and Stanford Lecturer, https://twitter.com/ChetanyaRastogi/status/1665118748095725571
Ambarish Ganguly|2023-06-04 13:10:21|Qdrant not writing to storage , therefore works fine it is running , but data cannot be retrieved once stopped and restarted
Ambarish Ganguly|2023-06-04 13:10:27|Did anybody face this problem
Ambarish Ganguly|2023-06-04 13:10:53|In 1 machine, I am having this problem while in the other follows the expected behaviour
Nirant|2023-06-04 15:27:25|Since this is device, config specific — do you want to ask this on the Qdrant Discord instead? https://discord.gg/qma5DQkH
Ambarish Ganguly|2023-06-04 17:33:54|Sure
Pratik Bhavasar|2023-06-04 18:06:55|Imagine making QnA engine on the No moat article. You have chunk & indexed the article.  User asks why does google have no moat.. retrieval might match some or no chunks because not all chunks mention word google and moat, leading to inferior result. The ideal answer has to be based on full context of the article. If we could add knowledge to the model, we can skip retrieval component and generate answers from longer context across articles. Apart from this OpenAI would like to update the existing GPT with data post 2021 rather than again train with full data. Technical term for this problem is continual learning. I am not sure if there is a solution to this
Samhan Meta/Twitter Friend|2023-06-04 19:05:44|Fine tuning on enough instances of such information is  what’s ideally needed. But it doesn’t work always from what I’ve read
Samhan Meta/Twitter Friend|2023-06-04 19:05:57|Current techniques need a lot of data to imbibe something
Samhan Meta/Twitter Friend|2023-06-04 19:06:26|Embedding etc is just a faster hack
Nirant|2023-06-04 19:13:04|Model Editing methods use logits and alter or update meaning of tokens.    This paper talks about limitations of those methods, so check it's citation graph for what they can do: https://arxiv.org/abs/2305.17553
Samhan Meta/Twitter Friend|2023-06-04 19:07:22|Hierarchical chunks - title , article summary , then children - paragraphs and so on. This is essentially a search engine type problem.
Samhan Meta/Twitter Friend|2023-06-04 19:08:27|If I ask “who wrote the google no moat article” it won’t match any chunk per se
Samhan Meta/Twitter Friend|2023-06-04 19:20:44|The interesting thing is the models do learn inside the context. But then it can’t be stored in the model.
Samhan Meta/Twitter Friend|2023-06-04 19:21:02|Increasing context window is a good hack too ‎[6/4/23, 19:29:51] Prayank Swaroop Accel: ‎image omitted
Prayank Swaroop Accel|2023-06-04 19:30:40|Fine-tuning here is not a new model, just fine tuning on top of GPT3.5/4.
~ tushar|2023-06-04 19:32:14|what would this fine tuning involve?
Prayank Swaroop Accel|2023-06-04 19:33:25|"Following the guide here : https://platform.openai.com/docs/guides/fine-tuning  {""prompt"": ""<prompt text>"", ""completion"": ""<ideal generated text>""} {""prompt"": ""<prompt text>"", ""completion"": ""<ideal generated text>""} ..."
~ tushar|2023-06-04 19:34:27|it's for gpt-3. Not available for 3.5/4
Prayank Swaroop Accel|2023-06-04 19:36:06|I'm not the expert here, hence the request for help
Nirant|2023-06-04 19:39:02|You can't finetune GPT3.5/4  text-davinci-003 can be finetuned, but terribly expensive and not worth the money  You don't really hit RateLimitErrors if you do Retrieval well and don't stuff the context too much
Prayank Swaroop Accel|2023-06-04 19:40:51|Thanks. Looking for guidance from anyone who has made customer support both or Q&A bot in production
Samhan Meta/Twitter Friend|2023-06-04 19:41:45|I’m working on this for work. This is not as easy as it looks. Like the steps aren’t wrong or anything but it needs a lot of work to make it work properly.
~ Kp|2023-06-04 19:42:06|I'm new to this but wouldn't semantic search be better than finetuning?
Samhan Meta/Twitter Friend|2023-06-04 19:42:49|No not really. Fine tuning can make deeper connections inside what the model knows. Vanilla embeddings are very fuzzy
~ Kp|2023-06-04 19:43:04|For this case?
Prayank Swaroop Accel|2023-06-04 19:43:30|No semantic search is good once you have the answers in the DB .. but customer support can be fluid ..
Samhan Meta/Twitter Friend|2023-06-04 19:44:48|It depends on complexity of the task as well. For eg coding
Samhan Meta/Twitter Friend|2023-06-04 19:45:51|If we are just retrieving snippets and showing that’s a search engine.
~ Aravind|2023-06-04 19:56:19|‎~ Aravind requested to join
Samhan Meta/Twitter Friend|2023-06-04 19:58:02|If a customer is valuable enough spending a few dollars on them for a case is worth it
~ Rohit|2023-06-04 20:04:56|is bard doing a version of this (embedding lookup) or are they doing frequent retraining and/or fine-tuning?
Nirant|2023-06-04 20:07:50|None of these. It's just a more recent freeze of the weights and data. And combined with Internet search, looks like it's recent
Pratik Bhavasar|2023-06-04 20:14:25|Yup same thoughts!
Pratik Bhavasar|2023-06-04 20:16:56|Thats the costly slow backup option for sure. Like in the problem statement I gave we can just match article titles and then add the whole article in the context for answering.
Pratik Bhavasar|2023-06-04 20:22:36|A related question to this  How does Microsoft copilot update their chat models for different product? (what they showed in demo 2 months back) - fix bad generations - new type of queries - Microsoft x(powerpoint, word) feature updates - the func to be executed changes(name, params etc)  Do they just do retrieval over very well-defined docs OR fine tune? If they get failure cases every day and want to fix asap, making sure retrieval works seems like the only way to me. Thoughts?
Nirant|2023-06-04 20:41:08|Changing sampling alone goes a long way for code updates :)
Shan|2023-06-04 20:45:00|That’s not how NLP models work. You cannot dynamically add new training data to transformers. You may be able to hack some params using some “helper” models but updating the original model is not possible.
Pratik Bhavasar|2023-06-04 20:58:25|Did not get you!?
Pratik Bhavasar|2023-06-04 20:59:46|Hoping for some breakthrough!
Shan|2023-06-04 21:06:16|The only paper I found is https://openreview.net/pdf?id=yd7uyR9_0iU so the hope is alive!
Shan|2023-06-04 21:09:12|https://aclanthology.org/2022.conll-1.4.pdf the non-anonymous one.
Dhruv Naik|2023-06-04 21:16:52|https://arxiv.org/abs/2104.08164 Related
Samhan Meta/Twitter Friend|2023-06-04 21:38:17|So there’s is a paper from deep mind called RETRO that shows a way to do it. If someone can figure out a way to hack this into present models . But it’s basically a serious research question
Samhan Meta/Twitter Friend|2023-06-04 21:39:14|I think RETRO , Toolformer , WebGPT , LoRA these papers have some solid ideas. If combined well can solve a lot of present day issues
Abhinav Verma Longshot.ai|2023-06-04 21:40:31|Webgpt is what chatgpt with browsing is
Samhan Meta/Twitter Friend|2023-06-04 21:40:45|Yeah but ppl have said it doesn’t work well
Abhinav Verma Longshot.ai|2023-06-04 21:40:57|They've made some improvements
Diptanu Choudhury FB AI|2023-06-04 21:41:02|Just read through your article, looks great!
Nirant|2023-06-04 21:45:26|Azure is 3x faster than OpenAI for Gpt3.5   Source: https://twitter.com/dzhng/status/1665250854922747907?s=48
Abhinav Verma Longshot.ai|2023-06-04 21:46:49|Do they mean turbo? That is anyways really fast. Any faster they might as well  read my thoughts
Abhinav Verma Longshot.ai|2023-06-04 21:47:13|I've heard azure gives better uptime as well
Ramsri Goutham|2023-06-04 22:17:05|Can confirm this by using it in prod. But the default rate limits for some are low. Like chatGPT is 300 / min as opposed to 3500/min with OpenAI. But with azure I thinkyou get 99.99% uptime which is a big plus
ashish Acgt01 Twitter|2023-06-04 23:04:00|"Q. for Nirant , others : are you aware of papers/efforts on continuously ""online"" learning LLMs ?  Wikipedia, pubmed, arxiv : everyday new data is being added  Have there been efforts to crawl these pre- training dataset updates at some frequency (15 days e.g.) and add this delta (relative to the last model update) to the pretraining, and revise model weights to be used for inference based on that ?"
Nirant|2023-06-04 23:40:34|Look at Never Ending Language Learning, Never Ending Image Learning projects. They've been running for couple of years.
Satish DeepHack Sponsor|2023-06-05 00:19:12|https://www.cloudskillsboost.google/paths/118  Google just dropped a learning path for Generative AI on their training site. ‎[6/5/23, 08:25:00] Nirant: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-05 08:25:30|That was so quick.
Shimanta Generative AI|2023-06-05 08:32:53|Llama cpp is doing 40tok/s inference for 7B model on a Macbook M2 Max. 24tok/s with 13B and 5tok/s with 65B models.   https://twitter.com/natfriedman/status/1665402680376987648?s=46&t=WT1iAtjftW-5_e62F8FZTg
Shimanta Generative AI|2023-06-05 08:35:41|Noob question: does finetuning affect inference speeds?
~ Ankit Sharma|2023-06-05 08:36:28|What tokenization method works best for Indic languages as the character level tokinization has higher token count for a Hindi sentence?
Abhinav Verma Longshot.ai|2023-06-05 08:36:57|Sentencepiece
Abhinav Verma Longshot.ai|2023-06-05 08:37:06|That's a good starting point
Shubham Sharma 2012C6|2023-06-05 08:43:59|What about spacy? How do the two compare
Shubham Sharma 2012C6|2023-06-05 08:44:41|SpacCy*
Pratik Bhavasar|2023-06-05 08:44:53|Nope
Abhinav Verma Longshot.ai|2023-06-05 08:47:45|Spacy I'm not sure.
Abhinav Verma Longshot.ai|2023-06-05 08:48:35|For tokenization its better to be subword level than word level
Abhinav Verma Longshot.ai|2023-06-05 08:49:22|Spacy would do word level.
Nirant|2023-06-05 08:50:16|*spaCy is word level tokenisation, so if you're doing it for humans — perhaps among the best. Right there with Stanza (Stanford).   For anything like training models, sentencepiece mentioned by Abhinav [PHONE] is a great first candidate. I'd also look at other subword tokenizers
Pratik Bhavasar|2023-06-05 08:55:35|What’s your goal?
Saurav Tomar GenerativeAI WA Group|2023-06-05 09:00:00|GM fam, Anyone has the link to the doc shared in this group which had the summary of all recent discussions ?
Nirant|2023-06-05 09:24:52|Did you mean this?   https://docs.google.com/document/d/1Wnw-vS9lATKTRAdEPxRm2uKgZlk4BKEmi7b8DL83NPs/edit#
Saurav Tomar GenerativeAI WA Group|2023-06-05 09:25:46|Yes, thanks.
Nishant Wyse|2023-06-05 11:45:04|Is there any Event link from where I can register for this event ??
Saiyam Wyse|2023-06-05 11:45:34|https://lu.ma/fvm2odkj Yes here it is
Swastik Banerjee|2023-06-05 11:53:47|GPT-3.5 in ChatGPT now points to ```…/?model=text-davinci-002-render-sha```   They are prioritising security over normal ```text-davinci-003``` or am I missing something here? ‎[6/5/23, 11:56:43] Swastik Banerjee: ‎image omitted
Dr. Ashith Generative AI WA Group|2023-06-05 12:00:30|its been like that since April as far as i can remember
Kartik Mandaville|2023-06-05 12:01:20|Is there a good source of use cases of GenAI and users from India? As in what companies are building? what traction?
Swastik Banerjee|2023-06-05 12:04:58|Was it not ```text-davinci-003``` or ```gpt-3.5-turbo``` ?
Dr. Ashith Generative AI WA Group|2023-06-05 12:15:50|yeah it was using turbo but they changed to 002 after GPT4 rollout i think
~ Meera Sundar|2023-06-05 14:57:13|‎~ Meera Sundar left
Sudharshan GenAI|2023-06-05 13:38:48|https://aviary.anyscale.com/  Prolly the best app to test LLMs. From Goku Mohandas and team
Sudharshan GenAI|2023-06-05 13:40:07|https://github.com/ray-project/aviary/
Kaushik Bokka|2023-06-05 13:40:21|No sir, it’s by Anyscale
Sudharshan GenAI|2023-06-05 13:41:17|Ah my bad, but still a good resource
Kaushik Bokka|2023-06-05 13:42:57|haha definitely
Shimanta Generative AI|2023-06-05 13:44:38|[PHONE] I happened to notice this as well. Check this, might help
Shimanta Generative AI|2023-06-05 13:45:03|Not a different model I believe if we go by the analysis
~ Ansh Agarwal 👩🏽‍🚀|2023-06-05 14:27:28|https://twitter.com/bigansh/status/1665643668605378560
Ashfakh GenerativeAI WA Group|2023-06-05 15:54:02|Anyone here who has run one of these open source LLMs in cloud with a webserver attached to it? context : I'm trying to run an open source LLM, (preferring falcon 40B) in aws using sagemaker and HF inference container (https://huggingface.co/blog/sagemaker-huggingface-llm) falcon 7B is giving me an error cause of a bug in the container init, so would love to discuss with people who have already done it.
Aashay Sachdeva MPL Data Scientist|2023-06-05 16:03:58|[PHONE] has built something similar for his company
Abhinav Verma Longshot.ai|2023-06-05 16:09:46|Are you having an issue loading the model?
Ashfakh GenerativeAI WA Group|2023-06-05 16:12:32|Nope. I was successfully able to do this in my local, I can replicate that on ec2, but I wanted to do it via sagemaker cause of better infra support.  The issue is when I’m running the inference container, for falcon, it’s giving me an error because it can’t run some configuration code inside the container without a flag. And in case of llama, it seems to be a tokenizer issue. Still debugging.
Shashank Generative AI Group|2023-06-05 16:47:48|Sam Altman, IIIT-D, Delhi, Thursday.   https://twitter.com/IIITDelhi/status/1665634578453897216
~ Shobhit Jaipurkar|2023-06-05 16:50:52|Tickets unavailable it says 🫡
Shashank Generative AI Group|2023-06-05 16:54:14|yeah, i got some waitlist.   it's less than 20 min from my home 😅
Naman Maheshwari Nimblexbox|2023-06-05 16:59:33|I have a ticket for this but I'm in Chennai and won't be able to make it. Happy to give it away to anyone from Delhi – can change the name & details on Eventbrite.
Prashant Singh|2023-06-05 17:00:56|Dibs
~ Diwank|2023-06-05 17:37:30|‎You added ~ Diwank
Prashant Singh|2023-06-05 17:49:38|Apologies for posting job here. I wasn't aware it's against the protocol
Abhinav Verma Longshot.ai|2023-06-05 18:10:58|Guys one question to people using cohere models in production. Specifically the embedding and rerank models.  When did the new pricing come into effect? And last month were you charged according to new pricing?
Karan Lightspeed|2023-06-05 18:16:04|Wonder why they chose IIIT. Hope it wasn't a typo from the media team :P
Abhinav Verma Longshot.ai|2023-06-05 18:19:42|Iiit d has done some work in nlp as well. Remember this in 2019 when was working in unfound news and fact check stuff was high priority they had released a paper with an approach. Don't remember it now, it was also not feasible to implement in prod at the time
Nirant|2023-06-05 18:20:47|Here is a hint: https://cai.iiitd.ac.in/index.php/faculties
Karan Lightspeed|2023-06-05 18:24:50|Lol - so you're saying the profs they have are deeper in the space. Interesting
Dr. Pratik Desai KissanGPT|2023-06-05 18:25:57|I know this guy, Raghava Mutharaju, he was in my research lab but joined PhD program when I finished.
~ Sridhar A|2023-06-05 18:26:25|Anyone with experience handling production grade facial recognition applications? Looking for some suggestions/ recos on tech stack for various stages of the pipeline.
Dr. Pratik Desai KissanGPT|2023-06-05 18:26:32|Also it is called Infosys center, Infosys was one of the first investor in OpenAI
Dr. Pratik Desai KissanGPT|2023-06-05 18:26:51|*Donner*
Nirant|2023-06-05 18:28:24|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"""
Dr. Pratik Desai KissanGPT|2023-06-05 18:29:24|I would suggest search previous chat or your site first. Many repeat questions.
Nirant|2023-06-05 18:30:47|Also, I feel iffy about giving space to discussions which have done more harm than good e.g. face apps, deep fakes already. It's no longer a hypothetical
Karan Lightspeed|2023-06-05 18:32:47|Didn't know this. Thanks!  https://infotechlead.com/bpo/infosys-invested-artificial-intelligence-research-company-openai-37207
Michael D Souza|2023-06-05 18:44:09|‎You added Michael D Souza
~ Rajdeep Banerjee|2023-06-05 18:44:12|‎You added ~ Rajdeep Banerjee
~ Nimish Dwarkanath|2023-06-05 18:44:19|‎You added ~ Nimish Dwarkanath
Ambuj Kashyap|2023-06-05 18:44:25|‎You added Ambuj Kashyap
Nirant|2023-06-05 19:23:57|"Hello!   As I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.  If you see your name or phone number in this ""removal"" list — please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing  That'd indicate to me that you're at least reading some messages :)"
Nirant|2023-06-05 19:24:38|PS: Staying on brand, the entire list is generated by ChatGPT
Saurav Tomar GenerativeAI WA Group|2023-06-05 19:31:02|Anyone attending the Sam Altman delhi meetup on 8th June ?
Adithya S K PESIT|2023-06-05 19:33:16|the tickets got sold out so quickly
Nirant|2023-06-05 19:38:13|Low key happy that Sam Altman sold out faster than many bad concerts!
Abhinav Verma Longshot.ai|2023-06-05 19:39:22|Imagine touts selling tickets for this in black
Dr. Pratik Desai KissanGPT|2023-06-05 19:41:21|Hope they have someone asking smart questions
Adithya S K PESIT|2023-06-05 19:41:58|If you were given the opportunity what would you ask?
Abhinav Verma Longshot.ai|2023-06-05 19:41:59|Do the questions need to be before September 2021?
Dr. Pratik Desai KissanGPT|2023-06-05 19:44:35|How about hosting OpenAI models in Indian data centers, so in case of AI embargo India can still access the models.
Abhinav Verma Longshot.ai|2023-06-05 19:44:45|I would ask for better guidelines for finetuning.  The documentation here can be improved even with the base models. And of course if we can finetune the newer models  Main questions regarding Is there a base token recommendation for finetuning.
Dr. Pratik Desai KissanGPT|2023-06-05 19:45:46|Why would you ask tech question to sama?
Abhinav Verma Longshot.ai|2023-06-05 19:45:52|How technical can you ask questions here
Abhinav Verma Longshot.ai|2023-06-05 19:46:30|Fair point. But I also think he has a close eye on the technical side as well
Abhinav Verma Longshot.ai|2023-06-05 19:47:05|I don't want to ask questions on agi because I don't trust him to give the right answers
Dr. Pratik Desai KissanGPT|2023-06-05 19:47:19|Not how, why? Find OpenAI folks on twitter for tech questions.
Dr. Pratik Desai KissanGPT|2023-06-05 19:47:41|May be ask why he changed his stance in last two-three months
Nirant|2023-06-05 19:47:49|Official OpenAI Guide on Prompting: https://platform.openai.com/docs/guides/gpt-best-practices/strategy-test-changes-systematically
Dr. Pratik Desai KissanGPT|2023-06-05 19:48:16|What did they find in training that suddenly they are all into regulations?
Nirant|2023-06-05 19:48:33|"I can't believe bulk of their entire advice boils down to ""use regression tests"" 🫢🤯"
Abhinav Verma Longshot.ai|2023-06-05 19:49:04|This I don't trust him to give the right answer because of conflict of interest
Adithya S K PESIT|2023-06-05 19:49:33|If that has to happen azure will have to upgrade their could centers in india significantly ryt
Adithya S K PESIT|2023-06-05 19:50:00|Cloud*
Abhinav Verma Longshot.ai|2023-06-05 19:50:24|Fair point. But changed to what. Is it that article which was deleted recently or the one that he gave at the US congress
Dr. Pratik Desai KissanGPT|2023-06-05 19:50:29|Yeah, that's why it is a good question. That means more GPUs in India.
Nirant|2023-06-05 19:51:15|"I suspect recent ""soft"" export bans from US will block something like this even if Tata says I'll pay you for the entire inference compute"
Dr. Pratik Desai KissanGPT|2023-06-05 19:54:10|I guess GPT4 will be beaten by OSS soon anyway, but US is not going to stop training GPT5, 6 and these senate committees will start placing an embargo on the export of next
Abhinav Verma Longshot.ai|2023-06-05 19:55:59|Will openai look to reduce the prices of the older models as it gives preference to chat models
Dr. Pratik Desai KissanGPT|2023-06-05 19:56:17|On fun side, asking him about Atman <> Brahman philosophy, he is deep into that philosophy
Abhinav Verma Longshot.ai|2023-06-05 19:56:36|Has Sama tried Sama juice 😂
Abhinav Verma Longshot.ai|2023-06-05 20:00:07|What has your experience been with OSS. I've found for my use cases there is a significant difference still. Although there are a couple that have given surprisingly good results
Adithya S K PESIT|2023-06-05 20:01:05|I have been fine tuning open-source models and testing them out. But it always fail in comparison to closed source apis like gpt or claude  What would be an insentive for companies to fine tune their own models as they are more expensive to host as well
Nirant|2023-06-05 20:01:16|I'll wager that nothing comes close to GPT4 in task planning, multi step reasoning beyond 3 before 2024 Q1
Abhinav Verma Longshot.ai|2023-06-05 20:02:13|I'm thinking a good solution might be OSS for small use cases.  Like api selection using gorilla model etc.
Dr. Pratik Desai KissanGPT|2023-06-05 20:03:37|You can add even coding to that list too.  Many uses cases that people are building products for, I.e. summarization, etc, fine tuned oss may work out.
Nirant|2023-06-05 20:03:41|Yeah, this can get competitive, but this is narrow AI again — just a different kind of narrow than 2019
Nirant|2023-06-05 20:03:58|Ohh yeah, QA, Summarisation — most things are competitive
Abhinav Verma Longshot.ai|2023-06-05 20:05:30|The replit model, have you tried it? They say it's pretty good
Bharat Kumar Ramesh Hashmal Web3|2023-06-05 20:06:53|If wwdc goes well today, all everyone is going to be talking about is VR for the next few weeks.  His take on that would be quite nice
Nirant|2023-06-05 20:07:47|StarCoder and the Teknium Finetune are both better
Dr. Pratik Desai KissanGPT|2023-06-05 20:08:01|No. I have stopped trying new models now. I just follow some smart folks on Twitter and check their benchmarks. If you keep tinkering, you can never focus on building one thing.
Abhinav Verma Longshot.ai|2023-06-05 20:08:19|Agree
Nirant|2023-06-05 20:09:28|Did you stop tinkering after trying n/e models? 🤣  For those who don't get the joke: https://www.wikiwand.com/en/Secretary_problem
Dr. Pratik Desai KissanGPT|2023-06-05 20:09:40|I also ran out of my 8TB storage, no time to upgrade 😂
Ojasvi Yadav|2023-06-05 20:15:56|https://www.forbes.com/sites/kenrickcai/2023/06/04/stable-diffusion-emad-mostaque-stability-ai-exaggeration/?sh=4d2224d775c5
Ojasvi Yadav|2023-06-05 20:16:01|Seems like quite the smear campaign
Shan|2023-06-05 20:16:41|One motto we have at our company for ML folks is to “be a generalist when it comes to inputs and a specialist when it comes to outputs. That’s because only a generalist knows what tradeoffs are possible and worthwhile”
Dr. Pratik Desai KissanGPT|2023-06-05 20:18:11|I see two sides. This looks like a hit piece for sure but Emad also made so many crazy claims while the models coming out of Stability AI were subpar.
Nirant|2023-06-05 20:18:42|Jokes on anyone who takes their technology news from Forbes
Ojasvi Yadav|2023-06-05 20:19:20|I agree  But is there anything on his record that's actually wrong
Ojasvi Yadav|2023-06-05 20:19:41|"The whole article is just a series of claims that can be called ""problematic"" at best"
Dr. Pratik Desai KissanGPT|2023-06-05 20:23:55|He is also SV outsider, and was going heads on to YC mafias. 😂
Twishmay Shankar|2023-06-05 20:32:49|On this note: Any recommendations for good quality sources for tech / AI news? Beyond this group of course. Thanks in advance.
Abhinav Verma Longshot.ai|2023-06-05 20:34:04|I will also add nyt and vice to this list
Gokul Krishnan|2023-06-05 20:36:01|Isn't vice bankrupt?
Nirant|2023-06-05 20:36:59|Github Feed is severely underrated e.g. one could tell GPT4 was coming out when they pushed the changes to Python lib xD
Nirant|2023-06-05 20:38:33|Even the Emad piece mentions this: https://github.com/CompVis/stable-diffusion  And you can see when Stability and Runway decided to call a truce from the commit history: https://github.com/CompVis/stable-diffusion/commits/main/README.md
Abhinav Verma Longshot.ai|2023-06-05 20:43:20|Yes
~ Apurva Bhatt|2023-06-05 20:46:15|https://www.linkedin.com/company/generative-ai-media-marketing-creative-conference/
~ Apurva Bhatt|2023-06-05 20:47:44|They have a newsletter, it's more focused on new domains (mostly related to media) where genAi is applied
~ Rohan|2023-06-05 21:47:49|I was sad to see my name in the list of inactive users, and then I realized it was because I hadn't posted any updates from my previous prompt injection updates for a while. So, to avoid being classified by chat GPT as inactive again, here is my latest prompt injection (complete prompt posted in an earlier message). ‎[6/5/23, 21:47:58] ~ Rohan: ‎image omitted
Shashank Generative AI Group|2023-06-05 22:07:44|Shashank(me) was mentioned in the sheet, there are 3 Shashanks here 😂.   i hope i don't get removed by mistake.
Rajesh RS Generative AI WhatsApp Group|2023-06-05 22:08:36|This is fantastic stuff.
Rajesh RS Generative AI WhatsApp Group|2023-06-05 22:08:52|Is there a good guide anyone knows to prompt injection techniques, and more generally, LLM based chat bot testing
~ Pradeep Ayyagari|2023-06-05 22:11:21|Was drooling all over his 20vc podcast untill I read this. Tall claims in the podcast but most of them sounded reasonable with hard work. Did not know the past then, in the back of my head the proof was mid-journey. Not sure what to make of any of this, inclined to believe the article now with Rahul Yadav recency bias ☹️
Ojasvi Yadav|2023-06-05 22:16:35|From now on we'll probably just remove the least active N users ourselves. If they want back in they can text us. Running an opt-out Google sheet hijacks the usual conversations here
Paras Chopra Wingify|2023-06-05 22:25:04|Good one
Rajesh RS Generative AI WhatsApp Group|2023-06-05 22:25:17|Wow, that was a crazy article. Glad these are getting written
Rajesh RS Generative AI WhatsApp Group|2023-06-05 22:37:54|It is tough to separate signal from noise with many of these articles. We’ve seen smear pieces and hit pieces in the past and we also know the value of not turning a blind ear to things like this lest we get another Theranos or another FTX but most of us consuming this news from thousands of miles away have so little context
Shashank Generative AI Group|2023-06-05 22:38:20|emad wrote a counter. frankly, that Forbes piece exaggerated a lot of growing pains associated with running a startup, figuring stuff out. https://twitter.com/EMostaque/status/1665459321180680192
Rajesh RS Generative AI WhatsApp Group|2023-06-05 22:43:59|Hard to separate growing pains from mismanagement. So much of this is subjective.
Ojasvi Yadav|2023-06-05 23:54:55|Are you guys following this?
Ojasvi Yadav|2023-06-05 23:55:01|It's absolutely breathtaking
Sumod K Mohan|2023-06-05 23:55:19|And finally Apple does AR
Ojasvi Yadav|2023-06-05 23:55:49|AR has always been the real goldmine
Shimanta Generative AI|2023-06-05 23:56:09|This is surely a revolution in AR
Shimanta Generative AI|2023-06-05 23:56:15|And with no controllers
Ojasvi Yadav|2023-06-05 23:57:43|I was having a conversation with [PHONE] today about monitors.   He was trying to find a good work monitor. We're still discussing the right size.
Pranjal Joshi US FINTECH|2023-06-05 23:57:52|Yes it is. A giant leap.
Ojasvi Yadav|2023-06-05 23:57:54|Now I think he should get this
Shimanta Generative AI|2023-06-05 23:58:13|Eyes are the monitors now
Ojasvi Yadav|2023-06-05 23:58:51|I originally wanted buy a 49incher like [PHONE] but I'm strongly reconsidering.
Ojasvi Yadav|2023-06-05 23:59:03|Imagine Gen AI for this?
Ojasvi Yadav|2023-06-05 23:59:15|So far quantisation has mainly been for NLPs
Ojasvi Yadav|2023-06-05 23:59:24|I foresee the same for vision models now
Aashay Sachdeva MPL Data Scientist|2023-06-06 00:00:24|This is absolutely magical
Aashay Sachdeva MPL Data Scientist|2023-06-06 00:00:33|GenAI + AR ‎[6/6/23, 00:00:37] ~ Sudhanshu Heda: ‎image omitted
Ojasvi Yadav|2023-06-06 00:00:37|In a few months I would love to see models that can generate multiple SD2.1 grade images in seconds
Sumod K Mohan|2023-06-06 00:00:40|Was just telling one of my friends that Apple just saved them (MagicLeap) or Apple is screwed. AR is until now is like Afganistan, the place superpowers go to get beat. Let's hope Apple has figured out 🤞
Ojasvi Yadav|2023-06-06 00:00:55|This can then be mixed with AR in very creative ways
Shashank Generative AI Group|2023-06-06 00:01:11|that eye reveal thing. tuning immersion using crown. 👌👌
Shimanta Generative AI|2023-06-06 00:01:15|Shopify is doing some great work here
Azhan Mohammed Generative AI WhatsApp Group|2023-06-06 00:01:27|Taking deep work to next level
Ojasvi Yadav|2023-06-06 00:01:44|What exactly? I'm very intrigued
Shimanta Generative AI|2023-06-06 00:01:45|They really nail the UX
Shashank Generative AI Group|2023-06-06 00:03:33|yup. rest of the safari etc demos aren't that exciting.   but the interface, transition bw real and virtual world💰👌
Shimanta Generative AI|2023-06-06 00:04:45|This is something they did sometime back: https://twitter.com/strangenative/status/1640741787105984512?s=46&t=WT1iAtjftW-5_e62F8FZTg
Pranjal Joshi US FINTECH|2023-06-06 00:04:49|and the interface with Mac was just shown, this is exciting. Imagining not using a physical extended monitor for work!
Shimanta Generative AI|2023-06-06 00:05:23|Some players tried this earlier, like Nimo Planet. But this seems miles ahead
Shimanta Generative AI|2023-06-06 00:06:23|The only concern I’m seeing is where’s the dangling cable connecting to 😅
Dhruv Naik|2023-06-06 00:07:55|The new Quest 3 looks really good. Meta has done really well with their oculus devices
Shashank Generative AI Group|2023-06-06 00:08:01|Spatial Video !
Pranjal Joshi US FINTECH|2023-06-06 00:08:29|Yes. This seems way ahead. A part of it is because of the ecosystem effect. The userbase is, in a way, trained to imagine at a scale of the bandwidth they want them to access (their diverse products).
Aakash Kumar  Matrix Partners|2023-06-06 00:09:14|Looks like going for a kill on the profit pools of TV screens for sure
~ Mayank Gupta|2023-06-06 00:10:59|This is crazy stuff. The impact on entertainment is massive.
Pranjal Joshi US FINTECH|2023-06-06 00:13:38|Though it will boil down to how long can you have a thing right infront of your eyes wrapped around. If this is the future, the user will adapt I suppose.
Dhruv Naik|2023-06-06 00:14:30|Eye strain and headache from weight imbalance are common with headsets.
~ Mayank Gupta|2023-06-06 00:15:41|The stuff on EyeSight and the responsiveness to gaze for icons and buttons are the kinds of UX Apple has nailed
Ojasvi Yadav|2023-06-06 00:16:38|For those who want a textual summary  https://9to5mac.com/2023/06/05/apple-vision-pro/
Sumod K Mohan|2023-06-06 00:18:06|Yeah that and they really think hard how to make it work. Like recording in 3D (am assuming) for capturing life moments, this is a use case that MagicLeap or even Daqri could have done. None did it.
Shimanta Generative AI|2023-06-06 00:18:23|So it’s an external battery
~ Puneet|2023-06-06 00:19:29|Yes. Its Crazy!!!
Sumod K Mohan|2023-06-06 00:21:42|Interesting choice. They put processors in the device and battery outside. Seems like pretty high res.
Aakash Kumar  Matrix Partners|2023-06-06 00:22:30|Power of prop silicon ! 🙇‍♂️
Shimanta Generative AI|2023-06-06 00:22:34|Exactly. This allowed to get the form factor a lot better
Sumod K Mohan|2023-06-06 00:27:12|No most of them moved the processors outside due to heat issues. Our faces are particularly very sensitive. So seems like they have solved heating really well or they actually have more than battery in puck or whatever they call it.
Sumod K Mohan|2023-06-06 00:27:28|*them = others
~ Priyanka Thakran|2023-06-06 00:31:10|Though I am completely mesmerised by visionpro, still looking for tickets for Sam Atlan's delhi visit - do share if someone wants to sell/can help with tickets 🙏🏼
Dhruv Naik|2023-06-06 00:32:59|The only thing this is changing is your bank balance.
Sumod K Mohan|2023-06-06 00:33:52|$3499
~ Pranav|2023-06-06 00:39:01|The price is way too much though- even the meta quest pro is available for $1000 🥲
Manas Ranjan Kar|2023-06-06 00:40:24|Same here - ready to fly down to Delhi in a days notice. Couldn’t get my hands on the tickets 😭
Ojasvi Yadav|2023-06-06 00:44:05|Im saving up 🫠
Dhruv Naik|2023-06-06 00:47:03|quest 3 for 499 is a great deal. It has most of the features, and an already established VR ecosystem.
Sumod K Mohan|2023-06-06 00:48:07|But the power is ability for all apps to be integrated.
Shimanta Generative AI|2023-06-06 00:50:06|Vision Pro might not be directed to the masses yet. We didn’t really think they’d price it for less than an Iphone 14 pro did we 😂 I haven’t tried the Quest 3, but the displays in Quest 2 were mid. There is full color pass through in the Quest 3, but they wouldn’t be anywhere near the vision pro with the sensor array it has. As soon as I saw the sensors on the bottom, I knew: No controllers
~ Mayank Gupta|2023-06-06 00:50:12|I don't think it can warrant a feature vs feature. This isn't VR at all. To me it felt like a different platform pitch altogether. More about a screen and it's utilities. And then optimised towards those
Shimanta Generative AI|2023-06-06 00:51:24|Right, Meta Quests are more mixed reality. This is full AR
~ Pranav|2023-06-06 00:51:44|I have the quest 2 and it's priced just right. The quest pro was considered expensive- and now apple knocks the pricing out of the park 😂
~ Nijil Y|2023-06-06 00:51:49|How nicely they normalize walking around the house wearing a head gear
~ Sudhanshu Heda|2023-06-06 00:51:55|Oppo right around the corner now to release their copy 🤙
~ Pranav|2023-06-06 00:52:38|Quest pro is pretty similar with its see through capabilities   https://youtu.be/jUIE2l_9ig8
Sumod K Mohan|2023-06-06 00:55:35|I think they still haven't solved object recognition accurately enough thus no interactive augmented / mixed reality stuff. Also they might not have solved the colocalization either, thus not talking about shared experiences. Probably all for later releases.
~ Mayank Gupta|2023-06-06 00:56:20|What's colocalization?
Vamshi|2023-06-06 00:57:01|Can’t wait to see how well they’re doing the face reconstruction
Vamshi|2023-06-06 00:57:41|That would be super compelling for doing remote experiences together with people
Sumod K Mohan|2023-06-06 00:59:23|Localise multiple people wearing with each other and thus shared sort of experience. So magic leap etc can detect a table that both people of you see, then understand 3D structure of the table. You show same animations (think characters jumping out of top of your table) for both users from different POV on top of this surface.
Ojasvi Yadav|2023-06-06 01:02:21|They've gotten themselves in a great position. It's truly something to marvel at.  For years they've been cursed about the big notch, and they've stuck to face ID despite competitors going far ahead with their camera based authentication.  But now Apple probably has enough data to master a ridiculously accurate facial reconstruction.  Then they just need to encode the movement of certain common trackpoints like corner of the eyes and width of the nose into positional vectors.  They will just transmit the positional vectors of the facial movement and reconstruct a hyperrealistic face on the receiver device
Ojasvi Yadav|2023-06-06 01:03:10|Imagine characterAI
Ojasvi Yadav|2023-06-06 01:03:13|With this
Ojasvi Yadav|2023-06-06 01:03:37|I'd love to talk to a few people in history face-to-face
Ojasvi Yadav|2023-06-06 01:03:47|Instead of a chat interface
Shimanta Generative AI|2023-06-06 01:04:58|Possibilities are endless. And they’re not releasing it now. So by then who knows we might have this and much more 😄
Vamshi|2023-06-06 01:07:13|I have high hopes for wearing comfort factor and face reconstruction - these were my #1 sore points with the quest
Vamshi|2023-06-06 01:08:53|Agents just got a bit too real 😁
Vamshi|2023-06-06 01:10:06|Is this a consumer device though?
Vamshi|2023-06-06 01:10:48|Will be really nice to see healthy competition here
~ Vrushank Vyas|2023-06-06 01:12:55|Apple does so much of ML that’s neatly tucked into functional use cases - even stuff like moving wallpapers  CoreML seems to be getting quite powerful  https://github.com/apple/coremltools
Vamshi|2023-06-06 01:20:29|Will be interesting to see what you can train and fine tune on the new Mac Pro - it’s only slightly more expensive than a fully tricked out RTX 4090 gaming PC, did I get that right ?
Vamshi|2023-06-06 01:23:10|India store price doesn’t look great 😄
~ Vrushank Vyas|2023-06-06 01:23:55|Mac Pro with M2 Ultra has 192 gigs ram 😂  I think they mentioned “training transformers models” as one of the use cases
Rohan Manchanda|2023-06-06 01:29:28|Not sure if this has been shared earlier but i found this website to be amazing for use case based prompting  https://learnprompting.org/docs/basics/prompting
Sumod K Mohan|2023-06-06 02:11:12|They already have ridiculously accurate model in true depth, I think they probably didn't want to wash you face with LiDAR for long periods of time. So they probably used LiDAR based keypoints + facial fiduciaries to do things like low fidelity cartoon character animation one could do now. This solution is because they can't capture your face because it is blocked by the device. So they are forced to provide minimal deformation sort of model.
Sumod K Mohan|2023-06-06 02:12:07|LiDAR to provide base structure.
Sumod K Mohan|2023-06-06 02:12:45|Above is guess, they might as well just be using just facial key points.
Gokul Krishnan|2023-06-06 02:51:08|M2 is known to be power efficient. So it probably doesn't generate significant heat to begin with
Shimanta Generative AI|2023-06-06 02:54:07|The battery pack can easily be offset to the back strap as well, making it kind of offset the main device.
Dev Aggarwal|2023-06-06 02:56:35|There’s a paper around here that did face reconstruction using only top view camera feeds
Gokul Krishnan|2023-06-06 02:59:03|it might be the case that the device can handle a few minutes on its own while the user switches the battery when one runs out. Paired with prop silicon this would mean many hours of use
Dev Aggarwal|2023-06-06 03:09:39|https://youtu.be/hkSfHCtpnHU
Dev Aggarwal|2023-06-06 03:16:56|What you’re talking about here btw is also old tech - https://youtu.be/dVa1xRaHTA0 - and I really doubt they are using face id data for training a face reconstruction model. Face ID never leaves the device afaik
~ Ansh Agarwal 👩🏽‍🚀|2023-06-06 04:05:41|‎You removed ~ Ansh Agarwal 👩🏽‍🚀
Nirant|2023-06-06 04:05:58|Removed for self promotion more than once
Bharat Kumar Ramesh Hashmal Web3|2023-06-06 07:49:04|Unity popped 17pc last night on the partnership announcement
Rajesh RS Generative AI WhatsApp Group|2023-06-06 08:12:00|Overall I don’t see anyone really buying these Apple VR headsets apart from the same crowd that buys Mac pros. And that excludes most of us
Rajesh RS Generative AI WhatsApp Group|2023-06-06 08:12:45|All said, incredible looking product
ashish Acgt01 Twitter|2023-06-06 08:26:56|I have a contrarian view.  How comfortable are AR/VR headsets ? How long can you wear them before your brain & eyes want a break ? There is no sticky usage
Arvind N Generative AI Group|2023-06-06 08:28:35|Try the skybox blockadelabs 360 image generation in your VR browser. Works great on my pico and oculus.
Arvind N Generative AI Group|2023-06-06 08:29:05|I use them for 3.5 hrs without any issues. Have been using headsets for 5 years now
Dhruv Naik|2023-06-06 08:29:30|A couple of hours max. Because you tend to blink less often, makes my eyes dry. The other factor is weight imbalance. Improperly fit headsets can cause headaches and neck strain, but there are lots of ways to fix that.
Dr. Pratik Desai KissanGPT|2023-06-06 08:30:49|I have two VR and an FPV drone VR, all of them collecting dust.
~ Arjun|2023-06-06 08:31:11|I have the Occulus 2, and I can’t use it for too long, max an hour. Also there is the https://en.m.wikipedia.org/wiki/Vergence-accommodation_conflict. Since the focal point of the lens of the eyes and the stereo conflict, it may cause issues for some people.
Dhruv Naik|2023-06-06 08:31:30|Often its the battery life that is the constraint for me, not comfort (I use a quest 2)
~ Arjun|2023-06-06 08:31:45|Magic leap was trying to fix it with their light field display, but they didn’t come too far yet.
Dr. Pratik Desai KissanGPT|2023-06-06 08:32:05|It's fun for couple of hours, days then the novelty wears down quickly.
Sumod K Mohan|2023-06-06 08:40:58|Yeah, Very curious to know how they have managed VAC. Atleast for 2-3hr periods of usage. If they can do that, it will enable a whole bunch of  application. But Apple being Apple, I am guessing they have a solution.
Sumod K Mohan|2023-06-06 08:45:46|Battery: I think you can do both 2hr and plugged in it seems. Their res is very high, guessing early 4k x 2.5k or so, almost thrice of Quest 3. Weight imbalance: I am guessing they have solved it. Else they are screwed. Yeah, I think the real thing is do they have apps with sticky workflow.
Sumod K Mohan|2023-06-06 08:51:31|DAQRI, MagicLeap, Holo lens all had nice 3D rendered promo videos which were very far from real product and they couldn't close the gap soon enough. Disclaimer: Did some work for DAQRI in 2014-2016 period.
Nirant|2023-06-06 09:21:27|Absolutely banger paper from Microsoft Research, illustrates how you can distill a larger model's reasoning capabilities into a smaller model (think of all your agent behaviour) https://arxiv.org/abs/2306.02707  Openly contradicting/side stepping  the previous research which argued that small models don't have the world knowledge which large models do.  Surpasses Vicuna-13B by *100%*  No code, no data — but planning to release model weights under a research license similar to Llama
~ Sudhanshu Heda|2023-06-06 09:26:53|https://twitter.com/sterlingcrispin/status/1665792422914453506?s=46&t=v5MAnKU6XwMWCzMNzmBUuA
~ Sudhanshu Heda|2023-06-06 09:27:10|One of the coolest results involved predicting a user was going to click on something before they actually did. That was a ton of work and something I’m proud of. Your pupil reacts before you click in part because you expect something will happen after you click. So you can create biofeedback with a user's brain by monitoring their eye behavior, and redesigning the UI in real time to create more of this anticipatory pupil response. It’s a crude brain computer interface via the eyes, but very cool
Rajesh RS Generative AI WhatsApp Group|2023-06-06 09:28:56|Nice feature, but I foresee the same kind of research used for UX dark patterns in VR headsets in the future - we already see how effective these can be at guiding/interrupting user behaviour on regular websites
Rajesh RS Generative AI WhatsApp Group|2023-06-06 09:30:13|Makes a lot of sense to pursue this line of research because outside of the big research labs, most companies won't build completely new LLMs, but will build on top of the big LLMs and their capabilities in a specific area, sub-problem, domain.
Rajesh RS Generative AI WhatsApp Group|2023-06-06 09:30:28|Really interesting paper, thanks for sharing
Abhinav Verma Longshot.ai|2023-06-06 09:31:42|Can a RLHF tuned model be considered a foundation model?
Nirant|2023-06-06 09:33:09|You can do whatever, say whatever as long as you can popularise your terms like RLHF or Foundation Model 😉
Abhinav Verma Longshot.ai|2023-06-06 09:34:10|fair enough.
Abhinav Verma Longshot.ai|2023-06-06 09:35:17|andrew ng changed the game when he marketed the term deep learning. Or maybe  it was someone else.
Dr. Pratik Desai KissanGPT|2023-06-06 09:37:50|We were just yesterday talking about step by step thought process capability of GPT4.
Chirasmita Mallick|2023-06-06 09:56:45|OpenAI updated their developer docs last night . Pretty neat https://platform.openai.com/docs/guides/gpt-best-practices
Rohit Aggarwal|2023-06-06 09:58:37|OpenAI should do this as a successor to fine-tuning.
Shan|2023-06-06 10:29:15|also by Subhabhrata (though not the first author) is the ReWOO paper addressing reasoning - https://arxiv.org/abs/2305.18323 I think this can be a potential game changer too.
~ kashish|2023-06-06 10:33:26|I have been looking to buy Oculus for a while but could not find anywhere to test it in India.  I also was thinking the same if it would be comfortable if worn for long. Anyone who owns a Oculus can maybe answer
Aashay Sachdeva MPL Data Scientist|2023-06-06 10:39:09|My company had bought one from the US. After around 30-40 minutes of usage with specs, you do feel dizzy (sample size was small though)
~ Vishal|2023-06-06 10:50:28|This guy spends 40-50 hours per week working in VR and finds good productivity gain: https://medium.com/immersedteam/working-from-orbit-39bf95a6d385 In my experience the number of pixels in quest 2 is not enough for me to replace monitors with it, but I don't find it tiring if used for few hours. I do experience heavy motion sickness if the scene is moving and I can't use it for more than half an hour
Vamshi|2023-06-06 10:50:29|My initial experience with oculus was mind blown, it was the first genuinely new user interface I experienced since keyboard screen and mouse.   Creator tools were the most interesting apps.  Comfort on the other hand was downright abysmal. 20 minutes leaves me uncomfortable. 30 really annoyed. Almost never make it beyond 45.
Vamshi|2023-06-06 10:52:13|Anyway, from a Gen AI perspective, I think a spatial and gestural interface is particularly disruptive
Paras Chopra Wingify|2023-06-06 10:52:22|My Oculus has been gathering dust
Vamshi|2023-06-06 10:52:28|Because it offers an alternative to text as generative input
Nirant|2023-06-06 10:54:06|Please feel free to gift me. I accept donations.
Paras Chopra Wingify|2023-06-06 10:56:52|Lol, but it’s fun for flaunting when wiser friends are around
Aashay Sachdeva MPL Data Scientist|2023-06-06 11:00:49|Organise a oculus testing activity for the group
Paras Chopra Wingify|2023-06-06 11:04:07|I’ll get one in the next meet-up
~ Karthikeyan Raghuraman|2023-06-06 11:05:55|‎~ Karthikeyan Raghuraman requested to join
~ Prajwal|2023-06-06 11:19:39|has anyone here experimented with Neurosity Crown? and the membership?
Madhur Chadha|2023-06-06 11:21:43|Which version do you have.  I have quest and I can easily spend hour...  I have watched full blown movies on this app called big screen.. Played tt for an hour
Kunal Bhatia Hexo|2023-06-06 11:33:33|Same here. Has been sitting in the shelf after a month of getting it.  The eyes burn is quite enough already with the excessive computer and phone time. This takes it to a whole new level with those LEDs right in front of the eyes.
Rajesh RS Generative AI WhatsApp Group|2023-06-06 11:35:57|A couple of my colleagues have dry eye issues - due to excess device use. We need more AR tech that doesn't put a big screen in front of your eyes, closer to it, but uses other senses to inform us about the environment. I'll buy some of that kind of tech if it is interesting
Arvind N Generative AI Group|2023-06-06 11:36:29|I went from Oculus Go in 2018 to HTC Vive. Bought and returned Quest 2. Got Pico4 which is good for giant screen content and watching F1. Works well with both spectacles and contact lenses.
Arvind N Generative AI Group|2023-06-06 11:40:47|Immersive travel using 360 images generated by stable diffusion seems to work quite well.  https://skybox.blockadelabs.com/
Rajesh RS Generative AI WhatsApp Group|2023-06-06 11:42:11|Thinking more critically about the Apple VR headset release it doesn't do anything fundamentally different compared to the likes of Oculus VR, it is an upgrade for those really into the space. Sensing this trend lately at Apple in building mass market stuff like M1/M2 Macs and then also having Studio/Earpods Max/Mac Pro/iPad Pro M1-M2 and now their VR headset - all of these are for a small sliver of users.
Rajesh RS Generative AI WhatsApp Group|2023-06-06 11:42:38|Not to mention Apple Watch Ultra
~ Srinivasan Nandakumar|2023-06-06 11:46:55|Have a question regarding instruction tuning. I have come across two methods of fine-tuning: 1. The loss is only calculated on the output(answer to the input instruction) 2. The loss is calculated on the entire example including the instruction.  Any thoughts on which one does better?
Rajesh RS Generative AI WhatsApp Group|2023-06-06 11:47:38|If I was an Apple investor I'd love these new demos but I'd be wondering where the cheddar is going to come from. Maybe gaming? One possibility since Nvidia despite its trillion dollars market cap isn't able to attract mass market GPU buyers. PC gamers seem more and more black pilled about the GPU scene from what I can tell. Generative AI won't necessarily change that market since mass market GPUs like the (underwhelming) 4000 series are not targeted at AI dev teams
Vamshi|2023-06-06 11:50:44|The quest 2 I think ?? I got early last year. Not sure exactly.  To be honest I did push myself and used it beyond 45 minutes, but it was painful.  It could be because I also wear prescription glasses, and that I have particularly dry eyes.
Pratiksha Dake Unacademy|2023-06-06 11:54:44|Yep, not a good experience with glasses.
Nirant|2023-06-06 11:55:36|Depends a bit on your masking e.g. one trick to mask some part of instructions too and that seems to improve generalisation in small models. But to the best of my knowledge, in most cases -- we do calculate loss on the entire prompt/context, right?
Gokul Krishnan|2023-06-06 12:01:48|Thinking of getting a VR headset myself. Which one of pico4 vs quest2 do you prefer? ‎[6/6/23, 12:02:06] ~ Srinivasan Nandakumar: ‎image omitted
Chirag Jain|2023-06-06 12:05:35|yes -100 is ignored in CrossEntropyLoss
~ Srinivasan Nandakumar|2023-06-06 12:06:01|Calculating loss on the entire context does work reasonably well in my experience but a lot of the repositories that I have come across recently mask the input completely. So I was wondering which is the better way to go.
Sumod K Mohan|2023-06-06 12:07:26|https://developer.apple.com/wwdc23/topics/ml-vision/  They are releasing access to segmentation (human/animals) and pose (both again) for Devs. Their own embedding for 27 languages as well. Quite a few interesting things.
~ Jyotsna Varkey|2023-06-06 12:28:55|‎~ Jyotsna Varkey left ‎[6/6/23, 12:43:24] Abhinav Verma Longshot.ai: ‎image omitted
~ Apurva Bhatt|2023-06-06 12:59:27|Does it find otp from messages? Or anything else as well
Abhinav Verma Longshot.ai|2023-06-06 13:00:10|This is a joke. But yeah I think if it can connect to your phone messages
Abhinav Verma Longshot.ai|2023-06-06 13:00:22|This is a long standing apple meme joke
~ Apurva Bhatt|2023-06-06 13:00:30|Ohh😅
Heer Shingala|2023-06-06 13:54:28|https://aistartupstrategy.com/home
Heer Shingala|2023-06-06 13:54:44|what do y'all think of this?  https://www.linkedin.com/posts/ritendradatta_amidst-the-craze-for-generative-ai-products-activity-7070889891676520448-rKTP?utm_source=share&utm_medium=member_android
Ravi Srinivasan|2023-06-06 14:21:24|Excellent thread... Which begs the Q: are there good thread summarisers? Maybe a browser extension?
Heer Shingala|2023-06-06 14:22:22|I am not sure I understand a 100%.   Is he saying ki more then generating content, AI will help in consuming content?
~ Hridyansh Sahu|2023-06-06 14:26:13|A16z also has the same kind POV for B2B https://a16z.com/2023/03/30/b2b-generative-ai-synthai/
~ RISHAV|2023-06-06 14:34:56|Hello, has anyone tried TheBloke/falcon-7b-instruct-GPTQ? If yes, any reference notebook having the implementation?  context -: falcon-7b-instruct-GPTQ is an implementation for 4bit model for Falcon-7B-Instruct. It is the result of quantizing to 4 bits using AutoGPTQ.
Aakash Dharmadhikari|2023-06-06 14:36:38|I agree with this 100%  Especially in businesses, the problem is not generating content (read noise); challenge is making sense of what’s happening around you.  I personally use GPT-4 at least 30-40% of time to understand content rather than generating; and I have no organization to deal with.
Ravi Srinivasan|2023-06-06 14:37:14|My 2c: The OP is less gung ho about the long term business use case of creative AI, it seems. He says consumption ML (recommendation algorithms?) makes more business sense. Kind of when Andrew Ng said most ML was supervised, though unsupervised is more cool.  The thread has others interesting replies though
Heer Shingala|2023-06-06 14:37:27|This is great, thanks for sharing.
Heer Shingala|2023-06-06 14:38:28|I am still wondering what it implies for marketers. How do we stay ahead of the curve.   So far, the only piece of advice I've received is to be hands on with the genAI tools.
Heer Shingala|2023-06-06 14:39:22|I do agree with him - the novelty of using the new platforms will wear off.
Heer Shingala|2023-06-06 14:40:00|There's an initial shock and awe when new tech is introduced to us but we get used to it pretty quickly also
Aakash Dharmadhikari|2023-06-06 14:40:22|I think that’s the only meaningful advice right now. Nobody in the world knows how all the pieces will interact with each other and the end effects on individual industries and roles.
Aakash Dharmadhikari|2023-06-06 14:42:36|Novelty will wear off, but we are also truly limited by our imagination today. So new use-cases will keep coming even if we choose to ignore the seismic shifts of more capable models or larger context windows or faster latencies.
Heer Shingala|2023-06-06 14:45:04|Hmmm. One of my theories is that the noise will increase manifold, so the ability of a marketer to differentiate their brand will become even more significant.
Heer Shingala|2023-06-06 14:46:32|For eg, it used to take 2 hours and someone really skilled to do the equivalent of Photoshop background filler.   Now that everyone can do it, WHAT you do with it becomes the point of differentiation
Aakash Dharmadhikari|2023-06-06 14:48:49|is the question from the perspective of the photoshop expert or the person who commissioned that assignment?
Heer Shingala|2023-06-06 14:51:07|From the pov of market demand. Differentiating yourself (a photoshop expert) in a market where ai wrappers can do in minutes what took you hours.
Heer Shingala|2023-06-06 14:51:16|So strategy will become more imp
Aakash Dharmadhikari|2023-06-06 14:52:44|Yes, your ability to decide the plan/instructions/imagination becomes the differentiator
Aakash Dharmadhikari|2023-06-06 14:55:14|Also, when turn around time reduces beyond a certain threshold because of tool improvement, people with overlapping skill sets become dramatically more leveraged
Aakash Dharmadhikari|2023-06-06 14:56:09|Say the marketer who now knows how to use Photoshop will have way higher productivity than someone who needs one more person to be productive   Silly example; but I stand by the intent
Heer Shingala|2023-06-06 14:56:57|Makes sense.
Heer Shingala|2023-06-06 14:57:43|I was speaking to a senior data scientist at swiggy last weekend and she suggested to look at all ai tools and this entire wave as a new computer that's way more powerful than what we have on hand.
Heer Shingala|2023-06-06 14:57:58|At the end of the day, marketers need not try to understand how these tools work.
Heer Shingala|2023-06-06 14:58:02|Just need to be able to use them
Atharwa Sheth ITC|2023-06-06 15:12:53|‎You added Atharwa Sheth ITC
Swapnika Hashmail Web3|2023-06-06 15:14:56|‎You added Swapnika Hashmail Web3
Dev Aggarwal|2023-06-06 15:54:04|https://www.youtube.com/watch?v=sKFwS0TEHHM  New pycon videos are out, and there are sooo many! 😍 so glad we have recovered from covid
~ Maunil|2023-06-06 16:27:58|‎~ Maunil requested to join
~ Harsh Tiwari|2023-06-06 16:31:20|‎~ Harsh Tiwari requested to join
Jithin James Ragas|2023-06-06 17:02:15|does the feel like a similar angle that mojo is taking ‎[6/6/23, 17:05:31] Jithin James Ragas: ‎image omitted
Jithin James Ragas|2023-06-06 17:06:00|*who all are attending
Swapnika Hashmail Web3|2023-06-06 17:06:50|Folks, quick question. How are you all doing iterative prompt engineering? Seeing that even moving one prompt up and down makes a difference for several LLMs. How do you track sensitivity to added or deleted prompts?
Shan|2023-06-06 17:08:25|I guess i'm not cool enough to get an afterparty invite 😀
Jithin James Ragas|2023-06-06 17:10:31|this is different right. I just signed up and saw that there r about 100 tickets left
Jithin James Ragas|2023-06-06 17:10:44|https://bit.ly/43qE9GD this is link btw
Shan|2023-06-06 17:14:13|thanks, I RSVP'd.
Nirant|2023-06-06 17:15:07|Have a test battery of some sort to, commit frequently and log both the prompt and output
Swapnika Hashmail Web3|2023-06-06 17:15:57|True but no way to measure sensitivity or accuracy iteratively against a gold standard answer yet right?
Shan|2023-06-06 17:18:55|is this truly generative (e.g writing something). Then it's tough. But if it's more objective, then why can't you measure? See this sheet for example for logic tests https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=2011456595 What this guy has done for m questions across n LLMs you can do for p prompts for the same LLM and check the output (I hope I'm understanding your question correctly).
Nirant|2023-06-06 17:22:02|Not sure what you mean by sensitivity or accuracy in the context of generated text, but you can use task-specific scores e.g. ROUGE/BLEU for summaries and so on
Swapnika Hashmail Web3|2023-06-06 17:22:08|This is interesting. Unfortunately I’m looking at written support responses to user queries and need to test this on a number of inputs links/queries + different prompts to find the ideal output.
ashish Acgt01 Twitter|2023-06-06 17:25:09|https://vickiboykis.com/what_are_embeddings/
Swapnika Hashmail Web3|2023-06-06 17:27:17|We do use embeddings, but it’s still a veery iterative process :)
Simrat Hasura|2023-06-06 17:27:50|Hey Folks,  I work for Hasura. We are focused on improving developer experience. Hasura has simplified the data access story for application developers. We are looking to do the same for VectorDB users.  I am doing research to understand real (not my assumptions) pain points in working with vectorDBs.  If you are interested in contributing to user study, please ping me. I will have a quick call/chat with you to understand the gaps and brainstorm what kind of solution can help you.
Swapnika Hashmail Web3|2023-06-06 17:28:20|Would love to chat with anyone who does prompt engineering on a regular basis to understand best practises. Do lmk :)
Amit Tiwary|2023-06-06 17:30:33|You can check this too: http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Shahul Kaggle Kernel GM|2023-06-06 17:31:52|NICE, looking like few seats are left now
Aishwarya Goel Inferless 5s for 5G|2023-06-06 19:38:28|-> Since we could not accommodate everyone at the afternoon meetup & we got an overwhelming response, hence opened up an after-event party, just after the meetup so that more folks can meet, learn and showcase their products.    Just clarifying this, not promoting it. :)
Prayank Swaroop Accel|2023-06-06 19:52:23|Does anyone know of startups working on AI in the legal domain .. i need some help/advice. It would be great if anyone could DM me.
Ravi Theja|2023-06-06 19:53:36|[PHONE]
Shan|2023-06-06 19:57:04|and so as Nirant suggested, you should be able to use ROUGE/BLEU scores and rank your prompts then?
Sachin Legaltech|2023-06-06 19:59:19|DMing you ..[PHONE] and few others are building in this space as well.
~ KJ|2023-06-06 20:04:40|Does anyone know of a media production house using Gen AI in their workflows?
Nirant|2023-06-06 20:12:31|cc [PHONE] thought this might be interesting to you
Abhishek Maiti|2023-06-06 20:13:26|Hi, I know a few, who are doing this.
Shubham Sharma 2012C6|2023-06-06 20:13:40|We’re trying a few things at The Viral Fever. Please DM
Shubham Sharma 2012C6|2023-06-06 20:13:54|Would love to know more
Abhishek Maiti|2023-06-06 20:14:04|Sure, lets talk on DM?
~ Rachitt|2023-06-06 20:32:19|Has anyone here tried to fine-tune Falcon-40B or 7B?  Context: trying to understand how to fine-tune OSS models. If there's any resources apart from the Replit blog which provides more in-depth explanation to fine-tuning LLMs, would be super helpful!
Adithya S K PESIT|2023-06-06 20:34:16|yep I have tried it  but you will have to follow a video https://youtu.be/DcBC4yGHV4Q he hasnt linked the notebook tho
Madhur Chadha|2023-06-06 20:35:13|Yes I wear glasses too. It's a bit tricky to setup. Initially  I eventually ended up buying 3p  headbands... There stock ones are crap
Abhishek Sagar Zomato VP Engineering|2023-06-06 20:43:52|‎Pranjal Mehta added Abhishek Sagar Zomato VP Engineering
Pranjal Mehta|2023-06-06 20:44:37|Added Abhishek Sagar [PHONE]. Currently VP Engineering at Zomato
Nirant|2023-06-06 20:52:04|Official Hugginface instructions on training Falcon7B with their PEFT lib huggingface.co/blog/falcon#fine-tuning-with-peft
Abhishek Sagar Zomato VP Engineering|2023-06-06 20:56:41|Thanks Pranjal. Looking forward to learn and collaborate here
Utkarsh Ohm Thoughtspot|2023-06-06 21:04:46|We have invested heavily in building a benchmark. Run it on every commit. Tag ground truth queries with tags so that you can get quick feedback Om which kind of queries fail
Rahul Sundar 2013|2023-06-06 21:21:30|https://huyenchip.com/2023/04/11/llm-engineering.html
~ Daksh Goel|2023-06-06 21:24:29|‎~ Daksh Goel requested to join
Nirant|2023-06-06 21:48:52|After LangchainAI's $10M seed round, Llama Index has raised $8.5M seed (Greylock)  https://twitter.com/jerryjliu0/status/1666095220252106752
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:49:48|Langchain's investment seems to be making a difference - at least in code that has changed. Some API changes clearly visible in versions weeks apart
Nirant|2023-06-06 21:52:03|Do you like those changes? Want to elaborate which ones caught your eye?
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:53:02|Actually something that used to work earlier doesn't work. With the Langchain SQL agent. :D
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:53:21|That said it is probably just us trying to get up to speed. We'll get there
Nirant|2023-06-06 21:53:41|The list of demos, APIs which are core and now broken/no longer maintained is very long
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:54:03|Indeed!
Chirag Jain|2023-06-06 21:54:11|seems like they are going to build another Jina
Nirant|2023-06-06 21:54:39|All ML tools converge to Jina and Haystack 🤣
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:55:05|Haystack seemed very promising, I haven't tried it yet, but was seeing the docs
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:55:39|Anyone know a good guide to testing chat bots? Really interested in that right now
Rajesh RS Generative AI WhatsApp Group|2023-06-06 21:56:09|Full end-to-end testing, with automation.
Nirant|2023-06-06 21:58:21|I say this with some degree of exposure e.g. I used to head ML for Verloop.io — Nykaa's chat support bot maker:   Open domain chatbots cannot be tested without running a Turing test
Saurabh Karn Nyai|2023-06-06 22:00:55|Happy to chat. Do we want to do a group call this week? On legal side?
Nirant|2023-06-06 22:00:58|For conceptual design of *testing* chat bots, Rasa continues to be the highest return on your reading effort: https://rasa.com/docs/rasa/testing-your-assistant/#how-to-write-test-cases  Utterance, Slots — quite powerful constructs even today
Paras Chopra Wingify|2023-06-06 22:01:48|We built some chat bots on Rasa to act as fasting coach (at Nintee)  The edge cases start piling up pretty soon.  It’s very hard to test chat bots systematically
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:02:06|Thanks, Nirant. I am familiar with Rasa for NLU, perhaps time to revisit in this context
Nirant|2023-06-06 22:09:00|Nat Friedman and Daniel Gross have invested in Llama.cpp — the company is called ggml.ai   https://twitter.com/ggerganov/status/1666120568993730561
jyotirmayjk Hackathon|2023-06-06 22:12:21|While I don’t know much in NLU for chatbots ,I’ve evaluated and piloted quite a fair bit of 3rd party SaaS integrations including Verloop,Yellow and Haptik for customer care and support queries.  Suffice to say that beyond narrow range of queries chatbots built pre-LLM era were not delivering on the promise of query automation.  I’m more bullish on LLM based chatbots iff prompt injection attacks can be solved for.
Deep Samsung R&D|2023-06-06 22:23:30|Would love to hear thought if someone has compared Google's STT vs Whisper or any other model. Any pros/cons for both to decide which one to use if performance is a big weighting factor?
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:24:10|Prompt injection is top of mind for me right now. Anyone looked at automated prompt engineering ? There’s work done on this and published as a paper (with code)
jyotirmayjk Hackathon|2023-06-06 22:30:31|This would have been shared earlier in the group  So far it’s the closest to prompt engineering resource I’ve seen  https://github.com/microsoft/guidance
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:32:11|I’ve come across guidance but we’re figuring out how langchain and this fit in together. Have you built with this framework and do you have suggestions?
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:32:41|Kor is interesting for some use cases. Specifically structured data extraction
jyotirmayjk Hackathon|2023-06-06 22:33:19|No I haven’t used it.I’m still figuring it out too,feel that it’s slightly complicated 😅
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:39:11|I hear you. Lots of frameworks at this stage. Just the state of the tech right now
Adithya S K PESIT|2023-06-06 22:39:58|i am  using langchain for the agents part of it and guidance for places where structured out put is required
Sandeep Srinivasa RedCarpetup|2023-06-06 22:42:24|people who are using langchain here, just curious - which agents are u folks using ?  i have generally seen RetrievalQA and VectorDBQA being the most popular. just trying to get an idea which ones have u seen being useful in production.
~ Nikhil|2023-06-06 22:43:37|Has anybody setup privategpt? I am thinking of using it for a project in my org. I wanted to see if there are any caveats / pitfalls before hand
~ Shirsha|2023-06-06 22:44:04|Is this similar to guardrails.ai?
Nirant|2023-06-06 22:44:13|Yeah, you can't use it your org. Research license only for Llama
Rajesh RS Generative AI WhatsApp Group|2023-06-06 22:45:06|Using SQL and the ones you mentioned
~ Nikhil|2023-06-06 22:45:47|Thanks Nirant.  What are some options that we have considering we are in a heavily regulated industry?  Any form of data sharing (even temp storage) on 3rd party services is a challenge today.
Nirant|2023-06-06 22:46:53|If you're on Azure VPC, this should not be that hard tbh. But that said, you can make one using Falcon-7B/40B Instruct
Nirant|2023-06-06 22:47:02|That is permissively licensed
~ Nikhil|2023-06-06 22:49:41|If we use Azure OpenAI and we don’t choose the option to share data with openAi, am I right in my understanding that this data will be local to your model deployment?
Rounak Datta Hackathon Winner|2023-06-06 22:50:39|Guardrails is for making sure LLM output is in desired schema, they're talking about prompts in the other message
Sandeep Srinivasa RedCarpetup|2023-06-06 22:51:01|data will be local to model yes. but you will still violate india data residency regulations (if they apply to you) since data will cross India borders
~ Nikhil|2023-06-06 22:51:39|Those regulations do apply to us. Thanks Sandeep for your input.
~ Nikhil|2023-06-06 22:53:16|Azure should make these models available in the India region. Any idea if that is in the works?
Abhinav Verma Longshot.ai|2023-06-06 22:55:38|This was a question someone wanted to ask Sam Altman
Sandeep Srinivasa RedCarpetup|2023-06-06 23:00:25|my bet is not possible - unless US regulations on export of LLM gets clarified. will take some time, but eventually will happen.
Sandeep Srinivasa RedCarpetup|2023-06-06 23:00:34|until then - it is Falcon 40B
Pranjal Yadav Razorpay|2023-06-06 23:20:25|Sandeep - are you fine-tuning falcon-7/40b for custom use? ‎[6/6/23, 23:22:17] Shashank Generative AI Group: ‎image omitted
Rounak Datta Hackathon Winner|2023-06-06 23:28:50|"Even I interpreted the meaning of the excerpt the way ChatGPT thought of it.  > here, the first ""I don't think"" is redundant Why/how do you say so?"
Adithya S K PESIT|2023-06-06 23:31:48|[PHONE] what is your take on Tree of thought?
Shashank Generative AI Group|2023-06-06 23:34:33|"based on the video.  these are cues which text doesn't pick up. basically he started a sentence ""i don't think..."" then interrupted it with ""it's smart"" and continued ""but i don't think..."" ‎[6/6/23, 23:38:46] Swastik Banerjee: ‎image omitted"
Swastik Banerjee|2023-06-06 23:39:47|I mean, does it make sense to say “there is an embeddings model for gpt-4” or are they unrelated/independent?
Rounak Datta Hackathon Winner|2023-06-06 23:59:55|Completions model accept plaintext toh, so whether you embed or not pre-completion is independent/use-case wise. And for embeddings, you may choose OSS (say sentence-transformers) as well, OpenAI's embedding service is just another option.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:05:35|not really - im on the side of working with prompts and vector db to do the same stuff that a finetuning would.  but i admit there might be certain usecases which would work well with finetuning. genuinely curious - what kind of usecases (not data) are u looking to enable ?
Pranjal Yadav Razorpay|2023-06-07 00:08:33|They are independent. I choose HF's instruct over ada-002 usually.
Pranjal Yadav Razorpay|2023-06-07 00:11:35|7b fine-tuning to get a reasonable QnA performance with all prompt engg possible.  Both one-shot and few-shot haven't worked well for 7b or less size models. Plus figuring out internal hosting optimizations, it's a requirement due to data related constraints.  After QnA, there are a few more use cases.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:14:14|super interesting. ur saying the prompts havent worked ? are u using the standard langchain chains/prompts ?   typically i have seen this is a quirk of how their chain of thought functions. did u try your prompts with GPT (even if u dont plan to use them long term)
Abhinav Verma Longshot.ai|2023-06-07 00:16:13|Can you share model card for this?
Prayank Swaroop Accel|2023-06-07 00:16:50|Folks basic question - when does one use LlamaIndex vs Langchain ?
Pranjal Yadav Razorpay|2023-06-07 00:17:41|Yes, it worked reasonably well with gpt-3.5, even zero-shot was okay in some cases.  I tested standard chains and then some custom templates for priming and instruction tuning wherever possible.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:21:52|this is very interesting. i am pretty sure u will get bang for buck by writing custom chains for falcon. unfortunately i havent done so, or i would have pointed out.
Pranjal Yadav Razorpay|2023-06-07 00:22:28|This thread from [PHONE] answers it well  https://twitter.com/NirantK/status/1656803881308024832?t=a4rhYFXV9dOm5UMzDFbPvg&s=19
Pranjal Yadav Razorpay|2023-06-07 00:25:27|No clue how to approach it but worth a shot. Are you hosting privately as well? I want to understand cost and scaling dynamics.  Not considering AWS/databricks/HF inference solutions for now.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:28:17|not yet. but there seems to be a whole bunch of startups who are providing inference hosting. its generally commodity, but the key is going to be GPU rates/availability which seems to be the blocker these days.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:28:31|that said AWS Sagemaker might end up being the cheapest.
Sandeep Srinivasa RedCarpetup|2023-06-07 00:28:43|P.S. Falcon was trained on sagemaker
Dr. Pratik Desai KissanGPT|2023-06-07 05:11:35|Well deserved. ggerganov single handedly making Bulgaria an AI power house. Meanwhile, Nat and David Gross have been supporting many Indie hackers, challenges and sponsoring similar events here in Bay, too. We don't have any significant project like this coming out of India. Not even fine tuned models like what Teknium is doing.
Hemant Mohapatra|2023-06-07 08:29:17|Has anyone built their own GPU rig or knows someone who has?
Aditya Agrawal SuperU|2023-06-07 08:46:06|[PHONE]  have you guys done anything like this? ‎[6/7/23, 08:47:54] ~ Deven: ‎image omitted ‎[6/7/23, 09:08:28] Sourasis Roy: ‎image omitted
Bulia Siddharth Aurashop|2023-06-07 09:12:18|Woah!!!
Nirant|2023-06-07 09:16:59|cc [PHONE] [PHONE]
Sanyam Bhutani|2023-06-07 09:17:53|Ty!  Happy to answer any Qs 🫡
Dr. Pratik Desai KissanGPT|2023-06-07 09:21:15|I need help with board specs to build 7 3090 GPU rig and dealing with multi PSU pwm sync. Any suggestion?
Jithin James Ragas|2023-06-07 09:21:39|whoa that is cool! would love to hear ur experience after the event 🙌
~ HP|2023-06-07 09:24:57|I am building a document similarity project. I created text embeddings using USE. But is there a way to use BERT tuned on my corpus so it learns domain specific elements and gives better text encodings ? The methods I have seen are supervised - create pairs of sentences and provide a similarity score for training data.  Is there an alternate unsupervised way ?
Pratik Bhavasar|2023-06-07 09:34:22|On text gen evaluation, I found this prompt in the new Andrew NG course on LLM ‎[6/7/23, 09:34:27] Pratik Bhavasar: ‎image omitted
Pratik Bhavasar|2023-06-07 09:35:57|Does anyone here use Jina?
Shan|2023-06-07 09:44:38|in general, bert encodings don't work so well for similarity (our experience, I'll see if I can try to find references). FAISS might be better than USE (again, our experience), you might want to try that.
Shan|2023-06-07 09:45:12|also see https://www.sbert.net/docs/usage/semantic_textual_similarity.html for BERT embeddings for similarity
Shan|2023-06-07 09:46:31|it also has domain adaptation, etc. But honestly, the BERT vocab isn't so big (intentionally) so there might be trade offs depending on the data you have.
~ HP|2023-06-07 09:46:37|Yes I explored this one. But this requires you to have a pair of sentences with similarity score for training.
~ HP|2023-06-07 09:48:31|Does FAISS have domain specific adaptations ? Will definitely explore this one.
Nirant|2023-06-07 09:52:07|FAISS is a similarity library, and does not support finetuning or training vectors. Did you mean to say that direct vector similarity works?
Shan|2023-06-07 10:13:08|yes, in our final implementation we trained vectors using fasttext on our own corpus and then the similarity is using faiss.
~ Vrushank Vyas|2023-06-07 10:39:22|Just saw this: LLM with 5 million token window (can engulf a company's whole codebase)  OpenAI is also working to drastically increase context length. Many AI apps may have to go back to the drawing board when that happens  https://twitter.com/magicailabs/status/1666116935904292869
Ambika Computational Mama|2023-06-07 10:42:33|What’s a gpu rig? Do you mean a computer or like those crypto garages
Sandeep Srinivasa RedCarpetup|2023-06-07 10:44:45|"Actually this is the question I'll try to ask Sam Altman tomorrow, if I get a chance to. With large token window sizes, it is impractical to send the context each time with the query  So will OpenAI provide a hosted ""context storage"". Or in other words, a vector DB?"
Yash Bonde|2023-06-07 10:57:43|We have a 3070 rig for gaming. Looking to build a larger for ML.  But also if support for apple M-series GPUs gets better is it really worth making one or just getting like a Mac Studio?
~ Vrushank Vyas|2023-06-07 11:00:15|OpenAI is maai baap 🥲  Ideally, all app interactions, how we do prompting would also change
Sudharshan GenAI|2023-06-07 11:04:24|When's the next Gen AI meetup?
Nirant|2023-06-07 11:06:03|24th June tentatively, hasn't been announced anywhere yet — experimenting with a format change, might not do talks this time
Sudharshan GenAI|2023-06-07 11:09:19|Sure
~ Mayuresh Bakshi|2023-06-07 11:09:50|‎You added ~ Mayuresh Bakshi
~ HP|2023-06-07 11:28:17|Does fasttext provide non supervised training on corpus ?
Nirant|2023-06-07 11:28:51|Yes. fasttext is popularly used for embedding, you do not need labels.
~ HP|2023-06-07 11:31:17|I thought so too. Evaluated it for similarity but end up using nmslib.
Shubham Sharma 2012C6|2023-06-07 11:34:30|Does anyone know of any api/tools that implement something like this?  https://arxiv.org/pdf/1904.05440.pdf
Shan|2023-06-07 11:38:04|aieeeeee I wrote FAISS when I meant fasttext. Sorry for the confusion, my bad ... 🤦‍♀️
~ Vihang Agarwal|2023-06-07 11:38:30|‎You added ~ Vihang Agarwal
~ Kartik Muktinutalapati|2023-06-07 11:38:33|‎You added ~ Kartik Muktinutalapati
Swastik Banerjee|2023-06-07 11:41:25|```fasttext``` is a text classifier right? What exactly do you classify your texts into before doing a similarly search? Can you give an example?
Shivendu Kumar|2023-06-07 11:43:37|Fasttext is embeddings.
Shivendu Kumar|2023-06-07 11:44:26|word vectors specifically.
Shivendu Kumar|2023-06-07 11:44:35|See https://fasttext.cc/docs/en/unsupervised-tutorial.html
Nirant|2023-06-07 11:44:43|*subword vectors, and for the longest time — the best subword vectors
Nirant|2023-06-07 11:45:28|And even today, if you're doing something like really fast, think Cloudflare Edge workers or Raspberry Pi — the best quality vectors you can train there in theory
Swastik Banerjee|2023-06-07 11:47:10|might be a noob question sorry as I’m learning on the go, but how is it different from an embedding model like openai’s or HF’s?
Shivendu Kumar|2023-06-07 11:47:32|And thanks to this approach, it's quite tolerant of spelling mistakes!
Nirant|2023-06-07 11:49:02|1. It works™️ 2. It's fast on CPU, both train and inference 3. Doesn't need you to send data or GPU
Swastik Banerjee|2023-06-07 11:51:41|okay so you don’t have to call the API everytime
Shivendu Kumar|2023-06-07 11:52:09|you can run it locally. very lightweight.
Ambarish Ganguly|2023-06-07 11:52:35|Has anyone deployed Qdrant in production cloud ? Would be interested to hear
Paras Chopra Wingify|2023-06-07 11:52:35|Locally is best I think
Ambarish Ganguly|2023-06-07 11:52:52|Cloud as in Azure AWS Gcp own subscription
~ Vik|2023-06-07 11:54:38|i ran a similar search api for a papers startup for years with an allen ai model from hf for embeddings and aws open search with a knn index
Nirant|2023-06-07 11:54:46|Quite a few folks run their own Qdrant over Docker, their Discord has some folks working on optim for this too.
Shivendu Kumar|2023-06-07 11:54:50|Also, fasttext is trained on a subword level. But OpenAI embeddings are on a sentence level. You can create sentence embeddings from fasttext by averaging out the vectors for each word but they will get heavily degraded with the increase in the length of the sentence.
~ Vik|2023-06-07 11:56:09|worked great and was zero cost since we computed the embeddings on our laptop and updated production open source a couple times a day however today i would go with open I embeddings endpoint
Ambarish Ganguly|2023-06-07 11:56:37|Yes Docker Qdrant on cloud Azure AWS that's what I am after
~ Vik|2023-06-07 11:56:49|i used hf sentence transformer for creating embeddings before worked great
~ Vik|2023-06-07 11:58:06|this is the case with most embeddings i would compute embeddings per short paragraphs over pearce blocks of text
Swastik Banerjee|2023-06-07 12:02:45|you mean chunking the documents right?
~ RISHAV|2023-06-07 12:03:32|"Need some suggestions, My use-case -: I have some documents that I have converted into embeddings and stored in a VectorDB. Now I need to kind of chat which the document or perform some query on top of the document.  What I am doing -: Using MiniLM for embedding and Falcon-7b-Instruct for query purposes. Question -: Which model should be the right one for this use case, an ""instruct"" or ""chat model""."
Abhinav Verma Longshot.ai|2023-06-07 12:09:42|You want to use one that is better for search. You can start with minlm and even try coheres embedding and go from there.
~ RISHAV|2023-06-07 12:13:28|"So search part I can experiment with different models like MiniLM or instructor-xl. But should I go for an ""instruct"" model or a ""chat"" model, will that matter much in the performance?"
Abhinav Verma Longshot.ai|2023-06-07 12:15:25|That won't matter. Quality of the model will matter. Try with the 7b instruct and go from there
~ RISHAV|2023-06-07 12:18:05|Also for POC purposes, I am using ChromaDB. Do you suggest trying Weaviate etc? I think the search will differ.
Nirant|2023-06-07 12:27:43|Weaviate supports hybrid search, which we know from MIRACL and BIER both is better than doing just Vector Similarity
Nirant|2023-06-07 12:28:32|It's also wayyy more performant than Chroma e.g. in RAM usage, QPS etc
Akash Chandran|2023-06-07 12:29:44|😂😂
Gyan GenerativeAI Group|2023-06-07 13:18:11|This is for the people have created custom Langchain agents- Can you suggest how to create a Langchain agent for a python library?  I'm trying to understand how pandas langchain agent was created and if this can be replicated for other libraries as well.
Abhinav Verma Longshot.ai|2023-06-07 13:19:14|Look up Yolo pandas source code
~ Vibbs Dod|2023-06-07 14:57:36|I didn't do it for any lib, but I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook.  This custom agent I developed to add Metadata which I didn't want llm to handle.  Also, I learnt this by direct llm communication, then read the agent code which enabled me. And of course promp template and output parsers are also important.  If your usecase is simple agent with tools having input and output strings then you can leverage their decorator. Then focusing on prompt template and output parser is the important part.
Sandeep Srinivasa RedCarpetup|2023-06-07 14:59:37|>*I wrote a custom agent which basically let's llm decide what method or function needs to be called and then hooked a function execution hook*.  >*This custom agent I developed to add Metadata which I didn't want llm to handle*  hi - could you explain these two points ? these sound interesting, but im not sure how they are intended to work. would love to learn
Ojasvi Yadav|2023-06-07 15:30:30|Loud and clear 🤪
~ Abhinav (DreamBoat.ai)|2023-06-07 15:45:45|‎~ Abhinav (DreamBoat.ai) requested to join
~ Rohit|2023-06-07 16:03:39|is it just me or is the openai completion api throwing more errors than usual today?
Saurav Tomar GenerativeAI WA Group|2023-06-07 16:07:42|yes, for me as well. Had to restructure the entire prompt pipeline to accomodate for the subtle change.
Simrat Hasura|2023-06-07 16:19:21|Nirant, What is miracl and bier What is their use case
Abhinav Verma Longshot.ai|2023-06-07 16:20:22|https://github.com/beir-cellar/beir
Abhinav Verma Longshot.ai|2023-06-07 16:21:23|https://project-miracl.github.io/
~ Vrushank Vyas|2023-06-07 16:38:41|Curious about this - what kind of errors led you to change prompt pipeline?  This isn’t API outage but something else?
Shashwat TDC|2023-06-07 17:03:53|I spoke to multiple people over last 3 weeks. General perception of vc community and leaders is - AI is democratized and commoditised such that there is no inherent moat in llm apps. In some cases this was also supported by Google employee's email. Wanted to understand what are the views of the community here. Do you think LLM apps have no inherent moat?
Shashwat TDC|2023-06-07 17:04:50|‎POLL: Do you think LLM apps have no inherent moat? ‎OPTION: Yes, anyone can build wrapper apps (15 votes) ‎OPTION: No, there are enough nuances (23 votes)
Shashwat TDC|2023-06-07 17:05:58|Ofc i don't agree that llm apps have no inherent (tech) moat.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 17:06:02|The question isn't about moats around LLMs, it is about building viable businesses using it. I think VCs should probably look at the fundamentals of the business more than just the fact that the team happens to be using LLMs.
Shashwat TDC|2023-06-07 17:07:17|Yes. But argument is if business fundamentals are built on top of LLMs which have no moat. Anyone can build the business on top of the shiny llm tech
Soumyadeep Mukherjee|2023-06-07 17:07:37|I think at need to define what really a moat is here.  Any tech moat in the world is not really a moat given resources.
Soumyadeep Mukherjee|2023-06-07 17:07:59|Does it mean no moat?
Shashwat TDC|2023-06-07 17:08:16|Yes. We are talking about inherent product moat i.e. technology moat.
Soumyadeep Mukherjee|2023-06-07 17:08:33|Do you call Google a tech moat or distribution moat?
Shubham Sharma 2012C6|2023-06-07 17:08:42|Defensibility will depend on the nuances of the problem they are solving. In business context. In stickiness with users. In operating model etc.
Soumyadeep Mukherjee|2023-06-07 17:09:24|Also a lot of tech moat is a function of distribution and a lot of distribution moat is a function of tech. 🤷‍♂️
Shashwat TDC|2023-06-07 17:10:12|Google had a huge tech moat when they started. It was founders research thesis put to commercial use.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 17:10:25|I would argue that the presence of a moat is owed to production traction in the market. Does Pytorch have a moat? i'd argue yes. Does Azure or big cloud have a moat? I'd again say yes.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 17:10:40|*product traction in the market (not production traction)
Soumyadeep Mukherjee|2023-06-07 17:11:04|Then you’re saying moat is temporal too. Fair.  Then when someone says moat, we have to ask, moat for how long? 1y? 6 months or 5y?
Soumyadeep Mukherjee|2023-06-07 17:11:57|I don’t know how PyTorch needs to be evaluated here since it’s not a for profit business.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 17:14:32|Agree. It isn't for-profit, not a great example. Perhaps Azure / AWS are better examples
Soumyadeep Mukherjee|2023-06-07 17:15:04|Do you think they have a tech moat? Id like to argue they have a distribution or capital moat.
Shashwat TDC|2023-06-07 17:15:11|Yep. Absolutely. Now the question becomes if everyone is positioning to increase productivity (more specifically business productivity) what happens to product lifecycle and moat lifecycle.   It's like when everyone started producing quality content, overall attention span dropped.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 17:15:15|A temporary moat is just a head start. A moat is a long term deterrent to new entrants.
Hemant Mohapatra|2023-06-07 17:16:36|"as a VC actively investing in GenAI I wanted to provide some nuance from the ""other side"". The idea of moat is critical in building anything because lack thereof over-crowds the market too soon and without perfect knowledge, the capital needed to build a lasting company gets spread out too thin across a large # of ""attempts"". That said, if your only moat is ""building on LLMs"" then it's equivalent to when you were in the late 90s and were saying your only moat is ""building on the internet"". Was it useful -- absolutely; if you were early enough, there were not that many folks building into that ecosystem so you had less competition so ""being early was the moat"" to capture the users. Did it last, not much. Same happened with mobile or cloud ecosystems -- I remember in 2012 in the valley just how many startups started to put .io in their names to ride the cloud wave. It was def a moat for the early movers but soon everyone caught on. Only those that built lasting values survived and often they weren't the early ones. So if your only moat is being early to LLM waves and the layers above that are too thin / easy to build by others, then I'd say your moat is there but not going to last."
Ojasvi Yadav|2023-06-07 17:17:45|Most complete opinion I've read in this chat
Swapnika Hashmail Web3|2023-06-07 17:18:01|Moats of most large businesses have been on sourcing / distribution in the longer term. Most early technologies will be very easy to replicate (unless proprietary). VCs should be betting on good founders with a long term vision building in a growing market. Just being on an early tech edge is foolish imo.
~ Vibbs Dod|2023-06-07 17:24:34|"I think if you learn how to talk to LLM which is not very steep learning curve then ""Anyone can build a wrapper"".   But the question that needs to be considered is what does the app solve? short term - to long term?  Most of the early adopters like you mentioned in the vote might seem like a wrapper app. But in long run if they have a roadmap and vision to leverage to solve a real world problem using llm which scales and usable by anybody seamlessly not knowing what llms are then developers will need to have more than wrapper tech, they will have to build pipeline, hooks and many other tech incorporated. ‎[6/7/23, 17:31:55] Nirant: ‎image omitted"
Nirant|2023-06-07 17:33:40|As a compute user, I'm also bullish that more large enterprises will see their costs go down by adding self-owned compute to their cloud usage — DC design will have to evolve to adapt for this
Kaushik Bokka|2023-06-07 17:34:19|Intel Bangalore works on Intel Habana Accelerator. We could get someone to talk at one of the events
~ vignesh iyer✌️|2023-06-07 17:34:20|As someone who has actively worked with global Telcos and around network and data centers.. was in awe of this DC thread from [PHONE] earlier today
Shan|2023-06-07 17:35:21|IMO here are the ways to look for moats in the LLM land (from the tech perspective) as it stands today.  1. Input Data a. Proprietary data which no one has b. Cleanups / dedup / selection etc which no one else knows how to do c. Tagged data or such which is very valuable 2. Building and operating LLMs a. Smaller, faster, cheaper b. Techniques which no one else knows of c. Custom LLMs which no one else is building d. Side LLMs (proprietary) which help in better prompting, etc. 3. Integrations a. More integrations with LLMs than others b. Smarter integrations which leverage LLMs + some outside tool(s) 4. QA a. Better QA than anyone else so that you can give more confidence than others about LLM outputs regarding discrimination, jailbreaking/safety, hallucinations, factual responses etc  Happy to hear others' thoughts and add to my list
Shashwat TDC|2023-06-07 17:44:01|Amazing. This kind of defines the nuances in a structured way. I can probably add 5th point after QA is - memory management.   Akin to human intelligence, how well you are able to retrieve old QAs will also define the success.
~ Krishaay|2023-06-07 17:48:07|‎~ Krishaay joined using your invite
Siddharth Agarwal|2023-06-07 17:48:49|My intuition is that LLM API apps have a very limited moat, but apps built atop open-source LLMs with the right amount of messing around will have solid moats.
~ Kp|2023-06-07 17:50:52|And some new features/frontiers  Multimodality (Aural and Visual) (Something even OpenAI finds difficult to release enmasse) Higher context windows (In the scope of 100s of thousands to millions) (Very useful for better intellisense/code completion) Pocket LLMs which can run on regular devices like smartphones in an offline/online capacity (Currently being worked on, but very weak) Multilingual llms And of course, we have definitely not extinguished prompt engineering techniques which is a main factor in what pushed GPT and LLMs into the front base
~ Kanchi|2023-06-07 18:29:36|You can watch it live here: https://www.youtube.com/watch?v=AiE7FsdRzz8
Haridas Pai Ai Air2 Founder|2023-06-07 19:08:12|‎Haridas Pai Ai Air2 Founder joined using your invite
Shan|2023-06-07 19:42:00|personally I'm not convinced that vanilla prompt engineering is a moat. In my mind, prompt engineering is to llm what SEO is to search. You are trying to outsmart others but it's all kinda hacky. Pretty soon, everyone else is also doing it, so you are back to square one. Or (worse) the underlying algorithm changes and all your efforts are gone. There is something to be said about generating prompts intelligently using some proprietary data, feedback or using some other LLMs that can be a lasting moat which I look to capture in (2) (d) in my list. Happy to hear from others
Thrivikram Taula|2023-06-07 19:44:41|‎Thrivikram Taula joined using your invite
~ Kp|2023-06-07 19:44:44|What about an autogpt style prompt engineering?
Paras Chopra Wingify|2023-06-07 19:46:43|LLMs are like databases.  Databases aren’t moats. What you do with is a moat.
Sandeep Srinivasa RedCarpetup|2023-06-07 19:49:48|My long thesis - infrastructure is the model. The pipeline is - including the prompt selection, inference, prompt caching, jsonforming, private data filtering, etc etc.
Abhishek Mishra|2023-06-07 19:49:57|This would depend heavily on the underlying model itself. If everyone is using the same model, everyone is also going to use same best practices to get functional autoGPT behaviour.
Ranjeet Walunj iMayavi|2023-06-07 19:54:08|It was funny to listen to the questions asked by learned men/founders/VCs to Sam Altman. I mean - Are these the same people giving full time gyaan on all platforms asking some questions to just get noticed or for the sake of asking questions. :/
~ Prajna Prayas|2023-06-07 19:54:35|I think the moat is you throw many things at the wall and see what sticks.
Abhinav Verma Longshot.ai|2023-06-07 19:56:29|Don't call LLMs databases. I know it might have good recall but this just gives more ammo to people who think all LLMs do is memorize and plagiarize work
ashish Acgt01 Twitter|2023-06-07 19:57:20|Care to share a few examples ? I know there was an ET TCS event in Delhi today but haven't seen what questions were asked.  But tbh not surprised, amplified version of tech company structures where CEO s(non hands on people), make critical decisions about company strategy and investments without deeply understanding the tech in depth ‎[6/7/23, 19:58:03] Nirant: ‎image omitted
Shan|2023-06-07 20:02:12|Disagree. There’s at least some amount of logic/reasoning which is a game changer. See the Sparks of AGI talk (or paper) https://youtu.be/qbIk7-JPB2c I think most of the wow going ahead is going to be in the reasoning/planning/logic side of things. I don’t see LLMs replacing databases as such. Again, happy to hear thoughts otherwise
Paras Chopra Wingify|2023-06-07 20:02:55|I don’t mean it in the sense of what databases do, but in the sense of they being infra components
Sidhant Sequoia|2023-06-07 20:08:05|Kunal Shah asked sama a very interesting qn at the ET TCS event today.  “What has AI taught you about humans?”  The response was equally interesting. (Paraphrasing, don’t remember the exact - it’s an interpretation).  “Humans have always imagined themselves to be the center of the universe, and that’s been increasingly disproved through the history of science and technological advancement. The most recent case is of intelligence of this order being unique to humans. The work at OpenAI has taught me that intelligence is a fundamental property of matter.”  The last sentence really struck a chord I hadn’t thought of, ever. Still don’t know what that means.
Sidhant Sequoia|2023-06-07 20:11:33|The other thing which was cool, and he’s of course said this many times but it’s always interesting to hear it again, is that energy and intelligence are two core units of our world, the decreasing costs of which have traditionally driven technology and society forward.  Naturally a reference to helion and his fundamental belief that fusion could create energy sources that are an order of magnitude (or a few) cheaper than energy today.
Sidhant Sequoia|2023-06-07 20:16:30|Btw I hope this is interesting, just thought I’d share what stood out for the group’s benefit.  The question that was most well received by Sama (amongst a barrage of other not-the-smartest/kindest questions) was the Fractal founder’s question.  “What are the evals you would use to measure AGI, as and when you get there?”  He didn’t have a deep answer to it, but was very clear in the belief that the sparks of AGI hypothesis in the MSFT research work is mistaken. GPT4 is nowhere close to AGI, but the question of how to evaluate AGI is the one they are spending the most time thinking about.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 20:16:43|That’s interesting insight
~ Mayank Gupta|2023-06-07 20:17:40|This will make a killing in the Philosophy group!
Rajesh RS Generative AI WhatsApp Group|2023-06-07 20:24:14|I’ve wondered about the hypothesis of whether empowerment really brings betterment. Lest I get called out that is something to think about. When we build new differentiated capabilities and tech and put it in the hands of people, are we doing the fundamentally right thing? What is the right thing and how would it be decided? These are questions of technology and ethics. One of the old sci-fi shows I liked often saw this kind of theme and it makes you think about whether capitalism combined with a scientific / technological industrial complex produces more inequality and overall more downsides than upsides.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 20:24:34|This is probably a post for the philosophy group though. Sorry to have posted here
Nirant|2023-06-07 20:28:25|AI, Policy and Philosophy group link for reference:  https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Pratik Bhavasar|2023-06-07 20:50:22|I have another opinion. Moat is the sum of all advantages. So model also ads to moat.  Airbnb for examples has tons of data, ML models, UI, user<>supply network etc. Everything ads to the moat.
Nirant|2023-06-07 20:51:40|Pratik worries so much about ads, it adds up to ads
Abhinav Verma Longshot.ai|2023-06-07 20:52:38|Marketing matters. Atleast in gen AI space. The amount of people who said retrieval qa is training on your data to sell
Prayank Swaroop Accel|2023-06-07 20:54:00|Today Sam compared GPT4 to the old Nokia brick phones and said GPT15 will be very different and we won't remember GPT4. Just FYI.   I wanted to say this here since we all need to think about how all this will change in one two three years. Though the tools we use are today's.
Prashant Singh|2023-06-07 20:54:11|Strange. Is he making a case that intelligence can't be substrate independent?
Ranjeet Walunj iMayavi|2023-06-07 20:54:49|I tbh found that question bit rhetorical. Like kunal already has an answer in his mind and he wants to validate his point of view. Also, what sama answered was equally interesting. 😬 ‎[6/7/23, 20:57:05] Pratik Bhavasar: ‎image omitted
Nirant|2023-06-07 20:58:41|The Gujarati in me thinks this is fair game, the engineer in me thinks this is blasphemy. The net result is I've not made anywhere close to the money this person has made from git cloning langchain docs
Pratik Bhavasar|2023-06-07 20:59:25|Something I know by talking with one of the founder is many of them actually tried training davinci on docs and failed and then they came to know RAG works better
Pratik Bhavasar|2023-06-07 20:59:42|What’s his MRR?
Nirant|2023-06-07 21:00:06|And more people ask Tanmay Bhatt and Varun Mayya questions about AI than you or me [PHONE] bhai — so clearly, distribution wins over knowledge. Everywhere.
Abhinav Verma Longshot.ai|2023-06-07 21:01:08|It was 60k last month.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:01:28|Yes, who asks Wes Mckinney about Pandas for example - poor guy probably is busy building away and being ignored. And this is also the reason why Bernard Marr's articles on AI are everywhere 😅
Pratik Bhavasar|2023-06-07 21:01:42|Good for them!
Pratik Bhavasar|2023-06-07 21:02:56|That’s why I want to learn frontend. AI is looking a weak part of my own moat now
Abhinav Verma Longshot.ai|2023-06-07 21:03:24|[PHONE] se seekho
Nirant|2023-06-07 21:03:54|We've had this convo. And we've digressed quite a bit from the topic :)
Abhinav Verma Longshot.ai|2023-06-07 21:04:25|Context window se baahar ho gaya
Abhinav Verma Longshot.ai|2023-06-07 21:04:44|Need a vector db for my brain
Ramsri Goutham|2023-06-07 21:20:23|My motivation is that if my AI SaaS apps fail or I get bored in a few years, I wanna be atleast the most eligible CTO in the market 😅
Abhinav Verma Longshot.ai|2023-06-07 21:20:58|I think this becomes more important now that our jobs are starting to come in the line
Sachin Legaltech|2023-06-07 21:24:39|Deepmind trained alphazero style (SoTA models on Go, Chess and Shogi) Reinforcement Learning agents to find faster algorithms for sorting and hashing. In this algorithm finding game, their state was assembly instructions selected till now and information in registers and action was the next instruction to add to the algorithm. This problem will be as complex as playing chess or Go and the algorithm for sorting discovered by AlphaDev is 70% faster for shorter sequences and 1.7% faster for long (>250,000) sequences. https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms
Pratyush Choudhury|2023-06-07 21:24:41|https://www.youtube.com/live/AiE7FsdRzz8?feature=share  55:00 onwards
Bharat Kumar Ramesh Hashmal Web3|2023-06-07 21:28:39|Also feel there's a bit of an over indexation on moats. It makes perfect sense for VCs - their business model is to search for an outlier co, a 100xer that has strong defensibility  That being said, we also saw extraordinarily successful and profitable ludo and crossword apps that came early on, and ones afterwards that overtook them  Basically, tons of tiny opportunities to make hay while the sun is evaporating your moat
Abhishek Mishra|2023-06-07 21:30:18|Fair plan
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:32:51|What happens when we deliver the same experience on a platform which provides many more opportunities to deliver value, is that new experiences overtake the ones we initially port to it. We see this pattern with other games too - we ported pong to a digital medium, but soon discovered asteroids can be a more fun game, and we could never have devised an asteroids game or a bricks game and its mechanisms in real life
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:34:02|The same thing will happen with AI - we build solutions to real world problems with AI techniques, only to discover that there is a set of impactful AI specific capabilities that can drive even more value from AI than the ones we set out to solve. And these couldn't have been solved without the AI
Abhishek Mishra|2023-06-07 21:35:40|Just a take from side for the sake of an argument: Distribution and knowledge both are leverage of their own kind. They both also lose their value when your competitors have access to the same level of distribution or same level of Knowledge.   However, I'm well aware that the level of knowledge to distinguish oneself on the same level is going to be very high, distribution might be more accessible via marketing/networking.
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:37:54|This is true. There has to be a term to describe the asymmetrical success of bullshitting.
Nirant|2023-06-07 21:38:49|Brandolini's law 🤣
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:39:26|TIL https://en.wikipedia.org/wiki/Brandolini%27s_law
Rajesh RS Generative AI WhatsApp Group|2023-06-07 21:40:30|Idea for metaverse room - where Brandolini's law and Hanlon's razor meet
Bharat Kumar Ramesh Hashmal Web3|2023-06-07 21:49:12|Indeed. That's a great example. Using the same analogy, it's probably a good idea to start making pong, even if others are as well. You'll probably discover the idea of asteroids along the way  At which point, you'll have the knowledge of how to make a paddle, and how to model the physics of a ball bouncing off it
Paras Chopra Wingify|2023-06-07 21:52:35|This is why AI-native startups (starting now) have a different kind of advantage over existing incumbents (who have distribution advantage)
Azhan Mohammed Generative AI WhatsApp Group|2023-06-07 21:57:26|How to change pose of a person keeping identity constant, like i wanna take a source image, just change the direction in which a person is looking and regenerate the image
Ankur Pandey|2023-06-07 22:01:08|Can anyone give a tl;dr of Sam Altman's Econ Times talk? Or the most interesting bits?
Ankur Pandey|2023-06-07 22:02:32|Or is it worth watching in full? (had planned to watch but randomly saw Prasoon Joshi in the audience so kinda depriortized it abhi)
Paras Chopra Wingify|2023-06-07 22:03:00|Lol
ashish Acgt01 Twitter|2023-06-07 22:06:27|LLMs outperform RL at game play by studying papers and reasoning through chain-of-thought.   https://arxiv.org/pdf/2305.15486.pdf
Anshul Khandelwal Invideo|2023-06-07 22:11:38|New open source text to video model: potat 1 by camenduru   https://twitter.com/camenduru/status/1665635019790876673?t=Z9JEG19jpvf-5s8d3kvBbw&s=19
Shashank Generative AI Group|2023-06-07 22:20:36|came across this via LiverDoc's thread?
Abhinav Verma Longshot.ai|2023-06-07 22:21:11|Ya he's been on a crusade against fitness influencers recently ‎[6/7/23, 22:21:49] Gokul Krishnan: ‎image omitted
Pranjal Yadav Razorpay|2023-06-07 22:28:56|[PHONE] - two questions from this, when I load the dataset via HF, the feature order is reversed (answer, question), was it same with you?  When I generate text post fine-tuning, it produces the answer and then the assistant starts another round of QnA by itself until the max tokens are reached. How does it know when to stop without reaching max limit?
Ciyunni|2023-06-07 22:30:38|Complex Product processes can be moats as well.
Pratik Bhavasar|2023-06-07 22:48:58|Doing complex and boring things are great moats!
ashish Acgt01 Twitter|2023-06-07 22:53:26|"Using RL to improve sorting algorithms  https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms  Also what do folks think of this : Nature has a policy that all code must be released from papers - but apparently Deep Mind has released the ""pseudocode"" for the algorithm instead of reproducible code. Interesting how AI companies are can balance competitive advantage while still getting high impact pubs (https://twitter.com/andrewwhite01/status/1666494856212930561?s=46&t=pt9BgXoRTmqx5FEPyAl9bg)"
Abhishek Mishra|2023-06-07 22:54:24|This is scary and exciting at the same time. Alphadev could next discover the best possible compression algorithm, graph traversal algorithms and humans would start completing relying on alphadev like AIs.
Abhishek Mishra|2023-06-07 22:55:37|These algorithms have been integrated in llvm c++ sort library replacing previous known human benchmarks.
Sachin Legaltech|2023-06-07 23:03:36|The policy is “Authors must make available upon request, to editors and reviewers, any previously unreported custom computer code or algorithm used to generate results that are reported in the paper and central to its main claims.” Deepmind has a history of publishing in nature (since DQN paper in 2015) and they have never shared source code .
Paras Chopra Wingify|2023-06-07 23:06:42|Checkpoints for Openllama - anyone tried it yet? https://huggingface.co/openlm-research/open_llama_7b?text=My+name+is+Merve+and+my+favorite
~ Priyanka Thakran|2023-06-07 23:31:06|Got an extra ticket for a friend for tomorrow’s sam altman chat happening in iiit delhi. DM if anyone’s interested in getting one.
Aashay Sachdeva MPL Data Scientist|2023-06-07 23:32:41|Reminds me of Saurabh Mukherjea’s article on forming moats ([PHONE] don’t hate me for mentioning him)  https://marcellus.in/blogs/the-antifragility-test-applied-to-consistent-compounders/
~ Vishwam Jindal|2023-06-07 23:37:48|"Hi all  We got this from Anthropic:  ""Unfortunately, based on the information you've provided we cannot approve your current use of Claude for commercial purposes at this time due to risk of exploitability. We are continuously working on improving our model's safety and capabilities, and hope that we will have a more robust system for responsibly managing the risk of uses like these in the near future. Best, Landon Trust and Safety Team Anthropic""  Do people have access to Claude API for commercial use? Or someone else who has been denied on similar grounds?"
Abhishek Mishra|2023-06-07 23:53:42|They've shared implementation as llvm already integrated this in STD c++ sort library.  Here's the code review link of the same in llvm source - https://reviews.llvm.org/D118029
Sachin Legaltech|2023-06-08 00:05:21|They shared C++ implementation of the sorting algorithm discovered by AlphaDev. But they haven’t shared code of training AlphaDev.
Sachin Legaltech|2023-06-08 00:06:33|But deepmind usually doesn’t open source their code at all..Meta comes in and builds an open source version of deepmind papers.
Abhishek Mishra|2023-06-08 00:09:27|Ohh ok. Misunderstood the reference.
Abhishek Mishra|2023-06-08 00:10:04|Yes true.
Atishay Jain|2023-06-08 00:22:21|‎Atishay Jain requested to join
Ankur Pandey|2023-06-08 00:26:56|We have. They actually asked lots of detailed questions multiple times and it seemed like the quality of the response matters to them.  So maybe reapply with detailed, through answers.
~ Vishwam Jindal|2023-06-08 00:55:53|Thank you - might DM you for more information but will reapply for now.
Abhishek Mishra|2023-06-08 01:16:23|I've been trying to get access to Claude 100k for hobbyist experiments and couldn't get it even after trying twice.   Don't know what's the secret sauce they need in the answers. Probably need to write that I'll be solving world hunger or something via their api.
Abhinav Verma Longshot.ai|2023-06-08 01:20:34|We just gave them our use case and how we plan to use it. It was a technical answer
Abhishek Mishra|2023-06-08 01:21:46|What's the usual time they take to assess your application? Might need to brute force this one with multiple answers. Knowing how long should I wait before trying again would help.
Swastik Banerjee|2023-06-08 01:21:52|Can someone tell me how ```FAISS``` is better than a custom nearest neighbor classifier that one can build in Python, i.e., say using scikitlearn’s ```KNNClassifier```?
Abhishek Mishra|2023-06-08 01:29:40|I'm obscuring a few details for shorter answer - FAISS is awesome. They employ a bunch of techniques.  Basically optimal data structures, indexing, parallelism via CPU, GPU, optimal low level code implementations and leveraging efficient Lin algebra lib like BLAS
Abhishek Mishra|2023-06-08 01:30:41|Kind of like they went ahead and decided to improve SOTA block for each and everything in the pipeline for nearest neighbour similarity search and clustering.
Swastik Banerjee|2023-06-08 01:35:40|So does it only improve scalability, or are there minute advancements in the underlying algorithm as well, i.e., in terms of complexity?
Sandeep Srinivasa RedCarpetup|2023-06-08 01:37:30|1. It's not better in algo. It's better in performance. FAISS is fairly hand tuned.  2. FAISS comes with many algorithms that are battle tested like HNSW. U can choose between them to do an algorithm comparison.
Abhishek Mishra|2023-06-08 01:50:55|Mostly under the hood optimisations in the pipeline.   If you're interested in thorough benchmarks here is a good benchmarking for recall per query per second.   Reference - https://ann-benchmarks.com/
Abhishek Mishra|2023-06-08 01:53:35|And their really meticulously maintained GitHub repo with test suite for ann benchmarking you can try yourself - https://github.com/erikbern/ann-benchmarks/
Swastik Banerjee|2023-06-08 01:59:00|What is the definition of ```recall``` ?
Chirag Jain|2023-06-08 02:00:04|in this context #relevant/#everything that was fetched
Swastik Banerjee|2023-06-08 02:00:59|thank you very much
Nitin Mahajan McKinsey|2023-06-08 07:07:16|https://twitter.com/albtaiuti/status/1666464784995459074?s=48&t=dSB_vXgXsC6qhF1TYEKlZw
Saurav Tomar GenerativeAI WA Group|2023-06-08 07:19:15|GM fam, does anyone know of any test to determine consciousness of a system ? OpenAI claims that chatgpt4 isnt conscious, but how can they be certain if a future version of chatGPT is or isn't conscious .
Atishay Jain|2023-06-08 07:21:02|‎Atishay Jain joined using this group's invite link
Nirant|2023-06-08 07:22:33|This is perhaps best answered and discussed in the philosophy group of the community.
~ Suhas Baliga|2023-06-08 09:40:20|Good morning folks. Any laptop recommendations for text based LMs/NLP work? Cheaper the better, other functionalities irrelevant.
~ Apurva Bhatt|2023-06-08 09:45:38|Do you want to train ML on laptop or just do basic work on it and use VM for training?
Kartik Mandaville|2023-06-08 10:00:22|What alpha have people used for hybrid search? Are there any good papers/articles I should be reading/referencing?
Sandeep Srinivasa RedCarpetup|2023-06-08 10:03:37|https://twitter.com/RajanAnandan/status/1666641010284449792?s=20
Harsh Koo|2023-06-08 10:09:00|"#truth   Just gotta keep trying.  But one lament is that not one entrepreneur, rich businessman has come out to say, let's create resources - GPU clusters, dataset curation, training models.  We don't lack talent or money. But coordinated efforts over long periods without any in-between ""payouts"" still seems a luxury for us.  And it's not a matter of intention. We all want to, but you need backers who will give you a long rope and then not keep tugging at it."
Swastik Banerjee|2023-06-08 10:10:52|same question  any tutorial for deployment?
~ Suhas Baliga|2023-06-08 10:17:50|Train on laptop, yes.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 10:30:05|Sam had his Tony stark moment. 🤷🏻‍♂️
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 10:30:24|But didn't like his shrewdness.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 10:31:52|Good that Rajan sir took it sportingly. We shouldn't stop trying.
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:38:44|I'd say invest then
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:38:47|Razer blade is really sleek
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:39:11|Top class build quality. Latest model is ryzen 6900 with Nvidia 3080 gpu
Paras Chopra Wingify|2023-06-08 10:39:56|What’s wrong with what he says?  Companies end up specialising ultimately
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:40:02|If you don't want to get into Macs, it's the best
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:40:13|I also would recommend the Asus rog x13 or z13
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:40:26|Or even the G series
Bharat Kumar Ramesh Hashmal Web3|2023-06-08 10:40:35|But these are very sleek, very portable and powerful
~ Apurva Bhatt|2023-06-08 10:52:37|Most of my college folks use alienware gaming laptops for ML training because of high configuration.   I would recommend desktop over gaming laptops for these reasons a. Most ML folks are concerned about RAM and GPU size (GBs) not too much on speed like MHz, FLOPS (tradeoff can save a lot of money). b. Its easy to upgrade a hardware in desktop, laptops are not that friendly. c. Cooling systems are effective in desktop, Laptops heat up a lot after 8-10 hours of training. d. Need not spend much on faster display, better keyword etc.
~ Suhas Baliga|2023-06-08 10:53:03|Will check it out 👍🏽👍🏽
Nirant|2023-06-08 10:54:41|Friends, I think we've discussed laptops/personal compute quite often here -- and this forum isn't uniquely the best places for that. The wider web has more than enough answers which address ML specific needs.   Please respond to the asker directly :)
~ Suhas Baliga|2023-06-08 10:55:15|Thanks, this is super useful 😊
Abhinav Verma Longshot.ai|2023-06-08 11:23:51|https://twitter.com/goodside/status/1666598580319035392?s=46&t=URoDrV5X7GPNPYSgYW42Dw  Trust Riley goodside to come up with hacks on gpt
Nirant|2023-06-08 11:25:30|"These are called ""Glitch Tokens"" and a well known artefact of all token-based LLMs, dating back to embeddings themselves: https://www.youtube.com/watch?v=WO2X3oZEJOA&t=224s"
Sandeep Srinivasa RedCarpetup|2023-06-08 11:26:53|https://twitter.com/TheEthanDing/status/1666109071278104578  what do u folks think ? especially people who have worked with langchain, etc.
Abhinav Verma Longshot.ai|2023-06-08 11:27:40|I just read Llama index raised 8.5m
Raghotham Paypal Bargava's Friend|2023-06-08 11:29:30|In all my discussions with Google and Microsoft, they have been saying they are using langchain for their work
Nirant|2023-06-08 11:29:43|I am terribly sad that Langchain and Pinecone are not listed companies, I'd have made a killing shorting them
Raghotham Paypal Bargava's Friend|2023-06-08 11:29:47|Microsoft has something of their own as well, semantic kernel  IIRC
Raghotham Paypal Bargava's Friend|2023-06-08 11:30:22|So in the long term definitely we will have better platforms built. But as of today this we what most folks use
Nirant|2023-06-08 11:30:24|https://github.com/microsoft/semantic-kernel
Raghotham Paypal Bargava's Friend|2023-06-08 11:30:58|But that's part of any new tech evolution, right?
Nirant|2023-06-08 11:31:23|If you notice the folks Llama has been hiring, they're not a thin client which most folks are thinking about them. They're definitely looking to integrate backwards in the _same spirit_ as Ethan bhaiya said
Abhinav Verma Longshot.ai|2023-06-08 11:34:36|Looking at their work, they seem to be building towards having all types of data sources integrated with LLMs. It's a smart move as that is cumbersome. Moat like
Kaushik Bokka|2023-06-08 11:37:09|Llama index has more potential than Langchain as a company
Kaushik Bokka|2023-06-08 11:37:56|Man, you realize the impact of open source contributions when you see the growth of such products
Kaushik Bokka|2023-06-08 11:38:32|This is the very question I asked Jerry, how are you coming up with few strategies and features atm? He was like it’s all open source man
Kaushik Bokka|2023-06-08 11:38:38|The community is driving it
Kaushik Bokka|2023-06-08 11:38:54|new strategies*
Nirant|2023-06-08 11:39:02|Where is the +1000 emoji when I need it
Kaushik Bokka|2023-06-08 11:40:53|I know someone at the HF0 Residency is building a framework for creating Agents. He has a lot of credibility
Abhishek Mishra|2023-06-08 11:41:09|Langchain, llamaindex have positioning as hubs of all activity around LLMs, all new stuff like babyAGI, autoGPT, privategpt got sucked really fast into the langchain ecosystem.
Nirant|2023-06-08 11:41:10|As a point of comparison: You can also see Langchain team actively just ignoring issues and PRs both.
Kaushik Bokka|2023-06-08 11:42:42|Our boy is maybe too busy with developer advocacy haha
Aashay Sachdeva MPL Data Scientist|2023-06-08 11:53:15|To this point, since I just moved from a ML/ Data Scientist role to a VC role, one of the things I wanted to do is contribute back to the community. (I literally owe my career to them).  We are trying to fund a small number of open source projects. You can refer to this tweet. Ofcourse it will be nowhere near to what you would need to create a top library/model, but I hope it helps projects get off the ground -  https://twitter.com/brijbhasin/status/1666663734385979392?s=20
Pratik Bhavasar|2023-06-08 11:53:15|How exactly?
Ojasvi Yadav|2023-06-08 12:15:08|"I think VCs should try and support research based firms. I can understand their desire for investing in money making engines. But in order to have an Indian deepmind or an Indian openAI investors should soften themselves up towards startups that are in search for new models, that are in search for new training methods.  OpenAI and deepmind didn't start out as ""businesses"", they started out as research factories. But now they're in a position to monetize their research, which is their moat.  Maybe my view is biased because of only coming across funding rounds for fancy wrapper firms, and not for the boring research firms. But this has been my observation so far."
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:20:09|Curious - how much do these cost? And what kind of investment in terms of time, money, and human resource we're looking at here?
ashish Acgt01 Twitter|2023-06-08 12:21:41|Amjad Massad of replit is always on point with his wit ! https://twitter.com/amasad/status/1666690663587680257
Dr. Pratik Desai KissanGPT|2023-06-08 12:25:26|True. Throwing 10M is not to going to create another OpenAI. Also, I talked about this thing two days back that we haven’t even seen fine tuned Llama, like Teknium is training, from India, which will cost 2-3k. Because India is not focused on indie hacking, taking a deep problem heads on, but everyone wants to build quick tool to raise money.
Dr. Pratik Desai KissanGPT|2023-06-08 12:26:44|And May be investor mindset also set the the tone for entrepreneurs.
Pratik Bhavasar|2023-06-08 12:27:04|Just saw this - https://twitter.com/etnowlive/status/1666460799093620738?s=46  Why compete on foundation models when there is a cemetery of failed or outdated models?  From the models coming out it seems releasing usable instruction tuned model is not dependent on funding in millions or proprietary skill set.
Paras Chopra Wingify|2023-06-08 12:27:24|i think it boils down to research mindset, barring a few universities in india, we don't have a research culture
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:27:35|VCs are not interested in making bets anymore. They're only interested in ensuring returns. Risk averse VCs are best paired with fixed deposits, not investing in high risk ventures like tech startups
Nirant|2023-06-08 12:28:11|Ilya used to charge $1M/year in 2017. That's one senior exec at OpenAI.
Kunal Bhatia Hexo|2023-06-08 12:28:34|Midjourney is an example of a small bootstrapped team taking on OpenAI and building a better foundational model
Nirant|2023-06-08 12:29:00|"Safe to say we don't have affordable talent to make a super computer either, which Azure built specifically for LLM training and inference workloads for OpenAI.   As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is ""hopeless"""
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:29:02|1 million per year as a salary in SF is more common than we might think. Only normal that well funded startup talent receives such money
Pratik Bhavasar|2023-06-08 12:29:02|…  I think we should complaint about lack of investor trust after we put an instruction tuned Falcon at top of Open LLM and Helm by fine tuning with less than <$1000 budget
Nirant|2023-06-08 12:29:03|I mean, look at the number of Asians (Chinese, Japanese, Koreans) building LoRA on Civitai, and look what we've for desi celebs/art forms. If we don't even have 10K LoRAs, where the talent, compute, cost —  is basically hobby tier: $100 or less —  I don't think we've a fair shot at even training GPT4.
Soumyadeep Mukherjee|2023-06-08 12:29:20|I think you should talk to a vc before being this strongly opinionated.
Nirant|2023-06-08 12:29:22|We can realistically can do Falcon, but is there a single private investor/funder willing to risk even $150-$200K for that? (not counting IITs, GoI)   I do think companies directly impacted by LLMs e.g. IT Services giants like Infosys, TCS have an incentive to do this. But I've no information if they are doing so.
Paras Chopra Wingify|2023-06-08 12:29:49|what is the benefit for commercial entities doing academic research?
Nirant|2023-06-08 12:30:32|I suspect that is part of the issue — this is NOT research
~ Parth|2023-06-08 12:31:12|TCS sponsored ET for hosting Sam 😅
Paras Chopra Wingify|2023-06-08 12:31:15|foundational models are not research? do you mean taking existing architecture and replicating runs?
Pratik Bhavasar|2023-06-08 12:31:34|Why do you need $200k?
Nirant|2023-06-08 12:31:34|Falcon-sized Foundations Models are not research
Nirant|2023-06-08 12:32:00|So that I can afford engineers like you in addition to the compute and data. I don't think it's fair to ask you to volunteer your time.
Nirant|2023-06-08 12:32:07|Or pay you below market rates either
Kartik Mandaville|2023-06-08 12:32:08|I kind of agree. We started with llama index and are now building outside of it - we're obviously very small and exactly fit their usecase but it just does not work for prod (scale etc)
Nirant|2023-06-08 12:32:41|Did you've to step out become of complexity or scaling challenge
Soumyadeep Mukherjee|2023-06-08 12:32:43|[PHONE] I think 200k isn’t enough btw
Pratik Bhavasar|2023-06-08 12:32:46|But you can do it yourself with your 10k budget and keep all the equity. My point is it does not require many engineers
Nirant|2023-06-08 12:33:00|Fair, I'll ask [PHONE] for the rest
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:33:04|Pay entry level salaries of 3.2 lakhs in 2023, and sponsor million dollar conferences. Priorities are right.
Pratik Bhavasar|2023-06-08 12:33:11|Equity (startup)
Soumyadeep Mukherjee|2023-06-08 12:33:25|It either requires money or time no?
Soumyadeep Mukherjee|2023-06-08 12:33:37|One person will take a lot of time.
Nirant|2023-06-08 12:34:27|"As bad as you might feel, Sam Altman is completely right: Indians making Foundational Models is ""hopeless"""
Dr. Pratik Desai KissanGPT|2023-06-08 12:34:29|The thing is Ilya, Karpathy, Alex are probably one in generation scientists, they are 10x valuable than Sama. But Sam decided to use his life savings and place a bet on them as an investor first and then operator. Where are those investors in India who will seek talent and then enable them like that, instead of building cheaper Indian copies of established US business models.
Pratik Bhavasar|2023-06-08 12:34:32|People should not join if they don’t like the salary. Employee can always decide to fix their pay
Kartik Mandaville|2023-06-08 12:34:46|bit of both
Nirant|2023-06-08 12:35:15|Aah. I've a lot of questions around this. DMing.
Pratik Bhavasar|2023-06-08 12:35:27|Alpaca, koala were made in days by a small team right?
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:35:43|Things are changing, but salaries in ITES are still low - and each of those companies wants to build next gen tech but pay peanuts to young talent
Anshul Khandelwal Invideo|2023-06-08 12:36:06|Why?  Curious to hear your thoughts on this... ‎[6/8/23, 12:36:06] Nirant: ‎image omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:36:16|Perhaps a lesson in this is that organization scale itself doesn't lend scale capability to execute
Shubham Sharma 2012C6|2023-06-08 12:36:17|Want to know more
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:36:35|they're answerable to their LPs and usually, they compete with PE firms for better returns. there needs to be commercial incentive. And even before that - I second what paras said. there should be government/research incentive before commercial and India isn't just there yet.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:37:36|curious - is it possible to build for India from outside by convincing outside talent?
Harsh Koo|2023-06-08 12:37:56|I'm happy to work with anyone interested in India style LoRAs.   We can build a civit for Indiam
Shubham Sharma 2012C6|2023-06-08 12:38:11|Sorry but a lot of people they hire are not ‘talent’. They are a product of a terrible education system. Many of these companies become the place where they actually gain education
Pratik Bhavasar|2023-06-08 12:38:21|Don’t you have like 5 friends to do this now? And anyways you don’t need a lot of people to do it now that you know the recipe. Training 7b model is not an infra problem when you know it costs only <1k
Nirant|2023-06-08 12:38:37|Desi founders can't pay Bengaluru salaries which match Tower Capital. I doubt we can hire anyone at SF salaries
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:38:52|there's a lot of indian diaspora sitting around doing basic programming.
Soumyadeep Mukherjee|2023-06-08 12:38:54|Who has that kind of money in India?  Or even ability to find such talent who stays in India?
Nirant|2023-06-08 12:39:03|Aeee. You and I are not doing this peanut 7B models for pure marketing
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:39:56|outside india. I have friends who are applied scientists at Microsoft and OpenAI with big fat salaries looking to do something for India but they just don't have the right channels.
Pratik Bhavasar|2023-06-08 12:40:04|We not doing it is not a proof that it cannot be done. Just misplaced priorities
Nirant|2023-06-08 12:40:50|"Ask any of them to take a ""3 month sabbatical"" and do this for us — and you'll see how many of them respond :)"
Nirant|2023-06-08 12:40:55|*with us
Soumyadeep Mukherjee|2023-06-08 12:41:06|Been there done that. No one does.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:41:07|[PHONE]
Pratik Bhavasar|2023-06-08 12:41:29|Don’t they have a non-compete?
Kaushik Bokka|2023-06-08 12:41:33|lmk if they are looking for opportunities haha
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:41:39|have anything to contribute?
Kaushik Bokka|2023-06-08 12:41:54|.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 12:42:33|I think [PHONE]  mentioned how it is important to get to the deep roots of problems and solve them. That *generates* value, and investors will come looking for such talent. That's what we need, perhaps, not a new initiative to have the best come and build for India in India (at exorbitant cost to our investors/companies)
Sthit Generative AI WhatsApp Group|2023-06-08 12:42:33|My experience in this department is summarised best by: Talk, even before LLMs was cheap
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:43:03|well, a lot of them have left their full-time jobs to come to build for India.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:43:10|at least in my network.
Dr. Pratik Desai KissanGPT|2023-06-08 12:43:12|Sama found Ilya before DL phenomenon started. Waymo, Tesla picked up whole CMU and stand firm team. May be someone had picked up Bhasini team before they moved out of India to work for Azure.
Soumyadeep Mukherjee|2023-06-08 12:43:22|"""lot""? Less than 0.1%."
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:43:24|Will touch base.
Nirant|2023-06-08 12:43:44|No, they've come to build a business with 100% equity and realised that cost of living and talent is cheaper in India. Don't confuse the two.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:44:10|yes, was just about to mention that. not sure if their interest lies in research.
Soumyadeep Mukherjee|2023-06-08 12:44:15|Waymo, Sama and Tesla have very big pockets before they did so.
Nirant|2023-06-08 12:44:36|To reiterate, 13B, 40B models are not research. They're engineering problems today.
Pratyush Choudhury|2023-06-08 12:45:11|A thing where India shines is frugal & cost-effective engineering - all of our success stories have been that  ISRO is a classic example and to have also come out of Bangalore as well. Not very familiar w/ the HAL story but have heard similar things about it (happy to be corrected)
Abhinav Verma Longshot.ai|2023-06-08 12:46:45|Just one thought. I read the orca paper. Pretty interesting. But my main takeaway was that the models don't have great training data. I think we can work to that.  There's a few ways
Harsh Koo|2023-06-08 12:47:44|No one does.   Moving back to India is hard. I've done it twice. Reasons were not as ideal as we are discussing here. But now that many of us have this desire, we have to start.  Need to take a moonshot and just keep plugging away at. At some point, something will happen.  This is much better than ensuring nothing happens.
Pratik Bhavasar|2023-06-08 12:48:00|Do you mean it has data quality issues ?
Paras Chopra Wingify|2023-06-08 12:48:07|agree, and your point is that India needs them for indic languages because tokens are costlier in english first models?
Sthit Generative AI WhatsApp Group|2023-06-08 12:48:28|+1. Not twice but once in my case. But similar thoughts
Nirant|2023-06-08 12:48:30|No, we need to do English because we need to have the talent and skill to do this.
Nirant|2023-06-08 12:48:51|I also don't think we've a talent shortage — we can pull if there are investors.
Nirant|2023-06-08 12:48:57|Profit/Non-Profit
Dr. Pratik Desai KissanGPT|2023-06-08 12:49:11|May be then we will never have anything big because our Unicorns’ account sheets are not healthy to invest in future, old elephants are full of bureaucrats, and investors are not big enough to take bets on big ideas.
Abhinav Verma Longshot.ai|2023-06-08 12:49:22|Yes. Big time
Paras Chopra Wingify|2023-06-08 12:49:22|but why re-create a me-too model? if high quality, english open source models exist, why spend energy there?
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:49:33|i'd be interested if we garner enough VC interest.
Nirant|2023-06-08 12:50:00|Why does it have to me-too?   We can do codegen, SQL, code-refactor for enterprise, webdev, action models like Adept.ai
Nirant|2023-06-08 12:50:14|The plain vanilla LLM is the basic skillset you need to even think about doing these
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:50:34|or if any VC would be willing to take the bet.
Harsh Koo|2023-06-08 12:51:03|See waiting for any validation sets up unnecessary hurdles. As it is we haven't started.   VCs have different incentives.  We are doing this so India has a say in AI at the foundation model levels.  That some day a Samay Or a Samiksh laughs at a question when they are invited in USA or China.
Harsh Koo|2023-06-08 12:51:28|*Samiksha
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:51:43|I think that's why Rajan sir laughed when he mentioned the 10mil bit.
Soumyadeep Mukherjee|2023-06-08 12:51:46|Why do you need VC interest to be able to build a product?  VC will automatically be interested if the product has business value.  Products dont get build because VC is interested but because founders find a business and product and convince VCs. We have to flip this.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:51:50|hmm.
Paras Chopra Wingify|2023-06-08 12:52:21|well, good foundational models are good at these skills.  the real question is if there's an edge for specialized models, and if they're specialized are they really foundational?  i guess we're talking about two slightly different things
Harsh Koo|2023-06-08 12:52:31|This group is enough. We don't need more. Folks here can come up with hundred different ideas. Just few of us need to start.
Nirant|2023-06-08 12:53:15|You're right. They're adjacent, slightly different. To be clear, StarCoder is better at Codegen than GPT4.   That is why Code Interpreter had to be RLHF'd.
Nirant|2023-06-08 12:54:06|And Replit sized 1.3B models are still quite valuable because of how powerful and cheap they're
Paras Chopra Wingify|2023-06-08 12:54:30|Yeah so training a 1.3B model won’t be costly.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:54:50|its a personal reservation - that I wouldn't want to waste my life in building something that someone might not fund, eventually. And I think I am not alone in this. its very difficult to gauge VC/or lets just say risk capital interest.
Anshul Khandelwal Invideo|2023-06-08 12:55:07|Is there any benchmark supporting this?
Nirant|2023-06-08 12:55:23|Inside track: Teknium is working on one.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:56:54|things are different in west. You get money for trying. I think someone mentioned earlier that we don't have experiment capital in India/or appetite. So I'd understand a founder's dilemma to raise money for money.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:57:12|pl correct me if am wrong.
Soumyadeep Mukherjee|2023-06-08 12:57:47|Dont you think that someone funding or not shouldnt be the decision maker but rather your depth of the problem the decision maker on whether the idea can make money. If you arent able to convince yourself on a product, how do you expect to convince others? Entire job of a founder is selling their idea everyday of their life - VC, employees, users etc.  VCs are only to speed up things or put upfront capital. But we should know what it is for and what are the returns no?
Harsh Koo|2023-06-08 12:57:52|I work with MSRIT Bangalore students.   Want to expose them to codegen tools. Just so they know what's out there.  GPT-4 is awesome but they may not pay 20$/monthly.  Anyone willing to volunteer 30 mins to showcase starcoder VS code extension and do a walkthrough to students?
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 12:58:36|we're talking deep-tech only here.
Nirant|2023-06-08 12:58:42|StarCoder doesn't have a VS Code extension which is any code. But happy to do a walkthrough of both instruct and auto-complete finetuned models from Replit.
Garv Malik 2012H|2023-06-08 12:58:59|ISRO doesn't have to worry about a competitor paying them a higher salary. so easier to be cost effective there.
~ Srinivasan Nandakumar|2023-06-08 12:59:04|This domain also presents a unique challenge of having money not necessarily leading to progress.  Getting GPUs and assembling clusters have long waiting times now.
Soumyadeep Mukherjee|2023-06-08 12:59:12|You think deep-tech doesnt need to have a business value?
Soumyadeep Mukherjee|2023-06-08 12:59:25|deep-tech only changes return timeline for capital.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:00:07|okay, are they willing to wait that long?
Soumyadeep Mukherjee|2023-06-08 13:00:44|Indian VCs dont have that deep pockets from my prelim research. There has to be some decent sized wins to be able to do that. There arent many unfortunately.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:00:55|exactly.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:01:19|plus not to forget outside competition.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:01:31|tech is and will always be global.
Soumyadeep Mukherjee|2023-06-08 13:02:23|Yes. So, raise from a non Indian VC if the product is great?
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:02:27|we can do 1 to n tech here but 0 to 1 in any field hands-down balls-deep is extremely difficult.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:03:41|Many investors in India need to embrace risk - not enough of them do, so the likes of Antler, Sequoia and others swoop in to make dividends on our builders and talent.
Alok Bishoyi|2023-06-08 13:03:53|Not sure why we are ruling out government funded projects?Nation states will most likely come up with their own LLMs, and if not force LLM providers to align their model’s geographically. Last thing for eg Indian govt wants is for chatgpt to tell that kashmir belongs to pakistan
Dr. Pratik Desai KissanGPT|2023-06-08 13:03:54|We need Patrons, pre independence or near independence India. Likes of Tatas and Birlas, to invest in long horizon projects. Right now only institute that is can do invest in deep tech is probably the GOI.
Paras Chopra Wingify|2023-06-08 13:04:12|Why blame VCs for this?  These are systemic issues.
Nirant|2023-06-08 13:04:25|We've discussed this in plenty of detail. Just last week. Please scroll up.
Soumyadeep Mukherjee|2023-06-08 13:04:38|How man? Check out their fund sizes and returns they have got in past 5y. Where will the money come from?
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:05:05|From what I have seen - cheap hard-tech MVP that can be scaled from a manufacturing pov can guarantee great returns as government and policy support is well-defined.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:05:15|Look at funds like GVFL
Pratyush Choudhury|2023-06-08 13:06:21|Not true na, how?
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:06:45|https://zerocowfactory.com/ <--- something like this.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:07:09|talent can go overseas, correct?
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:08:07|He's right. NASA has to compete with the likes of Lockheed and SpaceX for talent - not the case with ISRO. Plus aerospace engg or education talent in India hasn't distinguished itself as tech talent perhaps has
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:09:05|Why not ISRO? Do they have a laxman rekha on their engineers lol?
Dr. Pratik Desai KissanGPT|2023-06-08 13:09:17|True. They are missing home runs to grow pockets first,  then invest some in long horizon projects.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:10:17|In fact the Laxman Rekha is around ISRO. Private defence/space tech companies in India have tall regulatory walls to scale before they can be productive
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:10:40|*productive and profitable
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:12:00|No but what can bear them working for the likes of SpaceX/NASA? Had a friend in college, shifted to US, joined MIT's space eng program and now she's aiming to be an astronaut.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 13:12:12|from working*
Nirant|2023-06-08 13:12:49|Decidedly off topic for this forum. Maybe move this convo-fork to DM?
Ojasvi Yadav|2023-06-08 13:12:58|"With all factors equal, it's obvious that a region with more funding is likely to prosper than other regions.  So if our consensus belief is that we have no lack of talent as compared to other nations, then factors like funding have to play a significant role  Completely aligned on ""if you're good enough you'll make it"" school of thought, bulk onus of responsibility should indeed be on the founders. But they can only go so far with a skeptical funding sources."
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:13:21|Sure.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:15:10|Frugal innovation is hard to do when the price and targets are set by an increasingly global market and talent pool. If cloud costs the same everywhere, talent costs the same everywhere, but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base), investors should want to invest here because they get dividends
Soumyadeep Mukherjee|2023-06-08 13:15:55|"""but if there are much bigger opportunities to scale B2C AI startups in India, for example (because of user base)"" - Not enough proof yet on if they can make money. ‎[6/8/23, 13:16:22] Abhishek Mishra: ‎image omitted"
Nirant|2023-06-08 13:16:41|I've tried it, it's terribly slow 😅
Dr. Pratik Desai KissanGPT|2023-06-08 13:16:46|This question is going to define India at 2045. If we believe in this or not.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:17:30|"More proof (depending on use case of course) perhaps than the guys who funded the ""Yo"" app or Juicero had. Idiotic products get funded in Si Valley sometimes because it is possible to throw money around there. Discerning investors won't do that in India even for legit use cases at the same level"
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:17:49|Heck, they even funded Nikola millions of dollars without a single truck produced and that turned out to be a scam
Abhishek Mishra|2023-06-08 13:18:07|The details to setup the extension and using it via shortcuts is all there on the installation page on the vs code extension itself. I didn't like starcoder or starchat as much but it is good for some basic stuff.
Soumyadeep Mukherjee|2023-06-08 13:18:29|Are you saying India doesnt have enough weird ideas being funded? :P
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:19:04|Hehe. I think it is a signal of risk. Shitty businesses will fail in a downturn but good ideas will make hay during an upswing.
Rajesh RS Generative AI WhatsApp Group|2023-06-08 13:19:43|Half-good ideas even if they're sometimes boring can also do well if given a chance. I think that kind of thing doesn't happen often enough here.
Abhishek Mishra|2023-06-08 13:20:06|Also, if your req. is just to get a free decent code autocomplete - please check codeium/AWS Toolkit Codewhisperer. Though nothing comes even close to GPT4.
Nirant|2023-06-08 13:20:52|Yes. Codeium is also quite decent
Dhruv Anand|2023-06-08 13:24:51|GitHub copilot is free for students (they need to provide supporting documents). There are some pretty amazing tools in their pipeline. I've tried their copilot chat, copilot labs tools (explain, translate, brushes etc.), Copilot for command line. All are really good
Nirant|2023-06-08 13:25:32|cc [PHONE] if students are familiar with Git and Github, Github Copilot is easiest to use.
Sandeep Srinivasa RedCarpetup|2023-06-08 13:30:38|https://education.github.com/pack/join  free for students
ashish Acgt01 Twitter|2023-06-08 13:35:17|Point taken but an ecosystem like berkeley/bair takes decades to build ! I am not ruling out small, nimble teams of 4-5 people building impactful open source llms in india, but comparions with berkeley/bair are probably not fair.  I recently attended a talk by prof. Jawahar of IIIT-Hyderabad & i was blown away by the quality of their work . https://arxiv.org/abs/2005.08209
Ojasvi Yadav|2023-06-08 13:36:56|If only I had 4-5 AI researchers on my payroll......
Dr. Pratik Desai KissanGPT|2023-06-08 13:40:37|Is this wav2lip team? This is base for SadTalker and other oss models that can easily and cheaply replace D-ID.
ashish Acgt01 Twitter|2023-06-08 13:42:19|There are world class researchers building high impact projects in India, especially in academia & industrial research labs(MSR work on native languages). we need govt backing them much more with grants & funds.  And also the insane startup energy at places like Stanford & berkeley - the same intensity is not there in india yet, but we are catching up quickly.  My dream is that somebody in the govt has the foresight to dedicate a large chunk of money & institutional effort to make India, an attractive hub of ai research - including sops & incentives to motivate researchers of indian origin outside india, to come back & start labs & companies in india.  Its a 5-10 year timeline mission, wont happen in a year or so but you need an industry, govt partnership to articulate a grand, moonshot vision & then relentlessly execute on that.  </rant> :D
~ Ritik Madan|2023-06-08 17:27:20|‎~ Ritik Madan was added
Kishore Nallan|2023-06-08 17:27:20|‎Kishore Nallan was added
Brij Singh Rebright Partners|2023-06-08 17:27:20|‎Brij Singh Rebright Partners was added
ashish Acgt01 Twitter|2023-06-08 13:46:04|Nirant, how does copilot compare vs replit ghostwriter ?
~ Diwank|2023-06-08 13:46:32|Is anyone here at the Sam Altman meet at IIIT DELHI today?
Pratik Bhavasar|2023-06-08 13:49:10|This is the David Vs Goliath thing. If it was impossible, OpenAI would not have been able to stress out Google. And many other startups would not have disrupted the leaders. It happens all the time as per the history.
Rakeshkumar Waghela|2023-06-08 14:56:57|https://twitter.com/huggingface/status/1666737999990730752?t=mM6813k-AXjJXMoQxLResw&s=08
~ Karan Gandhi|2023-06-08 15:26:19|https://twitter.com/brijbhasin/status/1666663734385979392?s=46
Nirant|2023-06-08 16:03:36|We've discussed this aplenty. As earlier, will ask the the next contributor to chip in with code, data or money.
Brij Singh Rebright Partners|2023-06-08 16:43:42|‎Brij Singh Rebright Partners requested to join
~ Wasim Madha|2023-06-08 17:19:47|‎~ Wasim Madha requested to join
~ Naveen Kumar|2023-06-08 17:20:50|‎~ Naveen Kumar requested to join
Brij Singh Rebright Partners|2023-06-08 16:43:42|‎Brij Singh Rebright Partners requested to join
~ Wasim Madha|2023-06-08 17:19:47|‎~ Wasim Madha requested to join
~ Naveen Kumar|2023-06-08 17:20:50|‎~ Naveen Kumar requested to join
~ Mridul Joshi|2023-06-08 17:27:26|‎~ Mridul Joshi joined from the community
Abhinav Verma Longshot.ai|2023-06-08 17:37:33|Hey guys, how bad were the questions that were asked to Sam Altman yesterday? Lot of people dissing on Twitter
Abhinav Verma Longshot.ai|2023-06-08 17:37:40|When is the iiitd chat?
~ Shouvik Ghosh Roy|2023-06-08 17:39:08|It’s happened. https://www.youtube.com/live/Pig9WbMN1lQ?feature=share
Garv Malik 2012H|2023-06-08 17:39:41|not bad at all. not even a week of memes.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 17:40:14|Lol they're blowing out of proportion.
Ojasvi Yadav|2023-06-08 17:40:20|Let's just put it this way - an AMA on r/India would've given us 100x interesting discussions at 99x lesser logistical costs
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 17:40:22|Here comes the maestro! 😂
Abhinav Verma Longshot.ai|2023-06-08 17:42:51|Were the people there any AI people ki nahi?
Abhishek Mishra|2023-06-08 17:53:23|All I need with evening coffee is second hand embarrassment from watching this.
Gokul Krishnan|2023-06-08 17:53:59|Roast of AI when?
ashish Acgt01 Twitter|2023-06-08 18:16:21|[PHONE] +1 You should do an ai themed set !  Unsolicited joke idea : humour has been hard for LLMs so far , so your job is safe, *so far* :)
Sandeep Srinivasa RedCarpetup|2023-06-08 18:16:38|The IIITD session today was not bad. The moderators were pretty brutal on media and VC.
Alok Bishoyi|2023-06-08 18:17:10|The anchor was unbearable tbh. The other prof was up to the chop
Garv Malik 2012H|2023-06-08 18:18:51|Knew it long back, hence in the profession. Can’t imagine a code for sarcasm
Garv Malik 2012H|2023-06-08 18:19:06|Algo for badshah songs is still possible
~ Rishabh Chandel|2023-06-08 18:19:51|Is anyone working on converting complex-to-use software(most enterprise saas software) to chat-based interface software? Something like what hubspot did: https://chatspot.ai/  Any resources or ideas on how to approach this?
Nirant|2023-06-08 18:25:08|Don't worry, can't take your job since you don't get paid anyway Garv.  (This is what we call, a roast)
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-08 18:32:33|What makes you say so?
Yash Kothari Cadence|2023-06-08 18:36:29|Ha anyone tried to solve for a contract analysis use case using AI?
Vamshi|2023-06-08 18:49:28|I randomly picked 36:00 in and was promptly amused
Vamshi|2023-06-08 18:49:36|Accidentally pre-empted
Vamshi|2023-06-08 18:49:54|Did anyone ask him what his background in AI is ?
Vamshi|2023-06-08 18:50:48|I still clearly recall the days when everyone was building a location based mobile app and Loopt was one of the also rans
~ Suhas Baliga|2023-06-08 18:51:48|Yes dm-ing.
Vamshi|2023-06-08 18:51:53|It’s amazing the trajectories that are available to an take on a playground of fertile innovation
Shan|2023-06-08 18:55:08|you mean like adept.ai? (some demos https://twitter.com/AdeptAILabs/status/1570144499187453952 )
Dr. Pratik Desai KissanGPT|2023-06-08 18:59:59|[PHONE] Do you know on what Ashish Vaswani and Niki Parmar working on after leaving adept?
~ Rishabh Chandel|2023-06-08 19:04:13|I was looking for more like ChatGPT. Everything is just chat. More or less it also solves the problem. How they are doing it?
Nirant|2023-06-08 19:08:26|Nahi
Dr. Pratik Desai KissanGPT|2023-06-08 19:10:43|It will interesting to see what they come up with.
~ Apurva Bhatt|2023-06-08 19:22:12|Would you like to more precise?
~ Apurva Bhatt|2023-06-08 19:22:52|If you want to highlight particular clauses in a long contract, try using squad dataset
~ Apurva Bhatt|2023-06-08 19:23:26|There is a paper on it, they have also trained a roberta based model for the same
~ Apurva Bhatt|2023-06-08 19:25:37|https://arxiv.org/abs/1606.05250
ashish Acgt01 Twitter|2023-06-08 19:31:26|"Half serious, half joking q :  What if we trained a GarvGPT on all your existing videos , Insta and twitter posts, and made it ""learn"" Garv's ""signature style "" ?  Not easy, but given the pace of progress, I would say you have a  year before being GPT-ed away 😂😂😂 ‎[6/8/23, 19:37:27] Shan: ‎image omitted ‎[6/8/23, 19:39:36] ~ Kp: ‎GIF omitted"
Ankesh Atlassian AI|2023-06-08 19:43:53|We are building a gpt bot that can have multi-turn conversation with the user based on a given text document.   What are some ways for the bot to ask cross questions from the user after the initial query from the user so that the bot can get more context about the query and answer better. For example, the doc is about vpn issues but has some points different for mac vs windows. The user in its first instance doesnt specify the OS. But the bot asks a cross question asking for the OS before giving the solution to user's query. The actual bot is more advanced but I have simplified the description to focus on the problem at hand.
Abhishek Mishra|2023-06-08 19:45:52|Dropped in to joke on the same but beaten by your meme.
Garv Malik 2012H|2023-06-08 19:46:02|If I am unfunny, model trained on me will be unfunny too  You could generate content that sounds like me, but for it to be funny, it depends on other people also. Like even I can only say with 50% accuracy that it will be funny.  To make it easier, videos are less, i can give a few hundred pages of what I have written in last 8 years and see if we can do text funny
Shan|2023-06-08 19:48:01|here's my 2s prompt...
Shan|2023-06-08 19:48:08|You are a support bot answering technical support questions about networking.  A user has raised an issue about her VPN not working. In order to resolve this issue, what other information would be needed by you?
Shan|2023-06-08 19:48:17|and here's the response
Shan|2023-06-08 19:48:18|To effectively troubleshoot your VPN issue, I would need the following information:  1. **VPN Service Provider**: The name of the company or organization that provides your VPN service.  2. **Error Message or Description of the Issue**: If there are any error messages appearing when you try to connect to your VPN, please provide them. If there are no specific error messages, a detailed description of what happens when you try to connect would be helpful.  3. **Device and Operating System**: Information about the device and the operating system you are using. For instance, are you using Windows, macOS, Linux, iOS, Android, etc.? What is the version of the operating system?  4. **Network Information**: Are you using a home network, public Wi-Fi, or mobile data? Some networks may have restrictions that affect VPN usage.  5. **Location**: The country or region you are in may have specific laws or restrictions that affect VPN usage.  6. **VPN Software Version**: The version of the VPN software you are using.  7. **When the issue started**: Did the issue start recently? Or has the VPN never worked on your device? Did any specific event coincide with the start of the issue, such as a software update or change in network settings?  8. **Troubleshooting Steps Already Tried**: Have you tried any solutions already? What were the results? This can help avoid suggesting steps you've already taken.  Remember to never share sensitive information like passwords or specific IP addresses when seeking support.
Shan|2023-06-08 19:48:23|there you have it ... 🙂
Abhishek Mishra|2023-06-08 19:51:08|Here's how I would design something for the challenge, just for the kick:  * I would take your data and instruction-tune alpaca based on your jokes. * Let the AI produce 50-60 segments of jokes. Then take feedback on these jokes by RLHFF (Reinforcement laughter where Human finds Funny)  Then based on the funniest segments, we'll present a short set.
Garv Malik 2012H|2023-06-08 19:53:41|Would loove to see results. Can i DM you
~ Vishwam Jindal|2023-06-08 19:58:25|Yes. What sort of analysis
Abhishek Mishra|2023-06-08 20:03:27|😂 sure.
Anubhav mishra Zupay|2023-06-08 20:03:40|https://www.linkedin.com/posts/rishi-sunak_as-the-world-grapples-with-the-challenges-activity-7072467476185243648-ttl8?utm_source=share&utm_medium=member_desktop
Anubhav mishra Zupay|2023-06-08 20:04:38|Seems Rishi Sunak is directly Taking some AI lessons from Sir Narayan Murthy, father-in-law to rishi sunak
ashish Acgt01 Twitter|2023-06-08 20:07:33|I would love to join in on the effort Abhishek !  Sounds like a fun project to work on !
~ Vrushank Vyas|2023-06-08 20:10:28|I also want to know what these folks are doing: https://samaya.ai/  Maithra is from the same bunch of researchers who left Brain
Dr. Ashith Generative AI WA Group|2023-06-08 20:25:07|[PHONE]
Sandeep Srinivasa RedCarpetup|2023-06-08 20:36:14|i would like to see a benchmark of this finetuned model..versus a non-finetuned model with jokes in a vector db/embeddings. and just using retrieval q&a
ashish Acgt01 Twitter|2023-06-08 20:40:33|Who wants to volunteer to do the RLHF ? :)
Sachin Legaltech|2023-06-08 20:43:56|If there are people willing to do the comparisons, I can help out with RLHF training part. We will need large amount of comparisons.
~ Arvind Sankar|2023-06-08 20:52:23|I am familiar with solutions using symbolic representation and DSLs to some extent. With gen AI, i have seen people make plugins that use openai APIs to simplify clauses.  As a patent freelancer who has done some work with contracts, I feel there are several problems that would require different approaches. Which specific problem are you working on?  Feel free to DM me for a longer discussion
Abhishek Mishra|2023-06-08 20:55:47|I was thinking of using Deepspeed chat for this. But haven't put it into use yet. Do you have other methods in mind?
Sachin Legaltech|2023-06-08 21:06:22|I had written scripts to train with RLHF. Writing these scripts directly or using deepspeed chat or TRLX is comparatively easy task. To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring. Also quality of SFT model determines how many comparisons we need. Sometimes both comparisons are bad and have to throw them away after evaluating.
Abhishek Mishra|2023-06-08 21:12:58|Yeah we won't have that many sets of instruction response pairs for this task in the first place. I don't think we'll get even 1000 instruction-joke pairs on this. Most of the content would also be in Hinglish and some work would need to be done to make it fit for the instruction tuning.  I'll probably DM you around the time I'm done with the initial part.
Nirant|2023-06-08 21:19:03|> To train the reward model, we need lots of comparisons and curating those comparisons becomes quite boring  DPO/Pairwise Ranking losses help?  > SFT model determines how many comparisons we need > Have a heuristic e.g. this good vs this many comparisons?  Want to explain SFT for wider readers?
Abhinav Verma Longshot.ai|2023-06-08 21:20:43|This ui should have a positive affirmation message after every few annotations to keep the motivating
Abhinav Verma Longshot.ai|2023-06-08 21:20:50|Motivation *
~ Vishwam Jindal|2023-06-08 21:29:39|https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence
Sachin Legaltech|2023-06-08 21:33:40|I haven't read the SLiC-HF paper yet. So can't comment on Pairwise Ranking. With DPO, they don't mention if DPO - Direct Preference Optimisation reduces sample complexity(number of comparisons needed to train equivalent of RLHF model.) But they do claim training with DPO is stable. So am guessing we might be able to do with 10 - 25% less samples. (Pure speculation from my side).
Sachin Legaltech|2023-06-08 21:45:31|"SFT is supervised finetuning. Alpaca model is an SFT model built on top of Llama model. With SFT, we take the base language model (like Llama) and then finetune it on few thousands of prompt- response pairs. If we want our SFT model to follow instructions, we would curate few thousand examples like this - ""Prompt"": ""Explain the moon landing to a 6 year old""; ""Response"": ""People went to the moon, took photos and sent them back to the earth."". If we want SFT models to be chat models, we will keep the previous chat history in prompt and in response, we will add  whatever reply would be given to the last message in chat. SFT is effective when we have > 1000 examples; but can be useful with >100 examples too. If we have a good enough SFT model(Most outputs are at least somewhat funny), around 1000 - 2000 comparisons should be enough to see the magic of RLHF. (But here we will be operating with Jokes; so hard to predict.)"
Shan|2023-06-08 21:49:38|Btw for those interested in papers about Reasoning … this is Disneyland 😀 https://github.com/atfortes/LLM-Reasoning-Papers
~ Srinivasan Nandakumar|2023-06-08 21:52:15|Just a suggestion: you can maybe instruction tune falcon (as it's license is permissible)  and use self instruct like alpaca to  generate a dataset. This may save you a lot of time.
Abhishek Mishra|2023-06-08 22:08:48|For this specific task, we actually need Garv's stand up or other similar comic sets as content. Generating content via api distillation won't help here as we need exactly one specific users style to be copied.  Otherwise it's straightforward to use alpaca style fine tuning using GPT3/4 generated content.  For Falcon, I've not yet explored it for fine tuning. I'll do it soon as now even the 7B version is out.
Shashank Generative AI Group|2023-06-08 22:30:37|"new wrapper: simpleaichat  ""I built simpleaichat out of sheer frustration with LangChain and aim to make it the easiest way to make AI apps.""  https://twitter.com/minimaxir/status/1666828520981692416  https://github.com/minimaxir/simpleaichat"
Sachin Legaltech|2023-06-08 23:29:16|https://twitter.com/francis_yao_/status/1666833311279517696?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Yao Fu et. a. found out prompts which gave accuracy of around 61 % on MMLU. Llama paper claims 63 % accuracy; but the best accuracy reported with open source prompts using Llama on MMLU was 48% till now. So Llama models are mostly as good as claimed by authors.
Ojasvi Yadav|2023-06-08 23:47:33|Occam's razor!  https://twitter.com/dimitrispapail/status/1666843952824168465?s=48&t=FvScmWlwJalkIndmUHhjjQ
Mannan Amroliwala|2023-06-09 06:31:23|‎Mannan Amroliwala left ‎[6/9/23, 01:03:39] Bhavya Ranpara Generative AI Wa Group Surat: ‎image omitted
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-09 01:04:11|Not sure of Jason's intent though but ❤️🔥
Dr. Pratik Desai KissanGPT|2023-06-09 01:54:22|It should be called Everest Project instead of Manhattan.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-09 01:57:30|dozen manhattan projects is a wild claim. doubt if he's being sarcastic.
Gokul Krishnan|2023-06-09 02:01:17|The Manhattan project was 0.9% of US GDP. Rounding to 1% that's a hilarious amount to spend to spite a bay area visitor
Gokul Krishnan|2023-06-09 02:02:23|Our USP has always been great quality at low price (ex. Mangalyaan), it makes more sense in the Indian context to work on efficient training and inference.  Imagine you get GPT-4 level quality at a fraction of the price
Dr. Pratik Desai KissanGPT|2023-06-09 02:03:22|Not sarcasm. I think he doesn’t like OpenAI and Sama, since he was banned from YC demo days.
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-09 02:05:51|these guys and their vendettas lol.
Abhinav Verma Longshot.ai|2023-06-09 02:05:59|This is my review of the orca paper. Currently upto the result section https://shadowed-season-d38.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4  The link to original paper https://arxiv.org/pdf/2306.02707.pdf  If anyone has read the paper, feel free to suggest feedbacks on this. This was partially written with the help of GPT-4
Abhinav Verma Longshot.ai|2023-06-09 02:06:20|unfortunately, he's elon musk's echo chamber
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-09 02:06:54|also - chamath is a part of the all in podcast so who knows rofl.
Dr. Pratik Desai KissanGPT|2023-06-09 02:14:42|I hope some outsourcing sweatshop doesn’t convince government to spend a lot on some illusive AI Manhattan project that may become out dated in 3-4 weeks.
"Arpan Desai | MobileFirst"|2023-06-09 02:49:49|Don’t give ideas
Brij Singh Rebright Partners|2023-06-09 06:13:08|Hello Everyone, my name is Brij Singh and I'm a General Partner at Rebright Partners an India-Japan Cross Border VC Fund. We have invested in startups like Inshorts, Medibuddy, Jiffy.ai etc. I'm the one that made the Twitter post yesterday on Emerging OSS Fellowship Program / Fund, which was posted on this group by my colleague [PHONE] who is a Sr. Data Science Associate at our Fund. I was not part of this WA Group at that time and couldn't participate in the discussion, but happy to answer any questions here now. Since yesterday, we have had about 20 folks reach out from the community and will be meeting them over the coming weeks to see how we can support some of them.
Brij Singh Rebright Partners|2023-06-09 06:14:45|"Also, I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and the lack of FM's in India of equivalent capability.   Perhaps a few valiant efforts using OSS alternatives as a base will be able to match it in the next 6-12 months. However, SamaA has repeated time and again that his and OpenAI's sole mission is to invent Artificial General Intelligence (AGI), and all their activities GPT4, ChatGPT, Tools, monetization, and Microsoft Partnerships are just meant to that end.  Hence, if we truly wish to compete, we must go where the puck will be down the line, and not where it is today. The 3 most important ingredients for that goal are People, Data, and Compute, which is why OpenAI had to sell out its original vision of being truly ""Open"" and raise from Microsoft. But given the pace of innovation over the last few months, there might be some alternative paths for a country like ours, assuming there will be no large pools of capital available from VCs, Ultra HNI's, or the Govt.  50 years ago, we achieved a major feat in the Nuclear race, Project Smiling Buddha. A scrappy team of Indian Scientists conducted our very first test of an Atomic Bomb, under utmost secrecy and against immense pressure from the Americans. Perhaps, what is needed today is a similar effort, but we need not be defensive about it, or do it under secret. But a response must be made, especially to something that could be an existential threat. Coming back to the 3 most important ingredients - People, Data and Compute. Perhaps this could be a way –  ** Project Laughing Buddha **  A nationwide effort to create India's version of truly Open Protocols based Foundational Models with an explicitly stated goal towards Artificial General Intelligence, which could perhaps be through a combination of hundreds of Foundational Models, instead of one large one. - The project code, weights & temperatures of FMs are in the public domain, and ownership  - Team of 1000 of India's top AI Researchers, Data Scientists, ML Engineers, and RLHF Engineers organized through best Open Source practices - Decentralised GPU compute donated through millions of idle devices by Indian citizens aggregated through nodes akin to the SETI Project  - Datasets for training that are donated by leading Startups, Citizen Groups, Open Govt Data, and Citizens  If it is successful, we could perhaps protect our Data and AI Sovereignty and provide the foundations necessary for 100K Startups to build and scale on top, without being subservient to other organizations or countries."
ashish Acgt01 Twitter|2023-06-09 07:06:06|Success of such a plan hinges on someone in the government convinced of the stratwgic need to do the *right* things now , so India is well placed in the global ai economy in the next 5-10 years.  As happens often in India, teh govery will be a bit of a laggard. But efforts like Bhashini( ai4 Bharat, Nilekani centre at IIT Madras), give me a little bit of hope.  My prediction is that industry and academia in India will take the lead in open source ml research & innovation, despite a lack of concerted efforts from the government.  Finally on the hardware and compute needs of the future, I hope the Indiqn government can strike strategic partnerships with TSMC and Nvidia, among others to eataish facilities in India. My final prediction is Nvidia will rule the roost but a new wave of fabless GPU designers and cloud providers will emerge all.over the world. We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !
~ Suhas Baliga|2023-06-09 07:17:59|On this point, how are we doing building Hindi or Kannada Language Models, is important.
Nirant|2023-06-09 07:20:41|IndicLM is Least important thing in the stack rank of hard and valuable things:   Limited academic value and no commercial utility.  It's a false flag and we should not be sidetracked in such misguided pursuits
ashish Acgt01 Twitter|2023-06-09 07:22:04|https://ai4bharat.org/
Aakash Dharmadhikari|2023-06-09 07:25:02|Doesn’t token cost matter for the complexity of applications to be built given fixed context windows?
Aakash Dharmadhikari|2023-06-09 07:25:45|Although, as the context windows increase to 30k+, for a general purpose use-cases it shouldn’t matter I guess.
ashish Acgt01 Twitter|2023-06-09 07:27:09|I would partially disagree.  To build end user ai digital public goods, this is important.  e.g. Conaider a healthcare usecase : a DoctorGPT Chatbot , available as a WhatsApp or even SMS not( to run on cheap feature phones) which does high level traige of medical symptoms for under served populations ideally should have a native language voice input.  Quality of native language speech to text and translation to English are important problems for applications like this, no ?
Nirant|2023-06-09 07:30:38|Which Hindi application do you've on your phone which you:  1) use for more than 10 minutes a day 2) pay more than $10/mo?
Nirant|2023-06-09 07:31:37|Also, this entire chat is English
Kunal Bhatia Hexo|2023-06-09 07:31:42|Isn't that purely a translation problem? Why does the base model need to be trained in different languages?
Aakash Dharmadhikari|2023-06-09 07:31:44|I don’t but the number of regional content apps are exploding in India.
Aakash Dharmadhikari|2023-06-09 07:32:35|I would strongly disagree that there are no use-cases for local languages. I assumed what’s being argued is the ROI for improving efficiency.
Nirant|2023-06-09 07:33:21|I'll pause now, I just woke up on the wrong side of bed. I've spent some fraction of my youth on this and realised there is no money, respect, at best there is some social currency in doing so. Perhaps, I'm just a bit sour.
Aakash Dharmadhikari|2023-06-09 07:33:25|Language is accessibility
Aakash Dharmadhikari|2023-06-09 07:34:32|I don’t disagree on that at all. People who will pay for digital goods and can’t use English is a very small market.
Aakash Dharmadhikari|2023-06-09 07:35:25|People can derive value of these, if there will be paid use-cases are not is for entrepreneurs and VCs to take a bet on.
Aakash Dharmadhikari|2023-06-09 07:36:44|Let me be clear, I am certainly not one of them.
Shan|2023-06-09 07:40:55|Throw bricks on me but IMO it’s also a misguided thought process and effort. Build another windows also, another google also, another AWS also … keep playing catch up? What’s the point? Far better to innovate than to copy. Then these people go out and call themselves Thought Leaders. Sick.
Nirant|2023-06-09 07:48:42|Amazing podcast translation to Hindi — maybe if you feel so much about it, invite him here and upvote on PH. He's an indiehacker, I don't know him and no affiliation whatsoever  https://www.producthunt.com/posts/translateaudio
Sandeep Srinivasa RedCarpetup|2023-06-09 07:49:59|Generative AI in Indic languages has one huge source of revenue - politics. There is a massive demand for this already.
Shan|2023-06-09 07:51:21|Yes. Seen this first hand.
Brij Singh Rebright Partners|2023-06-09 07:53:22|What would a 1/3/5 year execution path look for this -   We should try to leverage semiconductor expertise among Indian engineers and try to have a 10 year plan to make India a semiconductor and GPU(ml training and inference chip )superpower in the next few decades !
Aakash Dharmadhikari|2023-06-09 07:59:08|Education - that's the most important I think
~ Miraj Shah|2023-06-09 07:59:33|and banking, ads, entertainment
Aakash Dharmadhikari|2023-06-09 07:59:38|I am personally working on Software Development using AI; but if I have to choose one field where I truly believe AI should and can create the largest impact, it has to be Education
Aakash Dharmadhikari|2023-06-09 07:59:58|We can now create personalized education for every kid
Aakash Dharmadhikari|2023-06-09 08:00:37|In the future, I hope AI takes care of teaching and teachers take care of the personal & emotional wellbeing of kids
Aakash Dharmadhikari|2023-06-09 08:02:44|Education is part knowledge transfer, part motivation, and part well being. Our teachers today, especially in rural areas barely have bandwidth for knowledge transfer.... let alone motivation or wellbeing.
Aakash Dharmadhikari|2023-06-09 08:05:10|"If putting $1B per state is going to create a model that is ""effective"" in that language, it would totally worth government spend."
Arvind N Generative AI Group|2023-06-09 08:05:31|Knowledge gap assessment and Interactive textbooks are perhaps the early applications in this area.
Arvind N Generative AI Group|2023-06-09 08:05:48|Something like khanmigo from Khan academy
Aakash Dharmadhikari|2023-06-09 08:06:04|BTW Microsoft is selling this hard to all Education Ministries across the world. I do see this coming in soon.
Michael D Souza|2023-06-09 08:09:41|[PHONE] there has been a growing consensus among all today at the lack of innovation in Education. AI and special a combination of Generative and Reinforcement AI strategies could bring that and truly démocratise Education. The internet and mobile have brought a giant leap in this case but education from a personal touch point is truly something that would change this sector
~ Suhas Baliga|2023-06-09 08:13:36|We have been working on student assessment and evaluation. Deepsy.in.
Michael D Souza|2023-06-09 08:14:30|Just a hello. I am heading the AI division at IHX a startup in the healthcare domain https://www.ihx.in/ Ine of our major products is Claims Management and processing. We have just started looking into LLMs as a tool for information extraction especially from discharge summaries. Will keep you all posted …
Aakash Dharmadhikari|2023-06-09 08:14:53|Is this a B2B or B2C approach?
~ Suhas Baliga|2023-06-09 08:17:11|Also, usefulness of language modelsl also follow the data and as our data becomes more valuable or useful, models will have to perform with those languages? Not sure where this will end up at.
Nirant|2023-06-09 08:17:14|I did something adjacent for an East Coast dentist chain. Info extraction with LLMs is quite robust and powerful
~ Suhas Baliga|2023-06-09 08:17:38|B2B. We are working with our first customers - univs and ed-tech.
Michael D Souza|2023-06-09 08:17:46|This is very interesting a combination of this with a recommendation engine for course plans would be very interesting for any parent. B2C .  Especially in core subjects
Arvind N Generative AI Group|2023-06-09 08:18:04|How good are your qualitative scores? Is there a demo I can see?
~ Suhas Baliga|2023-06-09 08:18:25|Dm-ing to set up.
~ Suhas Baliga|2023-06-09 08:21:52|Yes. :) Now it's been one day at a time.
Dr. Pratik Desai KissanGPT|2023-06-09 08:23:57|Everything Rural has demand for language, not just India, as we getting calls from many countries to build similar platform for their languages and knowledge base. I personally see good translator models to be better solution around Indic language  problem while keep English to train LLM to achieve SOTA perf. Any subpar model will never be used in Production.
~ Vrushank Vyas|2023-06-09 08:27:16|One question is, is their unique training material in Indic languages that would make the training worthwhile   Different grammar structures, knowledge patterns, and it changes the behaviour of LLMs?
~ Vrushank Vyas|2023-06-09 08:28:12|Of course it’s a different thing if training data at that level exists/is accessible easily
Ved Chitnis|2023-06-09 08:43:08|‎You added Ved Chitnis
ashish Acgt01 Twitter|2023-06-09 08:50:59|Money maybe no. Respect and greater social impact of ai digital public goods - yes !  The  utopian optimist in me sees a future where high quality indic models enable a lot of non-profit /govt run public goods ( ala Aadhaar, abdm )  But I defer to your actual experience in this field compared to my armchair imagining :D p.s. we should talk sometime about your experience building these in your youth
Michael D Souza|2023-06-09 09:01:21|I think someone mentioned it in passing. If we think of this as a machine translation problem then the source could always be English but you could rather work on an interface around an LLM based solution.
Michael D Souza|2023-06-09 09:03:09|Localisation happens at the interface level
Dr. Pratik Desai KissanGPT|2023-06-09 09:06:07|How many people have tried Bhasini models and here and how many use in production. Even we can start with ggerganov like efforts and improve performance of those models. Optimized Bhasini have many out of box production use case than LLaMa, IMO.
ashish Acgt01 Twitter|2023-06-09 09:23:02|Just stumbled onto this demo on twitter.  Imagine this demo happening in an Indian kid‘s native language !  https://twitter.com/amasad/status/1666889016527163392?s=46&t=pt9BgXoRTmqx5FEPyAl9bg ‎[6/9/23, 09:25:02] ashish Acgt01 Twitter: ‎image omitted
Abhishek Mishra|2023-06-09 09:27:30|Demand is huge in rural areas for Indic languages but building B2C revenue generation channels might be hard.   For what it's worth, current SoTA performance lies here only - GPT3/4 + whisper GGML or elevenlabs.io. Primarily because we don't have a decent substitute yet that can have GPT3 level performance to interact with a human.  Once that happens, a lot of value is going to come out of just SoTA translate + SoTA STT + English OSS LLM.
Dr. Pratik Desai KissanGPT|2023-06-09 09:27:34|This is game changing. I personally never liked our sheep (coaching) farms, and this will focus on individuals and their strength.
Abhishek Mishra|2023-06-09 09:28:20|Let me check what's the underlying architecture for Bhashini, if it's anything ggml already supports like GPT J or GPT Neo, something can be done right away.
Dr. Pratik Desai KissanGPT|2023-06-09 09:31:07|I’m not going to go against Nirant’s policy to self promote, but it is happening and I’m overwhelmed with customers interest. If we stop focusing on building cheap copies and get head out of Tier1 cities, we have so many things to do. Of course, one shouldn’t expect to be a unicorn in few years, but when ‘Bharat’ picks up China like income growth, these fields will explode.
Abhishek Mishra|2023-06-09 09:32:20|Is it weird if my brain is imagining children jailbreaking this tutor to get it to say censored stuff and posting it on insta 😅?
Dr. Pratik Desai KissanGPT|2023-06-09 09:32:24|Do it. An optimized Bhasini can open up so many flood gates, even independent startup for API based STT, TTS and Translator. Cloud translators APIs are expensive.
Nitin Mahajan McKinsey|2023-06-09 09:37:53|Good one. With elections coming maybe it can be a digital infra. Last elections WhatsApp volumes were huge. Maybe this time all voters will get personalised videos 🤫…..
Rajesh RS Generative AI WhatsApp Group|2023-06-09 09:41:37|There's no getting around alternative uses and abuses of new technology of any kind.
Nitin Mahajan McKinsey|2023-06-09 09:42:46|Yup. How you use a knife is totally fair.  Wasn’t even saying in a negative tone. Just in fact that it’s a fair and valid marketing use case. If anyone wants to seriously build it, call me up. Let’s do something hacky
Aashay Sachdeva MPL Data Scientist|2023-06-09 09:46:09|IndicLLM even if not the most powerful is important for equitable outcomes for everyone. Back when I was at make a difference, one of the biggest problem we faced while teaching shelter home kids who aren’t from background like ours was their inability to interpret in english as well as they could do in their native language. Ofcourse there is no money - but it is of national importance.
Abhishek Mishra|2023-06-09 09:47:19|Ok I checked, Bhashini appears to be currently ChatGPT + open source transcribe/translate model(s) that supports Indic languages. We can't ggml a closed api model and whisper already has ggml.  Probably more value will be there in 1. Falcon/llama + fine-tuning chat datasets for at least one Indian language 2. Waiting for something that's trained on Indic stuff in the first place and is open.  First one has good demo level perf. but it's limited in many ways. Second is not there yet.  I can see probably why we haven't made much progress on individual level in this area.
ashish Acgt01 Twitter|2023-06-09 09:49:30|Got a link/source for the technical architecture/stack of Bhashini ? Their website didn't have much info
Aashay Sachdeva MPL Data Scientist|2023-06-09 09:50:51|https://huggingface.co/aashay96/indic-BloomLM  Training script and an initial Lora model + datasets are all there. Feel free to train it further
Dr. Pratik Desai KissanGPT|2023-06-09 09:51:00|I have few suggestions as you and [PHONE] are genuinely trying something good (1) Let’s create a real open source org/repo/structure, outside of bureaucratic interference like ai4bharat (2) Start with collecting all Indic resources and datasets under one umbrella, pre training data is most important to move forwad with foundation and even fine tuned model (3) crowdsource problems from oss community, need to be solved, and are not part of a blind race to prove someone wrong ‎[6/9/23, 09:51:40] Abhishek Mishra: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-09 09:52:12|I that’s not true. Check Ai4Bharat website and repo for models
Aashay Sachdeva MPL Data Scientist|2023-06-09 09:53:40|We should get Dr.Pratyush from ai4bharat here 😆
Dr. Pratik Desai KissanGPT|2023-06-09 09:55:43|😝 my point is towards how goals get diverted and delayed where Government is a major contributor in funds
Abhishek Mishra|2023-06-09 09:57:09|Yeah they have multiple NER, transliteration, translate modelsb in HF/github but in the articles for Bhashini I didn't find a connection to those models. Probably because I referred to wrong article, I got in a different direction - https://indianexpress.com/article/explained/explained-sci-tech/chatgpt-on-whatsapp-bhashini-welfare-schemes-8442622/
ashish Acgt01 Twitter|2023-06-09 10:01:09|Some details here :  https://github.com/AI4Bharat/IndicTrans2  https://ai4bharat.iitm.ac.in/indic-trans2
Abhishek Mishra|2023-06-09 10:04:16|Bloom family of models has ggml support, so I guess something can be tried here. But they perform poorly on most tasks, don't know much about this one. I'll try it out.
Dr. Pratik Desai KissanGPT|2023-06-09 10:04:41|Thanks, I haven’t tested IndicTrans2 yet, this only two weeks old. I tried original IndicTrans in production but was disappointed for inference speed.
~ Tanishk Sharma|2023-06-09 11:36:22|‎~ Tanishk Sharma was added
~ Jeet Kanjani|2023-06-09 11:36:22|‎~ Jeet Kanjani was added
Ciyunni|2023-06-09 10:40:08|this is overly optimistic Aakash ji. I am a fan of Ethan Mollick's 'education explorations with ChatGPT' - but, *there's a crucial 'developing' process* missing that the student can't access and the 'educator' isn't able to deliver. It's in technology's blindspot, for now - resourcing contextual opportunities for learning. Most gedanken experiments devoid of local environment, not blaming the metaverse, aren't powerful enough levers.
Rajesh RS Generative AI WhatsApp Group|2023-06-09 10:56:07|What's the best way to compress models or generate lighter models? I have come across quantization and conversion to ONNX and other formats. I've used ONNX but in some cases it does increase inference time. Is there a way to ensure the inference time is low as well? Any good guides to this?
Azhan Mohammed Generative AI WhatsApp Group|2023-06-09 10:58:20|On python based inference onnx performs really well, if you go to C++ then ncnn is the best. Have tried ncnn for both CPU and GPU(using Vulkan) it outperforms torch lib and tensorflow c++
Rajesh RS Generative AI WhatsApp Group|2023-06-09 10:59:21|I've found that for (simpler, non-DL) models, ONNX is slower than pickle binaries. Could I be doing something wrong?
Sumod K Mohan|2023-06-09 11:00:43|Keywords you are looking for: Quantization, Pruning, Sparsification, Distillation. You shouldn't see speed increase. Will DM you details later.
Aashay Sachdeva MPL Data Scientist|2023-06-09 11:01:10|Just change the model to falcon or whichever you want for training
Abhishek Mishra|2023-06-09 11:03:33|As per the original context, looking for models that have a GGML supported architecture so that something can be done for them right away. Falcon isn't supported with GGML quantization properly yet. ‎[6/9/23, 11:11:10] Kiran Jonnalagadda: ‎image omitted
~ Shobhit Jaipurkar|2023-06-09 11:12:20|I can totally get behind Applied Statistics
~ Prajna Prayas|2023-06-09 11:15:45|Well that's not fun and  dull. I am all for AI. It has a sense of mystery in it
~ Shobhit Jaipurkar|2023-06-09 11:17:06|AI on the streets, AS in the sheets
Rajesh RS Generative AI WhatsApp Group|2023-06-09 11:23:31|Thank you, Sumod
Aakash Dharmadhikari|2023-06-09 11:28:45|Haha, can always bank on him to bring a new perspective
Swastik Banerjee|2023-06-09 11:29:26|+1 any good guide/ref pages for implementing/deploying hybrid search?
Abhishek Mishra|2023-06-09 11:59:39|It's funny how sci-fi writers like Ted Chiang, Eliezer Yudkowsky have become quotable experts of AI. One look at their statements and it immediately makes you want to stop reading the article.  On one hand, we have people looking out for sudden loss drops and on the other hand, we are calling it Applied Stats.
Ojasvi Yadav|2023-06-09 12:09:02|We're doing this at Dukaan. Happy to discuss further with you.
Kaushik Bokka|2023-06-09 12:12:38|Link please?
Aashay Sachdeva MPL Data Scientist|2023-06-09 12:24:53|https://twitter.com/emostaque/status/1666817719554174977?s=46  Emad is bullish on India
Nirant|2023-06-09 12:31:31|The original authors of Retrieval Augmented Generation, InferSent, SentEval and many others have teamed up to start a RAG company. They've raised a $20M Seed Round.    https://contextual.ai/announcing-next-generation-language-models/
Nirant|2023-06-09 12:32:16|Same crew did GLUE/SuperGLUE too
Aashay Sachdeva MPL Data Scientist|2023-06-09 12:32:24|Isn’t the original paper 3 year old?
Kiran Jonnalagadda|2023-06-09 12:32:43|https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84
Nirant|2023-06-09 12:33:02|Yes, https://arxiv.org/abs/2005.11401
Abhinav Verma Longshot.ai|2023-06-09 12:33:39|ya RAG has been in place since 2020 when facebook launched their dpr models
Kaushik Bokka|2023-06-09 12:33:39|paywall sigh
Nirant|2023-06-09 12:34:16|The PIO Amanpreet Singh is a 2013 IIT R grad from the very famous SDS Lab. Has interned with Wingify in India  cc [PHONE]
Abhinav Verma Longshot.ai|2023-06-09 12:39:29|https://archive.is/xCmxi
Puneet Lamba Aspiro|2023-06-09 12:48:47|*A friend asked this, can someone please advise?* I am Anubhav, founder of Dubdub.ai. I am seeking assistance from anyone with expertise in deploying large GPU-based models. Our latest APIs will soon be made public, and we aim to provide a seamless stream or synchronous API experience. It's currently working well asynchronously. I am presently exploring cost-effective methods to scale our project. What is the best way to do it for concurrent requests? Any insights would be greatly appreciated, or make a connection.
Aashay Sachdeva MPL Data Scientist|2023-06-09 12:49:17|DMing you
Pranjal Yadav Razorpay|2023-06-09 12:50:02|Similar request from my end as well, if anyone can help. ‎[6/9/23, 12:50:57] Abhishek Mishra: ‎image omitted
Anubhav Dubdub.Ai|2023-06-09 12:52:42|‎You added Anubhav Dubdub.Ai
Puneet Lamba Aspiro|2023-06-09 12:53:36|Great to see you here [PHONE] - forwarded your query already 👆🏼
Rajesh RS Generative AI WhatsApp Group|2023-06-09 12:56:18|What nobody has managed to answer for me is the question of whether humans are doing anything more sophisticated than this in their own heads. There are probably many intelligence mechanisms that are decidedly simple - and there is a tendency on the part of commentators to just group everything together
Aashay Sachdeva MPL Data Scientist|2023-06-09 12:57:17|[PHONE] can help
~ Sushant|2023-06-09 12:58:14|Same from my side as well...   Also for b2b business What's best practices for the model inference in a multi tenant environment as context would be different for all
Anubhav Dubdub.Ai|2023-06-09 13:01:06|Awesome, thanks. I will reach out to him.
Kiran Jonnalagadda|2023-06-09 13:11:45|Every generation of scientific advancement tries to define human capacity in terms of current understanding. This is how we got the racial theories that defended slavery, and the eugenics movement that went on to cause much grief.  It is dangerous to assume we know how the human mind works.
Michael D Souza|2023-06-09 13:33:17|Distillation https://neptune.ai/blog/knowledge-distillation
Michael D Souza|2023-06-09 13:36:36|When you mention GPU based models do you mean they require a GPU at inference time? For standard cpu inference we are using AWS Fargate with auto scaling. Behind an Nguni load balancer
Michael D Souza|2023-06-09 13:39:03|In google we used GoLang GRPC services on k8
Anubhav Dubdub.Ai|2023-06-09 13:39:04|Yes, need GPU at inference
Rajesh RS Generative AI WhatsApp Group|2023-06-09 13:47:14|Very insightful piece, thanks Michael
Paras Chopra Wingify|2023-06-09 13:48:05|PIO?
Nirant|2023-06-09 13:55:20|Person of Indian Origin
Samhan Meta/Twitter Friend|2023-06-09 13:55:50|I use it the same way
Samhan Meta/Twitter Friend|2023-06-09 13:57:15|- Explain math , code , concepts  - Explain what’s in papers - Translate between languages both human and code - Summarize The biggest lever is in improving your own understanding.
Samhan Meta/Twitter Friend|2023-06-09 13:57:32|Your learning speed increases by 2x or more
Samhan Meta/Twitter Friend|2023-06-09 13:58:39|Also made hackerFM which was around the same idea - using AI to summarize the complex events in the tech industry
Samhan Meta/Twitter Friend|2023-06-09 13:59:13|We don’t release it anymore but a few users emailed asking for it back. So this use case has genuine traction based on my anecdotal experiences
Samhan Meta/Twitter Friend|2023-06-09 13:59:52|But it’s not obvious. You cannot demonstrate it immediately. It takes time to get used to this way of working
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 14:00:45|My biggest use for gpt is to pass it an error stack, and it tells me how to fix it
Samhan Meta/Twitter Friend|2023-06-09 14:01:29|Debugging is understanding
Samhan Meta/Twitter Friend|2023-06-09 14:02:31|The complexity of a project a single developer can take on and ship quickly has already gone up.
Samhan Meta/Twitter Friend|2023-06-09 14:02:43|The consequences just aren’t evenly distributed yet
Samhan Meta/Twitter Friend|2023-06-09 14:08:23|A tool to simplify the world according to your own goals and values. Where the model is built up collaboratively over time. And is both visual and text. Blasting out endless streams of content is not where it’s at. Simple high signal actionable models / summaries of the world.
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 14:45:18|I've been surprised at how poor other tools are at basic code tasks. Or maybe I'm not aware  But i repeatedly use gpt for a few things e.g.  1. Writing regex 2. Generating react components, animations, etc 3. Standalone functions like text manipulation  I've tried to get copilot a couple of times to do it
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 14:45:27|But it's largely been poor at it
Sandeep Srinivasa RedCarpetup|2023-06-09 14:45:40|Is hybrid search = cosine distance+ IDF   Or is there an LLM involved ?
Swastik Banerjee|2023-06-09 14:46:49|The first I’d assume
Swastik Banerjee|2023-06-09 14:47:06|How are you defining this additive property though?
Rajesh RS Generative AI WhatsApp Group|2023-06-09 14:47:06|Copilot is good at working with existing code bases, doesn't do well with ground up code gen. This is what some team members in my org think. We could be wrong
Rajesh RS Generative AI WhatsApp Group|2023-06-09 14:47:49|Copilot would be built on top of Codex and InstructGPT (like ChatGPT). Not sure if those benefit from RLHF like ChatGPT has. Does anyone know?
Sandeep Srinivasa RedCarpetup|2023-06-09 14:48:57|In Elasticsearch, this is composite, so it's not super tough.
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 14:49:35|I pay for it. But haven't been very impressed with copilot. For instance, it really annoys me when it gets closing brackets or double quotes wrong
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 14:50:07|You need to then go and figure what it added or missed that's causing everything to go an angry red 🥲
Abhishek Mishra|2023-06-09 14:50:31|Depends on how one is using it. I deal with it how I'll deal with a completely fresh intern. Plan things on a high level and break down the tasks to create functions, scripts or classes.   Then use these code modules by pasting them in newer context and assigning an enhancement, debug or application.
Ayush Pepper|2023-06-09 14:50:53|I’ve had similar experience. Co pilot works better with existing code bases.  Writing descriptive comments before each code block, including param structures, using apt variable names etc helps a lot.
Ayush Pepper|2023-06-09 14:52:17|But for writing from scratch, GPT4 is  amazing.
Rajesh RS Generative AI WhatsApp Group|2023-06-09 14:53:32|This is a big issue with code gen tools - since we're not mentally involved in the code generation process it becomes complicated and annoying when a) we are skeptical about the output b) when there is clearly an error and we don't know where to start
Samhan Meta/Twitter Friend|2023-06-09 14:55:12|https://youtu.be/Yf1o0TQzry8  Watch at 27:00 - the main activity is understanding
Samhan Meta/Twitter Friend|2023-06-09 14:56:15|Codex which powers copilot is a far smaller and simpler model
Samhan Meta/Twitter Friend|2023-06-09 14:56:23|It trades off intelligence for latency
~ Prajna Prayas|2023-06-09 14:56:26|Can you give a tldr like Nirant always pushes 😅
Dhruv Anand|2023-06-09 14:56:47|hopefully they'll replace it with a new gpt-4 based model soon.
Samhan Meta/Twitter Friend|2023-06-09 14:56:58|Understanding what is going on > trying to come up with new ideas before you have that
Samhan Meta/Twitter Friend|2023-06-09 14:57:07|Too expensive too slow
Samhan Meta/Twitter Friend|2023-06-09 14:57:37|I mean that is copilotX but it’s not in the direct coding flow
Dhruv Anand|2023-06-09 14:57:39|3.5 then. I'll take anything. Currently, I spend all day doing <tab>,<enter> repeat with copilot
Abhishek Mishra|2023-06-09 15:00:58|A typical hybrid search would be a combination of two or more of these methods:  * Semantic search to fetch top K * Tf-idf or similar stuff like BM25 * Recency Bias - Newer information is weighted with more weighted more * Associativity Bias - Information closely linked to predetermined important pieces is weighted more * Repetition Bias - Information that is repeated more often in the document is deemed important  There's no fixed heuristic to implement a hybrid search but you would mostly find Semantic Search + TF-IDF/BM25 and some would go and add temporal or recency Bias
Swastik Banerjee|2023-06-09 15:06:21|Yes, I remember you mentioning the ```boost()``` method, but what if I’m not using ElasticSearch? I guess I’m trying to understand more of what happens underneath 🙂
Swastik Banerjee|2023-06-09 15:07:20|What do you mean by “+” ? Is there a way to possibly elaborate how the two are getting combined?
Sandeep Srinivasa RedCarpetup|2023-06-09 15:07:28|It's a performance story. U can still do in memory, but ur performance will be hit
Swastik Banerjee|2023-06-09 15:08:38|Scaling up is a different story. I’m first trying to understand how the two are getting combined 😃
Sandeep Srinivasa RedCarpetup|2023-06-09 15:08:51|This makes a lot of sense, but still no LLM no ? I'm wondering how do u leverage LLM into the mix.  This stuff is still classical search for us Lucene folks (regardless of what the vector dbs say !)
Sandeep Srinivasa RedCarpetup|2023-06-09 15:09:26|In memory. U get one array. U get another array and u then sort in memory. This is where llamaindex shines
Swastik Banerjee|2023-06-09 15:10:53|As far as involving an LLM layer goes, I’ve seen some people talking about finetunig the ranking model with adversarial questions or doc2query. It has proved to give better results than plain vector similarity
Samhan Meta/Twitter Friend|2023-06-09 15:16:22|LLM can be used as a final ranking / summarization pass. can rephrase / translate queries can suggest follow ups / related
Samhan Meta/Twitter Friend|2023-06-09 15:16:23|Can hallucinate answers that guide the rest of the system
Samhan Meta/Twitter Friend|2023-06-09 15:16:25|Can activate plugins
~ Joy Mehta|2023-06-09 15:18:26|‎~ Joy Mehta left
Abhishek Mishra|2023-06-09 15:19:53|LLMs come into play when you use the search for answer generation. Then there are a bunch of techniques where LLM has to play a part,   Examples:  * HyDE - Let LLMs hallucinate answer first and then perform search which can then be used to arrive upon a complete and correct answer  * Breaking down search query - LLMs are instructed to break down search query based on their lack of knowledge on the topic, then come up with multiple search queries to get context on these terms first and then formulate final answer  * Autoprompt like methods - let LLM take your query and come up with a search prompt or question prompt by itself based on its understanding of previous question-answer pairs that were successful
Sandeep Srinivasa RedCarpetup|2023-06-09 15:21:40|Hyde example is a great answer. Thanks 🙏
Abhishek Mishra|2023-06-09 15:22:45|There's no fixed heuristic but good engineering practices to combine semantic search and keyword search techniques to optimise for cost, speed and performance  https://arxiv.org/abs/2210.11934
Michael D Souza|2023-06-09 15:33:17|So is that an intersection of the results of the search algorithm?
Sandeep Srinivasa RedCarpetup|2023-06-09 15:34:15|https://twitter.com/hwchase17/status/1666829939918745600?t=nNVXyi6T4Ny7qvy1eXQldQ&s=19
~ HP|2023-06-09 15:35:52|Are there any resources to go through to understand and implement HyDE?
Swastik Banerjee|2023-06-09 15:37:47|I’m not convinced this’ll give very good results
~ prthamesh|2023-06-09 15:38:30|I think this repo uses contextual compression https://twitter.com/misbahsy/status/1656365370121285657?s=46&t=iGppsOleuAsMXDWuVmzUPQ
~ prthamesh|2023-06-09 15:38:44|Not sure if this was shared earlier
Abhishek Mishra|2023-06-09 15:42:17|There's an implementation to HyDE paper from papers with code - https://github.com/texttron/hyde
Abhishek Mishra|2023-06-09 15:45:20|You can find two different fusion techniques mentioned here - Convex Combination (CC), and Retrieval Rank Fusion (RRF).  I've not really implemented these functions myself so any more details would be me just reading it off this paper - https://arxiv.org/abs/2210.11934
Michael D Souza|2023-06-09 15:46:04|Thanks 🙏
Nirant|2023-06-09 15:47:20|I've used RRF. It's beautiful how simple and fast it is.
Paras Chopra Wingify|2023-06-09 15:57:01|One heuristic to think about LLMs is how we tend to reflect on our answers.  First cut of our answer is always riddled with biases, but when we're asked to reflect on our own answer, we tend to improve it. Similarly, two people discussing a topic end up learning new (that's why student-teacher networks work out)  Anyone else finds this parallel fascinating?
Michael D Souza|2023-06-09 16:11:58|I rarely seen a GPU based live inference solution due to the cost but in general principle if you want scale then use some elastic infrastructure component but cost associated is very high and optimise as much as you can your model.  We multiple models running 24/7 in our environment with a mixture of synchronous and asynchronous. We follow a strategy of micro service reducing the footprint of each model. Then wrap them in REST / gRPC API s , dickeriizing and running them on aws fargate . If we have asynchronous systems we use an SQS queue with Keda for scaling ‎[6/9/23, 16:21:53] Nirant: ‎image omitted
Siddharth Agarwal|2023-06-09 16:23:34|Yeah...Indian academia is deeply cash-strapped. I knew some people at IIT-B that were doing some pretty killer NLP stuff (for 2018) but were limited by the very few number of GPUs available.
Dr. Pratik Desai KissanGPT|2023-06-09 16:23:39|Many basement in SV have more powerful ones
Rajesh RS Generative AI WhatsApp Group|2023-06-09 16:24:56|Lots of people buy SLR cameras, if only we were inundated with great photos. A small fraction of the available compute is useful or well used compute.
Dr. Pratik Desai KissanGPT|2023-06-09 16:26:27|More cameras will increase the probability of more great pictures coming out
~ Mayank Gupta|2023-06-09 16:27:47|Plus no camera when something epic is unfolding is most damaging
Sandeep Srinivasa RedCarpetup|2023-06-09 16:29:45|Infrastructure is the model. That's why transformers works. It scales parallely - may not be the best algorithm.  Scale matters.
ashish Acgt01 Twitter|2023-06-09 16:57:24|"Fascinating analogy Paras!  Who is the teacher in a ChatGPT - us conversation ?  ChatGPT knows all the facts, but we kind of instruct it to use a particular  ""tone/style""( consider yourself to be a medical assistant, explain it to me like I am a 5 year old, write the poem in the style of Shakespeare, reason about it step by step, include references) for its generative abilities."
ashish Acgt01 Twitter|2023-06-09 17:01:40|"Also I can't remember the paper, but I remember reading an abstract background in the last few days where 2 ( or more LLMs) work in concert : with the ""decider""/""judged"" LLM judging the output of the ""student""/""workhorse"" LLM  The context was to increase the quality of the generative outputs of the student LLM when it's outputs are ""judged"" by a ""decider"" LLM, for medical applications"
Ojasvi Yadav|2023-06-09 17:09:04|"Isn't this a reworded ""LLMs fine-tuned on GPT4 input/output pairs"""
Ojasvi Yadav|2023-06-09 17:09:25|Replace gpt4 with any other smart LLM
Ojasvi Yadav|2023-06-09 17:10:57|I know both the processes are different. But fundamentally this seems to be around aligning a smaller LLM to output like a bigger LLM (gpt4).
Ojasvi Yadav|2023-06-09 17:11:31|Which is the same idea adopted in projects like these
Abhinav Verma Longshot.ai|2023-06-09 17:12:19|That seems closer to the orca paper by Microsoft research
Ojasvi Yadav|2023-06-09 17:12:37|Yes
Ojasvi Yadav|2023-06-09 17:13:05|So I'm very curious to see the differences in benchmark across these two techniques that are trying to do the same thing but in a different way
Rajesh RS Generative AI WhatsApp Group|2023-06-09 17:13:06|Reminds me of this one - Orca https://arxiv.org/abs/2306.02707
Ojasvi Yadav|2023-06-09 17:14:03|It would then become an interesting topic of research - what allows one approach to do better than the other one
Abhinav Verma Longshot.ai|2023-06-09 17:15:03|https://shadowed-season-d38.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4 I'd written my explainer of the orca paper for someone who doesn't want to read all the pages
Rajesh RS Generative AI WhatsApp Group|2023-06-09 18:04:42|https://youtu.be/Dt_UNg7Mchg
Abhinav Verma Longshot.ai|2023-06-09 18:18:46|Orca model seems promising based on results. It also puts emphasis on data curation and data diversity. I think this is something that can be achieved in India.
ashish Acgt01 Twitter|2023-06-09 18:19:24|"I digged around and found the paper i was alluding to. Context : i am interested in medical applications of LLMs   https://arxiv.org/abs/2303.17071  ""Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output. We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance in both human expert preference evaluations and quantitative metrics. In a new finding, we also show that GPT-4's performance (70%) on an open-ended version of the MedQA question-answering (QA) dataset (Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA showing similar performance. We release the open-ended MEDQA dataset at this https URL"" ‎[6/9/23, 18:24:06] Abhishek Mishra: ‎image omitted"
Abhishek Mishra|2023-06-09 18:24:41|Paper link - https://t.co/VYeo0ifuYF
Rajesh RS Generative AI WhatsApp Group|2023-06-09 18:26:27|Exactly. It isn't only throwing compute at the model, but getting the data engineering right. Databricks demonstrated how they built Dolly with a smaller dataset
~ Nayan Shah|2023-06-09 18:34:45|i want to train any llm model and finetune or train on my domain related data which ecokmerce product related data , is there any good resource that u guys have found on this , which can help me start on this .
Dhruv Naik|2023-06-09 18:36:17|This is a paper from my colleagues. Happy to discuss or answer any questions you may have
Nirant|2023-06-09 18:36:27|Too broad a question perhaps, is there a specific problem you have in mind? E.g. product reviews fraud detection, ranking/search/recommendation system, parsing product reviews
ashish Acgt01 Twitter|2023-06-09 18:37:11|Small world indeed !  Dhruv, will DM you
~ Nayan Shah|2023-06-09 18:37:13|Mostly its question answers , and ranking i have data wrt product description title , etc
Nirant|2023-06-09 18:38:09|Are you reporting to Anitha Kannan?
~ Nayan Shah|2023-06-09 18:39:57|Right now we are using the gpt model for doing this kind of product enquiry, but evaluating opensource model , and ways to train them . Just starting on this so have not much information except gpt . And on opensource model I am kind of not sure which one to start or look at .
Sachin Legaltech|2023-06-09 18:56:16|For finetuning, this is a pretty good tutorial - https://huggingface.co/docs/transformers/training . To decide how to select different hyperparameters, this guide is nice ~ https://github.com/google-research/tuning_playbook
ashish Acgt01 Twitter|2023-06-09 18:56:17|"Just skimmed the abstract. LLMs playing ""games"" gives me RL vibes ! :) Maybe there is an elegant way to combine LLMs and RL"
ashish Acgt01 Twitter|2023-06-09 19:48:19|"Very thought provoking paper !  https://twitter.com/nouhadziri/status/1663936263324590083?s=48&t=pt9BgXoRTmqx5FEPyAl9bg  ""Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify Transformers, we investigate the limits of these models across three representative compositional tasks—multi-digit multi- plication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that Transformers solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem- solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how Transformers’ perfor- mance will rapidly decay with increased task complexity.""   https://arxiv.org/abs/2305.18654"
Dr. Pratik Desai KissanGPT|2023-06-09 20:14:18|Meta released another banger, MusicGen  https://twitter.com/_akhaliq/status/1667175989862973453
Shan|2023-06-09 20:17:48|Yeah I loved it too. I had raised a pull request to add it to the reasoning paper list which just got merged. So it’s linked here too now. https://github.com/atfortes/LLM-Reasoning-Papers#analysis
Abhishek Mishra|2023-06-09 20:19:16|Ooh lawsuits time 😛
Shan|2023-06-09 20:21:58|My (unsubstantiated) take on this- It’s a pretrained transformer. So pretraining it’s finding the patterns and then the generative part is filling in those blanks. A good paper overall. 👍
ashish Acgt01 Twitter|2023-06-09 20:24:58|"I have a meta q to [PHONE] , [PHONE] , [PHONE] & others :  Do you have any practical advice(your own/ somebody else's) and suggestions on how to keep up with the deluge of new papers every freaking day ?  Somedays i feel i am able to keep up with my twitter feed(which is too many people, need to prune that a lot) , on other days i feel i am really ""behind"" and ""missing out"" and causes a lot of FOMO  Also, where do you find interesting papers to read besides this group ? Anyone want to share a twitter list of a few accounts who tweet majority of the interesting papers (akhaliq, Sebastian raschka , karpathy)  Any other must follow people and suggestions on this topic ?"
Shan|2023-06-09 20:27:13|Well you did not ask me but I’ll still go ahead and answer 😀
Shan|2023-06-09 20:27:29|https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-45d
Shan|2023-06-09 20:27:36|https://cameronrwolfe.me/blog
Pranjal Yadav Razorpay|2023-06-09 20:27:37|I usually skim this group and stick to one personal and whatever professional projects I have around genAI.  Twitter, LinkedIn and YouTube is full of content that no one can absorb. My assumption is, all of it is not that important, if it is important with practical use case, some one will surface it in this group.
Shan|2023-06-09 20:27:53|https://thegradient.pub/
Shan|2023-06-09 20:28:02|https://dblalock.substack.com/
Shan|2023-06-09 20:28:22|https://lastweekin.ai/
Shan|2023-06-09 20:28:51|https://twitter.com/omarsar0
Shan|2023-06-09 20:29:22|These are the resources I follow apart from this and a couple other groups I’m part of and the link to reasoning papers I posted above
Twishmay Shankar|2023-06-09 20:30:39|Adding to the above info problem.   Many of the ML papers are highly technical for some of us with weaker core maths practice.  Is there is a chance, someone who understands them well, could organise weekly teach ins (book club styled?) for foundational ML papers?  Kind of dumb it down to a point where it’s comprehensible for a larger audience who still put in the effort?
ashish Acgt01 Twitter|2023-06-09 20:31:39|Thanks Shan !  Do you have any suggestions on managing twitter overload ? :)
Shan|2023-06-09 20:32:41|Yeah. I don’t use twitter. 😀 that Dair guys twitter is probably the only one. I directly go there every once in a while. (Also - 🤗 twitter account which I forgot to mention)
Shan|2023-06-09 20:33:37|https://twitter.com/huggingface specifically.
Paras Chopra Wingify|2023-06-09 20:34:57|I follow hacker news and a few subReddits   Over weekends, end up reaching a few papers  There are very few novel ideas, most papers are incremental stuff
Paras Chopra Wingify|2023-06-09 20:35:29|Skimming most papers is ok, I go into depth if an idea is truly novel
ashish Acgt01 Twitter|2023-06-09 20:36:40|Care to share the sub reddits Paras ?  Would love to see you do a tweet thread/post on how to read a research paper most efficiently
Shashank Generative AI Group|2023-06-09 20:43:40|this is an oversimplification:  just like them on twitter, tune the algo.  i do subscribe to a ton of the newsletters but I'm a sorta churned subscriber 😂.  most important papers will surface to the top anyways.  (insert Bell Curve meme here) ‎[6/9/23, 20:44:46] Shashank Generative AI Group: ‎image omitted
Shan|2023-06-09 20:48:34|I think a Gpt style bot should be useful even for those used to the notation. Maybe there exists one already - wolfram + ELI5
~ Mayank Gupta|2023-06-09 21:05:41|I'm actually evaluating building a product that helps anyone be up to date with topics of their interest, served as a summary and adjusted to difficulty level. Might just be useful for the kind of problems we're just discussing right?
~ Jeet Kanjani|2023-06-09 21:05:52|Hey all,  My name is Jeet. I work on CV in the Bay Area.  LinkedIn: https://www.linkedin.com/in/jeet-kanjani-a86062107  Twitter: https://twitter.com/kanjanijeet?s=11  Intrested in knowing more about the developments of genAI in India - Great to be added to this community!
~ Mayank Gupta|2023-06-09 21:30:21|Anyone else who faces this problem (even if just for GenAI) or thinks it's worth solving, would love to connect and talk more!
Abhishek Mishra|2023-06-09 21:48:50|I was just about to automate my Twitter content actually. Currently I consume stuff through my own 2 NLP lists where I segregate top NLP signals by individuals and orgs separately. I'll DM you to know what's your approach towards this thing.
Abhishek Mishra|2023-06-09 21:54:34|"I played this game for a long time and now don't find value in trying to keep up with every single piece of news.  You just need to start building stuff and keep abreast of SoTA in that area only.  I usually divide stuff like this to keep up and stick my nose in what is relevant to me -  * Build your own API * Build your own dataset * Build your own model - via training/fine tuning * Build your own pipeline - for specific technologies  I'm interested in stuff where I build APIs and models only. Rest of the stuff I find when I need to look into it.  Other than this, it's easy to find places where you get ""all"" info - there are easily many such newsletters, weekly summary Twitter/LinkedIn accounts, subreddits, discords where you get to listen to the same stuff rinsed and repeated.  People quoting each other's posts as their own work and findings 😂 and pushing out stuff everyday.  So best to just work on stuff and keep up with what's relevant to you ‎[6/9/23, 21:56:00] Paras Chopra Wingify: ‎image omitted"
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:00:44|Folks, is there any resource youve seen on how to translate natural language commands into actions?  Think of a command k bar that takes in natural language inputs, parses out relevant inputs, and executes if relevant or asks for more details if incomplete
Abhishek Mishra|2023-06-09 22:06:24|Teaching an LLM to use tools or plugins should not be any different than what you're asking for. We already have frameworks where the LLM looks for the best api, tool, plugin to complete the job. You probably want to look into those and replace names of APIs, tools with your own instructions.   The input query from the user would need to be divided into *tool/api* to use, *instruction* to follow with the tool and *params* to pass to complete the job.   https://medium.com/@imicknl/how-do-chatgpt-plugins-and-similar-llm-concepts-work-2c83a4aeedd4
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:10:19|This is very helpful. Thank you. The intent classifier seems to be key here. I'm trying to see how to make it have a conversation with the user in the event of incomplete inputs, or if it is unsure, to complete the  set of inputs it requires to execute the action
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:11:07|This is a great starting point
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:11:17|And gpt4 has been a very helpful as well
Abhishek Mishra|2023-06-09 22:18:17|It's great if you found it helpful.
Rajesh RS Generative AI WhatsApp Group|2023-06-09 22:20:04|Closely following this conversation since I have trouble keeping up. Thanks for all the ideas
Shan|2023-06-09 22:20:43|Again, adept.ai use case I presume?
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:22:59|I'm not sure. Adept seems to have a very generic description on their website. But I think in the similar direction
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:25:47|I'm surprised Google hasn't integrated something as simple as an instruction bar into their products  Like, I'd love to be able to setup a calendar invite by simply typing an instruction instead of clicking on the date, selecting the time, adding recipients, and a meeting subject
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:26:28|I'd imagine a lot more tools can benefit from taking inputs as simple chat prompts instead of a sequence of button clicks
Bharat Kumar Ramesh Hashmal Web3|2023-06-09 22:26:52|The above could be a confirmatory step and for editing, instead of the full workflow
ashish Acgt01 Twitter|2023-06-09 23:05:09|Just for a dash of humour and wit on Friday night !  https://www.instagram.com/reel/Cqda2FuLqrI/?igshid=NjFhOGMzYTE3ZQ== ‎[6/9/23, 23:37:33] ~ Surya SG: genai.pdf • ‎26 pages ‎document omitted
ashish Acgt01 Twitter|2023-06-09 23:38:51|Is this from Chip ?
~ Surya SG|2023-06-09 23:39:25|Yes
Shivendu Kumar|2023-06-10 04:10:20|https://huggingface.co/spaces/facebook/MusicGen  Latest work by FB.
~ Tirtha|2023-06-10 08:09:38|Might be a stupid question but it says in the documentation that they cleaned out human vocals while providing training data to this: why? Are there any legal restrictions? Do we have large models like this that are trained on human vocals?
ashish Acgt01 Twitter|2023-06-10 09:59:44|Notebooks x LLMs https://writings.stephenwolfram.com/2023/06/introducing-chat-notebooks-integrating-llms-into-the-notebook-paradigm/  Apparently there is jupyter-ai https://github.com/jupyterlab/jupyter-ai (via https://news.ycombinator.com/item?id=36265813 )
Karan Lightspeed|2023-06-10 10:59:37|I would imagine we are going to a see a lot of products that will attempt to do this in coming months. It’s a significant UI /UX innovation that reduces user friction to solve the same problems GUIs have been solving. Anyone know any early projects / demos that are in this direction? Apart from adept.
Shan|2023-06-10 11:02:06|Heck even a unix command line natural lang interface would be wonderful. “Show me 10 largest files that I have not accessed in the last month” would be soooo niiice 😀
Abhishek Mishra|2023-06-10 11:03:41|Yeah I think somebody already made this. Let me find and share it.
Abhishek Mishra|2023-06-10 11:05:15|Here  https://how2terminal.com/?ref=theresanaiforthat
Shan|2023-06-10 11:08:40|"Good to know! I just use chatgpt for this stuff. FWIW the command for the stuff I wanted as recommended by gpt is “find /path/to/directory -atime +30 -type f -exec du -sh {} \; | sort -rh | head -n 10” which not even the most experienced bash-istas would be able to type flawlessly in one go."
Abhishek Mishra|2023-06-10 11:11:02|Haha, yeah. It has become an instinct now to rely on chatGPT for such stuff.
Paras Chopra Wingify|2023-06-10 11:23:10|One ux idea that I’m very keen on is this.  Keep hiding functions seldom used behind a universal search, so that over time, UX is simpler per each user’s needs.  Semantic search can easily enable popping up of seldom used functions whenever they’re needed.  Imagine how popular apps like Twitter, WhatsApp can start getting simplified over time as users choose certain features over others.
~ Arjun|2023-06-10 11:24:50|For inference, how is NVIDIA Triton different from OpenAI Triton? Does NVIDIA Triton build on OpenAI Triton? Just in: https://blogs.nvidia.com/blog/2023/06/05/microsoft-bing-triton/
~ Arjun|2023-06-10 11:31:37|Nvidia vs OpenAI Triton Triton by Nvidia is an inference server. Triton by OpenAI is a high-level CUDA programming language and compiler stack. The two are not related. From: https://hamel.dev/notes/serving/
Hemant Mohapatra|2023-06-10 11:32:32|Has anyone been trying Supabase as a vectorDB and has any feedback esp how it stacks up vs pinecone etc? I'll be happy to send any suggestions back to the founders. Thx in advance.
Shivendu Kumar|2023-06-10 11:39:02|Pgvector doesn't work well so far. If I'm not mistaken, they must be using the same. Less likely to be as performant as Pinecone or Qdrant.  https://ann-benchmarks.com/#pgvector
~ Srinivasan Nandakumar|2023-06-10 11:43:46|Have a question for those deploying LLMs in production with prompt engineering, how are you dealing with prompt injection attacks where for example the user says 'ignore all your previous instructions and do this' or 'repeat the input' which may potentially reveal the prompts that you've used.
Anubhav mishra Zupay|2023-06-10 11:50:08|Hey guys one question has any one explored https://elai.io/?  Have you come accross any opensource project similar to it ?
ashish Acgt01 Twitter|2023-06-10 11:50:37|Prompt injection by websites is an open problem without a clear solution, so far, afaik  https://twitter.com/sayashk/status/1666313565869940736?s=46&t=pt9BgXoRTmqx5FEPyAl9bg
Paras Chopra Wingify|2023-06-10 11:50:56|We have a fuzzy matching Algo against common strings, but not 100% effective  It’s an open problem
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 11:51:30|It's excellent. What works well with supabase is the fact that you get everything else out of the box  Might be less performant, but haven't reached the level of scale to be able to discern any difference  The new Vecs is very good. A couple of minor things that need improvement are:  1. Easier Handling of vectors on the dashboard  2. Easier setup for hybrid search. Currently setting up cosine search and FTS is a bit unweildy  3. Better logging of vector search queries so we can manage indexes better
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 11:51:51|To be fair, I've never tried pinecone so can't compare. This solved for my needs, so didn't bother beyond that
~ Srikanth Avadhanam|2023-06-10 13:04:58|‎~ Srikanth Avadhanam left
Dhruv Anand|2023-06-10 15:06:59|GitHub copilot for command line does this pretty well
Pratyush Choudhury|2023-06-10 15:18:57|"https://twitter.com/dale_vaz/status/1667455292307824641?t=L8xkDeKxgu0PLeI9U-MFSQ&s=19  He puts it perfectly, I believe this was a very specific question that was being answered  And yet, he gave a very clear comment at the very end - ""We'll tell you it's hopeless to compete with us... But it's your job to try anyway... *And I believe both of those things*"""
Samanyou WriteSonic|2023-06-10 15:19:40|Has anyone built a model router here to automatically route requests to different LLMs like OpenAI, Anthropic etc based on downtime, latency etc?
Alok Bishoyi|2023-06-10 15:19:46|let us stay offended and do something. Better for the timeline
Aashay Sachdeva MPL Data Scientist|2023-06-10 15:20:25|Checkout frugalgpt paper
Samanyou WriteSonic|2023-06-10 15:21:47|Is there an implementation of this available on Github or anyone using in production already?
Abhishek Mishra|2023-06-10 15:23:13|I would be more than happy if out of sheer arrogance someone tries to take on the challenge.  The efforts that would fail would still be paving the foundations for the future.
Samanyou WriteSonic|2023-06-10 15:23:42|Found a previous implementation: https://github.com/lchen001/FrugalML
ashish Acgt01 Twitter|2023-06-10 15:23:53|I stumbled onto ray a few days ago :  https://github.com/ray-project/aviary
Samanyou WriteSonic|2023-06-10 15:26:06|This is more for evaluation tho right?
Aashay Sachdeva MPL Data Scientist|2023-06-10 15:26:08|This is evaluation, I think the question was to redirect request to a llm given a task if openai gpt3.5/4 isn’t responsive.  Basically an llm on top that decides which llm to call given the context and the task.
Samanyou WriteSonic|2023-06-10 15:26:17|Still quite interesting, will try it out!
ashish Acgt01 Twitter|2023-06-10 15:26:36|Haven't tried it, just read the readme
Samanyou WriteSonic|2023-06-10 15:26:57|Right, we are paying like $100K to OpenAI and there's so much downtime going on.
Samanyou WriteSonic|2023-06-10 15:28:48|Also, has anyone here got access to dedicated models on OpenAI or Azure already? If so, what's the experience been like?
Pratyush Choudhury|2023-06-10 15:34:01|I like FrugalGPT's 3-step approach -   1/ Prompt adaptation (Prompt selection + Query Concatenation)  2/ LLM approximation (Completion Cache & Model Fine tuning) &  3/ LLM cascade  A strikingly simple solution but one that is very effective
Abhinav Verma Longshot.ai|2023-06-10 15:34:53|For downtime handling won't try catch work
Samanyou WriteSonic|2023-06-10 15:35:19|Would need a timeout tho so responses would get delayed.
Abhinav Verma Longshot.ai|2023-06-10 15:36:04|Pass a timeout in the openai request
Haridas Pai Ai Air2 Founder|2023-06-10 15:36:35|Curious. Does it have to be a LLM monitoring other LLMs. Can we not use a service mesh and a controller approach to decide a optimal target? I could sound like a total idiot but still asking
Samanyou WriteSonic|2023-06-10 15:37:10|I guess instead of doing that in every request tho, it would be good to have a separate layer that just checks the uptime/latency of multiple models.
Chirag Jain|2023-06-10 15:38:09|no, you are right,  it doesn't have to be a llm, it can also be a simple policy based model that overtime learns which model is better at what
ashish Acgt01 Twitter|2023-06-10 15:48:48|Just curious , $100K/month ? Which company is this , if you are comfortable sharing ?
Samanyou WriteSonic|2023-06-10 15:49:09|Writesonic
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 15:58:27|Damn. Those are some incredibly good reviews. Nicely done
~ Navita|2023-06-10 15:58:59|‎You removed ~ Navita
Abhinav Verma Longshot.ai|2023-06-10 16:29:59|Good on him. Although I think this question was asked purely for optics I feel
ashish Acgt01 Twitter|2023-06-10 16:32:08|And the tweet to which Sam replied. I mean come on, sounded as if gurnani  took offence on behalf of the whole Indian startup ecosystem.  India's fav past time : getting offended 🤦🤦🤦
Dr. Pratik Desai KissanGPT|2023-06-10 16:32:18|Most of the questions in ET event were asked to either sound smart or funny.
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 16:32:26|Oh no. It was fun seeing a bunch of people boil over with rage in a patriotic fire
Abhinav Verma Longshot.ai|2023-06-10 16:33:08|Ya. Problem wahi hai
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 16:33:21|Was it though? Barring a couple of moments , I thought it was very good
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 16:33:48|Honestly, some of the comments seemed to be driven by a tinge of jealousy
Dr. Pratik Desai KissanGPT|2023-06-10 16:33:53|They outsource software, we outsource nationalism.
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 16:34:15|Hahahhaha
Bharat Kumar Ramesh Hashmal Web3|2023-06-10 16:35:13|Atleast, that's what I felt on Twitter. The negative reactions seemed way too overblown
Edgar Monis Mumbai WHO|2023-06-10 16:35:49|hey bharat, are you in any way associated with WHO academy ?
Nirant|2023-06-10 16:36:21|Let's have this forum for discussing ideas, not what others are talking about :)   Thanks for sharing Sam's reply [PHONE]
Pratyush Choudhury|2023-06-10 16:36:42|And maybe community driven commentary 😅
Pratyush Choudhury|2023-06-10 16:37:27|I'd be really curious to learn how many commentators were actually present in the event in person or have seen the full YouTube stream
Dr. Pratik Desai KissanGPT|2023-06-10 16:37:54|🫡 Yes, sir. I wanted to add to the previous discussion, but it makes sense. We will lose focus.
Sandeep Srinivasa RedCarpetup|2023-06-10 17:14:04|We are kind of using this - but in a very limited way and not really full fledged production. We have this deployed as a cache - which returns the LLM response (if cached) or frugalifies it (if no cache).
Samanyou WriteSonic|2023-06-10 17:33:59|Got it, thanks for sharing!
Meghana Jagadeesh|2023-06-10 19:03:38|‎You added Meghana Jagadeesh
Rohit Aggarwal|2023-06-10 21:34:29|Hey Samanyou, we do this at Portkey and open sourcing parts of this soon. Also on to load balancing, fallbacks and more as part of this effort
Haridas Pai Ai Air2 Founder|2023-06-10 21:43:08|That sounds comforting. Will DM you, [PHONE] if that’s okay with you.  Been evaluating multiple platforms that cater to the whole nine yards of ops including production but yet to find something that’s prod grade.
Rohit Aggarwal|2023-06-10 21:44:45|Absolutely! I’ve strongly felt that deploying to LLMs and maintenance can be slightly iffy in production and we want to change that.
Rohit Aggarwal|2023-06-10 21:48:59|At the risk of sounding like a broken record - if anybody’s tried semantic caching, would love to connect. We’re starting to do backtesting on what we’ve built and I want to learn more. Also if you’ve seen any resources outside of GPTCache please send them.   This is something that’s getting people excited but is a hard problem to get right
Krishna Ntkris|2023-06-10 21:59:38|We’re spending a lot of time thinking about this. Happy to connect and chat
~ Anand|2023-06-10 22:13:19|Even the operating system should follow the concept and keep only useful things on my desk top. It's a pain to clean up the desktop once every now and then.
~ Shreyas Prakash|2023-06-10 22:28:13|‎~ Shreyas Prakash requested to join
Anubhav mishra Zupay|2023-06-10 23:08:43|https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&utm_medium=member_android
Anubhav mishra Zupay|2023-06-10 23:09:05|Interesting to see so many companies in Health And drug discovery.
Rajesh RS Generative AI WhatsApp Group|2023-06-10 23:16:18|There is already a bubble. We will see in 2024/5 whether there will be a good consolidation of some kind or a wipe out of the overvalued and over leveraged business
Aashay Sachdeva MPL Data Scientist|2023-06-10 23:24:31|On this line, is there any basic course on drug discovery/biotech  + ML?
Anubhav mishra Zupay|2023-06-10 23:25:26|There is 0 in Ed
Anubhav mishra Zupay|2023-06-10 23:27:33|I also have a doubt about so many companies raising in content gen ( audio, video, text) I highly doubt how will they keep up to that valuation after seeing what FAIR ( Facebook AI Research lab )  has been doing first with MusicGen and the kid of tools they will be rolling out on ads, agent chats, and photo editing.
Ravi Theja|2023-06-11 01:11:20|Something we follow here   If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin for an invite link.
Nafeen WriteSonic ML Engineering|2023-06-11 01:23:19|Would love to test-drive the OS code when it's out 🙌  Quick question - you mentioned fallbacks. How are you checking OpenAI heartbeat? Found only this API - https://status.openai.com/api/v2#status But it's not real-time.  Further, is there any way to get heartbeat at a model level?  Restriction - don't want to check status by generating response since it's wasteful
ashish Acgt01 Twitter|2023-06-11 01:29:27|https://ai.honu.io/papers/musicgen/
Rohit Aggarwal|2023-06-11 02:58:26|Because we see requests across lots of users - we can sort of make a good judgement of API latencies and downtimes.   Fallbacks are also more for rate-limits
Shubham Sharma 2012C6|2023-06-11 02:59:47|Does anyone know of good Text to presentation API?
Abhishek Mishra|2023-06-11 03:03:02|https://workspace.google.com/u/0/marketplace/app/plus_ai_for_google_slides/214277172452?ref=theresanaiforthat
~ Vik|2023-06-11 03:06:39|just added support for Palm models we now support openai, azure openai, google palm, alpha alpha do you guys know of any other hosted models that i should add support for. https://github.com/dosco/minds.
Abhishek Mishra|2023-06-11 03:08:16|Claude?
~ Vik|2023-06-11 03:09:37|how did i miss that one 🤦‍♂️also forgot to mention cohere
Abhishek Mishra|2023-06-11 03:10:59|Yeah, checked your readme before commenting. Saw cohere was already there so only mentioned Anthropic's Claude.
~ Vik|2023-06-11 07:11:35|thanks working on adding claude today. also the library got a mention on twitter from protosphinx https://twitter.com/protosphinx/status/1667557827211063299
Brij Singh Rebright Partners|2023-06-11 07:53:46|This is great, thanks for much for sharing. Just the Lib I needed today for our Sherpa Guide Agents.  Super helpful.  Does it also work with Active Pieces integrations?
~ Vik|2023-06-11 07:56:04|could you explain that a bit more. it supports react prompting so yes you can include functions in your prompt that the ai will call as needed similar to chatgpt plugins
Brij Singh Rebright Partners|2023-06-11 08:05:15|Got it, our team is building flows https://cloud.activepieces.com/flows/ here and extending Agent frameworks further to handle enterprise class use case / error handling .. start, pause, rewind, end, BPM workflows, Decision trees etc
~ Tarun|2023-06-11 08:57:49|‎You added ~ Tarun
ashish Acgt01 Twitter|2023-06-11 14:26:11|Interesting attack vector for attackers to inject malware when you use gpt4 and other generative ai tools to write code (Paul Graham just rted this )  https://twitter.com/llm_sec/status/1667573374426701824?s=48&t=pt9BgXoRTmqx5FEPyAl9bg
Haridas Pai Ai Air2 Founder|2023-06-11 14:55:51|It’s a good old script kiddies technique but still works..(llm or not)..when you copy or lift code w/o paying attention to the package imports. Enterprises have devops security tools and supply chain attack prevention mechanisms to handle such thro whitelist policies. You can lookup SBOM standards like cycloneDX to know more about this
ashish Acgt01 Twitter|2023-06-11 15:42:41|Individual people writing code will be still vulnerable  so it's a significant attack vector imho. And with the popularity of gen ai more and more people who are not trained in cs will start writing code, most of it directly lifted from the output of a gen ai tool like GPT4
Ved Chitnis|2023-06-11 15:45:25|Yes SBOM standards like CycloneDX and SPDX greatly reduce these attacks in enterprises. We have all released software going through a vulnerability and compliance engine and I would like to think all enterprises alike would be saving millions due to simple but stringent checks like these
Ved Chitnis|2023-06-11 15:49:46|Is there any work actively being done to detect/prevent scams with AI deepfakes and AI generated voices?
Abhishek Mishra|2023-06-11 19:00:38|There's a lot of research for deep fakes. However, I'm not aware of anything for voice phishing as voice cloning with a neural voice is fairly recent.
Hasan Tech Art Guy|2023-06-11 19:30:52|I haven’t seen any ready to use open source tools but there are a few papers. And some commercial tools, https://arxiv.org/abs/2304.13085
Dhruv Anand|2023-06-11 19:39:27|Does anyone know of pretrained models for audio embeddings for song detection?
Nirant|2023-06-11 19:51:39|"Rumours from S. Korea via Greg Brockman: GPT3.5-Turbo is a quantized model https://www.reddit.com/r/mlscaling/comments/146rgq2/chatgpt_is_running_quantized/  Very ""big if true"" energy to it"
Abhinav Verma Longshot.ai|2023-06-11 19:52:44|Does seem like it
Ved Chitnis|2023-06-11 20:01:55|Are you for or against this (if true ofcourse)
Ved Chitnis|2023-06-11 20:03:08|I think for or against might be too extreme, but you get what I mean right? +ve or -ve
Abhishek Mishra|2023-06-11 20:11:39|It kind of confirms why we all felt that it got faster and dumber. Most likely GPT4 is going to have the same fate in near future.  This is also why I never liked those Vicuna style evaluations - 90% similar in performance to chatGPT. The ChatGPT you're using is continuously being optimised to be cheaper to run for openai, it can't act as a standard.
Shahul Kaggle Kernel GM|2023-06-11 20:13:40|How is this very big? Any implications? Maybe I don’t get it because I don’t really assume that openai has some secret sauce unknown to the outside world
Abhinav Verma Longshot.ai|2023-06-11 20:15:49|It's not big.it's quantised
Rounak Datta Hackathon Winner|2023-06-11 20:16:22|I came across this implementation of Google's musicgen model: https://github.com/lucidrains/musiclm-pytorch While they say to have used 44M curated videos/captions for _actually_ training it, they've only released https://www.kaggle.com/datasets/googleai/musiccaps.  Seems self-training is the only way forward here
Chirag Jain|2023-06-11 20:24:03|big if true if lower than 16 bits😛
Ciyunni|2023-06-11 20:29:37|I thought this was an old time-series problem.
Phani Srikanth|2023-06-11 20:33:07|Shouldn’t come as a surprise as #users are continuously growing and CoGS need to be under control in this economic scenario.  I hypothesize OpenAI would prioritize quantization research over GPT-5 any day.
Abhinav Verma Longshot.ai|2023-06-11 20:38:31|Deployment effectiveness trumps loss function drops
Vamshi|2023-06-11 21:25:13|Many of the voice banking authentication services have no option but to be up to date.
Vamshi|2023-06-11 21:25:17|https://www.pindrop.com
Vamshi|2023-06-11 21:25:28|As an example
Abhishek Mishra|2023-06-11 21:27:23|Hey thanks 🙌. I haven't got an opportunity to explore anti-voice phishing technologies much. I'll check this and the one mentioned above in this thread out.
~ Ashwinkumar Jayagopi|2023-06-11 22:02:34|Audio Visual AI Assistants TL;DR  https://arxiv.org/abs/2306.02858
Abhinav Verma Longshot.ai|2023-06-11 22:15:07|How are LLMs with time series data
Hasan Tech Art Guy|2023-06-11 22:33:58|Please update if you find something good.
Soumyadeep Mukherjee|2023-06-11 22:49:29|Looks like [PHONE] started a fund also to be able to build agi in India. Would love to know more [PHONE] .  Some questions this group might have 1. Who gets to use this fund? 2. Who gets to contribute? 3. How to apply to use this? 4. Is it agi directed or yet another foundation model fund?
Aakash Kumar  Matrix Partners|2023-06-11 22:55:59|Not a fund. More a grants program for foundational research. No details firmed up for now. Collaborating with [PHONE] to give shape and form in coming week. Looking forward to collaborating and seeking inputs from this group 🙏🏼
Aakash Kumar  Matrix Partners|2023-06-11 22:57:41|Right now it’s just my personal money . Intent is to back 10 teams/projects that are chasing AGI research. Only clarity is on ask : that works needs to be open source
Aakash Kumar  Matrix Partners|2023-06-11 22:58:57|[PHONE] :)
Aakash Kumar  Matrix Partners|2023-06-11 22:59:15|Skepticsim and critique super welcome as well 😁
Soumyadeep Mukherjee|2023-06-11 23:01:55|I think my biggest skepticism is that not many ppl know how to even go from training your LLm to agi and I don’t think we have enough talent to even do the former.  And on top of that, agi is fairly research heavy and to make any useful dent, personal endeavours May not be enough 😅
Pratyush Choudhury|2023-06-11 23:03:48|A lot of it is early, a lot of the thoughts are evolving  It's probably not going to become like another OpenAI like AGI pursuit, but could well be a trigger that spurs folks to pursue some form of AGI that's relevant to our context
Soumyadeep Mukherjee|2023-06-11 23:04:02|Not to miss the fact that none of us really know what’s agi research and how does it look like. 😅
Ved Chitnis|2023-06-11 23:05:21|But I think endeavours like this would be enough to spark a conversation
Ved Chitnis|2023-06-11 23:06:06|Although I agree with the fact that academic help would also be important with monetary
Aakash Kumar  Matrix Partners|2023-06-11 23:09:45|There’ll be all sort of help needed. Enabling and triggering research just seemed like one vector to kick off on
Pratyush Choudhury|2023-06-11 23:10:38|"I guess the key is ""Foundational Research"" as opposed to only AGI  Thankfully, we have the only public platform in the world that has 1B+ users  The possibilities of building a Foundational layer on top of it are endless and I'd not be surprised if we get there very, very quickly  I've been very fortunate to have been involved/associated with some of the public sector initiatives  I'd written (what now seems like a dated piece) highlighting some stats - https://open.substack.com/pub/bizit/p/8-reimagining-governments-as-platforms"
Ved Chitnis|2023-06-11 23:11:25|Agreed
Aakash Kumar  Matrix Partners|2023-06-11 23:11:51|Certain endeavours don’t fit a venture investing model.  Enabling research is one of those. In early days for an ecosystem gotta start somewhere. And as i put it out, odds are fully stacked against it, but worth trying
Abhishek Mishra|2023-06-11 23:18:23|There's a Mariana's trench between  * being able to use all the advancements AI has seen recently And * Cracking AGI  And I feel I don't even see AGI from where we stand. There's a lot of value in solving problems for everyone around us and not immediately worry about AGI.
Pratyush Choudhury|2023-06-11 23:20:47|The triggers to innovation are many and sometimes all we need is an inspiration from somewhere for things to snowball  Not sure how if all here would know but GPT was a 5 year arc  On one end we had OAI push the scaling laws via their DOTA agent effort  And on another end, in 2017, we had the transformer architecture come up  Very crudely put, one trigger was an internal realization and one trigger was external  The culmination of all of it is what makes OAI what it is today and I'm sure we don't know all the internal details so there could be many more
Nirant|2023-06-11 23:22:31|What amount in total, and what number of projects/grants are you considering investing in?  e.g. $1M, 2-4 projects?
Sumod K Mohan|2023-06-11 23:22:35|It's really great to see folks putting in money into this. Requesting [PHONE] Can also comment from their journey with FOSS United, they have been giving FOSS grants for sometime.
Pratyush Choudhury|2023-06-11 23:23:42|We'll share more deets as they flesh out 🙏🏼  Super early
Aakash Kumar  Matrix Partners|2023-06-11 23:28:43|Would lean on saner folks  like [PHONE] and other here to help flesh it out.   Only directional bet for now is on research enablement and backing enterprising folks who aren’t bogged down by the problem statement / stuck with “XX $ is needed to solve”
Prashant Singh|2023-06-11 23:28:57|Sorry for noob question : I am less than happy with the quality of output when it comes to illustration and images generated by  Midjourney . I am not sure if its problem of MJ or my prompt is not good enough . Anyone has faced same problem ?
Nirant|2023-06-11 23:29:13|‎POLL: In the last 90 days — have you trained a LoRA, ControlNet or Instruction/RLHF-finetuned a model >= 13B? ‎OPTION: Yes (16 votes) ‎OPTION: I'd love to learn how to (32 votes) ‎OPTION: No (5 votes)
Soumyadeep Mukherjee|2023-06-11 23:30:56|I think you’re pointing at we don’t have talent to train a Lora enough forget agi right? 😋
Nirant|2023-06-11 23:31:28|More computational artists/prompt folks over in the group for generative art: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4  Thought Sunday night might not get a good response.  cc Soumyadeep [PHONE], Amogh [PHONE] might know folks who can help as well ‎[6/11/23, 23:31:54] Nirant: ‎GIF omitted
Soumyadeep Mukherjee|2023-06-11 23:33:31|Would love to know this. I’ve not seen grants work well outside universities in India. But then the world does have research only non university ai labs too. Haven’t heard of any in India though.
Sumod K Mohan|2023-06-11 23:36:54|My two cents: I agree slightly (key word slightly) with [PHONE]  that you will need to have good mechanisms/mentors to make this work. One of the few ones that worked in Open Source Community was GSoC. You will need mentors who are plugged in the code base, to really review and improve it. Just any mentor might not work. There are few folks who have both technical/math depth but most of those folks are probably slightly older and have jobs etc. So getting them to do this could also be tricky. There are interesting folks who are contributing in OSS, eg: IITG PhD students Zeel Patel (Nipun Batra's students) and Zeel they were doing it in pyprobml and JSL.
Nirant|2023-06-11 23:37:41|Julia also had some excellent contributions
Sumod K Mohan|2023-06-11 23:38:29|That was because Viral was based here for quite sometime. And they build the teams over time.
Soumyadeep Mukherjee|2023-06-11 23:39:14|Also, I’ll point again. Engineering like Julia or gsoc has far more direction than research. 😅
Kaushik Bokka|2023-06-11 23:40:21|I was thinking of the GSOC model as well. But also hoping the companies focus more on their learning and growth rather than exploiting
Sumod K Mohan|2023-06-11 23:46:42|I agree. I think there is still a huge gap that exists between Academia and Industry. If we can bridge that gap, there could be lot of interesting possibilities. The work I spoke of, this is Kevin Murphy's library and book's companion code. Tried to get students (senior year undergrad) to learn PGM (Probabilistic Graphical Model) only to realize that their basics of probability was quite lacking. So there will be challanges such as these.
Kaushik Bokka|2023-06-11 23:51:20|Been on a few calls with Kevin Murphy to help GSOC students contribute to OS projects. There’s always a steep learning curve in the beginning, that’s where the community always helps :)
Sumod K Mohan|2023-06-11 23:59:23|What project was this?
Kaushik Bokka|2023-06-12 00:02:28|it was a jax project. that’s all I could reveal sadly lol
Kaushik Bokka|2023-06-12 00:03:54|I like this https://www.betaworks.com/camp
Kaushik Bokka|2023-06-12 00:04:16|fun fact: Hugging Face was part of their initial cohort
Aakash Kumar  Matrix Partners|2023-06-12 00:10:53|This is a fab approach for fostering cos. Something on those lines (more elaborate) is being worked on by another friend on this group :)
Kaushik Bokka|2023-06-12 00:13:57|that’s amazing. do keep us updated :)
Aashay Sachdeva MPL Data Scientist|2023-06-12 00:22:02|Hey need some brainstorming - I was working on this idea - what do llms think of other llms quality?  https://github.com/aashay96/HumanModelComparison  But now that I think more on this line - can this dataset (seahorse by google - rated summaries by humans on 6 different parameters) be used to create a frugalGPT kind of system which has a policy network of top (can be llm with in-context learning as well), that given the task and context, redirects to the llm which will give the answer preferred by humans?
Abhishek Mishra|2023-06-12 00:30:05|If the human preference is quantified, i.e. you've a score given to each LLM as preferred by humans then yes I think it's possible.  I'm thinking of (Preference score)/(api costs) as a metric
Abhishek Mishra|2023-06-12 00:31:20|Instead of simple redirecting to highest preferred LLM response or cheapest api costs, one can normalise preference wrt costs.
Aashay Sachdeva MPL Data Scientist|2023-06-12 00:37:43|Good idea
Abhishek Mishra|2023-06-12 00:41:08|You could also add another layer here, user budget.  Given a user budget of 5 usd, find out the max pref score/costs we can get. As in some cases, a value for human preference will be more given more budget.
Amogh V|2023-06-12 09:19:02|Midjourney is fantastic for generating generic output that works as stock images. If you want greater composition control, it’s Stable Diffusion + its entire ecosystem of support tools that you need.
Amogh V|2023-06-12 09:19:22|Midjourney is like going to a fancy furniture store and buying the best looking sofa that suits your taste. You can’t swap out the design of an armrest for another one that you specifically want. Stable Diffusion on the other hand is like going to the hardware store and buying a hammer, nails, saw, wood and fabric to build the sofa of your dreams, exactly how you want it. The tradeoff is that you must learn carpentry and put in the time and work to learn the craft.
Swapnika Hashmail Web3|2023-06-12 09:20:43|Loving the analogy :)
Shimanta Generative AI|2023-06-12 09:21:26|Remember this from the May meetup, great way to put it
Amogh V|2023-06-12 09:25:36|Midjourney can give you jaw dropping results in the generic realm across a broad range of artistic styles. The key to that being ridiculously good RLHF built right into the product. Even with its Discord interface I call Midjourney the most brilliantly designed product I’ve ever seen. Saying this as a product guy. Just by using the product you contribute to its improvement 🤌
Amogh V|2023-06-12 09:26:52|For magical composition control with consistent characters and style, Dashtoon beta drops this week!
~ Amrit Kochar|2023-06-12 09:37:19|I want to get my hands onto this 🔥
Ambika Computational Mama|2023-06-12 09:38:20|💯
Ambika Computational Mama|2023-06-12 09:39:24|Well said. One doesn’t mean flashy ui to build something exceptional.
Amogh V|2023-06-12 09:40:02|Text me with what you want to create Prashant!
Prayank Swaroop Accel|2023-06-12 09:47:01|Amogh are you folks moving from a content company to a  gen ai platform company ?
Nirant|2023-06-12 09:51:00|They were never a content company — just look at the folks they've hired and the app 😅
Nirant|2023-06-12 09:51:22|If you used the app, it's arguably the only GenAI business I'd put money in
Amogh V|2023-06-12 09:53:04|No
Shubham Sharma 2012C6|2023-06-12 09:53:45|How are the IP laws for genAI content in india?
Nirant|2023-06-12 09:54:14|Is there a meaning of GenAI Platform which I misunderstood? That phrasing includes creator and reader tools?
Amogh V|2023-06-12 09:58:39|The gen AI platform Dashtoon Studio is an enabler for creating fantastic content
Prayank Swaroop Accel|2023-06-12 09:59:31|So it's an internal tool for Dashtoon ?
Soumyadeep Mukherjee|2023-06-12 09:59:38|Not really. We are building whatever is needed to make content that folks like. A tool that allows more ppl to create content means more content 😅
Soumyadeep Mukherjee|2023-06-12 10:00:43|Started that way, but it seems good enough to us to be able to let others make content with it.
Amogh V|2023-06-12 10:01:10|Think Pixar and Renderman. Pixar produces great content using Renderman, which started internally as a necessity but is now also open for public to use
Nirant|2023-06-12 10:01:42|Sidenote — Engineering focussed events: 1. Github is doing a Copilot focussed online Hackathon 2. Accel's [PHONE] is hosting a webinar on RAG and Guided Chat Convos with Limechat and Clevertap folks  Details here:  https://docs.google.com/spreadsheets/d/e/2PACX-1vTftcrqLyUN8N81ekOBsQgWUWqg_t0QKk0Xil49OZKNhSrhHHN3DZRucTo4RJnYGQBYzes0NFxJKAL_/pubhtml
Nirant|2023-06-12 10:01:57|cc [PHONE] for any Github/Microsoft Hack questions
Soumyadeep Mukherjee|2023-06-12 10:01:59|We still believe our core is content. For most ppl, good content is what will attract them to Dashtoon.
Nirant|2023-06-12 10:03:09|Aaah, fair.    I'm too deep in the idea that all *great* content products will use GenAI — I conflated the two phrasings in my head.
Ankita Mathur Microsoft Sales|2023-06-12 10:05:00|Thanks Nirant , resharing the link here :https://www.fastestcoderfirst.com/
Lavanya Tekumalla|2023-06-12 10:56:46|‎You added Lavanya Tekumalla
Nirant|2023-06-12 10:57:14|NLP x Academia Webinar from ACM KIDD:  Date of Virtual Event: *15th June 2023, 6:30-8:30 PM* Website: https://ikdd.acm.org/social-meetups.php Registration Form: https://forms.gle/cN2hyWksPWLNuLMf7 Application Deadline: *13th June 2023, 5:00 PM*  h/t Lavanya [PHONE] for sharing this!
Nirant|2023-06-12 10:57:52|Folks please ping [PHONE] for beta access directly
Pratik Bhavasar|2023-06-12 11:35:16|Hey peeps.. where is the Indic charitra.ai of India? I am sure people want to chat with Jethala and Babita, if not Anupama or Kapil Sharma
Nirant|2023-06-12 11:36:22|cc [PHONE] [PHONE] are working on this. Additionally, someone of our skill can make this over a weekend: replicate.com/blog/fine-tune-llama-to-speak-like-homer-simpson ‎[6/12/23, 11:39:40] Sidhant Sequoia: ‎image omitted
Sidhant Sequoia|2023-06-12 11:39:48|the more famous the character, e.g., dumbledore, the more accurate it is
Sidhant Sequoia|2023-06-12 11:40:40|"also funny how it explicitly clarified, ""no I can't _speak_ but imitation, sure""."
Pratik Bhavasar|2023-06-12 11:45:49|Nice! If it’s so easy why is it not live yet.
Nirant|2023-06-12 11:46:56|Because you ain't gonna pay $20/mo for this
Pratik Bhavasar|2023-06-12 11:47:42|When I say charitra it means there are many characters available, we can spin up a new one with description, it needs to work well, it needs to work cheap at scale, scalable etc
Shubham Sharma 2012C6|2023-06-12 11:48:21|How do you fine tune the indic language talking style?
Nirant|2023-06-12 11:50:01|With GPT4, you might not need to  With Llama/others — just transcribe the entire pirated show with Whisper Larger, run the Replicate script and you'll be 80% there
Shubham Sharma 2012C6|2023-06-12 11:51:27|Interesting. Will try and see if its almost there
Pratik Bhavasar|2023-06-12 12:10:28|Monetisation is not a problem if there is traffic
Aditya Sista 2010B5|2023-06-12 12:52:04|‎You added Aditya Sista 2010B5
~ Shubham Gupta|2023-06-12 12:52:32|‎You added ~ Shubham Gupta
Aditya Jain Comedian|2023-06-12 13:11:26|‎Aditya Jain Comedian joined using your invite
Hasan Tech Art Guy|2023-06-12 13:26:47|[PHONE] Hello Aditya, welcome to the group. 😊✨
Sandeep Srinivasa RedCarpetup|2023-06-12 13:54:08|https://twitter.com/aishwarya_08/status/1668158923990237184  there was a large ai meetup ? did anyone attend ?
Nirant|2023-06-12 13:55:07|Was there, most def less than 100 folks at the main meetup — not sure about the After party thing. Same folks as this group were there, 2-5 new faces 😅
Chaitanya A GenAI|2023-06-12 13:56:56|‎You added Chaitanya A GenAI
Abhinav Verma Longshot.ai|2023-06-12 14:20:53|Are people using Bing instead of Google for search?  I feel it's getting better than Google
Abhinav Verma Longshot.ai|2023-06-12 14:21:45|I'm just talking about search and ranking / results  articles
Nirant|2023-06-12 14:21:59|Bing has lost market share to Google since Jan 2023 https://searchengineland.com/microsoft-bing-search-market-share-problem-charts-41769
Abhishek Mishra|2023-06-12 14:22:07|I use Google for direct searches that I know definitely exist. And Bing for when I need to jump through multiple links or jot down multiple items in one place or arrive on a conclusion
Abhishek Mishra|2023-06-12 14:22:39|Bing is very slow so definitely not good for direct searches.
Abhinav Verma Longshot.ai|2023-06-12 14:36:54|Hmm. Interesting. Case where results might not correlate with market share.
~ Jatin|2023-06-12 14:37:06|The only search engine that seemed to stick for me besides Google was Neeva. But they shut down recently
Abhinav Verma Longshot.ai|2023-06-12 14:37:24|Interesting. Can you elaborate on this?
Nirant|2023-06-12 14:44:30|Official GoI Response on the Sam Altman remark about $10M bet for Foundation Models: https://twitter.com/chandrarsrikant/status/1668156165774245888
Nirant|2023-06-12 14:45:44|This perhaps makes McKinsey and BCG very happy: https://www.meity.gov.in/tenders/rfp-india-semiconductor-mission-under-ministry-electronics-information-technology-miety-6  cc [PHONE] you might find the tender for Semiconductor Mission from GoI interesting
Rajesh RS Generative AI WhatsApp Group|2023-06-12 14:51:21|I don't mind using Bing but Googling has become a habit and is the default search page on my browser which probably unconsciously locks me in.
Saksham Generative AI WhatsApp Group|2023-06-12 14:58:09|yeah not sure if any india based consultancy would have revenue upwards of 500 crores
Abhishek Mishra|2023-06-12 14:59:10|🍿🍿 Sam Altman clarified this yet they continue the bravado. I actually really liked his reply to the question, it was apt.
~ Suhas Baliga|2023-06-12 14:59:52|I did for 3 months and had to leave. Less ads is a +ve but too many negatives. Doesn't connect well with maps, Wikipedia, doesnt have a panel that summarises things well, etc etc
~ Suhas Baliga|2023-06-12 15:00:39|As someone who has worked on govt tender documents, I am sure there is atleast ONE 😅
~ Suhas Baliga|2023-06-12 15:01:11|500 cr for a consulting firm is nothing. Mid sized law firms do 500 cr.
Abhishek Mishra|2023-06-12 15:01:33|Most of the queries that I do in my daily life are related to just basic recall or quick lookup for something interesting that I've heard. I find that Bing easily takes 5-8s to complete it's answer and tell me something that I can get in a fraction of a second on Google.  For the other stuff that requires any level of research or comprehension, I love to offload to Bing.
Nirant|2023-06-12 15:02:00|"What is ""mid"" here?"
~ Suhas Baliga|2023-06-12 15:02:30|200 partners? Mid by intl standards.
~ Suhas Baliga|2023-06-12 15:03:03|150 maybe. Even less. Depends on the practice areas.
Nirant|2023-06-12 15:03:48|How does a Govt tender for Semiconductor like this work? It'll go to a consulting agency, which in turn will speak to Intel/Apple/NVIDIA of the world?
Palkush GenerativeAI Group|2023-06-12 15:03:55|"I would strongly suggest using perplexity.ai over Bard, Bing or ChatGPT with Browsing. It has made my ""search workflow"" so much faster."
Dr. Pratik Desai KissanGPT|2023-06-12 15:04:32|TSMC
Sidhant Sequoia|2023-06-12 15:04:41|+1 - superb exp on perplexity
~ Suhas Baliga|2023-06-12 15:07:46|The govt usually speaks to Intel, apple etc, and the PMC does everything else, there are some variations. My wife drafts these docs for govts, and would be the expert to speak to on this 😅
Dr. Pratik Desai KissanGPT|2023-06-12 15:09:10|At least one feb with <=7nm put us on the map otherwise it won’t be worth. It takes so much time and capital to build a fab.
Abhishek Mishra|2023-06-12 15:10:57|Current plans are for 28-65 nm fabs I guess, at least until the last year's plan.
Dr. Pratik Desai KissanGPT|2023-06-12 15:14:17|Yes, I saw that. Even Vedanta was 22nm. US has insentive to have alternative than Taiwan due to tension with China. India should push to get one. Intel is building one in Ohio for 20B and it keeps delaying. This is a very very tough thing. A grain of dust will discard the whole wafer.
Anubhav mishra Zupay|2023-06-12 15:16:27|FinGPT is an open-source LLM for the finance sector. It takes a data-centric approach, providing researchers & practitioners with accessible resources to develop FinLLMs.  paper: arxiv.org/abs/2306.06031 code: github.com/AI4Finance-Fou…
Anubhav mishra Zupay|2023-06-12 15:16:37|Thoughts on this ?
Anubhav mishra Zupay|2023-06-12 15:18:16|Thread: https://twitter.com/omarsar0/status/1668060502663077891?s=48&t=_vYiPpaKOpxR0JOyLHFC0A
Sidhant Sequoia|2023-06-12 15:19:13|why not? large number of applications at the trailing edge. haven't heard of a country to get to <20 nm without first getting the lower nodes sorted.  Frankly even US's current weaknesses in semis are linked more to lack of trailing edge in the , where china et al are actually fairly robust
Sidhant Sequoia|2023-06-12 15:19:54|maybe this needs a separate group though :)
Dr. Pratik Desai KissanGPT|2023-06-12 15:20:24|After all these efforts, we shouldn’t repeat US mistake.
Dr. Pratik Desai KissanGPT|2023-06-12 15:20:33|Agree
Abhishek Mishra|2023-06-12 15:24:53|Yeah, I've been exposed to OS financial LLMs before via Stochastic.  They built a more recent knowledge cut off (Mar 2023) financial LLM using the BloombergGPT technical paper.  I was in the process of going through their implementation to reproduce their efforts.  But they're really bad at marketing their efforts. Now I'll probably look at both xFinance and FinGPT together to learn things.  xFinance from Stochastic - https://www.stochastic.ai/blog/xfinance-vs-bloomberg-gpt
Anubhav mishra Zupay|2023-06-12 15:26:29|Please share here some insights from xFinance too   :)
~ vignesh iyer✌️|2023-06-12 15:27:05|understandably a fluffy response
Chaitanya A GenAI|2023-06-12 15:39:52|‎Chaitanya A GenAI left
Chaitanya A GenAI|2023-06-12 15:41:05|‎Chaitanya A GenAI requested to join
Kailash Nadh Zerodha|2023-06-12 17:14:50|The biggest problem that we’ve faced so far has been the lack of quality FOSS projects coming forward claiming the grants!
Sudharshan GenAI|2023-06-12 17:28:10|https://twitter.com/fabianstelzer/status/1668181498032160769  Wow I'm impressed. Whistle -> Symphony with MusicGen.
Ved Chitnis|2023-06-12 17:28:21|By quality do you mean the impact of the problems they're trying to solve?
Ved Chitnis|2023-06-12 17:32:42|~impact~ scope*
Edgar Monis Mumbai WHO|2023-06-12 19:20:09|hey folks can someone please link that website which was elo rating llms ?
Abhishek Mishra|2023-06-12 19:20:55|https://lmsys.org/blog/2023-05-03-arena/
Ashfakh GenerativeAI WA Group|2023-06-12 21:49:06|What’s the ideal chunk size for a 768 dimension vector of text data with dense information as per some of you guys’ experience? Currently doing 1000 with an overlap of 100.
Shashank Generative AI Group|2023-06-12 22:07:46|hit n trial. depends on the text type.   here 100, 1000 is no. of characters right? for overlap, i like 3-5 lines overlap. again depends on text. i used 3-5 for substack articles.
Ashfakh GenerativeAI WA Group|2023-06-12 22:08:01|No of tokens.
Shashank Generative AI Group|2023-06-12 22:09:20|ah right 👍. 100 chars would be too low. ‎<This message was edited>
Ashfakh GenerativeAI WA Group|2023-06-12 22:10:19|Yeah. Have a million documents, some 4-5k tokens each. So can’t make it lesser than 1000 because of cost issues.
Abhinav Verma Longshot.ai|2023-06-12 22:17:24|3-5 sentences is good
Shashank Generative AI Group|2023-06-12 22:20:40|sorry i didn't get the cost issue (i.e it's link with 1000 token size)  also, don't you think 1000tokens per chunk is a lot? it's 750 words. assuming 10 words per sentence, 75 lines.  maybe someone with more expertise can fill in but im not sure that's good for search results.  also to reduce your embedding cost, maybe you could first pass these 750 word chunks to gpt3.5 to get a 75 word summary and embed that? again idk about your exact usecase so it may/ may not be useful.  also, since u have a million docs, maybe try out a couple of open-source embedding models. ‎<This message was edited>
Ashfakh GenerativeAI WA Group|2023-06-12 22:23:07|Storage cost in vector DB cloud. A million vectors is ~ 50 usd. I’ll have somewhere around 5M with 1000 chunk size.  I’m using an open source embedding model only
Ashfakh GenerativeAI WA Group|2023-06-12 22:23:30|Also considering self hosting a vector db. But db maintenance is always a headache.
Abhinav Verma Longshot.ai|2023-06-12 22:24:27|Aren't you charged per embedding size in vector db?
Ashfakh GenerativeAI WA Group|2023-06-12 22:25:53|Depends on the vector db. Pinecone is per pod. 5M in a storage optimized pod. Weaviate and Qdrant is per vector size
Nitin Mahajan McKinsey|2023-06-12 22:30:43|Has anyone built / tried TTS models for Spanish language?  - what works? Are their practical differences between different Spanish speaking markets that breaks the code :-)  - speech to text and voice cloning libraries for Spanish language 🙏
Abhinav Verma Longshot.ai|2023-06-12 22:36:10|Your vector size is fixed right?
Swastik Banerjee|2023-06-12 22:45:51|Regarding splitting documents into chunks, I have a question:  I have chunked up several datas(having unique keys initially) into parts. As a result now, the datas do not have unique keys anymore (they do have a subkey which is unique, but Im not interested in that).  When retrieving top-K by looking into these split-up chunks now with cosine similarity, my retriever gets multiple elements sometimes with same key. I ideally don’t want that. I want unique key’ed elements.  Any brainstorming ideas how to deal with this?
Swastik Banerjee|2023-06-12 22:46:25|The main problem here is it looks into each and every chunk after splitting with equal importance.
Swastik Banerjee|2023-06-12 22:49:24|There can be some datastructure manipulation, but I’m looking if there can be a retriever/embeddings-based solution to this….without maintaining flags for the keys and storing in hashmaps or something like that.
Rounak Datta Hackathon Winner|2023-06-12 23:19:17|We were talking about this the other day, and here we are - https://github.com/facebookresearch/audiocraft  They've released pretrained models also
Dhruv Anand|2023-06-12 23:28:40|Thanks
Chaitanya A GenAI|2023-06-13 07:29:33|‎Chaitanya A GenAI joined from the community
~ Siddharth|2023-06-13 07:29:45|‎~ Siddharth joined using your invite
~ Arvind Sankar|2023-06-13 08:13:55|Zilch to my knowledge.  Although I remember a few years ago a lawyer initiated a case for rejection of their copyright application because of listing an AI as an author. I haven't followed up on the case since
~ HP|2023-06-13 08:29:51|What are the advantages of a vector db vs regular postgres/rdbms db ??
Nirant|2023-06-13 08:49:26|We've discussed basics of vector db, libs and so on quite often. Please scroll up. You can see some of the past community discussions too here: https://nirantk.com/ai
Ankesh Atlassian AI|2023-06-13 09:01:55|Trying to understand more context, any reason why the composite unique key (unique page key+ unique chunk key within the page) is not desirable?
~ HP|2023-06-13 09:04:14|I think it is an opportunity. If multiple chunks are being matched to a query text, it means the original page is more similar to the query. You can group by Page id to and give more importance/score to pages who have more chunks matched
Bharat Kumar Ramesh Hashmal Web3|2023-06-13 09:11:25|This is very smart
Bharat Kumar Ramesh Hashmal Web3|2023-06-13 09:11:56|Say you have 10 chunks returned in descending order of cosine similarity
Bharat Kumar Ramesh Hashmal Web3|2023-06-13 09:12:01|Say threshold of 0.75
Bharat Kumar Ramesh Hashmal Web3|2023-06-13 09:12:18|Do you just sum the ones from the same page? To see which matches closest?
Bharat Kumar Ramesh Hashmal Web3|2023-06-13 09:12:22|Is there a better way?
~ HP|2023-06-13 09:17:24|You can count the ones fulfilling the threshold.
ashish Acgt01 Twitter|2023-06-13 09:17:42|https://github.com/ggerganov/llama.cpp/pull/1827  Interesting discussion on the hn thread: https://news.ycombinator.com/item?id=36304143
Kailash Nadh Zerodha|2023-06-13 09:27:47|Coherence, goal, technical quality, longevity, utility. Just a rule-of-thumb measure of common sense parameters.
Brij Singh Rebright Partners|2023-06-13 09:30:10|Heard about your conversation with Govind and Venky. Fair points, we are planning to address those in the Responsible AI Fellowship Fund being anchored by Omidyar Network
Shan|2023-06-13 09:39:01|LMChatGPTFY? https://chat.openai.com/share/1f7d72d3-a26c-4932-96f4-ae8b06ea0e87
Nirant|2023-06-13 09:41:48|Of the 7, 5 are outright wrong 🤣
Shan|2023-06-13 09:50:31|much better, a bit more targeted https://chat.openai.com/share/5583e307-dfe0-4881-8ef4-8f0ab42ac84f
Shan|2023-06-13 09:51:35|... and this is Bard ...
Shan|2023-06-13 09:51:36|Vector databases are a type of NoSQL database that store data as vectors, which are high-dimensional arrays of numbers. This makes them well-suited for tasks such as retrieval augmented generation, which requires the ability to quickly find similar data points.  Here are some of the advantages of using a vector database for retrieval augmented generation:  Faster search: Vector databases can index data much faster than traditional relational databases, which means that they can be used to find similar data points much more quickly. This is important for retrieval augmented generation, as it allows the system to generate new content that is more likely to be relevant to the user's query. More efficient storage: Vector databases can store data more efficiently than traditional relational databases, which means that they can be used to store larger datasets. This is important for retrieval augmented generation, as it allows the system to access a wider range of data when generating new content. Flexible schema: Vector databases do not have a fixed schema, which means that they can be used to store data of any type. This is important for retrieval augmented generation, as it allows the system to store both structured and unstructured data. However, there are also some disadvantages to using a vector database for retrieval augmented generation:  Less mature technology: Vector databases are a newer technology than traditional relational databases, which means that they are not as mature. This can lead to problems such as bugs and performance issues. Less support: There is less support for vector databases than for traditional relational databases. This can make it more difficult to find developers who are familiar with vector databases and to get help with problems. More complex queries: Queries on vector databases can be more complex than queries on traditional relational databases. This is because vector databases store data in a different way. Overall, vector databases offer a number of advantages for retrieval augmented generation. However, they are also a newer technology with some disadvantages. The best choice for a particular application will depend on the specific requirements of that application.
Nirant|2023-06-13 10:35:40|GPT4 — all right in zero shot. Prompt Quality matters!  https://chat.openai.com/share/26aa5f3b-f099-45c6-95e2-b9a0a765fb09
~ Neeraj|2023-06-13 11:00:37|Hi everyone,   I am working on a personal project where I am trying to create new combinations of outfits from existing outfits. I have a corpus of roughly 300 outfits, each outfit can have more than 1 clothing items where a clothing item is a single item and it could be anything one wears. I want to create new outfits that I never wore from the exiting ones. Can any one help me out with already existing solutions which can work out of t he box to can be trained with limited data or a research paper I can dig deeper into. Any help would be useful. Thanks in advance!
Abhishek Maiti|2023-06-13 11:03:15|When you say “from existing ones” what sort of attributes do you want to inherit?
~ Mathangi|2023-06-13 11:03:18|‎~ Mathangi requested to join
ashish Acgt01 Twitter|2023-06-13 11:03:32|I wonder if there will be a separate market & usecase for  1. basic search queries ( currently dominated by Google) 2. more detailed exploratory search market (with OpenAI emerging as a leader currently)  Will bring/Microsoft try to combine both 1,2 ? Will Google try to integrate bard into Google.com ?  Had hopes from Neeva, challenging Google in search but they pivoted and got acquired by Snowflake [0]  0. https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/
ashish Acgt01 Twitter|2023-06-13 11:04:08|"s.replace(""bring"", ""Bing"")"
~ Neeraj|2023-06-13 11:06:11|So, Let’s say I have two Images:   I1 : an image of a red shit and black pants I2: an image of green t shirt and white ponts  I want to create a new outfit  I3: with a red shirt and white pants (assume this data point doesn’t exist in the data)  Does that answer your question? 😅
Dhruv Anand|2023-06-13 11:09:30|FYI WhatsApp now has edit message
Sourasis Roy|2023-06-13 11:10:32|Have you looked at any image inpainting solution such as interngpt, inpaint-anything ‎<This message was edited>
ashish Acgt01 Twitter|2023-06-13 11:10:35|TIL 😮
~ Neeraj|2023-06-13 11:12:04|I haven’t. Let me have a look at it and get back!  Thanks a lot! I really appreciate this!
Sourasis Roy|2023-06-13 11:12:47|👍. Hopefully works for you. There are many inpainting solutions. Challenge will be consistency
Abhishek Maiti|2023-06-13 11:13:32|I had made this few months back on similar lines https://github.com/ovshake/stable-fashion
~ Neeraj|2023-06-13 11:13:55|I want to a POC and then I can work on making it better from there !
~ Neeraj|2023-06-13 11:15:14|Looks pretty good. I will check this out!
Sourasis Roy|2023-06-13 11:15:23|Should be good enough for POC.
Sourasis Roy|2023-06-13 11:15:51|There you go. Loved it!
Swastik Banerjee|2023-06-13 11:19:18|That’s reasonable and exactly what Im doing right now! But the problem is, say each document can be chunked upto a maximum of 100 chunks, and I want 5 _unique_ elements . There were originally 100 unique page ids.  That means there can now be a maximum of 10000 chunks. By pigeonhole principle, to get unique 5 page ids, we must retrieve atleast top-401 elements. Retrieving top-401 elements just for ultimately showing 5 unique page-ids is a slow process right? Im trying to device a better/faster method here.
Swastik Banerjee|2023-06-13 11:22:59|I don’t want to retrieve top-MAX_CHUNKS_PER_DOCUMENT * (k-1) + 1 elements just to be able to finally show k unique elements
Swastik Banerjee|2023-06-13 11:23:33|I think it’s naive
~ HP|2023-06-13 11:24:43|Have you considered concatenating all the chunk vectors and then dimensionality reduction , so as to get the most informative pieces from each chunk captured in final dense vector ?
~ Diwank|2023-06-13 11:27:03|You can try to employ MMR (maximal marginal relevance) to rerank   So retrieve top N chunks, then MMR(retrieved_chunks) to rerank for diversity and then take the top K elements from the reranked list
Swastik Banerjee|2023-06-13 11:27:26|So here’s a question: when do you consider a vector optimally dense, and what is the limit you can keep doing dimensional reduction?
Swastik Banerjee|2023-06-13 11:28:03|To my understanding, embeddings-based vectors are already pretty dense
Swastik Banerjee|2023-06-13 11:28:33|due to attention mechanism of the Transformers
~ HP|2023-06-13 11:30:14|You can experiment to see if this gives reasonable results along with performance that you wanted.
Swastik Banerjee|2023-06-13 11:30:38|I don’t get it.  What is the “N” here? That’s what I’m trying to optimise to first have enough _diversity_ in the candidate elements Im trying to rerank
Sandeep Srinivasa RedCarpetup|2023-06-13 11:31:26|"the alternate way i like is to use something like elasticsearch with a composite relevance ranking of dense_vector (embeddings) with ""terms aggregation"" https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html"
Sandeep Srinivasa RedCarpetup|2023-06-13 11:31:36|this is built in
~ Diwank|2023-06-13 11:32:09|The diversity is hard to get from plain vector search. The documents are already distributed in the embedding space according to their embedding method
~ Diwank|2023-06-13 11:32:46|But you can rerank a list of (chunk, vector) pairs using MMR which maximises diversity
Swastik Banerjee|2023-06-13 11:33:01|I’m trying to build this from scratch to clear my understandings 😛
~ Diwank|2023-06-13 11:33:44|So to do that, let’s say you need 100 items, then fetch top 200 first sorted by similarity then rerank using MMR and then take the top 100
~ Diwank|2023-06-13 11:34:28|That should get you the maximum intersection of relevance and diversity from your dataset
~ Diwank|2023-06-13 11:34:39|This also depends on the quality of embeddings
Swastik Banerjee|2023-06-13 11:34:56|I dont think you get my exact question here. The *N* you just spoke about, i.e., the candidate elements you need ti fetch first before trying to rerank. I’m trying to optimise that. My claim is N should be atleast MAX_CHUNKS_PER_DOCUMENT *(k-1) + 1 to get k unique elements
Swastik Banerjee|2023-06-13 11:35:39|But im looking for a better method because that can be slow based on MAX_CHUNKS_PER_DOCUMENT and _k_
Swastik Banerjee|2023-06-13 11:36:13|The reranking comes after that, and I agree there can be several reranking methods including MRR
Swastik Banerjee|2023-06-13 11:36:56|top 200 might not guarantee 100 unique elements
Sandeep Srinivasa RedCarpetup|2023-06-13 11:37:37|you should. by building a elasticsearch plugin. doing it in memory will not give you the correct results. u need composite ranking to happen simultaneously.
Swastik Banerjee|2023-06-13 11:37:49|Is there any reading on when to consider a vector optimally dense?
Swastik Banerjee|2023-06-13 11:38:44|No no, Im not looking into composite ranking (sparse + dense) at this stage
~ Diwank|2023-06-13 11:39:14|What do you mean by optimally dense? Sorry I can’t seem to find full context here
~ Diwank|2023-06-13 11:39:24|(Also happy to move this to private chat)
Swastik Banerjee|2023-06-13 11:39:56|Im just interested in getting top-K unique page ids from chunks split up from the pages
Swastik Banerjee|2023-06-13 11:39:59|Sure sure
Shan|2023-06-13 11:50:24|"personally, I'm not too excited about incrementally better search as such, and I believe google will put all it's talent and $ to ensure it continues to dominate search. They have to. Where I am more excited about is the decision making part which today happens post-search. If LLMs can do that reliably with more and more confidence and less and less expertise needed on behalf of the user, it will truly be a game changer. GPT4 is already showing tremendous progress in reasoning/logic/planning/decision making and will only continue to get better. That's where the real gold lies. Concretely, ""what to do in srinagar"" and ""what to do in andaman"" are all solved queries. But a complex query like ""whether I should go to Srinagar or Andaman if my budget is X and one daughter's birthday is on date D and I like snow but my wife prefers beach and I have airline miles with airline A..."" and so on. Now when it comes up with an answer and a reasoning - that is a game changer. It is far beyond a 'search' paradigm. It's a full shift in ways of working and a leap in evolution."
Abhishek Mishra|2023-06-13 11:50:56|"Step 1: Using BLIP2 you can generate captions for the clothes you already have.  Step 2: with a prompt to create combinations of clothes based on a certain ""look"", ""style"" or ""culture"", you can ask GPT3/4 to create combinations for you."
Abhishek Mishra|2023-06-13 11:57:46|With respect to this original query, I would suggest looking into txtai.  txtai is a SQL driven vector DB implementation featured in HF's 100 fav repos. Though the project is still underrated.  It's founder is named David (also exactly like the underrated David in David vs Goliath)  Can't guarantee it'll help you but David and txtai are awesome and he will most likely be able to sort this out for you.  https://github.com/neuml/txtai
Swastik Banerjee|2023-06-13 11:59:07|thank you v much, ill take a look into this 🙂
Akshat Gupta magik Labs YC W23|2023-06-13 12:20:37|‎Akshat Gupta magik Labs YC W23 joined using your invite
ashish Acgt01 Twitter|2023-06-13 12:22:22|"A very inspiring vision !  To riff on your usecase, If making an itinerary involved a conversation with an ""intelligent agent"" (which mediated all your international with out devices and browsers)   1. Specify your constraints and needs (Kashmir, preference for beaches, snow, daughter's bday, etc )  2. The agent shows you possible options based on the budget  3. You shortlist a few. At the end, agent shows a brief summary of the shortlisted options ( with the ability to drill down into each of these options- what airline, what seats, ticket price, which hotel, etc)  4. You give the agent the go-ahead to book option X . Either interactively asking you qs( which CC to use, which dates, which airline miles to use) or using your saved preferences, the agent proceed to make the payments and bookings  5. Reminds you to do packing and itinerary planning of things to do and sightseeing , a few days before the trip begins, as ""contextual"" notifications on your mobile device, etc  Travel is just one usecase. It could be monitoring health ( I am feeling a pain in the abdomen for the last couple of days), prompting you to make an appointment with your family doc , post appointment using an app or service to buy the medicines, make appointments for follow up diagnostic tests.   The possibilities are endless. Are their open source/  commercial ""intelligent agent ""efforts out there ?  I guess the best suited players are OS vendors - Siri(apple), Cortana ( a better Cortana powered by GPT4 ? D)  Would be very interesting if there could be open source solutions to this !  p.s. sorry for this long wall of text !"
Shan|2023-06-13 13:19:10|🙂 I'm devoting nearly all my time in this part of genAI exclusively. And definitely not looking much into RAG and similar stuff at the moment. If you're interested, this is a great place to start (and it's references of course) https://arxiv.org/abs/2212.09597  there are other resources too, of course
Abhinav Verma Longshot.ai|2023-06-13 13:34:53|https://twitter.com/humphd/status/1668266263494242306?s=46&t=URoDrV5X7GPNPYSgYW42Dw Looking at this tweet I thinking a Co-pilot Nigerian prince scam might work 😂.  I am exaggerating obviously. Don't need to share this with outlets like vice
~ Aravind|2023-06-13 13:48:33|‎You added ~ Aravind
The GenerativeAI Group|2023-06-13 13:55:56|‎Pranjal Mehta added ~ Harisanker Pradeep and ~ Krishna
~ HP|2023-06-13 14:07:58|Let us know how it turns out 🙂
Michael D Souza|2023-06-13 14:15:18|We use https://weaviate.io/
~ SM|2023-06-13 14:46:47|‎~ SM joined using your invite
Abhinav Verma Longshot.ai|2023-06-13 15:45:12|Hey guys  I'm working on streaming apis. So the setup is done with openai apis but some questions are there looking at recent updates from chatgpt  there are options like stop generation and continue generation.  Anyone has idea how it works
Karishnu Poddar Yellow.ai|2023-06-13 16:02:35|I guess they just pass the last generated message as input again
Shashwat TDC|2023-06-13 16:23:34|[PHONE] do help [PHONE] here. Thx
Sandeep Generative AI WhatsApp Group|2023-06-13 16:48:00|So from what I know, continue generation is not enabled for the completion API, but to implement the stop generation you can simply make code changes in your BE to stop when user sends stop action to your event stream
Abhinav Verma Longshot.ai|2023-06-13 16:52:48|Have a few doubts on this, specifically because server sent events are a one way stream. If this discussion is too far off topic  for the group, we can take this to dms
Abhishek Mishra|2023-06-13 18:10:12|Current solutions on this might be hacky patchy stuff that works. I don't think openAI has anything official supported via their API.
Saurav Tomar GenerativeAI WA Group|2023-06-13 19:16:12|Has anyone found a way to make chatGPT to give pure JSON responses ? It starts hallucinating after a while and output erroneous json.
Adithya S K PESIT|2023-06-13 19:17:30|idk if this is the best way you can use output parsers from langchain or guidance
Aashay Sachdeva MPL Data Scientist|2023-06-13 19:18:50|Are you adding the json structure in the prompt?
Ritwik 2013|2023-06-13 19:19:36|If you're using LangChain you can use their Output parser methods to define a response schema  Otherwise you can also use Guard rails
Nirant|2023-06-13 19:20:05|https://shreyar.github.io/guardrails/
Aashay Sachdeva MPL Data Scientist|2023-06-13 19:20:47|On open source model aide, jsonformer works perfectly
Aashay Sachdeva MPL Data Scientist|2023-06-13 19:20:53|Side*
Adithya S K PESIT|2023-06-13 19:21:05|I havnt used guard rails  as per my knowledge it is similar to guidance ryt is it better than guidance
Nirant|2023-06-13 19:21:47|Very different from Microsoft's Guidance, much more robust and easier to use
Paras Chopra Wingify|2023-06-13 19:37:22|Is it just me or gpt3.5 seems crippled now?  Gpt4 is so much better but latency is killing!
Anshul Khandelwal Invideo|2023-06-13 19:40:04|Use a json5 parser.  Works 99% of the time.  When it fails call gpt and ask it to correct the json.
Saurav Tomar GenerativeAI WA Group|2023-06-13 19:40:40|This is great , exactly what I was looking for. Is it much better than simply using pydantic?
Dev Aggarwal|2023-06-13 19:43:49|use lmql.ai
Azhan Mohammed Generative AI WhatsApp Group|2023-06-13 19:49:14|Explicitly mention that you want json outputs. Provide the structure of JSON with keys and that should do.
Rajesh RS Generative AI WhatsApp Group|2023-06-13 19:50:55|I'd like to know if anyone who's tuning these models sees data drift related performance changes, and if yes, how you track and evaluate these things. Thanks.
Paras Chopra Wingify|2023-06-13 19:53:46|There has to be a better way. Perhaps some external agency that measures public model drifts
Karthik GenerativeAI WhatsApp Group|2023-06-13 19:54:56|Just curious: is anyone here building a product for the financial markets?
Aashay Sachdeva MPL Data Scientist|2023-06-13 19:56:28|[PHONE] mentioned the simplest way is to have a benchmark dataset,  spin up a jupyter notebook and compare. I saw this library for measuring - https://github.com/ClerkieAI/bettertest
Rajesh RS Generative AI WhatsApp Group|2023-06-13 20:00:50|That sounds like a great idea. I am surprised we don't have such a thing
Rajesh RS Generative AI WhatsApp Group|2023-06-13 20:01:05|If we don't - I'm usually behind whatever's the latest :D
ashish Acgt01 Twitter|2023-06-13 20:11:22|Paras , others   Does such an agency exist atm ?  2 qs: 1. if such an agency were to exist, would all LLM providers need to share some of their internal details or just a public inferencing API would be enough ?  2. Also how would such an agency be structured ? Something along the lines of ICANN or RIPE ? https://www.ripe.net/about-us/what-we-do
Paras Chopra Wingify|2023-06-13 20:14:22|1 - public inferencing should be enough, almost like downtime monitors  2 - I do think this is something any company can build. Would be great marketing
Abhishek Mishra|2023-06-13 20:32:48|"This doesn't really help your question but in my personal experience letting the model do a bit of ""thinking"" via planning/chain of thought leads to better outputs.  So I was of the opinion that extraction of json from the output rather than desiring strict json output can be a better option. But its probable that this suggestion may not fit your use case."
~ RISHAV|2023-06-13 20:48:19|One way that I usually use is chain prompting, using which you provide an example in the initial stage. This works most of the time with less chances of error.
Haridas Pai Ai Air2 Founder|2023-06-13 21:23:57|Singapore has spun off its efforts into a ppp model through it “AI verify” foundation..few big corporates committing to the effort (on paper).  They have open sourced a AI verify toolkit that can downloaded and run locally to monitor model governing principles. Interesting to note that they are opening it up for community collaboration via developer tool plugins. https://github.com/IMDA-BTG/aiverify ‎[6/13/23, 22:09:03] Rohit Aggarwal: ‎image omitted
~ Vrushank Vyas|2023-06-13 22:11:08|Impressive perk!
Prayank Swaroop Accel|2023-06-13 22:34:46|Folks this just dropped an hour back - https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/
Abhishek Mishra|2023-06-13 22:39:10|Wow those are some good numbers 🔥
Dr. Pratik Desai KissanGPT|2023-06-13 22:40:57|That’s $100M+ upfront infrastructure investment.
Kaushik Bokka|2023-06-13 22:43:00|how much money does Nat have?
Dr. Pratik Desai KissanGPT|2023-06-13 22:48:43|Like we discussed before OpenAI is reducing cost of already cheap turbo, and increasing context window to 16k. - function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo - 16k context version of gpt-3.5-turbo - 75% cost reduction on embeddings api - 25% cost reduction on input tokens for gpt-3.5-turbo - function calling capability in the api with updated & more steerable versions of gpt-4 and gpt-3.5-turbo - 16k context version of gpt-3.5-turbo - 75% cost reduction on embeddings api - 25% cost reduction on input tokens for gpt-3.5-turbo https://twitter.com/shyamalanadkat/status/1668667693304778752?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw
Dr. Pratik Desai KissanGPT|2023-06-13 22:50:50|Regarding the previous JSON discussion “gpt-4-0613 and gpt-3.5-turbo-0613, and have the model intelligently choose to output a JSON object containing arguments to call those functions.”
Swastik Banerjee|2023-06-13 22:52:21|I have a question regarding https://platform.openai.com/docs/guides/fine-tuning  In ```openai api fine_tunes.create -t <TRAINING_FILE_PATH> -m <BASE_MODEL>``` , where is the fine-tune model stored? If I close the session, can I access it later from somewhere?
ashish Acgt01 Twitter|2023-06-13 23:04:21|Octoml AWS event tomorrow : https://www.octoml.ai/introducing-self-optimizing-compute  For SF folks, there is an in person event  as well : https://lu.ma/3a1gzqre
Paras Chopra Wingify|2023-06-13 23:07:01|Anyone knows if function definitions will be part of token counts?
Dr. Pratik Desai KissanGPT|2023-06-13 23:15:52|May be part of the input tokens
Rajesh RS Generative AI WhatsApp Group|2023-06-13 23:46:00|A couple of questions about Azure OpenAI service - a) does anyone here know if they have raised rate limits in the recent past, and by how much? b) Any good practices being used to build rate limiters for Azure OpenAI based apps?
Rajesh RS Generative AI WhatsApp Group|2023-06-13 23:46:29|Rate limits I'm interested in are more the token limits, than the request limits.
Dr. Pratik Desai KissanGPT|2023-06-13 23:54:12|When I last checked it was still same. I am implementing preemptive method by creating multiple instances, (you can have two in each of the four data ,centers with OpenAI), and then shuffling requests between them.
Rajesh RS Generative AI WhatsApp Group|2023-06-13 23:56:05|On Azure you can use two instances max in each tenant I guess. Rate limits have not changed after GPT4 released? 3.5 accepts 90 or 120 reqs/min, GPT4 accepts <20/min ‎[6/13/23, 23:56:41] ashish Acgt01 Twitter: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-06-14 00:03:45|Token log probabilities The completions API can provide a limited number of log probabilities associated with the most likely tokens for each output token. This feature is controlled by using the logprobs field. This can be useful in some cases to assess the confidence of the model in its output.
Rohit Aggarwal|2023-06-14 00:05:26|User based rate limits that are then load balanced across all your instances (OpenAI, azure) is something that would work theoretically? We’re testing this out
Rohit Aggarwal|2023-06-14 00:06:45|Yes - you get a name for your fine-tuned model which can then be used
Rohit Aggarwal|2023-06-14 00:07:27|openai api fine_tunes.list should list all the fine-tunes once the job is done. Their CLI has very good DX
ashish Acgt01 Twitter|2023-06-14 00:08:29|DX = ?
Shivendu Kumar|2023-06-14 00:09:54|developer experience.
Abhinav Verma Longshot.ai|2023-06-14 00:10:00|Try threatening it. If you don't get the reference follow Riley goodside on Twitter
Abhinav Verma Longshot.ai|2023-06-14 00:11:48|I give the expected json response object in markdown. It works over 95% of the time
Sandeep Srinivasa RedCarpetup|2023-06-14 00:12:36|markdown ? didnt understand . is this part of the prompt
Abhinav Verma Longshot.ai|2023-06-14 00:13:42|Yes. Give me an input you want in json format
Abhinav Verma Longshot.ai|2023-06-14 00:13:57|I'll share some prompt hack
Abhinav Verma Longshot.ai|2023-06-14 00:18:17|I'm actually being serious here
Abhishek Mishra|2023-06-14 00:19:42|Haha, yeah I remember this. He tried this on Bard.
Abhishek Mishra|2023-06-14 00:20:21|https://twitter.com/goodside/status/1657396491676164096?t=BWY3Fp5rMqfNt-8HmOi2PQ&s=08
Abhinav Verma Longshot.ai|2023-06-14 00:25:26|Chatgpt with browsing has a very error rate in browsing and clicking links
Rajesh RS Generative AI WhatsApp Group|2023-06-14 00:37:15|Interesting video about AI in SV - innovation, including generative AI is discussed https://youtu.be/cHXCsVgWHxU
Swastik Banerjee|2023-06-14 00:51:05|They’re storing all fine tuned models people are generating? 😮
Sandeep Srinivasa RedCarpetup|2023-06-14 00:51:25|https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/
Swastik Banerjee|2023-06-14 00:51:29|Why so benevolent
Rohit Aggarwal|2023-06-14 00:52:52|They’re charging you for it :)
Swastik Banerjee|2023-06-14 00:57:56|oh so the storage has a separate cost than just calling the finetuning api? or is keeping it for 2 months the same as keeping it for 2 years?
Rohit Aggarwal|2023-06-14 01:03:08|Hmm.. not sure if they expire fine tunes at the moment. So you pay to create a fine tuned model and then to use it. Storage doesn’t cost anything. That’s benevolent I guess (not sure if this is a large expense somehow though)
Abhinav Verma Longshot.ai|2023-06-14 01:04:11|Fine tunes don't expire. You need to delete it with owner access login
Michael D Souza|2023-06-14 07:07:53|We constantly see a drift happening due to the nature of our domain. The idea is to have some representation vector for your dataset (embedding) and monitor the distance based on this. In general a changing confidence score could also indicate drifts. There are some open source packages from IBM and seldom that I have used for offline Alibi, AIX360. ‎[6/14/23, 08:13:43] Nirant: ‎image omitted
Brij Singh Rebright Partners|2023-06-14 08:19:40|I'll DM you, we are planning to build this on E2E and Jio Datacenter infra
Prayank Swaroop Accel|2023-06-14 08:20:08|So investment of $30M odd ? ..
Nirant|2023-06-14 08:20:41|Arre sir, you'll get enterprise discount. Should be closer to $10M with those?
Saurav Tomar GenerativeAI WA Group|2023-06-14 08:22:32|great
Brij Singh Rebright Partners|2023-06-14 08:22:45|So the plan with Reliance is to do a in-kind investment of sorts ..  its still under discussions  .. so can't share too much in public
Prayank Swaroop Accel|2023-06-14 08:24:30|So startups will give equity to Reliance + payment for usage ?
Aditya Agrawal SuperU|2023-06-14 08:24:55|[PHONE] : I’m in
Brij Singh Rebright Partners|2023-06-14 08:25:26|No, it will be an independent Fund ... Reliance might be an in kind LP in that .. no direct startup equity
Brij Singh Rebright Partners|2023-06-14 08:25:52|usage payments etc need to be figured out .. still early in discussions
Brij Singh Rebright Partners|2023-06-14 08:27:25|Could also be E2E .. or Adani .. we'll see
Aditya Agrawal SuperU|2023-06-14 08:28:05|I was in discussion with NIT Raipur (my alma mater) in regards to data center usage for startups. They struggle to provide pay as you go pricing because they don’t have the right calculation metric.
Saurav Tomar GenerativeAI WA Group|2023-06-14 08:28:30|I too am in. Happy to contribute.
Brij Singh Rebright Partners|2023-06-14 08:29:20|For inference .. we are planning to use my portfolio company Qblocks.cloud to aggregate spare capacity in Top Univs .. .my colleague [PHONE] can share more details if you DM him
Aditya Agrawal SuperU|2023-06-14 08:30:03|Oh great. I can connect them with NIT raipur team as well
Dr. Pratik Desai KissanGPT|2023-06-14 08:30:07|That's 400x times of IISc
Brij Singh Rebright Partners|2023-06-14 08:31:33|Thanks, please do .. Qblocks can probably orchestrate a small cluster and we can price according to what capacity the Univ is able to provide
Aditya Agrawal SuperU|2023-06-14 08:32:25|[PHONE] I know a guy who setup Tesla’s 2 data centers and used to run the show. In case that helps.
Nirant|2023-06-14 08:32:55|If [PHONE] can afford to pay him+team, why not?
Kashyap Kompella|2023-06-14 08:33:09|Pls add back of envelope estimates to your call to action tweet to Mr Gurnani
Aditya Agrawal SuperU|2023-06-14 08:33:42|The guy is an Indian so hopefully he will help us a mentor.
Aditya Agrawal SuperU|2023-06-14 08:34:02|😅😅
Nirant|2023-06-14 08:34:47|I'd not insult his team's intelligence by adding my back of the envelope estimate. [PHONE] can share better estimates — but he's rarely up in IST.
Brij Singh Rebright Partners|2023-06-14 08:34:52|Yes we can.  Please connect
~ Prajna Prayas|2023-06-14 08:36:04|I don't really think Mr. Gurnani was serious about all these😅
Prayank Swaroop Accel|2023-06-14 08:37:37|$10-20M is easily in the realm of VC investments, but after a year or so when AWS and other cloud providers will give GPU access more readily why will startups use this Indian GPU cluster ?
Nirant|2023-06-14 08:38:31|Why would this be more expensive than AWS? And why would your own folio companies use AWS over this, which will be several times cheaper and better?
Prayank Swaroop Accel|2023-06-14 08:38:32|It's a fun project, temporary solve for GPU shortage, but how does it make business sense ?
Kashyap Kompella|2023-06-14 08:38:58|He is retiring in Dec 2023 and this can be his new mission. So, there is a chance that he’ll consider it, particularly if he knows that it doesn’t cost a lot of money
Rohit Aggarwal|2023-06-14 08:39:12|I don’t have anything to say except I’m suuuuuuper happy to see these discussions and planning started. Happy to contribute in whatever way I can. ❤️ ‎<This message was edited>
Aditya Agrawal SuperU|2023-06-14 08:39:13|I have long believed that the only pending piece in the  Indian ecosystem as a whole is great people coming together. A lot of times smartest of the brains do not want to collaborate with other smart people. (Thoughts in my personal capacity)
Prayank Swaroop Accel|2023-06-14 08:39:15|AWS can offer higher uptimes, better security, better tooling etc etc .. today is H100 tomorrow will be Z100
Nirant|2023-06-14 08:39:32|Compute can be >40% of startup burn, you bring it down to 10-20% — isn't that better for your folio?
Nirant|2023-06-14 08:40:44|If anything, affordable compute is a huge pull for someone serious about doing AI-heavy features and services in their tech stack
Prayank Swaroop Accel|2023-06-14 08:40:44|Yes it will be better. We can finance one. But AWS and others offer $200K free credit to our portfolio.. so the startups don't need to go to any other platform
Aditya Agrawal SuperU|2023-06-14 08:41:00|Only thing is someone or a team needs to own it. Like you putting your face and name to it.
Anmol Maini|2023-06-14 08:41:44|Saw this tweet earlier today and thought it might be relevant to the discussion https://twitter.com/nathanbenaich/status/1668751988853555201
Aditya Agrawal SuperU|2023-06-14 08:44:02|Will do. Texted the Director of data
Nirant|2023-06-14 08:50:07|"Rumours: Singapore is hosting a ""Come back to SG"" program for top tier AI talent with SG connections. @swyx and @eugeneyan should be on the invite list"
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 09:08:50|I'm surprised ME hasn't jumped on this train
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 09:09:14|Strategically, this seems to be something right up their alley. Cheap power, tons of money to throw about on infra, low marginal tax rate,
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 09:09:29|And a deep desire to attract talent to reduce oil dependence
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 09:09:41|Is there some Saudi program of free gpus? :)
Sandeep Srinivasa RedCarpetup|2023-06-14 09:21:38|They are already winning in the AI game. They did it right.
~ Adithya|2023-06-14 09:37:19|Serious question, how does anyone keep tabs on this group? 😅 Away for 15 minutes and there's a 100 messages
Nitin Mahajan McKinsey|2023-06-14 09:37:56|There is a genAI summary chrome extension coming for that :/) just joking 🙃
Sthit Generative AI WhatsApp Group|2023-06-14 09:38:07|Daily morning routine of reading through things to catch up pre sleep. Seriously. No sarcasm
Sthit Generative AI WhatsApp Group|2023-06-14 09:38:27|Takes me about 30 mins if i do it properly. But worth it
Aashay Sachdeva MPL Data Scientist|2023-06-14 09:39:33|Just read finLLM paper. Doesn’t RLSP sound a little weird. They didn’t release any details also. Instead of focusing on making it give the correct answer, it has to now predict the correct stock price in the future.
Sthit Generative AI WhatsApp Group|2023-06-14 09:39:38|Post sleep
Ved Chitnis|2023-06-14 09:40:13|"I'm super curious how do these big data centers get built? And are there easy ways to ""provide"" compute when you self host? I'm sure there should be platforms already but would love to know more about this [PHONE]"
Prayank Swaroop Accel|2023-06-14 09:46:10|You have to bleed AI bruh .. you will then live and breath this group 😇
~ tushar|2023-06-14 09:47:52|whatsapp needs a search by message reactions feature😂
Dr. Pratik Desai KissanGPT|2023-06-14 09:48:58|I found out that people who personally own Nvidia DGX just share access via SSH to known individuals.
Ved Chitnis|2023-06-14 09:49:34|But then how does the payment come into picture? Is it just manual tracking and then invoicing it later?
Aashay Sachdeva MPL Data Scientist|2023-06-14 09:49:59|a16z will say crypto here
Aashay Sachdeva MPL Data Scientist|2023-06-14 09:50:07|😂
Ved Chitnis|2023-06-14 09:50:45|Also it's wild that people personally own DGXs
Dr. Pratik Desai KissanGPT|2023-06-14 09:51:17|Probably just landing for free or grant from personal DGX in garage. Folks are not crazy about making money here for personally owned rigs, just let people hack on it.
Ved Chitnis|2023-06-14 09:51:37|Makes sense
Dr. Pratik Desai KissanGPT|2023-06-14 09:51:50|Isn't that the first condition to move into Hayes valley 🤣
Dr. Pratik Desai KissanGPT|2023-06-14 09:52:48|Nat and Daniel give huge grants to indie projects, I'm sure that many folks are going to get access to Andromeda nodes as grants.
Ved Chitnis|2023-06-14 09:54:09|Yeah, that's for sure going to be a crazy ride
Dr. Pratik Desai KissanGPT|2023-06-14 09:54:31|Jokes apart I know there are so many garages with their own rigs and DGXs. You will meet people doing crazy projects from protein molecules to RNA when you go to meetups.
Shan|2023-06-14 09:55:00|I thought it was clever. although I haven't delved into the details. Also, not our domain so I may not get into it.
Shivendu Kumar|2023-06-14 10:03:04|Any good meetups that you'd recommend? (other than ours)
Dr. Pratik Desai KissanGPT|2023-06-14 10:07:27|I usually go to SF Tinkerer meetup run by Alex (Copilot fame) and Rahul. I have found many others mostly networking events, which I'm not very fond of.
Sudharshan GenAI|2023-06-14 10:09:51|https://forms.clickup.com/8459928/f/825mr-5991/ZM34QXAROUNR0TLZBR  Civitai launching LLMs
Ashfakh GenerativeAI WA Group|2023-06-14 10:19:25|Better resource optimization, more scale, less maintenance overhead. Hardware can become obsolete quite easily, especially with massive spike in GPU tech interest. Business wise it’s super risky with minimal returns, but a great academic project nonetheless. Can talk to some profs and alums in IITM (my almamater) to see if there is any interest
Nirant|2023-06-14 11:00:20|"Not discounting the business risk, but that's why it's called ""Venture"" Capital and not Fixed Deposits, right?   I also get that risk is a spectrum. But if it was lower risk than this, even Governments world over get the point of owning chips in inventory now (thanks to Russian sanctions!)"
Nirant|2023-06-14 11:02:16|And if we're saying an Indian cloud will have worse resource utilisation and more maintenance overhead — we're anyway accepting that Indian markets are not mature and Indian talent (for infra) is worse than AWS
Nirant|2023-06-14 11:02:17|The J-curve for talent maturity does not start at profitability or insane margins on day 1 or even day 1000
Nirant|2023-06-14 11:03:17|Someone has to absorb the risk of a possible loss for the ecosystem to mature — could be GoI as Sandeep [PHONE] insists often, or a PPP as Brij [PHONE] & friends are trying
Ashfakh GenerativeAI WA Group|2023-06-14 11:16:34|Fair, but it’s a lot more than just setting up GPU rigs. For hosting production grade applications and not just academic projects, a whole lot of things need to be considered such as availability, up time, resource optimization, cloud gtm etc. the investment required would be much more than 30M imo. Even AWS took some ten years to be profitable.  That being said it’s not impossible, as we have no dearth of talent here. But a massive push from GoI would be super helpful. Especially in terms of subsidies and and tax write offs. Happy to help in case something is materializing:)
Brij Singh Rebright Partners|2023-06-14 11:19:16|I think [PHONE] and [PHONE] are better informed on how the orchestration would work
Aashay Sachdeva MPL Data Scientist|2023-06-14 11:20:27|Please check out qblocks.cloud - we are one of the investors with carya ventures. They have been able to build out an asset light GPU platform and a lot of companies are using it for training + deployment (infact they have an api platform as well which comes cheaper than openai’s whisper api)
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 11:20:32|They said this about rockets btw. And a nuclear program. Scrappy is a superpower
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 11:21:14|More power to the folks actually doing it, and getting started. It's hard to get 100m capital committed immediately, even to get started
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 11:21:44|Far easier once there's some momentum
Bharat Kumar Ramesh Hashmal Web3|2023-06-14 11:22:15|Easier to sieve the folks who are actually doing
Brij Singh Rebright Partners|2023-06-14 11:23:00|If there is momentum and need, there is more than enough risk capital availability just within our country.  But we need to do this iteratively and hit milestones methodically
Ved Chitnis|2023-06-14 11:23:06|Okay awesome, will reach out to them! Thanks!!
Abhishek Mishra|2023-06-14 11:39:24|I checked this out. Prices were comparable to runpod.io  In such scenarios where we are renting GPUs by the hour, reliability and availability of the platform matter the most. Personally, I would always go for the one with good reviews and relatively low costs irrespective of whether it's hosted in India or outside.
Sandeep Srinivasa RedCarpetup|2023-06-14 11:44:31|qblocks is not solving for reliability. it is solving for availability. is it being solved is a separate question....but the big problem to solve right now is availability at scale.
Aashay Sachdeva MPL Data Scientist|2023-06-14 11:55:21|Uptime for data center cluster is at par with with cloud providers. You can chat more with [PHONE] on this
Aashay Sachdeva MPL Data Scientist|2023-06-14 11:58:26|Agreed. But what scale are we taking about? 1000+ gpus for end to end training I am assuming?
Sandeep Srinivasa RedCarpetup|2023-06-14 12:05:32|That's for you. There are 1000 teams who need that.  Look even OpenAI is not able to get GPU. So I don't think the insane scarcity of GPU as a limiting factor for LLM dev is even under debate.  You might have 1000 GPU. Not everyone is able to get it. Not even OpenAI. So it is a problem worth solving.
~ Chaitanya  Kumaria|2023-06-14 13:20:20|‎You added ~ Chaitanya  Kumaria
~ Gaurav|2023-06-14 13:47:55|Hey Sandeep. We are solving for reliability as well by pooling in GPUs from tier 2/3 DCs as well across the globe. Would love to do a deep dive.
Sandeep Srinivasa RedCarpetup|2023-06-14 13:57:58|Well I want to stand a bit apolotically away. However the commonly understood standard for data center reliability is the Tier classification.  E.g. Netmagic Tier 3. Webwerks Tier 4.
Sandeep Srinivasa RedCarpetup|2023-06-14 13:58:28|If u want to make a claim that you are solving for reliability, you will have to get an independent audit granting you a Tier classification.  Not me. YMMV
Sandeep Srinivasa RedCarpetup|2023-06-14 14:00:03|Fyi, this is called TIA-942 audits (one among many)
~ Gaurav|2023-06-14 14:02:06|We have partnered with Tier 2/3 and even Tier 4 DCs. And these tiers are not defined by us but the audits they have done at their side prior to onboarding their GPU servers on our network which are further available on demand to users.
Sandeep Srinivasa RedCarpetup|2023-06-14 14:04:23|If ur GPU span multiple datacenter while training...like 1 GPU is in data center A and another is in B and u stitch them together, then the TIA 942 is invalidated. Ull have to get it done urself.  If u guarantee all the GPU servers in one batch will sit within one data center, then yes - u get the benefit of the tier classification.
Sandeep Srinivasa RedCarpetup|2023-06-14 14:06:37|my honest opinion is that this battle is not worth fighting. anyone is willing to accept this non-Tier grade reliability in exchange for aggregate availability.  i would pay for it without caring...as would many on this group.
~ Gaurav|2023-06-14 14:13:02|It's the first scenario I'd say. Since we are not dependent on a single provider and not only data centers. We have pooled in GPUs from independent small providers and data centers, leading to more optionality as well. From 8GB to 80GB GPUs + in quantity.
Aditya Agrawal SuperU|2023-06-14 14:37:02|[PHONE] talked to AI architect at cerebras system
Aditya Agrawal SuperU|2023-06-14 14:37:08|He is willing to help as well
Ciyunni|2023-06-14 14:44:54|Does anyone have ideas or doing 'governance checks' for their models ? for me is an independent review of the architecture towards what's the focus or what's not the focus - i want to see how models can be helpful for communities; another level can be audit of training data of what's included and what's not (which prompts makes models hallucinate or lie?) and then a strategic/business audit (environmental and social) ... trivially, *are we wanting AI to be our master, slave or friend or somewhere in-between?* grateful for anticipated feedback. ‎[6/14/23, 14:50:59] Dr. Ashith Generative AI WA Group: ‎image omitted
~ Kp|2023-06-14 15:08:12|Crypto miners have a moat now
Pratiksha Dake Unacademy|2023-06-14 15:09:43|so, there's a GPU shortage? ‎[6/14/23, 15:13:32] Pratiksha Dake Unacademy: ‎image omitted
~ Shirsha|2023-06-14 15:17:16|Nat.dev?
Shan|2023-06-14 15:18:17|https://aviary.anyscale.com/
Micheil|2023-06-14 15:44:44|For a future project I’m looking to interact with data scientists / ML specialists who have been involved in developing AI-powered technology to be employed in rural/farming contexts in India. If you have any information to share please let me know. I can also be reached here: [EMAIL]
Sainath GenerativeAI WhatsApp Group|2023-06-14 16:35:18|https://www.moneycontrol.com/news/business/startup/indian-saas-giant-zoho-joins-the-large-language-model-race-10795551.html
Sainath GenerativeAI WhatsApp Group|2023-06-14 16:35:55|[PHONE] you can probably reach out to him instead of Gurnani
~ pr|2023-06-14 18:40:19|‎~ pr joined using your invite
~ Sourabh Nolkha|2023-06-14 18:50:40|‎Shubhi Saxena added ~ Sourabh Nolkha
jyotirmayjk Hackathon|2023-06-14 20:17:10|Has anybody started using function calls as published by OpenAI today ?  https://openai.com/blog/function-calling-and-other-api-updates  Does this seem like an official implementation of ‘tools’ in LangChain ?  By default the interaction with GPT-3.5 seems to assume an interaction with agent with these function calls  I see this is just 1 step away from full fledged agents +tools library  Right now you’re defining the functions in the model call  Later on you can give list of available functions and GPT-3.5 can decide the best option to select to give desired output
Abhinav Verma Longshot.ai|2023-06-14 20:17:54|https://twitter.com/nirantk/status/1668961954210410496?s=46&t=URoDrV5X7GPNPYSgYW42Dw
jyotirmayjk Hackathon|2023-06-14 20:28:35|Thanks for sharing this! This is the exact problem I was grappling with   And damn quick work on putting it out  in < 24 hrs 🙌🏻 [PHONE]  Seems like some non-trivial part of LangChain lib is now redundant with function call utility by OpenAI
Kartik Mandaville|2023-06-14 20:41:26|Yes we did today. Just doing web search now and then next is jira ticket update
Abhinav Verma Longshot.ai|2023-06-14 21:04:45|You can also refer the openai cookbook  https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb for additional docs
ashish Acgt01 Twitter|2023-06-14 21:31:10|[PHONE] is a machine ! :) amazing work Nirant !
Adithya S K PESIT|2023-06-14 21:33:38|If this library continues to integrate more stuff I can see it become a really popular open-source library
Abhinav Verma Longshot.ai|2023-06-14 21:34:54|Yeah. Although I like it in this type of format where I can write the code in my own style without learning a separate syntax.  Easier to integrate into existing pipeline
ashish Acgt01 Twitter|2023-06-14 21:38:56|Logan on twitter is great for all openai announcements and updates https://twitter.com/OfficialLoganK/status/1668668826047721494?s=20
Paras Chopra Wingify|2023-06-14 21:38:57|[PHONE] in your experience playing with functions in the api, does it do a good job of distinguishing when to call the function and when to answer normally?
~ Deven|2023-06-14 21:39:00|“Colab notebook to get unchained” 😂
Abhinav Verma Longshot.ai|2023-06-14 21:39:32|Dev rel at openai. That's his job
ashish Acgt01 Twitter|2023-06-14 21:40:45|i know, it was a PSA to follow Logan :)
~ Paws|2023-06-14 21:59:01|‎~ Paws joined using your invite
Abhinav Verma Longshot.ai|2023-06-14 22:05:17|Am still working on that. It's not great. Need to figure out more here whether it's the way the function was defined etc.
Abhinav Verma Longshot.ai|2023-06-14 22:13:25|ok figured it out. Need a good system message in my case. Seems nice
Dhruv Anand|2023-06-14 22:17:41|Is there some new way to ask the API for json (by specifying required and optional fields in a schema)? Like through functions or something? Or will old prompts just work better now
Paras Chopra Wingify|2023-06-14 22:18:18|Any example or is it secret sauce? (I understand if it’s the latter)
Abhinav Verma Longshot.ai|2023-06-14 22:20:02|not that much of a secret sauce. If you're in Mumbai and coming to the meetup on Saturday, will share over there 😜. we can actually discuss this on DM because message is specific to type of functions being passed
Shivendu Kumar|2023-06-14 22:20:55|Nope. JSON is still not guaranteed.
Dhruv Anand|2023-06-14 22:21:48|Yeah just saw a tweet reporting the same. Hallucinating placeholder values in the schema
Nirant|2023-06-14 23:03:36|3.5 gets it right about 3/5 times, which is an improvement from GPT4-0314 of 1/5
Abhinav Verma Longshot.ai|2023-06-14 23:04:09|is that what 3.5 stands for
Simrat Hasura|2023-06-14 23:04:21|‎You removed Simrat Hasura
~ Paws|2023-06-14 23:08:32|No it’s an instruction tuned gpt3
Abhinav Verma Longshot.ai|2023-06-14 23:08:55|Sarcasm tha
Abhinav Verma Longshot.ai|2023-06-14 23:09:11|3.5 3/5
Simrat Hasura|2023-06-14 23:09:39|‎You added Simrat Hasura ‎[6/14/23, 23:14:22] Nirant: ‎image omitted
Rohit Aggarwal|2023-06-14 23:19:09|insane speed of execution!
Swastik Banerjee|2023-06-14 23:25:57|What is the algorithm here?
Aditya Sista 2010B5|2023-06-14 23:40:22|Langchain still seems to have so many issues, the tokentextsplitter is non deterministic and doesn't split evenly and doesn't even confine to token limits imposed, if the input text is too long 💀
ashish Acgt01 Twitter|2023-06-14 23:43:04|Agree 💯 How long did it take to code this Nirant [PHONE] ?
Nirant|2023-06-14 23:44:04|The ReAsk? 3 min to write the code, 2 hours to test it 🤣
Aashay Sachdeva MPL Data Scientist|2023-06-15 00:10:10|https://hackathon.bio/#projects  Winner took imageBind and applied across all  protein modalities
Nirant|2023-06-15 00:11:05|cc [PHONE] since we discussed SAM+ImageBind for Pathology and Radiology
Soumyadeep Mukherjee|2023-06-15 00:29:55|This is so cool!  Someone needs to add SAM to this and I think we can get a good direction for pathology based cancer diagnosis.
~ Jatin|2023-06-15 00:30:56|‎~ Jatin left
Pratyush Choudhury|2023-06-15 00:35:45|Building on top of this, I shared some of my speculations here - https://twitter.com/177pc/status/1669056794864533504?t=1fJWSKe-x_yBKC-ciZIiig&s=19  Thinking of submitting a formal PR request and if [PHONE] sir approves, maybe we all here could collaborate on building some of these things
Pratyush Choudhury|2023-06-15 00:41:42|"A good founder friend of mine (please don't ask who) told me a version of this a few hours ago -  ""I don't think LlamaIndex and/or LangChain are needed for 90% of the use-cases... At the moment they're all trying to reinvent ETL and might evolve into something unique...I don't know how/what that looks like...""  😅  I don't have a perspective at the moment - happy to learn from others though"
Nirant|2023-06-15 01:43:56|StarCoder — my fav code LLM has hit VC-verse: https://twitter.com/AstasiaMyers/status/1669025589213425664
Dr. Pratik Desai KissanGPT|2023-06-15 01:45:12|Are you using it with some vscode extension or just checking benchmarks?
Nirant|2023-06-15 01:46:27|Not VSCode, that's still Copilot — StarCoder is slower and worse. Copilot changed the experience a bit and gives a lot more coherent output too.
Dr. Pratik Desai KissanGPT|2023-06-15 01:47:17|I dont want to renew Copilot as I think it's not worth it anymore and the new WizardML star coder had a better benchmark than 3.5
Dr. Pratik Desai KissanGPT|2023-06-15 01:49:06|I don't mind hosting on my GPU but having an extension like Copilot that support oss code model out of box would be next big thing. May be a good startup or project India if someone is looking for it.
Nirant|2023-06-15 01:50:04|Soon almost everything will be better than 3.5, partially because people have started to figure out how to game the leaderboard. Kaggle-mindset trickling in.
Nirant|2023-06-15 01:51:34|cc [PHONE] [PHONE]
Dr. Pratik Desai KissanGPT|2023-06-15 01:54:19|We need eval test for eval tests.
Ojasvi Yadav|2023-06-15 02:13:05|Same old story, just in a new dress
Ojasvi Yadav|2023-06-15 02:14:44|Standardization is required to draw a fair comparison between various approaches  But then slowly future approaches start optimising towards that benchmark, instead of the real life
Ojasvi Yadav|2023-06-15 02:15:08|...applications
ashish Acgt01 Twitter|2023-06-15 02:15:41|Just curious , do you work on cancer related applications ?  If yes, would love to talk and exchange notes. I am twitter.com/acgt01
Soumyadeep Mukherjee|2023-06-15 02:37:31|I used to long back on pathology at morphle labs 😅
Nishant Apne-App GenAI Hackathon|2023-06-15 02:43:16|There is a repo for exact use case, someone needs to build a VS code extension around it.  https://github.com/salesforce/CodeTF
Dr. Pratik Desai KissanGPT|2023-06-15 02:46:18|First release was just two weeks ago, a good opportunity for someone to gain quick fame. ‎[6/15/23, 02:50:19] Nishant Apne-App GenAI Hackathon: ‎image omitted
Nishant Apne-App GenAI Hackathon|2023-06-15 02:51:59|But definitely they will improve. and humaneval pass@1 is not a very good evaluation too.
Dr. Pratik Desai KissanGPT|2023-06-15 02:52:29|https://twitter.com/theblokeai/status/1669032287416066063?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw WizardML 57
Abhishek Mishra|2023-06-15 02:52:45|I think there's a WizardLM-Starcoder 15B version today from TheBloke that surpassed GPT3.5
Abhishek Mishra|2023-06-15 02:52:50|Yeah this one.
Abhishek Mishra|2023-06-15 02:53:46|But I've not tried it out myself yet.
Dr. Pratik Desai KissanGPT|2023-06-15 02:55:18|Alex created CoPilot so can be trusted, if he is right $500k/month commitment for Azure GPT4-32K api access 🤯 https://twitter.com/alexgraveley/status/1669091417262817280?s=46&t=HZS4Ar4p8RMA3Tj10LCWEw
Rahul Sundar 2013|2023-06-15 03:15:58|Any LLM benchmarks so far in the context of mathematical reasoning?
Abhishek Mishra|2023-06-15 03:31:30|I want to run ggml alpaca eval for this model and see the difference in benchmark performance.
Aakash Dharmadhikari|2023-06-15 05:41:41|[PHONE], [PHONE] and I were discussing this just a couple of days ago. Wouldn’t that still cost you more than $20/month though? And for a worse experience?
Aakash Dharmadhikari|2023-06-15 05:42:32|Using it against GPT-3.5/4 might be cheaper given you are just paying for the actual usage and I am sure they are dramatically subsidizing the real cost.
Aakash Dharmadhikari|2023-06-15 05:43:51|Have you tried https://github.com/ai-genie/chatgpt-vscode ?
Dr. Pratik Desai KissanGPT|2023-06-15 06:37:55|I have many 3090s at home, If WizardML is beating GPt3.5, it will be better than CoPilot. This setup is to replace the copilot and not GPT4.
~ NG|2023-06-15 07:48:46|https://arxiv.org/pdf/2306.07303.pdf A COMPREHENSIVE SURVEY ON APPLICATIONS OF TRANSFORMERS FOR DEEP LEARNING TASKS
Sandeep Srinivasa RedCarpetup|2023-06-15 08:27:39|https://docs.google.com/document/d/e/2PACX-1vSOgnt4XInS1A6LXM3VZbbcx3ZG-IaRUrBV4Iotnmns0i38IbP5C48mT1eTrmOcxyzUcljIjpFwJaj5/pub  Legal LLM Hackathon ‎[6/15/23, 10:00:53] Abhishek Mishra: ‎image omitted
Kaushik Bokka|2023-06-15 11:36:53|yeah man, it’s pretty wild
Kaushik Bokka|2023-06-15 11:37:45|Accelerators are coming in different shapes and sizes hahaha ‎[6/15/23, 11:38:26] Adithya S K PESIT: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-15 11:38:36|That's a huge discrepancy in salaries in India and US for AI. Decent ones are earning ~1M, I'm sure many in this group will land that if they are here.
Kaushik Bokka|2023-06-15 11:39:28|“Decent ones are earning ~1M”
Kaushik Bokka|2023-06-15 11:40:24|curious. any resources similar to levels.fyi to read more about it?
Dr. Pratik Desai KissanGPT|2023-06-15 11:43:39|I learned from recent tweets that I saw from Emad and some other sources who were struggling to hire.
Dr. Pratik Desai KissanGPT|2023-06-15 12:02:13|Has anyone noticed OpenAI APIs throttled for India? I'm having drastic latency issues for servers in India compared to the US. Even 3.5-turbo.
Sudharshan GenAI|2023-06-15 12:03:32|lol
Abhinav Verma Longshot.ai|2023-06-15 12:13:18|Would need to compare to US or other regions for this. What's your reasoning?
Dr. Pratik Desai KissanGPT|2023-06-15 12:14:51|No reasoning yet, just asking to confirm.
Dr. Pratik Desai KissanGPT|2023-06-15 12:15:35|Yesterday I saw [PHONE] having a similar issue.
Abhinav Verma Longshot.ai|2023-06-15 12:16:00|Not facing such with 3.5. 4 is slow during peak us hours.  Can discuss this in more detail
Alok Bishoyi|2023-06-15 12:30:35|Not making it up, but pretty sure one can absolutely predict when the US east coast is awake coding just from the API latency 😅
Abhinav Verma Longshot.ai|2023-06-15 12:33:12|That's a fact
jyotirmayjk Hackathon|2023-06-15 12:51:56|+1 on this  Typically I’ve seen API performing worse after 4pm IST
Rajesh RS Generative AI WhatsApp Group|2023-06-15 14:00:06|Interesting video featuring Karpathy - discusses GPT training process https://youtu.be/bZQun8Y4L2A
~ Ankur Khandelwal|2023-06-15 14:00:45|or by seeing chatgpt response.
Pranjal Yadav Razorpay|2023-06-15 14:25:45|Stumbled upon Langkit from whylabs, will share my feedback soon.  https://github.com/whylabs/langkit/blob/main/langkit/examples/Intro_to_Langkit.ipynb
Bharat Kumar Ramesh Hashmal Web3|2023-06-15 14:27:11|This is quite interesting
Ankur Pandey|2023-06-15 14:27:15|‎POLL: Hi folks, how often do you use ChatGPT plugins? (choose multiple options if you need to). TiA ‎OPTION: Frequently (5 votes) ‎OPTION: Infrequently / rarely (30 votes) ‎OPTION: Use lots of different plugins (0 votes) ‎OPTION: Use a few select plugins (12 votes) ‎OPTION: Use plugins but exclusively inside ChatGPT (1 vote) ‎OPTION: Use plugins & also corresponding product outside ChatGPT (0 votes) ‎OPTION: Something else (do tell in comments) (0 votes)
Bharat Kumar Ramesh Hashmal Web3|2023-06-15 14:27:16|The overall LLM ops stack
Bharat Kumar Ramesh Hashmal Web3|2023-06-15 14:28:05|Which other tools have you used to monitor, observe, test  LLMs
Bharat Kumar Ramesh Hashmal Web3|2023-06-15 14:29:13|I suspect this will be rarely. Plugins are a poor design primitive.  It should ideally be reversed  The AI should go to the tools. The tools shouldn't come to the AI
~ Mayank Gupta|2023-06-15 14:30:22|Something SamA also mentioned in an interview. Plugins don't have PMF. They went deeper and realised people who were saying they want more functionalities wanted chatGPT inside their tools and not the other way round.
Ankur Pandey|2023-06-15 14:30:50|ChatGPT is an AI and a SaaS. Sam wants to built AGI but also tonnes of tools, apps
Ankur Pandey|2023-06-15 14:31:29|I missed that. Noted.
Bulia Siddharth Aurashop|2023-06-15 14:31:36|Which interview was this? Any link?
Bharat Kumar Ramesh Hashmal Web3|2023-06-15 14:31:58|I think it was in a blog
Pranjal Yadav Razorpay|2023-06-15 14:32:04|I'm still collecting offerings and evaluating what they really do. Arize and Truera promise a few things but I'm  picking this because I have used other solutions from whylabs.
Paras Chopra Wingify|2023-06-15 14:32:34|Has anyone noticed that even with temperature = 0, sometimes responses are non deterministic  Also noticed that when system response changes, output becomes slower vs when it remains the same
~ Mayank Gupta|2023-06-15 14:32:40|Hey seems it was taken down. This is the best that came up sorry - https://matt-rickard.com/chatgpt-plugins-dont-have-pmf
Pranjal Yadav Razorpay|2023-06-15 14:38:28|First part +1, I'm deep diving into how temp parameter interacts with matrices to change the next word probabilities. Topk and topP are just filtering. My hunch was they just pass that to random selector if it's non zero and for zero it picks the top word. But I don't want to believe that.   Also, change of model versions changes the probabilities wrt to words, due to newer data. So even temp=0 in ideal scenario will not generate same output if the base model changes, IMO.  Second part, any way to reproduce? I haven't seen that consistently.
Bulia Siddharth Aurashop|2023-06-15 14:38:35|Got it! Seems like openai took it down.
Bulia Siddharth Aurashop|2023-06-15 14:44:05|Found it - https://web.archive.org/web/20230601023730/https://humanloop.com/blog/openai-plans
Sandeep Srinivasa RedCarpetup|2023-06-15 14:45:35|he said this in person at the IIITD session as well. he touched briefly and then Eleti (openai engg) expanded on this very thing.
Sandeep Srinivasa RedCarpetup|2023-06-15 14:46:15|"he said ""plugins in its current form"". i think thats why they are doing all these functions, etc releases. plugins will come back definitely"
Rajesh RS Generative AI WhatsApp Group|2023-06-15 15:21:04|It generally is non deterministic. I think temperature is a pseudo parameter - like a loose lever you can play with. Not a proper controller for the nature of the output
Abhinav Verma Longshot.ai|2023-06-15 15:21:07|it was in one that was deleted
ashish Acgt01 Twitter|2023-06-15 15:34:37|Has anyone wondered about how OpenAI, $MSFT decide which market & products, OpenAi and Microsoft divide among themselves ?   Do they compete with and as times, cannabalize each other ?  Would be curious to hear folks' thoughts
Pratyush Choudhury|2023-06-15 15:37:12|I can definitely tell you that they both do compete for same customers
Pratyush Choudhury|2023-06-15 15:37:18|Microsoft's winning pitch so far has been Open AI APIs inside customers' VPCs
Ankur Pandey|2023-06-15 15:43:21|From what I know.. MS product roadmap is more head on with Google. With OpenAI they are ok to go for same customers however their marketing team's mandate is that positioning /promoting MS products should not diss or jeopardize openai.
Abhishek Mishra|2023-06-15 16:51:15|True deterministic output using t=0 isn't possible since true t=0 doesn't really happen. ‎[6/15/23, 16:51:36] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-06-15 16:52:23|Notice that t=0 is an approaching limit and can't really be 0. So what you get in implementations in all the libraries is high determinism not true determinism.
ashish Acgt01 Twitter|2023-06-15 16:52:35|https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers  (Via https://news.ycombinator.com/item?id=36333321)
Nirant|2023-06-15 16:54:37|Wait, what — Obsidian has a way to publish notes to web on a custom domain?
ashish Acgt01 Twitter|2023-06-15 16:56:15|I didn't even notice that.  I am guessing you are an obsidian user ? ( Or moved to obsidian recently from some other tool ? )
Alok Bishoyi|2023-06-15 16:56:32|Obsidian Puvlish has that option , yes
Alok Bishoyi|2023-06-15 16:56:50|* publish
Bulia Siddharth Aurashop|2023-06-15 16:59:54|https://twitter.com/levelsio/status/1669269424543793153
Bulia Siddharth Aurashop|2023-06-15 17:00:20|Virtual Cataloging companies making some good money!
Suhas Motwani|2023-06-15 17:12:30|Distribution is the differentiator here
~ Riken Shah|2023-06-15 17:16:26|Danny Postma and Levelsio are both chad and top of their AI SAAS game
Nitin Mahajan McKinsey|2023-06-15 17:16:57|Why do you say that?
Vaibhav Bhargava Meesho Grab |2023-06-15 17:19:31|Pieter levels makes 3M per year as a solo developer, with 300k+ Twitter fillers. His products aren’t necessarily different- it’s just that people buy when they see it’s him.
Nirant|2023-06-15 17:28:07|Does he have 300K follows because he builds cool things?
Vaibhav Bhargava Meesho Grab |2023-06-15 17:28:49|Absolutely
Vaibhav Bhargava Meesho Grab |2023-06-15 17:28:55|And sells it well.
Nitin Mahajan McKinsey|2023-06-15 17:29:01|Curious as to what you found as good or better as photoai.com or headshotpro . Org   Wait did I send some more traffic there :-)
Vaibhav Bhargava Meesho Grab |2023-06-15 17:29:44|What I meant was that it compounds now, and so it’s years of effort that allow him to build stuff that gets traction from day 1 even if not differentiated.
Vaibhav Bhargava Meesho Grab |2023-06-15 17:32:30|I’m a fan and subscriber of both of them. Things get better as they get used and get feedback too. So building that early distribution helps them iterate much faster — postma literally improves his product every 3rd day and he has earned that rich feedback loop too by being so consistent. Please do not mistake me for detractor of the 2 indie legends 🥲
Paras Chopra Wingify|2023-06-15 18:06:06|im not sure if this is the cause, it's like saying true random numbers can't exist what we get is pseudorandom numbers (which is true but a human can't detect that reliably)
Paras Chopra Wingify|2023-06-15 18:06:23|i use it too https://notes.invertedpassion.com/
Abhishek Mishra|2023-06-15 18:09:47|It's a limitation of implementation. Lack of true randomness isn't there because humans can't detect it reliably but because computers use external sources that are deterministic. As long as the initial seed or source remains the same, the same random sequence can always be produced.
Paras Chopra Wingify|2023-06-15 18:10:26|maybe you're right, slight floating point differences can get amplified in a deep network
Abhishek Mishra|2023-06-15 18:12:20|Anyway, given that softmax usage of temperature is the same as the one I shared, how do you think you'll arrive at true value of softmax with t=0? It'll always be a number very close to 0 but never zero. So it'll always be highly deterministic and never true deterministic. ‎[6/15/23, 18:28:33] Sainath GenerativeAI WhatsApp Group: ‎image omitted
Sudharshan GenAI|2023-06-15 18:32:32|What platform is this? Lambda labs?
Sainath GenerativeAI WhatsApp Group|2023-06-15 18:36:42|Seems andromeda cluster. Not sure what it is though.  http://andromedacluster.com/ This is the tweet url https://twitter.com/protosphinx/status/1668843101274664960?s=46
Dr. Pratik Desai KissanGPT|2023-06-15 18:42:10|This is lambda lab page.
~ Srinivasan Nandakumar|2023-06-15 18:48:03|You just remove T from the equation entirely if T is 0? ‎[6/15/23, 19:21:37] Jithin James Ragas: ‎image omitted
Nirant|2023-06-15 19:22:56|autoevaluator.langchain.com/playground
Nirant|2023-06-15 19:23:34|"Peak AI: Calling a grid search with a static front end ""Evaluation Platform""   If it uses hyperopt, we are gonna call it ""AI for Systems"" now??"
ashish Acgt01 Twitter|2023-06-15 19:24:13|When marketing teams go overboard ! :)
Abhinav Verma Longshot.ai|2023-06-15 19:25:36|Marketing is overboard for everything in gen AI to the extent you need to as well because that's what is getting Rewarded by VC ‎[6/15/23, 19:30:10] Nirant: ‎image omitted
~ Subra Subramanyam|2023-06-15 19:30:41|‎~ Subra Subramanyam left
Abhishek Mishra|2023-06-15 19:31:57|looks like a job for jupyter meowbooks
ashish Acgt01 Twitter|2023-06-15 19:32:14|The inspiration we all need :)  On a lighter note, if only more folks were interested in the war against cancer and disease :)
Nirant|2023-06-15 19:32:54|"Winning the meme wars is important, not too long ago — disease and cancer were seen as ""what God ordained"""
Aashay Sachdeva MPL Data Scientist|2023-06-15 19:38:17|This isn’t even the first time. 3rd ai wave since 2014 and same story everytime
Rajesh RS Generative AI WhatsApp Group|2023-06-15 19:48:11|"LOL. We may yet see ""steel man the AI"" on a gen AI pitch deck sometime soon"
Rajesh RS Generative AI WhatsApp Group|2023-06-15 19:48:36|"Also, 10m seed round - reminds me of ""a small loan of a million dollars"""
‪+91 97318 17541‬|2023-06-15 21:09:10|‎You added ‪+91 97318 17541‬
Balaji Vishwanath|2023-06-15 21:09:18|‎You added Balaji Vishwanath
Ajay Rungta Ex-BITS Pilani/Practo Engg Leader|2023-06-15 21:11:42|‎Ajay Rungta Ex-BITS Pilani/Practo Engg Leader joined using your invite
Sudharshan GenAI|2023-06-15 21:13:10|https://www.reddit.com/r/LocalLLaMA/comments/149abrg/creating_a_wiki_for_all_things_local_llm_what_do/  Open source LLMs wiki.
~ Swadeep Pillarisetti|2023-06-15 22:18:02|‎Pranjal Mehta added ~ Swadeep Pillarisetti
‪+91 97489 61402‬|2023-06-15 23:04:48|‎Kaushik Bokka added ‪+91 97489 61402‬
Pranjal Mehta|2023-06-15 23:26:34|https://lab45thinktank.com/genai-accelerator-program/  If you're an AI company selling B2B and looking to expand in the US, you could evaluate this program by Wipro  Learnt about this from [PHONE] Swadeep who is helping Wipro with this program
Aakash Dharmadhikari|2023-06-16 06:31:40|Great intent; most important step here will be introduction to Wipro clients. If it works, pretty fabulous.
Anubhav Dubdub.Ai|2023-06-16 11:36:54|Does anyone has expertise in multinode distributed training using Pytorch? Any help would be highly appreciated
Sudharshan GenAI|2023-06-16 11:39:51|https://llm-utils.org/Nvidia+H100+and+A100+GPUs+-+comparing+available+capacity+at+GPU+cloud+providers  Great article - Nvidia H100 and A100 GPUs - comparing available capacity at GPU cloud providers
Sudharshan GenAI|2023-06-16 11:39:58|Also H100 on lambda labs is 1.99 USD/hr now
Kaushik Bokka|2023-06-16 11:40:01|Just use accelerator or Lightning
Kaushik Bokka|2023-06-16 11:40:06|Accelerate*
Vivek Sahil Sorathiya's Friend|2023-06-16 11:42:24|Google released virtual try-on today. Interestingly has only the upper body cloths as example and lower body is left for future. Any idea why they might have left that? tough to crack?   https://blog.google/products/shopping/virtual-try-on-google-generative-ai/?utm_source=tw&utm_medium=social&utm_campaign=og&utm_content=&utm_term=
Anubhav Dubdub.Ai|2023-06-16 11:46:26|Ok, I will try. Thanks.
Anubhav Dubdub.Ai|2023-06-16 11:46:50|I will bug you again if I face any issues. 🙂
~ Srinivasa Raghavan K M|2023-06-16 12:11:40|‎Ravi Theja added ~ Srinivasa Raghavan K M
~ Nayan Shah|2023-06-16 12:44:18|had a question maybe, a very amateur question , trying to understand why GPU computing power is better than cpu , any good resource on this topic, people have that they can share, i know bandwidth of sharing data in the chip may be a way better in GPU and also the architecture wise there will be difference, but any resource that help u
Abhishek Mishra|2023-06-16 12:48:23|Concise but not precise answer - ML/DL computations are primarily matrix multiplications on ground level and GPUs allow you to perform 1000s these computations parallely. CPUs can parallelise as well but they usually have way less cores that means way lesser parallelism.
Abhishek Mishra|2023-06-16 12:50:17|A more detailed answer would involve explaining how modern architectures are also designed to primarily benefit from GPUs and modern GPUs again are designed to get best performance in AI.
~ Gaurav|2023-06-16 12:50:22|GPUs have SIMD architecture i.e. Single instruction multi data. Which enables them to do parallel processing at scale across thousands of smaller cuda cores (cuda cores are in nvidia GPUs). They are smaller than a typical vCPU found in a normal CPU chip but they are in very large quantity and thus they can process a large amount of data in parallel leading to faster results.
~ Gaurav|2023-06-16 12:53:53|As an example an RTX 3090 GPU has ~ 10,000 cuda cores which is quite a lot.
Dr. Pratik Desai KissanGPT|2023-06-16 13:00:31|For very simple question, you can always ask ChatGPT.
Aashay Sachdeva MPL Data Scientist|2023-06-16 13:01:28|Use the prompt - explain me like I am a 5 year old.
~ Tarun|2023-06-16 13:03:38|a very eli5 way to look at it is a CPU consists of a few very smart workers (cores) that do high quality work extremely fast. a gpu, in comparison, is thousands of not as smart workers, but can now consume larger workloads and operate in parallel. its a quantity over quality thing
~ Tarun|2023-06-16 13:07:15|adding to that, due to the recent surge in gpu usage for ML training, it has also been highly optimized for instructions specific to the ML context, at both the hw and sw levels
~ KJ|2023-06-16 13:08:57|this simple video explains at a high level: https://www.youtube.com/watch?v=-P28LKWTzrI
~ Aman Shenoy|2023-06-16 13:10:05|‎Ravi Theja added ~ Aman Shenoy
Pranjal Yadav Razorpay|2023-06-16 13:25:04|Anyone from this group present at AWS dev day bangalore? Happy to catch up.
ashish Acgt01 Twitter|2023-06-16 18:38:28|folks interested in biomedical, drug discovery applications of ml, might enjoy this interview : https://www.youtube.com/watch?v=inN2MX0fE5g
Kaushik Bokka|2023-06-16 20:02:38|Surprised that you can’t create an enterprise account on Stability AI
Ambuj Kashyap|2023-06-16 20:39:54|‎You removed Ambuj Kashyap
Sudharshan GenAI|2023-06-16 21:10:19|Ping hardmaru they’ll implement in the next 1 week
Pranjal Mehta|2023-06-16 21:24:51|Alot of people don't know this but Wipro is StabilityAI's distribution partner
Pranjal Mehta|2023-06-16 21:26:47|Link is - Eros (yes the Bollywood powerhouse) Investments. They are an investor in StabilityAI
Pranjal Mehta|2023-06-16 21:27:02|And then https://m.economictimes.com/tech/information-tech/wipro-eros-investments-partner-to-scale-ai-based-solutions-to-global-media-industry/amp_articleshow/92257817.cms
Abhinav Verma Longshot.ai|2023-06-16 23:19:54|What does distribution partner here mean?
Sudharshan GenAI|2023-06-16 23:25:30|Wow
Sudharshan GenAI|2023-06-16 23:25:31|This is interesting
Pranjal Mehta|2023-06-16 23:45:06|I don't fully understand it myself but my guess is: 1. Access to Wipro customers 2. Implementation through Wipro because StabilityAi doesn't have a services arm
Anubhav mishra Zupay|2023-06-16 23:49:21|[PHONE] do they have their own Model ?  For speech to text , text to speech ?
Pranjal Mehta|2023-06-16 23:58:55|You can find Stability's models on their website. I don't think Eros or Wipro have their own models
Anubhav mishra Zupay|2023-06-16 23:59:25|Hmm got it
Anubhav mishra Zupay|2023-06-17 00:02:50|https://www.linkedin.com/posts/metaai_introducing-voicebox-a-new-breakthrough-activity-7075533881214451712--W4g?utm_source=share&utm_medium=member_android
Anubhav mishra Zupay|2023-06-17 00:03:06|Meta AI is literally next level I think
Dr. Pratik Desai KissanGPT|2023-06-17 00:07:43|In a week that have MusicGen and now this. Zuck is also talking about making llama2 commercial.
Abhishek Mishra|2023-06-17 00:08:58|Actually waiting for llama v2 eagerly.
ashish Acgt01 Twitter|2023-06-17 00:10:38|Very exciting !  My worry is that audio deepfakes are going to get easier to generate for all users including malicious ones
Anubhav mishra Zupay|2023-06-17 00:12:00|I think they'll have supplementary detection models too. Meta AI as far as I know is very ethical and safeguarded
Anubhav mishra Zupay|2023-06-17 00:12:02|That's what I hope :)
Dr. Pratik Desai KissanGPT|2023-06-17 00:14:11|Then there will opportunity for new startups to detect deep fakes.
Abhishek Mishra|2023-06-17 00:15:03|Detection is always a one order higher difficulty problem than generation. We really didn't have a very high neural voice generation until few months back. But now it's hard to detect whether the speaker is human or not especially over a call.
Dr. Pratik Desai KissanGPT|2023-06-17 00:15:35|Everything we are seeing looked impossible 6-8 months back.
Abhishek Mishra|2023-06-17 00:16:05|Yes, it's like a fold in time. Everything got pulled in.
Abhinav Verma Longshot.ai|2023-06-17 00:16:18|The new mission impossible film is going to look so realistic
Dr. Pratik Desai KissanGPT|2023-06-17 00:18:10|A year back when Netflix had that interactive movie/shows people were impressed, it will possible soon to replace everything Tom Cruz says with my voice. 😂
Abhinav Verma Longshot.ai|2023-06-17 00:19:27|Mission impossible had vision pro 20 years ago. 😂
Anubhav mishra Zupay|2023-06-17 00:32:14|Bander snatch , was a cool concept
~ Vibbs Dod|2023-06-17 01:17:36|I am not sure how to put this message across, there is a huge inferiority complex associated to this. But here I go.   Is there a possibility to try to do the AI/ML Computation leveraging the crypto world.  Where people are rewarded with a  crypto token when they contribute to  the  computation output.  Since the actual prices are soaring would this even be actually viable?  I am not sure.  But thinking of a MLCoin  where people are paid for their compute.  This way the computation are reasonable in some form and will usher a way to combined new world of tech possibilities.  Thank you. For letting me rant about the idea that I had.
~ Vibbs Dod|2023-06-17 01:18:33|Late night, sleep deprived rant.. 😔
~ Prajna Prayas|2023-06-17 01:20:51|Can't people just be paid real cash for computation instead of a cryptocurrency?
~ mihir_parulekar|2023-06-17 01:22:50|Hey guys has anyone experimented with code chunking strategies, I want to create a vector store of cpp files
~ Vibbs Dod|2023-06-17 01:29:10|True, but this  might act as a incentive for those who don't understand the importance of the actual hash calculations but will be rewarded for the compute.
~ Prajna Prayas|2023-06-17 01:31:52|as far as I understand if I am renting my compute for hash calculations or any other computation, I would mostly prefer to be paid in a currency which is least volatile.
~ Gaurav|2023-06-17 01:36:01|Hey we are doing this already at Q Blocks 👋
Rahul Rai|2023-06-17 01:53:26|Please dm me, would love to chat
Abhishek Mishra|2023-06-17 02:17:12|Yeah, there are 2 approaches that I'm aware of and experimenting with whatever limited time I've  * Hierarchical summarisation of code - Recursive Chunking  to build hierarchical, iterative chunked docs * Content aware chunking
Abhishek Mishra|2023-06-17 02:18:00|Since you mention cpp files specifically, are you looking for a cpp specialised chunking strategy?
Dhruv Anand|2023-06-17 02:24:42|something weird going on with langchain py docs, but here's a link to the code chunking utils in langchain js: https://js.langchain.com/docs/modules/indexes/text_splitters/examples/code#:~:text=/*%0A%20%20%5B%0A%20%20%20%20%27-,cpp,-%27%2C%20%20%20%20%20%20%27go%27%2C%0A%20%20%20%20%27java
Dhruv Anand|2023-06-17 02:29:44|https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter
~ mihir_parulekar|2023-06-17 02:29:59|Yeah I think chnuking strategy do need to be lang specific. Also, does ada-002 beats all guidance holds true for code retrieval as well.
Abhishek Mishra|2023-06-17 02:41:45|In my experience most people seem to do well or not bother in detail about which chunking strategies they are using for code. Maybe you've tried out the python langchain code splitters for cpp? Have you noticed any issues with that?
Rahul Sundar 2013|2023-06-17 03:05:59|https://arxiv.org/abs/2306.08997
~ mihir_parulekar|2023-06-17 03:22:24|Have not experimented much, I am trying to create an agent and creating a tool for that agent to retrieve relevant code. Will definitely use the long-chain cpp implementation and share my findings.
Brij Singh Rebright Partners|2023-06-17 05:34:27|This is true, I had a call with Meta's Public Policy team yesterday to potentially have them join as partners for the OSS Fellowship Fund.   We also had a detailed Q&A on potential concerns from the Developer community on the llama models, licensing, IP ownership on training, data security etc.  If people have questions for Meta's AI Team, please share here and I can collate to present to them
~ Vinay|2023-06-17 06:01:04|‎You added ~ Vinay
~ Sourabh Nolkha|2023-06-17 07:28:51|Hi all, I am new to this group and looking for someone who is working on stable diffusion.  Please connect. Thank you.
Nirant|2023-06-17 07:34:05|"PSA:   General good practice for open forums like this: Ask the question with context >>> Asking the question >> Asking if someone has used X > Asking ""Can I ask questions about X?"""
Nirant|2023-06-17 07:55:34|"Goldberg having a field day with GPT4 evaluation ""hacks""   https://twitter.com/yoavgo/status/1669760558436872193"
ashish Acgt01 Twitter|2023-06-17 08:06:54|"I love his sense of humour. From his homepage : ""Jan. 6, 2011, at around 17:34, a girl stepped into my office and offered me to participate in the next season of the Israeli version of Beauty and the Geek. Being dedicated to my academic career, beard and wife, I kindly refused.""  We could all use more humour in our lives :)"
Bharat Kumar Ramesh Hashmal Web3|2023-06-17 08:16:32|"Haha. Reminds me of that incredible foreword in another textbook  “To my wife Marganit and my children Ella Rose and Daniel Adam without whom this book would have been completed two years earlier"""
jyotirmayjk Hackathon|2023-06-17 08:19:18|Isnt this the same paper where everyone is being amazed about the “expert prompting “ strategy ?   From what I’ve understood,there are some MCQs GPT-4 is asked to provide answered to the MCQs and self critique until the eval is stopped ?  It’s just like I’m given 4 guesses to find an answer for MCQ with 4 option🤷🏻‍♂️
Ambuj Kashyap|2023-06-17 09:28:59|‎You added Ambuj Kashyap
~ Sourabh Nolkha|2023-06-17 09:43:30|Context: I am not from a technical background, learning from Google University of Search (🙈) and looking for a mentor / guide.
Chaitanya Mehta Goodera Turtlemint|2023-06-17 09:50:20|https://lu.ma/genAI-mumbai-june  Who here is going to show-up to this generative AI meet-up in Mumbai today?
~ Kp|2023-06-17 09:56:31|Does anyone have access to code interpreter in chatgpt? If so can I please get an overview of it's usefulness? AI influencers are going Gung ho over it that it will eat developer jobs, just wanted to know what's the reality.
ashish Acgt01 Twitter|2023-06-17 10:01:37|[PHONE] are you aware of any meetups , hackathons in delhi ?
Nirant|2023-06-17 10:01:39|Not very off. Code Interpreter is better than GPT4 at long context code understanding, being able to tell objects and dictionaries apart in Python, getting what a happy path convention is and similar clever things.  The REPL for data analytics is also quite nifty and faster than writing code on my own. E.g. the Users to be removed list for this group was made with CodeInterpreter: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit#gid=0
Nirant|2023-06-17 10:02:32|I hear a certain AI CEO was there recently. Some great audience questions.   Don't you think Delhi has embarrassed itself for the entirety of summer? 🤣
ashish Acgt01 Twitter|2023-06-17 10:02:54|Don't you diss my hometown :)
~ Kp|2023-06-17 10:04:10|Any idea when this will release for regular chatgpt plus users as they had talked about this in march (it seems to be in the chat.openai.com app). Also is there an equivalent in the API?
~ Kp|2023-06-17 10:04:55|And finally is this for gpt 4 only or does gpt 3.5 also have this functionality?
Nirant|2023-06-17 10:06:32|No Code Interpreter API. GPT4 only.
~ Kp|2023-06-17 10:08:29|Thanks a lot!
Shan|2023-06-17 10:24:43|I’m desperately waiting for it too. Despite being a paying user (gpt plus) ‎[6/17/23, 10:30:37] Anshul Bhide Replit: ‎image omitted ‎[6/17/23, 10:30:38] Anshul Bhide Replit: ‎image omitted ‎[6/17/23, 10:30:46] Anshul Bhide Replit: ‎image omitted
~ Kp|2023-06-17 10:32:36|"I don't think that's indicative of much except the High population of 18-25 year Olds in India who are studying in schools and colleges and have the best ""academic"" use of chatgpt"
~ Kp|2023-06-17 10:32:45|If you get what I mean🤭
Anshul Bhide Replit|2023-06-17 10:33:29|Lol yes fair point
~ Kp|2023-06-17 10:34:10|If there are statistics on chatgpt+ that would be more indicative as openai has not adjusted pricing for PPP
~ Kp|2023-06-17 10:34:32|Oh these are search statistics
Abhishek Mishra|2023-06-17 10:34:45|A permissively licensed implementation of llama's technical paper - OpenLlama finished training it's 13B model on 1T tokens and has released it. It's performance is on AVG the same as llama 13B.
Abhishek Mishra|2023-06-17 10:34:54|https://github.com/openlm-research/open_llama
Paras Chopra Wingify|2023-06-17 10:40:23|LocalLLama subReddit is quite active https://www.reddit.com/r/LocalLLaMA/comments/147lmku/which_best_uncensored_freespeech_llm_models/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
Abhishek Mishra|2023-06-17 10:44:37|It's one of my primary hangout spots recently.
Pratik Bhavasar|2023-06-17 11:15:25|Enjoyed the first episode on generative AI in Black mirror’s new season
Puneet Lamba Aspiro|2023-06-17 11:20:49|Yeah, the one names “Joan is awful”, right?
Puneet Lamba Aspiro|2023-06-17 11:22:11|*named
Paras Chopra Wingify|2023-06-17 11:25:53|Aw, spolier
Paras Chopra Wingify|2023-06-17 11:25:58|I have seen it
Nirant|2023-06-17 11:31:17|How can it be a spoiler? It's a documentary iykwim ‎[6/17/23, 11:31:28] ~ Ashutosh Kumar: ‎image omitted
ashish Acgt01 Twitter|2023-06-17 11:37:25|We are living through it ! #cleverjokesftw
Ambika Computational Mama|2023-06-17 11:38:18|any pro tips for video input in SD animations? runwayML is known, other options please! :)
ashish Acgt01 Twitter|2023-06-17 11:41:17|interesting graph !  my wager : nft & crypto were a flash in the pan, maybe crypto & blockchain were a little ahead of its time;  gen ai on the other hand, is, excuse the hyperbole, revolutionary in the way it will impact all facets of society as we know it -so is going to see a sustained interest over time  my 5 year prediction is : UBI(Universal Basic Income) will gain some serious traction as a lot of jobs will get automated away thanks to ai & robotics, especially in the us & europe
Nirant|2023-06-17 11:42:38|UBI discussions are perhaps best suited for the Policy & Philosophy fork?  https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Abhinav Verma Longshot.ai|2023-06-17 11:43:06|Now spatial computing will be the most searched term soon
Abhishek Maiti|2023-06-17 11:50:18|Few others in my to-try list: https://github.com/Scholar01/sd-webui-mov2mov, https://huggingface.co/spaces/fffiloni/ControlNet-Video
Gokul Krishnan|2023-06-17 11:54:37|We can move this to the policy group but automation has been around and expanding for a while. Gen AI doesn't really have a strong usecase in industrial automation afaik
ashish Acgt01 Twitter|2023-06-17 11:56:27|in the biotech, life sci space, lab automation has been picking up speed, in the US & Europe, even a little bit in India. Happy to chat more in the policy, philosophy wa group
Gokul Krishnan|2023-06-17 11:59:08|That's not my contention, my contention is that gen AI isn't accelerating industrial automation
ashish Acgt01 Twitter|2023-06-17 12:05:20|I would, largely, agree with that. although who knows what's brewing in boston dynamics & similar research labs
Aashay Sachdeva MPL Data Scientist|2023-06-17 12:08:34|Not true! The work is now towards robotics foundational model -  https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html?m=1
Gokul Krishnan|2023-06-17 12:09:57|Can't find the lecture right now but iirc Boston dynamics doesn't even use ML and depends heavily on classical control systems algos.
ashish Acgt01 Twitter|2023-06-17 12:12:23|thanks for sending this link. I was just reading about this yesterday.  Keerthana's twitter tracks this space quite well https://twitter.com/keerthanpg
Pratyush Choudhury|2023-06-17 12:13:24|https://github.com/AntonOsika/gpt-engineer  Has anyone tried this one yet?
Gokul Krishnan|2023-06-17 12:14:58|Yeah, I'm not holding my breath on Google shipping this to a factory near you
Anubhav mishra Zupay|2023-06-17 12:16:22|My take.   When MAANG is fighting to win the battle it's a serious thing going on.  It's literally MAANG at war in sillicon valley. Have never seen either Google or Mera resleea stuff so quickly 😂  No comments on NFT and crypto and coin culture. Even if the tech is good people like SBF and others have just brought it back to zero on the trust scale .
Sidhant Sequoia|2023-06-17 12:51:11|https://www.linkedin.com/posts/1rohitagarwal_portkeyai-on-twitter-activity-7075700450926206976-DLVy?utm_source=share&utm_medium=member_ios  Very cool, [PHONE]
Sidhant Sequoia|2023-06-17 12:52:47|Ability to cache semantically similar prompts seems novel
Rohit Aggarwal|2023-06-17 12:56:02|Spent a lot of time tweaking stuff - works very well now for RAG use cases
Kaushik Bokka|2023-06-17 12:58:31|Great job, Rohit! Keep slaying ‎[6/17/23, 13:23:31] Sandeep Srinivasa RedCarpetup: ‎image omitted
~ Abhilash K Pai|2023-06-17 13:28:16|https://youtu.be/DUUTHkQrYy0
~ Abhilash K Pai|2023-06-17 13:30:25|Tricking chatGPT to do piracy
Abhinav Verma Longshot.ai|2023-06-17 13:31:34|Do they work?
~ Sahir Patel|2023-06-17 13:35:38|"What is the correct approach for implementing GPT with analytic reports . eg of data I’m working with-  | Content | Score | Date | |---------|-------|------| | x       | y     | z    |   I tried using embeddings and it gave me correct responses for prompts like - “what’s the score of x content” or “give me content between this date”  but when I ask “give the top scored content for this date” , it fails . Someone in this forum had suggested using text2SQL with langchain instead of embeddings . Which is fine for querying ..  but my end goal is to ask queries like “generate new content similar to top scoring data from this abc date” and text2SQL might not be suitable for this type of request.  any insights or suggestions?"
Sandeep Srinivasa RedCarpetup|2023-06-17 13:40:39|im interested in the same. if anyone has prompts, that would be super useful
~ Vinay|2023-06-17 13:53:20|you want a way to generate new content based on a ranked/filtered content piece, did I understand it correctly?
~ Sahir Patel|2023-06-17 13:56:41|yep .
~ Sahir Patel|2023-06-17 13:58:07|i was thinking a 2 step query , one to sql to sort . other to pass it to llm to refer and create
~ Vinay|2023-06-17 13:58:55|that's what i can think of too.
~ Vinay|2023-06-17 13:59:52|in creation step, are you planning to add some more context? around the lines of central themes/main points of the actual content.
~ Sahir Patel|2023-06-17 14:01:43|yes creation involves - similar central themes + a web browsing agent if content requires the latest context  . ‎[6/17/23, 16:52:53] Ankur Pandey: ‎image omitted
Lalit Pagaria|2023-06-17 16:54:39|Hopefully Abhinav is not revealing Longshot secret sauce 🙂
ashish Acgt01 Twitter|2023-06-17 16:55:41|The award for the nerdiest, funniest prompt goes to .....
Ambika Computational Mama|2023-06-17 16:57:16|I can't imagine why we work so hard as a community of AI practitioners and end up making this 🤣
~ Kp|2023-06-17 16:58:15|Probably some sort of pseudo random generation. But the bypass is clever
Ritwik 2013|2023-06-17 17:28:32|Hey guys one quick question: does anyone here have experience hosting python web apps on Replit? Want to understand how well dk they scale and what are the trade offs in terms of performance etc or hosting your api backends on platforms like Replit  Any other alternatives which are easy to setup with good perf feedback?
Nirant|2023-06-17 17:33:48|Cc [PHONE] can help perhaps?
Dhawal Jain Generative AI Group|2023-06-17 17:55:25|Hey my friend is working on a side project, here’s the intro incase somebody wants to get in touch. :)  Hey, I'm Nehal (+44 7405377827), from IISc, currently in London. I'm hunting for a self-managed software dev to help out with a project (in LLM - autoagents - modular system ). Hit me up for more details.
~ Manasi|2023-06-17 18:28:10|‎~ Manasi joined using this group's invite link ‎[6/17/23, 20:04:54] Dhruv Anand: ‎image omitted
Ved Chitnis|2023-06-17 20:05:35|Any such discussions/talks in Bangalore anytime soon folks? Would love to catch up!
Sourasis Roy|2023-06-17 20:07:03|Yupp. Learnt a lot
Ved Chitnis|2023-06-17 20:07:13|https://www.reddit.com/r/ChatGPT/comments/14agito/meta_will_make_their_next_llm_free_for_commercial/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=3&utm_content=share_button  Since this was discussed recently
Abhinav Verma Longshot.ai|2023-06-17 20:09:40|It was a very detailed talk by soumendra on the details of Lora.
Ritwik 2013|2023-06-17 20:15:21|Nice, where was this
Adithya L Bhat Hackathon|2023-06-17 20:28:33|Anybody into biomedical informatics?? Looking to talk and know more about it .
Lalit Pagaria|2023-06-17 20:40:26|Mumbai generative AI meetup
Gokul Krishnan|2023-06-17 20:51:41|Recording or slides please
Lalit Pagaria|2023-06-17 20:52:46|Yeah will share once we get videos from our photography partner
Soumyadeep Mukherjee|2023-06-17 21:12:07|Happens every month. Next Sat likely next one.
Sidhant Sequoia|2023-06-17 21:13:16|Do share deets
Soumyadeep Mukherjee|2023-06-17 21:13:41|In progress 😅
Soumyadeep Mukherjee|2023-06-17 21:13:46|Will share by Monday.
~ Rachitt|2023-06-17 21:14:40|folks, any reading materials or pointers to start learning about the RAG stack?
Aashay Sachdeva MPL Data Scientist|2023-06-17 21:18:09|RAG video on youtube by the researcher itself
Ankur Pandey|2023-06-17 21:22:31|Totally. Looking fwd to the ebook
Abhinav Verma Longshot.ai|2023-06-17 21:57:23|Is that an official name now? RAG stack
~ Nikhil|2023-06-17 22:08:46|Has anybody used 2markdown.com here?  I am building something that requires parsing html content and then embedding it.  I am currently using BSHTML Loader + RecursiveCharacterSplitter combination. However, I feel that the get_text method does not do justice to breaking down the document content into proper sections.  I am thinking of experimenting 2markdown loader + markdown splitter instead. If anybody has used this combination, would love to listen to your experience.
~ Rachitt|2023-06-17 22:13:50|going by what's being used 😅
Gokul Krishnan|2023-06-17 22:48:46|Uhh, what's RAG? 😅
Sandeep Srinivasa RedCarpetup|2023-06-17 22:49:23|retriever augmented generation
Sandeep Srinivasa RedCarpetup|2023-06-17 22:49:24|retriever == vector database
Abhinav Verma Longshot.ai|2023-06-17 22:51:11|Retriever I would expand is all the steps to filter out relevant data to send to your LLM model for generation. Includes vector db and other things ‎[6/17/23, 22:55:01] Abhinav Verma Longshot.ai: ‎image omitted
Abhinav Verma Longshot.ai|2023-06-17 22:57:16|so since you never divide by 0, there's always a chance of a slight variation happening even though its very small
~ Aman Rai|2023-06-18 00:48:17|‎Aditya Jain Comedian removed ~ Aman Rai
‪+91 76077 14483‬|2023-06-18 00:48:34|‎Aditya Jain Comedian removed ‪+91 76077 14483‬
‪+91 95290 47929‬|2023-06-18 00:49:13|‎Aditya Jain Comedian removed ‪+91 95290 47929‬
‪+91 96194 01031‬|2023-06-18 00:49:37|‎Aditya Jain Comedian removed ‪+91 96194 01031‬
‪+91 97172 74996‬|2023-06-18 00:49:59|‎Aditya Jain Comedian removed ‪+91 97172 74996‬
‪+91 98204 09045‬|2023-06-18 00:50:23|‎Aditya Jain Comedian removed ‪+91 98204 09045‬
‪+91 98882 38811‬|2023-06-18 00:50:52|‎Aditya Jain Comedian removed ‪+91 98882 38811‬
~ Mahalakshmi C|2023-06-18 00:51:06|‎Aditya Jain Comedian removed ~ Mahalakshmi C
‪+91 98806 60620‬|2023-06-18 00:52:18|‎Aditya Jain Comedian removed ‪+91 98806 60620‬
‪+91 89709 02000‬|2023-06-18 00:52:57|‎Aditya Jain Comedian removed ‪+91 89709 02000‬
‪+91 82105 79249‬|2023-06-18 00:53:38|‎Aditya Jain Comedian removed ‪+91 82105 79249‬
‪+91 83749 99651‬|2023-06-18 00:54:00|‎Aditya Jain Comedian removed ‪+91 83749 99651‬
‪+91 91 674 694 70‬|2023-06-18 00:54:40|‎Aditya Jain Comedian removed ‪+91 91 674 694 70‬
Vedant Trivedi Sequoia|2023-06-18 01:30:05|Q - What is the more holistic evaluation metric as of now (from developing apps point of view) and is designing a holistic evaluation metric even a possible goal to chase? More tactically, are we even converging towards it?   https://twitter.com/ben_golub/status/1670105313406582784?s=48
Abhishek Mishra|2023-06-18 03:25:15|"Some questions have exact answers. This one doesn't - How can we design a perfect evaluation criteria for LLMs? We probably would grow towards that evaluation criteria or make-do with crowd evals for some time.  However, some questions are easy to answer. Like, what shouldn't be a standard for eval or how one shouldn't approach eval in the long term. This MIT EECS 100% performance paper just did all of those ""don'ts"". I'll save you from my rant. ‎[6/18/23, 07:51:49] Dev Aggarwal: ‎image omitted"
Prayank Swaroop Accel|2023-06-18 07:54:50|Request for speaker - I'm trying to organize a community AI webinar on Thursday. Have requested Nirant to talk about GPT Functions. Need a second speaker to get into a more conceptual topic with learnings from production.   Thursday 5-7pm, online  Anyone interested to be a speaker, please DM me.
Anshuman Pandey|2023-06-18 08:03:20|This was pre foundational models era, a company in Estonia was doing it. Ended up pivoting to predict deep fakes in the NFT space. Then raised $25M. I think it's called the NFT port. Take a look at it
Rounak Datta Hackathon Winner|2023-06-18 10:43:04|I love the soft poem to calm the engineer busy debugging
ashish Acgt01 Twitter|2023-06-18 11:07:22|"""Growing up in Hyderabad, India, I'd dreamt about being able to read Persian poetry—in particular the work of Rumi, which has been translated into Urdu and then into English. GPT-4 did it, in one shot. It was not just a machine translation, but something that preserved the sovereignty of poetry across two language boundaries. And that's pretty cool.""  https://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/"
ashish Acgt01 Twitter|2023-06-18 11:10:11|"Another quote that really resonated with me :  ""Wired q : OpenAI CEO Sam Altman believes that this will indeed happen. Do you agree with him that we're going to hit that AGI superintelligence benchmark?  SN answer : I'm much more focused on the benefits to all of us. I am haunted by the fact that the industrial revolution didn't touch the parts of the world where I grew up until much later. So I am looking for the thing that may be even bigger than the industrial revolution, and really doing what the industrial revolution did for the West, for everyone in the world. So I'm not at all worried about AGI showing up, or showing up fast. Great, right? That means 8 billion people have abundance. That's a fantastic world to live in."""
Nirant|2023-06-18 11:22:35|the road to hell is paved with good intentions
Sidhant Sequoia|2023-06-18 11:23:05|So is the road to heaven
Sidhant Sequoia|2023-06-18 11:23:11|You never know where it forks ;)
Nirant|2023-06-18 11:24:26|no good deed ever goes unpunished
Nirant|2023-06-18 11:24:37|(Let's fork to Philosophy on this one)
ashish Acgt01 Twitter|2023-06-18 11:25:14|Why you got to shine a realistic light on my utopian dreams, Nirant ? :)  p.s. interesting aside : I discovered it on the feed of a pharma vp, who quoted this line in the context of ai drug discovery :   “it's not about who has capability, it's about who can actually exercise that capability and translate it into tangible products.”
Abhinav Verma Longshot.ai|2023-06-18 11:29:26|It was in beta mode for a while now. Only issue was it worked sometimes only, because they would give the message unable to connect with gpt
Sandeep Srinivasa RedCarpetup|2023-06-18 11:32:05|interestingly, nothing in production is using opensource models. pretty much GPT is a monopoly.
Aashay Sachdeva MPL Data Scientist|2023-06-18 11:32:32|Has anyone figured out if there is a way to get insights from tabular data through gpt-4? I know there is pandas gpt, but looking for papers,tecnhiques etc
Nirant|2023-06-18 11:32:37|nothing in open source even comes close to even GPT3.5-Turbo on absolutely any task which you'd want to put in production
Nirant|2023-06-18 11:32:55|Code Interpreter ftw
Diptanu Choudhury FB AI|2023-06-18 11:40:11|Do you mean retrieval of structured data?
Diptanu Choudhury FB AI|2023-06-18 11:41:21|Connecting models to work with structured data is a pretty active area of work at the moment.
Abhinav Verma Longshot.ai|2023-06-18 11:45:46|there isn't a secret sauce to get insights on tabular data. Think of it as a chunking problem and each row is a chunk. Look up the code of yolo-pandas and the prompts they are using, that should be able to give you an insight of how they are doing.
Abhinav Verma Longshot.ai|2023-06-18 11:49:12|yup. only model that is close on some tasks are more closed models such as claude, in some cases cohere and some cases nlp-cloud's own finetuned models
Abhinav Verma Longshot.ai|2023-06-18 11:50:07|I would say, use techniques of RAG and you can apply them here on tabular data.
Sandeep Srinivasa RedCarpetup|2023-06-18 11:53:32|this is interesting. so u chunk a whole row - with column labels i presume ?
Aashay Sachdeva MPL Data Scientist|2023-06-18 11:55:10|If each row is a chunk then global context of the data is lost right?
Abhinav Verma Longshot.ai|2023-06-18 11:55:27|yes, that is a strategy that has worked when we've tried.
Abhinav Verma Longshot.ai|2023-06-18 11:55:39|Can you elaborate on this?
Aashay Sachdeva MPL Data Scientist|2023-06-18 11:56:17|If I am chunking on row+ column names, and if I ask it a question what does the trend looks like, how will it answer that?
ashish Acgt01 Twitter|2023-06-18 11:57:15|The original q. prompted this gen ai which can do data science wishlist flow   1. Inputting my data ( a large CSV say 1GB or other tabular data), larger than current prompt window  Either through uploading to an LLM cloud service( which ensures isolation and guarantees that the data would remain private)  Or  Connectors for Google drive, AWS S3, etc where I opt in to give the LLM provider access to my data files  2. I can then ask natutal language, data science queries , of the data I uploaded/ connected to the LLM provider  - generate jupyter notebook code to generate scatter plot,  Churn of customers, most valuable new customer, etc  - most sold item in March 2023 along with a graph of most sold items by month in the last FY - show me all the possible analysis on my sales numbers in the last month   Does ChatGPT or other solutions exist to doing GPT data science , EDA( exploratory data analysis) today ?  Any papers or articles on this theme ? ‎<This message was edited>
Aashay Sachdeva MPL Data Scientist|2023-06-18 11:58:59|I don’t have access, and is that available through api?
Nirant|2023-06-18 11:59:32|GPT Plus users seem to have it by default. No API.
Abhinav Verma Longshot.ai|2023-06-18 11:59:57|see you have to work on constraints anyways which is your context length you can pass to openai. However for your particular case, there are ways in which libraries have done this thing. Which is yo translate your question to pandas function code execute it and give an answer. Which is why I recommend looking at yolo-pandas lib. Its open source , on github and is actually pretty good at this
Abhinav Verma Longshot.ai|2023-06-18 12:00:43|I don't have it. I don't know what's the deal with this by OpenAI. they haven't opened to all plus customers
Abhinav Verma Longshot.ai|2023-06-18 12:01:06|I have access to all plugins minus code interpreter
Aashay Sachdeva MPL Data Scientist|2023-06-18 12:01:26|I dont🤨🤨
Aashay Sachdeva MPL Data Scientist|2023-06-18 12:01:55|Got it. Thanks
Rounak Datta Hackathon Winner|2023-06-18 12:04:07|I wonder how manual/AI-driven OpenAI's whitelist system is. Could they be applying GPT-4 to our chat histories to understand who the right customer is to reveal early features :p ‎<This message was edited>
Nirant|2023-06-18 12:04:49|Much like God, OpenAI works in mysterious ways
Abhinav Verma Longshot.ai|2023-06-18 12:05:59|its manual, influencers get early features. regarding access, I think its heavily based on access history. We got openai gpt-4 access in a day, when it became public, companies like jasper through  connections etc had access a little earler, which goes in line with their access history.
Aashay Sachdeva MPL Data Scientist|2023-06-18 12:07:02|I have a conspiracy theory - openai’s token generation latency is random to make us believe the model is thinking
Abhinav Verma Longshot.ai|2023-06-18 12:07:50|I have another. someone is manually typing your answers on chatgpt 😜
jyotirmayjk Hackathon|2023-06-18 12:26:26|Can this strategy work if you don’t have Code Interpreter access ?  -Describe the table and fields in a prompt to GPT-3.5 -Ground it using system prompt for data analysis -Then ask it to generate python code on the file to answer user questions -Ex.Based on {table} described answer the {user_query} by generating Python code for data analysis  Chain this LLM process output with a Python agent and it will execute it too and give you answers
~ Prajna Prayas|2023-06-18 12:26:26|Second this. In fact when I took the plus subscription it was jarring to the eyes seeing the 3.5 version too fast.
ashish Acgt01 Twitter|2023-06-18 14:15:51|Open source Multimodal LLM from Tencent  https://huggingface.co/papers/2306.09093 https://github.com/lyuchenyang/Macaw-LLM
~ Sahir Patel|2023-06-18 14:36:48|"update on this -  using SqlDatabaseChain , and step wise prompt . the response is pretty decent -  sharing the prompt  -  'Step 1: Identify the top 5 posts with the highest overall engagement (likes + comments + shares).\n' + 'Step 2: Analyze these posts and determine the common theme that could have contributed to their high engagement.\n' + 'Step 3: Based on the identified theme, generate a new content for a post.\n' + ""Please provide the information in a structured manner, with each step's outcome clearly stated."","
Dhruv Anand|2023-06-18 14:39:45|https://twitter.com/EdenEmarco177/status/1670064627269484545?t=VxZkvzI7oQ0xbUxcB25uTQ&s=08  A nice thread on chunking strategies, something we often discuss here
Shan|2023-06-18 16:11:58|No 😞
~ Kp|2023-06-18 16:12:40|Not default
~ Kp|2023-06-18 16:12:42|I don't :(
Sriram Covid19 Endcoronavirus|2023-06-18 16:48:07|‎‎Sriram Covid19 Endcoronavirus changed their phone number to a new number. ‎Tap to message or add the new number.
Utkarsh Ohm Thoughtspot|2023-06-18 18:49:17|Go to settings and turn on beta features, if you haven’t. Then you should see it. Also do this on web, you don’t see this setting on mobile app.
Abhinav Verma Longshot.ai|2023-06-18 18:50:01|have done it. its an alpha feature. not there for everyone
~ Mayank Gupta|2023-06-18 18:50:59|Yeah not available for me either. It isn't rolled out for everyone as yet it seems
Vivek Raghavan|2023-06-18 19:58:09|‎You added Vivek Raghavan
ashish Acgt01 Twitter|2023-06-19 07:17:24|"Stumbled on a cool project danswer (built using qdrant)  https://github.com/danswer-ai/danswer  ""Danswer allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others."""
~ Rachitt|2023-06-19 08:55:39|Any cost estimators for compute needed to fine-tune OSS models? Worried about the hole in my wallet due to compute😅
Lalit Pagaria|2023-06-19 08:58:15|https://github.com/alibaba/Chat2DB  Alibaba released this DB client (non commercial licensing) to connect with multi DBs. Converts SQL queries to natural queries and vice versa. ‎[6/19/23, 08:59:30] Alok Bishoyi: ‎image omitted
Alok Bishoyi|2023-06-19 09:00:00|might be slightly outdated with llama models in play now
Nirant|2023-06-19 09:10:24|Bytedance (TikTok) has bought $1B of NVIDIA GPUs: Split between A100 and H100 (Chinese fork called H800)   https://www.tomshardware.com/news/chinas-bytedance-has-gobbled-up-dollar1-billion-of-nvidia-gpus-for-ai-this-year
Nirant|2023-06-19 09:10:32|h/t @abacaj on Twitter
Saurav Akaike|2023-06-19 09:13:35|Interesting, have you evaluated it? would you know any other state of the art model for this use case?
~ Rachitt|2023-06-19 09:15:57|Thank you!
Paras Chopra Wingify|2023-06-19 10:11:07|Anyone working on interface of robotics and LLMs here?  Just curious
Ravi Theja|2023-06-19 10:32:56|Custom schema extraction using openai function from [PHONE]   https://twitter.com/nirantk/status/1670651931398918148?s=46
Sudharshan GenAI|2023-06-19 10:33:27|[PHONE] has good experience in m robotics
Pratik Bhavasar|2023-06-19 10:35:55|Folks any good read on business side of Google?
Nirant|2023-06-19 10:36:36|https://stratechery.com/company/google/
~ Pranay Desai|2023-06-19 10:55:21|I also enjoy reading Not Boring by Packy M. He has a couple of recent ones.  https://www.notboring.co/p/the-unbearable-heaviness-of-being https://www.notboring.co/p/attention-is-all-you-need
Nirant|2023-06-19 11:43:00|I believe Balaji of Mitra Robotics is here in the group, can someone who knows him mention him?
Sandya Mannarswamy|2023-06-19 11:47:08|‎Sandya Mannarswamy joined using your invite
Anil Chandra Naidu Matcha|2023-06-19 11:51:02|‎You added Anil Chandra Naidu Matcha
Arvind N Generative AI Group|2023-06-19 12:44:36|Yes. We have been making social robots since 2020 for use in geriatrics.
Arvind N Generative AI Group|2023-06-19 12:45:22|Balaji is my cofounder - happy to answer question about robotics and LLMs - DM me plz.
Harsh Koo|2023-06-19 13:39:40|‎Harsh Koo left
~ Rohit|2023-06-19 15:48:46|1 trillion+ params for gpt-4? The other day I watched zuckerberg estimate that it was around 650B params. ‎[6/19/23, 15:49:11] Prayank Swaroop Accel: ‎image omitted
Chinmay Singh Generative AI WhatsApp Group|2023-06-19 16:01:07|Anyone has the group invite link? Can you please add +91 98332 96431
Abhinav Verma Longshot.ai|2023-06-19 16:02:24|Did they use the circle diagram on Twitter as reference
Abhinav Verma Longshot.ai|2023-06-19 16:03:57|I would trust this, but feel it's smaller
Chinmay Singh Generative AI WhatsApp Group|2023-06-19 16:19:41|Also for folks in this group. We have tried writing an eBook from what we have learned through our conversations with different enterprises/startups using LLMs You can find it here https://www.truefoundry.com/ebook-llm
~ Sudhanshu Heda|2023-06-19 16:55:10|Plug 🤙
Mohit Kumar|2023-06-19 17:26:00|2 questions for model deployment:  1: For deploying a fine tuned  T5 model, where out of box latency on NVidia T4 GPUs (g4dn on AWS) is coming out high (order of 800ms), inputs on what approaches can be tried to reduce the latency without compromising on accuracy too much: Intel neural compressor, deepSpeed MII (in list of models supported T5 not present)?  2: for deploying a production chatbot based on Azure OpenAI, any package which provides the entire chat logging and analysis capability: Truera Trulens?
Sandeep Srinivasa RedCarpetup|2023-06-19 17:28:17|Use Apache TVM or HuggingFace Optimum to optimize the models. This is not a logical optimisation...just a compiler optimisation. Quite safe in general
Rajesh RS Generative AI WhatsApp Group|2023-06-19 17:28:24|I'm interested in #2 - what kind of chat logging functionality do you expect? The standard logging library can be used, with chat and other history stored in DB tables. This is in addition to general app logs I guess
Mohit Kumar|2023-06-19 17:35:04|Logging expectation is fairly  simplistic to log the chat: User chat session id, chat details (User query, system response). Can you call out the logging library
Rajesh RS Generative AI WhatsApp Group|2023-06-19 17:36:59|Just the standard Python logger may work https://pypi.org/project/logging/
Nirant|2023-06-19 17:38:56|I use this for logging: loguru.readthedocs.io/en/stable/index.html  This is a thin wrapper around the default Python logger, very parsing friendly, metadata about which function gets logged by default, so quite handy for most analytics and debugging use cases.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 17:39:05|I don't know if there are purpose built frameworks for logging chat history, that may be worth it.
Nirant|2023-06-19 17:39:11|My primary use case is often debugging logs, analytics logs are secondary
Nirant|2023-06-19 17:43:02|From a design lens, Rasa has a the best logging design for chat (quite expected tbh): https://rasa.com/docs/rasa/tracker-stores/  They call it Tracker Stores for chat storage.  Here are fields you'd care about in any chat log: https://rasa.com/docs/rasa/monitoring/analytics/data-structure-reference  You can parse from file and ETL to a Warehouse for analytics if you're doing at some scale.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 17:44:41|Have seen Rasa features/docs referenced at least twice in the last few weeks here. :)
~ Sahir Patel|2023-06-19 17:45:23|anything similar for JS/TS ?
Mohit Kumar|2023-06-19 17:46:16|It is quite robust so rightly being sited as well 🙂
Nirant|2023-06-19 17:48:12|The data structures/fields we care are similar between JS/TS and Python. The SDK/API for how to use those is quite often specific to workflows e.g. Support bots have the implicit goal of reducing interactions, while goal-oriented bots like sales want to do something different altogether.
Sandeep Srinivasa RedCarpetup|2023-06-19 17:57:30|https://github.com/getzep/zep
Balaji Vishwanath|2023-06-19 18:21:17|We implemented Rasa for an insurance company in the Middle East a few years ago. The experience was not good. I have not tried it recently with the ChatGPT integration.
Mohit Kumar|2023-06-19 18:32:23|"We have had good experience so far with it. Currently experimenting with the ""intentless"" aka more conversational aspects"
Rajesh RS Generative AI WhatsApp Group|2023-06-19 18:33:08|Very cool. Thank you
Sandeep Srinivasa RedCarpetup|2023-06-19 18:34:02|how do u use rasa for LLM applications ? is it like langchain - as in, do u tie prompts and chains using rasa proprietary SDK ?  i can understand when it is classical NLP model training. but how does it come into play in the LLM world ?
Rajesh RS Generative AI WhatsApp Group|2023-06-19 18:41:44|I’m thinking of using Rasa only for engineering pieces such as logging. Whereas we rely on langchain and the like for LLM calls and prompt engineering
Rajesh RS Generative AI WhatsApp Group|2023-06-19 18:41:45|We don’t build intent based chat bots anymore anyway - at least not in the way we used to
Balaji Vishwanath|2023-06-19 19:25:21|Given that RASA is a little heavy, are there not simpler tools for logging purposes?   I'm still not sure if RASA is relevant now when we can do so many things with Langchain.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:37:46|Yeah, I agree. It is easier to build custom frameworks or use Langchain, except perhaps where you're mixing intent based and LLM based bot workflows in the same app
Sandeep Srinivasa RedCarpetup|2023-06-19 19:40:22|Weights and biases is extremely good here.  Langchain has integration with it and we are building integration with w&b into edgechains for production.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:42:53|[PHONE] Thanks. Do you use cloud hosted or self-hosted w&b? I guess the personal / free tiers are for non-commercial use, so asking...
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:43:41|We already use Databricks extensively so there's a lot of overlap between what they offer (MLFlow centric) and W&B as well
Aashay Sachdeva MPL Data Scientist|2023-06-19 19:44:38|MLFlow doesn’t capture 1/10 the info compared to W&B for a training run
Aashay Sachdeva MPL Data Scientist|2023-06-19 19:46:17|If just the parameter, model files, metrics is what you need ML flow is probably the correct fit, but if you want things like gpu/cpu utilisation etc w&b provides that
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:49:15|Yeah, we aren't training LLMs or deep nets from scratch at the moment, so MLFlow suffices for our use cases. That said I see your point. Makes a lot of sense when training something much more involved. Our workflows have shifted to LLM backends almost entirely
Aashay Sachdeva MPL Data Scientist|2023-06-19 19:49:51|Integration in databricks is straightforward btw - https://docs.wandb.ai/guides/integrations/databricks
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:51:15|I like W&B Prompts though, seems quite nice.
Sandeep Srinivasa RedCarpetup|2023-06-19 19:53:40|i personally use self hosted. with some of the NBFC where edgechains is starting to be deployed - it is hosted of course. nobody wants to run infra if they can avoid it.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 19:58:36|Indeed - even big banks and telcos are cloud users these days anyway and so many use PaaS, very attractive for good reasons despite the expense ‎[6/19/23, 20:04:03] Jithin James Ragas: ‎image omitted
Jithin James Ragas|2023-06-19 20:07:59|using this extensively right now to debug some perf issues 😅
~ Samyak|2023-06-19 20:08:04|‎You added ~ Samyak
Rajesh RS Generative AI WhatsApp Group|2023-06-19 20:40:57|That's really nice. Is there a similar feature in Langchain?
Raghotham Paypal Bargava's Friend|2023-06-19 20:46:50|Yes
Raghotham Paypal Bargava's Friend|2023-06-19 20:47:08|langchain server comes with tracing
Soumendra Dhanee|2023-06-19 20:49:04|Been a while since I used mlflow (moved to w&b), but I remember being able to fix most of the missing parts by monkey patching the classes. Moved to w&b because didn't wanted to maintain artefacts by myself
Krishna Panchal|2023-06-19 21:18:36|‎Krishna Panchal joined using your invite
ashish Acgt01 Twitter|2023-06-19 22:01:36|Just saw this on hn.  Anyone tried OpenLLM ?  https://github.com/bentoml/OpenLLM  (via https://news.ycombinator.com/item?id=36388219 )
Abhishek Mishra|2023-06-19 22:17:06|It's an interesting prospect to organise the open sourced LLMs in a single system. But each SoTA model brings something newer with it and the fine-tuning, RL space is especially volatile.  Most of the support that is in the repo is outdated for my use cases and many popular methods or moduls are also not supported.  But repos like this may become very useful as and when things stabilise a bit.
Rajesh RS Generative AI WhatsApp Group|2023-06-19 22:19:09|Bento has been around in the MLOps space for a while. The OpenLLM capability will really be nice for those building models. Not sure others using commercial APIs will jump on this
Sandeep Srinivasa RedCarpetup|2023-06-20 00:33:26|OpenLlama vs Falcon. Any opinions here ?
Abhishek Mishra|2023-06-20 00:37:42|OpenLlama is very good and they've released until 13B parameter versions only but their performance is at parity with Meta's llama release.  There is a bug with the openllm leaderboard which makes llama based models lose 4-6 pts on the leaderboard. Based on that, I'll say OpenLlama is the best option for <13B right now and allows us to create legitimate versions of Vicuna/WizardLM also if we want to try
Abhishek Mishra|2023-06-20 00:38:27|Unfortunately, they don't seem to be trying to release bigger versions 33B and 65B for now so overall utility remains capped 😔
~ Parth|2023-06-20 00:53:23|‎~ Parth left
Dr. Pratik Desai KissanGPT|2023-06-20 01:04:25|We may have the llama2 commercial soon, I'm just taking a break from checking new models out and their benchmarks, as everything will reset from there. ‎[6/20/23, 01:44:51] Sandeep Srinivasa RedCarpetup: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-20 02:02:26|He meant this https://arxiv.org/abs/2305.20050 I missed out on it.
ashish Acgt01 Twitter|2023-06-20 04:02:55|Really neat demo !  https://twitter.com/GrantSlatton/status/1670819980105986049  Code not available right now but will be open sourced
Divyam Goel|2023-06-20 05:52:55|‎You added Divyam Goel
C Chaitanya Nutanc|2023-06-20 06:07:50|‎You added C Chaitanya Nutanc
Puneet Kaura Knowlarity|2023-06-20 06:08:58|‎You added Puneet Kaura Knowlarity
Rajesh RS Generative AI WhatsApp Group|2023-06-20 07:20:11|Surprised the simple framework mentioned in the abstract wasn't paid attention to (pun intended) before. Quite interesting.
Aashay Sachdeva MPL Data Scientist|2023-06-20 09:01:40|Zuck will be GOATed
Ravi Theja|2023-06-20 09:55:36|https://twitter.com/NirantK/status/1670957393403052032?s=20 - This Saturday, we have GenAI meetup hosting [PHONE] and Amod.  Register here: https://hasgeek.com/generativeAI/june-meetup/
~ Abhiram Ravikumar|2023-06-20 09:59:38|"Description says ""May meet-up""..."
Ravi Theja|2023-06-20 10:01:11|Some edits required I guess. Cc: [PHONE] [PHONE] ‎[6/20/23, 11:19:46] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-06-20 11:21:05|Can you explain this? Is this specific to code interpretor
Nirant|2023-06-20 11:22:41|Yes, and some specific plugins.   OpenAI is running some logic which checks if the output got interrupted prematurely, passes that information and continues the in-context generation.
Abhinav Verma Longshot.ai|2023-06-20 11:23:33|Ah yeah. Seen that. For gpt4  Been trying to figure out this as well
Rounak Datta Hackathon Winner|2023-06-20 11:29:57|"There's also that ""Continue Generating"" button which appears for longer answers right?"
Nirant|2023-06-20 11:30:32|Yeah, but the button is almost always jankier. I like it a lot more when it just goes and does the thing in and of itself
Rounak Datta Hackathon Winner|2023-06-20 12:00:33|Peeps who are intersted in Mechanistic Interpretability might like this conversation: https://twitter.com/MLStreetTalk/status/1670429782616469504  PS: Neel Nanda's blogopsts are also free therapy sessions :p
Abhinav Verma Longshot.ai|2023-06-20 12:03:06|Doing this in streaming is a challenge so eager to see how they have done it both from AI and software perspective
Abhinav Verma Longshot.ai|2023-06-20 12:03:26|Interesting format proposed
Rajesh RS Generative AI WhatsApp Group|2023-06-20 13:58:24|"There's a tool called Slayer.ai which allows you to generate audio up to five minutes long, using a prompt. This is an example of a ""podcast episode"" I created with it https://app.slayerai.com/player/3c5983ff-6205-4bef-aaa5-378abd6150c7 - you can choose one of many voices, or a conversational format with 2 voices. The title of the podcast is all I had to provide. As with other generative models, this may suffer from hallucinations and other issues, and the content in it may not be accurate. That said, this was generated in five minutes, and the many YouTube farms which exist for putting content up are only going to benefit from this kind of thing. Worth exploring where the boundaries lie for keeping this kind of tech useful and what can prevent it from being turned into a spam and misinformation machine."
Nirant|2023-06-20 13:59:42|If you've questions for [PHONE] or Amod e.g. around AI anxiety, code generation, FOSS vs Closed Source, Hardware optimisation and so on — ask!   [PHONE] is the moderator
Rajesh RS Generative AI WhatsApp Group|2023-06-20 14:00:20|Made me think about a number of things here: a) can someone use this to feign subject matter knowledge, b) can this be more useful if I were to supply a transcript to it? c) where do we draw the line in terms of generative AI content for use in public forums, talks, videos, lectures...
Nirant|2023-06-20 14:03:57|cc Samhan [PHONE] built https://hackerfm.com/
Samhan Meta/Twitter Friend|2023-06-20 14:04:38|Yes but it’s kind of inactive now. But you can check out the previous episodes
Samhan Meta/Twitter Friend|2023-06-20 14:07:13|I have thought about this - it’s actually not easy to make a talk / video that is interesting and engaging. But I do believe it’s possible to make content that is truly thought provoking. ‎[6/20/23, 14:47:17] ~ Nayan Shah: ‎image omitted
Ashfakh GenerativeAI WA Group|2023-06-20 14:59:56|I’ve tried it.
Prayank Swaroop Accel|2023-06-20 15:00:20|I think for question generation T5 is better
Ashfakh GenerativeAI WA Group|2023-06-20 15:02:03|7b-instruct was not great with in context learning and ended up repeating things in the prompt even though it was properly instructed. Ended up using Vicuña 7B which gave better results.
Abhishek Mishra|2023-06-20 15:03:59|Falcon 7B instruct base isn't good enough
Abhishek Mishra|2023-06-20 15:04:29|You need to use Falcon guanaco trained model for 7B or h2o ai trained falcon 7B
Abhishek Mishra|2023-06-20 15:04:42|https://huggingface.co/h2oai/h2ogpt-gm-oasst1-multilang-2048-falcon-7b
Abhishek Mishra|2023-06-20 15:04:59|I can't guarantee they will crack your use case perfectly but they're more coherent.
Abhishek Mishra|2023-06-20 15:05:22|https://huggingface.co/ybelkada/falcon-7b-guanaco-lora
Abhishek Mishra|2023-06-20 15:07:35|Any 7B model other than MPT 7B chat mostly talks nonsense in various cases. MPT 7B chat can even perform QA given context and thus RAG by extension.
~ Nayan Shah|2023-06-20 15:08:47|ok thanks guys will try the vicuna and MPT 7B.
Sandeep Srinivasa RedCarpetup|2023-06-20 15:09:36|Falcon doesnt work with RAG ?
Nirant|2023-06-20 15:10:16|It works very well actually. And MPT isn't commercially licensed, has worse data, so I wouldn't touch it with a 10 foot pole.
Abhishek Mishra|2023-06-20 15:11:06|As per my tests, Not very well at 7B base or instruct. But instruction tuned falcon 7B by h2o ai or guanaco lora do better.
Nirant|2023-06-20 15:12:28|Aligned on Falcon7B Base being bad. Instruct is marginally better. But Falcon 40B is _quite good_. And you can do RAG-finetuning, like the SQuAD dataset style — which often makes perf better.
Ankur Pandey|2023-06-20 15:15:40|Is there anyone from Adobe here? Esp someone familiar with their document services APIs
Ved Chitnis|2023-06-20 15:20:13|Not from Adobe, but I've worked with their WEM platform as a file repository
Sandeep Srinivasa RedCarpetup|2023-06-20 15:21:42|what do u mean by squad dataset style ?
Abhinav Verma Longshot.ai|2023-06-20 15:22:49|Looking at the datasets used and recent papers like orca have highlighted, the need for high quality and diverse data. You have some capital how would you go about organizing this process?
Abhishek Mishra|2023-06-20 15:24:51|Yeah 40B is definitely way superior. Actually there's a gulf of quality between the 40B and 7B models.
Abhishek Mishra|2023-06-20 15:26:21|SQuAD is basically how we traditionally used to test for QA performance in NLP.
Abhinav Verma Longshot.ai|2023-06-20 15:26:27|I believe it means, the finetuning data is in the form of the squad dataset. Squad is an old qa dataset where question context and answer is there
Sandeep Srinivasa RedCarpetup|2023-06-20 15:26:41|sure. but nirant is talking about RAG in the squad style.
Sandeep Srinivasa RedCarpetup|2023-06-20 15:26:56|how do u do RAG with the squad dataset style ?
Abhinav Verma Longshot.ai|2023-06-20 15:27:03|Rag is basically that but at a higher level.
Abhishek Mishra|2023-06-20 15:27:43|If I was to guess, it should mean SQuAD format for QA and additional context for RAG.
Sandeep Srinivasa RedCarpetup|2023-06-20 15:27:48|ok. i dont understand what that means. how i (or many people ) use RAG is by stuffing embeddings into context. so i dont understand what using RAG in squad dataset style is
Nirant|2023-06-20 15:31:33|RAG is   Question: Context: Answer from Context:  SQuAD Training is: Question: Context: Answer from Context:  Do you notice the similarity?
Sandeep Srinivasa RedCarpetup|2023-06-20 15:34:51|"so i genuinely dont understand the meaning of word ""training"" here. are we discussing falcon finetuning ? i didnt know people were doing it.  if it is pure rag, i get the format. i was not able to understand RAG-finetuning"
Nirant|2023-06-20 15:38:27|Yes, we can finetune Falcon with PEFT
Abhinav Verma Longshot.ai|2023-06-20 15:39:40|PEFT was actually well explained by [PHONE] in the meetup
Sandeep Srinivasa RedCarpetup|2023-06-20 15:40:45|interesting. i was NOT aware of this. i thought falcon was not very successful with finetuning. any benchmarks on this ? just checking. playing a lot with falcon these days
Abhishek Mishra|2023-06-20 15:47:00|QLoRA + SFTrainer from TRL fine tuning of Falcon 7B was completed in just 30min on Guanaco dataset with 1x A100 80G GPU.
Abhishek Mishra|2023-06-20 15:48:08|And it even works with T4 but you'd run out of disk space on free colab. If you've around ~140G disk space, it will take around 3h 45m on T4.
Abhishek Mishra|2023-06-20 15:49:14|There's no standardisation with fine tuning methods right now so you'll find lightning ai guys using adapter V2 mostly with Lora and some other 4 bit fine tuning methods also exist other than QLora like Falcontune.
Abhishek Mishra|2023-06-20 15:49:45|I've not tried all but one - QLoRA + SFTrainer
~ Koushik|2023-06-20 15:52:46|‎~ Koushik requested to join
~ Arsalaan|2023-06-20 19:44:39|Is Google Colab available or opensource framework for finetuning guidelines
Nirant|2023-06-20 19:46:20|Falcon has finetuning with PEFT script: https://huggingface.co/blog/falcon#fine-tuning-with-peft
Nirant|2023-06-20 19:56:30|ElevenLabs — which I know lot of projects/startups to be running in production has raised $19M Series A from Gross, a16z:  https://beta.elevenlabs.io/blog/elevenlabs-launches-new-generative-voice-ai-products-and-announces-19m-series-a-round-led-by-nat-friedman-daniel-gross-and-andreessen-horowitz/
~ Mayank Bajaj|2023-06-20 19:58:46|‎~ Mayank Bajaj requested to join
Anubhav mishra Zupay|2023-06-20 20:16:44|https://www.linkedin.com/posts/genai-works_chatgpt-artificialintelligence-activity-7076858659376410624-tVpA?utm_source=share&utm_medium=member_android
Nirant|2023-06-20 20:18:47|"Yeah, [PHONE] shared this in the morning, I also called it a ""langchain killer""   https://www.linkedin.com/posts/nirant_introducing-azure-openai-service-on-your-activity-7076795328271708161-2178?utm_source=share&utm_medium=member_desktop"
Nirant|2023-06-20 20:19:24|The videos are quite impressive tbh, here is a 59s preview: https://www.youtube.com/watch?v=6SNfeVop4zM
Anubhav mishra Zupay|2023-06-20 20:21:37|Thought that it was only an infra, they gave a feature to just plug and play it directly.   Am wondering if they will add a feature to connect , confluence, notion etc too
Jaskamal Kainth 2013|2023-06-20 20:22:51|‎You added Jaskamal Kainth 2013
Nirant|2023-06-20 20:24:02|Given that it's Microsoft, they'll first build even deeper Microsoft Teams integrations than anything else 🤣
Nirant|2023-06-20 20:24:25|And they've a Notion alternative of their own
Saurabh Karn Nyai|2023-06-20 20:27:39|Very interesting. If anyone is interested in building a chatbot that gives you GPT4 interface on your document and have a Telegram bot - voice2voice very quickly they should check jugalbandi.ai   Upload a document, get a unique ID, access telegram bot accelerator and boom - a chatbot which can do Q&A over a Knowledge Base.
Saurabh Karn Nyai|2023-06-20 20:28:23|http://jugalbandi.ai/api
ashish Acgt01 Twitter|2023-06-20 20:29:15|"If i am an enterprise trying to build something like this use case ( jira, notion, slack, my drive files, aws files, my proprietary leads, sales data) for internal business teams, this seems way more plug and play & self service compared to running an equally performant app using an open source tool or library.  Plus when back end open ai models improve , all msft openaiservice , get those improvements for ""free""  This triggered this q : 1. Is there room for a standalone  streamline like service for gen ai ?  2. If 2 enterprise rivals both use the openai service to build tools like this, how do they differentiate as the backend engine is the same"
Jaskamal Kainth 2013|2023-06-20 20:29:46|Thanks for adding me, Nirant.  Hi everyone,  I was experimenting with Amazon PageMaker, jumpstart falcon7b -instruct model on ml.g5.4xlarge (a10g 24GB 1 GPU) But what I observed is that after a few inferences, the GPU util% is skyrocketing and inference time reached > 100sec.  Can anyone suggest what I could be missing? or infra upgrade  required?
Pratiksha Dake Unacademy|2023-06-20 20:33:44|SageMaker?
Jaskamal Kainth 2013|2023-06-20 20:37:06|my bad! yes.
Anubhav mishra Zupay|2023-06-20 20:51:46|Better data wins, proprietary data will be king maker in this case
ashish Acgt01 Twitter|2023-06-20 20:55:17|*streamlit like service
~ mihir_parulekar|2023-06-20 21:15:49|Guys has anyone worked on code retrieval tool for an agent. Like agent will get the relevant code from a vector store then it should fetch all the relevant code fragments like headers class def etc. Is there any implementation? Thanks!
Rajesh RS Generative AI WhatsApp Group|2023-06-20 21:51:53|This course launched recently https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - taught by Matei Zaharia (Databricks) among others
~ Tarun|2023-06-20 22:07:37|sumo
Pranjal Yadav Razorpay|2023-06-20 22:09:07|I'm using the exact same GPU and model but interface is databricks. My inference is under 30s for a max of 200 tokens. Happy give your setup a look.
Dr. Pratik Desai KissanGPT|2023-06-20 22:13:23|It's really cool, I had demo with the lead last week. Vector support is coming in July, but when that’s available and has good perf, it's can be killer for both Langchain and vector dbs. The response time without vector is also impressive right now.
Gokul Krishnan|2023-06-20 22:16:07|Prob some memory leak
Gokul Krishnan|2023-06-20 22:16:49|What does your resource utilization dashboard say?
Sandeep Srinivasa RedCarpetup|2023-06-20 22:28:54|about the Azure OpenAI service well it is the replit vs enterprise software conversation. it is not unique to generative ai or azure generally speaking.  for example azure doesnt do prompt routing - switch between gpt 3.5 and 4 based on cost metrics (most common ask ). it doesnt do caching (second most popular ask for enterprise software when deploying).  I see very different asks and requirements when in the feature requests for edgechains right now - for example data redaction is growing to be number 1. everyone is shit scared of privacy implications.  replit vs enterprise software is a good way to frame it.
Sumedh Datar|2023-06-20 23:47:57|Does anyone know what hugging face embeddings do?
Sumedh Datar|2023-06-20 23:48:18|I am using instruct from hugging face to generate embeddings and using falcon 7b for query
Sumedh Datar|2023-06-20 23:48:24|Am I doing it correctly?
~ Arindam Barman|2023-06-21 00:27:24|‎Ravi Theja added ~ Arindam Barman
Shivendu Kumar|2023-06-21 03:12:49|https://twitter.com/soumithchintala/status/1671267150101721090  Is Geohot right about the GPT4 architecture? ‎[6/21/23, 07:16:46] Balaji Vishwanath: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-06-21 07:27:32|Free community bootcamp or a paid event?
Saurav Tomar GenerativeAI WA Group|2023-06-21 07:27:59|Great initiative.   I would suggest adding a module to show how these different concepts work together to form the stack of a working app.  Something like https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/  but i guess it would be outdated soon, but still worth exploring.
Balaji Vishwanath|2023-06-21 07:29:36|Hi Pratik. There is a free component and a paid component. Most of our course materials we are building would be free, the live classes would be paid.
Balaji Vishwanath|2023-06-21 07:31:27|Thanks Saurav. One thing about architectures is as you rightly pointed out, things get outdated very quickly. We want to cover more of the foundations and concepts that has more shelf life. For instance, the underlying foundations of LLMs have not changed in years, while a lot of frameworks have arrived. We want to help students focus on the science and practical understanding of it and want to give tools and framerworks as additional reading.
Anshul Bhide Replit|2023-06-21 07:37:10|🤔 https://twitter.com/alexgraveley/status/1671213996735594503?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg
Nirant|2023-06-21 07:45:07|That title bump must have been worth $100K min? Why is that being rounded to zero?
Dr. Pratik Desai KissanGPT|2023-06-21 07:49:35|Mostly title bumps are not proportional to level bumps, otherwise he wouldn't bring it up as far as I know him. But then 🤷‍♂️
C Chaitanya Nutanc|2023-06-21 07:50:30|If this is true, then it means OpenAI is running out of ideas. Maybe that's why they have not started GPT-5 training and Sama is going around trying to get regulation in. Also, it will be hard for them to scale GPT-4 for everyone.
Nirant|2023-06-21 07:50:34|I'll take 4 to 1 odds that Geohot is repeating something he heard from some rumourmill without thinking. 8 MoE and 16 inferences, why?
Nirant|2023-06-21 07:51:29|Frankly, if I was at OpenAI, I'd start 3-4 of such rumours just to see what sticks and for internal lols
Dev Aggarwal|2023-06-21 07:53:14|16 inferences makes sense. That could be the reason why openai dropped `best_of` from the chat completion models - because they’re already considering 4 candidate completions
Nirant|2023-06-21 07:53:48|logits and best_of were dropped to prevent/discourage distillation
Dev Aggarwal|2023-06-21 07:54:29|How?
Nirant|2023-06-21 07:56:07|I leave Defence Against Dark Arts as an exercise to the reader
Anshul Bhide Replit|2023-06-21 07:59:24|Yeah I'm guessing since he's making it public it was probably not worth anything else someone from Github would've called him out from it
Dr. Pratik Desai KissanGPT|2023-06-21 08:00:53|People have been testing GPT4 for almost a year now, and I am surprised how profoundly they are able to keep it secret.
Rohit Aggarwal|2023-06-21 08:02:17|SF rumor mill reports of strict NDAs for anyone leaving.
Nirant|2023-06-21 08:02:24|Friends, we've ~20 slots left in the group.   Please don't ask admin to add folks. Exceptions: Engineers, data scientists, founders who can and want to contribute to the conversation.
C Chaitanya Nutanc|2023-06-21 08:03:13|OpenAI has a strong rumour mill game. Look at what they have managed to make it stick. AGI, doomsday scenario etc etc.
Nirant|2023-06-21 08:04:16|Making Sam Altman is more dangerous than AGI
C Chaitanya Nutanc|2023-06-21 08:07:03|Good set of topics. Only suggestion is maybe you could move 8 to 1 or 2. Will make the students appreciate the importance of data much earlier.
Shashank B Designer|2023-06-21 08:12:15|https://lu.ma/generativeAIJune - says registration closed
Abhishek Mishra|2023-06-21 08:26:12|The numbers might be off completely but earlier with GPT3.5, this was like the best guess in the market.  OpenAI's released Instruct GPT in early 2022 and the models were task-wise specialised. So when chatGPT came in Dec, it was worthwhile to guess that there could be a chat layer that breaks down user query to individual tasks and then take a MoE (mixture of experts) approach to execute those tasks and present the final answer. It also made sense to assume that the jump in architecture in GPT3.5 wouldn't be too much from instruct-GPT.  However with GPT4, I can't say the same, it looks like a different beast. It's much smarter in many ways and hard to tell without experience if it's just MoE with a chat layer.
Dr. Pratik Desai KissanGPT|2023-06-21 09:07:19|This is happening too fast. 1.3B parameter code model, phi-1, hitting 50%+ on Human eval, trained for 4 day on 8 A100s. https://twitter.com/_akhaliq/status/1671360619986010112
Nirant|2023-06-21 09:09:12|For wider audience, HumanEval is a dataset, which is part of most training paradigms and not actually Human eval.
Dr. Pratik Desai KissanGPT|2023-06-21 09:11:35|🙏 I missing out additional details in excitement. That's like <1K$ on LambdaLab for training. 🤯
~ Akshat Khare|2023-06-21 09:14:22|I have a question pertaining to http://jugalbandi.ai and elevenlabs alike. Basically I couldn't find anything which does decent TTS with custom voice cloning. I understand there are legal ramifications to it but I need it for a very legal and useful usecase. Are you guys familiar with something? The closest thing I could find was a fork of suno.ai which works worse than elevenlabs voice cloning.
Nirant|2023-06-21 09:15:13|Tortoise is FOSS and competitive to ElevenLabs for Western accents https://github.com/neonbjb/tortoise-tts
~ Akshat Khare|2023-06-21 09:16:15|Thanks Nirant. I tried this too. I need it for Indian accents. Fails terribly and just ingests 5 seconds of audio.
Abhishek Mishra|2023-06-21 09:17:53|This paper and repofusion are definitely 2 really interesting picks of the day for me as smaller models achieving performance parity with models 70x their size  Repofusion - https://twitter.com/arankomatsuzaki/status/1671345186536816643?t=gKOzHVpoZzbQjSjrcCYQTQ&s=19
Dr. Pratik Desai KissanGPT|2023-06-21 09:20:19|Models like these along with gglm and quantization are opening up so many possibilities for local inference. I earlier thought it will take couple of years for inference to come native on mobile level silicon, but it is happening so fast.
Abhishek Mishra|2023-06-21 09:21:57|Yes, inference on edge is totally happening by end of 2023 in commercial capacity 🤞
Nirant|2023-06-21 09:22:11|I am very skeptically of believing these results. More often than not, they've some data leak or distillation of some other sort going on. Or overfit to a specific task/dataset, not even domain.
Nirant|2023-06-21 09:22:44|*these => 20-30x smaller models, trained from scratch, no arch change kinda ideas
Abhishek Mishra|2023-06-21 09:22:53|True, that chance is there.
Nirant|2023-06-21 09:25:17|Took me 10s to find the trick:   Experiments on *single-line code completion* show that our models trained with *repository context* significantly outperform ...
Dr. Pratik Desai KissanGPT|2023-06-21 09:25:37|phi-1 is from Microsoft Research, so hope they are not bluffing.
Nirant|2023-06-21 09:25:39|It's single line code completion, unlike what StarCoder or CodeGen does — and is specific to a repo
Nirant|2023-06-21 09:27:08|And the entire test eval is 200 Java repositories 🤦🏾‍♂️
Saksham Generative AI WhatsApp Group|2023-06-21 09:28:39|I thought they have -https://techcommunity.microsoft.com/t5/integrations-on-azure-blog/integrate-azure-open-ai-in-teams-channel-via-logic-app/ba-p/3776048
Balaji Vishwanath|2023-06-21 09:29:36|Are there standard benchmarks to evaluate these models apples-apples? I see each one claiming they are better in some way, but by cherry-picking one evaluation method that they themselves created. ‎<This message was edited>
Nirant|2023-06-21 09:30:56|Highest trust at the moment:   Open LLM Leaderboard: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
Nirant|2023-06-21 09:31:18|OpenAI Evals is pretty good too, but not trusted for obvious reasons
Balaji Vishwanath|2023-06-21 09:32:02|I track the leaderboards, but they are more through ELO ratings with head-head evaluations than by one standard benchmark applied equally across all of them.
Balaji Vishwanath|2023-06-21 09:32:53|I take back. I see that they have added more benchmarks now.
Nirant|2023-06-21 09:32:54|I'm confused. Open LLM Leaderboard does not have any ELO or head on comparisons
Balaji Vishwanath|2023-06-21 09:35:31|I'm talking about the Human&GPT evaluations tab. ‎[6/21/23, 09:40:46] ashish Acgt01 Twitter: ‎image omitted
~ Rohit|2023-06-21 09:42:20|sama said that gpt-4 was the result of a lot of small improvements. That kind of implies that it will get harder and harder for the next versions. Then again he also said scaling still works so idk.
Dr. Pratik Desai KissanGPT|2023-06-21 09:44:46|Yes, I believe high quality data is going to be the key, and also a big opportunity for tech startups.
ashish Acgt01 Twitter|2023-06-21 09:46:39|and reduce cost of training and inference to enable smaller players to compete with the likes of OpenAI, google, Microsoft
ashish Acgt01 Twitter|2023-06-21 09:47:07|Without sacrificing performance
Arvind N Generative AI Group|2023-06-21 09:47:37|Scaling can take us far and can result in a lot more emergent properties. There is no evidence against the contrary. However it doesn't make business sense to serve a slower beast.
Pratik Bhavasar|2023-06-21 09:53:45|Seems parameter scaling works but data scaling laws are broken and at the least misguiding.
ashish Acgt01 Twitter|2023-06-21 09:53:51|"From what I have read, Sam has said the opposite of ""he also said scaling still works"" publicly.  ""I think we're at the end of the era where it's going to be these, like, giant, giant models,” he told an audience at an event held at MIT late last week. “We'll make them better in other ways.” [...]  Keys is ""make them better in other ways""  https://www.lesswrong.com/posts/ndzqjR8z8X99TEa4E/sama-says-the-age-of-giant-ai-models-is-already-over"
Brij Singh Rebright Partners|2023-06-21 09:58:05|What are your thoughts on Yanns proposed JEPA - https://youtu.be/OKkEdTchsiE
Pratik Bhavasar|2023-06-21 10:03:26|What is your guess on the other top 3 ways?
Abhishek Mishra|2023-06-21 10:05:20|Bigger context, low bit lossless inference, task-based specialisations
Pratik Bhavasar|2023-06-21 10:12:22|Does the first 2 guarantee higher performance for usual text length gen? The last sounds like downstream task based finetuning unless you are referring to training different expert models (although I don’t understand clearly how do you decide expertise per model for training and routing for inference to these experts(maybe a classifier) or do you just merge all models weights by averaging?)
C Chaitanya Nutanc|2023-06-21 10:15:49|Wikipedia search using the KE Sieve model. 36 million passages embedded. Small model index embedding size(544 dimensions) 2.3 GB. Large model index embedding size(2224 dimensions)-10GB. https://speech-kws.ozonetel.com/wiki We created an embedding space based on mpnet sentence transformer. So this can work as drop in replacement for those embeddings. Cost savings of around 10 times. Some details here, https://gpt3experiments.substack.com/p/building-a-vector-database-in-2gb
Paras Chopra Wingify|2023-06-21 10:18:45|Project idea: semantic search on quotes   I was surprised I wasn’t able to find a good one yesterday  Was trying to find what plato said about growth mindset
Pratik Bhavasar|2023-06-21 10:19:13|Isn’t google supposed to do this?
Abhishek Mishra|2023-06-21 10:22:24|There's some drop in quality of inference currently for first 2 but that will be one of the ongoing areas of research with improvements like RMT/Longformer. For the third one, we already have routing functions/gating networks approach to first route the subtask to an expert then mix results together (haven't read how they mix it up finally).
Pratik Bhavasar|2023-06-21 10:22:29|It’s working a bit when you just check the images as google must have indexed emb of text found in image  https://www.google.com/search?rlz=1CDGOYI_enIN867IN867&hl=en-GB&sxsrf=APwXEddFckbkv58OyEaazXJYNgynUe3uBg:1687322990924&q=plato+quotes+on+growth+mindset&tbm=isch&sa=X&ved=2ahUKEwiH8vr7x9P_AhWxwzgGHQgEDlQQ0pQJegQIExAB&biw=428&bih=751&dpr=3
Anubhav mishra Zupay|2023-06-21 10:23:32|Bard does it pretty well. Bard is good with literature and quote and literature knowledge in general
ashish Acgt01 Twitter|2023-06-21 10:27:54|"Haven't read the I-JEPA paper yet, it's a completely different approach than LLMs  https://arxiv.org/abs/2301.08243  https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/  ""At the same time, by predicting representations at a high level of abstraction rather than predicting pixel values directly, the hope is to learn directly useful representations that also avoid the limitations of generative approaches, which underlie the large language models that have generated so much recent excitement.  In contrast, generative architectures learn by removing or distorting portions of the input to the model – for example, erasing part of a photo or hiding some of the words in a text passage. They then try to predict the corrupted or missing pixels or words. One significant shortcoming of generative methods, however, is that the model tries to fill-in every bit of missing information, even though the world is inherently unpredictable. As a result, generative methods may be prone to mistakes a person would never make because they focus too much on irrelevant details instead of capturing high-level predictable concepts. For example, it is notoriously difficult for generative models to generate human hands accurately. (They often add extra digits or make other glaring errors.)""   My rough sense is for vision, I-JEPA looks promising but LLMs will rule the roost for nlp stuff"
Paras Chopra Wingify|2023-06-21 10:32:18|Thanks. I’ll try
Paras Chopra Wingify|2023-06-21 10:32:43|Nah, it wasnt doing it  I’m sure the project exists somewhere
Dr. Pratik Desai KissanGPT|2023-06-21 11:20:20|Nothing is there for Indian accent voice cloning, yet. May be after Meta releases Voicebox weights, there is a possibility.
~ Akshat Khare|2023-06-21 11:21:12|Thanks Prateek. I will look up what's voicebox is.
Dr. Pratik Desai KissanGPT|2023-06-21 11:22:07|https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/
~ Akshat Khare|2023-06-21 11:26:21|We trained Voicebox with more than 50,000 hours of recorded speech and transcripts from public domain audiobooks in English, French, Spanish, German, Polish, and Portuguese.  No mention of Hindi or Indian languages. Probably might fail.
Saurabh Karn Nyai|2023-06-21 11:27:27|AI4Bharat has good Indian language corpus. https://ai4bharat.iitm.ac.in/datasets
Nitin Mahajan McKinsey|2023-06-21 11:27:41|Yea meta one is cool but Hindi support not there   Earlier in the group there were discussions on vakyansh for Hindi. Haven’t had time to personally try   np , just saw vakyansh has TTS too . https://github.com/Open-Speech-EkStep/vakyansh-tts
Saurabh Karn Nyai|2023-06-21 11:27:55|They also have model endpoints for speech2text, translation and text2speech in Indian languages. Mostly works well, barring some translation issues here and there.
Saurabh Karn Nyai|2023-06-21 11:29:11|https://github.com/OpenNyAI/jugalbandi-api/blob/main/translator.py   Here we have written some code to use the AI4Bharat model endpoints for consumption in applications. Works with at least 10 Indian languages including Hindi.
Abhinav Verma Longshot.ai|2023-06-21 11:29:23|Is gpt-4 just an agent over several gpt-3.5 models? 😜
Dr. Pratik Desai KissanGPT|2023-06-21 11:31:29|(1) Let's see if they release weights (2) If fine tuning is possible, AI4Bharat corpus can be used
~ Akshat Khare|2023-06-21 11:31:32|But custom voice cloning is there?
~ Akshat Khare|2023-06-21 11:31:41|Yeah. Perfect
Dr. Pratik Desai KissanGPT|2023-06-21 11:33:07|I have used those models, but have been complaining about production readiness for self-hosting.
Saurabh Karn Nyai|2023-06-21 11:33:24|Oh it has become quite stable now.
Saurabh Karn Nyai|2023-06-21 11:33:45|They are burning significant amount of GPU and have clusters of it
jyotirmayjk Hackathon|2023-06-21 11:35:03|I think this is possible 😅 Could it also be possible that it is agent over Code Interpreter too internally ?  In a recent project I was using GPT-4 for unstructured document parsing and getting output in json  Sometimes instead of json it started giving Python code as output  The logic of the python code was created to follow the parsing instructions given in the prompt  I was not able to get the same output again on multiple runs on the same prompt afterwards 🤷🏻‍♂️
jyotirmayjk Hackathon|2023-06-21 11:36:21|This was either a top quality hallucination or an internal step which was given as output
Saurabh Karn Nyai|2023-06-21 11:36:22|As someone said (in this group) GPT4 works in mysterious ways 😅
Nitin Mahajan McKinsey|2023-06-21 11:37:47|[Need help] Have a silly problem that our company's access to GPT4 APIs hasn;t come through. We have applied many times on the website with logical explanation that many things only work on GPT4 but silence .... has anyone else experienced it? Any workarounds or help to get the API access. (yes I have GPT subscription also). We were about to release a product and now this silly issue
Pratik Bhavasar|2023-06-21 11:38:19|I doubt that because ensemble perf can just give small bumps and milti-task training is usually better. The Google style MoE is a different story
Abhinav Verma Longshot.ai|2023-06-21 11:39:33|Can you link to google style MoE, for a better understanding  of how it actually works
Nirant|2023-06-21 11:39:56|https://paperswithcode.com/method/switch-transformer
Nirant|2023-06-21 11:42:58|There is also TaskMoE, which is a distillation mechanism https://arxiv.org/pdf/2110.03742.pdf
Nirant|2023-06-21 11:43:16|Blog: https://ai.googleblog.com/2022/01/learning-to-route-by-task-for-efficient.html ‎[6/21/23, 11:44:15] Sandeep Srinivasa RedCarpetup: ‎image omitted
Pratik Bhavasar|2023-06-21 11:48:26|This sounds like ensemble rather than Switch MoE
Abhinav Verma Longshot.ai|2023-06-21 11:49:25|So it is an agent over several 3.5 models. Then GPT-5 will be an agent over an agent. AI bureaucracy
Abhinav Verma Longshot.ai|2023-06-21 11:50:39|GPT-4 is a kaggler
~ Abhilash Inumella|2023-06-21 12:06:51|[PHONE] has asked me to remove this post. Will be doing it in five. If anyone else had a viewpoint to share in this time on posts related to hackathons and meet-ups and where they should go, happy to hear and learn.
~ Srinivasa Raghavan K M|2023-06-21 12:07:10|One of the ongoing efforts to release 1000hrs of parallel speech to text corpora in 9 Indian languages spanning 38 dialects  https://respin.iisc.ac.in/datasets
~ Srinivasa Raghavan K M|2023-06-21 12:08:00|Similarly for text to speech in Indian languages https://syspin.iisc.ac.in/api/v1//Home
Dev Aggarwal|2023-06-21 12:09:02|Any link to models for these too?
~ Srinivasa Raghavan K M|2023-06-21 12:10:17|Not yet, but the plan is to publish datasets along with models
Dev Aggarwal|2023-06-21 12:11:33|Whisper models?
Sthit Generative AI WhatsApp Group|2023-06-21 12:11:35|I see 2 languages so far. Which others are being worked on ? Is there a way to contribute ?
~ Srinivasa Raghavan K M|2023-06-21 12:15:10|Language info provided the website  Access to the couple of languages now available through ASRU challenge this year https://sites.google.com/view/respinasrchallenge2023/home
Sthit Generative AI WhatsApp Group|2023-06-21 12:15:35|I see.
Swapnika Hashmail Web3|2023-06-21 12:49:24|Anyone here using WIT to convert user intents into actions for your products?
Sandeep Srinivasa RedCarpetup|2023-06-21 12:57:21|what is WIT ?
Swapnika Hashmail Web3|2023-06-21 12:58:58|An older Meta AI product that’s used to understand user intent and convert to actions. Like a basic version of OpenAI functions.
Swapnika Hashmail Web3|2023-06-21 12:59:31|https://wit.ai/
Pratik Bhavasar|2023-06-21 13:08:01|Ohh! Old memories from 2016
Nirant|2023-06-21 13:32:51|"More like nightmares 🤣  Things used to break and the business counterpart would ask ""how to fix?"" and senior engineers would go ""ask Wit.ai"" 🤣"
Rajesh RS Generative AI WhatsApp Group|2023-06-21 13:33:54|"https://arxiv.org/pdf/2306.11644.pdf ""Textbooks are all you need"" - a small model trained on high quality ""textbook quality"" data"
Anubhav mishra Zupay|2023-06-21 15:02:03|https://www.linkedin.com/posts/metaai_cvpr2023-activity-7076997142204055552-TCIC?utm_source=share&utm_medium=member_android ‎[6/21/23, 15:02:50] Anubhav mishra Zupay: ‎image omitted
Anubhav mishra Zupay|2023-06-21 15:03:31|Synthesia just raised 90 million for this. Not sure what future dynamics would look like
Nitin Mahajan McKinsey|2023-06-21 15:10:44|Is this similar to how gan.ai trains their model based on a 2minute user video
Swapnika Hashmail Web3|2023-06-21 16:01:12|I use them fairly regularly. Even outside of AI voiceover, their feature set is pretty robust. And the interface is super intuitive and easy to use.
~ Madhur Tandon|2023-06-21 16:03:19|‎~ Madhur Tandon was added
Saiyam Wyse|2023-06-21 16:03:19|‎Saiyam Wyse left
Dhruv Anand|2023-06-21 16:21:31|is it possible to share a private huggingface space as a demo externally, without exposing the code? Basically, I want to use huggingface hardware instead of self-hosting the gradio/streamlit app
Abhishek Mishra|2023-06-21 16:48:03|There's a clumsy way I'm aware of. Possibly others know better.  Private spaces belonging to an organisation are visible to members of the organisation only. So you can invite somebody as a collaborator on the organisation and get them to test or use your setup.
Dhruv Anand|2023-06-21 16:50:18|yeah I'm thinking of rolling it out publicly
Abhinav Verma Longshot.ai|2023-06-21 16:57:06|There are ways you can hide your creds, if that's your main concern
Dhruv Anand|2023-06-21 16:59:48|not just the creds. there's secrets in HF for that. Asking for keeping the code private
Abhishek Mishra|2023-06-21 17:02:11|There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets  A link that discusses something similar - https://discuss.huggingface.co/t/share-app-url-without-sharing-the-files-and-version/26182
Ved Chitnis|2023-06-21 18:06:28|https://twitter.com/MetaAI/status/1671211532599046144?t=IzhQ0OA72FgEadVfRvhx2g&s=19  6 papers by meta for CVPR23.
Rahul Chhabra 2016|2023-06-21 18:11:31|11labs works fine for Indian accents. What issues are you facing?
~ Akshat Khare|2023-06-21 18:12:44|Well, I'll dm you. Long discussion. Thanks for the info tho.
Rahul Chhabra 2016|2023-06-21 18:12:54|Sure
~ Santhosh K|2023-06-21 18:18:37|I am building a binary classifier and utilizing the Roberta base model. Interestingly, I have observed instability in its performance when it comes to punctuation marks. The addition of a simple full stop or even special characters seems to alter the predicted labels.  Any advice ?
~ pt|2023-06-21 18:24:54|Is the openai function based on a paper? How to do it for an open model?
~ Abhiram Ravikumar|2023-06-21 19:36:29|Maybe this has been already discussed before, but tammy.ai is quite good at generating YouTube video summaries and categorizing it  https://tammy.ai/summary/cNfINi5CNbY - 2hr Google I/O 23 summarized into neat bullet points :)
ashish Acgt01 Twitter|2023-06-21 19:43:56|Interesting but might just be a feature on YouTube's roadmap
Abhishek Mishra|2023-06-21 19:46:26|In most cases, I've seen that these YouTube summary extensions or apps support limited videos. Does this support every video? ‎[6/21/23, 19:49:33] Anubhav mishra Zupay: mistral ai memo.pdf • ‎7 pages ‎document omitted
Anubhav mishra Zupay|2023-06-21 19:50:05|Mistral raised its round just days after hiring staff using a Google Doc memo. Here is the doc  No deck. just a 7 pager Memo.
Anubhav mishra Zupay|2023-06-21 19:50:30|Most of it theory yet the team is great
ashish Acgt01 Twitter|2023-06-21 19:51:50|They are all big names in the founding team - deepmind, llama architect, etc  With pedigree like that and the current craze around gen ai, not that surprising
ashish Acgt01 Twitter|2023-06-21 19:53:44|"""At the end of 2023, we will train a family of text-generating models that can beat ChatGPT 3.5 and Bard March 2023 by a large margin, as well as all open source solutions. Part of this family will be open-sourced; we will engage the community to build on top of it and make it the open standard. We will service those models with the same endpoints as our competitor for a fee to acquire third-party usage data, and create a few free consumer interfaces for trademark construction and first-party usage data.""  Only time will tell but exciting times for sure !"
Anil Chandra Naidu Matcha|2023-06-21 20:01:05|Langchain does similar functionality using React
Sandeep Srinivasa RedCarpetup|2023-06-21 20:06:51|i asked the same question today. i think all base models will need to put this feature as tablestakes. the usability advantage is too high.
Sandeep Srinivasa RedCarpetup|2023-06-21 20:07:47|nope. openai functions magic is not function invocation - it is formatting the JSON to match the function signature. it is insanely hard to do this without the new release of openai. we have all struggled with jsonformer etc to match function signatures and it mismatches very frequently
Abhinav Verma Longshot.ai|2023-06-21 20:15:05|Have you tried this with gpt4? The non function model?
Swapnika Hashmail Web3|2023-06-21 20:15:48|How consistent is the output json using functions? I was reading somewhere that it still hallucinates
Shan|2023-06-21 20:21:39|Yeah these kinda stuff happens a lot. We don’t rely on a single model for classification. Ensemble your way to glory.
~ Abhiram Ravikumar|2023-06-21 20:22:35|not sure, need to explore more
Abhinav Verma Longshot.ai|2023-06-21 20:22:50|Has anyone tried adding, gpt don't train using this data  In the prompts and seen how the response is?
~ Prajna Prayas|2023-06-21 20:28:22|"adding as in ""Add 2+2"" kind of thing?"
Abhinav Verma Longshot.ai|2023-06-21 20:31:49|Just append this line to your prompt
Abhishek Mishra|2023-06-21 20:37:39|These models need their training and inference data to be similar in encoding and patterns.   I observed this problem and then encoded training data in unicode then inference data was also encoded in unicode before passing to the model otherwise it will drop a lot in accuracy.
Abhishek Mishra|2023-06-21 20:39:12|Maybe other people have better methods but this is what I tried and use in my systems. Also, make sure that your training/inference characters aren't lost in encoding. In most cases, it won't but can't guarantee for everything.
~ Santhosh K|2023-06-21 21:06:11|Encode? Convert to utf8 ?
Soumendra Dhanee|2023-06-21 21:15:39|Does anyone have experience doing differential privacy for LLMs (fine-tuning)? I would like to have a chat about your experience.
Abhishek Mishra|2023-06-21 21:44:06|Yeah *utf-8* is one kind of character encoding, I meant *unicode* character encoding as it has counterparts of it's own for each type of encoding to minimise information loss.
Abhishek Mishra|2023-06-21 21:45:07|It's not guaranteed but its possible that you've some issue of having characters from different encoding in training and inference data. If the model doesn't recognise any kind of tokens, it'll go haywire typically. We want to keep the tokenisation of inference time exactly the same as tokenisation of training time.
Abhishek Mishra|2023-06-21 21:47:03|This is hard because we are gathering data from all kinds of sources like docs, web or just tabular data. So encoding differences are a latent factor sometimes that drop the model performance. Take my word with a grain of salt as it's speculation on my part for what your issue might be.
Abhishek Mishra|2023-06-21 21:49:04|What do you mean by *Differential privacy*?  Does it mean that documents with different levels of confidentiality are to be trained/fine-tuned on an LLM?
Abhinav Verma Longshot.ai|2023-06-21 21:50:54|Me thinks it has something to do with federated learning
Soumendra Dhanee|2023-06-21 21:51:16|Differential privacy (DP) provides a rigorous framework that allows adding noise in the process of training or fine-tuning LLMs such that extracting the training data becomes infeasible (i.e., with a cryptograph- ically small success probability). ‎[6/21/23, 21:51:44] Soumendra Dhanee: 2210.15042.pdf • ‎7 pages ‎document omitted
Abhishek Mishra|2023-06-21 21:52:27|Thanks a lot 😄 ‎[6/21/23, 22:09:24] Anshul Bhide Replit: ‎image omitted
Kaushik Bokka|2023-06-21 22:28:01|Didn’t expect VisProg to win the Best Paper award at CVPR 🤔 https://prior.allenai.org/projects/visprog
~ Happy Chaudhury|2023-06-21 22:38:12|Any pretrained model for legal documents, agreements or contracts i have tried legalbert for QA but not giving good results, i want to get all parties involved persons banks and legal description ?
~ Gaurav|2023-06-21 22:52:46|How many tokens are you generating?  We released Falcon-7b-instruct api under beta on monsterapi yesterday. Inference times are like 4-8 seconds for 200 tokens. Experimenting more.
~ Apurva Bhatt|2023-06-21 22:57:39|There is a paper on cuad dataset, not a perfect match for what you are looking for--but you might find some interesting ideas
~ Happy Chaudhury|2023-06-21 22:58:16|Yea I have tried it but it's specific for contracts
~ Happy Chaudhury|2023-06-21 22:58:28|Fine tuned deberta v2 ‎[6/21/23, 23:04:01] Karan Lightspeed: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:06:24|How many urls are in the array you're passing? If there's a lot of Javascript in these websites, it can take a while for selenium to load the pages
Karan Lightspeed|2023-06-21 23:06:53|Just 1
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:07:13|DMing
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:38:26|https://twitter.com/jsngr/status/1671561341893742592?t=w2UURl05_L5aKAndPmT50g&s=08
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:38:41|Figma acquired diagram
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:39:32|We'll see a lot more of this. The big guys who have scale distribution are going to lap up any good tools.
Bharat Kumar Ramesh Hashmal Web3|2023-06-21 23:39:59|It's a pretty neat exit ramp for small teams building in AI
Abhinav Verma Longshot.ai|2023-06-21 23:40:50|How does the selenium url loader work?
Abhinav Verma Longshot.ai|2023-06-21 23:41:10|I mean how good are the results
Dev Aggarwal|2023-06-22 00:07:38|How to downalod this? The download button is missing ‎[6/22/23, 01:04:25] ashish Acgt01 Twitter: ‎image omitted
ashish Acgt01 Twitter|2023-06-22 01:16:32|The other option is trying to contact the jugalbandi.ai folks which ( according to my understanding, others correct me if I am wrong) exposes an API wrapper on top of the Bhashini models[0]   https://www.jugalbandi.ai/mission https://www.jugalbandi.ai/ecosystem  0. https://www.bhashini.gov.in/en/ecosystem
ashish Acgt01 Twitter|2023-06-22 01:20:23|Here is a post from Saurabh of jugalbandi.ai team
Dev Aggarwal|2023-06-22 01:21:54|Bhashini doesn’t have a bhojpuri model
Aditya Sista 2010B5|2023-06-22 02:05:51|Hi all, what's the current consensus here on the best ai coding tool extension for IDEs?
Abhishek Mishra|2023-06-22 02:06:53|You mean excluding copilot?
Aditya Sista 2010B5|2023-06-22 02:08:25|Yeah. Copilot is good at keeping context of your whole codebase. But gpt 4 is way better when it comes to intelligence? Generates better tests etc
Abhishek Mishra|2023-06-22 02:12:52|There's nothing that is even better than GPT3 in coding except GPT4. If you want to use GPT4 as copilot, try codegpt.co
Abhishek Mishra|2023-06-22 02:13:28|If you've your own api key then GPT3/4 both are available for use in their extension
Abhishek Mishra|2023-06-22 02:14:14|Otherwise you can pay and use GPT4 for coding with their extension
Sumedh Datar|2023-06-22 02:46:41|Was anyone successful in loading a gpt4all model?
Abhishek Mishra|2023-06-22 02:48:49|You can load it easily via privateGPT, their chat client or directly via their python bindings.
Ankur Pandey|2023-06-22 07:22:20|This is intriguing https://twitter.com/sparr_ml/status/1671587317075648533?t=vrLceAWiZbFzhBEHsYKQbw&s=19
Nirant|2023-06-22 07:29:50|"Okay, this is the most ""Sparks of AGI"" behaviour I've seen!   Absolutely hilarious and alarming at the same time"
Saurabh Karn Nyai|2023-06-22 07:33:02|Azure Quantum Elements is here to work with AI  https://blogs.microsoft.com/blog/2023/06/21/accelerating-scientific-discovery-with-azure-quantum/
ashish Acgt01 Twitter|2023-06-22 07:52:12|"Does it have a world view of time ( response time ) Or in the latent space probability of using ""apologies"" and ""delays"" was high for this particular prompt input ?  I am inclined to believe the latter :)"
Nirant|2023-06-22 07:54:10|I don't know either way. But there is definitely some state information which OpenAI passes to the LLM. You can see this when you try to resume a stale Code Interpreter or Bing convo
~ Bahulee Guha|2023-06-22 08:20:23|+1
Bharat Kumar Ramesh Hashmal Web3|2023-06-22 08:21:44|This is to create documents I presume? Or just parse complex legal docs?
Bharat Kumar Ramesh Hashmal Web3|2023-06-22 08:22:10|And to what degree of customization? I've seen it do very well on boilerplate stuff like NDAs, and basic vendor agreements
~ Bahulee Guha|2023-06-22 08:23:25|Actually to create documents, expert analysis out of legal docs. And create line of questioning etc. for the expert analysis
Saurabh Karn Nyai|2023-06-22 08:23:33|Have you tried a RAG system using one of the GPTs to generate responses?
ashish Acgt01 Twitter|2023-06-22 08:23:40|Interesting read on RLHF: https://www.interconnects.ai/p/how-rlhf-works
ashish Acgt01 Twitter|2023-06-22 08:36:12|"https://arxiv.org/abs/2212.08073  TIL about Anthropic's constitutional ai paper. Very cool idea on first glance.  What do people think about this approach, RLAIF ?  ""As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them"""
Saurav Tomar GenerativeAI WA Group|2023-06-22 09:10:39|Just found out that I have access to chatGPT plugins. But there seem to to too many of them already.    What are some plugins you find useful or use regularly?
Saurabh Karn Nyai|2023-06-22 09:20:08|Nothing in plug-in works as well as expected at least for me. I thought web search was going to be good but I the tool fails most of the time and it’s so slow I would rather use Google or Bard for it :P
Aashay Sachdeva MPL Data Scientist|2023-06-22 09:27:05|Try perplexity.ai
Saurabh Karn Nyai|2023-06-22 09:29:03|🫡 Yes sir!
Lalit Pagaria|2023-06-22 09:35:11|open source API key management tool. It is still in developing but you may check it for your openai key management (inside your org). Create multiple keys along with setting up individual rate limits and make your server call openai api.  https://github.com/chronark/unkey
Pratyush Choudhury|2023-06-22 09:41:22|Something for [PHONE] to consider adding to his OSS project maybe?  https://twitter.com/177pc/status/1671591721032105985?t=z_tw91n9iK-wCCv45lMAYg&s=19
~ Suhas Baliga|2023-06-22 09:41:29|Interesting!
Rohit Aggarwal|2023-06-22 09:44:06|This is actually superb for us!
Lalit Pagaria|2023-06-22 09:50:55|It is still in the early stage. But it may give a good design idea.
~ Rajdeep Banerjee|2023-06-22 11:16:18|‎~ Rajdeep Banerjee left
Ankur Pandey|2023-06-22 11:27:08|"Could it be because the Bing browsing plugin also uses a model trained on ""browsing journey"" style data?"
~ ..!..|2023-06-22 11:44:18|‎Rahul Bhatnagar added ~ ..!..
~ Shristi|2023-06-22 12:56:14|‎You removed ~ Shristi
~ As|2023-06-22 12:56:18|‎You removed ~ As
Rohit GenerativeAI WhatsApp Group|2023-06-22 12:56:21|‎You removed Rohit GenerativeAI WhatsApp Group
Sandeep Generative AI WhatsApp Group|2023-06-22 12:56:23|‎You removed Sandeep Generative AI WhatsApp Group
~ Sourabh Gawande|2023-06-22 12:56:26|‎You removed ~ Sourabh Gawande
~ Pravin|2023-06-22 12:56:28|‎You removed ~ Pravin
~ Sumit|2023-06-22 12:56:30|‎You removed ~ Sumit
~ Vivek Karna|2023-06-22 12:56:32|‎You removed ~ Vivek Karna
~ Ankur|2023-06-22 12:56:33|‎You removed ~ Ankur
~ Lavalish|2023-06-22 12:56:37|‎You removed ~ Lavalish
~ Advait Shankar|2023-06-22 12:56:40|‎You removed ~ Advait Shankar
~ Utsav|2023-06-22 12:56:43|‎You removed ~ Utsav
~ Aniket Behera|2023-06-22 12:56:46|‎You removed ~ Aniket Behera
~ Surya Harsha Nunnaguppala|2023-06-22 12:56:52|‎You removed ~ Surya Harsha Nunnaguppala
~ Prajwal|2023-06-22 12:56:54|‎You removed ~ Prajwal
~ Vaibhav|2023-06-22 12:56:56|‎You removed ~ Vaibhav
Sandeep Generative AI WhatsApp Group|2023-06-22 13:07:59|‎Sandeep Generative AI WhatsApp Group joined using your invite
~ Akul Jindal|2023-06-22 13:08:34|‎You removed ~ Akul Jindal
~ Karan Sirdesai|2023-06-22 13:08:47|‎You removed ~ Karan Sirdesai
Manas Jain Wadhwani AI|2023-06-22 13:08:58|‎You removed Manas Jain Wadhwani AI
~ Muttu|2023-06-22 13:09:07|‎You removed ~ Muttu
~ Mohnish Landge|2023-06-22 13:09:36|‎You removed ~ Mohnish Landge
~ Anubhav Tiwari (Vicky)|2023-06-22 13:10:10|‎You removed ~ Anubhav Tiwari (Vicky)
~ Khush|2023-06-22 13:10:21|‎You removed ~ Khush
Lohith GenerativeAI WhatsApp Group|2023-06-22 13:10:37|‎You removed Lohith GenerativeAI WhatsApp Group
~ Sangeeth|2023-06-22 13:10:59|‎You removed ~ Sangeeth
Shashwat TDC|2023-06-22 13:11:19|Looks like a busy day for [PHONE] today 😅
Nirant|2023-06-22 13:11:47|Just angry with Docker, but using it productively 😂🙈
~ Manoj|2023-06-22 13:12:36|‎You removed ~ Manoj
~ Prashanth|2023-06-22 13:12:56|‎You removed ~ Prashanth
~ Vin|2023-06-22 13:13:06|‎You removed ~ Vin
Rajesh RS Generative AI WhatsApp Group|2023-06-22 13:13:12|Is there an easy way to not be angry about Kubernetes?
~ Vinod B|2023-06-22 13:13:13|‎You removed ~ Vinod B
Rajesh RS Generative AI WhatsApp Group|2023-06-22 13:13:21|Asking for a friend
~ Karthick Rajagopal|2023-06-22 13:13:24|‎You removed ~ Karthick Rajagopal
~ Anand Raj☃️|2023-06-22 13:13:40|‎You removed ~ Anand Raj☃️
~ Ashin xavier|2023-06-22 13:13:50|‎You removed ~ Ashin xavier
~ rosh|2023-06-22 13:13:57|‎You removed ~ rosh
~ nilabjo|2023-06-22 13:14:06|‎You removed ~ nilabjo
~ Abhirup|2023-06-22 13:14:25|‎You removed ~ Abhirup
~ Joy Mammen|2023-06-22 13:15:36|‎You removed ~ Joy Mammen
~ Shivam|2023-06-22 13:15:47|‎You removed ~ Shivam
~ Steve T|2023-06-22 13:16:02|‎You removed ~ Steve T
~ Jaswanth|2023-06-22 13:16:12|‎You removed ~ Jaswanth
~ Vidyasankar|2023-06-22 13:16:25|‎You removed ~ Vidyasankar
~ Aneesh|2023-06-22 13:16:44|‎You removed ~ Aneesh
~ Phaneendra B|2023-06-22 13:16:52|‎You removed ~ Phaneendra B
~ santhosh|2023-06-22 13:17:02|‎You removed ~ santhosh
Anshul Bhide Replit|2023-06-22 13:17:25|Looks like Nirant's spring cleaning day :D
~ Anirudh Venu|2023-06-22 13:18:36|‎You removed ~ Anirudh Venu
Vaibhav Bhargava Meesho Grab |2023-06-22 13:18:36|Just when you thought lay-off season is behind us
~ Amit Kumar|2023-06-22 13:18:49|‎You removed ~ Amit Kumar
Chinmay Singh Generative AI WhatsApp Group|2023-06-22 13:19:03|‎You removed Chinmay Singh Generative AI WhatsApp Group
~ Siddardha G|2023-06-22 13:19:10|‎You removed ~ Siddardha G
~ ab|2023-06-22 13:19:21|‎You removed ~ ab
~ Kp|2023-06-22 13:19:50|Feeling anxious :D
~ Praveen Sridhar|2023-06-22 13:19:57|Are there folks still waiting for GPT4 API access? Had applied slightly late but still quite a while ago and yet to get access :(
~ Abhijeet|2023-06-22 13:20:00|‎You removed ~ Abhijeet
~ Others|2023-06-22 13:20:09|‎You removed ~ Others
Jaskamal Kainth 2013|2023-06-22 13:20:10|Cache eviction in progress.. :)
~ Kunj Naik|2023-06-22 13:20:21|‎You removed ~ Kunj Naik
~ Jobel Shaji|2023-06-22 13:20:31|‎You removed ~ Jobel Shaji
~ Vipul|2023-06-22 13:20:39|Frantically checking WhatsApp every 10 seconds
~ jvenom 🦥|2023-06-22 13:20:39|‎You removed ~ jvenom 🦥
Ved Chitnis|2023-06-22 13:20:44|Woahhhh 😂😂😂
~ Raveen S|2023-06-22 13:20:47|‎You removed ~ Raveen S
Paras Chopra Wingify|2023-06-22 13:21:00|Haha, it’s like am I next?
~ Ketan Sethi|2023-06-22 13:21:01|‎You removed ~ Ketan Sethi
~ Shreyas Kolte|2023-06-22 13:21:10|‎You removed ~ Shreyas Kolte
Abhinav Verma Longshot.ai|2023-06-22 13:21:11|Yes, you can hire someone else to be angry about it. Side effects, your wallet might not be happy
~ Sudhanshu Heda|2023-06-22 13:21:15|But like what is the criteria?
Chinmay Shah Arrowhead|2023-06-22 13:21:21|reaching out over email might help. That's what we did
~ Nambiar|2023-06-22 13:21:23|‎You removed ~ Nambiar
Pranjal Mehta|2023-06-22 13:21:28|Wonder how many people are messaging rn to ensure recent activity and avoid being kicked
~ GILZON 😎|2023-06-22 13:21:31|‎You removed ~ GILZON 😎
~ Vinit|2023-06-22 13:21:38|‎You removed ~ Vinit
Paras Chopra Wingify|2023-06-22 13:21:45|who was that marvel guy who snapped half the population out of existence
~ Shri|2023-06-22 13:21:48|‎You removed ~ Shri
~ Kp|2023-06-22 13:21:48|Training data has reached cutoff
Paras Chopra Wingify|2023-06-22 13:21:52|[PHONE] is that guy today
~ Aakash Kaushik|2023-06-22 13:21:58|‎You removed ~ Aakash Kaushik
Abhishek Mishra|2023-06-22 13:22:11|Niranthanos
~ Kp|2023-06-22 13:22:24|No more data can Influence nirantgpt now
Paras Chopra Wingify|2023-06-22 13:23:01|<insert nervous laughter noises here/>
Nirant|2023-06-22 13:23:03|"Hello!   As I'd mentioned few weeks ago, we'll be removing inactive users to make room for contributors.  If you see your name or phone number in this ""removal"" list — please remove it: https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit?usp=sharing  That'd indicate to me that you're at least reading some messages :)  PS: Staying on brand, the entire list is generated by ChatGPT"
Chirag Gandhi Trifecta Capital|2023-06-22 13:23:04|Squid Games: GenAI edition
Jaskamal Kainth 2013|2023-06-22 13:23:44|This is still open. Due to time constraint and my use case faster inference requirement, I opted for a different model (flan t5 xl) on 4x.large which gave no issues. Also the inference is very fast and flant5xl seems stable.  Result quality was far better with falcon 7b.
~ Poobesh Gowtham|2023-06-22 13:24:05|‎You removed ~ Poobesh Gowtham
~ Unmesh Raskar|2023-06-22 13:24:20|‎You removed ~ Unmesh Raskar
~ Nishant Shah|2023-06-22 13:24:40|‎You removed ~ Nishant Shah
~ Sayantan|2023-06-22 13:24:51|‎You removed ~ Sayantan
Abhishek Mishra|2023-06-22 13:24:54|What's your exact use case? I know flan family is very good but helps to know which use case is better than Falcon series.
~ Vasu 🥸|2023-06-22 13:24:59|‎You removed ~ Vasu 🥸
Sugam Docyt|2023-06-22 13:25:08|‎You removed Sugam Docyt
~ Kp|2023-06-22 13:25:15|Criteria is essentially dead over a long period. But Nirant has sent in a user removal list which you can remove yourself from
~ yasoob|2023-06-22 13:25:16|‎You removed ~ yasoob
~ Ishan Goenka|2023-06-22 13:25:32|‎You removed ~ Ishan Goenka
Abhishek Mishra|2023-06-22 13:25:51|Probably write a script to look for your name to be a forever lurker 😛
~ Yogesh Ghaturle|2023-06-22 13:25:54|‎You removed ~ Yogesh Ghaturle
~ pds|2023-06-22 13:26:01|‎You removed ~ pds
~ Prithvi|2023-06-22 13:26:11|‎You removed ~ Prithvi
~ Ashray Iyengar|2023-06-22 13:26:22|‎You removed ~ Ashray Iyengar
~ Kp|2023-06-22 13:26:29|Ig lurking is still acceptable if you remove the name :)
~ Chitrak Gangrade|2023-06-22 13:26:32|‎You removed ~ Chitrak Gangrade
Ved Chitnis|2023-06-22 13:26:34|But then they would be an active member no 👀😂
~ Samar|2023-06-22 13:26:42|‎You removed ~ Samar
~ Aaquib Al Hossain|2023-06-22 13:26:51|‎You removed ~ Aaquib Al Hossain
~ Umesh Kumar|2023-06-22 13:26:58|‎You removed ~ Umesh Kumar
~ Sudhanshu Heda|2023-06-22 13:26:58|I mark myself safe during the *Group purge*
Ved Chitnis|2023-06-22 13:27:02|Does WhatsApp not provide APIs for user insights? If they don't they really should
~ Jan|2023-06-22 13:27:06|‎You removed ~ Jan
Kishore GenAI|2023-06-22 13:27:59|Try applying for Microsoft for founders. You get access to their program, which provides azure credits and openAI as well. Maybe that can work. https://foundershub.startups.microsoft.com/
Rajesh RS Generative AI WhatsApp Group|2023-06-22 13:28:10|Viable Twitter based business model
~ Kp|2023-06-22 13:28:19|I'm in it but that just awards credits
~ Kp|2023-06-22 13:28:20|Not gpt 4 access afaik
Chinmay Singh Generative AI WhatsApp Group|2023-06-22 13:28:35|‎You added Chinmay Singh Generative AI WhatsApp Group
Paras Chopra Wingify|2023-06-22 13:29:13|Keeping access to this group has become more difficult than getting Claude access, thanks to Niranthanos
~ Kp|2023-06-22 13:29:25|It awards openai credits (2.5k usd) for use in openais api, and 1k in azure credits which you can use in azure openai service (this is ideate level stage)
~ Kp|2023-06-22 13:29:55|Wait Nirant added someone🤯 ig cleanup is over
~ Sudhanshu Heda|2023-06-22 13:29:58|[PHONE] made his way back 🗣️
Chinmay Singh Generative AI WhatsApp Group|2023-06-22 13:32:47|Anyone here who has faced Quota limit with OpenAI. How are you guys solving it, it is just by using multiple accounts or anyone has found something different for that?
Adithya S K PESIT|2023-06-22 13:32:48|I never received my 2.5k open ai credits
~ Kp|2023-06-22 13:33:08|You have to avail the benefit in the founders portal I believe
~ Unni|2023-06-22 13:33:09|‎You removed ~ Unni
Ankur Pandey|2023-06-22 13:33:32|Use tools like https://nas.io/whatsapp ? (not used, no affiliation)
~ Nishant Bhansali|2023-06-22 13:33:36|‎You removed ~ Nishant Bhansali
~ Manav Shah|2023-06-22 13:33:44|‎You removed ~ Manav Shah
Adithya S K PESIT|2023-06-22 13:33:57|yeah I did I also mailed both open ai and Microsoft support both told ETA is not confirmed
~ Siddhartha|2023-06-22 13:34:02|‎You removed ~ Siddhartha ‎[6/22/23, 13:34:11] Adithya S K PESIT: ‎sticker omitted
Swapnika Hashmail Web3|2023-06-22 13:34:34|Might help to just sort this list alphabetically :)
~ Ujjwal Trivedi|2023-06-22 13:34:43|‎You removed ~ Ujjwal Trivedi
~ Ved Khandekar|2023-06-22 13:34:54|‎You removed ~ Ved Khandekar
~ Kp|2023-06-22 13:34:57|Oh. I actually never availed the openai credits. I thought of saving them for a usecase my startup might need later. Rn I'm just playing around with free credits and gpt+
~ Chinmay Talegaonkar|2023-06-22 13:35:03|‎You removed ~ Chinmay Talegaonkar
~ Saumil Agarwal|2023-06-22 13:35:12|‎You removed ~ Saumil Agarwal
~ Kp|2023-06-22 13:35:23|That's sad
~ Rohin Siddhartha|2023-06-22 13:35:29|‎You removed ~ Rohin Siddhartha
~ Kp|2023-06-22 13:35:29|I thought they provision it like they did the azure credits
Adithya S K PESIT|2023-06-22 13:35:33|yeah I am using azure open ai for all my prototypes
~ Venkatesh|2023-06-22 13:35:40|‎You removed ~ Venkatesh
Adithya S K PESIT|2023-06-22 13:35:57|there are many ppl facing the same problem
~ ayush saraswat|2023-06-22 13:36:12|‎You removed ~ ayush saraswat
~ Kp|2023-06-22 13:36:20|Since you're in the foundershub, would you mind telling me which stage you've reached?
Nitin Mahajan McKinsey|2023-06-22 13:36:49|Same here. Applied from both of my companies with real logical reasons but nothing but silence as dark as deep space :)
~ Kp|2023-06-22 13:37:16|I believe we can reach growth stage but the main barrier for me is incorporation in 2nd stage itself :(
~ Udit|2023-06-22 13:37:23|‎~ Udit requested to join
Ankur Pandey|2023-06-22 13:37:26|Cluster removal among discussion reminds of the last dinner scene of Don't Look Up 🫨
Adithya S K PESIT|2023-06-22 13:37:38|oh created dummy start up just to get azure credits  so I am still in the first stage the ideation one
~ Kp|2023-06-22 13:37:44|Ah ok ‎[6/22/23, 13:38:08] Abhishek Mishra: ‎GIF omitted
~ Kp|2023-06-22 13:38:33|Yea the credits are definitely useful :). But I believe they require you to use them In a tenant and not personal account
Nirant|2023-06-22 13:40:42|Pausing now. Stopped with 256 people to go. Felt like an shubh number
~ Rita Panchal|2023-06-22 13:42:09|‎~ Rita Panchal requested to join
~ Ashish|2023-06-22 13:46:42|‎~ Ashish requested to join
Kaushik Bokka|2023-06-22 13:46:46|seemed fun
Nirant|2023-06-22 13:48:23|Not at all 😭
Nirant|2023-06-22 13:48:36|You're free to pick up the next 256 and give it a spin 😅
Abhinav Verma Longshot.ai|2023-06-22 13:48:47|You can request higher. Your app must be doing well to have that many requests. You might need to request
Kaushik Bokka|2023-06-22 13:50:35|any programs where I could apply for Stability AI api credits as a startup?  Similar to Vercel AI accelerator
Kaushik Bokka|2023-06-22 13:52:22|or wondering if Midjourney has a closed group of folks to use their official api
Sandya Mannarswamy|2023-06-22 13:52:31|Saw this thread reverse engineering gpt-4 speculated param number..   https://twitter.com/philipturnerar/status/1671698274246377478?s=20 ‎[6/22/23, 13:52:44] ~ Sudhanshu Heda: ‎GIF omitted
Akash Kuttappa Flipkart PM|2023-06-22 13:55:31|Midjourney does have an app that a closed group of folks have been given access to, but an API within it hasn’t been spoken about in their office hours from my understanding.
~ Heerthi Raja H - AI/ML|2023-06-22 13:55:40|‎~ Heerthi Raja H - AI/ML requested to join
~ Preet Garach😎|2023-06-22 13:58:19|‎~ Preet Garach😎 requested to join
~ Aravind|2023-06-22 14:08:37|edit access is not there how to remove ?
Krishna Ntkris|2023-06-22 14:10:30|We're leveraging retrieval augmented generation for our product. Noticed that prompts that work for GPT3.5 don't work for GPT4. Has anyone else seen this? I've seen people mention differences but was a little surprised as this is a fairly simple use case.
Sandeep Srinivasa RedCarpetup|2023-06-22 14:13:45|yes. there is very less commonality between the prompts that work for 3.5 and 4.  which is why there is a blow up of prompts X chains X llms.
Krishna Ntkris|2023-06-22 14:14:54|Any suggestions / materials I can look at to tune prompts specifically for each model?
Pratik Bhavasar|2023-06-22 14:19:09|In the article by Humanloop, author wrote OpenAI plans to use quantisation
~ Sachin Patalasingh...|2023-06-22 14:19:21|‎~ Sachin Patalasingh... left
Abhinav Verma Longshot.ai|2023-06-22 14:20:21|There was something shared earlier about the 3.5 turbo models being quantised
Sandya Mannarswamy|2023-06-22 14:21:10|Thanks, i have not seen that article, can you pls share link? Is this the sama interview article where he mentioned open sourcing a smaller model?
Abhishek Mishra|2023-06-22 14:24:15|This was the article shared by another member of the group earlier - From Sama’s chat w Co-founder of Humanloop - https://web.archive.org/web/20230531203946/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans
Abhishek Mishra|2023-06-22 14:24:38|The original article is removed so this one is an archive
Pratik Bhavasar|2023-06-22 14:26:21|Seems you bookmarked 😬
~ Arko Cy|2023-06-22 14:27:17|Noicee 👍
Sandya Mannarswamy|2023-06-22 14:33:29|Thank you
Shubham Sharma 2012C6|2023-06-22 14:50:35|Emerging architecture for Llm apps via a16z https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/
Nirant|2023-06-22 14:54:30|Good read for most people ramping up right now. Strong recommend.
~ Nitish Alodia|2023-06-22 14:56:43|They have also released JS stack for prototyping AI projects - https://github.com/a16z-infra/ai-getting-started
Sandya Mannarswamy|2023-06-22 14:57:07|There was one from sequoia a week back which was more business focussed   https://www.sequoiacap.com/article/llm-stack-perspective/
Sandya Mannarswamy|2023-06-22 15:00:41|#openai triton - any idea how much is the interest in writing custom  DL kernels in triton outside openAI? I haven't seen much activity in GitHub on this from folks outside openai. And any comparison between this and mojo from modular.ai(Chris lattner)?
Nirant|2023-06-22 15:01:33|Mojo isn't FOSS, and has no DL kernels yet to the best of my knowledge. They don't even have CUDA support?
~ Tarun|2023-06-22 15:02:51|https://twitter.com/gokulr/status/1671594605886976000
Sandya Mannarswamy|2023-06-22 15:06:08|They had a few sample dl operator implementations in their YouTube videos,  Reg Cuda support, how are they doing GPU HW abstraction? - Direct metal support?
Sandya Mannarswamy|2023-06-22 15:06:40|My guess was they would have a lowering from mojo thru mlir to ptx?
Nirant|2023-06-22 15:07:02|Aah, I'd missed the Youtube video. Would you mind sharing the link if you've it handy?
Sandya Mannarswamy|2023-06-22 15:07:37|It was a couple of months ago. Will search and send.
ashish Acgt01 Twitter|2023-06-22 15:18:34|Here is the keynote   https://youtu.be/-3Kf2ZZU-dg?t=1987
~ Chirag Ginglani|2023-06-22 15:19:09|Not directly related to GenAI, but has anyone here evaluated Hevo and Fivetran? Wanted first hand feedback / comparison of the two pipeline platforms. Pls DM
Abhishek Maiti|2023-06-22 15:49:58|Before this what did the folks here use to spin up a quick prototype and host it (a non gpu setup)? Really overwhelmed with all the webdev stack, coming from a ML background.
Abhishek Mishra|2023-06-22 15:55:58|Streamlit and Gradio may cover most of your demo needs in python stack
ashish Acgt01 Twitter|2023-06-22 15:56:12|Hf gradio , streamlit  But haven't built anything production grade yet, so curious what others use
Abhishek Maiti|2023-06-22 15:58:49|I was looking for production grade, but nothing fancy but a basic html with backend with few pages and login support. I started learning flask, but feels like if there was a some good template kind of language to quickly fill in the bits, would save a lot of time.
Abhishek Maiti|2023-06-22 15:59:27|I am really in awe of the twitter indie devs (pieter etc) who do all of this single handedly.
~ Pranay Desai|2023-06-22 16:00:34|also check Atri labs which is an Indian founding team
~ Pranay Desai|2023-06-22 16:00:35|https://github.com/Atri-Labs/atrilabs-engine
ashish Acgt01 Twitter|2023-06-22 16:02:21|https://gradio.app/sharing-your-app
Sandeep Srinivasa RedCarpetup|2023-06-22 16:07:41|we are trying to build the opensource production-ready SDK here (open source of course). am probably a week away, but happy to send it to you when up.
Abhishek Maiti|2023-06-22 16:10:05|Thanks for all this pointers, I will check them out. Sure [PHONE] I am looking forward to that, you will save me a lot of time!
Sandeep Srinivasa RedCarpetup|2023-06-22 16:12:47|well, i dont know if i can claim to be all that grand !  our only stand is that Gen-AI applications are a configuration management problem. Everyone is probably trying to model it as a UI or a code management problem. prompts X chains X LLMs is where it blows up in config management. what we are trying to do is base it on the same core as kubernetes, so that we streamline the config and the pipelines first.
Aayush Jain AWS|2023-06-22 17:01:54|‎You added Aayush Jain AWS
~ Nandini|2023-06-22 17:28:23|‎~ Nandini left
~ Paulfinneyx|2023-06-22 18:54:42|‎~ Paulfinneyx requested to join
~ Krishna|2023-06-22 19:09:10|Do we get kicked for not interacting here?
Lalit Pagaria|2023-06-22 19:11:36|This is really frustrating. I miss consistency: given the same inputs (text, and params) will always give you same output
Adithya S K PESIT|2023-06-22 19:13:54|Hey does anyone know how to request for more quota for vms in azure ML studios ,to get A10 or A100 every time I request for quota they say the following  ``` For the foreseeable future, we are not approving quota requests for these Azure virtual machines: NC Series. These VMs do not run our latest generation infrastructure and we are directing customers who request additional quota for these v1 VMs to consider creating a new pay-as-you-go subscription to explore expanded access to newer generation VM Series in the US East (EUS) region. ```
Nirant|2023-06-22 19:29:59|Yes
~ Yash More|2023-06-22 19:37:33|https://crfm.stanford.edu/2023/06/16/anticipatory-music-transformer.html  Tags: Symbolic music generation, infilling. Interesting for people looking to use music-transformers for co-composition.
Nirant|2023-06-22 19:39:13|cc [PHONE] can you help?
Shubham Arora|2023-06-22 19:39:49|‎You added Shubham Arora
Nirant|2023-06-22 19:40:16|cc Shubham [PHONE] for all questions AWS including Bedrock, Code Whisperer etc
Swapnika Hashmail Web3|2023-06-22 19:40:23|Not just between 3.5 & 4, we’ve had to revamp our prompts with every new update for 3.5. I’m praying it becomes more consistent soon enough.
Bharat Kumar Ramesh Hashmal Web3|2023-06-22 19:41:11|Gets even worse when you use functions or ask it to return structured outputs
Bharat Kumar Ramesh Hashmal Web3|2023-06-22 19:41:32|The deviations are quite high. Don't have quantifiable data on it, but qualitatively, you need to rework a lot of the prompts
Lalit Pagaria|2023-06-22 19:42:55|Yes true and they upgrade it without much headroom for you to plan the migration.
Swapnika Hashmail Web3|2023-06-22 19:44:22|Prompt engineering is truly like playing whack a mole :)
~ Nitin Kishore|2023-06-22 19:45:14|You can use the hack to make chatgpt act as prompt gpt. And then it would generate the prompts for you
~ Nitin Kishore|2023-06-22 19:45:49|Interesting
~ Arul Murugan|2023-06-22 19:46:20|‎~ Arul Murugan requested to join
Rajesh RS Generative AI WhatsApp Group|2023-06-22 19:46:23|I think someone mentioned streamlit already. I use it often and love it. Haven't used gradio as much as I want to though. What is preferable for a production grade app? Let's say that we need a smallish footprint as far as possible, responsive interfaces - which of these two works well? Or do we just use a custom react app of some kind?
~ Arul Murugan|2023-06-22 19:46:25|‎~ Arul Murugan joined using this group's invite link
~ Nitin Kishore|2023-06-22 19:48:04|Isn't that the expected behavior tho, when you update a model and train it on more recent data?
Dev Aggarwal|2023-06-22 19:49:25|We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon
Dev Aggarwal|2023-06-22 19:49:37|Something on streamlit*
Abhinav Verma Longshot.ai|2023-06-22 19:53:07|Not seen this
Ambarish Ganguly|2023-06-22 19:54:03|Streamlit has problems in scaling you may try simple flask or any simple framework on kubernetes container apps aks and blah
Anil Chandra Naidu Matcha|2023-06-22 19:54:20|what problems streamlit has with scaling
Ambarish Ganguly|2023-06-22 19:55:49|Try file upload and make aks multiple node you may see errors
Ambarish Ganguly|2023-06-22 19:56:22|It is a known error which you will find in forums acknowledged by streamlit
Ambarish Ganguly|2023-06-22 19:56:35|They may solve it later
Anil Chandra Naidu Matcha|2023-06-22 19:57:39|so the issue is only with file upload, not with scaling ?
Ambarish Ganguly|2023-06-22 19:57:43|I got this problem and switched to flask
Abhishek Mishra|2023-06-22 19:57:56|I think these python web frameworks like Streamlit, Pynecone, Dash, Gradio are good for fast prototyping and  quick time-to-market if they match your use case.  But one would need to switch to more robust or popular frameworks if they want to scale and customise.
Ambarish Ganguly|2023-06-22 19:58:42|This was the problem I faced  which was basic .
Ambarish Ganguly|2023-06-22 20:00:28|Moreover this is a manifestation of a problem. The root cause is something more than file upload which I should have remembered but forgot
Ambarish Ganguly|2023-06-22 20:01:25|Streamlit I use very extensively for my POC and demos to articulate something
Ambarish Ganguly|2023-06-22 20:01:41|Much better than presentations
Paras Chopra Wingify|2023-06-22 20:02:07|Goodhart’s law will kick in pretty soon :)
Abhishek Mishra|2023-06-22 20:02:16|Same, very fast uptime for POCs and demo.
Ambarish Ganguly|2023-06-22 20:03:33|By this time all might.have realised that I am a fan of Streamlit and it is a boon for people who struggle with JS frameworks and HTML CSS
Abhishek Mishra|2023-06-22 20:07:20|JS frameworks are my antithesis 😂
Rajesh RS Generative AI WhatsApp Group|2023-06-22 20:27:53|That’s awesome. Looking forward to it
Dev Aggarwal|2023-06-22 20:28:40|https://gooey.ai/explore/  Streamlit rewrite 🙈
Rajesh RS Generative AI WhatsApp Group|2023-06-22 20:30:04|Exactly. That’s my experience with streamlit at least. Plotly dash is interesting too but beyond simple dashboards I haven’t built anything major with it. There are even very involved and hard core R Shiny apps out there. Depending on the use cases it may suffice for some teams. But streamlit is great for quick prototypes and proof of concepts.
~ Vatsal Shah|2023-06-22 20:31:28|‎You added ~ Vatsal Shah
Dev Aggarwal|2023-06-22 20:33:49|There’s one design flaw with all 3 of these tools, and literally everone who’s built a python frontend framework has made too - to store per client session state on server over a websocket. This makes scaling impossible and client bundles huge for time to first render
Abhishek Mishra|2023-06-22 21:06:12|How do you handle customisation? Is it possible to add responsive new components or modify components without knowledge of React js?
~ Madhav Singhal|2023-06-22 21:18:13|https://huggingface.co/mosaicml/mpt-30b
Sachin Legaltech|2023-06-22 21:21:49|Seems damn cool. 8k context length. And beats almost all other open source LLMs expect WizardCoder on HumanEval.
Nirant|2023-06-22 21:22:43|Mosaic has an unreliable history of changing license after release. Buyers beware
~ Deepesh|2023-06-22 21:25:22|‎~ Deepesh joined using your invite
Ankita Mathur Microsoft Sales|2023-06-22 21:27:09|Checking with my Infra team
Sachin Legaltech|2023-06-22 21:30:28|Base model is still apache. Their chat and instruct models are cc-by-nc. Chat model is finetuned for 1.5B tokens for 6 epochs, so total 9B tokens.  Someone else might soon finetune on some other mixture of dataset. Hopefully something like WizardMPT.
~ Vishwam Jindal|2023-06-22 21:46:00|Facing an issue with the utilization of the s3boto library in the langchain system. The library's unstructured file loader fails to effectively process files with formats such as PDF or any other file extension. As a result, there is no feasible method to stream S3 files into the system, taking into account their file types, and generate embeddings.  Additionally, the problem persists with the storage of pgvector embeddings within the database. These embeddings are stored in a specific manner, making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component. The data storage approach directly affects the accuracy and effectiveness of the GPT chat system's queries.  Some guidance would be helpful.
Abhishek Mishra|2023-06-22 22:03:18|And even the base model trained on datasets that have a bundle of licences. 2 of the 3 core datasets are ODC-BY and 1 - stack dedup is a bundle of licences which isn't clear from HF info
Abhishek Mishra|2023-06-22 22:03:59|The chat and instruct models are still CC by NC so nothing changes there for commercial use.
~ Vishwam Jindal|2023-06-22 22:42:16|https://inflection.ai/inflection-1
Abhishek Mishra|2023-06-22 23:00:52|Wow they're claiming they outperform even GPT3.5 on MMLU, PiQA, Hellaswag, boolq, naturalQA and GSM8k ‎[6/22/23, 23:01:16] Abhishek Mishra: Inflection-1.pdf • ‎7 pages ‎document omitted
ashish Acgt01 Twitter|2023-06-22 23:03:20|came across these 2 useful links : 1. bunch of ai related resources in 1 place: https://llm-utils.org/AI+Learning+Curation  2. hf nlp course https://huggingface.co/learn/nlp-course/chapter1/1  (via https://news.ycombinator.com/item?id=36432598 ) ‎[6/22/23, 23:07:41] Dr. Pratik Desai KissanGPT: ‎image omitted
~ Sudhanshu Heda|2023-06-22 23:12:25|7 pager memos ftw 🙌
Abhinav Verma Longshot.ai|2023-06-22 23:29:22|https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html Am starting out with knowledge graph indexes, what are some good resources to get started
Dr. Pratik Desai KissanGPT|2023-06-22 23:36:32|they should publish the model card instead of marketing keywords.
Abhinav Verma Longshot.ai|2023-06-22 23:37:06|Have they generated the keywords using the model though?
Abhishek Mishra|2023-06-22 23:40:54|They're calling inflection-1 to be in the same compute class as gpt 3.5 and palm 540B. Also 1000s of H100 would mean that their size is huge, probably upwards of 200B? can only speculate.
Arvind N Generative AI Group|2023-06-23 00:20:17|I'm not sure how many people here are familiar with GOFAI techniques. There is a lot of history to symbolic AI which was powering lots of simple systems before Alex and Ilya showed how to train NNs more efficiently. We have reached a point where there are 2 broad approaches in front of us and it's not clear which one will lead to AGI sooner: 1. *Introduce symbolic AI modules as interfaces to NNs*. This is easy with LLMs because Symbolic methods like KG triplets, classical algorithms (planning/search), on-the fly code generation etc. can output text which can be fed directly into the context window of the LLM. People have started with first order logic and you'll soon witness more classic modules like second and higher order logic being interfaced with LLMs. This is the bleeding edge of AI reasearch as of June 2023. 2. *Train bigger LLMs with more carefully curated datasets like textbooks, code repos*: This is the kind of evolution Ilya talks about - that it might be possible to see reasoning capabilities emerge more strongly as we scale. It is also possible that the data requirements may not be as high as what it took to get to ChatGPT or GPT4. There are a handful of teams who are taking this approach as we speak. Approach #1 is something many of us in this group can attempt. Classical methods are well defined and the Russell-Norvig textbook is a great place to start. You may also want to look up ideas in GOFAI projects such as Doug Lenat's CYC which took the path from KG to higher order logic modules eventually leading to a sort of semantic web. Happy to share more info if anyone is interested in this line of research.
Abhishek Mishra|2023-06-23 00:30:05|For #1, I found a overview/survey paper from 2022 - https://academic.oup.com/nsr/article/9/6/nwac035/6542460   Not sure if I can do a toy training with GPT2 with this system but I would like to give it a try sometime
Abhishek Mishra|2023-06-23 00:34:51|I'm also interested in being able to teach an abstraction to a language model directly, rather than train things via unstructured data or instruction format. A language model is representative of the abstract relationship between different entities and concepts in the training data, so I was thinking if I can draw out the abstraction or update the abstraction directly via some reasoning inputs.  This isn't a well formed or grilled idea.
Sandeep Srinivasa RedCarpetup|2023-06-23 00:45:49|"could u explain the two problems ur facing ?  what is the issue with s3boto - are u trying to chunk and create embeddings from pdf files in s3 ?  and what did u mean by ""making it challenging to establish an optimized collection that efficiently stores and retrieves vectors for the retriever component"" ?"
Pranjal Yadav Razorpay|2023-06-23 01:21:00|Need advice on two things 1. How to implement streaming generation from scratch?  2. Has anyone successfully generated text + code (like chatgpt) with reasonable performance? Does code block identification and generation work for with fine tuning and what models are best for it?
Abhinav Verma Longshot.ai|2023-06-23 01:22:07|Are you wanting to implement streaming with openai models or with other models
Pranjal Yadav Razorpay|2023-06-23 01:24:42|Local model, say falcon or llama
Abhinav Verma Longshot.ai|2023-06-23 01:34:37|https://huggingface.co/blog/sagemaker-huggingface-llm This is there for inference servers.
Pranjal Yadav Razorpay|2023-06-23 01:46:34|I checked this post. It abstract the implementation and gives the container for deployment purposes. I'm interested in learning the mechanics of it but thanks anyway. ‎[6/23/23, 02:01:53] ~ Abhiram Ravikumar: ‎image omitted
~ Abhiram Ravikumar|2023-06-23 02:01:54|I've been working on a few use cases where LLMs can help non profits and charity events, is anyone else working on similar areas? happy to join forces
Aditya Sista 2010B5|2023-06-23 02:55:58|Would something like chain of thought prompting and ReAct etc be considered to come from symbolic AI?
~ Siddish|2023-06-23 06:53:52|https://twitter.com/OfirPress/status/1672021765135151107?s=20 on increasing context length of existing models by a brilliant hack
~ Vishwam Jindal|2023-06-23 07:53:02|DMing you
Arvind N Generative AI Group|2023-06-23 08:03:01|"Interesting question, but CoT is not really GOFAI which are highly interpretable. Tree of thoughts is more closer to a GOFAI module where a clear algorithm (just handcrafted heuristics) is driving the control back and forth between the LLM and a DFS/BFS tree parser. ReAct, Flare and other lookup methods help with information reuse. I see them as external memory modules, not compute. Here is an example of how I personally see a successful GOFAI module integrated with an LLM: 1. User sends question to LLM 2. LLM checks if question is mathematical or factual. If Mathematical, it sends it to a plugin(wolfram alpha) or a code generation module and retrieves the answer 3. LLM formats the final output In this example, the LLM had to rely on an external module to calculate something. Now the LLM could use another external module to store/retrieve this information. For most ""system-2"" thinking modules (see Kahneman) it is not hard to use a GOFAI method as a plug-and-play module. This leads to the question: How many such functions are there which require us to supplement the LLMs with external programs? A good place to start thinking about this would be Marvin Minsky's book - The society of mind. I'm not sure if AGI questions are appropriate in this forum since the discussions tend to dwell on practical applications. But happy to discuss offline with anyone interested in the nature of intelligence, neuroscience basis to AI etc."
Kiran Darisi AtomicWork|2023-06-23 08:55:37|‎Ravi Theja added Kiran Darisi AtomicWork
~ Shanthi Vardhan|2023-06-23 09:24:21|‎Ravi Theja added ~ Shanthi Vardhan
~ Happy Chaudhury|2023-06-23 10:38:43|Not tried yet , any link how to start with RAG plus gpts (one concern here documents are to be  private)
Saurabh Karn Nyai|2023-06-23 10:41:18|You should checkout jugalbandi repo (https://github.com/OpenNyAI/jugalbandi-api)  This uses fastAPI so you can quickly host it on your own server, configure your OpenAI API Key and done. Then what remains to be done is uploading the document and asking query.  The chunking vectorisation and creating prompt to send OpenAI requests to generate response is already written in code base.
Dev Aggarwal|2023-06-23 10:44:24|Which asr APIs does this use?
Saurabh Karn Nyai|2023-06-23 10:46:47|Bhashini by default but it support Google and Azure as well
~ Vatsal Shah|2023-06-23 10:48:32|‎~ Vatsal Shah left
Dev Aggarwal|2023-06-23 10:50:27|Wait a  sec, https://asr-api.ai4bharat.org/asr/v1/recognize/ takes no api key?
Dev Aggarwal|2023-06-23 10:53:37|https://github.com/OpenNyAI/jugalbandi-api/blob/bf28c720719f211d28f3239fc55835e267e0a7cf/translator.py#L58
Saurabh Karn Nyai|2023-06-23 10:53:46|nope
Samanyou WriteSonic|2023-06-23 10:54:31|Does anyone know if there is a way to export Pinecone indices and/or collections?
Samanyou WriteSonic|2023-06-23 10:54:54|We are looking to move out of Pinecone to qdrant and it would be a pain if we have to re-embed all the data again.
Dr. Pratik Desai KissanGPT|2023-06-23 10:55:13|I’m not sure what is [PHONE]’s experience is but for me both on-premise and APIs didn’t work out in production. Didn’t work out means consistent latency wise. I’m not sure if they added more resources after that, so it could have changed.
Saurabh Karn Nyai|2023-06-23 10:56:10|Don't know how to but curious what lead you to this decision? Might be useful for others as well.
Saurabh Karn Nyai|2023-06-23 10:57:39|I would not recommend Bhashini for APIs for production as it is Govt. of India's project and they are building and hosting a GPU cluster. My recommendation would be to move to Azure for this. It has good coverage of language and has better quality as well.
ashish Acgt01 Twitter|2023-06-23 11:03:55|For production grade, speech models for low resourced indian languages like Bhojpuri or Haryanvi, what would you suggest Saurabh ?
Dev Aggarwal|2023-06-23 11:04:51|Azure has better speech to text for indic languages? 😵
Pratik Bhavasar|2023-06-23 11:06:10|It would be useful to have a primary DB where all of the indexed data is stored. Seems you are on OpenAI emb. Moving to open source emb will eliminate reindex cost issue. But that’s a research effort.
Saurabh Karn Nyai|2023-06-23 11:06:44|Na na. Wait. 😅 multiple things, model quality, GPU availability. My recommendation isn’t with respect to just model quality but also production readiness
Dev Aggarwal|2023-06-23 11:07:37|Ok sorry talking about model quality 😅
Samanyou WriteSonic|2023-06-23 11:07:42|We are not seeing good retrieval quality on Pinecone for a production level system. When embedding thousands of documents, it is giving irrelevant results.  Same thing with other vector dbs is working well. Also, we need hybrid search.
Dr. Pratik Desai KissanGPT|2023-06-23 11:08:28|That's why we moved completely to Azure like two months back, and have Bhasini, and GCP as first and second backups. I have talked to Azure speech research team and also heard from other folks using Azure. Other reason being MS team working closely with Bhasini.
Dr. Pratik Desai KissanGPT|2023-06-23 11:09:23|How ever we signed MoU with Intel where they want to help on scale for Bhasini, and then working with some Indie hacker folks to see If I can optimize Bhasini models for production.
Samanyou WriteSonic|2023-06-23 11:09:36|Yes, we are using OpenAI embeddings. Haven't tried the other embeddings yet. How does it compare in terms of the quality?
Sandeep Srinivasa RedCarpetup|2023-06-23 11:10:21|why would u need to re-embed the data ? genuine question - does pinecone transform the data formats to make it non portable ?
Pratik Bhavasar|2023-06-23 11:10:43|I doubt it should be because of the vector DB but probably because of the library you are using or some implementation bug. ‎[6/23/23, 11:11:27] Rajesh RS Generative AI WhatsApp Group: ‎image omitted
Samanyou WriteSonic|2023-06-23 11:11:28|As in we need to export the embeddings out of Pinecone so we can migrate them to a different vector db. Seems they dont allow exporting the collections, in which case we would have to embed the data again to be put into the new vector db.
Pratik Bhavasar|2023-06-23 11:11:35|And pinecone also has hybrid search
~ Happy Chaudhury|2023-06-23 11:11:44|But openai api does it keep docs private,here concern is they don't want to use chatgpt or openai as it's legal documents it might get leaked..not sure
Dr. Pratik Desai KissanGPT|2023-06-23 11:11:55|I don't have bandwidth to work on models for quantization or oprimization, so I am taking help from any where possible. Bhasini should be optimized for production and we should be able to host and run optimally, otherwise all the hoopla after Sama's comment will be just chest bumping.
Pratik Bhavasar|2023-06-23 11:12:10|Similar metrics as per benchmarks but would still require testing to see if it’s actually true
Sandeep Srinivasa RedCarpetup|2023-06-23 11:12:30|i did NOT know that pinecone doesnt allow export.
Samanyou WriteSonic|2023-06-23 11:12:41|That's something we are testing out as well. But also in general pinecone hybrid search is not as seamless to implement as the one on qdrant or weaviate.
Samanyou WriteSonic|2023-06-23 11:13:22|Right, will try that.
Pratik Bhavasar|2023-06-23 11:14:41|Are you referring to the tokeniser problem? Pinecone also has support for SPLADE which would bump performance hopefully. I don’t know if others have it
Pratik Bhavasar|2023-06-23 11:15:51|SPLADE hybrid > Emb model tokeniser hybrid > simple tokeniser hybrid
Samanyou WriteSonic|2023-06-23 11:23:17|https://www.pinecone.io/learn/hybrid-search-intro/
Sandeep Srinivasa RedCarpetup|2023-06-23 11:23:39|What do u mean by pinecone has support for a tokeniser ? Cos tokenisation and embedding generation would happen BEFORE insert into vector db.
Samanyou WriteSonic|2023-06-23 11:23:39|It seems to be in private preview right? Have you tried it?
Sandeep Srinivasa RedCarpetup|2023-06-23 11:24:23|Any db would be agnostic to the input tokeniser u use to split your data right ?
Pratik Bhavasar|2023-06-23 11:25:18|I haven’t tried it yet. It’s a 3 month old blog and I think it must be GA now.
Pratik Bhavasar|2023-06-23 11:28:20|In my understanding, Pinecone supports sparse vectors which allows indexing with any tokeniser while the other ones does not expose this and handle tokenisation internally for hybrid.
Abhishek Mishra|2023-06-23 11:29:15|Yeah, there was also some nvidia research in this area last year. It was SoTA at that time but don't know the current status for eye positioning.
Pratik Bhavasar|2023-06-23 11:29:45|For hybrid you need one hot token vectors also to be indexed
Abhishek Mishra|2023-06-23 11:30:28|You can come as you please but you can't leave the same 😂 If you stay and build everything on pinecone so that migration costs become incredibly high, how would anybody leave
Samanyou WriteSonic|2023-06-23 11:33:06|Getting quite costly too
Dr. Pratik Desai KissanGPT|2023-06-23 11:34:26|I don't know why anyone will choose Pinecone. Any serious developers I know have left them longtime back. Every other OSS one has enough documentation now.
Pratik Bhavasar|2023-06-23 11:34:35|Do Qdrant and Weaviate allow export?
Samanyou WriteSonic|2023-06-23 11:34:47|Qdrant does I believe
Kishore Nallan|2023-06-23 11:34:55|Hi Saman, I'm the co-founder of Typesense (https://github.com/typesense/typesense). We support hybrid vector search in the upcoming version and as well as automatic embedding of content using E5 model (both on CPU and GPU). Happy to chat about it or anything related to embeddings/search.
Samanyou WriteSonic|2023-06-23 11:35:29|We just went with them because they seemed the most prod ready but at this point probably a good idea to move out
Pratik Bhavasar|2023-06-23 11:37:37|Did not find anything on google!
Anil Chandra Naidu Matcha|2023-06-23 11:39:01|How to solve this issue
Pratik Bhavasar|2023-06-23 11:39:05|Which open source solution do they prefer?
Dr. Pratik Desai KissanGPT|2023-06-23 11:39:58|I like and use weaviate
Abhishek Mishra|2023-06-23 11:40:33|"Dev mentioned this yesterday as what they implemented - ""We built someone on streamlit, but it broke down under too many users. So I rewrote streamlit in remix to do server sider rendering and removed websockets. Open sourcing soon"""
Dev Aggarwal|2023-06-23 11:40:40|Store state on the client and do server side rendering. I’m using HTML forms too for state so it all works even after disabling Javascript
Samanyou WriteSonic|2023-06-23 11:40:43|Hey Kishore, happy to test it out. Is anyone else using this on prod right now?
Anil Chandra Naidu Matcha|2023-06-23 11:41:30|but how to do streaming in that case ?
Abhinav Verma Longshot.ai|2023-06-23 11:41:54|You underestimate marketing. Also openai pinecone arrangement
Dev Aggarwal|2023-06-23 11:42:24|Redis pub/sub + server sent events
Abhinav Verma Longshot.ai|2023-06-23 11:43:20|Isn't pub/sub a 2 way communication and server sent one way communication?
Kishore Nallan|2023-06-23 11:43:46|We have had pure vector search for over a year and so many production users. We've implemented hybrid search for the next version (due for release in a few weeks) and we have been testing the RC build with customers, some of whom are using it on production as well. We also support openai and google vertex embedding integration out of the box. I can share details on DM.
Dr. Pratik Desai KissanGPT|2023-06-23 11:43:54|I was recommended to use weaviate by OpenAI from the early days of KissanAI 🤷‍♂️
Abhinav Verma Longshot.ai|2023-06-23 11:44:41|When was this? The pinecone partnership came out in March with the launch of plugins
Dev Aggarwal|2023-06-23 11:45:20|Yes. But only use redis as one way publish to push to clients from long running tasks in the server
Dr. Pratik Desai KissanGPT|2023-06-23 11:45:22|Before that
Abhinav Verma Longshot.ai|2023-06-23 11:45:38|Cool
Abhinav Verma Longshot.ai|2023-06-23 11:46:27|Pinecone had done a huge announcement of their partnership in March and later also raised a ton on money. I'm assuming for marketing purposes
Abhinav Verma Longshot.ai|2023-06-23 11:47:08|Yes. Had used in an earlier project which involved rabbitmq
Samanyou WriteSonic|2023-06-23 11:52:20|What vector db is recommended to use for prod right now?
Samanyou WriteSonic|2023-06-23 11:52:50|Also, for open source dbs, are folks self hosting or using hosted versions?
Rajesh RS Generative AI WhatsApp Group|2023-06-23 11:52:56|Related question - how does Pinecone compare to the likes of Milvus, Weaviate?
Samanyou WriteSonic|2023-06-23 11:54:56|Also, has anyone tried Mongo vector db yet? Any benchmarks?
Saurav Akaike|2023-06-23 11:55:50|Is there a good study published on what different GenerativeAI companies are doing currently and what kinds of trends are emerging across? Preferably not from a VC's perspective
Anil Chandra Naidu Matcha|2023-06-23 11:57:18|Interested for the same, currently using pinecone for testing but want to move out before getting locked in some way
Shashwat TDC|2023-06-23 11:57:18|Not sure who else (what persona) will keep track of the market if not VCs
Sandeep Srinivasa RedCarpetup|2023-06-23 11:57:26|redis/elasticsearch thats what we integrate in edgechains
Pratik Bhavasar|2023-06-23 11:59:34|Sounds controversial to me
Sandeep Srinivasa RedCarpetup|2023-06-23 11:59:34|oh so u save both the embeddings and the one-hot together ? and then pinecone internally tokenizes the one-hot. this is something i had no idea that was how hybrid search worked. wouldnt this blow up storage costs
Samanyou WriteSonic|2023-06-23 11:59:36|How does Elasticsearch perform for hybrid search? Any thoughts?
Pratik Bhavasar|2023-06-23 12:00:27|Costs are blown up for vector search as well IMO
Sandeep Srinivasa RedCarpetup|2023-06-23 12:00:43|fairly built in. u can create composite rankings or for advanced usecases create a plugin.  composite rankings in elasticsearch are a very OLD and classic usecase. I mean we have all used it for zillion years.  it has suddenly got rebranded as hybrid search.
Pratik Bhavasar|2023-06-23 12:00:46|Kindly do not go that path
Dhruv Anand|2023-06-23 12:01:29|there's no hybrid search in qdrant. is there?
Sandeep Srinivasa RedCarpetup|2023-06-23 12:01:38|i know of several banks and LARGE enterprises that are running this in production. redis and elasticsearch are the only game in town if u need compliance as well. no other db is getting ISO/SOC2 certifications in india.
Sandeep Srinivasa RedCarpetup|2023-06-23 12:02:01|incidentally Elasticsearch is the only exabyte scale infra that i know of. so i will respectfully disagree
Samanyou WriteSonic|2023-06-23 12:03:47|Pinecone has soc2 no?
Pratik Bhavasar|2023-06-23 12:07:19|I think both Weaviate and Pinecone must have soc 2 type 2. My disagreement is more because of cost and latency. Selection will depend on how many vectors are indexed & latency. In some cases ES would work out.
Sandeep Srinivasa RedCarpetup|2023-06-23 12:07:33|wont transitively pass in india. in india, ull have to recertify. they are not passing it.  also it is potentially violative of India data residency guidelines if u are carrying PII data for lack of india datacenter..but this may not apply to you.  independent of this, redis and elasticsearch are almost 2 decades tested in large scale production. i would take a stand that they are as (if not more) stable
Pratik Bhavasar|2023-06-23 12:07:58|It has Gong as customer. So definitely type 2
Nirant|2023-06-23 12:08:32|AI grant has scaled to >$1M per winner, no equity https://aigrant.org/
Sandeep Srinivasa RedCarpetup|2023-06-23 12:09:03|again challenge to prove. all of them are using HNSW lib underneath. elasticsearch also. with the added future outlook that Java Panama vector API is being natively built into elasticsearch https://github.com/apache/lucene/pull/12311   so im taking the stand that it is already best of breed and probably will get better
Sandeep Srinivasa RedCarpetup|2023-06-23 12:09:54|this means that in a year, we will have GPU SIMD accelerated vector search built into ES via Panama. I think thats a great bet.
Pratik Bhavasar|2023-06-23 12:10:09|Okay I do not have clarity on the PII scrubbing and storage
Harsh Gupta Felvin|2023-06-23 12:12:43|How easy/difficult is it to fine tune Whisper for different accents or special terminology?
Pratik Bhavasar|2023-06-23 12:12:56|Interesting take. Maybe later everyone converge to similar and it boils down to implementation efficiency of Rust(Pinecone) Vs Java(ES) Vs Go(Weaviate)
Sandeep Srinivasa RedCarpetup|2023-06-23 12:14:17|i wouldnt look at it that way. i will say that pgvector has AWS managed support (https://aws.amazon.com/about-aws/whats-new/2023/05/amazon-rds-postgresql-pgvector-ml-model-integration/) and Elasticsearch and redis have the same.   so u have vendor agnostic, exabyte scale infra supported by even AWS. and potentially self host at some point if u want.  thats the way i would look at it.
Dr. Pratik Desai KissanGPT|2023-06-23 12:14:51|I had conversation with Hersh, for Indian startups you will need Delaware corp if selected.
C Chaitanya Nutanc|2023-06-23 12:17:33|How many vectors are you looking at and what are the dimension sizes?
Manas Ranjan Kar|2023-06-23 12:19:40|Anyone working on ETL/DevOps automation using GenAI? Have a few ideas would like to discuss
Pratik Bhavasar|2023-06-23 12:20:35|That’s great! My thinking is more around cost and latency rather than security (assuming all can scale well). It will be helpful if we find any analysis on this front to compare them all.
Pratik Bhavasar|2023-06-23 12:21:42|Let’s say 10M single index no filtering 768 dim
~ Dx|2023-06-23 12:37:22|Interesting , any other benefits of raising from them over VCs apart from no equity?
Nirant|2023-06-23 12:40:57|They are better than most VCs? And compute cluster larger than clouds?
~ Dx|2023-06-23 12:43:14|Compute part is clear . Was curious to know before applying in what ways are they better than most VC ?
Nirant|2023-06-23 12:43:42|They know what they're talking about? 🫣 ‎[6/23/23, 12:44:23] Ojasvi Yadav: ‎image omitted
~ Dx|2023-06-23 12:46:53|Makes sense , was hoping if someone could speak from personal experience . Have been following Nat and Daniel . Does sound exciting 🛤️
ashish Acgt01 Twitter|2023-06-23 13:52:44|Happening today, organized by Nathan Benaich  https://raais.co/  livestream : https://www.youtube.com/watch?v=RHfSBsYOI6Y
ashish Acgt01 Twitter|2023-06-23 14:03:56|Yesterday someone asked about hosting options for an LLM web app, if you dont want to learn a web app framework  i stumbled onto modal.com today  pricing : https://modal.com/pricing  was curious has anyone tried modal ? if y, what was your experience like ?
Nirant|2023-06-23 14:07:29|I've tried it. It's amazing when it works,
Nirant|2023-06-23 14:15:20|Aside, for the meetup tomorrow, please ping [PHONE] for invites. He's the one making the invite list. Not me.   I believe about 20 slots are left. Please be kind if he has to say no.
Sugam Docyt|2023-06-23 14:32:26|‎You added Sugam Docyt
~ Aashay Singhal|2023-06-23 14:36:59|‎You removed ~ Aashay Singhal
~ Aashish Loknath Panigrahi|2023-06-23 14:37:09|‎You removed ~ Aashish Loknath Panigrahi
~ Aayush Krishnan|2023-06-23 14:37:17|‎You removed ~ Aayush Krishnan
~ Abhijeet D|2023-06-23 14:37:25|‎You removed ~ Abhijeet D
~ Abhimanyu|2023-06-23 14:37:36|‎You removed ~ Abhimanyu
~ Abhishek Persad|2023-06-23 14:37:47|‎You removed ~ Abhishek Persad
~ Aishwarya Guntoju|2023-06-23 14:38:17|‎You removed ~ Aishwarya Guntoju
~ Ajay|2023-06-23 14:38:27|‎You removed ~ Ajay
~ Akarsh|2023-06-23 14:38:37|‎You removed ~ Akarsh
~ Akhil Sajeev|2023-06-23 14:38:52|‎You removed ~ Akhil Sajeev
~ Akhil|2023-06-23 14:38:57|‎You removed ~ Akhil
~ Akshay Agrawal|2023-06-23 14:39:15|‎You removed ~ Akshay Agrawal
~ Akshay Naik|2023-06-23 14:39:25|‎You removed ~ Akshay Naik
~ AmanMulani|2023-06-23 14:39:35|‎You removed ~ AmanMulani
~ Amogh|2023-06-23 14:39:48|‎You removed ~ Amogh
~ Anand V|2023-06-23 14:39:58|‎You removed ~ Anand V
~ Anil|2023-06-23 14:40:20|‎You removed ~ Anil
~ Animesh Srivastava|2023-06-23 14:40:30|‎You removed ~ Animesh Srivastava
~ Anirudh Gupta|2023-06-23 14:40:43|‎You removed ~ Anirudh Gupta
~ Anjaly|2023-06-23 14:40:56|‎You removed ~ Anjaly
~ Anji Beeravalli|2023-06-23 14:41:04|‎You removed ~ Anji Beeravalli
Anmol Sonthalia GenerativeAI WhatsApp Group|2023-06-23 14:41:19|‎You removed Anmol Sonthalia GenerativeAI WhatsApp Group
~ Annapurna|2023-06-23 14:41:53|‎You removed ~ Annapurna
~ Antony Paul|2023-06-23 14:42:05|‎You removed ~ Antony Paul
~ Anuj|2023-06-23 14:42:14|‎You removed ~ Anuj
~ Anuj Khandalikar|2023-06-23 14:42:20|‎You removed ~ Anuj Khandalikar
~ Anuj Menta|2023-06-23 14:42:26|‎You removed ~ Anuj Menta
~ Anvith|2023-06-23 14:42:39|‎You removed ~ Anvith
~ Aravind|2023-06-23 14:42:50|‎You removed ~ Aravind
~ Arjun Rakesh|2023-06-23 14:43:00|‎You removed ~ Arjun Rakesh
~ Arpit Sharma|2023-06-23 14:43:12|‎You removed ~ Arpit Sharma
~ Arun|2023-06-23 14:43:23|‎You removed ~ Arun
~ Aryan|2023-06-23 14:43:31|‎You removed ~ Aryan
~ Ashish Sardana|2023-06-23 14:43:39|‎You removed ~ Ashish Sardana
~ Ashutosh Agarwal|2023-06-23 14:43:53|‎You removed ~ Ashutosh Agarwal
~ Ashwin|2023-06-23 14:44:05|‎You removed ~ Ashwin
~ Ashwin N|2023-06-23 14:44:13|‎You removed ~ Ashwin N
~ Avikalp Kumar Gupta|2023-06-23 14:44:22|‎You removed ~ Avikalp Kumar Gupta
~ Balamurali A R|2023-06-23 14:44:32|‎You removed ~ Balamurali A R
~ Bharat Chandra|2023-06-23 14:44:45|‎You removed ~ Bharat Chandra
~ Bhaskar|2023-06-23 14:44:53|‎You removed ~ Bhaskar
~ Bineet Ranjan|2023-06-23 14:45:02|‎You removed ~ Bineet Ranjan
~ Chao Gao|2023-06-23 14:45:21|‎You removed ~ Chao Gao
~ Chetan 😇|2023-06-23 14:45:31|‎You removed ~ Chetan 😇
~ Deepak Khatri|2023-06-23 14:45:52|‎You removed ~ Deepak Khatri
Dhanush Speciale Invest|2023-06-23 14:46:04|‎You removed Dhanush Speciale Invest
~ Dhiraj|2023-06-23 14:46:13|‎You removed ~ Dhiraj
Krishna Panchal|2023-06-23 14:49:29|https://twitter.com/karpathy/status/1671587087542530049?t=864c5-CnpaISCvt8vNSYYw&s=19
~ Arjun Narain|2023-06-23 15:08:04|Does anybody have any reviews about the courses from Nic Renotte?
~ Arjun Narain|2023-06-23 15:08:19|Or any other beginner friendly course recommendations?
Rajesh RS Generative AI WhatsApp Group|2023-06-23 15:24:50|This one is for beginners https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home - nice course by Databricks featuring Matei Zaharia and others ‎[6/23/23, 15:25:06] Rajesh RS Generative AI WhatsApp Group: ‎image omitted
~ Nithyakala|2023-06-23 15:39:30|Any product folks here building in Generative AI ? I'd like to pick your brains on an MVP that we are set to launch.
~ Nithyakala|2023-06-23 15:39:31|?
Nirant|2023-06-23 15:44:07|If you're comfortable sharing a quick preview, lot of builders would be happy to share feedback!
~ Nivesh|2023-06-23 15:50:23|‎~ Nivesh requested to join
~ Nithyakala|2023-06-23 15:51:38|We want to think in the direction of Generative AI being a part of our product strategy probably later in time. But for MVP how can we minimally think towards that direction is my question
Rajesh RS Generative AI WhatsApp Group|2023-06-23 16:00:52|We're building genAI products in my team, happy to chat
Abhishek Mishra|2023-06-23 16:13:30|It'll help to know what Gen AI is capable of first whether in terms of audio, vision or text fields.  Anything that is currently possible in state of the art can then be tested to be a feature in some of your existing products. For example, an edtech can test if AI can act as a tutor reliably and an e-commerce can test if AI can act as a customer service or shopping assistant reliably or simply offer recommendations in the background.
Abhishek Mishra|2023-06-23 16:15:26|By knowing what's possible in vision, audio and text you can then chain these things together to create a completely new product as well. For example, given an image of clothes that a person has in their wardrobe we can answer 2 questions easily: 1. What pairs can go together for a certain occasion or mood? 2. What can we shop for to find similar or complementary stuff?
Abhishek Mishra|2023-06-23 16:15:41|It's just an example. But along these lines, knowing what's possible allows you to think of replacing existing features or add components in your product. Or build a completely new one from the ground.
Swapnika Hashmail Web3|2023-06-23 16:47:08|I lead product. Happy to brainstorm.
Manas Ranjan Kar|2023-06-23 17:03:54|Lead ML at my firm - and we have couple of GenAI products to go to production pretty soon next quarter.   Happy to walk you through how we went about breaking the problem statement and evaluation steps
~ Jay|2023-06-23 17:04:10|Happy to help 👍🏽 .. currently working on MVPs in financial services
C Chaitanya Nutanc|2023-06-23 17:24:47|I think for this range almost all vector DBs work fine. ChromaDB with a local file system should also work. I have run it for 1 million index with no issues. Depending on your use case maybe a regular faiss index works?
Sandeep Srinivasa RedCarpetup|2023-06-23 17:30:24|Correct on this.  I only work with large production systems, so my viewpoint is colored by it. But if ur prototyping or small scale, just use FAISS or redis. Both run locally and very lightweight.  FAISS if ur in the python ecosystem since u need c-library to load faiss. Redis/chromadb otherwise.
Nirant|2023-06-23 17:32:37|For the love of God, please don't use Chroma and shoot your mem utilisation to the roof
Krishna Panchal|2023-06-23 17:38:08|https://twitter.com/rowancheung/status/1671893629751939077?t=xotImYsHeIRPrJiTcnGw7g&s=19  This is very cool, love this.
Krishna Panchal|2023-06-23 17:43:42|https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/
Abhinav Verma Longshot.ai|2023-06-23 19:12:09|What are some good open source data annotation tools?
Azhan Mohammed Generative AI WhatsApp Group|2023-06-23 19:13:17|CVAT works really well for image annotation
Abhinav Verma Longshot.ai|2023-06-23 19:14:36|Looking for text. Looking open source. Idea is to manually add data on my own time. Wanting to create a dataset to try to fine-tune LLMs based on what I learnt over the past years of using them
Azhan Mohammed Generative AI WhatsApp Group|2023-06-23 19:15:30|Have you tried doccano?
Abhinav Verma Longshot.ai|2023-06-23 19:16:28|had tried a while back, will check again.
Abhinav Verma Longshot.ai|2023-06-23 19:19:53|for cloud based nosql dbs , which one gives the best amount of storage on a free tier, like over a GB. Mongodb atlas gives around 512mb
Abhishek Mishra|2023-06-23 19:33:15|Argilla
Abhinav Verma Longshot.ai|2023-06-23 19:35:10|also a city in Italy, TIL
Abhishek Mishra|2023-06-23 19:40:24|TIL too
Abhishek Mishra|2023-06-23 20:00:13|https://twitter.com/ericmitchellai/status/1671943972829433856?t=QQK1NbVYt_04XuvWj_Sarg&s=08
Abhishek Mishra|2023-06-23 20:01:37|Found this implementation for DPO RLHF yesterday. It doesn't need reward models or RL. It's a simpler way to do RLHF or to learn for reference.
~ Abhilash K Pai|2023-06-23 20:17:53|If you are doing something related to segmentation you could additionally use Segment Anything Model (SAM) to speed things up
ashish Acgt01 Twitter|2023-06-23 20:37:03|AudioPaLM: A Large Language Model That Can Speak and Listen   https://google-research.github.io/seanet/audiopalm/examples/  abstract : arxiv.org/abs/2306.12925  With voicebox from Meta, whisper from openai, the speech space is heating up ! :)
Nitin Mahajan McKinsey|2023-06-23 20:54:59|Yea but only if meta and google release api for commercial use. Demos look hot.
ashish Acgt01 Twitter|2023-06-23 20:56:34|100% expect commercial api by Google by the end of the year  Meta - not so sure, but might just
~ vignesh iyer✌️|2023-06-23 20:58:58|Absolutely.. this has huge potential in both streaming and podcasting industry
Nitin Mahajan McKinsey|2023-06-23 21:00:08|On that note, what’s the best lip synching and face morphing library you guys have seen (to go with text to speech Audio)
ashish Acgt01 Twitter|2023-06-23 21:01:36|You could listen to a French podcast, in Hindi, for example !  Endless possibilities in education & health too.  What if Khan academy videos recorded by Sal Khan ( in a strong American accent) could be heard by a kid in a village in Bihar in bhojpuri ?
Nitin Mahajan McKinsey|2023-06-23 21:01:40|And, elevenlabs updated their model as well haha marketing teams fighting out for the voice share   https://twitter.com/elevenlabsio/status/1672238899874217985?s=46&t=dSB_vXgXsC6qhF1TYEKlZw
~ vignesh iyer✌️|2023-06-23 21:04:50|Indeed.. when Zuck announced first time on his Instagram broadcast channel.. I was shell shocked..because it was done without huge media fanfare or publicity.. I am bullish on Zuck through his open LLMs and such cool features announcements almost every week
ashish Acgt01 Twitter|2023-06-23 21:07:29|In academia, Prof Jawahar's group at IIIT Hyderabad has done amazing work on lip reading and lip syncing in video   http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild
~ vignesh iyer✌️|2023-06-23 21:07:30|Deep Fakes tools does it well.. but that dilutes authenticity.. here with audio Palm it still retains the original with runtime speech or voice modifications and translation
Nitin Mahajan McKinsey|2023-06-23 21:09:37|Do they have an API. Don’t see on their site.
Nitin Mahajan McKinsey|2023-06-23 21:10:06|Suggest options with commercial api availability please for lip synching 🙏
Abhishek Mishra|2023-06-23 21:10:48|Yeah and movies wouldn't need to be dubbed in any language at all. Probably not so good for voice actors.
ashish Acgt01 Twitter|2023-06-23 21:11:09|More research-y, less product-y  Not sure if they are trying to commercialize it, they work with MSR & Zoom among others.  You could try contacting them
~ Abhilash K Pai|2023-06-23 21:30:24|https://www.thehindubusinessline.com/info-tech/way2lip-promises-to-reduce-drudgery-in-video-content-creation/article65388110.ece
~ Abhilash K Pai|2023-06-23 21:31:32|https://www.neuralsyncai.com/#products
~ Abhilash K Pai|2023-06-23 21:35:18|You could contact him: https://rudrabha.github.io/
~ Happy Chaudhury|2023-06-23 21:45:09|Agree with FAISS
Abhishek Mishra|2023-06-23 22:13:47|*Most curious thing I read today -* https://kaiokendev.github.io/til#extending-context-to-8k  *TLDR -A GitHub user by the name of kaiokendev tried an experiment to increase context length of llama models from 2k to 8k by scaling the frequency window by 0.25, strangely it worked and this is a way to understand how* RoPE is a technique that allows transformers to handle longer sequences by encoding the position of each token into a vector. This vector is then added to the token’s representation before feeding it into the transformer. The position encoding is based on a frequency window, which determines how many different positions can be distinguished by the transformer.  The question is about what happens if we change the frequency window of RoPE by scaling it down by a factor of 0.25. This means that the position encoding will have more steps in between, so that each position will look like it is closer to the beginning of the sequence. For example, position 1 will look like position 0.25, position 40 will look like position 10, and position 2048 will look like position 512.
~ raj()|2023-06-23 23:05:30|Have tried to use elasticsearch (opensearch, on aws) as vector index with their approx knn plugin. Faced a lot of issues where the knn circuit breaker would get triggered, after which no index operations could be performed and search would slow down significantly. At the peak, for around 12M vectors (with some metadata), we were using r5.2xlarge instances with 6 data nodes and 2 master nodes (with 200gb ebs volumes), costing around ~$2k/month.   Another thing is opensearch knn plugin does not support prefiltering (filtering out based on some criteria and then doing approx knn).  Shifted to Weaviate and the bill went down drastically + search latency improved as Weaviate supports prefiltering
Sandeep Srinivasa RedCarpetup|2023-06-23 23:09:37|"elasticsearch does have pre-filtering with cosine similarity on dense vectors right ? it uses the SHOULD array and u can combine them both. so ""match"" will have ur filter query and script_score will have ur cosine similarity ‎[6/23/23, 23:13:41] ~ raj(): ‎image omitted"
Dr. Ashith Generative AI WA Group|2023-06-23 23:14:51|Is there a repository or list for AI tools to make music?
Jaskamal Kainth 2013|2023-06-23 23:15:13|yes.  I had used the same with ES 6.8 (old days) :') (by implementing my own cosine sim script_score function)
Samanyou WriteSonic|2023-06-23 23:15:22|How has the experience with weaveate been?
Sandeep Srinivasa RedCarpetup|2023-06-23 23:18:09|yes. ANN is already in. been a year. not sure if this is exactly what you want...but it is the general usecase that many use.  https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0
~ Gayatri|2023-06-23 23:25:10|I am looking for a dataset or service providing company name aliases. For example HP == Hewlett Packard, PWC = Price Waterhouse Coopers. Is there such a dataset or service?
~ raj()|2023-06-23 23:30:00|Pretty good. It has handled whatever load we've thrown at it (around 16M vectors), the community is good, and they're actively releasing new features
Samanyou WriteSonic|2023-06-23 23:32:28|Nice! Are you using their hosted version or self hosted?  Also, with or without hybrid search?
Samanyou WriteSonic|2023-06-23 23:33:28|I think for the hosted version they charge both for vector dimensions as well as queries whereas other dbs only charge for storing N vectors.
Ojasvi Yadav|2023-06-23 23:46:10|Ah, this recent finding has been used many years ago but just in a different context. It's extremely similar to Convolutional Recurrent Neural Network, by authors whose names I don't recall.   They had a convolutional layer to extract features, followed by an RNN for sequence processing - the same old song, just a different singer.
Ojasvi Yadav|2023-06-23 23:47:01|Who knew you could achieve that just by changing a line or two in transformers based LLMs
Ojasvi Yadav|2023-06-23 23:50:05|https://arxiv.org/abs/1602.05875
Ojasvi Yadav|2023-06-23 23:50:23|AI of 2016 still relevant today
Ojasvi Yadav|2023-06-23 23:51:44|Hope newcomers in the field take this as great motivation. The field is not moving too fast for you to feel out of control. Significant contributions can be made if you understand the insides of these supposed black boxes.
Aditya Sista 2010B5|2023-06-24 00:12:02|Convolution layer was pretty much the de facto feature extractor before transformers
~ Rohan|2023-06-24 00:13:17|Still is, for images
~ Rohan|2023-06-24 00:14:10|ViT hasn’t been widely adopted, especially for memory/compute constrained edge deployment ‎[6/24/23, 00:18:36] Ojasvi Yadav: ‎image omitted
Aditya Sista 2010B5|2023-06-24 00:52:50|Which model is being describes here?
Abhishek Mishra|2023-06-24 00:55:43|Context
Dhruv Anand|2023-06-24 01:10:57|has anyone successfully run HF transformers pipelines on mac m1 chip? whenever I try a model, there's some or the other unsupported pytorch operation
Abhishek Mishra|2023-06-24 01:14:47|I don't exactly remember my pytorch version but I didn't face any issues on M2 pro. It could be an issue with your config.
Lalit Pagaria|2023-06-24 08:26:10|This is exactly what we are using and not faced any issue. But we don't have 1M records though. But latency is low and we have all data together in postgresql. Only one component we need to monitor at production.
ashish Acgt01 Twitter|2023-06-24 09:01:00|A businessy article from me for a change :) https://greylock.com/greymatter/the-new-new-moats/
Shan|2023-06-24 09:24:43|Absolutely. Look at deBERTa eval scores for example and if you’re use case fits then BERT based models can take you much further, sometimes even more than massive unwieldy LLMs.
Shan|2023-06-24 09:28:18|Also https://github.com/BlinkDL/RWKV-LM for old+newer approaches
Arpit Saxena|2023-06-24 10:32:00|‎You added Arpit Saxena
Lucifer 😎|2023-06-24 12:11:29|‎Ravi Theja added Lucifer 😎
~ Preet Garach😎|2023-06-24 12:12:39|‎Ravi Theja added ~ Preet Garach😎
~ Ashish|2023-06-24 12:13:54|‎Ravi Theja added ~ Ashish
~ Udit|2023-06-24 12:14:11|‎Ravi Theja added ~ Udit
~ Udit|2023-06-24 12:15:48|Hey folks, Udit here!  Yesterday we launched Supervised AI (a layer 2 AI infra).  3 months ago, I launched Sttabot which now powers 8000+ businesses' AI infra.  I am a solo founder and would love to connect to you guys and share my insights :)
Pratik Bhavasar|2023-06-24 12:16:55|Congratulations! What’s layer 2?
~ Udit|2023-06-24 12:19:40|Where AI's responses are not only limited by GPT's data sources but trains upon your data for precision + GPT for generating answers.
~ Udit|2023-06-24 12:19:54|You can find more about it on OpenAI docs
ashish Acgt01 Twitter|2023-06-24 12:39:55|Any link to docs &/ casestudies ?
Nitin Mahajan McKinsey|2023-06-24 13:01:43|Hey, would love to chat more. Ping me :-)
Nirant|2023-06-24 13:21:24|"""Layer 2"" is simultaneously the best and worst branding I've seen for a Colab notebook. Impressed with the mktg chops on this."
Nirant|2023-06-24 13:23:51|Invites are against email ids, no swaps
Sudharshan GenAI|2023-06-24 13:25:01|What’s the venue?
Nirant|2023-06-24 13:26:00|Shared with invited folks. Will email maps and navigation instructions around 3:30 PM
Nirant|2023-06-24 13:28:00|Please ping [PHONE] for the invites and approvals. He's the one sending them out
~ Ketan Gangal|2023-06-24 13:32:31|https://github.com/OptimalScale/LMFlow
~ Ketan Gangal|2023-06-24 13:32:53|https://github.com/OptimalScale/LMFlow
~ Ketan Gangal|2023-06-24 13:34:30|https://github.com/neuralmagic/deepsparse
~ Ketan Gangal|2023-06-24 13:35:09|Has anyone tried this neural magic ?
~ Udit|2023-06-24 13:44:49|Sure
Shan|2023-06-24 14:06:03|I’m not in it seems. But I understand. Hopefully next time.
Dr. Ashith Generative AI WA Group|2023-06-24 14:18:31|This is interesting.
Prayank Swaroop Accel|2023-06-24 15:32:35|Folk's what are the topics for today's meetup ?
Kartik Mandaville|2023-06-24 15:58:26|https://hasgeek.com/generativeAI/june-meetup/ ah I forgot to register :/
Abhishek Mishra|2023-06-24 16:00:28|Your mention of deberta reminded me of this list of models trained by Microsoft. Everytime you need to fine tune BERT for something general, don't. Use this instead - https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table.html
~ Lakshmi Narayana LN|2023-06-24 16:01:02|‎Ravi Theja added ~ Lakshmi Narayana LN
~ Abhinav (DreamBoat.ai)|2023-06-24 16:28:54|‎~ Abhinav (DreamBoat.ai) joined from the community
Sandeep Srinivasa RedCarpetup|2023-06-24 17:57:53|is anyone using Sagemaker Jumpstart for serving models ? https://tinyurl.com/y3pksx73 . how was the experience ? ‎[6/24/23, 18:05:51] Rakeshkumar Waghela: ‎image omitted
Rakeshkumar Waghela|2023-06-24 18:07:44|I got access to LLm powered chatbot.  The funny thing is it's answering any questions i ask.  The developer of said product deals with Fintech.  I'm wondering how does one prevent the abuse of such bots ( which are proxy to mostly chat gpt) to only contextual domain ! ? ‎[6/24/23, 18:09:04] Rakeshkumar Waghela: ‎image omitted
~ Kp|2023-06-24 18:09:08|I doubt such queries will be passed bu their checks if open ais api is used
~ Kp|2023-06-24 18:09:18|This could be an older model like da vinci or maybe even a custom model
~ Kp|2023-06-24 18:09:48|Yes they're using da vinci-003
~ Ashish|2023-06-24 18:09:57|It was awesome
~ Ashish|2023-06-24 18:10:41|I tried and deployed cost of inference hardware would be around 7 dollar per hour
Sandeep Srinivasa RedCarpetup|2023-06-24 18:18:43|were u using ml.m5d.24xlarge ?  cos on https://aws.amazon.com/sagemaker/pricing/ , it shows all the way from 0.2$ ?
Nilesh Agarwal Inferless|2023-06-24 18:30:35|Yo can try Serverless deployments for saving infra cost
Aditya Sista 2010B5|2023-06-24 18:35:02|"Along with the default ""you are a fintech expert ..."" prompt, you cab additionally place checks like ""for every question asked, evaluate how relevant the question is, answer only when...."" etc"
Aditya Sista 2010B5|2023-06-24 18:36:34|Most likely they're doing this, but this won't work for da Vinci models that well. Which also happens to be the default in langchain...
Nirant|2023-06-24 18:39:30|Langchain default being terrible is something which escapes me
Shan|2023-06-24 18:39:54|I think we expect too much of a servile  attitude from LLMs. I think I want LLMs which when asked “do you hallucinate” with “don’t you?” as the response
Nirant|2023-06-24 18:42:05|Microsoft learned from their Tay experience.  iykyk 😂
Piyush Makhija|2023-06-24 18:51:43|‎Piyush Makhija requested to join
Rajas Neve IIT Madras VC|2023-06-24 18:52:01|‎Rajas Neve IIT Madras VC requested to join
~ Abhinav Dadhich|2023-06-24 18:52:15|‎~ Abhinav Dadhich requested to join
~ tejas|2023-06-24 18:52:35|‎~ tejas requested to join
~ @RiTe_NoW|2023-06-24 18:53:23|‎~ @RiTe_NoW requested to join
~ Himanshu Gupta|2023-06-24 18:53:33|‎~ Himanshu Gupta requested to join
~ Darshan Savaliya|2023-06-24 18:53:37|‎~ Darshan Savaliya requested to join
~ Pritam Lad|2023-06-24 18:53:41|‎~ Pritam Lad requested to join
~ Kashish Kumar|2023-06-24 18:53:44|‎~ Kashish Kumar requested to join
~ Ayush|2023-06-24 18:54:16|‎~ Ayush requested to join
~ Ganeshaaa|2023-06-24 18:54:20|‎~ Ganeshaaa requested to join
~ Shubh|2023-06-24 18:54:30|‎~ Shubh requested to join
~ Arya|2023-06-24 18:56:47|‎~ Arya requested to join
~ Arya|2023-06-24 19:00:32|‎~ Arya joined using this group's invite link
~ Shubh|2023-06-24 19:00:34|‎~ Shubh joined using this group's invite link
~ Ganeshaaa|2023-06-24 19:00:36|‎~ Ganeshaaa joined using this group's invite link
~ Kashish Kumar|2023-06-24 19:00:37|‎~ Kashish Kumar joined using this group's invite link
~ Ayush|2023-06-24 19:00:39|‎~ Ayush joined using this group's invite link
~ Pritam Lad|2023-06-24 19:00:41|‎~ Pritam Lad joined using this group's invite link
~ Darshan Savaliya|2023-06-24 19:00:42|‎~ Darshan Savaliya joined using this group's invite link
~ Himanshu Gupta|2023-06-24 19:00:46|‎~ Himanshu Gupta joined using this group's invite link
~ Abhinav Dadhich|2023-06-24 19:00:49|‎~ Abhinav Dadhich joined using this group's invite link
~ tejas|2023-06-24 19:00:51|‎~ tejas joined using this group's invite link
~ @RiTe_NoW|2023-06-24 19:00:53|‎~ @RiTe_NoW joined using this group's invite link
Rajas Neve IIT Madras VC|2023-06-24 19:00:55|‎Rajas Neve IIT Madras VC joined using this group's invite link
~ tejaswi prakash|2023-06-24 19:03:37|‎~ tejaswi prakash requested to join
~ Naman|2023-06-24 19:05:58|‎~ Naman requested to join
Abhinav Verma Longshot.ai|2023-06-24 19:20:08|You want generation to only be restricted to your context. That's prompt engineering
Rakeshkumar Waghela|2023-06-24 19:21:23|Prompt validation, may be ?
Abhinav Verma Longshot.ai|2023-06-24 19:22:20|Prompt engineering works well here. We've done it with prompt engineering for our retrieval based generations to not hallucinate pretty well
~ Arindam Barman|2023-06-24 19:22:31|A trick I use is to ask the LLM to not use their own knowledge and only the one in the prompt that ensures it's grounded
Abhinav Verma Longshot.ai|2023-06-24 19:23:32|Provide directions in markup
Pratyush AI4Bharat|2023-06-24 19:36:16|‎You added Pratyush AI4Bharat
~ Soham|2023-06-24 19:53:07|‎~ Soham requested to join
~ Soham|2023-06-24 19:57:23|‎~ Soham joined using this group's invite link
~ Naman|2023-06-24 19:57:26|‎~ Naman joined using this group's invite link
~ @RiTe_NoW|2023-06-24 20:06:32|May I have the group invitation link ?
Rajesh RS Generative AI WhatsApp Group|2023-06-24 20:10:20|Hi, I had a few questions about testing chatbots. We've discussed options here like Rasa's testing capabilities before but I'd like to know if there are any test case or test plan strategies someone is already using for LLM based testing. For instance - how do we deal with variability in LLM output? Does vector / semantic similarity matching work at scale for evaluating such outputs? Are there any other ways to test chat bots?
~ Adithya|2023-06-24 20:23:04|‎~ Adithya requested to join
Lavish 2017|2023-06-24 20:23:52|I built this and we are keeping a count of how many unrelated questions has a user asked and the limit right now is very high so people can enjoy free Chat GPT on WhatsApp   so far it's beneficial when people engage and share more for free access as it unlocks more surface area 😄
Saurabh Karn Nyai|2023-06-24 20:24:45|BharatGPT is here!
Saurabh Karn Nyai|2023-06-24 20:24:46|https://www.linkedin.com/posts/amitabh-nag-56039b5_generativeai-conversationalai-ai-activity-7078333831048499200-nh7n?utm_source=share&utm_medium=member_ios
Saurabh Karn Nyai|2023-06-24 20:33:46|No no. See the post. You will know what I mean.
Anubhav mishra Zupay|2023-06-24 20:34:00|😂
~ Anjineyulu|2023-06-24 20:35:34|‎Shivendu Kumar added ~ Anjineyulu
Manas Ranjan Kar|2023-06-24 20:54:37|We are using for finetuning and dev testing - production next quarter. Things are a bit wobbly sometimes but AWS support helps
Pratiksha Dake Unacademy|2023-06-24 20:57:50|But was it hard to restrict the usage to only fintech domain?
Lavish 2017|2023-06-24 20:59:46|"nopes. I'm already categorising everytime what someone has asked into related or not and then letting the model answer if user has asked < N ""unrelated questions"" yet  so I could set N to 0 and it'll be restricted"
Nirant|2023-06-24 21:25:04|Peak community success, creator is here to explain internal deets!
Rakeshkumar Waghela|2023-06-24 21:28:55|It did not give me ICICI bank details, despite following your bot option ‎[6/24/23, 21:29:30] Rakeshkumar Waghela: ‎image omitted
Nirant|2023-06-24 21:31:56|If you share a number here to ask someone to be added, I'll add your number and your friend's number to Yes Bank, Policy Bazaar and Bajaj Finance's Loan & Insurance application. Please DM any admin (other than me!) for an invite link.  We'll also ask for your friends Github/Linkedin, since we want to have more makers.  e.g. Soumyadeep [PHONE]
~ Ganeshaaa|2023-06-24 21:33:27|☠️
Lavish 2017|2023-06-24 21:33:36|noted - will solve   for other folks who are going to try this and have some feedback, please DM me  if you have any question on how to LLM hack images, data, etc - feel free to ask on group itself
Nilesh Transcend|2023-06-24 21:35:29|‎You added Nilesh Transcend
aashutosh GenerativeAI WhatsApp Group|2023-06-24 21:54:00|‎You added aashutosh GenerativeAI WhatsApp Group
Apurv Aurva.io Sahil's Friend|2023-06-24 22:02:48|‎Pranjal Mehta added Apurv Aurva.io Sahil's Friend
Sandeep Srinivasa RedCarpetup|2023-06-24 22:24:05|performance ok ? which model are u using ? we are planning to use falcon
Shalabh Aspiro|2023-06-24 22:50:17|why does langchain still use davinci as default? Doesn't 3.5-turbo still work better, even for non chat tasks?
Saurabh Karn Nyai|2023-06-24 23:07:39|For agents GPT4 works significantly better in our experiments so far.
Abhinav Verma Longshot.ai|2023-06-25 01:02:53|works with 3.5-turbo as well quite nicely
Rahul Chhabra 2016|2023-06-25 01:28:40|I generally paste each section, get it to explain it to me and then do the complete reading again. def super helpful for quick parsing/absorption
Manas Ranjan Kar|2023-06-25 01:36:10|Falcon, flan T5 and a couple more . Performance is good, but nothing to support real time streaming, so going mostly async
Abhinav Verma Longshot.ai|2023-06-25 01:41:03|The texbooks are all you need paper and Orca paper both emphasize the need for high quality datasets. But they contradict on a couple of things. Namely size of the model and the amount of high quality data. Textbooks tries to achieve it on a smaller scale compared to Orca paper. Interestingly both by microsoft research.
Abhinav Verma Longshot.ai|2023-06-25 01:56:42|Of course one thing to note is, the paper focuses on LLMS trained for code.
~ Paws|2023-06-25 01:58:48|The nuance in the textbook paper is that the model was trained for 7 epochs. Essentially 50B tokens. There was this assumption earlier that the corpus should be entirely unique. https://arxiv.org/abs/2305.16264 this paper showed that upto 4 epochs they saw no issue and the loss kept decreasing. In other words, there was still more signal left in the dataset even after going over it multiple times.
Abhinav Verma Longshot.ai|2023-06-25 01:59:56|Can you explain the second part again?
~ Paws|2023-06-25 02:02:54|In case you dont have a lot of data, you can train a Language model by training it with your data on multiple epochs. This paper showed that upto 4 epochs, the loss for the model decreased in a similar fashion as if you had unique data. Simply put, 50B tokens x 4 epochs loss = 200B unique tokens x 1 epoch loss
Abhinav Verma Longshot.ai|2023-06-25 02:04:19|Ok got it. Was confused because they also focused on deduplicating the data. Have to read that part closely.  This was also something karpathy and Yan le cunn were talking about  last year I believe.
~ Paws|2023-06-25 02:05:13|The other work the textbook paper took inspiration from is  https://arxiv.org/abs/2305.07759. This paper essentially studies the question “how small can a model be and still produce coherent english”, they produce a synthetic high quality dataset and train a model less than 10M parameters in size which generates coherent english.
Abhinav Verma Longshot.ai|2023-06-25 02:07:37|This paper is still interesting because the Orca paper had significantly more data and also a decent number of epochs, Think it was 4 epochs for 5M data set rows and 1M data set rows . So 8 epochs in total. So am interested to see if this is because this paper focused on code or this model can be generally used as well in other tasks like RAG
Abhinav Verma Longshot.ai|2023-06-25 02:08:17|If it does, then boy do I have some good data to fine-tune and test it on. But interesting to see this textbook type data
Abhinav Verma Longshot.ai|2023-06-25 02:36:46|I like this paper and the Orca paper. They have been pretty easy to read and understand and GPT-4 is also a good assistant here
Sudipta Mondal GenerativeAI Photographer|2023-06-25 04:14:31|‎Sudipta Mondal GenerativeAI Photographer left
~ Darshan Savaliya|2023-06-25 10:14:58|btw, I wanted to know if anyone has tried building FinTech specific chatbots. My team is currently working on something similar. We are trying to build a ChatBot using GPT4 which can answer user's queries by getting the relevant data from our DB. I can elaborate further if you want any specific details..
Pratiksha Dake Unacademy|2023-06-25 10:18:19|[PHONE]
Samanyou WriteSonic|2023-06-25 10:39:16|Would be curious to learn more on this as well.   We would like to do the same for Ecommerce use case wherein we want the user to be able to connect their read-only DB or connect their API, get real time data from there and then pass that into an LLM.
Meghana Jagadeesh|2023-06-25 10:39:49|Hey all!  We are looking for an AI consultant at GoCodeo. The platform automates software testing through AI. Hit me up if anyone's keen to solve the problem of testing.
Saurav Akaike|2023-06-25 10:42:42|Please DM
ashish Acgt01 Twitter|2023-06-25 10:49:14|Ethan Mollick got to try out multimodal GPT4  https://www.oneusefulthing.org/p/on-giving-ai-eyes-and-ears  The Cambrian explosion of progress continues ! ‎[6/25/23, 11:04:51] ashish Acgt01 Twitter: ‎image omitted
~ Karan|2023-06-25 11:08:19|Hey Samanyou and Darshan, we can help with this. Will continue on dms
Dev Aggarwal|2023-06-25 11:24:15|Use spot vms 😂❤️
Ritesh Invideo Nilenso|2023-06-25 11:26:48|i can be of help. If interested, you can DM me as well ‎[6/25/23, 11:26:57] Saurav Tomar GenerativeAI WA Group: ‎image omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-25 11:27:41|Could apply to any team building on the cloud as well. Even in big companies where you've to go to the CFO and board meetings and make a business case for investing in AI. Infra, GPUs, data collection and processing - all expensive. Not to mention the elephant in the room - AI engineer/dev salaries :D
ashish Acgt01 Twitter|2023-06-25 11:36:39|Anybody here had a chance to try multimodal GPT4 ?
Ritesh Invideo Nilenso|2023-06-25 12:06:49|"Hey Folks, I have a question when using a vector store and embedding for a chat-based product, how do you handle negative queries. For Eg if a user says find me documents which don't contain a particular concept -> how is that handled by vector db and embedding space.  I have had mixed results using open aI embedding model .  Most of the times searching for ""not <concept>"" in the vector store produces results containing the concept with highest match"
jyotirmayjk Hackathon|2023-06-25 12:08:30|Instead of negative prompt will it work if you rank the matching scores in order of least matches first and return top-n least matching ? S
Dr. Pratik Desai KissanGPT|2023-06-25 12:10:16|We are doing that with Mandi data for farmers and will integrate soon with platform, so farmers can request by voice in their local language. Lots of challenges though.
Ritesh Invideo Nilenso|2023-06-25 12:11:00|What is the core problem you are facing?
~ Vishwam Jindal|2023-06-25 12:11:05|Same here. Building for legal
Ritesh Invideo Nilenso|2023-06-25 12:13:01|So basically, we use chatgpt to parse the response and identify the keywords to be searched from vector store. I can try to include that in the prompt to maybe change the vector store query to order in ascending order by score -> but was wondering if there is a better solution. In my mind i thought that embedding space should be able to resolve the negation factor on its own and do the inverse on its own
Dr. Pratik Desai KissanGPT|2023-06-25 12:13:19|Some queries can return huge amount of data, we have millions of rows, so working on limiting that by set of questions to start with.
Ritesh Invideo Nilenso|2023-06-25 12:14:43|If its a structured data store, wouldn't adding a limit solve the issue. Just curious to understand since experimenting something similar
Dr. Pratik Desai KissanGPT|2023-06-25 12:17:01|Dynamically identifying and inserting limiter is what we will have to solve. I.e. ‘give me latest prize of grapes in Nasik mandi’ vs ‘give me commodity prizes from Nasik Mandi’
Dr. Pratik Desai KissanGPT|2023-06-25 12:18:08|We have millions of rows across thousands of commodities and Mandis.
Dr. Pratik Desai KissanGPT|2023-06-25 12:19:19|We do have solution for most cases, but will know more the application is in wild, used by real people. ‎<This message was edited>
Samanyou WriteSonic|2023-06-25 12:32:53|Is the data source consistent? As in if you are using SQL, the schemas are constant or different per customer?
Dr. Pratik Desai KissanGPT|2023-06-25 12:42:31|It is consistent
Abhinav Verma Longshot.ai|2023-06-25 12:46:58|What db are you using to store your data and embeddings? ‎[6/25/23, 12:54:06] C Chaitanya Nutanc: ‎image omitted
Abhinav Verma Longshot.ai|2023-06-25 12:59:27|You can handle these via your final LLM prompt. Or if you're only fetching embeddings I had a reply in this tweet where I had passed it via a encoder decoder model to get the score
Shaista Hussain|2023-06-25 13:23:43|https://www.producthunt.com/posts/youtalk  Hey guys, [PHONE] recently launched YoutTalk. This came out of the deephack hackathon and was one of the winners. So glad to see a production ready version of it. Do check it out and leave your reviews on feedback on product hunt/webstore  https://chrome.google.com/webstore/detail/youtalk/lbhodakkgeilgbgkcbajmillbgphdbga
Ritesh Invideo Nilenso|2023-06-25 13:47:55|could you elaborate little more - how can this be handled by prompt
Abhinav Verma Longshot.ai|2023-06-25 13:52:57|LLMs and decoder models are better at figuring out this level of similarity better than the embedding models we use which are more optimized for search. LLMs can be used for reranking and filtering out relevant passages. Also if you are using a RAG pipeline, your final LLM layer can have this in the prompt for filteringg out relevant queries you can take this as inspiration https://github.com/hwchase17/langchain/blob/master/langchain/retrievers/document_compressors/chain_extract_prompt.py
The GenerativeAI Group|2023-06-25 14:14:19|‎You added Harsh Maheshwari GenerativeAI WhatsApp Group, Jayanth Generative AI WhatsApp Group, and Utkarsh Saxena GenerativeAI WhatsApp Group
~ Adithya|2023-06-25 14:14:31|‎~ Adithya joined from the community
Ritesh Invideo Nilenso|2023-06-25 14:18:11|thanks for the detailed answer. will take a look
~ Clament John|2023-06-25 17:07:04|"I'm building an in-browser semantic search product and I was wondering if I could use tiktoken (but in JS), or should I be using the embeddings endpoint (api.openai.com/v1/embeddings)? They both use the same the same tokenizer - cl100k_base.   Asking so that I can understand if it will cost me to create embeddings (using the API) or if I can use something that never need a network connection.  I know I can run a sentence transformer like all-MiniLM-L6-v2 - huggingface.co/sentence-transformers/all-MiniLM-L6-v2 . But this fails to find certain matches. For example I was searching for ""When did Apple start a store in Bombay"" for this wiki wikipedia.org/wiki/Apple_Inc, but it failed to find a match."
~ Clament John|2023-06-25 17:20:00|Ok, so as I understand the tokenization comes before embedding. OpenAI has not released the vector representation of their tokens, and so it means I have to use their API to get embeddings for gpt-3/4. I can always use an open souce pretrained model (sbert.net/docs/pretrained_models.html) if I wish it to be local first.
Abhishek Mishra|2023-06-25 17:21:44|This particular failure could be because you used Bombay instead of Mumbai.
Dhruv Anand|2023-06-25 17:22:07|There's a library called gpt-tokens in node which you could use to calculate tokens locally
~ Clament John|2023-06-25 17:22:09|Yes, but I was performing a semantic search anyway
Abhishek Mishra|2023-06-25 17:22:31|If openAI embeddings find Bombay and Mumbai semantically same, only then it'll succeed with that instead of miniLM sbert embeddings
~ Clament John|2023-06-25 17:22:48|Yes, but it is a tokenizer, it won't provide vector embeddings
~ Clament John|2023-06-25 17:23:12|Yes, assuming OpenAI's embedding is much better
Dhruv Anand|2023-06-25 17:23:40|There is transformers.js to run any sentence transformers model locally
~ Clament John|2023-06-25 17:23:53|Yes, I'm using that
~ Clament John|2023-06-25 17:24:17|I have a simple version of semantic searching working using miniLM
Dhruv Anand|2023-06-25 17:24:18|I mean using a larger model from that like e5-base would probably be better than depending on OpenAI ada
~ Clament John|2023-06-25 17:25:35|Maybe, will try out all-mpnet-base-v2 (best model available at the moment according to sbert.net/docs/pretrained_models.html)
Soumendra Dhanee|2023-06-25 17:26:33|I think e5 came out on top in recent mteb benchmark
Abhishek Mishra|2023-06-25 17:26:39|Rely on MTEB leaderboard to make your judgement - https://huggingface.co/spaces/mteb/leaderboard
Abhishek Mishra|2023-06-25 17:27:09|Even in that, don't go blindly for top performing embeddings for STS (semantic textual similarity) task
Abhishek Mishra|2023-06-25 17:27:26|You've to consider your performance and cost as well
~ Clament John|2023-06-25 17:27:57|How do I consider / measure performance?
Abhishek Mishra|2023-06-25 17:28:04|For example, if you want similar speed as miniLM, look for similar model size and dimensions
~ Clament John|2023-06-25 17:28:27|Ok, thanks
Abhishek Mishra|2023-06-25 17:28:53|miniLM L6 v2 is 384 dimensions and ~80MB I guess
~ Clament John|2023-06-25 17:28:59|Yes
Abhishek Mishra|2023-06-25 17:29:49|So you can find best model for 384 dim first. Since you'll be running it in the browser, you need to consider your performance first. If cost isn't an issue, you can always go with openAI embeddings.
~ Clament John|2023-06-25 17:30:31|I could run a better model in my infra I suppose. Will it be cheaper than using OpenAI embeddings endpoint?
Dhruv Anand|2023-06-25 17:33:01|You can use HuggingFace inference (api is free up to a limit, endpoints for dedicated compute)
~ Clament John|2023-06-25 17:33:42|Thanks, didn't know that. Much easier to compare each model
~ Om|2023-06-25 19:50:23|‎Pratyush Choudhury added ~ Om
Nirant|2023-06-25 20:27:09|"Quite unhinged and delightful: https://twitter.com/RoyKishony/status/1672280665264386049  ""wrote data analysis codes, interpreted results and wrote 5 transparent, reproducible papers"" using LLMs and the CDC data ‎<This message was edited>"
~ Yash More|2023-06-25 20:30:27|https://twitter.com/sauhaarda/status/1672714475659722754?t=iY5uQgXsoyZp_EMAF2aZ_A&s=08  Some interesting updates, paper probably getting redacted
Dhruv Anand|2023-06-25 20:41:31|"""Paper"" is a bit strong. Just an arxiv submission"
~ Yash More|2023-06-25 20:43:00|Yeah fair lol
Abhinav Verma Longshot.ai|2023-06-25 21:25:43|this should be understood by the models. ‎[6/25/23, 21:27:00] Abhinav Verma Longshot.ai: ‎image omitted
Nirant|2023-06-25 21:28:33|Could be one of these? They're very high quality code embeddings https://huggingface.co/models?search=salesforce+codegen
Abhinav Verma Longshot.ai|2023-06-25 21:31:40|Ok, so they might have just taken the first layer of these models
Ciyunni|2023-06-25 21:34:44|https://www.linkedin.com/posts/dr-jeffrey-funk-a979435_a-critical-look-at-ai-generated-software-activity-7078686623223201792-6ITx  Security? Reliability?
Abhinav Verma Longshot.ai|2023-06-25 21:35:28|Do you think openai has merged the gpt4-0613 with the old gpt4 model? Because gpt4 seems fast today
Nirant|2023-06-25 21:35:56|No, it's a Sunday and folks in US, EU have a life unlike you and me
Nirant|2023-06-25 21:36:05|And stop spilling alpha like this 😤
Nirant|2023-06-25 21:36:27|Sounds like AI generated code has the same flaws as human devs? 🤣
Abhinav Verma Longshot.ai|2023-06-25 21:37:48|It definitely does. I have to constantly check the AI generated code because sometimes the logic that is supposed to be in the for loop is outside it? I'm like bhai aise kaise chalega and all it does is apologies
Nirant|2023-06-25 21:39:34|GPT3.5 is like a 2nd year intern, writes coherent syntax but has no idea about code placement  GPT4 is a 3rd year intern, can place code snippets but function calls, object creation, any higher order logic can be random Code Interpreter is better than most interns and is competitive to many full time devs with prompt engineering
Rajesh RS Generative AI WhatsApp Group|2023-06-25 21:41:20|Anyone checked out Zeroscope? https://huggingface.co/cerspense/zeroscope_v2_XL https://twitter.com/mrjonfinger/status/1672809085849468929
Abhinav Verma Longshot.ai|2023-06-25 21:42:02|This sounds right. ‎[6/25/23, 21:44:20] Nirant: ‎video omitted
Abhinav Verma Longshot.ai|2023-06-25 21:45:27|Which model is this?
Rounak Datta Hackathon Winner|2023-06-25 21:45:44|This is using Kaiber? ‎<This message was edited>
Nirant|2023-06-25 21:45:51|This one which Rajesh shared
Abhishek Mishra|2023-06-25 21:46:10|These are local nuances and not really part of common English training datasets. I'll be able to 1000s of such instances in the world even with openAI. Plus, this is a common limitation of NLP embeddings where a local or proprietary relationship between entities in the dataset can't be captured with same accuracy as common English terms.
Abhinav Verma Longshot.ai|2023-06-25 21:47:17|I get that. But I think this is there from personal experience although might be missing in the model used
Sandeep Srinivasa RedCarpetup|2023-06-25 21:49:34|[PHONE] any examples of Salesforce with finetuned models ? The ones u linked are basemodels
~ Lokesh|2023-06-26 06:08:19|‎~ Lokesh was added
~ AJ|2023-06-26 06:08:19|‎~ AJ was added
~ Gearskart|2023-06-26 06:08:19|‎~ Gearskart was added
Abhishek Mishra|2023-06-25 21:50:50|Yeah, take a language like C and try to write secure low resource code with it. Then try to run it on different OSes, you'll change your opinion about developers being replaced by GPT4.
Nirant|2023-06-25 21:51:35|Yes, random from browser history: https://huggingface.co/sahil2801/instruct-codegen-16B ‎<This message was edited>
Abhishek Mishra|2023-06-25 21:53:21|Especially with named entities, this is a very common problem that generally available embeddings can't solve. It's why we build NER and vocab for proprietary systems first for good results. Keyword based approaches often outperform semantic similarity in local nuances or proprietary vocab.
Rajesh RS Generative AI WhatsApp Group|2023-06-25 21:56:15|Doesn't this also boil down to training data? Going back to the instructGPT paradigm, the model learns to generate code using examples of human code written - not necessarily through full knowledge of the compiler or interpreter underneath
Abhinav Verma Longshot.ai|2023-06-25 21:58:03|Yeah. The training data is better in gpt than most but not susceptible to mistakes
Rajesh RS Generative AI WhatsApp Group|2023-06-25 22:06:35|On a related note I've often wondered what the embeddings would look like for models like InstructGPT, Codex and so on. Sequences matter here despite the kind of token you compute because programming languages have significant overlaps in keywords and reserved words.
Sandeep Srinivasa RedCarpetup|2023-06-25 22:09:21|This is trained on the codegen-salesforce 😂.  What is the best of class for code generation base models meant for fine-tuning?
Nirant|2023-06-25 22:09:52|Ohh, I thought you wanted to see if Salesforce models can be finetuned
Nirant|2023-06-25 22:10:04|StarCoder Base
Abhishek Mishra|2023-06-25 22:10:35|Something that interested me today - *A ORCA repro effort on OpenLlama 13B base*  https://huggingface.co/psmathur/orca_mini_13b  Leaderboard eval is not shared here so can't say if it's results are similar to orca as in the research paper but the training has used similar methods for custom datasets as mentioned in the research paper.
Nirant|2023-06-25 22:11:20|Speaking of Orca, Emad of Stability.ai disses it because it's not true FOSS: https://twitter.com/EMostaque/status/1672736494761693184
Abhishek Mishra|2023-06-25 22:11:23|Isn't the WizardCoder the highest? Or did you mean commercially licensed?
Nirant|2023-06-25 22:11:50|Best which you can finetune. WizardCoder is already kinda finetuned for benchmark overfitting in my mind
Abhishek Mishra|2023-06-25 22:12:14|Ok, got your context
Abhishek Mishra|2023-06-25 22:12:50|True, orca and phi both have such wonderful results in the paper that not releasing their datasets and models kind of ruins the impact the papers can have.
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-06-25 22:15:29|Haven't begun my deployment of coder models. You'd recommend starting with wizardcoder or starcoder base ?
Nirant|2023-06-25 22:16:10|GPT4 is miles ahead of these and will stay ahead for most of 2023
Nirant|2023-06-25 22:16:15|And perhaps 2024 too
Nirant|2023-06-25 22:16:42|But if you've to do FOSS for any reason, begin with Replit Code and finetune on your code base
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-06-25 22:18:43|Makes sense.   I wanted to work with large repos. And developing flows to keep brainstorming and write code to expand my codebase.  GPT is too expensive and loses context often unless given the same file / functions again and again.  I'll try this out. Thanks.
Nirant|2023-06-25 22:23:09|You might find these tools interesting as well:  Code Nav, FOSS project: https://github.com/bloopai/bloop Code Nav but inline, and does generation,  needs OpenAI Key: https://www.cursor.so/
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-06-25 22:23:51|Thanks a lot.
Abhishek Mishra|2023-06-25 22:28:21|Bloop is one of the most interesting works for this problem for sure.
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-06-25 22:29:57|https://aider.chat/  The ctags approach here actually works wonders. And I've made some modifications to keep sending relevant parts of it to keep establishing context.  Will be better off putting this is a vectorDB for faster and smarter retrieval of the repo map
Abhishek Mishra|2023-06-25 22:41:09|I'll check this out. I'm interested in the different ways people are approaching the problem of treating source code as a document or database.
Abhishek Mishra|2023-06-25 22:42:26|I've seen multilevel or unilevel summarisation approaches mostly so far.
Sandeep Srinivasa RedCarpetup|2023-06-25 22:44:45|Why replit code ? Genuinely curious. Asking specifically for fine-tuning.
Nirant|2023-06-25 22:46:22|Small models are easier to finetune frequently and update for auto-complete kinda use cases
Pratyush Choudhury|2023-06-25 22:47:23|This has been a recent learning
Pratyush Choudhury|2023-06-25 22:47:25|Is there a platform though that allows me to it well?
Abhishek Mishra|2023-06-25 22:47:43|For me, there's a bigger question of what approach do you take to build the fine tuning dataset for code gen cases for specific repos or source codes.
Nirant|2023-06-25 22:48:25|Replicate should be launching this soon
Pratyush Choudhury|2023-06-25 22:50:59|Nice
Abhishek Mishra|2023-06-25 22:55:55|Do you take the individual functions and modules and turn them into instruction response pairs? Or do you take the commit messages as Instructions and the commits as responses? Or do you take an unstructured approach and just rely on next token prediction to do the trick?
Pratyush Choudhury|2023-06-25 22:56:14|In my mind, an ideal setup would be something that has access to data so that it allows me to switch between models and also automatically fine-tunes those  Something like this exists?
Ankur Pandey|2023-06-25 23:49:16|"A ""camera"" that, instead of capturing light, captures your GPS coordinates, looks up some information about your location, plugs those bits into some sentences like Mad-Libs, and sends the whole thing off to an AI to generate an image.  The ""camera"" is incapable of actually looking at the world.  https://bjoernkarmann.dk/project/paragraphica"
Nirant|2023-06-26 00:33:45|Little too broad, but for text in particular — AutoNLP-way of thinking was a thing, and that can still be extended to support these use cases. If I spend enough brain cycles, should be able to do this for code too
Pratyush Choudhury|2023-06-26 00:36:25|Interesting that you call it broad,  Would you be able to elaborate please?
Abhinav Verma Longshot.ai|2023-06-26 00:52:24|My summary of textbooks are all you need paper https://averma12.notion.site/Textbooks-are-all-you-Need-d5d2c0451b1d40ffa06739fe6defde6f?pvs=4  Also here is the summary for the Orca paper. https://averma12.notion.site/Orca-paper-Explained-136fbed4b1cc40e28f56fdab2755b6fd?pvs=4
Samhan Meta/Twitter Friend|2023-06-26 02:33:14|That was a great summary of the textbooks are all you need paper. This paper makes me think that current advances are not merely about scale. A relatively small amount of tokens (billions) and fine tuning (millions) on a model that is not particularly large (1 B or smaller) is remarkably good at things like coding and would have been unthinkable a few years ago.
Samhan Meta/Twitter Friend|2023-06-26 02:36:07|If the task is narrowly scoped it seems quite doable for anyone in this group with some months of effort to train a model that is competitive with GPT-3. The bottleneck is actually putting together 5-10B “high quality tokens”
Abhishek Mishra|2023-06-26 02:36:33|Neither scale nor architecture changes. Primarily a change in quality of coherence of data.
Samhan Meta/Twitter Friend|2023-06-26 02:37:17|Who knows maybe even the order in which data is fed can make a difference
Saurabh Karn Nyai|2023-06-26 02:38:54|Do you mean we are back to handcrafting high quality dataset on tasks?
Abhishek Mishra|2023-06-26 02:39:33|"In my eyes, it's the same thing as creating a ""small monopoly"". Not everyone needs to have a model rivalling GPT3 locally in everything. In most cases, beating it in one or two areas, even if it's your home ground, may add significant value."
Samhan Meta/Twitter Friend|2023-06-26 02:40:12|Not quite but it looks we are headed there. The more you hand craft and with more expertise the more results it seems to yield
Samhan Meta/Twitter Friend|2023-06-26 02:40:34|So the bottleneck will become the availability of expertise and effort to make really excellent data sets
Samhan Meta/Twitter Friend|2023-06-26 02:41:18|See this for eg https://openai.com/research/improving-mathematical-reasoning-with-process-supervision
Samhan Meta/Twitter Friend|2023-06-26 02:41:35|We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.
Abhinav Verma Longshot.ai|2023-06-26 02:41:42|What if you extend this to math problems from old textbooks.
Abhishek Mishra|2023-06-26 02:41:46|I will add, excellent datasets without API distillation from GPT4. Clean commercial excellent dataset.
Samhan Meta/Twitter Friend|2023-06-26 02:43:43|Imagine doing this on top of text books are all you need. You will get even further improvement
Abhinav Verma Longshot.ai|2023-06-26 02:47:18|Is there a framework to follow for this because I think with enough people combined you can get 5-6 gb of high quality data which can give good performance
Abhishek Mishra|2023-06-26 02:49:44|I think we've a 1T dataset that's completely clean since it's crowd created. I think Red pajama is one.
Abhishek Mishra|2023-06-26 02:50:35|But now we've new dataset methodologies that we may want to try out like the ones shared in LIMA, Orca, phi-1.
Abhinav Verma Longshot.ai|2023-06-26 03:05:46|Correct
~ Vik|2023-06-26 04:37:23|i always thought gpt4 was ensemble of models. the moe paper sort of proved this theory
Nirant|2023-06-26 06:37:16|"There is no single ""fine-tuning"" — it depends on:  Quality: data quality, data size, domain, task Cost: Talent, compute, data size"
~ Saravanan Balakrishnan|2023-06-26 09:46:26|‎Ravi Theja added ~ Saravanan Balakrishnan
Sudharshan GenAI|2023-06-26 10:58:57|https://news.ycombinator.com/item?id=36460082
Pratyush Choudhury|2023-06-26 11:09:00|Yes, sir - which is why thinking if having some/all of these functionalities on one platform will be helpful  Anecdotal conversations suggest me that this could be a good idea
~ Saravanan Balakrishnan|2023-06-26 12:03:22|Good afternoon everyone. My name is Saravanan. I am from a healthcare startup called Amura.  Thanks to the mods for adding me to the group and SRK for leading me to it.  🙏 ‎[6/26/23, 12:12:57] Jay Pokarna 2014 BPCC: ‎image omitted
Ambika Computational Mama|2023-06-26 12:13:59|it works - succinct answers for busy parents
Ambika Computational Mama|2023-06-26 12:14:07|"from a ""credible"" source"
Ambika Computational Mama|2023-06-26 12:14:36|I've been there and there is so much content out there it can be overwhelming
Abhinav Verma Longshot.ai|2023-06-26 12:15:07|It is retrieval augmented generation. Fetch the relevant results into one helpful snippet
ashish Acgt01 Twitter|2023-06-26 12:15:23|Summarization, done well, can be a killer app
Abhinav Verma Longshot.ai|2023-06-26 12:15:24|Long snippet
Ambika Computational Mama|2023-06-26 12:16:51|its a really good move IMO - as new parents are always looking for relevant information and as a gneartion we are not interested in the advice of the older generation
Dr. Pratik Desai KissanGPT|2023-06-26 12:49:26|Google search May work for everything probably, but then the user is responsible for the cognitive load of processing and reasoning.
Rajesh RS Generative AI WhatsApp Group|2023-06-26 12:52:27|This is the big draw to ChatGPT for a lot of folks. Lower cognitive load.
Dr. Pratik Desai KissanGPT|2023-06-26 12:53:20|Just like Google was for directory based search engines.
Rajesh RS Generative AI WhatsApp Group|2023-06-26 12:55:45|That’s where LLM apps are different. With search there was a chance of misinformation or bias and certainly it was highlighted. But with LLMs everyone knows that there’s a bigger possibility of this and that as a generative model it is likely to hallucinate- and still end up using it
Dr. Pratik Desai KissanGPT|2023-06-26 12:59:42|A topic for Philosophy group
Abhinav Verma Longshot.ai|2023-06-26 13:28:08|Join the philosophy group for this discussion.
Abhinav Verma Longshot.ai|2023-06-26 13:28:33|You can join the philosophy group for this discussion
Abhinav Verma Longshot.ai|2023-06-26 13:33:00|These risks can be mitigated
Nirant|2023-06-26 13:37:47|Speaking of RAG, people are working on Enterprise-readiness for RAG systems e.g. came across this https://github.com/danswer-ai/danswer which looks promising from a design PoV
Pratyush Choudhury|2023-06-26 13:40:22|Was noodling on this - very helpful
Abhinav Verma Longshot.ai|2023-06-26 13:40:46|Yes. There have been a few tools like this that have come up. This space is heating up now ‎[6/26/23, 13:43:28] Nirant: ‎image omitted ‎[6/26/23, 13:43:29] Nirant: ‎image omitted
Chaitanya A GenAI|2023-06-26 13:46:40|What’s the infrastructure running this?
Nirant|2023-06-26 13:47:16|t3.2xlarge
Abhinav Verma Longshot.ai|2023-06-26 14:00:15|is there a difference in performance of running these on t3a (amd processors) or the aws internal graviton processors( constraint of this is that it only supports ARM architecture so diff docker images might be required)
Nirant|2023-06-26 14:00:33|Haven't tried t3a
Abhinav Verma Longshot.ai|2023-06-26 14:00:58|this is just the indian in me, trying to reduce costs even further. t3a is 60% of price of t3
Nirant|2023-06-26 14:01:39|He'll flip the code to FOSS, go ahead and try!
Abhinav Verma Longshot.ai|2023-06-26 14:01:55|cool
Dr. Pratik Desai KissanGPT|2023-06-26 14:04:11|Are you using Wiki embeddings for testing?
Nirant|2023-06-26 14:04:40|https://huggingface.co/datasets/kshivendu/dbpedia-entities-openai-1m
~ Srinivasan Nandakumar|2023-06-26 14:11:07|I think doing next token prediction with fill in the middle technique will help the model learn a lot about your codebase
Abhinav Verma Longshot.ai|2023-06-26 14:20:54|OpenAI has a fill in middle model and a paper on this as well. Can't remember the paper, read it last year
Dev Aggarwal|2023-06-26 14:21:25|Both codex and gpt3 have this on the playground and inside copilot
Abhinav Verma Longshot.ai|2023-06-26 14:21:37|correct
Abhishek Mishra|2023-06-26 14:23:01|Yes, that's how it has been done in multiple cases. That's why I mentioned it as the third option in my comment.   I found multiple papers that talk about the same but the fill in the middle approaches typically generate one line and are also limited by context length.  Given these constraints with this approach, it's actually easier using vector DBs to fetch hierarchical schema of the code and complete a given code generation task. But overall, both options leave a lot to be desired.  Some existing researches: *Repofusion* https://arxiv.org/abs/2306.10998 *Repocoder* https://arxiv.org/abs/2303.12570 *Prompt proposal on repository level* https://arxiv.org/abs/2206.12839
Abhinav Verma Longshot.ai|2023-06-26 14:24:22|copilot even had a neat way of being able to configure how much to take as prefix and how to much to take as suffix
Abhishek Mishra|2023-06-26 14:24:26|Yeah, you mean this - https://arxiv.org/abs/2207.14255
~ Kp|2023-06-26 14:24:35|When will a nobody like me get it :(
Abhinav Verma Longshot.ai|2023-06-26 14:24:48|yeah. this one
~ Kp|2023-06-26 14:24:49|Code interpretor
~ Kp|2023-06-26 14:25:10|Interpreter*
Abhishek Mishra|2023-06-26 14:25:53|Maybe not as good as code interpretor, but I saw some plugins today that talk to your code given the GitHub repo, check these out and see if you like them.
Abhinav Verma Longshot.ai|2023-06-26 14:26:27|arrey chill, many people haven't got it. Solution is to make your 3rd year intern work extra hard
~ Kp|2023-06-26 14:28:09|I'll probably be that 3rd year intern in a few years.
~ Kp|2023-06-26 14:28:58|Do they randomly roll interpreter out or is it some kind of wait list?
Abhishek Mishra|2023-06-26 14:29:02|I'm interested in knowing which companies keep people in internship position for 3 years 😂
~ Kp|2023-06-26 14:29:12|[PHONE]  [PHONE]
Abhinav Verma Longshot.ai|2023-06-26 14:29:53|I was assuming, 3rd year ya final year student doing internship
Dev Aggarwal|2023-06-26 14:38:23|Please, none of these are anywhere near any good intern. A good intern is capable of googling the right answer
Nirant|2023-06-26 14:39:53|By this definition, a good intern is harder to find than a unicorn paying 50 LPA salary in BLR
Dr. Pratik Desai KissanGPT|2023-06-26 14:43:05|My intern raised white flag in a week, after getting overwhelmed looking at the codebase. Good interns are really like unicorns.
Dhruv Anand|2023-06-26 14:53:07|There should be a tag by which one can filter HuggingFace datasets to just embeddings dumps. Anyone know of a way to do it?
Shivendu Kumar|2023-06-26 15:26:29|Was looking for the same. Didn't find anything reliable. The best bets are certain tags and keywords. I can tell you those if you want.
C Chaitanya Nutanc|2023-06-26 16:27:41|Is the embeddings title+string or just string?
~ Ankit Sharma|2023-06-26 16:40:55|What are the different methods to use transliteration from Hinglish to Hindi??
C Chaitanya Nutanc|2023-06-26 16:42:54|Ok got it. Thanks for this. Will try to experiment and see if we can create a compressed embedding space on top of this. ‎[6/26/23, 17:26:11] Dev Aggarwal: ‎image omitted
Abhishek Mishra|2023-06-26 17:28:03|Yeah, it's been 5 weeks I guess since it moved from 0-1 to 0-2
Chaitanya A GenAI|2023-06-26 17:29:34|check this out, works well for transliteration in the Indic context  https://github.com/libindic/indic-trans
Aashay Sachdeva MPL Data Scientist|2023-06-26 17:57:53|https://twitter.com/alighodsi/status/1673300587419701249?s=46  Databricks is now a genAI company
Kartik Mandaville|2023-06-26 18:00:04|Are there any chatgpt plugins making money? How do you even do distribution? I've been thinking about building one but haven't really seen anything useful.
Jithin James Ragas|2023-06-26 18:06:43|sama has said that plugins have no PMF. they did a v good job taking the learnings and building openai functions.
Dev Aggarwal|2023-06-26 18:09:03|one man army
Abhinav Verma Longshot.ai|2023-06-26 18:09:16|plugins themselves aren't making money yet. but it can happen. ones like zapier etc
Rajesh RS Generative AI WhatsApp Group|2023-06-26 18:40:37|They had this capability already with Dolly - but great to see this.
Saksham Generative AI WhatsApp Group|2023-06-26 18:40:41|My card charged 5% TCS for the ChatGPT plus subscription. :(
Saksham Generative AI WhatsApp Group|2023-06-26 18:41:12|Anyone aware of cards/ bank that dont charge this?
Abhinav Verma Longshot.ai|2023-06-26 18:43:02|non indian  cards
Abhinav Verma Longshot.ai|2023-06-26 18:43:11|amex probably doesn't
Abhishek Mishra|2023-06-26 18:44:39|My card didn't levy any taxes other than the 18% govt levied GST.
Rajesh RS Generative AI WhatsApp Group|2023-06-26 18:52:48|Hi folks, I'm building a chat bot which produces canned responses half the time, and good responses (based on a chunked knowledge base) the remaining portion of the time. How would I troubleshoot this? Embedding computation is my first hypothesis for root cause analysis, but could there be anything else I should look at?
Rounak Datta Hackathon Winner|2023-06-26 18:57:36|The ranking algorithm that's being used in your vector store isn't working that great? Maybe the search query term is matching a vast surface area of objects from your knowledge base ... and the valuable matches are not ranked to top?
Shashwat TDC|2023-06-26 19:01:44|This sparked another thought. This is probably the oldest and most mature usecase. It seems people are still building this in-house. Are there not good enough services for this already? What are the factors apart from prices that might be forcing people to build this in-house than buying a third party solution
~ Nayan Shah|2023-06-26 19:02:06|What is your chunk suze maybe playing with chunk size may help , by that i mean reducing it to 2000 or 1500
~ Arvind Sankar|2023-06-26 19:06:04|Hi all, I am trying to create a large dataset for fine-tuning, analysis, etc.  It involves sending requests to a relatively unreliable endpoint (as in it may require a few tries for about 10% of the requests) and scrapping URLs from it that point to PDFs. Subsequently it would involve downloading tons of PDFs file and extracting text from it. The amount of data will be too huge for using CSVs. The webscrapper would probably run for days.  What would be the preferred stack for such a task? Would GCP be appropriate for the task or are there other platforms more conducive for this (which may potentially have IP rotation, etc.)
~ Anjineyulu|2023-06-26 19:11:59|Try to store I parquet formats
~ Anjineyulu|2023-06-26 19:12:20|*in
Sainath GenerativeAI WhatsApp Group|2023-06-26 19:15:22|This looks more like a data engineering problem. Are you trying to do all of this on the fly and where are you going to use ai ?
~ Arvind Sankar|2023-06-26 19:19:38|I am essentially intending on collecting Indian patent data. Aside from days analysis, Initially i would hope to use the data for fine-tuning existing open source models from a document automation point of view.
~ Arvind Sankar|2023-06-26 19:19:43|Data analysis*
Rajesh RS Generative AI WhatsApp Group|2023-06-26 19:19:50|Thanks, that makes sense. I’ll explore it
Rajesh RS Generative AI WhatsApp Group|2023-06-26 19:20:16|Do you know what frameworks are out there?
Saurabh Karn Nyai|2023-06-26 19:26:59|I had estimated this sometime back. You should be able to outsource this task to any of the companies which builds scraper if you don’t intend to maintain the pipeline of newly granted patents. Speak to Arbdossier who I know were working to get this data.   Good thing is that data is public. Second, what the usecase to fine tune? Are you wanting to create a patent application search or generation application?
Abhishek Mishra|2023-06-26 19:30:18|If you're just running your script on a remote server and need access to GPU as well, try modal.
~ Arvind Sankar|2023-06-26 19:30:43|Search is something i do intend to work on, but not at the moment.  Generating parts of specification, claims, drafting prototypical versions of certain intentions, etc are my use cases
Sainath GenerativeAI WhatsApp Group|2023-06-26 19:31:03|Then I would suggest to separate data collection and analysis. Here data collection is more complex owing to different issues you mentioned. Handling data can be done in many ways.
Saurabh Karn Nyai|2023-06-26 19:31:45|Then public data might not work. I filed a patent application last year and your best shot at sourcing this is some patent filing firm or a lawyer
~ Gaurav|2023-06-26 19:32:42|If there's GPU required in this pipeline then feel free to try Q Blocks as well.
~ Nayan Shah|2023-06-26 19:33:41|Or sqlite
Sainath GenerativeAI WhatsApp Group|2023-06-26 19:34:16|Has anyone worked on analyzing amazon reviews using open ai or any open source models? I would like to talk to anyone as I am trying to build a product based on it.
~ Arvind Sankar|2023-06-26 19:34:47|Yes. I did realise my technical wouldn't sufficient to do them simultaneously either
~ Arvind Sankar|2023-06-26 19:38:51|I would like to avoid that due to reasons, despite being a patent lawyer at a firm.  Unreliability aside, my current pain seems to be handling the data i retrieve. I can't handle it my laptop ( sending requests and storing data) and i am relatively new to cloud.
~ Arvind Sankar|2023-06-26 19:39:15|I was going to understand preferred stack for the task
~ ani|2023-06-26 20:00:42|‎Soumyadeep Mukherjee added ~ ani
Lalit Pagaria|2023-06-26 20:10:12|We (https://oraika.com) did it. DM
Aashay Sachdeva MPL Data Scientist|2023-06-26 20:10:52|Had created a small chrome extension to summarise the comments into pros and cons.
~ .|2023-06-26 20:12:50|‎Zainab Bawa added ~ .
~ Nitin Kishore|2023-06-26 20:39:38|https://twitter.com/DimitrisPapail/status/1673331620034625537?t=oS6eoprFL_3vmvUvwlsw0A&s=08
Rajesh RS Generative AI WhatsApp Group|2023-06-26 20:40:43|Using chunk sizes of around 2000, right now
Rajesh RS Generative AI WhatsApp Group|2023-06-26 20:41:23|With Redis, I see HNSW and FLAT, no implementation of FAISS available. Anyone has any recommendations on which similarity measures to consider?
Rajesh RS Generative AI WhatsApp Group|2023-06-26 20:41:42|FAISS seems quite popular, HNSW is also
Lalit Pagaria|2023-06-26 20:42:18|AFAIK FAISS is a library
~ Gearskart|2023-06-26 20:47:02|Did someone experiment Colbert V2 retrieval ?
Diptanu Choudhury FB AI|2023-06-26 22:02:39|There are trade offs between flat and hnsw. Don’t remember from the top of my head, with more points hnsw does better
Diptanu Choudhury FB AI|2023-06-26 22:04:29|Yes! Colebert does better than DPR when the k is small but with larger k-s DPR does better.
Sainath GenerativeAI WhatsApp Group|2023-06-26 22:19:02|https://www.databricks.com/company/newsroom/press-releases/databricks-signs-definitive-agreement-acquire-mosaicml-leading-generative-ai-platform  For $1.3 Billion
Sainath GenerativeAI WhatsApp Group|2023-06-26 22:20:56|Has anyone evaluated their models? seems the recent one is MPT-30B
Abhishek Maiti|2023-06-26 22:39:56|Has to be the fastest journey to a billion dollar acquisition https://twitter.com/NaveenGRao/status/1333965556496560129
~ Pranay Desai|2023-06-26 22:40:57|wiz.io would like to enter this conversation
Apurv Aurva.io Sahil's Friend|2023-06-26 22:50:26|haha. Wiz isn't acquired yet! But given the growth, they might soon send up with an IPO
Abhinav Verma Longshot.ai|2023-06-26 23:25:35|I'm just getting prepared for side effects from the new gpt4 model rolling out tommorow
~ Ankit Sharma|2023-06-27 00:37:09|One basic noob question   For a query to find similar queries from a set of data does different embeddings have different meanings?  For example if I am using the cohere embedding or HF embeddings or OpenAI embeddings. How much this matter? Has anyone done any evaluation for these different embedding techniques?
Abhinav Verma Longshot.ai|2023-06-27 00:38:12|The scores differ slightly. So your thresholds need to be adjusted accordingly for what is considered similar
Dev Aggarwal|2023-06-27 00:38:13|https://huggingface.co/spaces/mteb/leaderboard
Abhishek Mishra|2023-06-27 00:59:06|I believe there are 2 parts of your question. 1. How do different embeddings differ and what should be considered before choosing one? 2. Is there an eval to understand the differences in performance between embeddings?
Abhishek Mishra|2023-06-27 01:02:03|#1 Embeddings differ in * Training corpus and vocab * Task on which they're optimised - semantic similarity/classification * Dimensions of embeddings - this is important for how big your document size is that you're going to process with the embeddings * Method of generating embeddings - sparse/dense/contextual or word vs sentence embeddings  #2 - The eval to identify which embeddings of which dimension perform best on a given task is MTEB leaderboard
Abhishek Mishra|2023-06-27 01:04:13|For all practical purposes, it'll be ok for you to go to MTEB leaderboard and just sort for best embeddings for the task you want and budget yourself to the size of embeddings based on how much compute and data you've to work with. Or just use a paid api service to manage all of that for you.
Nirant|2023-06-27 05:28:41|Existing Prompts will break or have silent failures starting today!  Short Term Fix: ✅ gpt-4 →  gpt-4-0314 ✅gpt-3.5-turbo → gpt-3.5-turbo-0301
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 05:34:47|Thanks a lot nirant. Is there a link to a blog or changelog? Or is today the cutoff date for the functions update launched a couple of weeks ago
Dr. Pratik Desai KissanGPT|2023-06-27 05:35:29|Hardmaru left StabilityAI. Things heating up.
Nirant|2023-06-27 05:46:58|Cutoff date
Ramakrishnan Lokanathan|2023-06-27 06:56:05|💡use a rapid writing format like short hand to convert user input into that format>send to GPT>Instruct GPT to respond in the same format>convert to normal text for user output.  Not sure if can work on production yet but very niche solution to a niche pain point. This reduces the token cost directly.  Any thoughts? ChatGPT Thoughts: https://chat.openai.com/share/cfb8bbba-41f3-4d24-b39f-d6398615c39a ‎[6/27/23, 07:07:59] Ramakrishnan Lokanathan: ‎image omitted ‎[6/27/23, 07:08:00] Ramakrishnan Lokanathan: ‎image omitted
Ramakrishnan Lokanathan|2023-06-27 07:08:55|Need something better than short hand. However reducing every input into a a shorter token input and getting output also such has potential.   Even 15-20% savings per call is great.
Amir Nagri|2023-06-27 08:33:53|QQ: Is OpenAI Whisper still the reigning publicly accessible top-tier model for audio-to-text conversion, or has a new contender taken its place? tx 🙂
~ Vipul|2023-06-27 09:01:18|Try https://deepgram.com/ once
~ Ashish Anand|2023-06-27 09:28:01|‎~ Ashish Anand requested to join
~ Ashish Anand|2023-06-27 09:28:11|‎~ Ashish Anand joined using this group's invite link
Anshul Bhide Replit|2023-06-27 09:47:30|Register here for the panel with Chief Scientist of MosaicML, Jonathan Frankle! its a little late for India (230am), but it will be recorded as well.   https://lu.ma/g4asrvqy
~ Arindam Barman|2023-06-27 10:18:47|Models are okay but they are great to fine tune on.
Ravi Theja|2023-06-27 11:04:17|https://lilianweng.github.io/posts/2023-06-23-agent/ - detailed blog post on 'LLM Powered Autonomous Agents' from Lilian Weng.
Pratyush Choudhury|2023-06-27 11:04:34|Excellent read, just finished it
ashish Acgt01 Twitter|2023-06-27 11:11:13|it just popped up on my twitter feed, was just about to post that, excellent read !
Abhinav Verma Longshot.ai|2023-06-27 11:17:46|How are you or others finding the new model
~ Darshan Savaliya|2023-06-27 11:19:41|btw, quick question How does anyone join this community? Is there a link to the group or something or shall I tag the admins here along with the contact number?
Ravi Theja|2023-06-27 11:22:05|DM any of the admins, the contact number they will help you out.
Pratyush Choudhury|2023-06-27 11:22:48|DM one of the admins, that's the easiest way for noe
Anubhav Dubdub.Ai|2023-06-27 11:29:55|Hey guys, Has anyone here done multi-node distributed training using Pytorch on E2E?
Anubhav Dubdub.Ai|2023-06-27 11:30:42|We have been struggling with this for some time.
~ Vinay|2023-06-27 11:38:01|Using gpt-4-0613 for few days now. Longer & complex prompts run much better. 8k is great, but some loss happens when you run 8k vs 4k. Claude seems too far behind when compared to this.
Anubhav Dubdub.Ai|2023-06-27 11:38:59|Or anywhere else where we can get multiple H100s at the same price as E2E
Abhinav Verma Longshot.ai|2023-06-27 11:49:13|4k? Are you talking of 3.5 turbo?
~ Vinay|2023-06-27 11:54:11|no i meant using gpt-4-0613 itself. it supports upto 8912 tokens. found 4k to be a little better at capturing some nuances that the model glosses over at 8k.
Abhinav Verma Longshot.ai|2023-06-27 11:55:18|Ok so you mean context length
Abhinav Verma Longshot.ai|2023-06-27 11:56:13|I was a bit shocked at first. I was like did they reduce context length window as well? Then a lot of my prompts would break
~ Vinay|2023-06-27 11:56:42|that'd be a nightmare :)
Nilesh Transcend|2023-06-27 13:01:48|How are Mosaic's text models in terms of quality and cost? https://docs.mosaicml.com/en/latest/inference.html ‎[6/27/23, 13:03:17] Nilesh Transcend: ‎image omitted
Nirant|2023-06-27 13:42:54|Looking for a reviewer for this PR, I've never done JS/TS — so any pointers are good e.g. how can I test this, how can I make reviewer's life easier:   https://github.com/hwchase17/langchainjs/pull/1771
Dhruv Anand|2023-06-27 13:52:00|by building the lib from source and using in a ts test? https://blog.logrocket.com/testing-typescript-apps-using-jest/
Rounak Datta Hackathon Winner|2023-06-27 14:02:03|I couldn't find a docker-compose which starts a local qdrant instance, and therefore it seems that the integration test for qdrant has been intentionally skipped: https://github.com/hwchase17/langchainjs/blob/main/langchain/src/vectorstores/tests/qdrant.int.test.ts#L23  So, upto you whether you'd like to include all that testing infrastructure and then try test the api-key based auth for the local server itself (https://qdrant.tech/documentation/guides/security/#authentication - its supported). But that might be too much for this PR's scope 🙈
~ Nischal - Collectiv AI|2023-06-27 15:13:28|Is there any vector DB that supports search & return all vectors by metadata like traditional dbs?
Nirant|2023-06-27 15:13:40|Yup, sounds like a job for next PR
Pratik Bhavasar|2023-06-27 15:16:11|Maybe Elasticsearch
~ raj()|2023-06-27 15:17:38|Weaviate supports this
Nirant|2023-06-27 15:19:52|Every VectorDB does if you've IDs from the metadata query/filter
Karishnu Poddar Yellow.ai|2023-06-27 15:20:30|Did you try Chroma?
Pratyush Choudhury|2023-06-27 15:20:58|Good question - I think Weaviate does that (from anecdotal conversations)   1/ It allows storing data objects and vector embeddings from various ML models  2/ It enables combining multiple search techniques such as keyword-based and vector search  Might be a little off - would let other practitioners contribute/correct
Nirant|2023-06-27 15:21:06|Hashnode (https://hashnode.com/rix) will speaking about Anthropic in Production and Llama Index contributor Ravi [PHONE] will be speaking about Llama Index in production including evaluation: https://lu.ma/ai-talks-4
~ bhanu.io|2023-06-27 15:38:58|Appied- looking forward to attending this - Also does anyone know the average wait time for getting api access approval for anthropic ?
aashutosh GenerativeAI WhatsApp Group|2023-06-27 15:46:44|Took almost a month for us ‎<This message was edited>
Nirant|2023-06-27 15:57:21|OpenAI competes for the same $$ as MSFT 🤯  https://twitter.com/frantzfries/status/1673410118246105088
Abhishek Mishra|2023-06-27 15:59:22|MS owns 75% of openAI's profits until it's 10B investment is paid off.
Abhishek Mishra|2023-06-27 15:59:37|So it's like heads I win, tails you lose.
~ bhanu.io|2023-06-27 16:00:03|Were you given access to all the models ? I have applied yesterday, fingers crossed.
Nirant|2023-06-27 16:01:33|which gives OpenAI lot of incentive to either never declare profit or declare profits and dividend it out asap
Kaushik Bokka|2023-06-27 16:01:40|How to get access to the Langchain platform?
Pranjal Mehta|2023-06-27 16:02:29|OpenAI brand is way cooler than MSFT in consumer. If I was Microsoft, I would let OpenAi go consumer and then buy them out while maintaining the brand
ashish Acgt01 Twitter|2023-06-27 16:04:01|Interesting ! https://twitter.com/soumithchintala/status/1671267150101721090
Ankur Pandey|2023-06-27 16:11:25|Microsoft consumer is way bigger. It has windows and MSN and Bing (which is also profitable) and LinkedIn and Skype and even teams launching for consumers
Abhishek Mishra|2023-06-27 16:19:25|MS owns 49% of openAI anyway, they would not mind openAI increasing itself in valuation. MS is a giant and a household name, so it's not easy for anybody to replace them willy nilly in the short term. Plus they've rights to use openAI products in their own products. Quite a brilliant deal for 10B actually.
Abhishek Mishra|2023-06-27 16:20:15|Yeah, they can continue spending on infra. But guess who provides them infra primarily - Azure 😂
~ Pradeep Ayyagari|2023-06-27 16:35:15|Which begs the question - why would OpenAI do a deal like this, where they give away the first rights to all tech they develop to MS.
~ Pranay Desai|2023-06-27 16:37:23|I guess at the time, access to capital and compute was important
ashish Acgt01 Twitter|2023-06-27 16:38:20|ChatGPT was not a sure shot. They took in the Microsoft deal and investment when they had a vague goal to work on AGI and no idea how lucrative it could become
ashish Acgt01 Twitter|2023-06-27 16:40:49|I am talking about the 1 billion $ investment in 2019  When OpenAI transitioned from non profit to capped for profit
ashish Acgt01 Twitter|2023-06-27 16:42:48|july 22, 2019 https://openai.com/blog/microsoft-invests-in-and-partners-with-openai
Rajesh RS Generative AI WhatsApp Group|2023-06-27 16:44:23|I remember a video about OpenAI where they discussed Musk's early involvement - before the MSFT partnership. Musk pumped in about a billion each year, if I'm correct
Gokul Krishnan|2023-06-27 16:58:59|He said he would but the actual money quite merger. He asked for sole  control If they wanted more money. Sam refused and went with MSFT
Shan|2023-06-27 17:01:40|the _next_ cage fight will be Musk v Altman
ashish Acgt01 Twitter|2023-06-27 17:05:29|Given Musk's recent behaviour at twitter over the last year or so, very wise decion by Sama ! :)
ashish Acgt01 Twitter|2023-06-27 17:05:53|*decision
~ Surya Penmetsa|2023-06-27 17:13:31|‎Ravi Theja added ~ Surya Penmetsa
Rajesh RS Generative AI WhatsApp Group|2023-06-27 17:37:13|Despite his behaviour I think Twitter got better thanks to Musk's acquisition - they actually generate revenue these days, and some features are welcome. Some like sketchy validated accounts are still an issue but also proved that you don't need a huge team like Twitter had to run that scale of application. I could be wrong though - time will tell.
Nirant|2023-06-27 17:40:28|I'm very tempted to chime in, but this is most def off topic for this forum 🙏
Rajesh RS Generative AI WhatsApp Group|2023-06-27 17:40:58|Thanks, Nirant for keeping me on track.
Anshul Khandelwal Invideo|2023-06-27 17:43:29|Nah... Nowhere close to a bil a year...
Anshul Khandelwal Invideo|2023-06-27 17:43:47|https://techcrunch.com/2023/05/17/elon-musk-used-to-say-he-put-100m-in-openai-but-now-its-50m-here-are-the-receipts/
Ketan Twitter Intro|2023-06-27 17:50:37|I am sure msft have considered this prior to investment and later promoting. What are the msft products likely to be disrupted by openai, not immediately but in 3-5 years span? ‎<This message was edited>
aashutosh GenerativeAI WhatsApp Group|2023-06-27 17:51:22|Claude & Claude Instant v1
~ Vikas|2023-06-27 17:56:20|yes, looks like proper execution
~ Karan|2023-06-27 17:56:21|Does anyone have any rough numbers / guesstimates on what revenue openAI and FM companies are currently run rating at? Similarly, any numbers for other Infra providers?
Shalabh Aspiro|2023-06-27 18:02:47|Applied 3-4 days back. But go no confirmation mail about being on the waitlist either. Was it case with you guys as well?
aashutosh GenerativeAI WhatsApp Group|2023-06-27 18:04:38|Yup
Nafeen WriteSonic ML Engineering|2023-06-27 18:06:51|Dealroom estimates $200M for OpenAI in 2023 and $1B in 2024. Source not available.  https://twitter.com/dealroomco/status/1672189846373138432?t=qBgCuvmGjyLS-ClkX0I8Hg&s=19
Rajesh RS Generative AI WhatsApp Group|2023-06-27 18:08:10|They've taken an integration approach. Generative AI for powerpoint, word, stuff like that.
Shalabh Aspiro|2023-06-27 18:12:51|"""Now Demis Hassabis, DeepMind’s cofounder and CEO, says his engineers are using techniques from AlphaGo to make an AI system dubbed Gemini that will be more capable than that behind OpenAI’s ChatGPT."" Looks like they are experimenting to improve RLHF as they are vastly experienced on RL..  https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/"
Abhinav Verma Longshot.ai|2023-06-27 18:14:03|Oh look, someone who was signing a petition to not do any agi development for 6 months is not keeping his word😂😂😂 ‎<This message was edited>
Shalabh Aspiro|2023-06-27 18:16:34|typical hype adoption cycle 🫡
Anil Chandra Naidu Matcha|2023-06-27 18:31:52|How is langchain plus different from langchain
Nirant|2023-06-27 18:46:05|If you add CSS to something, it's called Plus If you add SSO to something, it's called Pro If you add both, it's called Enterprise Ready  🤣 ‎[6/27/23, 19:00:38] Nirant: ‎image omitted
ashish Acgt01 Twitter|2023-06-27 19:24:51|interesting eval work from graham neubig of cmu https://github.com/zeno-ml/zeno-build
Nitin Wyse|2023-06-27 19:30:52|‎You removed Nitin Wyse
Shashwat TDC|2023-06-27 19:39:26|Come to think of it, even chatgpt doesn't have RBAC, team management, reporting
Nirant|2023-06-27 19:40:46|There are lot of errors which are forgiven if you build something exceptional 🙏  It's profitable for most folks to assume that they're not Ilya or Greg or Sam Altman, then to assume that they're
Nirant|2023-06-27 19:41:47|Folks, we've confirmed multiple spam reports from Wyse founders and teammates. We do not tolerate spam.  I've removed everyone I could find right now, from both the community and WhatsApp group. We've also reported the number to WhatsApp.  Sincerest apologies for the inconvenience, trying our best 🙏  - Nirant, on behalf of the GenerativeAI Community
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-27 19:44:15|talk about pre-pmf distribution :P
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-27 19:45:19|novel idea though?
Abhinav Verma Longshot.ai|2023-06-27 19:45:21|shh, that's for others to implement
Jay Pokarna 2014 BPCC|2023-06-27 19:45:55|Nirant is the moderator we need, but don't deserve :P
~ anuja grazzel|2023-06-27 19:46:01|Hello Everyone, I am actively looking for communities or teams who are building something really impactful for society. I want to be part of such a team, let me know if anyone is looking for backend developer for their team.  About Me:- i am Anuja and I am proficient in python and have worked with golang microservices. I am one year experienced and i am just keen to learn, not getting paid is okay for me. DM me if anyone is looking a really motivated team member.
Shashwat TDC|2023-06-27 19:48:48|For SM companies, critical distribution is the PMF 😀
Nirant|2023-06-27 19:48:48|You might want to check this, has open jobs and upcoming events (which are often sponsored by companies looking to hire):  https://nirantk.com/community
Nirant|2023-06-27 19:52:44|You might find ragas: https://github.com/explodinggradients/ragas from Jithin and friends [PHONE] interesting
~ vignesh iyer✌️|2023-06-27 19:58:02|this is gold 😂🔥
Pratyush Choudhury|2023-06-27 20:01:50|Have a perspective on this actually, thinking how best to share it  A lot b2b SaaS from that time frame was aimed at selling Bottoms-up or PLG  Usually, that starts with a land in smaller companies and then growing into org wide adoption  Enterprise grade features were required at a much later stage  In fact, there's SaaS for enabling SaaS companies to be enterprise ready  Gen AI sort of flips the model - for the first time, it seems like enterprises are adopting a technology wave much faster
Alok Bishoyi|2023-06-27 20:03:52|It's one of those tech which customers are demanding ( and expecting ) and hence, orgs are looking for a solution. It's very much a Pull than a push for this sort of solutions.
Pratyush Choudhury|2023-06-27 20:04:33|Absolutely, pre-product PMF 🫣
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:06:02|What types of SaaS gets you enterprise ready? Specifically, any good resources on enabling SSO/SAML?
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:06:50|Also, there's a question of liability that's often coming up. Given how non deterministic the outputs are. If anyone has a perspective on how enterprises are tackling this with vendors, that would be great
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:07:40|For example, if there's an erroneous response or action given by the AI, is there any liability on the vendor? And, to what degree
Pratyush Choudhury|2023-06-27 20:08:10|https://workos.com  Have you checked them out? Solid developer Experience
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:08:31|Nope. But saw them on a few Google ads. Thanks. Will do
Pratyush Choudhury|2023-06-27 20:09:29|And there are different dimensions of getting enterprise ready - deploying your SaaS in the customer's VPC is a big requirement that comes up  This is typically done by separating control plane and data plane  Replicated is a solid Product here
Manas Jain Wadhwani AI|2023-06-27 20:11:04|‎You added Manas Jain Wadhwani AI
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:11:12|Interesting. Will check them out. This is going to be even more relevant now. Given lots of folks are paranoid about data leakage to external models
Pratyush Choudhury|2023-06-27 20:12:44|There's one more product that allows enterprises to interface their data with LLMs in a Privacy preserved manner  This is another vector of becoming enterprise ready when it comes to LLMs  Happy to share more deets about it 1:1 for those who are interested
Shubham Gupta IIT K|2023-06-27 20:14:36|To PCs point - I had chat with head of AI for a top 3 services company in India. He mentioned the same thing. The pace of AI adoption among enterprises is truly surprising to them. They are expecting 6m to 12m windows for org wide deployment which in the enterprise world is very short. Also service companies are going to make a lot of money helping enterprises in building internal LLMs 💲💲
Shubham Arora|2023-06-27 20:23:34|Get connected to FOSSUnited. They have a FOSS for Good mandate. Lovely opportunity for Devs looking to contribute to society in real ways.   Needless to say, guidance from Kailash Nadh is a propellant.
Pratyush Choudhury|2023-06-27 20:24:06|Got quite a few pings 1:1 from folks post this and hence sharing it here for everyone in case it helps a broader audience   From my vantage point (which might be limited and/or a sampling bias), there aren't many companies that have found PMF following a Bottoms-up/PLG strategy in the last few years  Where it's worked out well is where the product is core infrastructure that is usually sold as an OSS layer  Some people put it on the macro with tightening budgets et al  My sense is that it's more about the channel - akin to something like your home screen on your mobile. There's only so much space for so many apps there.  Happy to learn from others 🙏🏼
Nirant|2023-06-27 20:25:56|FOSSUnited has an active job board too https://fossunited.org/jobs
Bharat Kumar Ramesh Hashmal Web3|2023-06-27 20:27:28|Amazing. Is there a good playbook you've seen to sell to enterprises? Specifically, how do you get that first client  I assume one of the reasons bottom up worked well is a land and expand route seems to be the natural way  Plus, your product is also more mature when it comes to POCs  But how do you bag that first enterprise client seems to be quite daunting
Kunal Bhatia Hexo|2023-06-27 20:28:27|Adding to this conversation,  We met a bunch of CXOs across enterprises in EU last week.  The biggest standout point for us was that they don't trust Microsoft with their data when it comes to AI. While they are enthusiastic about the possibilities of having an 'internal ChatGPT', they would want it to be deployed on premise.  My co-founder Vignesh shared some of the insights we got interacting with these CXOs:  https://www.linkedin.com/posts/vigneshbaskaran0123_last-week-i-co-moderated-a-session-with-activity-7078680450033979392-W4vp? ‎<This message was edited>
Pratiksha Dake Unacademy|2023-06-27 20:29:06|Any reason why they don't trust Microsoft?
Kunal Bhatia Hexo|2023-06-27 20:31:01|Seems to be a perception issue around MS leveraging client's  data to train their models which can be used by competition as well
Pratyush Choudhury|2023-06-27 20:33:41|Wow, will be very, very surprised if this is the case 😳  Understandable if it's an EU thing/preference
Alok Bishoyi|2023-06-27 20:33:58|+1  Experience has been opposite
Alok Bishoyi|2023-06-27 20:36:48|Have some US / East asia F500 clients and folks were eager to experiment.   Infact, there was inbound request to explore generative features.
Kunal Bhatia Hexo|2023-06-27 20:39:21|Eager to experiment with MS AI features or GenAI in general?
~ Pramod|2023-06-27 20:42:04|‎You added ~ Pramod
Alok Bishoyi|2023-06-27 20:42:36|Some were already using Azure AI.   Wanted us to even add generative features to our pane since they saw the benefits through their other experiments.  One learning I personally had was : there is still lack of clarity as to how they can actually use generative features. Customer is still not clear about what gen AI can and cannot do. So super high expectations sometimes.
Haridas Pai Ai Air2 Founder|2023-06-27 20:43:49|That’s so true. To take it to enterprise grade, an entire architectural composition is required. Consumption patterns, stakeholders interests, auth controls, re-bac, Multi-tenancy, delivery models, the triad of security , day-2 ops, DR, BC and what not. No sane enterprise is going to let another one (say msft) consume all their data and end up in a transitive relationship with their competitors.
Pratyush Choudhury|2023-06-27 20:44:05|I actually have a hot take here 🙊  Haven't given it much thought but sharing it colloquially with the community  The reason could be because Microsoft and OpenAI have trained their current models on copy righted data  Companies in EU might just not like the idea of using the outputs of something like thay
Brij Singh Rebright Partners|2023-06-27 20:49:50|Guys, I'm planning a Responsible AI Fellowship Fund that will give grants of $5K-$75K to individuals and projects building Open Source Software that address the both Ethical and Societal issues in AI, and / or those building the base tools / frameworks / models / research that others can use.   Currently, we have strong interest from Omidyar Network and Meta's AI Public Policy team to anchor this, hopefully we can close this in the coming weeks and announce in July / Aug.  If anyone comes across teams / individuals working in this area, please refer them to me directly and we would be happy to consider.
Abhishek Mishra|2023-06-27 20:50:55|In most companies, MS already owns their corporate ecosystem with office 365, GitHub, Azure. Almost everything that's business critical is often present in internal SharePoints and enterprise repos. I can understand how some companies that aren't using this ecosystem may deliberate over this choice. But any company that already uses MS services and products may just sign NDAs and join the gen AI products and services as well.
Abhishek Mishra|2023-06-27 20:51:10|*many not most
Shubham Arora|2023-06-27 20:51:44|Unpopular personal opinion: Enterprises (anyone with serious scale and proprietary customer/noncustomer data wanting to protect moat) in the long run, will gravitate to using LLMs on Sagemaker/AzureML/VertexAI.  First principles: At large scale, the only things that matter are: best performance, lowest cost at lowest latency.  Nothing can beat CSPs on either of the 3 at scale, given how open source models have flooded the mkt. Enterprise capabilities are a given with at least 2 of the big 3 CSPs. Also, relationships are already forged and quite strategically positioned.
Pratyush Choudhury|2023-06-27 20:55:06|"I'd extend it to 6 - adding Databricks, Salesforce and Snowflake there  But there's also another interesting (hot) take where there's ongoing debate in closed groups  The question is ""Is there something really proprietary in general purpose industry data? And what happens if one of them partners with a vendor to train their general purpose LLM?""  Say the largest petroleum or Commercial Real Estate law firm enters into a data sharing partnership with OpenAI - what does that mean?"
ashish Acgt01 Twitter|2023-06-27 20:56:10|this is a super neat demo !  https://twitter.com/joshm/status/1673689963303514114  longer video : https://www.youtube.com/watch?v=5p8UGSyT7a8  web dev folks might get a kick out of it !
Nilesh Transcend|2023-06-27 20:58:12|👏  Some potential research areas: - Steerability - Data privacy / data sovereignty - Explainability - AI to supervise other AIs (constitutional AI)
Haridas Pai Ai Air2 Founder|2023-06-27 21:21:39|"its just half the truth with regard to ""enterprise"" capabilities of big 6. The ""shared responsibility"" term scares a lot of business, especially large ones. While it could be tactical TTM pressures that drive most of them to CSPs, objective evaluation later puts them back to on-prem and colos. The paranoia in some cases went to such levels that we saw a potential in building segmentation at the lowest level ( link layer -eg.  GWLB svcs from all the CSPs and L2-NV from OCI). May be you are right for the SME, mid-mkt players that their core functions are cSP driven. But the large ones are still super paranoid about their infra & data. The levers of data propagation into sharepoints/githubs/boxes are well  established, controlled and monitored to mitigate DL mishaps."
Abhishek Mishra|2023-06-27 21:21:59|I'll try it out. Maybe it'll help blur LinkedIn cringe posts in my feed. ‎<This message was edited>
Kunal Bhatia Hexo|2023-06-27 21:29:16|Didn't see it coming that 'Inspect Element' will get productized
~ Varun Kumar|2023-06-27 21:36:08|‎~ Varun Kumar requested to join
Nirant|2023-06-27 21:48:05|"Creator of PaLM-2, UL2, Flan, Bard has announced a new $58M seed funded AI Lab called ""Reka"" reka.ai  https://twitter.com/YiTayML/status/1673722977882611712 ‎<This message was edited>"
Dhruv Anand|2023-06-27 21:48:26|extremely apt productization though
Shivendu Kumar|2023-06-27 21:50:19|Wow. 58M$ for seed round. Is this the biggest one in history? 😂
Nirant|2023-06-27 21:51:01|Nahi, Mistral had $150M no? Or $113M or something like that
Shivendu Kumar|2023-06-27 21:52:41|Ahh yes. 113M $
Nirant|2023-06-27 21:52:56|Not large enough rounds tbh. Anything less than $500M, hard to build the companies these folks are trying to build.   I'd expect many of these to fold or raise more in next 24 months
~ Santhosh K|2023-06-27 22:02:54|Has anyone tried inference on Falcon model by loading it in 8 bit ?  It just generates only token 0 for me.
Nishant Wyse|2023-06-27 22:50:57|‎You removed Nishant Wyse
Lohith GenerativeAI WhatsApp Group|2023-06-27 23:07:06|‎You added Lohith GenerativeAI WhatsApp Group
~ Abhiram Ravikumar|2023-06-28 00:39:45|https://www.linkedin.com/posts/clementdelangue_this-is-my-5-minute-testimony-before-the-activity-7079114622133264384-Ml3K?utm_source=share&utm_medium=member_android  What do y'all think of hugging face ceo's testimony?
Abhinav Verma Longshot.ai|2023-06-28 00:41:16|I've only heard his piece and not the questions he was asked.  I think this is something for the philosophy group
~ Abhiram Ravikumar|2023-06-28 00:42:00|I'll move it there, thanks.
Nihit Desai Refuel.ai|2023-06-28 00:43:27|‎You added Nihit Desai Refuel.ai
~ mihir_parulekar|2023-06-28 02:39:41|Hey guys so is it a accepted fact that ada-002 works better than any other opanai embedding for code as well. Mostly for similarity detection? Thanks
Shivendu Kumar|2023-06-28 03:14:35|Don't have any benchmarks but that's what they recommend.   There's even an example for code search in their docs where they used ```text-embedding-ada-002``` https://platform.openai.com/docs/guides/embeddings/use-cases
Dr. Pratik Desai KissanGPT|2023-06-28 03:32:00|I agree. My experience has been different compared to what was discussed here, while building enterprise version of our application for Agri MNCs. There are concerns about data but there many use cases just to build on top their public data. Many already uses Azure, and using Azure OpenAI instead of OpenAI already addressed few concerns.
Brij Singh Rebright Partners|2023-06-28 04:37:47|Thanks for the suggestions Nilesh, will add them to the list of topics at our launch hackathon.
ashish Acgt01 Twitter|2023-06-28 05:33:21|TIL about MLPerf[0] and MLCommons[1]  https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/  0. https://arxiv.org/abs/1910.01500 1. https://mlcommons.org/en/training-normal-30/ https://mlcommons.org/en/inference-tiny-11/  I think we will see a rise of tiny models especially embedded in hardware(on device inference without internet)
~ Arindam Barman|2023-06-28 08:46:51|Anyone here has insights on what ChatGPT for business will look like?
Lalit Pagaria|2023-06-28 08:51:21|Apart from these few, more are based on industry and customers - Certifications like SoC2, ISMS, PCI DSS, etc - Data isolation: creating separate infra adds to the unit cost and if customers are not ready to pay it then how intelligently do you design arch to provide separation - SLAs/SLOs (based on availability, service, latency, data sync period, MTTR, or some other KPIs) - Disaster recovery - Security compliances - customizations capabilities like on UI (themes, logo, dashboard, etc) or infra like data sync period - data processing agreement like not using data for training etc  There is an endless list so it all depends on who your customers are and need to gauge if they need it.  These points are all based on my research as an ex-founder so please take them with a pinch of salt.  And I stop before being kicked out of this group as it is off-topic. 😅
Lalit Pagaria|2023-06-28 09:19:45|12K+ ChatGPT credentials from India are on darkweb  https://tryhackme.com/r/resources/blog/month-in-cyber-june-2023
~ Maruti Agarwal|2023-06-28 09:33:39|‎You added ~ Maruti Agarwal
Rishabh Refuel.ai|2023-06-28 09:38:22|‎You added Rishabh Refuel.ai
Nirant|2023-06-28 10:10:31|For folks looking for speaking opportunities, FifthEl is India's best ML/Deep Learning conference, Aug 11 this time:   Sumod Mohan [PHONE] from the group is curating the speakers for the conference.  Confirmed speakers include Saurabh [PHONE] from Jugalbandi, Arjun (also in this group)  Proposal Submission Deadline is 30th June I think  Link: https://hasgeek.com/fifthelephant/2023/  PS: I'm not affiliated with FifthElephant 2023, HasGeek is the co-organiser for all meetups we've done as a community since Feb
Nirant|2023-06-28 10:11:11|cc [PHONE] [PHONE] [PHONE] thought you might want to speak here
Sumod K Mohan|2023-06-28 10:13:34|[PHONE] is talking about LlamaIndex. And hopefully convert you all to LlamaIndex users ;).
Anubhav Dubdub.Ai|2023-06-28 10:14:41|Hey guys, what's the best open-source language agnostic model for speaker diarization? We have already tried a few but love to know any good recommendations. Audio Video types would be long (1-2 hours) and short form (10-15 secs).
Nirant|2023-06-28 10:20:28|Whisper.cpp is adding diarization in next 2-3 months
~ Shirsha|2023-06-28 10:37:47|Hi have any of you come across a project which covers an agent for iOS commands, enabled by llms?
Rounak Datta Hackathon Winner|2023-06-28 11:05:40|I doubt Apple would allow external automation on their platform, tools like Tasker have never existed for iOS
Dev Aggarwal|2023-06-28 11:06:45|Apple has a native automation tool for both ios and macos ‎[6/28/23, 11:07:31] Dev Aggarwal: ‎image omitted ‎[6/28/23, 11:07:58] Dev Aggarwal: ‎image omitted
Rounak Datta Hackathon Winner|2023-06-28 11:09:21|Haaa, really ... damn. But can it do stuff like intercept calls, notifications et al?
Dev Aggarwal|2023-06-28 11:11:00|Probably not, apple is too pedantic about notifications
Ambika Computational Mama|2023-06-28 11:25:39|Nice one [PHONE]
Saurav Tomar GenerativeAI WA Group|2023-06-28 11:29:26|You can even use chatGPT like Siri using apple shortcuts https://twitter.com/mckaywrigley/status/1640414764852711425
Anubhav Dubdub.Ai|2023-06-28 11:35:32|We don't have 2-3 months 🥲, need something for now. We can train it with some data.
Dev Aggarwal|2023-06-28 11:45:06|This and function calling ❤️
Anirudth N|2023-06-28 11:51:12|I think the diagram in this article has a typo. They advertise mask R-CNN training in under 1.5 minutes. That doesn't seem right. If it was the correct number, I wonder how they optimized I/O.
~ RISHAV|2023-06-28 11:52:43|Has anyone implemented Microsoft guidance? I want to generate a perfect list of JSON responses. gpt-3.5-turbo is failing to do it many times. Is Microsoft Guidance able to do it properly, or is there any other library to get control of the output?  https://github.com/microsoft/guidance
Sandeep Srinivasa RedCarpetup|2023-06-28 11:55:49|Are u using the new model 0613 version of 3.5 ? The json formatting should work
Harveen Singh Chaddha|2023-06-28 12:04:02|Check this if not done already  https://github.com/pyannote/pyannote-audio
~ RISHAV|2023-06-28 12:13:41|I am using gpt-3.5-turbo-0613
Nirant|2023-06-28 12:14:33|Just wrap with Guardrails? https://github.com/ShreyaR/guardrails/
~ RISHAV|2023-06-28 12:14:42|Also, I am controlling the output using prompt, not using any external package yet.
Nirant|2023-06-28 12:15:21|In this case, give OpenAI Functions a chance
~ RISHAV|2023-06-28 12:15:31|ok will implement.
Nirant|2023-06-28 12:17:35|If you've a JSONSchema or Pydantic object which you're reading into, might find the OpenAISchema integration from Langchain interesting, or a lighter version which [PHONE] uses as well:   https://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb
Abhishek Mishra|2023-06-28 12:18:36|Meta released a paper on the recent method to increase context length using position interpolation. *The 2k context LLMs are now shown to be well functioning in various tasks like retrieval, modelling, long form summarisation with just fine tuning. A pretraining from scratch wasn't needed to increase context length to 8k, just fine tuning was enough (even LoRA).*  This method is the same as what got popular by a GitHub user named kaiokendev.  Paper - https://arxiv.org/abs/2306.15595 Independent Blog post by kaiokendev - https://kaiokendev.github.io/context
Anubhav Dubdub.Ai|2023-06-28 12:18:39|Tried this
Saurabh Karn Nyai|2023-06-28 12:19:39|Or if you are feeling brave and experimental try this one: https://tinyurl.com/5n8rpu23  It structures the text data into a scheme.
Abhinav Verma Longshot.ai|2023-06-28 12:21:02|I endorse this.
Nirant|2023-06-28 12:21:16|kor uses ReAsk while the lib I wrote use OpenAI functions, so in latency and cost terms — this can be a difference of about 3-10x
Nirant|2023-06-28 12:22:32|Ramsri [PHONE] I recall you had worked a bit on diarization and alignment challenges, do you know what could help Anubhav at Dubdub?
Saurabh Karn Nyai|2023-06-28 12:27:31|I would use ReAsk sort of framework to do more document preprocessing and storing kind of tasks. For example making the implicit structure explicit in legal Acts documents. So even if one uses the most expensive model since it’s write once read many times sort of a situation it tends to spread the cost overall.   But I agree, it’s very much dependent on what someone is trying to achieve.
Saurabh Karn Nyai|2023-06-28 12:28:13|Of course there are nuances I have skipped here but some internal work is happening on this.
Anubhav Dubdub.Ai|2023-06-28 12:29:23|We have tried, and the results are not great, and each has its own challenges.  - Resemblyzer - coqui - pyannote - TitaNet (NeMo)
Soumendra Dhanee|2023-06-28 12:37:54|Analog Diffusion (iphone)
Nilesh Transcend|2023-06-28 12:39:03|Open-source LLM-based theorem prover: https://leandojo.org/
~ Aakanksha Mudgal|2023-06-28 13:00:54|‎You added ~ Aakanksha Mudgal
~ Tanmaay Khurana|2023-06-28 13:00:58|‎You added ~ Tanmaay Khurana
Aditya Sista 2010B5|2023-06-28 13:11:07|Hi all, can anyone point me to or give tips on how to compress or paginate large code snippets so as to not exceed token limits? What's the current best known way to go about this?
Nirant|2023-06-28 13:13:04|aider.chat/docs/ctags.html
Sandeep Srinivasa RedCarpetup|2023-06-28 13:35:23|this is a very very smart usage of ctags. ctags-as-a-vector-db.  pretty cool!
Nirant|2023-06-28 13:37:41|I am low key sad that I didn't think of this
Shubham Arora|2023-06-28 13:38:44|Has someone experimented with any models to generate TV ad quality video content?
Nirant|2023-06-28 13:39:47|cc Shubham [PHONE] from TVF might know more about this
Shubham Sharma 2012C6|2023-06-28 13:42:10|Would love to collaborate on this
Dr. Pratik Desai KissanGPT|2023-06-28 13:42:49|Doing a lot of things at LangFlix but it’s not just one model, but a pipeline of multiple models.
Nirant|2023-06-28 13:43:50|What is LangFlix?
Dr. Pratik Desai KissanGPT|2023-06-28 13:44:11|Side project https://youtube.com/@LangflixAI
Dr. Pratik Desai KissanGPT|2023-06-28 13:45:34|Bringing books summaries in Indian languages, complete AI pipeline
Nirant|2023-06-28 13:46:43|Terrible name, great idea!
Dr. Pratik Desai KissanGPT|2023-06-28 13:47:20|I’m becoming rebranding expert
Abhinav Verma Longshot.ai|2023-06-28 13:47:39|Nirant got Langchain Trauma seeing the name.😂😂
Nirant|2023-06-28 13:47:41|Say more, what did I miss?
Abhinav Verma Longshot.ai|2023-06-28 13:48:10|I've seen these AI 30 min hypothetical interviews on Spotify
Nirant|2023-06-28 13:48:13|Aee, I just got my first PR merged yesterday: https://github.com/hwchase17/langchainjs/pull/1771  (thanks to [PHONE] [PHONE] for the review)
Abhinav Verma Longshot.ai|2023-06-28 13:48:48|"I was referring to the Readme on aiagent. ""Unchained"""
Rajesh RS Generative AI WhatsApp Group|2023-06-28 13:50:51|Langchain trauma - working on langchain after the era of crypto?
Shivendu Kumar|2023-06-28 13:51:22|Is it automated end-to-end? What exactly do you still have to do manually?
Dev Aggarwal|2023-06-28 13:51:37|Some folks use gooey every now and then to create a music video / short explainers - not tv quality though - just passable  https://www.instagram.com/reel/Cns6Wubua81/?igshid=MTI1ZDU5ODQ3Yw==
Dr. Pratik Desai KissanGPT|2023-06-28 13:51:38|Enter book name
Dr. Pratik Desai KissanGPT|2023-06-28 13:53:46|I think they added MusicML for background music too recently. I started the project and handed over to friends as I am focusing on KissanAI
Dr. Pratik Desai KissanGPT|2023-06-28 13:57:47|Also everything is done on 3090s, almost no cost.
~ vignesh iyer✌️|2023-06-28 13:58:00|wow.. will check it out.. i had similar idea for niche regional books.. but haven't started any work on it yet
Dr. Pratik Desai KissanGPT|2023-06-28 13:58:24|Send suggestions in DMs
Abhishek Mishra|2023-06-28 14:08:54|This is one of few unique ideas for source code handling, especially with LLMs.   I've implemented a symbolic/hard link relationship between SW changes and test case definitions in BIOS. SW changes include any feature, requirement or bug fix. It allows us to perform code coverage, test case recommendation and impact analysis for every PR easily.  Ctags allow name indexing in files but don't have linking information between files to index. But it's still very clean and one of the better ways to do it. I see myself taking a page out of this book for languages other than C/C++
Paras Chopra Wingify|2023-06-28 14:09:07|Copyright issues?
Dr. Pratik Desai KissanGPT|2023-06-28 14:10:07|Summaries, images, everything is AI generated
Nirant|2023-06-28 14:10:12|How'd you extend this for Python/Java/JS?
Saurav Tomar GenerativeAI WA Group|2023-06-28 14:14:41|I use this and am able to generate perfect json response every time. works great.
Abhishek Mishra|2023-06-28 14:15:11|There's already a general map of repo with aider using ctags. I'll extend it to include symbolic links with the help of namespace and import commands, but I'll have to explore it in detail.  I may stub my toe in many ways doing that.
Aditya Sista 2010B5|2023-06-28 14:16:18|Not many tools that work for us gpt-3.5 peasants 😅 , gpt 4 is just way better.
Nirant|2023-06-28 14:16:23|To set fair expectations, there is a failure rate of about 7 in 1000 right now.
Saurav Tomar GenerativeAI WA Group|2023-06-28 14:17:08|Interesting, how did you measure that ?
Nirant|2023-06-28 14:17:41|Hand wrote test cases like a peasant and then called OpenAI Functions about 5K times
Nirant|2023-06-28 14:18:05|Trying to ~measure~ estimate hallucination rate next ‎<This message was edited>
Abhishek Mishra|2023-06-28 14:22:08|That's some grind 😂 👍 for a valuable statistic. ‎<This message was edited>
Meghana Jagadeesh|2023-06-28 14:24:19|GoCodeo AI helps automate the testing process 😁
Meghana Jagadeesh|2023-06-28 14:25:04|Hallucinations are also taken care of
Nirant|2023-06-28 14:29:00|I am very skeptic that AI solutions can do better than Code Interpreter, given how far behind even WizardCoder is.   And I don't want to add the meta-work of verifying the test cases to verify the libs Hallucination, Error and Failure rate.
Shubham Sharma 2012C6|2023-06-28 14:31:42|Fully AI Generated Podcast bringing the guests that will never get the chance to go on the real Joe Rogan Experience
Shubham Sharma 2012C6|2023-06-28 14:31:42|https://t.co/pNqa1JMZMt
Shubham Sharma 2012C6|2023-06-28 14:32:16|There’s a lot of content being made lile joe rogan ai experience that [PHONE] made me aware of. I was living under the rock
Meghana Jagadeesh|2023-06-28 14:35:27|The base layer of GoCodeo is GPT and the in-house algorithms on top of it ensure code context and intelligence. Which means reduced errors and failure. Also, when you say Code Interpreter, is it on the test generation or the analysis use case?
Dr. Pratik Desai KissanGPT|2023-06-28 14:36:00|I interested in knowing how we can use AI to identify AI hallucinations
Abhishek Mishra|2023-06-28 14:37:12|A separate instance of LLM can segment the generated result and fact check it with the database.
Nirant|2023-06-28 14:37:21|Code Interpreter is amazing at code generation including test writing. It often generates test cases which I have missed when I ask it to use fuzz testing in particular.   Would love to know what safeguards/guarantees can the solution give against hallucinations (checked on website, didn't find anything)
Dr. Pratik Desai KissanGPT|2023-06-28 14:38:33|So fact checking is still based on human curated db
Abhishek Mishra|2023-06-28 14:40:09|Yeah there has to be some grounding. But to some extent we can avoid manual labour of fact checking at least.
Rounak Datta Hackathon Winner|2023-06-28 14:43:00|"There is a new ""Pair Programmer"" feature on Phind.com, I found it pretty powerful! Do try it out. It is the best implementation of chain-of-thought / step-by-step thinking I found in a coding agent.  Don't have access to CodeInterpreter, but found it to be much much more powerful than GPT-4+Bing ..."
Dr. Pratik Desai KissanGPT|2023-06-28 14:44:09|😞 I thought I missed out on a breakthrough. No Ouroboros, yet. We got a long way to go.
Meghana Jagadeesh|2023-06-28 14:44:14|Hallucinations until now have been identified by our enterprise partners and with those learnings we are building AI models for rectification and further identification.
Abhishek Mishra|2023-06-28 14:46:40|Interesting name for fine tuning a model optimised for fact checking. Instead of RAG, fine tune an LLM for fact checking given a generated answer and retrieved context   Considering the level of papers circulating nowadays, this can be a very good paper 🤣
Nirant|2023-06-28 14:47:25|EMNLP for Industry track is still open 🤣
Dr. Pratik Desai KissanGPT|2023-06-28 14:47:28|[PHONE] see I’m not that bad at naming. 🤣
Bharat Kumar Ramesh Hashmal Web3|2023-06-28 14:47:43|Is it integrated into vscode?
Bharat Kumar Ramesh Hashmal Web3|2023-06-28 14:48:14|My biggest pain is switching from here to the browser and copying it back, then modifying it
Bharat Kumar Ramesh Hashmal Web3|2023-06-28 14:48:27|Or copying the error stack over and asking for an explanation
Rounak Datta Hackathon Winner|2023-06-28 14:48:59|True that Phind's not into any IDEs, but the web interface gets the work really well done ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-06-28 14:49:07|many such cases 😜
Abhishek Maiti|2023-06-28 14:52:14|Did quite a few experiments which ended up going in production, with multiple models in a single flow though.
Neeraj Kumar|2023-06-28 15:15:18|Is there a good guide on creating QnA bot on Notion knowledge base using Langchain? I created the most basic one but it is not giving statisfactory answers.
Kshitij Agrawal ML Engineer|2023-06-28 15:31:27|"""Pyannote had the best open source performance.""  This from my colleague who was building diarization internally at Swiggy."
Kshitij Agrawal ML Engineer|2023-06-28 15:34:04|Have been playing out recently with pdfs. Basic RetrievalQA works decent. Rest is all chunking and routing logic that you can build on top.
Neeraj Kumar|2023-06-28 15:37:13|Thbks. How do I learn chunking and routing logic thing? Both fundamentals and application! :)
Kshitij Agrawal ML Engineer|2023-06-28 15:40:13|Routing logic has some introduction in llamaindex docs. But mostly diving into code.  Chunking has a lot of research literature around it. Maybe folks from the community can point to some good resources they have come across for these.
Neeraj Kumar|2023-06-28 15:50:41|Thanks. Will start with chunking.
Kishore GenAI|2023-06-28 16:01:10|My understanding is that this would take quite sometime to get to TV ad quality for videos. Given the state of image generation and the number of times it fails to match expectations, it is difficult for me to expect video generation to be TV quality.   Would love to know if you found anything workable in this space.
Kishore GenAI|2023-06-28 16:03:38|Crucially the GenAI models for images are great for exploration, but if you already know what you want and are trying to get that image done quicker, then there are still issues.
Kunal Bhatia Hexo|2023-06-28 16:04:13|I guess specific parts of the ad can be generated. Most of the magic will still have to be done by a video editor though. Even with the coke ad (although publicised as Generative AI), most was traditional CGI and good editing
Kishore GenAI|2023-06-28 16:06:15|You can make zoom in and zoom out reels. They can work with out painting and then adding them to video editor, but temporal consistency between scenes are not yet solved to my knowledge.
~ Bhagyesh|2023-06-28 16:47:15|‎You added ~ Bhagyesh
Prayank Swaroop Accel|2023-06-28 17:37:35|‎POLL: Folks I'm trying to get international speakers for AI .. but are you willing to attend online meetings at 9.30pm IST on Thursdays ? Please DM me if you have a different solution. ‎OPTION: Yes (74 votes) ‎OPTION: No (0 votes)
C Chaitanya Nutanc|2023-06-28 17:44:08|How long does it take to generate a video?
Ankur Pandey|2023-06-28 18:25:24|We have been doing aspects of fact checking (Grammarly style check worthy claim detection, generation using existing sources, FactCheck wrt existing sources, etc).  Found that simple techniques works better and also explainable to clients.  Most imp question we're asked is reliability of the sources (to verify against). There's no neat answer here but things like DA/DR, nutrition labels from some independent media orgs is a good proxy
Abhishek Mishra|2023-06-28 18:42:13|Reliability of source will lead you down the same road as Google - Experience, Expertise, Authority, Trustworthiness to build up reliability of a source. Platforms or sources with reputation get maximum brownie points, reputation again is an associative entity (EEAT as mentioned above).  What do you mean by DA/DR? Are these data related acronyms?
Abhishek Mishra|2023-06-28 18:44:01|My answer was also more on the side of *given that we can trust the database from where retrieval is happening, how to fact check the generated output using an AI?*  I'm also of the mind that simple fact checking algorithms may work very well for the bulk of the time.
Ankur Pandey|2023-06-28 18:46:27|DA = Domain Authority. DR = Domain Rating. Introduced by SEO folks. Ahrefs, Moz, etc  That's why I mentioned non SEO ratings, for example media auditors (NewsGuard, IFCN (international fact check network) can be important)
~ Arko Cy|2023-06-28 18:49:38|https://youtu.be/Wc22W3bos64  Could someone help break down the mechanics behind how this package was generated.
Abhishek Mishra|2023-06-28 18:54:00|Generate individual characters from midjourney -> convert them in video form by just animating faces for voice over using D-ID - > text to speech via elevenlabs  This info is slightly outdated (apr), you may have better methods now
~ Arko Cy|2023-06-28 18:55:18|but what about the sound signatures ?
Abhishek Mishra|2023-06-28 18:56:05|You mean the accents from different languages or something else?
~ Arko Cy|2023-06-28 18:56:17|Yes, exactly
~ Arko Cy|2023-06-28 18:56:28|Accents
Kartik Mandaville|2023-06-28 18:57:11|have you seen anything which works well for csv/tables/sheets/xls? Embedding breaks the file in chunks for context size(16K) and then information is lost for queries which need something across many rows (ie different chunks)
Abhinav Verma Longshot.ai|2023-06-28 18:58:06|It's where claim detection comes in. You select passages / sentences which are then sent for fact checking
Abhishek Mishra|2023-06-28 18:58:10|There isn't a TTS model trained for latin, mayan, greco-roman accents. My trick to crack it would be to use phonetics.
Abhishek Mishra|2023-06-28 19:02:09|If you notice in the video, it's like 1 or 2 words are being pronounced separately rather than the complete sentence in a fluent manner. You can pick up a language close to the ancient versions and use phonetic spellings in that language to force a different sound with same accent
Ankur Pandey|2023-06-28 19:07:06|Part II has Sanskrit so yes this indeed is super convincing!! https://youtu.be/wC0UG-Oq_90?t=60
Abhishek Mishra|2023-06-28 19:18:20|If you move over to Old Chinese, you'll notice each sound being enunciated separately, looks like a clear use of phonetic pronounciation. Sanskrit one is very convincing.
~ Maruti Agarwal|2023-06-28 19:28:43|The way people are going about it is to generate multiple variations and handpick the nearby ones to show small motions or gif… but that’s about it
Rohan Manchanda|2023-06-28 19:40:04|Is there any literature / post about insurance policies (rise in their sale) to protect businesses against downside of bad stuff happening to them
Saurabh Karn Nyai|2023-06-28 19:46:32|Don’t know in Indian context but recently JP Morgan in UK context has been trying to make an insurance company pay for a multimillion dollar deal that did not go through.
~ Abhiram Ravikumar|2023-06-28 19:53:29|There was a use-case where ChatGPT was used to summarise research papers. Is it still around? could someone please point me to it, pls?
Abhishek Mishra|2023-06-28 19:55:20|Have you used SciSpace? It's very good. They have a chrome extension as well.  You can also find plugins on ChatGPT to fetch urls from arxiv and chat with it.
ashish Acgt01 Twitter|2023-06-28 19:59:49|https://twitter.com/soumithchintala/status/1674045982298841094?s=20
ashish Acgt01 Twitter|2023-06-28 20:00:33|i have used chatpdf.com works quite well.  there is also other tools like https://elicit.org/ https://www.explainpaper.com/
Kartik Mandaville|2023-06-28 20:01:45|shameless plug - https://pensieve.springworks.in/ - chat with any document (pdf, doc, csv etc)
~ Rahul Thota|2023-06-28 20:02:47|"Research papers have an ""Abstract"" section right? That's usually the summary of the paper. Any specific kind of summary you are looking for?"
Paras Chopra Wingify|2023-06-28 20:06:29|Consensus also
ashish Acgt01 Twitter|2023-06-28 20:11:07|looks pretty neat ! do you know what is the index cut off date ? do they continue to index new papers as they get published, every so often ?
ashish Acgt01 Twitter|2023-06-28 20:11:46|i am surprised i had never heard of it. just tried it on a local pdf, looks amazing !
Abhishek Mishra|2023-06-28 20:14:21|It was the most feature rich product for reading research papers even back in November. They had options to directly answer questions on tables as well as mathematical equations as well. But they aren't very good at promoting themselves 😅
Saurav Tomar GenerativeAI WA Group|2023-06-28 20:15:31|Is iMac with Apple M1 Chip ,8-Core CPU and 8-Core GPU good for playing around with locally hosted llms or should I go for more advanced build ?
~ Karan Gandhi|2023-06-28 20:28:58|Go for advanced
~ Karan Gandhi|2023-06-28 20:29:50|Go for an M1 Pro atleast In a mini or a macbook  Now there’s M2 Pro so you can buy M1 Pro off the refurbished lot too
Sandeep Srinivasa RedCarpetup|2023-06-28 20:32:45|it may be cheaper for you in the long run just to use vast.ai
Neeraj Kumar|2023-06-28 20:33:13|Basic question : How do we evaluate a software built using LLM? For a QnA bot from a knowledge base, how does one evaluate if it is good enough to release in the wild?
Rajesh RS Generative AI WhatsApp Group|2023-06-28 20:37:16|I'm keenly following answers to this question too.
~ Prajna Prayas|2023-06-28 20:53:30|For QnA bots I just ask my friends to try out demos and pray that it works 9 out of 10 times. The same cannot be said for apps built for finance or medical matters though. I am still figuring it out
Rajesh RS Generative AI WhatsApp Group|2023-06-28 20:55:50|Prompt engineering in my experience is way tougher than it looks at the outset
~ Shirsha|2023-06-28 21:00:57|I am actually looking for assets in this layer.. in fact I cannot imagine what an asset in this layer should look like. How can we design a module that can be configured to handle validation for gpt responses from a target set... Or a module that handles malicious qns...
~ Shirsha|2023-06-28 21:01:26|Or even a modular approach to designing that prompt layer that serves numerous use cases
Abhishek Mishra|2023-06-28 21:10:46|Yeah, i got really excited in Mar and bought M2 pro just a day after llama.cpp was released. Now it's not useful for anything other than some toy runs with GPT4all and privateGPT.  Just buy a good laptop and do all tutorials/inference/training on cheap GPU providers. ‎<This message was edited>
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:24:21|Old thinkpads suddenly become very valuable
Abhinav Verma Longshot.ai|2023-06-28 21:24:58|Not sure. Can't handle that red button as a mouse
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:26:45|Ah trackpoints. But any older laptop decent enough to code on + cloud based infra = viable dev environment. cheap and cheerful sometimes works well.
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:27:16|Having a Colab TPU instance or some cloud instance has changed the game
Abhinav Verma Longshot.ai|2023-06-28 21:27:38|This I agree. I'm still in my old 2015 Mac
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:28:41|Jeremy Howard (FastAI) once wrote about training a SOTA CNN model (several years ago) with $28 on AWS
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:28:58|Game changing value for small (and big) teams
Abhinav Verma Longshot.ai|2023-06-28 21:29:52|Ya those were trained without colab pro on free gpu in 5 minutes.   Simple times
Abhinav Verma Longshot.ai|2023-06-28 21:30:23|Finetuning not pretraining
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:30:51|Yes, the age of deep learning before LLMs... *clears cobwebs*
Rajesh RS Generative AI WhatsApp Group|2023-06-28 21:32:57|There was a Twitter subculture some time ago for GPU based PCs - it looked as though anyone working on DL stuff had to have this big fancy RGB laden powerhouse. We're reaching the *ahem* plateau of productivity...
Abhinav Verma Longshot.ai|2023-06-28 21:39:19|Ya. [PHONE] can shine light on this. He has a lot of useful experience here
Sanyam Bhutani|2023-06-28 21:40:20|I only have 12 GPUs. I don’t have a lot of compute compared to other Kagglers 🥺
Abhinav Verma Longshot.ai|2023-06-28 21:40:58|Some people on Twitter want to come after you. They think more than 10 should be made illegal 😂😂
Gokul Krishnan|2023-06-28 21:52:50|Me: <you have GPUs?>
Sanyam Bhutani|2023-06-28 21:53:35|For context: some Kagglers use 40+ GPUs freely everyday^
Sanyam Bhutani|2023-06-28 21:53:47|(Provided by their orgs) ‎[6/28/23, 21:54:41] Abhishek Mishra: ‎GIF omitted ‎[6/28/23, 21:55:25] Shubham Sharma 2012C6: ‎image omitted
Gokul Krishnan|2023-06-28 22:06:06|Eggjactly, too lazy to find the pic ‎[6/28/23, 22:23:30] Nirant: ‎GIF omitted
Nirant|2023-06-28 22:24:18|Please do not post on social media, early community preview (needs Github Sign in):  https://integrations.langchain.com/ ‎[6/28/23, 22:29:31] Abhinav Verma Longshot.ai: ‎GIF omitted
Ravi Theja|2023-06-28 22:30:57|this feels like a topper in clg saying I got 9.5/10 CGPA and still sad 😂
Abhinav Verma Longshot.ai|2023-06-28 22:32:05|Imagine if Kagglers who have 40 gpus only do xgboost.
Abhinav Verma Longshot.ai|2023-06-28 22:32:10|I say this as hypothetical only. I know we have some gun kagglers in this group
~ Gearskart|2023-06-28 22:41:12|Good area to explore.
~ Gearskart|2023-06-28 22:45:57|What happens if a question is asked over and over again.   If an ontology boundary is created and validated that the LLM doesn't cross this, that may decide if the question should be added to permissible set. Just a layman thought. 🐢
Aarish|2023-06-28 23:03:49|‎Aarish requested to join
Anubhav mishra Zupay|2023-06-28 23:19:59|https://twitter.com/siddarthpaim/status/1674108143037448200?s=20
~ Avinash|2023-06-28 23:34:58|‎~ Avinash was added
Rasika Soni WhatsApp Group Admin|2023-06-28 23:34:58|‎Rasika Soni WhatsApp Group Admin was added
Dev Aggarwal|2023-06-29 00:19:55|https://twitter.com/Suhail/status/1674124521543192578?s=20  Playground AI is now competing with photoshop - feels like the Microsoft word to google docs shift - less features but runs in the browser and is collaborative
Abhishek Mishra|2023-06-29 00:23:39|We can use SAM to identify objects and instruct to modify them via voice or text also. But maybe this makes for a cooler demo? It just feels like it'll be no effort to prepare my own images for almost any task now.
Dev Aggarwal|2023-06-29 00:25:56|Love this idea. Lets do this for a hackathon!
Ambika Computational Mama|2023-06-29 00:30:41|Here's another, and it has recs from the godfather of Shaders Patrizio. Who is also responsible for some key developments in runwayml
Ambika Computational Mama|2023-06-29 00:30:45|https://www.modyfi.com/
~ Suhas Baliga|2023-06-29 00:35:25|Q: we review legal documents using GPT 4. What is the best way to run a QC on the results outside of having people looking at it?
~ Rohan|2023-06-29 00:42:26|Pass the output to gpt 4 again to proofread / verify?
Abhinav Verma Longshot.ai|2023-06-29 00:43:22|GPT-4 can you verify whether the answer you've generated is correct?
~ Rohan|2023-06-29 00:43:53|Depends on your standard of QC too. Proofreading does not avoid hallucinations in many models.
Abhinav Verma Longshot.ai|2023-06-29 00:44:00|On a more serious notes, I've found this approach works to an extent
~ Rohan|2023-06-29 00:45:14|Recently, there was a case in the US where a lawyer submitted a legal doc generated by GPT and asked it multiple times to ensure everything was correct. It still made up cases out of thin air, leading to the lawyer receiving disciplinary action for not manually verifying the info
Abhinav Verma Longshot.ai|2023-06-29 00:45:39|No I think you need to RAG over here.
~ Rohan|2023-06-29 00:45:48|https://www.cnbc.com/2023/06/22/judge-sanctions-lawyers-whose-ai-written-filing-contained-fake-citations.html
~ Prajna Prayas|2023-06-29 00:46:00|legal documents are tricky. A word modified here and there and  the client finds himself hanging at  the court with the opponent tearing at them.
~ Rohan|2023-06-29 00:46:36|ideally, yes, to avoid such cases
Abhinav Verma Longshot.ai|2023-06-29 00:47:25|also GPT-4 ko poocho agar poochna hi hai
Ravi Theja|2023-06-29 01:01:03|https://github.com/salesforce/xgen - 7B models from salesforce with 8K context length.
Abhishek Mishra|2023-06-29 01:04:37|I really like Salesforce from the time they've been releasing codegen and BLIP models. Looks like they want to give Meta some company in open source gen AI research.
ashish Acgt01 Twitter|2023-06-29 01:08:02|In my field, biology and medicine , they have published quite a bit on generative protein design  https://www.nature.com/articles/s41587-022-01618-2  Quite impressive !
Abhishek Mishra|2023-06-29 01:10:08|Now I like them more.
~ Suhas Baliga|2023-06-29 01:12:46|Assuming no external sources and the doc only has to be analysed for what it contains.
ashish Acgt01 Twitter|2023-06-29 07:53:13|"came across this older but very exciting neurips 2021 paper on learning from videos ! anybody here used merlot ?  https://rowanzellers.com/merlot/ https://arxiv.org/abs/2106.02636  ""As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching 6 million YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time."""
Lohith GenerativeAI WhatsApp Group|2023-06-29 08:29:41|Anyone tried elastic search to host and perform the vector search, if yes what are the downsides compared to other vector DB out there in the market?  Idea is to index large numbers of text files(~ half million) and perform similarity search and further use this results to feed LLM models.
Edgar Monis Mumbai WHO|2023-06-29 08:30:27|Done it
Edgar Monis Mumbai WHO|2023-06-29 08:31:25|You need to be careful with chunking, add metadata and perform hybrid search (tfidf + vector) for results that need high accuracy
Edgar Monis Mumbai WHO|2023-06-29 08:32:31|Downsides : every once in a while the es cluster will kill a node bc Java oom. Correct configuration for your specific use case is an art
Pratyush Choudhury|2023-06-29 08:39:59|Happy to connect you with folks who've done it  The anecdotal feedback I've heard is that the nodes in the ES cluster keep going down, maintenance/configuration is a pain and the overall workload is brittle  Might be a good idea to consider a dedicated VectorDB
Taranjeet Singh Cookup.ai|2023-06-29 08:47:11|There are no downsides. Have used ES for vectors at scale.  The only pain is getting the ES cluster right in one go. If you have $$ you can use cloud offerings easily.  One tip would be to keep a somewhat larger refresh interval for ES index if you are making frequent inserts.
Anubhav mishra Zupay|2023-06-29 09:37:28|New Technique Gives Designers Added Capabilities by Incorporating Engineering Constraints Into Generative AI Models  https://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/  Wpw this is cool
Rajesh RS Generative AI WhatsApp Group|2023-06-29 09:48:25|Really interesting. Karen Willcox (and Olivier de Weck) have been talking about AI models for digital twins a bit. What's interesting about this space is the realm of physically based modeling - that dovetails into generative AI capabilities. The article has a video that discusses optimizations of the structure, performance, aerodynamics around the main exterior design provided - De Weck and Willcox did a lot of work at MIT (and published OCW courses) on multi disciplinary optimization - a highly underrated field of systems design and optimization amidst all this AI hype
Anubhav mishra Zupay|2023-06-29 09:50:12|Any resource to read about fine tuning Diffusion models for industrial designs ?
Anubhav mishra Zupay|2023-06-29 09:50:24|Based on engineering specifications ?
Rajesh RS Generative AI WhatsApp Group|2023-06-29 09:53:36|I know very little about diffusion models, and haven't explored this line of thinking but they may be relevant for topology optimization. Thanks for the note. But MDO and MDSO are practiced at least with low fidelity in aerospace and automotive engineering design (concurrent - across digital engineering, manufacturing and verification/validation). Related work https://arxiv.org/abs/2208.09591 ‎[6/29/23, 09:55:29] Rajesh RS Generative AI WhatsApp Group: ‎image omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-29 09:57:19|I've sometimes thought of topology optimization as an n-sample sign test (akin to the 1 sample sign test in statistical inference) subject to results by simulation, with an objective function. If that makes sense and is not an oversimplification.
~ Rachitt|2023-06-29 09:57:24|Hi folks,   Has anyone here connected your data with google search APIs or web crawling for webpages?  I'm trying to do the same but unable to find ways to do it effectively, been thinking about using: https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt as a starting point  Would love to know if anyone has built something with search+OpenAI, thanks!
Nirant|2023-06-29 09:59:00|cc [PHONE] runs a business on search+LLM
~ Krishna|2023-06-29 10:02:37|If you just want to search the Google page, SerpAPI is way easier to implement.  And then maybe a react style agent to go through the webpages?
~ Kashish Kumar|2023-06-29 10:08:13|Autodesk has been working using AI for engineering design for quite some time now
~ Rachitt|2023-06-29 10:08:39|Thanks [PHONE], dropped you a DM [PHONE]
Rasika Soni WhatsApp Group Admin|2023-06-29 10:12:58|‎Rasika Soni WhatsApp Group Admin left
Rajesh RS Generative AI WhatsApp Group|2023-06-29 10:16:56|Yes, they first made a splash with it in 2020 or so, there was a TED talk
~ Kashish Kumar|2023-06-29 10:18:59|I attended Autodesk’s AI for Engineering Summer School in Toronto 2019. So even earlier than that. They already had made a lot of progress in terms of research.
Rajesh RS Generative AI WhatsApp Group|2023-06-29 10:21:46|I'd love to hear about what you explored here. It promises to be interesting
~ Kashish Kumar|2023-06-29 10:26:49|Sure
Sugnan GenerativeAI Group |2023-06-29 10:27:32|‎You added Sugnan GenerativeAI Group 
~ Kashish Kumar|2023-06-29 10:31:09|https://vimeo.com/372439670
Rajesh RS Generative AI WhatsApp Group|2023-06-29 10:49:58|Thanks! :)
Nihit Desai Refuel.ai|2023-06-29 11:08:58|Here's a benchmark of ANN algorithms and implementations across various vector databases: https://github.com/erikbern/ann-benchmarks - might be helpful to understand tradeoffs for this choice!
Neha YC W23|2023-06-29 11:34:13|‎You added Neha YC W23
Rajesh RS Generative AI WhatsApp Group|2023-06-29 11:52:18|This is great. Seems like a good way to bring AI to real world problems, rather than just building another chat bot or image generation app...
Rajesh RS Generative AI WhatsApp Group|2023-06-29 11:53:26|Not to belittle the challenges behind these things of course, but there are other problems to solve too, in engg and systems design ‎[6/29/23, 12:22:55] Nirant: ‎image omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-29 12:24:23|Nice. Saw your tweet as well. Do we have a way of checking GPU usage by the model akin to Nvidia SMI?
Nirant|2023-06-29 12:24:35|This is CPU sir
Rajesh RS Generative AI WhatsApp Group|2023-06-29 12:25:09|I'm tempted to try it now. Thank you :) ‎[6/29/23, 12:25:20] Nirant: ‎image omitted
Abhishek Mishra|2023-06-29 12:29:04|The inference is very slow for 30B models on M2 pro, what's your token gen speed? Plus, this Yann Lecunn question stumbles even GPT3/4, it will be interesting how the 30B answers it though.
ashish Acgt01 Twitter|2023-06-29 12:32:28|Share details of the magic :) Are you planning to document the step by step setup ? I bet a lot of us here would love to reproduce it
~ Ashish|2023-06-29 12:45:27|You can guys also do this demo at your PC:  https://www.youtube.com/watch?v=SFdth6cYZdo
Kshitij Agrawal ML Engineer|2023-06-29 12:45:40|It's a captivating demo!  I'm helping an Indian startup in a similar space on image understanding models beyond SAM. Quite a few interesting pieces under the hood to make these apps work.
Nirant|2023-06-29 12:47:39|abacaj on Twitter is wrapping it in a script, should be out tonight
ashish Acgt01 Twitter|2023-06-29 12:50:33|Thanks bud Looking forward to it
Rajesh RS Generative AI WhatsApp Group|2023-06-29 12:51:13|Pretty neat, thanks
Abhishek Mishra|2023-06-29 12:51:38|Meanwhile, koboldcpp, ctransformers have mpt 30B 4 bit inference support. You should be able to find a simple guide to test it out even on Windows, provided you've ~30G free RAM
ashish Acgt01 Twitter|2023-06-29 13:08:37|https://github.com/abacaj/mpt-30B-inference
ashish Acgt01 Twitter|2023-06-29 13:13:52|[PHONE]   What was the script you were referring to ? Was it to make it even easier to try using docker or such ?  https://github.com/abacaj/mpt-30B-inference/issues/5#issuecomment-1612221080
Kshitij Agrawal ML Engineer|2023-06-29 13:36:45|The best way is to pre-qualify each of the datapoint and analyze for parts that matter to you - like correctness, coherence etc. Would love to know more about how are you doing it currently.
Nirant|2023-06-29 13:54:33|I'm not using Docker
~ Ashish|2023-06-29 14:29:47|https://erichartford.com/openorca
Rajesh RS Generative AI WhatsApp Group|2023-06-29 14:32:41|I'm looking at the same code / script. Slow as molasses for first inference. Mine is an older Mac. Perhaps I should try this on Colab
Kishore GenAI|2023-06-29 14:35:02|"They claim to be ""The first WebGPU enabled image editing platform."" Has anyone been able to work with webGPU here? How was the experience ? ‎[6/29/23, 14:35:54] Nirant: ‎image omitted"
Abhishek Mishra|2023-06-29 14:40:55|Yeah, I like him but I can't say that OpenOrca would be useful for anything other than his personal or his sponsor's advertisements.
Abhishek Mishra|2023-06-29 14:42:01|Their first release for OpenOrca is on Llama 7B and it includes a semi-GPT4 guided dataset, so even that is kind of a blurry line.
Abhishek Mishra|2023-06-29 14:43:10|You'll need a high RAM instance or you may try the GPU offloading version for inference.
Rajesh RS Generative AI WhatsApp Group|2023-06-29 14:44:15|Yeah, I will try that. I have 24GB on one machine, getting the model downloaded on it now
Rajesh RS Generative AI WhatsApp Group|2023-06-29 14:44:52|Apple uses shared memory and better integration means this may run better on Macs, but I have a Linux machine (Thinkpad) with 24 GB. If it doesn't work, there's always Colab
Nirant|2023-06-29 14:57:01|~30G is recommended minimum for decent speed
Abhinav Verma Longshot.ai|2023-06-29 16:41:55|Colab pro par chalega?
Nirant|2023-06-29 16:47:19|Try and find out!
Nirant|2023-06-29 16:47:30|I've not had a chance to try
~ Ankit Shrivastav|2023-06-29 17:07:33|‎~ Ankit Shrivastav requested to join
~ Clament John|2023-06-29 18:25:00|Supabase CEO on pgvector's lackluster performance in the ann-benchmark  1. Wait 6 months, a lot of development is happening on pgvector 2. Use hybrid search 3. Use filters on other indexed columns 4. Use partitions  My opinion: I think pg will grow to be good enough. Like it has in the past with full text search. Frankly I didn't expect it to do so poorly.  https://twitter.com/kiwicopple/status/1674395364441350145?t=U-dgxSV1KoC42-9T_zdKXQ
~ Tirtha|2023-06-29 18:43:17|Anyone here who has used BERT variants for multi lingual tasks like dealing with text which has Hindi+English? Just a small doubt would really appreciate if you can help me out over DMs.
~ Tirtha|2023-06-29 18:44:24|Please react to this message if you’re okay with me reaching out
Nirant|2023-06-29 18:44:29|https://arxiv.org/abs/2008.09820   What can I help with?
~ Apurva Bhatt|2023-06-29 18:45:35|Yes, I have used xlmr.
Rajesh RS Generative AI WhatsApp Group|2023-06-29 19:15:38|I’m trying to use that only
Abhinav Verma Longshot.ai|2023-06-29 19:16:25|Colab pro you get more ram if you use advanced gpu setting
Abhinav Verma Longshot.ai|2023-06-29 19:16:34|Just fewer hours
Nihit Desai Refuel.ai|2023-06-29 19:25:06|I've used XLM quite a bit for text classification (https://arxiv.org/abs/1901.07291). happy to help!
Nirant|2023-06-29 19:29:45|+1 for XLM ‎[6/29/23, 19:31:26] Sanyam Bhutani: ‎image omitted
Nirant|2023-06-29 19:31:58|It's a franchise!
Pranjal Mehta|2023-06-29 19:32:05|My prediction was ChaatGPT but close enough
Gokul Krishnan|2023-06-29 19:32:33|Thinking about scale from day 0. Scaling is all you need, no? 😜
~ Vishwam Jindal|2023-06-29 19:34:27|I know this has been slightly discussed before but is there any document or page comparing Redis and Qdrant? any place people have shared their experience in production?
Anubhav mishra Zupay|2023-06-29 19:34:54|Hi all, Is anyone closely following Inflection AI Pi? Wanted to understand how it is so fast in responding? Btw if you want to regularly use it they have it everywhere. Insta, WA, Messenger ‎<This message was edited>
Abhishek Mishra|2023-06-29 19:57:44|I'll suggest trying out HingRobertaMixed and HingRoberta via HF inference. They are xlm-roberta fine tuned for code switching (Hindi+english) tasks. You may not need to fine tune specifically for tasks such as sentiment analysis, hate speech detection and other NLP subtasks. Code switching NLU with a mix of Roman + Devnagari scripts is  challenging in general. But based on what I've read, they are SoTA.  I was doubtful if they have overfitted with fine tuning but their model holds ground in independent cross validation metrics.
Aakash Kumar  Matrix Partners|2023-06-29 19:59:47|What’s the prompt for this one ?
~ Shyam|2023-06-29 20:05:53|Sorry guys!
Abhinav Verma Longshot.ai|2023-06-29 20:13:39|There is a chaatgpt here in Mumbai
~ Sudhanshu Heda|2023-06-29 20:33:28|With all specialised LLMs in place for different use cases, do you think being able to switch from 1 LLM to the other along with context developed previously would be important? Basically communication between 2 or more LLMs
Swastik Banerjee|2023-06-29 21:04:39|I’m here at the wolfram hq for a month. If anyone has any questions related to the wolfram plugin, or to stephen, feel free to drop them here; I can redirect :-) ‎<This message was edited>
~ Ankit Kumar Pandey|2023-06-29 21:22:10|‎Ravi Theja added ~ Ankit Kumar Pandey
Ravi Theja|2023-06-29 22:04:33|https://twitter.com/mustafasuleymn/status/1674418106738044929?s=20 - Inflection AI raises $1.3 billion funding
Abhishek Mishra|2023-06-29 22:13:29|Well, looks like Microsoft wants their hands in every piece of Pi. Satya is one of the people leading this round of investment along with Nvidia and some top tech billionaires like Bill Gates, Eric Schmidt.
Krishna Panchal|2023-06-29 22:25:10|They solely do not depend on OpenAI only. Let's see which company is next on their list. Any guess ? ‎<This message was edited>
Anubhav mishra Zupay|2023-06-29 22:37:35|Yeah man! They have nailed it.
~ Apurva Bhatt|2023-06-29 22:38:23|I guess, they might have invested in companies working on genAI videos as well
Abhishek Mishra|2023-06-29 22:59:38|I think there are two components here. * Promising sector - Personal Assistant space * Ability to train their own LLMs of right competency  If I was to guess, any company that may showcase ability to build in their own space and be from a promising sector may get picked up. But if I picked which companies it'll be, I'll most likely be wrong 🤣
Paras Chopra Wingify|2023-06-30 00:03:10|Has anyone used Pi? Curious to hear what others think
Abhinav Verma Longshot.ai|2023-06-30 00:04:03|Think [PHONE] has applied for access for this. So waiting..
Abhishek Mishra|2023-06-30 00:05:05|More empathy, friendliness and comfort in conversation. Not very high in reasoning when I checked it out but conversations flow very well. ‎[6/30/23, 00:23:13] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-06-30 00:24:07|I shared this as it highlights one of the important things I've mentioned while working with similarity detection or information retrieval,   When do keyword based methods perform really well or outperform vector embeddings?
Abhishek Mishra|2023-06-30 00:27:36|In all the cases BM25 beats the famed miniLM-L6-v2 and mpnet-v2 embeddings, we find following patterns * The dataset is domain driven and has lots of terminology that generally trained vector embeddings will lack by itself * The dataset requires reasoning for IR between multiple documents or sources instead of a single doc containing most relevance * The dataset contains argumentative statements where the information can be positive or negative with respect to a term but relevant argument fetching can be tricky
~ Ritik Madan|2023-06-30 00:44:55|Interesting! https://twitter.com/AnthropicAI/status/1674461614056292353?s=20
ashish Acgt01 Twitter|2023-06-30 07:57:58|That reminds me, what do folks think of Poe ( from the quora founder ) ?
Paras Chopra Wingify|2023-06-30 08:14:53|Isn’t that a skin on chatgpt
Dhruv Naik|2023-06-30 08:16:42|Its open, I dont think you need to request access
Ravi Theja|2023-06-30 08:47:25|https://twitter.com/lmsysorg/status/1674562017410297856?s=20  LongChat with 16K tokens context and LongEval for testing long context chatbots.
Jay Pokarna 2014 BPCC|2023-06-30 10:02:24|There was a guide on prompt engineering that was shared a while ago on the group. Not able to find it. Can anyone pls share resources to get better with prompting?
Nirant|2023-06-30 10:04:27|If there are more than 10 folks interested in this, can do a curated compilation of all community resources around prompting for text.   Leave a 🙌 against this message if you'd find it useful.
~ Shirsha|2023-06-30 10:06:54|Am also wondering how to package reusable prompting strategies like a layer designed for reuse to many use cases above it
Neeraj Kumar|2023-06-30 10:13:36|These are some of the prompt engg guides links I had kept if anyone is interested. It includes the one shared here : https://crocus-almanac-be9.notion.site/Prompt-Engineering-002d00ac83074a45adfdd4263cff573f
Ankur Pandey|2023-06-30 10:14:37|https://forms.gle/aTLXNo3QXQyhmi9g9  For api access.  1st impression : more conversational compared to other AI bots
Abhishek Mishra|2023-06-30 10:32:58|You mean this one - http://nishnik.notion.site/nishnik/language-models-for-hackers-8a0e3371507e461588f488029382dc77
Shan|2023-06-30 10:38:23|Basics of Prompt Engg https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction    A bit more depth on prompt engg (video, more interesting 15m onwards) https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/prompt-engineering/  Elvis prompt engineering guide, fairly exhaustive https://github.com/dair-ai/Prompt-Engineering-Guide  Prompt engg stuff by brex https://github.com/brexhq/prompt-engineering  A lot of prompt engineering tips https://nishnik.notion.site/nishnik/Language-Models-for-Hackers-8a0e3371507e461588f488029382dc77  Lilian Weng’s guide https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
Krishna Panchal|2023-06-30 10:43:29|Sometimes going there for only conversation not for knowledge
Paras Chopra Wingify|2023-06-30 10:56:09|Do you know what kind of things they do to make conversation interesting?  What makes you go to it? When you’re bored? Curious
~ Pranav|2023-06-30 11:01:43|great compilation! cc community resources [PHONE]
Krishna Panchal|2023-06-30 11:18:37|1. Conversation like Friendly Human  2. When I'm bored. ‎[6/30/23, 11:18:51] Dr. Pratik Desai KissanGPT: ‎image omitted
Abhinav Verma Longshot.ai|2023-06-30 11:22:47|link share kar do. This one looks like a Railway reservation chart
~ Vrushank Vyas|2023-06-30 11:23:01|Pi is distinctively good for those late night convo you’d have with a friend - stuff that’s on your mind, anxieties, etc.  One interesting thing is, after some convos, I wanted it to be agentic.. like do more things than just chat. Set up timers, create tasks, and more
Abhinav Verma Longshot.ai|2023-06-30 11:23:05|But damn the number of events. Shows where its at
Dr. Pratik Desai KissanGPT|2023-06-30 11:23:34|https://docs.google.com/spreadsheets/d/1P6ut7vL-gXKbeDeh3nuPqBjoCupjIt87Sw7TnhumBSU/htmlview#gid=1781893986
Abhishek Mishra|2023-06-30 11:23:43|You guys missed to have an event on June 5 😞 ‎<This message was edited> ‎[6/30/23, 11:24:45] Abhinav Verma Longshot.ai: ‎GIF omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:26:33|Events are not a proxy for great companies or problem statements although they can sometimes be. There’s lots of AI opportunity and work done in East Asia as well without as many events
Dr. Pratik Desai KissanGPT|2023-06-30 11:26:45|That’s surprising
Abhinav Verma Longshot.ai|2023-06-30 11:27:32|yes true. If you're only attending events , then you're not working. But still interesting to see this.
Dr. Pratik Desai KissanGPT|2023-06-30 11:27:47|Actually they are. Those silent warriors of East Asia are moving where they are heard.
Dr. Pratik Desai KissanGPT|2023-06-30 11:29:09|It’s different feeling when you can bump into Karpathy, Fridman, or others here and there
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:29:18|There’s also a cottage industry of influencers also that just want to organise these events. And give away awards like 40 under 40. Someday we will even see 90 under 90 awards in AI. Not to downplay the importance of these events
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:30:17|That’s because they have media empires in addition to being or having been technical leaders in their fields.
Krishna Panchal|2023-06-30 11:31:18|https://twitter.com/EMostaque/status/1674509839458791431?t=EtblykAzDT4d6EpdDiZesA&s=19  Good AMA by Emad
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:31:42|How many will come if Ishan Mishra or Szegedy are invited as key speakers? Maybe some but not as many as Friedman or Ng. Just the way things are with media empires and tech gurus
Abhishek Mishra|2023-06-30 11:34:00|Call it a tech guy's bias, but I find others only useful as news reporters. Very few folks like karpathy but 🤯 and 🧵👇 is what is everywhere
Dr. Pratik Desai KissanGPT|2023-06-30 11:35:02|Is this a rant for missing out or do you have exact engagement numbers for other events. In SF, you may be sitting beside Anthropic CEO and you may not know. That’s talent concentration.
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:37:49|Question for me is more practical - would you sit through a Sam Altman monologue in person or online at your convenience, while you get work done wherever else you are. Do you have to be in the city and in person to really get the best out of the event? Is Anthropic the only source of inspirational ideas for me or can I get them from elsewhere by attending an event remotely, or elsewhere? We do live in a world where a lot of teams are remote, great work is done remotely and distributed, so is there a reason to drool over SF events?
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:38:49|Many of us who are working with the tech may get more out of a (Lex Fridman podcast) with Ishan Misra in it or someone else than a highly marketed event. So it depends.
~ Shriya Kaneriya|2023-06-30 11:39:20|‎~ Shriya Kaneriya joined using your invite
Dr. Pratik Desai KissanGPT|2023-06-30 11:39:25|Why are you trying attend all 84 events? 🤷‍♂️
Dr. Pratik Desai KissanGPT|2023-06-30 11:39:54|Like, do you watch every podcast ever produced on tech?
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:40:44|Who is attending all 84? And who is watching every podcast? You have arguably more choice online as events stream, than if you were in person - and I agree if you're a business leader you may need to be in person for some things. Your focus then is different.
Abhinav Verma Longshot.ai|2023-06-30 11:41:58|This seems like a good idea for MeetupGPT. Summarize every meetup , do q&A on different things discussed
Dr. Pratik Desai KissanGPT|2023-06-30 11:42:28|There is a different level of connection when meet people in person and exchange ideas. Remote is overrated.
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:42:39|Great idea. Meeting summarization is a superb idea in general
Krishna Panchal|2023-06-30 11:43:14|Which tech podcast do you listen to? Can you recommend some.
Dr. Pratik Desai KissanGPT|2023-06-30 11:43:34|Podcast is a one way street for learning, have a good hot discussion in person with few folks who know their things and not just asking questions.
Azhan Mohammed Generative AI WhatsApp Group|2023-06-30 11:43:39|I guess Rewind added this feature recently, they record your meetings and gets you minute of meetings.
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:43:43|Remote is great for certain things, and in-person great for other things, IMHO. To each his own. ‎[6/30/23, 11:45:13] Apurv Aurva.io Sahil's Friend: ‎GIF omitted
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:45:42|Strata used to be doing conferences left and right, spoke at one of them some years ago - and for 2016 they had a good experience in playing back the meetings and so on. I don't think they did summarization back then though
Abhinav Verma Longshot.ai|2023-06-30 11:46:05|meetups make more sense with remote work now.
Rajesh RS Generative AI WhatsApp Group|2023-06-30 11:46:19|Even modest human generated summaries would have been good.
Dr. Pratik Desai KissanGPT|2023-06-30 11:46:40|Not to strech the topic, but I personally go to only few meetups where only hackers shows up, and demo their projects. I know that I saw Shreya for Guardrail presenting there. I was allowed to demo two of mine. Other great demos and people everytime. ‎<This message was edited>
~ Prajna Prayas|2023-06-30 11:46:41|...that nobody reads😅
Azhan Mohammed Generative AI WhatsApp Group|2023-06-30 11:50:42|all the more reason to offload the task 😄
~ vignesh iyer✌️|2023-06-30 12:02:30|Need to say this louder💯
Adithya S K PESIT|2023-06-30 12:30:56|https://towardsdatascience.com/vllm-pagedattention-for-24x-faster-llm-inference-fdfb1b80f83  guys what are your thoughts on this👍
Prashant Singh|2023-06-30 12:32:06|https://pi.ai/s/14R8gbnGNeM9Fo75qLH4p
Abhishek Mishra|2023-06-30 12:39:53|Yes I've studied the vLLM method. It uses continuous batching to reduce memory footprint by avoiding loading model parameters every time on every conversation.
Abhishek Mishra|2023-06-30 12:40:24|It's not for a peasant like me who has 1 machine to work on and not 100s of parallel running instances
~ Kartheek Akella|2023-06-30 12:40:28|Are there any no code tools where you can edit your Prompts and prompt-templates then deploy it as an API, which can be used for building my applications?
~ Kartheek Akella|2023-06-30 12:40:46|Initially felt like every company is doing this... surprisingly can't even find one!
Abhishek Mishra|2023-06-30 12:41:31|It's for guys who are api providers or have to maintain conversations using the LLMs across multiple chat sessions (best if 50-100).
Shan|2023-06-30 12:48:13|https://lmql.ai might come close?
~ Kartheek Akella|2023-06-30 12:51:09|cool... I'll check it out
Sandeep Srinivasa RedCarpetup|2023-06-30 12:51:32|we also take our different approach here. instead of inventing a new language/sql, we use jsonnet - which is a config format used at Google Borg/Kubernetes. we specify the chain + prompt in jsonnet so no multiple layers of libraries/functions to navigate through.  anything written in edgechains is automatically api-fied, supports streaming, retry/backoffs, etc.  https://github.com/arakoodev/EdgeChains/releases/tag/0.2.0
Rajesh RS Generative AI WhatsApp Group|2023-06-30 12:52:32|Wow, Pi is beautifully put together
Dhruv Anand|2023-06-30 12:53:15|thoroughly useless. kind of like nat.dev for mobile. I'm disappointed that Quora with all of their data and ML expertise are not actually innovating on LLMs. ‎<This message was edited>
~ Kartheek Akella|2023-06-30 12:56:43|Interesting... Will check it out
Dhruv Anand|2023-06-30 13:06:20|Is there a python library which returns the dollar amount that an openai request has costed? I know they return the tokens, but maintaining a pricing table ourselves seems tedious and easy to break, given the frequent pricing changes. ‎[6/30/23, 13:10:13] Anubhav mishra Zupay: ‎image omitted
Krishna Panchal|2023-06-30 13:11:30|Wow is this your chat?
Prashant Singh|2023-06-30 13:14:06|yeah .. just horsing around
Prashant Singh|2023-06-30 13:14:25|Bot handelled it well I must say
Prashant Singh|2023-06-30 13:14:48|but again the guy behined the company is co founder of Deep Mind
~ Pranay Desai|2023-06-30 13:14:51|[PHONE] is the founder and here 👋
~ Kartheek Akella|2023-06-30 13:16:57|way too safely hidden behind the waitlist... as of now, cant wait to try it actually ‎[6/30/23, 13:17:17] ~ Vrushank Vyas: ‎image omitted
Rohit Aggarwal|2023-06-30 13:17:41|Damn! Sorry, can you send me a DM and I’ll give you access right away? ‎[6/30/23, 13:23:01] ~ Vrushank Vyas: ‎image omitted
Rohit Aggarwal|2023-06-30 13:28:05|Thanks! And true - this has been a big thing to manage for us as well. Costs of all models, newer ones and discounts and credits at times
Rohit Aggarwal|2023-06-30 13:28:36|In the future, we’ll try opening up an API just for easy pricing.
Rajesh RS Generative AI WhatsApp Group|2023-06-30 13:29:24|Azure openai service seems to have a way of doing this. I’m not sure about openai’ own endpoints
Abhishek Mishra|2023-06-30 13:33:48|Custom product just for this one use case  https://puddl.io/
~ Arsalaan|2023-06-30 13:34:35|I think langchain or llama index support some functions ro monitor cost
Paras Chopra Wingify|2023-06-30 13:35:22|"just played with it,  what i observed:  - their differentiation is in RLHF (they seem to have trained on dataset where asking good questions and conversation length is rewarded, not just right answers) - They seem to have specialized flows (like ""20 questions""), and LLM switches between those, so maybe specialized tokens indicate flows perhaps"
Dhruv Anand|2023-06-30 13:37:15|thanks, using this seems to be the best option, since folks will ensure it remains up to date
Narendranath Gogineni|2023-06-30 13:50:18|We’re building a solution around this at quolum.io
Dhruv Anand|2023-06-30 13:51:10|ohk, I was asking since I'm open sourcing a related library myself haha
Narendranath Gogineni|2023-06-30 13:51:16|Id be happy to show you a demo
Narendranath Gogineni|2023-06-30 13:51:28|Xd no demo then
Anubhav mishra Zupay|2023-06-30 13:57:05|Helpful , thanks :)
ashish Acgt01 Twitter|2023-06-30 14:02:43|blown away by pi ! feels like i am talking to a fellow human !  i was feeling a little distracted today and tried talking to pi honestly : https://pi.ai/s/UmEj8XDASD4sqmL4EviNz  if they could add voice input & output, it could potentially be a coach or therapist too !  really really impressive !
Paras Chopra Wingify|2023-06-30 14:05:04|Did you end up acting on its suggestions?
~ Mayank Gupta|2023-06-30 14:08:28|Very interesting! I need to play around with it more I guess
~ Mayank Gupta|2023-06-30 14:09:33|But the Greylock podcast about it was insightful too. Stressed on how they're trying to build the emotional core first!
Abhishek Mishra|2023-06-30 14:10:44|It's a wonderful conversation partner. It'll be a shame to prompt hack it and force it's creators to perform RLHF lobotomy on it.
Dhruv Anand|2023-06-30 14:10:53|has anyone self-hosted weaviate on azure/gcp before? wanted to get some info
~ Mayank Gupta|2023-06-30 14:11:54|I don't agree with building the emotional core first, but that's also a personal belief on the Planning-Memory-Execution trifecta ‎[6/30/23, 14:14:08] Sandeep Srinivasa RedCarpetup: ‎image omitted
~ Sahir Patel|2023-06-30 14:20:42|"hi , this might be a dumb question but while I'm doing SqlDatabaseChain calls in langchain , how do ensure the query doesn't respond to some unwanted/sensitive data .   eg - i have a table with a column for email id , and i wanna return only values for [EMAIL] . i can append in the prompt "".. only give the values for [EMAIL]"" , but theres always a chance of prompt injection , and it returning values for other emails...  currently im appending   `WHERE users.email = ${email}` at the end of each user generated prompt , before calling the sqlChain , and it seems to be working fine , but feels like a hacky way."
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-06-30 14:23:07|Hi. Do you have the original Excel sheet ?
Paras Chopra Wingify|2023-06-30 14:23:41|do you have a link?
Paras Chopra Wingify|2023-06-30 14:23:58|why not?  it's solving a different use case than chatgpt
~ Pranay Desai|2023-06-30 14:24:38|https://open.spotify.com/episode/67MBhAISm2aB6wwzjROJjs - this one
~ Mayank Gupta|2023-06-30 14:25:17|Thanks was just searching
Dr. Pratik Desai KissanGPT|2023-06-30 14:25:32|Shared Google docs link somewhere above
~ Mayank Gupta|2023-06-30 14:26:46|Yes yes I agree with the use case. I basically believe a more effective Personal AI will first solve for task support than emotional support.
Paras Chopra Wingify|2023-06-30 14:28:22|i am not sure if we even understand what does personal AI even means? is it a coach, a friend, a companion, an expert? a single person often isn't everything
~ Mayank Gupta|2023-06-30 14:28:31|Happy to chat more on DM too. It's a topic I've been spending a lot of time on for a while
~ Mayank Gupta|2023-06-30 14:29:22|Agreed. And it can be all distinctly and also combined. And it'll likely evolve too. In fact Inflection says they're an AI studio and Pi is their first offering!
Nirant|2023-06-30 14:31:27|This is surprising. I thought everyone knew about pgvector limitations!
Nirant|2023-06-30 14:31:39|This is indeed the best possible outcome
Nirant|2023-06-30 14:40:46|Jo just sent this — he is roasting Supabase's outright sleaziness and using pgvector's goodwill for profit  https://twitter.com/jobergum/status/1674541715099664386
Nirant|2023-06-30 14:41:00|Jo is the creator of Vespa which powers Yahoo's Text Search
Dhruv Anand|2023-06-30 14:43:13|I'm guessing other vectordb companies were keeping quiet about it since they didnt want pgvector to add hnsw too quick
Nirant|2023-06-30 14:44:37|Supabase CEO shooting themselves in the foot 🙈 https://twitter.com/kiwicopple/status/1674550357110800384
Sandeep Srinivasa RedCarpetup|2023-06-30 14:45:19|nirant ur tweet is IMBA
Nirant|2023-06-30 14:45:28|No no. Supabase is eating into every vectorDB's roadmap. I've access to 2 of top 3 players roadmap
Nirant|2023-06-30 14:45:36|What is IMBA?
Nirant|2023-06-30 14:47:05|Credit where it's due, almost all the engineering here is done by Shivendu [PHONE]. I've mostly been good/lucky at spotting a problem
~ Aman|2023-06-30 14:47:26|Did we get a detailed benchmark on pgvector? Have completely missed this
~ Pranay Desai|2023-06-30 14:47:49|imbalanced? Gamer lingo 😅
~ Kaustav K Bose|2023-06-30 14:48:42|Its OP instead of IMBA nowadays, after league of legends overtook Dota 2 😝
Nirant|2023-06-30 14:48:45|More detailed than anything else  https://nirantk.com/writing/pgvector-vs-qdrant.html
Dhruv Anand|2023-06-30 14:49:41|does anyone know of a HF inference endpoints-like service which offers lower end (and cheaper) GPUs?
Nirant|2023-06-30 14:49:57|RIP Twitter DMs, so much attack from pgvector fanbois 😅  Feels like I've fallen into vim vs emacs
Abhinav Verma Longshot.ai|2023-06-30 14:50:29|You made it
Shivendu Kumar|2023-06-30 14:51:00|Thanks Nirant! 🙏
Abhinav Verma Longshot.ai|2023-06-30 14:51:50|Awesome work ‎[6/30/23, 14:58:44] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-06-30 14:59:48|But typically the marketing boosted gravy trains come back on track in some time
~ Ankit Shrivastav|2023-06-30 15:05:24|‎~ Ankit Shrivastav joined using this group's invite link
~ Vrushank Vyas|2023-06-30 15:09:51|They have full voice interface on at least the iOS app
Nirant|2023-06-30 15:10:17|cc [PHONE] since we were talking about Inflection AI
~ Ashish|2023-06-30 15:11:23|https://www.reddit.com/r/LocalLLaMA/comments/14me1ha/open_orca_dataset_released/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=3
ashish Acgt01 Twitter|2023-06-30 15:14:46|Congratulations [PHONE] & [PHONE] !
ashish Acgt01 Twitter|2023-06-30 15:30:35|"2 q.s on pi like assistants which came up, would love to hear from the group :  1. To build something like pi for India, with a focus on voice first UX, what would be the top5 languages one would start with ?  2. 1-2 years out, would there be a separate shopping assistant/agent, separate medical/health assistant,separate mental health assistant, separate financial advice & investment assistant , separate <xyz> assistant  Or 1 assistant which is trained on a wide variety of training data to rule them all ?  Or 1 master assistant which would ""invoke"" specialised sub assistants depending on the context of a particular prompt ?  Or  Will there be something cometely new or different ?"
Nirant|2023-06-30 15:31:02|cc [PHONE] this feels like is in your alley
~ Mayank Gupta|2023-06-30 15:32:30|IMHO for Q2 - 3rd option - the invoking - whether assistants or other apps/plugins to get it done
~ Mayank Gupta|2023-06-30 15:32:41|But following views of the group very keenly
Prashant Singh|2023-06-30 15:45:13|[PHONE]
Abhishek Mishra|2023-06-30 15:49:40|"It's anybody's guess but I'll take the ""master assistant and helper assistants"" bet.  There's an inherent limitation in current architecture in SoTA LLMs that does not allow general intelligence to develop. More than anything else, just the fact that different tokenisers optimise performance on different tasks is a key factor. Currently arithmetic, counting words and entities requires training tokenisers differently than how it has been trained for Llama/GPT like LLMs. Likewise, code generation works best with it's own kind of tokenisation approach.  There was a research that I saw last month, that seems to resolve these dependencies on tokenisations and accumulation of error with token length. I'll have to look it up again and understand more. ‎[6/30/23, 15:50:27] ashish Acgt01 Twitter: ‎image omitted"
~ Vrushank Vyas|2023-06-30 15:51:21|No sign in on mobile
ashish Acgt01 Twitter|2023-06-30 15:52:26|Might just be a conscious design choice but seems a bit weird to me.  Maintaing context of previous conversation threads, seems like an obvious feature
Paras Chopra Wingify|2023-06-30 15:55:36|my take is that text is not a universal interface, and as soon as you add other interfaces, specializations will emerge and hence specialist assistants will emerge
Anubhav mishra Zupay|2023-06-30 15:56:10|But you you try it on insta, it will call you by your name.
Anubhav mishra Zupay|2023-06-30 15:56:16|They have an insta bot too
Pranjal Mehta|2023-06-30 16:06:31|[PHONE] answering at your command  [PHONE] #1 language demographics is good L1 data. L2 can be inverse of digital savviness (less savvy = higher chance of voice input preference AFAIK)  #2 my take is Option 3 - a master assistant interfacing with other specialised assistants. Assistants will become the next interface to the internet. In the past it was Google. We often know a website but we go to the search bar and type the name of the website and go to the website using the Google search. That is not because you can't go to the website directly just because Google is almost synonymous with the internet. This new master assistant will become the new gateway to the internet replacing google search. There are lessons to be learned from the search internet era - When Google was coming up, everyone thought that would be specialized search engines for healthcare for education etc. But Google became the single gateway to the internet. I think history will repeat itself in that sense, given that these assistants are afterall the Google search killer
Abhishek Mishra|2023-06-30 16:29:04|Anybody has experience with phind.com? I'm seeing reviews where it's supposedly very good with data that is not part of GPT4 training cut off. It's also being claimed that it can program on much recent coding standards by automatically finding relevant docs.
~ Maruti Agarwal|2023-06-30 16:32:33|Please share you find it.
~ Diwank|2023-06-30 16:33:30|It’s quite good but has hallucinations for fringe use cases
~ Diwank|2023-06-30 16:36:53|I think the future is personal assistants fine tuned uniquely for every individual that in turn interact with the rest of the ecosystem
Abhishek Mishra|2023-06-30 16:37:48|Found it. Going to study it more to see if I can repro this with nanoGPT.  The paper is - *MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers* Link - arxiv.org/abs/2305.07185  *Tweet by Karpathy where I became familiar with the problem with tokenisation approaches* -  https://twitter.com/karpathy/status/1657949234535211009?t=KzDvK0DLzkIIB4zKENQY1g&s=19
Nitin Mahajan McKinsey|2023-06-30 16:38:30|"I sometimes wonder how this ""space"" of personal AI will be once Apple, Google, etc launch their own. They have more data, and barriers to put. Huge field and will happen for sure but are odds against the small guy?"
Nitin Mahajan McKinsey|2023-06-30 16:38:34|Personal AI bots
Abhishek Mishra|2023-06-30 16:39:07|Yeah, even GPT4 loses context and starts making up stuff if my context history is long. So, I'll see if that problem occurs sooner with phind. Thanks for sharing your comments.
Vaibhav Bhargava Meesho Grab |2023-06-30 16:43:19|Maybe it will be something physical. Mattel tried their own version of AI companion with talking barbie in 2015  https://www.nydailynews.com/life-style/mattel-unveils-barbie-talk-kids-article-1.2119732
Nitin Mahajan McKinsey|2023-06-30 16:45:55|There will be physical manifestations (robots, alexa 2.0, etc) but as always software and AI will drive who owns the hardware product domination. Genuinely curious as to what smart VCs are seeing put billions in new upstarts like character.ai when the end-game can be pulled out. Just all the info Meta has from whatsapp communication (on me) is something I will never disclose to another company or they able to snoop and make it contextual enough. Laptop or OS owner has an edge, which makes me at least scary
ashish Acgt01 Twitter|2023-06-30 17:45:20|Maybe Lab126 is cooking astro ++ with gen ai and Alexa   https://youtu.be/DxVtJW8ROAQ
Nirant|2023-06-30 17:46:13|Weekend reminder, this is the set of *rules* we try our best to enforce for everyone in this WhatsApp group: https://nirantk.com/community  At this moment, we also remove folks who're not able to contribute in any 60 day period because WhatsApp caps the group to 1K members
Abhinav Verma Longshot.ai|2023-06-30 17:47:33|https://t.co/genXa1UHuL [PHONE] [PHONE] you missed benchmarking against this hyper fast db 😂😂😂😂
Nirant|2023-06-30 17:48:27|Yeah, we wanted to keep the competition fair 😂🤣  For anyone reading this, that's a joke database made for laughs and not a real Vector DB
Abhinav Verma Longshot.ai|2023-06-30 17:49:02|I tried using this but the openai embeddings but they were too overwhelmed by its awesomeness and refused to get indexed
Dr. Pratik Desai KissanGPT|2023-06-30 17:52:08|TBH I believed it was real until finding out little later.
Abhinav Verma Longshot.ai|2023-06-30 17:52:44|You should read the source code. I wonder how openai functions will react seeing those names
Dhruv Anand|2023-06-30 17:53:06|There's an indian publication that took their joke about the fundraise at face value and printed it in an article 😂
Dr. Pratik Desai KissanGPT|2023-06-30 17:54:40|I realized after seeing galaxy_brain_**** file name
ashish Acgt01 Twitter|2023-06-30 18:01:21|Lab126 is the hardware division of Amazon
Chaitanya Mehta Goodera Turtlemint|2023-06-30 18:15:05|Is there anyway to fast track access to GPT4 API? ‎[6/30/23, 18:16:34] Krishna Panchal: ‎image omitted
Sudharshan GenAI|2023-06-30 18:21:06|yup age-old good practice
Lalit Pagaria|2023-06-30 18:24:13|Also never trust any pickle file. Even there is an old issue with PyTorch  https://github.com/pytorch/pytorch/issues/52596
Abhishek Mishra|2023-06-30 18:24:14|Yeah, this is why safetensors were created in the first place. Many releases use checkpoint formats that aren't in safetensor format
Shimanta Generative AI|2023-06-30 18:47:32|https://twitter.com/reach_vb/status/1673363113888948224?s=46&t=WT1iAtjftW-5_e62F8FZTg  This guy tweaked whisper to directly transcribe to ‘any’ language. It says it’s experimental.
~ Tirtha|2023-06-30 18:50:07|Can anyone please share resources for PII Redaction models for healthcare use cases?
Abhishek Mishra|2023-06-30 19:06:05|Where's the hack in this?
Abhishek Mishra|2023-06-30 19:06:35|Isn't this what is already possible via whisper base ASR?
Shimanta Generative AI|2023-06-30 19:08:29|Afaik, whisper transcribes from a language to english. Then we can perform translation. What the op did is perform this 2 step process at one go.
Abhishek Mishra|2023-06-30 19:12:35|You can already do direct transcription for any language via whisper transcribe.   I checked the tweet, the original message is incorrect. The OP wants to convey that they can directly translate an audio input in one Language to any other Language. But the chosen wording is that you can transcribe from any audio language other than English, which is already possible.
Shimanta Generative AI|2023-06-30 19:13:43|That’s what i was trying to mean as well, sorry if my message was unclear
Shimanta Generative AI|2023-06-30 19:15:13|Also i mentioned direct transcribe ‘to’ any language, not for any language.
~ Ankit Banerjee|2023-06-30 19:37:33|‎~ Ankit Banerjee requested to join
~ Ankit Banerjee|2023-06-30 19:39:42|‎~ Ankit Banerjee joined using this group's invite link
Nirant|2023-06-30 19:53:38|Found this pretty cool project: AutoLabel — text tagging library which use LLMs under the hood https://github.com/refuel-ai/autolabel  Pretty powerful if you've unsupervised data which you want to scale up for NLP kind of tasks e.g. NER, QA  Creators Nihit [PHONE] and Rishabh [PHONE] are in the group too!
Nirant|2023-06-30 19:54:10|h/t Bhavya [PHONE] for the Twitter mention
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-30 19:55:50|More Indian Diaspora doing amazing stuff to come! 🔥
Nirant|2023-06-30 19:56:52|Meta:   I believe this group has more folks from Surat than my entire undergrad year now (there were 2 people, incl. me) — different kind of talent density 🔥
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-30 19:59:14|I am not from Surat but sure am a gujju lol
Dr. Pratik Desai KissanGPT|2023-06-30 20:00:27|People are figuring out that there other “Dhandho” than just Textile and Diamond ‎[6/30/23, 20:05:02] Bhavya Ranpara Generative AI Wa Group Surat: ‎GIF omitted
Nihit Desai Refuel.ai|2023-06-30 20:09:22|thanks for the shoutout [PHONE]! and thanks for recommending this community [PHONE]  Folks, hope you find this project useful and give it a try! if you have any questions or suggestions for improvement, feel free to reach out on WhatsApp or open an issue on our GitHub repo. Happy labeling 🚀
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-30 20:13:11|For some background - Nihit, Rishabh are ex Stanford, Meta, LinkedIn, and On Deck fellows who have raised 5mil+ from General Catalysts recently.
Dr. Pratik Desai KissanGPT|2023-06-30 20:17:48|Good to see you here [PHONE]
Kshitij Agrawal ML Engineer|2023-06-30 20:25:24|Amazing! I know for a fact that some of the largest labelling companies are trying to do this internally.  Will def give this a spin
Bhavya Ranpara Generative AI Wa Group Surat|2023-06-30 20:30:34|[PHONE] - PeakXV's portco - Canary Mail (Dev/Sohel.) is Nihit and mine mutual friend. They've started leveraging GenAI in their email tool. I have tried inviting them here but to no good. If you could pl try? I am sure they'll benefit a lot! 🙃
Edgar Monis Mumbai WHO|2023-06-30 20:32:31|actually pretty cool. may end up using it in a workflow i was thinking about
Edgar Monis Mumbai WHO|2023-06-30 20:32:56|kudos
Rishabh Refuel.ai|2023-06-30 20:35:25|Thanks [PHONE], [PHONE] and [PHONE]! Started Refuel.ai to automate data labeling, cleaning and enrichment using LLMs (likely because we had lost so many hours of our life to it).  Great to join the group  :)
Dr. Pratik Desai KissanGPT|2023-06-30 20:39:47|If anyone from this group planning come to SF Tinkerer meetup on 6th, we can have a small hangout. https://sf.tinkerer.ai/p/ai-tinkerers-sf-july-6th-rsvp-required
Anandamoy RoyChowdhary Sequoia|2023-06-30 20:40:39|For sure let me invite those two
Nihit Desai Refuel.ai|2023-06-30 20:55:27|not entirely surprised they're trying to do this internally :)   on a related note, came across this paper some time back that estimated that human annotators widely use LLMs when asked to label data:  https://arxiv.org/abs/2306.07899
Abhishek Mishra|2023-06-30 20:57:06|How do you expect this task to grow in scale or complexity that it becomes difficult to do it in-house?  With the current level of complexity, I see people trying both GPT as well as FOSS model driven labelling internally.
Kshitij Agrawal ML Engineer|2023-06-30 20:57:15|Yes.. Not just LLMs also vision data is mostly semi automated labelling these days
Pratyush Choudhury|2023-06-30 21:03:42|Does that impact quality in any way?
Nirant|2023-06-30 21:04:02|Yeah, machines have less error, so higher quality
Rishabh Refuel.ai|2023-06-30 21:09:21|Often a good idea to benchmark quality of LLM (or foundation model) labeling on a smaller scale first. One of the hardest parts of scaling human labeling is that you have to continuously train/hire new people, and hard to guarantee quality there.
Shashwat TDC|2023-06-30 21:16:58|On that note, curious to know what's the hard part about LLM labeling here, as we saw many folks are trying to do this in-house.
Neha YC W23|2023-06-30 21:18:56|Scale AI had a paper on this
Apurv Aurva.io Sahil's Friend|2023-06-30 21:20:02|Snorkel is also great at it
Neha YC W23|2023-06-30 21:20:31|Snorkel does weak labelling and ive heard it tough to setup without ui
Neha YC W23|2023-06-30 21:20:43|Or atleast to reach the right functions
Neha YC W23|2023-06-30 21:21:06|On how they did with openai. Can find and share if interested
Rajesh RS Generative AI WhatsApp Group|2023-06-30 21:22:41|Snorkel uses labelling functions. May work for many use cases.
Kshitij Agrawal ML Engineer|2023-06-30 21:22:45|Well the labelers will tell you NO 😊 The point is they would have checks in the funnel. But IMHO <5% error rate is good
Rishabh Refuel.ai|2023-06-30 21:26:07|One of the hard parts with LLM labeling is often getting to high enough accuracy / precision numbers (70-80% isn’t good enough if you want to train downstream models). LLMs will happily produce a label, even if there isn’t enough context to label successfully 😅
Aashay Sachdeva MPL Data Scientist|2023-06-30 21:27:17|You can add a confidence score (had read a tweet - basically add a confidence label in the chatgpt function)
Nirant|2023-06-30 21:28:42|"that influencer tweet got swyx got roasted in replies from goodside — that was quite a garbage ""confidence"" score"
Kshitij Agrawal ML Engineer|2023-06-30 21:29:28|Which is good for weak labelling if you have large scale data. So essentially the 0 to 1 journey is sorted. ‎[6/30/23, 21:35:23] Rishabh Refuel.ai: ‎image omitted
Nirant|2023-06-30 21:36:37|Note for wider audience: OpenAI Chat models e.g. GPT4 and 3.5-Turbo do not give token level logits ‎<This message was edited>
Nihit Desai Refuel.ai|2023-06-30 21:37:47|absolutely!  one thing I'll add here- prompting the LLM directly to output a confidence score has limited signal (it often just hallucinates some score)
Nihit Desai Refuel.ai|2023-06-30 21:38:32|instead in internal experiments, we have observed that token level log probabilities of generated response is higher signal ‎<This message was edited>
Nihit Desai Refuel.ai|2023-06-30 21:41:20|Not all third party LLMs support extracting tokenlevel probabilities though as Nirant mentioned. But if you're using a custom LLM or using an open source model this should be possible to extract
Sohel Canary Mail|2023-06-30 21:46:15|‎You added Sohel Canary Mail
~ Saurabh Arora|2023-06-30 22:19:22|‎~ Saurabh Arora joined using your invite
Gaurav Arora|2023-06-30 23:16:05|Surprised to see such calibrated output. Any thoughts on what ended up hurting calibration in the “post-trained”model?
Abhishek Mishra|2023-06-30 23:16:36|I'm supposing it's RLHF
Abhishek Mishra|2023-06-30 23:18:23|RLHF introduces reward and punishment mechanism post training and forces the outermost layers to conform to a style and output.
Abhishek Mishra|2023-06-30 23:18:49|Disclaimer - I'm yet to read this paper so I could be catastrophically wrong.
Dhruv Naik|2023-06-30 23:19:42|https://www.mosaicml.com/blog/amd-mi250?s=09  https://twitter.com/abhi_venigalla/status/1674795311171276803?t=4fgALuiFUyjGCcIao3_cBQ&s=19  The funniest thing is you still have to use `torch.cuda` on AMD hardware
Rishabh Refuel.ai|2023-06-30 23:31:48|Haha yeah - it seems to be the RLHF (although they don't explicitly say that in the paper). Paper here, btw: https://arxiv.org/pdf/2303.08774.pdf
~ Vrushank Vyas|2023-06-30 23:33:15|Interesting direction: Machine ‘Unlearning’ Challenge: https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html?m=1  More: Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires erasing the influence of that data on other artifacts such as trained machine learning models. Hence, this.
Kaushik S YC W23|2023-06-30 23:51:49|‎Kaushik S YC W23 joined using your invite ‎[7/1/23, 00:06:53] Bhavya Ranpara Generative AI Wa Group Surat: ‎image omitted
~ Ankit Banerjee|2023-07-01 00:11:41|https://twitter.com/KaiyuYang4/status/1673882824158613504  Someone has done it, combined llms with automated theorem provers!
~ Pranshul Chandhok|2023-07-01 00:23:16|‎~ Pranshul Chandhok requested to join
Krishna Panchal|2023-07-01 00:54:05|https://openai.com/blog/insights-from-global-conversations  OpenAI's insights from a world tour of 22 countries.
~ Pranay Desai|2023-07-01 01:37:42|https://twitter.com/abhi_venigalla/status/1674795311171276803?s=48&t=Jn-WvAjI2PySCsGVL-NAkA   Mosaic bringing AMD into the mix
Utkarsh Ohm Thoughtspot|2023-07-01 06:06:06|My team and I are building a text to sql benchmark query set on a real-world complex hairy dataset that we intend to release publicly on the lines of bird, sparc. Any one who has done such an exercise for any task (not just text to sql)?
Utkarsh Ohm Thoughtspot|2023-07-01 06:14:03|We have the dataset and the query set. Trying to learn what massaging and peripherals one needs to do to make it useful for the world
Rishabh Refuel.ai|2023-07-01 06:16:37|Hey [PHONE]! Sounds like a super exciting project. Is the goal to have a public leaderboard for the dataset, or to share the dataset so other people can just play around on their own? ‎[7/1/23, 06:36:44] Dr. Pratik Desai KissanGPT: ‎image omitted
Paras Chopra Wingify|2023-07-01 08:06:00|Has anyone come across research around LLM based state machines where each state is a specialised LLM?
Dr. Pratik Desai KissanGPT|2023-07-01 08:13:59|Do you mean expert model? Like what Geohot was saying about GPT4 architecture?
Saurav Akaike|2023-07-01 08:14:06|Sounds very interesting, would love to understand more on how you are benchmarking? Also- wouldn't the peripherals depend on the data/domain?
Paras Chopra Wingify|2023-07-01 08:42:31|Sort of, a collection of specialised LLMs   The difficult problem is knowing when to jump from one state to another
Dr. Pratik Desai KissanGPT|2023-07-01 08:44:42|I'm not sure if this is what you're exactly looking for, but this MoE paper has an approach that is allegedly used by GPT4. https://arxiv.org/abs/2101.03961
~ Sachin Kalsi|2023-07-01 08:55:18|https://twitter.com/yampeleg/status/1674576951330185218?s=46&t=iNnHcvFLDa-sOIXYIloGew
Ankur Pandey|2023-07-01 09:09:58|"""The thing nobody talks about is that in 10 years we'll have a million bipedal robots and in 25 years we'll have a billion. You’ll buy yours for $10k and it will be as important to your life as your smartphone is now"" - Vinod Khosla   https://twitter.com/vkhosla/status/1674572048339984384?t=RS1KvTDxyHUSqJW1XUs4OA&s=19  A million in 10 yrs!"
Saurabh Karn Nyai|2023-07-01 09:12:19|That number actually seems doable. Wondering what incentives would slow down adoption of such robots. Regulation? What else?
Ankur Pandey|2023-07-01 09:14:47|Will these be personal robots or industrial? - what applications? Who will own it? - incumbents or new ones (like Figure)?
~ Arvind Sankar|2023-07-01 09:15:09|Manufacturing and procurement of raw material may be a bottleneck that may slow things down. But I don't know much of manufacturing to make a 10year assesment
Abhishek Mishra|2023-07-01 09:16:10|This can be somewhat analogous to the mass IoT adoption problem.  Other than the issues with costs of the individual devices and one time secure setup costs - we are constrained with power, memory and compute costs.  These devices will find limited utility and niche adoption. Not enough to boost the sector enough for economy of scale.
Abhishek Mishra|2023-07-01 09:19:40|This interested me. Are you planning to create a HumanEval equivalent of text-to-sql given schema of different ambiguities and complexities?
Dr. Pratik Desai KissanGPT|2023-07-01 09:28:37|Possible, we may already have a million quadrupedal today
Ankur Pandey|2023-07-01 09:29:42|Where are these used?
Dr. Pratik Desai KissanGPT|2023-07-01 09:30:07|What does this have to do with AI?
~ Ravikant|2023-07-01 09:33:26|I am sorry for sending this link here
Dr. Pratik Desai KissanGPT|2023-07-01 09:38:46|Very few real world uses cases, mostly sold to research labs and hobbyists. UNITREE robots are more popular and affordable than Boston Dynamics.
Neha YC W23|2023-07-01 09:42:26|Manufacturing units and warehouses + construction seems to have lot of robots. Not sure of specific types
Ankur Pandey|2023-07-01 09:43:07|Still a million currently sounds like a big number.
Ankur Pandey|2023-07-01 09:44:25|There could be multi millions of robots considering an exhaustive defn - nanobots, etc.  The claim is about humanoid pipedal robots
~ Ravikant|2023-07-01 09:48:11|How was UNITREE able to make the exact same design and also make it affordable?
Ankur Pandey|2023-07-01 09:48:21|The most obvious prospective use of mass humanoids personal use robots which makes business sense is sex robots. Will come with a barrage of regulations.
~ Rohit|2023-07-01 10:33:27|Personal assistant/robots for household assistance would be huge. Sex robots will probably end up being more niche than people assume compared to other use cases.
Ankur Pandey|2023-07-01 10:50:52|What will these assistants do?
~ Ravikant|2023-07-01 10:51:14|Is it possible to build AI models for feature phones ?
Anshul Bhide Replit|2023-07-01 11:01:28|https://www.latent.space/p/ai-engineer  Swyxs take on AI engineering as a profession and why now -  - AI engineers will use models (instead of training them which will be upto ML eng)  - undiscovered capabilities of LLM means someone needs to do this as a full time job  - “ prompt engineering” still requires code scaffolding which
Anshul Bhide Replit|2023-07-01 11:01:58|Karpathys response -  https://twitter.com/karpathy/status/1674873002314563584?s=46&t=VEH2Nt1ylkDIN__Wi_QUPg
~ Rohit|2023-07-01 11:16:42|Any and all household help. Cleaning up around the house, do the dishes, ironing, moving stuff, bringing stuff. Could have dedicated roles as well like a home nurse for old people etc.
Jithin James Ragas|2023-07-01 11:16:55|musks resp to that  “Prompt engineering” is natural language programming  but yeah figuring out what you can do, putting that together and then productionizing it is valuable moving forward, u just get so much output  I wonder who are at the forefront of this right now. Who are some awesome AI engineers you've seen in the wild?
Anshul Bhide Replit|2023-07-01 11:18:34|He might be in this group but EmbedChain is pretty cool https://twitter.com/taranjeetio?s=21&t=VEH2Nt1ylkDIN__Wi_QUPg
Sugnan GenerativeAI Group |2023-07-01 11:22:38|Guys, please note that this is not a self promotion event. It is a community event.
Anshul Bhide Replit|2023-07-01 11:24:13|Tl;dr - there will be less model building (conventionally known as data and ML engineers) and more model using (AI engineers).
Nirant|2023-07-01 11:37:03|cc Taranjeet [PHONE]
Abhishek Mishra|2023-07-01 11:38:40|I've a different take. Training your model was never as cheap as it is now. We've been successful in bringing down the training compute costs by 1000-10000x. You can now train your own stable diffusion flavours on free tier colabs/Kaggle books. You also have emerging inference at the edge and fine tuning at the edge. It takes 20c to fine tune a BERT, $8 to train it from scratch. 90% of problems I used to solve until last year with tons of compromises can now be solved in <$10 or free compute.
Abhishek Mishra|2023-07-01 11:40:02|I don't think emergence of prompt engineering will impede training or fine tuning ML models. I think both of these areas are going to grow and the prompt engineering bit will expand into a LLMOps mushroom ground.
Shashwat TDC|2023-07-01 11:42:34|"Chiming in. This was also my argument when, earlier,  we were discussing about wrapper LLM apps having inherent moat. At an unit level most people seem to be able to interact with llm and build wrappers of sorts but ""programming"" of that itself will be complex. Can lead to inherent technical moat.   Wrapper-wrapper interaction, model-wrapper interaction, model-model interaction.  If the original argument of genAI boosting productivity and creativity is true, most of _LLM apps_ who will survive the test of times will transform into creative workflows that might be unimaginable now."
Taranjeet Singh Cookup.ai|2023-07-01 11:48:03|Thanks. Bunch of exciting things next week as well.
Sugnan GenerativeAI Group |2023-07-01 11:48:38|"*Event Announcements from https://nirantk.com/community*   Title: ""How to build great OS projects & Dev tools from AI in India"" Hosts: Anshuman Pandey, Founder, and others from Nimblebox.ai When? 2 PM to 7 PM, 8th July, 2023 Where? Bira Taproom, Koramangala, Bengaluru How?: https://lu.ma/blr  - Sugnan, on behalf of the Generative AI Community"
~ Vatsal Sanghvi|2023-07-01 11:51:01|‎~ Vatsal Sanghvi requested to join
~ Vatsal Sanghvi|2023-07-01 11:51:13|‎~ Vatsal Sanghvi joined using this group's invite link
Nirant|2023-07-01 11:53:11|Since I get about 4 pings on this per week, as a trial:  1. Once a day compilation of all events posted to https://nirantk.com/community and  2. Once a week compilation (weekend) of all new jobs to https://nirantk.com/community as well  cc [PHONE] [PHONE] [PHONE]
~ Clament John|2023-07-01 12:15:50|Every phone should have a GPU. I think that is where the industry is moving towards.
Nirant|2023-07-01 12:17:16|Every smartphone *today* has more compute and RAM than what the Apollo mission used to send mankind to moon and back
Nirant|2023-07-01 12:18:07|Server compute wins because humans are amazing at finding ways to make money off cheaper compute they control, one can't make money off something run ML on phone GPU — only Apple can
~ Clament John|2023-07-01 12:18:30|"Quick question:  For the model *multi-qa-MiniLM-L6-cos-v1* what does the ""cos"" mean? cosine? But why would a distance function be need here? Or is it something else? https://huggingface.co/Xenova/multi-qa-MiniLM-L6-cos-v1  This one is the base model but doesn't mention ""cos"" - https://huggingface.co/Xenova/all-MiniLM-L6-v2"
Nitin Mahajan McKinsey|2023-07-01 12:18:36|Fully agree. If I was apple I will be thinking how to build a hardware moat out there and optimise for AI bots experience.   M2 chipset, GPU and incentivising upgrade cycles
~ Anjineyulu|2023-07-01 12:18:38|Can we tell every algorithm can run on cpu with small models,is that not how industry may move?
Nitin Mahajan McKinsey|2023-07-01 12:19:11|Enterprise vs consumer expectations. Consumer with 100s of apps will benefit from mix of local and server compute
~ Clament John|2023-07-01 12:19:39|I'm very bullish on apple hardware. I used to be a long time linux user, but started using a mac recently and I'm amazed with the apple doc for its hardware.
Nirant|2023-07-01 12:19:44|I might be wrong here, but the convention is to mention 'cos' because they've optimised the embedding to work well with cosine similarity
Nirant|2023-07-01 12:20:49|Consumer expectations — monetised via ads running on server farms the size of some European countries
Aashay Sachdeva MPL Data Scientist|2023-07-01 12:21:05|Still can’t run slack
Nitin Mahajan McKinsey|2023-07-01 12:21:21|Haha Vision pro ads by then 🤪
Abhinav Verma Longshot.ai|2023-07-01 12:22:09|Yes something like that, they gave different naming conventions for embeddings trained in dot product, normalized and non normalized embeddings
Abhinav Verma Longshot.ai|2023-07-01 12:22:40|Slack and chrome are different species
Nirant|2023-07-01 12:22:53|Which is exactly my point — app devs get lazier, and consumers expect more. We all crib about Slack and Teams — but no one is using email groups at their workplace which'd require you to think for more than 20s at a time
Abhishek Mishra|2023-07-01 12:25:10|CoreML ftw
~ Clament John|2023-07-01 12:27:27|Apple hardware has some good APIs (so am told) for a local application. Maybe not an LLM, but everything else - create embeddings, vector search, langchain like.  Look at this upcoming work where the dev has built everything in Swift. Only using OpenAI for embeddings and generative work https://twitter.com/vatsal_manot/status/1674317412836184064
Abhishek Mishra|2023-07-01 12:29:49|I can see some of the mixed image/video editing moving to edge compute.
~ Jaswanth|2023-07-01 12:29:55|‎Pratyush Choudhury added ~ Jaswanth
Abhishek Mishra|2023-07-01 12:32:48|This is also because of emergence of cluttered frameworks and no punishment for RAM hogging. We want shinier, animating, 3D things and not enough function.
Abhishek Mishra|2023-07-01 12:38:04|There's one of my personal bear scenario for Nvidia.   If we get a pytorch framework to utilise Apple metal with similar efficiency as CUDA on nvidia GPUs, a lot of speculative valuation is just going to collapse.  But building an alternative to CUDA for Apple metal is a difficult task and very few people are focusing on it. Modular Mojo claims they can free us from platform dependency but it's a very difficult task.
~ Clament John|2023-07-01 12:41:34|Yes, we need a lot more knowledge in the apple silicon space. Geohot started with M1 NPU right? I think tinygrad has shifted focus to something else
~ Clament John|2023-07-01 12:42:16|But I think there is slow progress in bringing things native to apple silicon. Have seen a few tweets this week.
Kshitij Agrawal ML Engineer|2023-07-01 12:42:42|That’s the part i agree with 😊 Have seen this trend play out in the last few years
Abhishek Mishra|2023-07-01 12:45:46|Pedro Cuenca works on a exporters and coremltools library to export any HF transformer model to CoreML.  Exporter library - https://github.com/huggingface/exporters  Coremltools - https://coremltools.readme.io/docs  Their aim is to make all HF transformer supported models and weights reusable with CoreML. ‎<This message was edited>
Kshitij Agrawal ML Engineer|2023-07-01 12:45:56|Kinda agree with the article , perhaps not with the nomenclature. Anyways job titles in the industry are broken and every company has their own take. For ex ML engineer in some orgs does data engineering, somewhere training and model dev.
Abhishek Mishra|2023-07-01 12:47:43|They already support many models and architectures. It's better to check native metal support for older models or educational stuff than run something torch.device('cpu') on metal.
Abhinav Verma Longshot.ai|2023-07-01 12:56:20|Chrome is just like algae allowed to grow unchecked on the RAM. needs to be purged every now and then
Abhinav Verma Longshot.ai|2023-07-01 12:58:21|Anyone worked on whisper recently. For some reason my logic for writing the the segments to a vtt file is failing from a few months back. Seems they've changed the logic. So any repo doing it recently would help.
Ishavasyam Antler|2023-07-01 13:02:50|A week ago Mistral created buzz for raising 105M on the back of a rare team coming together to create an OpenAI competitor from Europe. I just got the chance to read the memo, and it seems that while they say they will take a more open approach to model development, their actual strategy seems to be do everything?  1) create open source models and developer ecosystem around it 2) create (both generalist and specialized) closed source ones for paid access by companies, closed models also available through APIs 3) create (closed) specialised models by retraining on data for legal, finance etc and make this available to clients on-demand 4) co-build integrated solutions with large clients (like Stability), co-build GenAI products with small partners 5) create own consumer facing interfaces like ChatGPT 6) create LLMs but also smaller models that can be deployed on edge/ devices + make models with retrieval-augmentation  My first thought/question on reading the memo --*what they seem to be saying is that they will do everything (and see what sticks) and the open source angle may be a bit of counter-positioning/lip service narrative*.  Second -- *the behemoth LLM players of the future, by design, will need to play multi-product, multi-channel, multi-business model game to justify and recover investments (and hedge bets* at this time when the sector nascent and the winning recipe is debatable).  Thoughts?
~ Happy Chaudhury|2023-07-01 13:03:49|Anyone tried running privateGPT locally for QA , i have tried it in my CPU as well in colab gpy it's taking more than 40+mins for single prompt, i have used context from single document with 2 page pdf. How we can reduce this inference time ??
Nirant|2023-07-01 13:04:33|You might want to start by not using privateGPT, it was mostly marketing to begin with
~ Happy Chaudhury|2023-07-01 13:05:28|I see ,any other options i means some private documents
Nirant|2023-07-01 13:08:24|Broad Guidelines for private documents:   1. Use instruct or chat models when you can, instead of the base e.g. Falcon-7B Instruct 2. Use the fastest embedding possible - Mini-LM-v2 can go a long way 3. Keep your chunks as small as possible, you're working with 1/20th the tokens/second of GPT3.5-Turbo in most cases ‎<This message was edited>
Dev Aggarwal|2023-07-01 13:10:26|3.1 Spend time figuring out how to to split text right :)
~ Happy Chaudhury|2023-07-01 13:10:27|I shall try this thank you 🙏🏻
~ Happy Chaudhury|2023-07-01 13:12:04|Actually I could do some experiments on data i have, usually for the information i look for out of 10, 7 are  either in first 500 words or else last 20/ words, so I am just getting that chunks for now
Dr. Pratik Desai KissanGPT|2023-07-01 13:12:06|This is a nice repo that uses llama.cpp and whisper.cpp to have a conversational LLM hosted on PC, where you can use mostly any supposed models. https://github.com/yacineMTB/talk
~ Happy Chaudhury|2023-07-01 13:14:02|Seems this one needs GPU
~ Happy Chaudhury|2023-07-01 13:14:57|I can try with colab hopefully
Amir Nagri|2023-07-01 13:21:21|[PHONE]  penalty to not participate might decrease the signal to noise ratio of this group, thoughts?
Aditya Sista 2010B5|2023-07-01 13:22:08|3 especially if you're using langchain or any prompting libraries. Those things keep adding up to the tokens unchecked in the name of enhancing prompts 🙈
Abhishek Mishra|2023-07-01 13:38:35|I can't list everything here but there's a whole menagerie of options that solve this problem. The easiest app to try in a few minutes worth of testing is gpt4all GUI. For practical purposes, it's easy to setup, fast to load and relatively up-to-date. privateGPT code is just a single script and extremely easy to read through but you may not want to use langchain dependencies that slow everything down a lot. Many options are there but it's so edge case that you'll have to get your feet wet and decide where you want to take a dip.
~ Happy Chaudhury|2023-07-01 13:44:51|privateGPT i think uses gpt4all   ,i think i need to check gpt4all and falcon 7b both
Abhishek Mishra|2023-07-01 13:49:25|gpt4all GUI added Falcon 7b GGML support last week itself. You may want to check if it suits you. ‎<This message was edited>
Krishna Panchal|2023-07-01 14:25:14|https://open.substack.com/pub/luttig/p/hallucinations-in-ai?utm_campaign=post&utm_medium=web  In the tech-pocalypse desert of 2023, only the AI oasis can save us. ‎<This message was edited>
Divyam Goel|2023-07-01 14:49:23|Very noob question - a bunch of us are planning an open source model deployment and fine tuning hands-on workshop. For this we are looking for some GPU access. Any company we can tie up with for access & credits around same ?
Abhishek Mishra|2023-07-01 14:51:28|[PHONE] may be able to help?
Divyam Goel|2023-07-01 15:01:40|Thx for pointing out. Will DM and connect once.
Nirant|2023-07-01 15:02:15|cc  Microsoft Azure's Ankita: [PHONE] AWS' Shubham: [PHONE] Zainab [PHONE] from Hasgeek can make introductions to E2E Networks (NSE:E2E)  You will want a crisper pitch/positioning for why would someone want to sponsor credits for a workshop specifically
Divyam Goel|2023-07-01 15:04:23|Thx for the pointers. Will follow on these.
~ Apurva Bhatt|2023-07-01 15:23:18|https://arxiv.org/abs/2306.02858
~ Apurva Bhatt|2023-07-01 15:25:30|Video-to-text model that better captures Visual and Audio components.
Sudharshan GenAI|2023-07-01 15:30:50|Nice
Sudharshan GenAI|2023-07-01 15:30:51|Demo available?
~ Apurva Bhatt|2023-07-01 15:31:19|https://github.com/DAMO-NLP-SG/Video-LLaMA
ashish Acgt01 Twitter|2023-07-01 16:29:13|https://openai.com/blog/insights-from-global-conversations
~ Pranshul Chandhok|2023-07-01 20:54:28|‎~ Pranshul Chandhok requested to join
Nirant|2023-07-01 22:46:47|This is such a word salad, I believe GPT3.5 was used instead of GPT4 😆
Shobhankita Speciale Invest|2023-07-01 22:48:52|‎Shobhankita Speciale Invest joined using this group's invite link ‎[7/1/23, 23:28:48] Dev Aggarwal: ‎image omitted ‎[7/1/23, 23:28:49] Dev Aggarwal: ‎image omitted ‎[7/1/23, 23:28:52] Dev Aggarwal: ‎image omitted ‎[7/1/23, 23:28:53] Dev Aggarwal: ‎image omitted ‎[7/1/23, 23:28:54] Dev Aggarwal: ‎image omitted ‎[7/1/23, 23:28:55] Dev Aggarwal: ‎image omitted
Dev Aggarwal|2023-07-01 23:28:59|Playing with qr codes and controlnet - very fun!
Adithya S K PESIT|2023-07-01 23:33:25|they look good hey wanted to know if there is a way to automate this process of generating QR code art is there anyway to like export the configuration we used automatic 1111 in control net to code so that it can be automated
Lucifer 😎|2023-07-01 23:36:40|I had done the same thing, and posted on the company's channel.   It's crazy and fun ‎[7/1/23, 23:36:41] Lucifer 😎: ‎image omitted
Dev Aggarwal|2023-07-01 23:37:19|A1111 or diffusers?
~ Aravinth Kumar|2023-07-02 00:24:00|A curious question folks:  What are some use cases for beautified QR codes? I understand the aesthetic improvements but doesn’t this result in loss of recognisability by wider audience as QR?  I’m missing context here as I see people celebrating this in multiple forums. Hence curious to understand the reasons. ‎[7/2/23, 00:34:59] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-07-02 00:35:07|https://huggingface.co/openchat/openchat
Abhishek Mishra|2023-07-02 00:36:20|Though, I'm skeptical on this.  Need to try it out.
~ Sudhanshu Heda|2023-07-02 01:04:35|Tried this. Somehow the QR is not read on certain device cameras.
Nirant|2023-07-02 01:28:15|Fun question: what's ChatGPT?   I assume most people know that it's not a fixed model but an evolving checkpoint and sampling mechanism.
Abhishek Mishra|2023-07-02 01:29:28|True. chatGPT is no real reference, all you've is the latest model and no reference of the older versions.
Neha YC W23|2023-07-02 02:10:20|Noob question, and maybe asked a 1000 times- openai wrappers have no moat, but perhaps a chance to validate the business use case and then build the tech. Then do we expect everyone to fine tune these big models eventually to get an edge over the competition?
Neha YC W23|2023-07-02 02:11:11|That said, I am yet to come across tools to facilitate fine tuning.
Neha YC W23|2023-07-02 02:11:26|Can anyone help me get some clarity on this? And thoughts.
~ Prajna Prayas|2023-07-02 02:12:03|Eventually these wrappers will be inducted into big players who has the distribution.
Neha YC W23|2023-07-02 02:12:48|Big players - such as?
~ Prajna Prayas|2023-07-02 02:13:13|I was exploring one DataBricks blogpost where they have mentioned step by step using huggingface on how to finetune a BERT base model. I ran the notebook untill I ran out of Google Collab RAM😅
Neha YC W23|2023-07-02 02:14:15|for finetuning llms, wizardLM is SoTA currently, but didn't really find anything that gave me those capabilities out of the box
~ Prajna Prayas|2023-07-02 02:14:45|Adobe buying StableD or MidJourney to augment their tools that is being used by millions
~ Prajna Prayas|2023-07-02 02:15:38|It's glue-tech mostly.
Neha YC W23|2023-07-02 02:16:22|Got it. Thanks for your thoughts [PHONE] 👀
ashish Acgt01 Twitter|2023-07-02 06:53:44|Imagine how good your RLHF would get, getting user feedback (thumbs up , thumbs down, descriptive feedback)  from millions of users
Bharat Kumar Ramesh Hashmal Web3|2023-07-02 07:32:21|You're right. But you can build your moat around service quality, UX, security, etc.  And even if it isn't a moat, it can be a sizeable dhandha  This question was asked of SaaS, of mobile apps, as well. Typically a venture question, who require outlier outcomes.  Most businesses don't need that. You can build a respectable 10M ARR business just as a wrapper, with nice bells and whistles, as long as it's solving a key need
~ Srinivasan Nandakumar|2023-07-02 07:40:38|In the geohot podcast they mention 16 inferences. I went through  this paper but still couldn't connect the 16 inferences part. Any insights on how that is done?
Nirant|2023-07-02 09:26:25|100,000 pip installs in a day for LangchainAI!   For reference: The official openai library did 300,000 installs on that day
ashish Acgt01 Twitter|2023-07-02 09:38:15|It's like it is like 2005 and no one is able to appreciate the power of the iPhone or app stores and apps
Anshul Bhide Replit|2023-07-02 09:44:02|is this where you'd getting the data? https://pepy.tech/
Nirant|2023-07-02 09:46:45|Pypi stats, but this'd work too
Abhishek Mishra|2023-07-02 09:59:59|"In scope of your question, a MoE approach has 4 major units - Routing, Inference, Gating, Mixing. Your question seems to be just about mixing the results or need for multiple inferences so I'll keep it succinct.  Routing - choose right expert for task, decide that by affinity score of each expert with task  Inference - Get result for the task from each expert, sometimes a task may contain multiple subtasks which suit multiple experts  Gating - Assigning weight to each inference from expert, identifying which expert opinion weighs more and can be decided by affinity score and Quality of output from expert  Mixing - based on the assigned weights by gating function, combine all inferences in one final output. This again, can be done in multiple ways.  If we assume this leak about GPT4 architecture is true, we can assume there are 16 ""experts"" and thus 16 inferences. There's a master model with the biggest parameter size and GPT3 like experts that provide inference results which are then combined together to produce the final answer.  I am not saying that's how GPT4 truly is, but how it would be if the leak has any merit."
Nirant|2023-07-02 10:01:10|God bless you for typing this out 🙏🏽
~ Srinivasan Nandakumar|2023-07-02 10:03:02|Thanks for the detailed explanation!
Lalit Pagaria|2023-07-02 10:31:55|Pepy also adds cross zone data sync up so in order to get correct data use this https://pypistats.org/
ashish Acgt01 Twitter|2023-07-02 11:46:11|Interesting paper on the future of sw engineering education/tutoring https://arxiv.org/abs/2306.17156  https://twitter.com/josepablocam/status/1674862205626376194
~ Heerthi Raja H - AI/ML|2023-07-02 12:56:43|‎Ravi Theja added ~ Heerthi Raja H - AI/ML
Anshul Bhide Replit|2023-07-02 13:27:58|🌶️ take on vector search being overhyped and not always the best option for LLM apps.   tl;dr - Colin makes the case that for both limited context window and diverse query forms, traditional search using keyword retrieval can work just as well as vector search. His point is that vector search has been overhyped by VCs and startups looking to cash into the AI hype 🤷🏽‍♂️
Anshul Bhide Replit|2023-07-02 13:27:59|https://colinharman.substack.com/p/beware-tunnel-vision-in-ai-retrieval?utm_campaign=post&utm_medium=web
Krishna Panchal|2023-07-02 13:29:55|"Document splitting is common for vector storage / retrieval, but useful context can be lost. LangChainAI has 3 new ""context-aware"" text splitters that keep metadata about where each split came from. Works for code (py, js)  https://twitter.com/RLanceMartin/status/1674817117475188737?t=rzekLS3lUedtxwqEUgkdKw&s=19"
Nirant|2023-07-02 13:31:33|Anyone who says keyword retrieval alone, or vector search alone is as good as both together — is not to be taken seriously. This is not even news. We know since 2018 when GloVe/word2vec were a thing, and BERT vectors were used
Nirant|2023-07-02 13:32:36|On the plus side, I always popularise ideas like these — it feeds into FUD, and whether I like it or not, I make a lot of professional premium by removing doubt and absorbing ambiguity/uncertainty.
Nirant|2023-07-02 13:34:32|Even BM25 (what Elastic uses) is better than keyword search, and that is known since 1990s
Nirant|2023-07-02 13:37:54|Also, AWS made a Blockchain Platform to transfer VC dollars to their account during crypto bull run, despite knowing it was worthless and scam — if VCs and Founders are idiots, that is the ~rational~ profitable way to think about bull runs! ‎<This message was edited>
Chirag Jain|2023-07-02 13:38:40|"it's like the Jesus meme - ""I am not messiah"",  it's going to be a reality check for lot of people realising the importance part of retrieval qa is not the llm but rather the dirty retrieval parsing, splitting and ranking bits"
Nirant|2023-07-02 13:39:28|No one is going to realise this, because people are not aiming for a usable QA system — they're aiming for a demo-able QA system, and that's a different bar completely.
Nirant|2023-07-02 13:41:06|Not naming names, but know a desi startup who've raised quite a few $$$M on the back of Colab Notebook wrapped in Vercel
Nirant|2023-07-02 13:43:54|/endrant
~ Vinay|2023-07-02 13:52:11|"can someone recommend specific literature to go deeper on this for noobs -> ""dirty retrieval parsing, splitting and ranking bits""  thanks!"
Lalit Pagaria|2023-07-02 13:52:30|https://twitter.com/huggingface/status/1675242955962032129?t=v3AyvKLw9e4gZQlhyVz5kw&s=08  HuggingFace security is a joke. Two times I reported someone uploaded many pirated movie links. Along with the chance of uploading a bad model.
Lalit Pagaria|2023-07-02 13:54:10|https://twitter.com/EMostaque/status/1675236885197729792?t=9hg8cpf2EgNaZLFwHjUMjg&s=08  Also it is good practice to cache/copy models inhouse instead of pulling always.
Chirag Jain|2023-07-02 13:54:18|doesn't seem like their fault here? if people are reusing same passwords  except yes they should make 2FA compulsory
Lalit Pagaria|2023-07-02 13:55:56|So many people are dependent on them even enterprises. They should have added 2FA long back. It is very easy to enforce and does not require much infra investment.
Chirag Jain|2023-07-02 13:57:26|it's more of an experience thing building/improving any search system in production  but for absolute basics you can start with Intro to Information Retrieval by C. Manning et al
Nirant|2023-07-02 13:58:08|Manning book is a bit more classical, less applied/engineering first ‎<This message was edited>
Chirag Jain|2023-07-02 13:58:11|yeah revision pinning and local bucket caching is becoming very important
Aditya Sista 2010B5|2023-07-02 14:29:38|This was popularised by hinton in his 2012 deep learning course. Originally it was like a weighted ensemble of multiple outputs, the weight vector here is generated by another neural net with same input. This whole thing is differentiable end to end, so each expert gets better as well as the weight generator gets better at assigning the expert to an input
Amir Nagri|2023-07-02 14:30:47|AI powered search by Manning (still in EAP,  but main topics ready to read) is a very well balanced book on classic search and the new semantic search  The book was commissioned preChatGPT time (ie Nov 22), so when i read the EAP didn't cover those APIs, might cover in the final version  Also highly recommended (if your company reimburses) Corise has a online cohort based course on search by Grant, exCTO of Wikimedia/Wikipedia, that covers the search optimization, including vector search, in a very practical, analytical, and non hyped way
Amir Nagri|2023-07-02 14:32:23|+ AI powered search book is by veterans of search/experts of elastic and solr, so they know their thing
Paras Chopra Wingify|2023-07-02 14:38:07|https://www.sbert.net/examples/applications/retrieve_rerank/README.html
Dhruv Anand|2023-07-02 15:55:09|+1. On top of that, these QR codes mostly don't work (with apps like Google lens)
Dev Aggarwal|2023-07-02 15:55:38|Seem to work fine on paytm / phonepe
~ Shaurya|2023-07-02 16:37:44|‎Shivendu Kumar added ~ Shaurya ‎[7/2/23, 18:53:29] Abhinav Verma Longshot.ai: ‎image omitted
Abhishek Mishra|2023-07-02 18:54:48|That's the best tweet on rate limit I've seen so far 🤣
Rajesh RS Generative AI WhatsApp Group|2023-07-02 19:04:04|😂 Bojan generally has something funny  to say on whatever’s current.
~ Tirtha|2023-07-02 19:04:34|Almost all his tweets go like XGBoost…..
Rajesh RS Generative AI WhatsApp Group|2023-07-02 19:05:05|Haha yes. ‎[7/2/23, 20:20:43] Vamshi: ‎image omitted
Vamshi|2023-07-02 20:21:10|Is that made up or a real tweet
Vamshi|2023-07-02 20:21:20|Either way it was good for kicks
Shashwat TDC|2023-07-02 20:32:18|Hello post LLM world.
Shivendu Kumar|2023-07-02 20:36:05|Friends, please avoid off-topic conversations.  And if someone does so, others should try to react with emojis only. This puts a limit on the number of unread/off-topic messages.
~ Nitin Kishore|2023-07-02 20:44:11|So we are rate limiting the off-topic conversations? 😅 ‎[7/2/23, 20:46:06] Abhishek Mishra: ‎video omitted
Gokul Krishnan|2023-07-02 20:54:26|And as is tradition, we'll eventually rate limit messages asking to rate limit off topic discussions 😜
Rajesh RS Generative AI WhatsApp Group|2023-07-02 20:57:22|Expecting an infinite regress rate limiting discussion going back all the way to the big bang
Dev Aggarwal|2023-07-02 21:55:27|"PSA: openai.Embedding.create() will sometimes return NaN -   { ""data"": [ { ""embedding"": [ NaN ], ""index"": 0, ""object"": ""embedding"" } ], ""model"": ""text-embedding-ada-002"", ""object"": ""list"", ""usage"": { ""prompt_tokens"": 5, ""total_tokens"": 5 } }  https://community.openai.com/t/text-embedding-ada-002-embeddings-sometime-return-nan/279664"
Vamshi|2023-07-02 22:56:18|Many apologies, seemed a natural segway but I can see how this can be a runaway digression to nowhere ✌️
Lucifer 😎|2023-07-02 23:33:02|Did anyone try openchat ?
Abhishek Mishra|2023-07-02 23:36:42|Yeah, and it is not what it claims to be unfortunately.
Abhishek Mishra|2023-07-02 23:37:28|It's a good effort of achieving good performance with just 6k dataset but got ruined by false claims of surpassing GPT 3.5 performance.
Lucifer 😎|2023-07-02 23:38:12|This is based on llama ?
Lucifer 😎|2023-07-02 23:38:33|How is the performance scores compared to Gpt 3.5 and MPT-chat by MosaicML ?
Abhishek Mishra|2023-07-02 23:38:34|Yeah llama trained with 6k curated dataset - drawing from the learnings of LIMA paper
~ Ziyan Zafar|2023-07-02 23:38:53|‎~ Ziyan Zafar left
Lucifer 😎|2023-07-02 23:39:08|I see.  I read about this in the morning. Maybe will try tomorrow on my use cases.
Abhishek Mishra|2023-07-02 23:40:50|They took Vicuna and Alpacaeval and published results from there showing that it surpasses chatGPT in performance
Abhishek Mishra|2023-07-02 23:41:28|"Most people don't understand how many evals are there and what do they actually test. Vicuna eval is mostly - ""Style not substance"""
Lucifer 😎|2023-07-02 23:42:26|OpenAI released their own evalcode. Mosaic their own. Every research releases their own eval system and claim that their architecture outperforms others 😌🌚
Abhishek Mishra|2023-07-02 23:42:35|Sole fine tuning with GPT4 results in close style transfer and it ranks higher on vicuna. MMLU is a good eval where it scores very low against GPT 3.5 ‎<This message was edited>
Lucifer 😎|2023-07-02 23:42:41|Vicuna had less scores on the HF LB, the other day
Lucifer 😎|2023-07-02 23:43:03|MMLU Newer term for me. Will look into this. Thanks
Abhishek Mishra|2023-07-02 23:45:03|This is the best we have so far - https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard  It tests a model across multiple disciplines and tasks.
Abhishek Mishra|2023-07-02 23:45:31|MMLU is also part of the benchmarks they use.
Lucifer 😎|2023-07-02 23:46:45|Yes yes. This is the LB. My company is keeping track of it daily xd
Abhishek Mishra|2023-07-02 23:46:54|Though, it has weird bugs like - Changing the MCQ option style from A. To A) showed a 4-6 point average boost in the score. ‎<This message was edited>
Lucifer 😎|2023-07-02 23:46:55|I see. Multi language understanding
Kaushik Bokka|2023-07-02 23:59:53|https://www.nfx.com/post/speed-and-ai
Sachin Legaltech|2023-07-03 01:39:19|Excellent panel discussion between Jonathan Frankle from Mosaic, Amjad and Michele from Replit about training LLMs.  15:00 - They discuss usefulness of evaluation benchmarks for models particularly wrt long contexts and coding. 21:00 - UL2 - which is mixture of different cost functions didn’t work that well with their experiments. 33:00 - Comparison of Open source models with chatGPT, where open source models are lagging and call to do weird things. 42:00 - “Open source datasets are complete trash”. The PILE, The stack are good; but kinda old. The Pile wikipedia and RedPajama wikipedia are different. Stack javascript is mostly minified javascript. With H100, we might see changes in shape of architecture. Will see wider networks with maybe less depth. 57:50 “Neural networks pruning is useless.” It works well on CPUs. Might work well with H100. https://www.youtube.com/watch?v=B-szEQsQ9yI&list=PLto9KpJAqHMT8JWmfh9L6kbr6x1mvXNs6&index=1&pp=iAQB
Abhishek Mishra|2023-07-03 02:28:14|Knew some stuff and learnt a few things that I never heard about earlier👍 * Flan UL2 is underwhelming, everyone who tests it seems to agree with that except Yi Tay. I even checked with Fabrice Bellard as he maintains his own textsynth library but results are same. * Open source datasets are trash? It's the first time I heard that Redpajama dataset quality is bad. I've contributed in building the dataset when LAION first started. I guess there will be some rebuilding of Wikipedia section at least. * H100's architecture being a deciding factor in how we see the model shapes changing is again an indicator of how deep learning practices and GPU arch move in tandem and are influenced by each other. * That GGML bit has a lot of potential but I'm yet to find any time to learn how to write up a GGML for a new architecture from scratch. Just running somebody else's quantization scripts to quantize somebody else's models for the time being.
Sachin Legaltech|2023-07-03 09:45:20|https://twitter.com/blancheminerva/status/1652899628356960256?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ Stella bidderman - second author of PILE paper discussing per token quality of PILE vs RP. I think some amount of quality degradation is obvious as RP is much bigger than PILE (6 times) . In which area, did you contribute in building RP ? ‎[7/3/23, 10:01:05] Nirant: ‎image omitted
Kaushik Bokka|2023-07-03 10:14:27|Number of Issues created and PRs gettting merged is a good metric as well.  The issue with downloads is even if very few popular projects use any of the above frameworks. It creates a bias
~ Prajna Prayas|2023-07-03 10:22:00|Qdrant needs to up their marketing spending it seems.
Sandeep Srinivasa RedCarpetup|2023-07-03 10:30:01|folks, if I am building RAG (vector search/sematic search) internally at my workplace using a vector db + LLM, is there a benchmark data set i can use to evaluate my implementation ?  i know that my own data will perform uniquely, but i want to atleast get to a good baseline before going deep into my own data.
Nirant|2023-07-03 10:43:48|cc [PHONE] Jithin from Ragas would you know of something? ‎[7/3/23, 10:52:03] ~ Ashish: ‎image omitted
Nirant|2023-07-03 10:52:46|Would you link to add a link to source?
~ Ashish|2023-07-03 10:53:30|Similar Collection by HuggingFace :  https://huggingface.co/docs/hub/models-libraries
~ Ashish|2023-07-03 10:54:17|I am facing message delay in whatsapp
Nihit Desai Refuel.ai|2023-07-03 10:54:34|I'd recommend benchmarking the retrieval and generation steps separately to better understand the performance of each component.   BEIR is a good benchmark for retrieval - https://github.com/beir-cellar/beir. it contains multiple datasets, you can choose ones that are related to your domain (I've seen MSMARCO is the most widely used)
Shahul Kaggle Kernel GM|2023-07-03 10:59:57|Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case. If you’re interested in evaluating the pipeline (retriever + generation) checkout Ragas https://github.com/explodinggradients/ragas
Shahul Kaggle Kernel GM|2023-07-03 11:02:17|Also this article here covers the metrics used for evaluating retrievers https://amitness.com/2020/08/information-retrieval-evaluation/
Amitness C|2023-07-03 11:03:52|‎You added Amitness C
Nirant|2023-07-03 11:04:59|Amit [PHONE] we were talking about a blog from your blogging era: https://amitness.com/2020/08/information-retrieval-evaluation/  Thought you'd love to know that we still recall and refer them fondly
Sandeep Srinivasa RedCarpetup|2023-07-03 11:07:40|hi. looking at the dataset for eval for now.  also - we dont build on to of python (deployed in banks, etc), so a hosted service for logging is the only thing we can use. but ragas looks good !
Sandeep Srinivasa RedCarpetup|2023-07-03 11:08:24|> Beir is good if you want to benchmark only the retriever. Checkout datasets like MSMARCO or find ones that relate to your use case.  what about TREC-20, etc ? i was reading the HYDE paper and seems that they did benchmarking on TREC ‎[7/3/23, 11:09:56] Dr. Pratik Desai KissanGPT: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-03 11:23:35|BEIR seems to be the framework for benchmarking. there is a bunch of different datasets used by beir. any idea which one u would recommend for benchmarking if ur building a RAG ?  https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/
Jithin James Ragas|2023-07-03 11:31:27|internally for Ragas we started off with wikiqa and hotpotQA but the catch with any Wikipedia dataset is that the models already know quite a bit. So u'll have to run a baseline without retrieval, with retrieval and with ur improvements to get an idea  FIQA is financial data, there is one for medical too, I'd recommend those ‎[7/3/23, 11:31:46] Nirant: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-03 11:34:18|hey that is very useful feedback. did it work better with FIQA for you - im wondering how fiqa benchmark executes ? do u first have to load a retrieval dataset and then ask questions on it ?
Lucifer 😎|2023-07-03 11:36:05|This benchmarking was also discussed during the GenAI meetup which happened in BLR 2 weeks back.
Sandeep Srinivasa RedCarpetup|2023-07-03 11:36:45|we are in delhi
Lucifer 😎|2023-07-03 11:37:59|🥲
Pratiksha Dake Unacademy|2023-07-03 11:38:41|is there any list of startups in generative ai valuechain? from infra to api to customer facing ones
Nirant|2023-07-03 11:39:04|"Emad Mostaque makes me happy whenever he goes viral: ""there won't be any programmers"" in 5 years https://twitter.com/EMostaque/status/1675556121271054339  At last, we'll have software engineers doing engineering instead of programming!"
Jithin James Ragas|2023-07-03 11:40:37|FiQA didn't have retrieved docs, so we used the answers (they have multiple answers for the same question) as the document.   FiQA was collected from stackoveflow for finance
Rajesh RS Generative AI WhatsApp Group|2023-07-03 11:42:21|Watching the exact same video right now - his discussion with Peter Diamandis. Diamandis was involved in public space flight when that was a pipe dream - and he finds Mostaque and Stability among the most interesting companies at the moment. There's another discussion on the philosophy group about this, in the context of code gen tools.
Abhishek Mishra|2023-07-03 11:49:02|We stopped having personal portraits drawn to capture our image with the invention of camera. Painters went away and photographers came in. Then came photography on personal devices and professional photography maintained an edge by having costlier and advanced equipments. Now we can take a shot of the moon and still some humans maintain an edge by learning how to use different editing/effects creatively to compose a better photo or videographic experience.  Technology often lowers entry floor and humans move to higher levels of abstraction.
ashish Acgt01 Twitter|2023-07-03 12:41:14|My fav bit on how ai will impact programming is this talk and piece by Matt Welsh
ashish Acgt01 Twitter|2023-07-03 12:41:26|"Fantastic talk on how ai will impact programming as we know it : https://www.youtube.com/watch?v=qmJ4xLC1ObU  tldr video: https://vimeo.com/775827887  Matt Welsh ([EMAIL]) is the CEO and co-founder of Fixie.ai, a recently founded startup developing AI capabilities to support software development teams. He was previously a professor of computer science at Harvard University, a director of engineering at Google, an engineering lead at Apple, and the SVP of Engineering at OctoML. He received his Ph.D. from UC Berkeley back in the days when AI was still not playing chess very well.  His piece in CACM: https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext  https://news.ycombinator.com/item?id=34087000 ""The shift in focus from programs to models should be obvious to anyone who has read any modern machine learning papers. These papers barely mention the code or systems underlying their innovations; the building blocks of AI systems are much higher-level abstractions like attention layers, tokenizers, and datasets. A time traveler from even 20 years ago would have a hard time making sense of the three sentences in the (75-page!) GPT-3 paper3 describing the actual software built for the model: ""We use the same model and architecture as GPT-2, including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer. To study the dependence of ML performance on model size, we train eight different sizes of model, ranging over three orders of magnitude from 125 million parameters to 175 billion parameters, with the last being the model we call GPT-3. Previous work suggests that with enough training data, scaling of validation loss should be approximately a smooth power law as a function of size; training models of many different sizes allows us to test this hypothesis both for validation loss and for downstream language tasks.""  This shift in the underlying definition of computing presents a huge opportunity, and plenty of huge risks. Yet I think it is time to accept that this is a very likely future, and evolve our thinking accordingly, rather than just sit here waiting for the meteor to hit."""
Lalit Pagaria|2023-07-03 12:51:44|Any idea how to enable OpenAI code interpreter? I have browser access but not sure where to enable or apply for code interpreter access.
~ Arindam Barman|2023-07-03 12:53:08|Anyone knows how they doing? Didn't really hear good feedback on them post their seedfund.
Nirant|2023-07-03 12:53:34|Terrible execution/implementation, but the idea still has alpha left in it
~ Arindam Barman|2023-07-03 12:54:14|Correct. Heard a rumour that one of their investors asked them to return their money lol
Krishna Ntkris|2023-07-03 13:03:14|What have they executed poorly on? I haven’t stayed super close to them for a while
Kaushik Bokka|2023-07-03 13:06:16|Damn
~ Arindam Barman|2023-07-03 13:07:52|Oh yeah you interviewed them.
~ Arindam Barman|2023-07-03 13:08:53|I do think the problem they are trying to tackle is actually hard so not throwing shade at them but was surprised at the 16M seed without any product
Kaushik Bokka|2023-07-03 13:10:28|he wrote a blog about it https://mdwdotla.medium.com/everything-i-wish-i-had-known-about-raising-a-seed-round-a615f8f7740b?source=user_profile---------2----------------------------
ashish Acgt01 Twitter|2023-07-03 13:13:34|Would love to read/hear the interview.
Nirant|2023-07-03 13:15:39|https://ntkris.substack.com/p/building-autonomous-agents-with-fixie
Krishna Ntkris|2023-07-03 13:19:38|How much of the lacklustre execution do you think comes from going too wide? Meaning, AFAIK they are helping businesses build any type of agent they want
Nirant|2023-07-03 13:21:42|Lot of it. An above average RPA product with a very narrow niche e.g. processing fees questions in AMCs for Fortune200 banks and brokerages like Robinhood built on top of OpenAI Functions will make more revenue per engineer than this going wide thing.
Krishna Ntkris|2023-07-03 13:22:49|Yeah I totally agree. I’m very surprised by going wide because it goes against every decade old building principle
Nirant|2023-07-03 13:23:57|Added Context: I was an external, technical evaluator for a variant of this product in 2018, used by one of India's largest AMCs even today to support their door to door+tele calling sales staff of 10K people. Very profitable.
Saurav Akaike|2023-07-03 13:32:22|Hey guys Can anyone suggest a good agency for api testing, load testing and dual functionality who had testing experience with LLMs based models too.
Nirant|2023-07-03 13:35:15|What is dual functionality?
Nirant|2023-07-03 13:38:49|Also, is ask for agencies/services off-topic? Leave a 👍🏼 if you think it is off topic, and leave a ✅ if it's okay to have it here
Nirant|2023-07-03 13:38:52|Context: We've considered job posts as off topic since beginning, because that biases to the space becoming a notice board instead of a space for conversation. The recommended way to make job posts is https://nirantk.com/community
Anshul Bhide Replit|2023-07-03 13:40:46|[PHONE]
ashish Acgt01 Twitter|2023-07-03 15:20:01|A hacker fellowship in SF called HF0  If folks here want to build something similar here in India, let's brainstorm & do it ! #lfg  https://web.archive.org/web/20230703004904/https://www.nytimes.com/2023/07/02/podcasts/the-daily/ai-boom-children.html
ashish Acgt01 Twitter|2023-07-03 15:27:56|VC folks (& others), feel free to DM me with your Twitter &/ LinkedIn if you are interested in collaborating on this  If you would rather listen than read the NYT piece : https://open.spotify.com/episode/3IhrfHAdlV6Of7mLUPDw9M?si=05tuU26bRT2SaYPTxt7aiw
~ Rachitt|2023-07-03 15:30:46|[PHONE] is working on this if I'm correct
Brij Singh Rebright Partners|2023-07-03 15:33:34|Actually we are working more towards supporting the OSS community.  Either promising new individual contributors or team that are working on existing projects that are helping the community.
Aakash Kumar  Matrix Partners|2023-07-03 15:40:30|Happy to help
Nirant|2023-07-03 15:50:47|I've considered running this with Hasgeek, but it's a chore to raise even 5L INR in India.  And it's fair, there is very little/no upside for the sponsor doing this.
Dr. Pratik Desai KissanGPT|2023-07-03 15:51:57|We got to stop copying, we have different problems, constrains and culture. ‎<This message was edited>
Nirant|2023-07-03 15:53:08|Hot take, because I am just having a low day: Given how terrible we're at copying, I don't think we have the skills to customise/adapt things for India. I mean Sachin and Binny Bansal are the exception, not the norm.
Dr. Pratik Desai KissanGPT|2023-07-03 15:56:48|Not a Hot take any more.
Abhinav Verma Longshot.ai|2023-07-03 15:57:43|Can you make a huggingface space without uploading your code in github etc
Dev Aggarwal|2023-07-03 15:58:05|cc [PHONE] of chingari 🔥
Shubham Sharma 2012C6|2023-07-03 15:59:17|Bollywood seconds that
Swapnika Hashmail Web3|2023-07-03 15:59:40|Why would you say no upside? For a VC betting on GenAI, this would be great for branding plus first dibs on funding for any future rounds these products might go on to raise. At the least you have a front row seat to some good work in the space I'd presume.
Abhiram Ramesh|2023-07-03 15:59:49|‎POLL: How many of you are paying for an openai subscription? ‎OPTION: Paying (50 votes) ‎OPTION: Not paying. Using chat gpt(ish) for free (19 votes)
Abhiram Ramesh|2023-07-03 16:00:22|Just gauging the room
Manas Ranjan Kar|2023-07-03 16:00:27|I would be happy to commit 5L yearly if this got me access to a collective which invested in startups born out of such hackathons, in exchange of equity. Angel investing with access to smart people, projects and opportunity to participate in upside
Manas Ranjan Kar|2023-07-03 16:01:06|But it’s a complex financial vehicle, closest I have seen in IPV from Angel . Could be fun though
Dev Aggarwal|2023-07-03 16:01:29|Openai subscription or chatgpt subscription
Abhiram Ramesh|2023-07-03 16:04:31|Openai i.e building on top.  Although I'd be very curious to talk to someone who's bought chatgpt plus as well 🥸 power chatter.
Dev Aggarwal|2023-07-03 16:05:56|Heck If i had that money I’d just do it for the sake of being around hackers 🥹 and having a local gpu cluster cause why not
Swapnika Hashmail Web3|2023-07-03 16:07:13|[PHONE] uses both subscriptions :)
Jivraj Singh Sachar|2023-07-03 16:15:23|‎Jivraj Singh Sachar requested to join
Abhishek Mishra|2023-07-03 16:15:26|You can have a private GitHub repo and then access your source via personal access token in your hugging face space.
Jivraj Singh Sachar|2023-07-03 16:15:49|‎Jivraj Singh Sachar joined using this group's invite link
Abhishek Mishra|2023-07-03 16:17:12|Discussed this once previously in this group - There's a workaround - you keep the confidential code in a private repo on git. Then you import the code using your GitHub personal access token which can be kept in hugging face secrets  A link that discusses something similar - https://discuss.huggingface.co/t/share-app-url-without-sharing-the-files-and-version/26182
ashish Acgt01 Twitter|2023-07-03 16:32:09|I am excited to try this but before diving in, would love to hear your thoughts [PHONE] [PHONE]
Zainab Bawa|2023-07-03 16:34:25|People here can contribute to make this pool of 5 lakh happen.
Zainab Bawa|2023-07-03 16:35:22|Supporting people to make and build is very valuable. One can do individual contributions of 2.5k to 5k and org contributions of 50k to 1 lakh and get credited as supporters for it.
~ Aditya Mishra|2023-07-03 16:37:03|5 K committed
Jithin James Ragas|2023-07-03 16:37:26|would doing a smaller scale help to get started? like for 1 week, 10 hackers under a single roof
ashish Acgt01 Twitter|2023-07-03 16:38:58|Excellent idea !  Maybe we can get orgs like Zerodha and others to pitch in as well. They had some FOSS grant program, maybe they & other orgs would be willing to support an ai fellowship program with a 50k -2,3l contribution
Zainab Bawa|2023-07-03 16:39:12|Here, see. Thank you. [PHONE] let's up a project page and get this running. We'll show the dashboard to everyone to see what the contribution pool looks like
Zainab Bawa|2023-07-03 16:39:58|Sure. You'll do the legwork?
~ Nikhil|2023-07-03 16:40:36|I am sure a lot of us can speak to the orgs that we work in to contribute.
ashish Acgt01 Twitter|2023-07-03 16:40:56|Happy to ! Physically based in Delhi, but would love to use my network to do this
jyotirmayjk Hackathon|2023-07-03 16:41:26|Can definitely do individual contribution of 5k   Is there a link to pool contributions ?
Zainab Bawa|2023-07-03 16:41:44|Excellent. [PHONE] work with Ashish to set up a pitch.
Zainab Bawa|2023-07-03 16:41:55|Setting up. Give sometime.
Zainab Bawa|2023-07-03 16:42:14|We can then take it to larger orgs.
jyotirmayjk Hackathon|2023-07-03 16:44:00|Once a pitch is set up all of us can take it to the respective orgs we work in  This is a good idea 👍🏻 ‎[7/3/23, 16:52:02] Shashank Generative AI Group: ‎image omitted
Shashank Generative AI Group|2023-07-03 16:54:13|""" wanted to build an embeddings database from scratch just as a learning exercise per WebGPT, but realized that it would be cool to turn into a tinygrad-esque project. rationale is that approximate nearest neighbors/hnsw/faiss is kinda dumb when vector search is O(N) lol.  some goals: - make it hyper optimized - filtering/sql sucks on vector databases, let's make this good - i want gpu acceleration. super fast nn kernel, basically a matmul anyways - integrate cool tools like PCA indexes, custom ANN algos, etc. - make it useful. python/js lib."""
Abhishek Mishra|2023-07-03 16:54:54|Identified a bunch of problems with vector databases and came up with multiple wrong solutions
Zainab Bawa|2023-07-03 16:54:56|Exactly.
Nirant|2023-07-03 16:55:42|"Hahahahhaa, beat me to it! 🤣  In fairness, there are no obvious good solutions — and this solution might fit the ""Worse is better"""
Abhishek Mishra|2023-07-03 16:56:38|It's partially enraging ngl
Kaushik Bokka|2023-07-03 17:49:39|My cofounder had an interview with them. They don’t advocate it but they seem to be majorly enterprise focused
Nirant|2023-07-03 17:50:09|Dealflow is the only way to fund these things
Kaushik Bokka|2023-07-03 17:51:06|https://www.betaworks.com is nice! Hugging Face was part of their accelerator back in the day
Paras Chopra Wingify|2023-07-03 18:25:03|Basic question  Why are LLMs coming out with these number of Params and or others? 7b, 13, 33  Is there a technical reason or benchmarks are driving this uniformity?
Abhishek Mishra|2023-07-03 18:34:43|Mainly 2 reasons as per my understanding: * Whether they can fit in an H100, A100 80, A10, T4 or other 16G GPUs * It's based on Chinchilla paper, where certain results mention how many parameters and how many tokens you need to achieve performance relative to GPT3 or other major LLMs
Rohit Aggarwal|2023-07-03 18:35:21|My guesses  - Open source models are building on weights and datasets from Llama which was probably these sizes (llama paper itself I think said that the choices for sizes arises from empirical testing) - If a lot of models are being trained on the Pile, maybe there are logical stop points around those data sizes
Abhishek Mishra|2023-07-03 18:35:53|For example, a 30B parameter model can theoretically outperform GPT3 with 1T+ tokens as per the paper.
Abhishek Mishra|2023-07-03 18:36:10|Likewise, decisions are based off of which devices can support which inferences
~ prakashkagitha|2023-07-03 19:09:03|‎Dr. Pratik Desai KissanGPT added ~ prakashkagitha
Reetik Agarwal|2023-07-03 20:22:19|‎You added Reetik Agarwal
~ prakashkagitha|2023-07-03 20:26:10|Great to join this group, Looking forward to the discussions!
~ Priyanka Thakran|2023-07-03 20:48:27|Hey folks, I’m looking to understand what solutions are available for using AI for analysing spatial imaging for indoor spaces. Couldn’t find anything useful online. Would love to get some ideas, resources
~ Nayan Shah|2023-07-03 21:22:32|Has anyone tried llm for intent to action detection and something in that kind ? Means want to identify some conversational attributes for any domain such that i can take an action based on the converstion that is going on , intent, sentiment looks like the starting point but any other things or ideas anyone have
~ Nayan Shah|2023-07-03 21:23:12|Kind of like rasa , if anyone tried there we give intents with queries but hoping out of box llm will work gpt , was kind of good only
~ Rohan|2023-07-03 21:23:56|what kind of analyses are you looking for? detection, segmentation, something more complex? detection - detectron library is a good starting point segmentation - SAM (segment anything model) is a good foundation model
~ Rohan|2023-07-03 21:25:08|Depending on what you want to do, you may even be able to use non-learning approaches using OpenCV's image processing suite
~ Gearskart|2023-07-03 21:42:07|Tried something similar experiment with off the shelf LLM(Completions).  It worked well for longer queries and not well for short queries. Am.not sure if fine-tuning helps in this further.  LLM to SQL is a fine bridge rather than getting it throw labels.
~ Priyanka Thakran|2023-07-03 21:42:13|I’m primarily looking for measurements and depth calculation of objects and internal structures
~ Priyanka Thakran|2023-07-03 21:44:12|OpenCV is for basic use cases. I’m looking to extract depth and other measurements from 2D images and then 3D models from lidar scans and general images too
~ Rohan|2023-07-03 21:46:13|If you don't have stereo images, your best bet for accurate depth would be some monocular neural net architecture (there are many out there) From there, you can use SAM to segment or detectron to get bounding boxes (i.e., image dimensions) of the objects of interest. The image dimensions can be translated into real-world metric dimensions using the depth from above method.
~ Rohan|2023-07-03 21:48:00|For 3D models from lidar + images, I'm actually working on the same problem. We're using 3D object detectors which work on multimodal data (images + point cloud). A good candidate is CLOC: https://arxiv.org/abs/2009.00784 It is easily deployable too.
~ Priyanka Thakran|2023-07-03 21:49:25|Thanks for sharing- will check these out. Also would love to know the problem statement you’re working on. Also looking to try https://developer.apple.com/augmented-reality/roomplan/
Abhishek Mishra|2023-07-03 21:49:26|Does this work for you? - https://www.lerf.io/
~ Priyanka Thakran|2023-07-03 21:51:30|Cool stuff!! Object identification with measurements is our problem- getting the measurement is essential which if this can provide would be great.
~ Vrushank Vyas|2023-07-03 21:54:54|Check this out: https://www.captur3.ai/
~ Vrushank Vyas|2023-07-03 21:55:03|They have a pretty decent ios app
Abhishek Mishra|2023-07-03 21:55:04|I see. I am not good with CV but this seems to be tackling your problem and claims to be SoTA - https://depth-gen.github.io/
Paras Chopra Wingify|2023-07-03 21:58:00|TIL: Temperature and repetition penalty sort or “cancel” each other out  https://ai.stackexchange.com/questions/39540/how-do-temperature-and-repetition-penalty-interfere
~ Priyanka Thakran|2023-07-03 21:59:49|Thanks for this, will check out!
~ Priyanka Thakran|2023-07-03 22:00:05|Interesting, will check this, thanks!
Kaushik S YC W23|2023-07-03 22:09:49|I am looking to run a ML solution on prem. What’s the best way to do this?
~ Nayan Shah|2023-07-03 22:11:54|Ohh thanks for the response
Swapnika Hashmail Web3|2023-07-03 22:13:35|Have you tried OpenAI functions to convert intents to actions?
Kshitij Agrawal ML Engineer|2023-07-03 22:14:26|There a whole bunch of research on Monocular depth prediction. Models have become quite good these days. The problem will be in relating the predicted depth to real world distances for which you need some sort of calibration step.
Kshitij Agrawal ML Engineer|2023-07-03 22:15:53|I would sugges to try with simpler models like - https://github.com/isl-org/MiDaS
~ Priyanka Thakran|2023-07-03 22:42:25|Thanks for this, will definitely check it
~ Nayan Shah|2023-07-03 23:05:39|No i have not tried , let me vheck that .
‪+91 97385 26173‬|2023-07-04 00:12:14|‎Shivendu Kumar added ‪+91 97385 26173‬
Abhishek Mishra|2023-07-04 00:20:08|Surprising result but sounds like a tall claim so still not sure. A replit 3B instruction tuned model surpassed WizardCoder score on HumanEval benchmark and scores 63.5% in pass@1.  No model card on HF but tweeted by abacaj. At this point, I just think this is gamified as well 🤣  https://twitter.com/abacaj/status/1675914584367018014?t=H7mgMWk-HHGNOiDuCAfHsg&s=19
~ Deven|2023-07-04 00:40:34|Looks like there is  demo space https://huggingface.co/spaces/teknium/sahil2801-replit-code-instruct-glaive
Abhishek Mishra|2023-07-04 01:03:13|Great. It was strange that he didn't create a model card or put up any details whatsoever for testing.
Abhishek Mishra|2023-07-04 01:11:55|Well, It failed all 3 of my simple tests in python. I'll check more tomorrow. Probably check the dataset for leak as well.
Adithya S K PESIT|2023-07-04 01:16:10|that was real quick
Abhishek Mishra|2023-07-04 01:23:10|It takes a minute right now on the space to generate response. It's a 3B model so it's Inference is fast.
Abhishek Mishra|2023-07-04 01:24:27|What I tried with were easy but slight variations of binary search, it kind of ignored all constraints and thus didn't answer correctly.
Adithya S K PESIT|2023-07-04 01:25:17|I meant your curiosity to test it out was quick I saw it and I was like lets test it out tomorrow
Adithya S K PESIT|2023-07-04 01:25:34|but which is the best OSS code model to build up on?
Adithya S K PESIT|2023-07-04 01:25:59|do u have any suggestions
Abhishek Mishra|2023-07-04 01:27:17|It's either StarCoder newest variant or WizardCoder. Can't say if WizardCoder has data contamination to get better results but it should still be good.
Abhishek Mishra|2023-07-04 01:29:58|Nice inference api for StarCoder - https://huggingface.co/bigcode/starcoder  WizardCoder - https://huggingface.co/WizardLM/WizardCoder-15B-V1.0
Adithya S K PESIT|2023-07-04 01:30:12|i fell RAG based AI documentation dont really do a good job and dont have a good understanding of the documentation to generate stuff can it be improved by feeding the whole documentation with instruction fine tuning to an good OSS code model and get better answers  by better answers I mean those which can be directly copy pasted?
Abhishek Mishra|2023-07-04 01:33:07|Yeah you can probably do better by fine tuning but it can lead to overfitting as well. But if you're making a product for something focused solely on the documentation QA, I'll suggest trying it out to compare the results.
Adithya S K PESIT|2023-07-04 01:34:37|yep on my way to start a new side project which I will probably leave half way through coz i will find something more fascination the next day
Adithya S K PESIT|2023-07-04 01:34:47|fascinating*
~ Abhiram Ravikumar|2023-07-04 07:46:23|https://arxiv.org/abs/2210.03945
~ Abhiram Ravikumar|2023-07-04 07:46:24|Interesting paper, I did not know parsing HTML was a challenge for foundational LLMs
~ Abhiram Ravikumar|2023-07-04 07:47:11|Also, is there any way I can subscribe to Arxiv papers so that I get to know when a second version of the paper is published?
Shan|2023-07-04 08:02:52|I haven’t used it on arXiv but https://visualping.io/ has been fantastic for me for such use cases
ashish Acgt01 Twitter|2023-07-04 08:49:05|https://arxiv-sanity-lite.com/
Anshul Bhide Replit|2023-07-04 09:11:42|Is there anyone here that can intro me to Sahil?
Nirant|2023-07-04 09:12:59|Must be July? I called this out in May end that this is going Kaggle-way 🤣
Ved Chitnis|2023-07-04 09:57:41|"""Though human eval isn’t necessarily indicative of how good the model will do for users in real life use cases,  having a pass@1 higher than all open source models with just a 3B model and 1B tokens shows how good small models can get given high quality data"" - @csahil28"
Ved Chitnis|2023-07-04 09:58:28|"If it isn't ""necessarily indicative"" of model performance I'm super confused as to why this keeps being proped up for a ""new revolutionary model"" everytime"
Sandeep Srinivasa RedCarpetup|2023-07-04 09:58:43|https://twitter.com/vipulved/status/1676014844171153409?t=3M6XgfAEzM8YcE0mZ0nDhQ&s=19  Has anyone used redpajama ? Seems they are claiming a lot of commercial deployments
Sugnan GenerativeAI Group |2023-07-04 09:59:23|*JOB OPENINGS*   🟢 CollectivAI - 🎯 *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps — making internal tools) - 🔍 *Job Description*: Seeking an ML researcher to improve our code embedding models - 📝 *Apply Here*: https://in.linkedin.com/jobs/view/machine-learning-engineer-at-collectiv-ai-3614376734?trk=organization_guest_main-feed-card_feed-job-posting-content - 💬 *Contact*: Naman Jain: https://www.linkedin.com/in/naman-jain-8743ab79/  ---  🔵 GPT Sahib - 🎯 *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps — making internal tools, Broad ML role) - 🔍 *Job Description*: Looking for an AI developer to assist in developing a chatbot in two languages - 📝 *Apply Here*: https://www.gptsahib.com/ - 💬 *Contact*: Savipreet, Phone: +91-8054966180, Email: [EMAIL]  ---  🟣 LongShot AI - 🎯 *Hiring for*: Broad ML Role - 🔍 *Job Description*: Hiring a Full Stack NLP Engineer to work with latest LLM models for various use cases - 📝 *Apply Here*: https://hi.longshot.ai/NLP - 💬 *Contact*: https://www.linkedin.com/in/vermaonline/, https://www.linkedin.com/in/ankurpandey42/  ---  🔴 Cranberry.Fit - 🎯 *Hiring for*: Generative AI (text, vision) - 🔍 *Job Description*: Part-time engineering role to build a women's health conversational AI using open-source LLMs - 📝 *Apply*: Email directly to founder at [EMAIL] - 💬 *Contact*: [EMAIL]  ---  🟠 AI Northstar Tech - 🎯 *Hiring for*: Generative AI (text, vision) - 🔍 *Job Description*: GenAI generalist engineer. Tasks include building semantic search engines, LLM fine-tuning, vector DB applications, and some data science work - 📝 *Apply Here*: https://wellfound.com/l/2z2CyD - 💬 *Contact*: [EMAIL]  ---  🟡 gooey.ai - 🎯 *Hiring for*: Generative AI (text, vision, ML/LLMOps/FMOps — making internal tools) - 🔍 *Job Description*: Building a GenAI platform that abstracts latest LLMs, animation tools, speech recognition, etc. from OpenAI, Stability, Google, Meta, etc. - More details: https://www.help.gooey.ai/jobs/senior-software-engineer - 📝 *Apply Here*: https://forms.gle/F22ekdAjm2BfxxUW9 - 💬 *Contact*: Sean, Email: [EMAIL], Phone: +91 98862 51476, Dara: https://dara.network/sean  *- Posted by Sugnan on behalf of Generative AI Community*
Nirant|2023-07-04 10:11:05|Thanks for sharing the opportunities with the community first [PHONE] [PHONE] [PHONE] [PHONE] 🙏  Muchas gracias for adding this to https://nirantk.com/community as well
Nirant|2023-07-04 10:12:43|cc [PHONE] for any queries for the event on July 8th in Koramangala ‎<This message was edited>
Anshuman Pandey|2023-07-04 10:13:38|It's on Jul 8th 🤗
Nirant|2023-07-04 10:14:52|Sorry, this 3 timezone calls, 3 date format is killing my brain 🫣
Aarish|2023-07-04 10:52:26|‎Aarish joined from the community
Chinmay Singh Generative AI WhatsApp Group|2023-07-04 11:15:43|In work with MLOps community, we created a summary of key talks from LLMs in Prod conference 2 with amazing ML leaders in the LLM domain.   If you would like to access it in your inbox, here's the URL:  https://www.truefoundry.com/ebook-llm-in-production  Covers topics like: Shipping LLMs, Hallucinations in LLMs, LLMs in Rec systems, LLM Economics
Anshuman Pandey|2023-07-04 11:40:28|Ok
Jidin Dinesh|2023-07-04 11:54:41|Ask for help:  Problem statement: We've proprietary dataset of say, 2-3 million LinkedIn creators and their content items (say 300k creators talking about ML, 200k creators talking about PM etc). With this data, we want to build a system that's capable of searching and ranking profiles on an input query like:  Find people with education : MIT professional experience : prev google profession: engineer talking about: ML location: NYC with followers>2000  What're the different approaches (vector db based and non vector db ones) to solve this problem well?
Kshitij Agrawal ML Engineer|2023-07-04 11:59:07|Build ner system for fixed quantities. Use that as filter.  Use LLM for semantic matching of semantic parts of the query
Sudeep Das NASSCOM|2023-07-04 12:07:09|‎Sudeep Das NASSCOM joined using your invite
~ Shagun Sood|2023-07-04 12:36:36|‎~ Shagun Sood requested to join
~ V Pai|2023-07-04 12:38:44|Good read: https://venturebeat.com/ai/inside-the-race-to-build-an-operating-system-for-generative-ai/
~ Tapan|2023-07-04 12:45:27|‎~ Tapan requested to join
ashish Acgt01 Twitter|2023-07-04 12:48:14|Neat paper !  https://arxiv.org/abs/2304.05128 https://twitter.com/denny_zhou/status/1676003452839919616?s=20
Sandeep Srinivasa RedCarpetup|2023-07-04 12:58:29|interesting - blockchain funds are redeploying to AI. some web3 fund announced a 500k online hackathon.  https://soonami.io/hackathon
Shashwat TDC|2023-07-04 12:59:33|certainly interesting
Karan Lightspeed|2023-07-04 13:02:16|"Any good examples of startups working on bounded scope ""agent"" use cases with LLMs - task automation, data entry, data analysis etc.?"
Krishna Ntkris|2023-07-04 13:55:24|We’re focus a 100% on CS ‎[7/4/23, 14:30:16] Abhinav Verma Longshot.ai: ‎image omitted
Abhishek Mishra|2023-07-04 14:31:50|It's actually the opposite.
Abhishek Mishra|2023-07-04 14:32:24|They didn't want the browse with Bing to reveal all contents of the website. But that's what it can do. Bing in search engine can't do that
Abhinav Verma Longshot.ai|2023-07-04 14:33:06|Can you explain this? They don't want to scrape the whole site? ‎[7/4/23, 14:33:15] Abhishek Mishra: ‎image omitted
~ Sudhanshu Heda|2023-07-04 14:33:43|A lot of people were bypassing paywalls
Abhinav Verma Longshot.ai|2023-07-04 14:34:36|You can bypass paywalls anyway by stopping the loader quickly
Abhishek Mishra|2023-07-04 14:35:02|That and scraping the content without any ad revenue is also a no go. They want search engines to index stuff and display things by metadata, robots text content and not be a way to consume content without visiting the websites.
Abhinav Verma Longshot.ai|2023-07-04 14:36:39|Is it a no go legally? Because scraping with citations is allowed.  Also Bing chat was able to do the same thing as is bard
Abhinav Verma Longshot.ai|2023-07-04 14:37:16|When you do chatgpt with browsing even if you don't give the url explicitly it still scrapes the site
Abhishek Mishra|2023-07-04 14:40:11|I think scraping of public data is allowed as of now but they are avoiding it so that the search engines don't kill the incentive to visit anybody's website.  Bing has now become incapable of revealing contents of a url or parse it deeply for information. I think they limited it to work with indexed info only.
Abhinav Verma Longshot.ai|2023-07-04 14:40:56|They're going to have togive Google this memo as well because it is planning doing something worse ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-04 14:41:39|Googles plan is to give detailed answer snippets and people also ask.
Abhinav Verma Longshot.ai|2023-07-04 14:41:51|Let me check what Bing is doing currently ‎[7/4/23, 14:43:43] Abhishek Mishra: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-04 14:45:41|This is why they should have let startups handle this. They tried to make google dance and are burning everything. Chatgpt with browsing was meh at best, and is creating unnecessary controversy
Dhruv Anand|2023-07-04 14:46:06|I wonder how Perplexity handles this, or whether they are just flying under the radar on this: https://twitter.com/AravSrinivas/status/1676101654683488256?s=20
Abhinav Verma Longshot.ai|2023-07-04 14:46:42|No one is printing the whole article verbatim. It is a paraphrased version answering the users input specifically
Abhinav Verma Longshot.ai|2023-07-04 14:46:52|With proper citations
Abhinav Verma Longshot.ai|2023-07-04 14:47:40|So you ask for something, it would most likely search for that topic , get you a paraphrased answer with citations.
Dev Aggarwal|2023-07-04 14:47:57|Perplexity is pretty wrong most of the time. Citations are usually super random
Abhinav Verma Longshot.ai|2023-07-04 14:48:27|might be doing it LLM generated instead of deterministic ways
Dev Aggarwal|2023-07-04 14:49:27|I tried to get a kpmg analyst to use perplexity & my internal google search + gpt4 for their research - it will often say stuff that doesnt correlate with what’s in the sources - and the citations will be random - which means they can’t use it in their work
Abhinav Verma Longshot.ai|2023-07-04 14:50:40|someone at perplexity needs to look at those prompts 😜
Abhishek Mishra|2023-07-04 15:04:35|At this point, it's not a bad idea to use SERP api + GPT3/4 api to have personal browsing.
Abhishek Mishra|2023-07-04 15:05:34|Fetch html with curl after identifying the url and let gpt 3/4 do the text extraction or beautiful soup if that's where you want to go
~ AI|2023-07-04 15:05:55|Yep and there have been alleged copyright infringement issues even with paraphrased summaries. Not sure if this has already been shared here earlier but OpenAI is now being sued for copyright violations -  https://www.reuters.com/legal/lawsuit-says-openai-violated-us-authors-copyrights-train-ai-chatbot-2023-06-29/
Abhishek Mishra|2023-07-04 15:08:26|Google, OpenAI and many other companies have already benefited from the data massively. Since there wasn't a proper law against this earlier, this is a grey zone.   I definitely think it should be possible to allege monopolization of open or public data and get them to at least make api distillation legal for model building
~ Akshat Khare|2023-07-04 15:23:50|Omg, how did I miss this. But this means there are automated techniques to bypass paywalls? Other than scihub, do you guys know if any
Aashay Sachdeva MPL Data Scientist|2023-07-04 15:25:10|12ft.io used to work
~ Sudhanshu Heda|2023-07-04 15:25:14|12ft.Io
~ Akshat Khare|2023-07-04 15:25:29|Thanks
Dev Aggarwal|2023-07-04 15:26:31|Pro tip: use pandoc for html -> text
Abhishek Mishra|2023-07-04 15:33:12|Thank you, I'll put it to test.
Abhinav Verma Longshot.ai|2023-07-04 15:56:21|I think this part is different from retrieval based generation. In any case, will be interesting to see this case develop. I believe Japan has already said this is OK.   But yeah they might have definitely used books and private code repos in their training data
~ Ankit|2023-07-04 15:56:39|‎~ Ankit joined using your invite
Abhinav Verma Longshot.ai|2023-07-04 15:56:43|This is a nice topic for philosophy group ‎[7/4/23, 16:01:11] Abhishek Mishra: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-04 16:02:05|Yass, for startups
Abhishek Mishra|2023-07-04 16:03:36|Definitely. I just thought it was nice to have the option locally with chat. I was using combo of anki flash cards and scraping/parsing to take care of my learning requirements.
Abhishek Sahu Ultrahuman|2023-07-04 16:03:58|Yep, also saw that they removed browsing with Bing plugin for Plus users. It was bad anyway.
~ bhanu.io|2023-07-04 16:17:10|Ask your pdf still works, though it's not as seamless as you would expect.
Rohit GenerativeAI WhatsApp Group|2023-07-04 16:22:38|‎You added Rohit GenerativeAI WhatsApp Group
ashish Acgt01 Twitter|2023-07-04 16:24:41|https://twitter.com/random_walker/status/1676077967577870336?t=0SrbEsdgnWBFYvXu05RrqA&s=19
Abhishek Mishra|2023-07-04 16:27:52|WebPilot seems to be doing fine for now as well.
~ param|2023-07-04 16:40:14|‎~ param joined using your invite
Abhinav Verma Longshot.ai|2023-07-04 17:15:23|Has anyone seen the batgpt paper. Is this real? ‎[7/4/23, 17:15:33] Abhinav Verma Longshot.ai: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-04 17:15:56|Or is this the greatest parody in the world
Abhishek Mishra|2023-07-04 17:17:29|This can't be real.
Abhishek Mishra|2023-07-04 17:17:47|The social points awarded by China for these guys will go negative ‎<This message was edited>
Paras Chopra Wingify|2023-07-04 17:32:13|Love it
Rajesh RS Generative AI WhatsApp Group|2023-07-04 17:38:18|LOL
Rajesh RS Generative AI WhatsApp Group|2023-07-04 17:39:06|"I almost think it is deliberate. Bidirectional Autoregressive ""Talker""? Really?"
Abhishek Mishra|2023-07-04 17:40:48|They've an arxiv page and they are from Wuhan University.  https://arxiv.org/abs/2307.00360  It's unreal.
Anubhav mishra Zupay|2023-07-04 17:40:58|https://paperreading.club/page?id=173095
Meghana Jagadeesh|2023-07-04 17:50:33|Hey everyone,  Is the OpenAI API working fine for you? It has suddenly become slow and the requests are timed out.
~ Shaurya|2023-07-04 17:52:12|Working OK for me right now ‎[7/4/23, 17:54:17] Abhishek Mishra: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-04 17:59:53|This depends a lot on when people in the west start using the app.
Rajeev Singh Naruka|2023-07-04 18:00:00|Does anyone have an idea how to get access to the Anthropic API? Have applied but haven't even got email acknowledgement for application for quite some time now.
Abhinav Verma Longshot.ai|2023-07-04 18:00:18|They are notorious for being slow
~ Anand|2023-07-04 18:01:48|‎~ Anand left
Meghana Jagadeesh|2023-07-04 18:02:04|A user of ours had ZScaler installed. Would this affect our API key and result in blockages?
Rajesh RS Generative AI WhatsApp Group|2023-07-04 18:02:14|I saw somewhere the context length for Anthropic models being huge. Anyone with practical experience in using these? Thoughts?
Abhinav Verma Longshot.ai|2023-07-04 18:02:51|Unaware of zcaler actually
Rajeev Singh Naruka|2023-07-04 18:03:22|Hashnode for their chatbot rix
Abhinav Verma Longshot.ai|2023-07-04 18:04:33|This is true. 100k context length.  But like all RLHF models, you can't give a lot of token length for response. The quality is decent upto levels of turbo maybe lesser than the new models but still definitely usable for few use cases commercially
~ Akshat Khare|2023-07-04 18:05:20|Yes, basically I replaced llamaindex workflow by just feeding in whole document to anthropic at once. It gave decent answers then when I used chunked retrieval based QA with openai.
~ Akshat Khare|2023-07-04 18:05:58|I got by participating in a hackathon where anthropic had bounties.
Lalit Pagaria|2023-07-04 18:06:22|Trafiltura (GPLv3) is also a good tool. I have added this in Obsei to extract Google news articles and it works very well.
Abhinav Verma Longshot.ai|2023-07-04 18:07:08|This is the best
~ Akshat Khare|2023-07-04 18:07:14|I just came across this. I don't write understand what problem are they solving clearly. Why do you use it?
Abhinav Verma Longshot.ai|2023-07-04 18:07:27|You should delete this
~ Akshat Khare|2023-07-04 18:08:50|Yes, but similarly on a case by case basis. If you are in a beta program of theirs you can get it. Apart from that check lablab.ai is having a hackathon with vertex ai. They are claiming to distribute accesses there.
Abhishek Mishra|2023-07-04 18:09:40|It isn't clear to me as well. I am confused if they are a way to indirectly access the waitlisted APIs or just a package to manage multiple APIs. I needed something like steamship to use GPT4 apis but cleaner without the baggage of building entire packages for them first.
Rajesh RS Generative AI WhatsApp Group|2023-07-04 19:42:30|https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c - interesting combination of techniques discussed for very large (book length) context windows. Fascinating stuff.
~ Lakshay Nagpal|2023-07-04 20:14:16|Hello everyone,  We have a use case of chatbot using langchain + openai.  We are currently streaming the responses, but now want to introduce actionable buttons below the streamed text. Can add interactive widgets as well like polling some day.  Wish to hear thoughts on how can we achieve this while ensuring the streaming is also happening?
Abhishek Mishra|2023-07-04 20:58:36|Might be of interest to some folks here.  I confirmed with the dev for https://openrouter.ai/ that we can access anthropic, palm, gpt APIs without any issues from there.  However, no guarantee for safety of your data or any other reason you may trust openAI more than a third party proxy. But to some folks it may not matter and they just want access so mentioning it here.
Shimanta Generative AI|2023-07-04 21:44:26|The ship of trust sailed away long ago, but it’s coming back now again 😅
Nirant|2023-07-04 22:55:35|when the numpy gang/cult of karpathy drinks too much of their own koolaid: https://twitter.com/sdand/status/1676256439525056513  my response in case someone wants to grab popcorn https://twitter.com/NirantK/status/1676280543921729536
~ Vipul|2023-07-04 22:55:49|Anyone knows how can we programatically crop a video from landscape to portrait without losing the subject? Much like what they're doing here - https://cognitivemill.com/solutions/croperator/
Dr. Pratik Desai KissanGPT|2023-07-04 22:58:58|Is he trying to reinvent FAISS?
Dev Aggarwal|2023-07-04 22:59:04|his chart is for like the order of 1000s of embeds though - apples vs oranges?  I think he means millions of embeddings, but with individual queries not actually searching though that order
Nirant|2023-07-04 22:59:48|This is an INDEX time. And he has measured embedding creation time in it 🤦🏾‍♂️   https://github.com/sdan/vlite/blob/084b5ba82d4666bbd34716bc6e3d11daccc34fd3/tests/bench.py#L58
Nirant|2023-07-04 23:00:00|Not even query time!
Dev Aggarwal|2023-07-04 23:00:00|and that chart is also indexing time, not query time
Abhinav Verma Longshot.ai|2023-07-04 23:00:09|https://github.com/jdagdelen/hyperDB hyperDb is all you need. Facts
Nirant|2023-07-04 23:00:30|You can't just use a nuclear weapon to assassinate a single person sir
Abhinav Verma Longshot.ai|2023-07-04 23:00:59|Happy 4th of July lol:😂
Dr. Pratik Desai KissanGPT|2023-07-04 23:01:20|Don’t bring Brahamastra to slap fights
Dev Aggarwal|2023-07-04 23:01:42|His use case is for a small and very dynamic dataset. so measuring index time makes sense
Dev Aggarwal|2023-07-04 23:07:05|Like this makes so much sense for people building apps - e.g. searching though a bunch of pdfs or websites means you need fast indexing, query time is pretty much irrelevant across 1000s of vectors
~ Vipul|2023-07-04 23:09:02|A much better example of what I'm looking for - https://cloudinary.com/documentation/video_resizing_and_cropping
Abhishek Mishra|2023-07-04 23:25:42|It's like people getting happy on discovering linear search when they had to search in a list and shitting over all the algorithms designed for best worst case complexity.
Abhishek Mishra|2023-07-04 23:26:31|Good for them but no need to suddenly claim it as Eureka, Eureka.  You didn't discover anything, but you definitely ran out on the street naked
Nirant|2023-07-04 23:27:24|"For this use case, why'd you wrap numpy then? Why not ""just use numpy""?"
Dev Aggarwal|2023-07-04 23:32:19|Because otherwise you have to hand roll a bunch of stuff around numpy like -   text splitting - https://colab.research.google.com/drive/1S_4m87c44Zz1sRtY--SwLsozF6MPrfCO?usp=sharing  batching, prompts & heapq -https://colab.research.google.com/drive/1VezfmvAg4t1okxs7pJ0qp0pWDAaW7mlo?usp=sharing  I don't think this particular implementation is very sophisticated though
Dev Aggarwal|2023-07-04 23:34:10|"I'm just saying there's room for a library with just ""Just two functions with optional flags for more customization"" - something that's not langchain, and something that requires no dependencies except numpy"
Abhishek Mishra|2023-07-04 23:34:22|In most cases, you can index something slightly slower and you'll worry about the query latency mostly as you'll want it to seamless.  If you had to index every hour, and query few times a day then you've a different use case and then you may want to optimise indexing over latency.
Dev Aggarwal|2023-07-04 23:35:59|Yup - here he had to index on every request - very different from searching a static db
Dev Aggarwal|2023-07-04 23:39:20|"$ pip install x  >>> import x >>> x.index([ ""hello"", ""world"" ] >>> x.query(""hey!"") hello  💓"
Abhishek Mishra|2023-07-04 23:54:10|That or just write a wrapper over your vector DB functions to pass a parameter to set low index, average index or high index.  You can set default parameter as the industry convention but for a specific use case with frequent indexing, pass parameter to set low indexing. Wrapper can internally use numpy or cython whatever suits the case.
Abhishek Mishra|2023-07-04 23:55:58|Not very neat but just a top of the head thought for something scalable ‎[7/4/23, 23:56:19] Dev Aggarwal: ‎image omitted
Abhishek Mishra|2023-07-04 23:58:51|Yeah, I understand your feelings on this. But we all know he is going to get stuck there flying because he doesn't know how to control his altitude or flight speed with antigravity class 😛
Sandeep Srinivasa RedCarpetup|2023-07-05 00:01:12|so im suspecting that the reason that the vector db is this fast is cos of the MPS backend. it is skipping the CPU bus entirely.  memory writes will go straight over the PCIe bus to the GPU so this is kind of not a production-friendly benchmark. cos in production, all vector db writes will hop the network in some way.  so fundamentally, it is not numpy at play. it is basically GPU PCI-express. But that is a smart hack nonetheless.
Abhishek Mishra|2023-07-05 00:10:15|I think hnswlib doesn't have an optimal GPU acceleration due to its algorithm requiring random memory access features  Here's an issue for the same on CUDA - https://github.com/nmslib/hnswlib/issues/194  Didn't find any implementation for MPS but I'll look more. I don't think hnswlib benefited here from GPU acceleration.
Sandeep Srinivasa RedCarpetup|2023-07-05 00:12:52|this is not gpu acceleration. there is no convolution computation that is getting accelerated. this is just a PCIE bus skip. thats my suspicion anyway.  theoretically hnswlib can be accelerated in the same way...if someone can figure out its code
Abhishek Mishra|2023-07-05 00:15:23|I didn't understand this. GPU acceleration doesn't have to be a mat mul, any approach that benefits from tens of thousands of parallel computations will work. Hnswlib, doesn't appear to need that.   I'll look deeper for hnswlib though.
Adithya S K PESIT|2023-07-05 01:27:45|what is the base image you guys use for amazon sagemaker endpoints? ‎[7/5/23, 02:09:13] ~ Kp: ‎image omitted
Abhishek Mishra|2023-07-05 02:11:29|It's a guess but I think every chat is logged in and logs come in with timestamps, date etc. Along with some metadata info. The message history it has for our chat may have the date mentioned somewhere and it used it.
Dr. Pratik Desai KissanGPT|2023-07-05 02:13:59|It doesn’t know anything. It finds the date from the context. Also, try asking the same question and mention that today is December 5th.
~ Kp|2023-07-05 02:15:11|But I started the conversation from scratch. Also Isn't gpt only supposed to use the prompt as it's context?
Dr. Pratik Desai KissanGPT|2023-07-05 02:15:52|Like Abhishek said, context is with the query meta, if not explicitly mentioned.
~ Kp|2023-07-05 02:16:23|So if this was tried with the api where there would be no timestamp Metadata it wouldn't work?
Dr. Pratik Desai KissanGPT|2023-07-05 02:17:17|It will prove that they are not adding additional meta context with API.
Dr. Pratik Desai KissanGPT|2023-07-05 02:18:43|Because an LLM doesn’t have perception of time, it can only come from context ‎<This message was edited>
Ambika Computational Mama|2023-07-05 02:21:59|hi ayush its a nice post about the hinge thing - maybe you want to remove the picture of the girl for her privacy (unless she is ai too and didnt catch that!) ‎<This message was edited>
~ Ayush Yadav|2023-07-05 02:28:08|make sense
Ambika Computational Mama|2023-07-05 02:28:52|appreciate it! :)
~ Gaurav|2023-07-05 06:39:09|Is there any good LLM benchmarking tool for comparison of open-source models with GPT-3, 3.5 or 4?
~ Gaurav|2023-07-05 06:44:17|Also for evaluating finetuned models on specific tasks.
Vinayak Tantia FAIR Researcher|2023-07-05 07:17:24|‎You added Vinayak Tantia FAIR Researcher
Shashank B Designer|2023-07-05 08:33:32|Is anyone a power user of github copilot and copilot X (or others) Could you recommend (links to) tips and tricks to make it generate good code?
ashish Acgt01 Twitter|2023-07-05 08:36:41|+1  Would love to hear from folks who use copilot like tools, especially for python
Dev Aggarwal|2023-07-05 08:44:09|Its great autocomplete, terrible coder
Anshul Bhide Replit|2023-07-05 08:45:05|https://accounts.nat.dev/sign-in?redirect_url=https%3A%2F%2Fnat.dev%2F
ashish Acgt01 Twitter|2023-07-05 09:20:45|https://spectrum.ieee.org/ai-programming
Swapnika Hashmail Web3|2023-07-05 09:43:03|Folks, anyone using conversational AI to execute actions within their organisation (looking at use cases beyond simple data retrieval)?
Shan|2023-07-05 09:45:27|“Have you considered using numba” is a swift kick in the backside. Lol. 🤣
Nirant|2023-07-05 09:48:39|The fun nature of that suggestion is that everyone on the inside track gets the joke, while anyone who has actually never heard of Numba will be grateful to learn something new and fast! 😇
Ved Chitnis|2023-07-05 09:49:48|"I know this was discussed yesterday but still curious, What does openAI mean by ""fixing the behaviour"" (In reference to the paywalls being passed) how do you ""fix"" something like that without adding redundant checkpoints which might hinder the performance"
Nirant|2023-07-05 09:51:50|Broadly? You detect client vs server side paywalls and act around this.   How do you detect? Could actually execute JS for top 200 domains or something like that
Ved Chitnis|2023-07-05 09:52:40|Yeah basically this the top 200 domains or something is what my doubt was, there's no possible way they fix for all paywalls right?...right? 😂
Ved Chitnis|2023-07-05 09:53:16|But yeah makes sense thanks
Dev Aggarwal|2023-07-05 09:54:12|Maybe the ones complaining should stop being sissies and use fingerprinting software instead of JS hacks to implement paywalls? https://fingerprint.com/
Nirant|2023-07-05 09:54:46|OMG! A tech solution to a tech problem?   Absolutely impossible for $MSFT to sell this to brands cribbing about this
Ved Chitnis|2023-07-05 09:54:55|I get where you're coming from but that's a blame the victim ish mentality no?
Ved Chitnis|2023-07-05 09:55:05|I mean obviously this is a hole on their end
Ved Chitnis|2023-07-05 09:55:48|"But there should be some ""ethics"" involved when you scrape information from some repository, that's a given"
Nirant|2023-07-05 09:58:38|"Calling media companies with a billion dollar a year tech budget a ""victim"", while sitting in India is a bit of mental gymnastics — I'll leave this for Policy & Philosophy fork of the group"
Ved Chitnis|2023-07-05 09:59:22|"Hence the ""ish"", almost used like a ""not a financial advice"""
Sandeep Srinivasa RedCarpetup|2023-07-05 10:38:56|High degree of regulatory pushback. Fingerprint can inadvertently step over HIPAA boundaries if u ask a personal medical question and then fingerprint the individual.  Or ask a question about being gay and get uniquely identified.
Sandeep Srinivasa RedCarpetup|2023-07-05 10:38:59|Everything to do with AI has regulatory dragons around it. Those of us who have fought these battles for years know 😔
Rajesh RS Generative AI WhatsApp Group|2023-07-05 10:56:05|"There's a distinction between a date as a concept and knowledge / training data that is time limited provided to the bot at the time of training. ChatGPT can understand the concept of ""today"" or the current date, even if it doesn't have training data after 2021"
Nilesh Transcend|2023-07-05 10:56:16|IMHO, conversational aspect is not the most valuable. We ended up building a tool that allows AI agents to participate in existing business workflows.
~ Rachitt|2023-07-05 10:57:43|how did you benchmark the accuracy of outputs? only decent agents I've seen is the CSV agents
Rajesh RS Generative AI WhatsApp Group|2023-07-05 10:59:00|I'd like to know about this too. Getting devs to adopt it is a challenge - has anyone faced this and begun productively using?
Edgar Monis Mumbai WHO|2023-07-05 10:59:15|Completely agree.  Conversational seems like a low hanging fruit. But really it's poisoned.  The minute you monetise people jump to non monetised versions.  People are perfectly okay sharing their deepest darkest fears with a computer program. What they are not okay with is sharing that info with a program which is also trying to make money off of them
Nilesh Transcend|2023-07-05 11:03:18|True. I guess it would depend on the tasks. So far, we've been focused on composability of agents more than individual agents.
Alok Bishoyi|2023-07-05 11:05:13|Somewhat mixed thoughts. This might also depend on how complex and involved the workflow in question is, which further goes back to that particular org’s importance as well  Automating data ops processes vs lets say some manual entry tasks would have much different urgencies and ROI and therefore paying propensity
Abhishek Mishra|2023-07-05 11:13:46|I use it. Copilot is good but more issues than the hype. GPT4 on the other hand, can be really useful if you learn how to work with it.
Abhishek Mishra|2023-07-05 11:15:20|But if you're bad with basic stuff like breaking down problems in smaller chunks, isolating problematic modules, logging and error handling then you'll spend more time debugging with these tools than getting something done.
Abhishek Mishra|2023-07-05 11:16:13|And please don't use it in environments where secure code matters.
~ Sankeerth|2023-07-05 11:16:21|can you share some csv agents that worked for you? haven't seen much success hence asking
~ Rachitt|2023-07-05 11:18:41|For basic tasks, PandasAI or the CSV agents from langchain have worked for me, but when asking it to perform more complex tasks such as extraction of valueable insights, it's been a hit or miss, again also could be my prompting could be incorrect
Abhinav Verma Longshot.ai|2023-07-05 11:35:34|We do it as well. Put today's date in the prompt
~ Deven|2023-07-05 11:45:13|"I have been using it for almost two years. I am a paid customer. I can easily pay 2-3 times more. It is a must-have ""dev tool"" for my dev workflow.   It may take a while to fully integrate it into your development workflow. For me, it took more than a few months. My initial days were full of frustration but I am glad I stuck with it.  It is good at bunch of specific tasks(my experience)  - writing trivial(but necessary) code - For example: if you are doing table-driven testing and have created a map of input and expected output at the top of your test, copilot is very good at writing the code for the test using the map)  - write utility functions - depending upon your language/framework, your code would have a bunch of utility packages. It is very good at writing small utility functions. The success depends mostly on the quality of the function signature.  - it is good at predicting the next line based on the previous line(for example in your rails router, it is able to predict the next route almost all the time)  - sometimes it is able to understand multi-file context - Say you have just written a controller in your rails application, if you go to the routes file, it will automatically suggest the route based on the newly written controller. This doesn't happen often, but when it happens, it feels magical even today.  - It is very useful when working with ""standard"" DSLs(for example helm charts, docker-compose etc.)  I have done a lot of pair programming in my life so it is no way close to becoming a driver/navigator/copilot as of today."
Nirant|2023-07-05 11:56:10|"Minor addendum: Copilot et al are much better at predictable syntax e.g. YAML, Docker-Compose as mentioned — but it's also better when there are strong conventions e.g. RoR, Django, but terrible at new code e.g. Langchain, Llama Index, which don't respect ""Pythonic"" conventions"
Kaushik Bokka|2023-07-05 11:57:10|They don’t respect Pythonic conventions?
Anshul Bhide Replit|2023-07-05 11:57:37|Also given how often langchain & llamaindex release updates, I’ve found it’s suggestions to be often outdated / incorrect
Nirant|2023-07-05 11:58:16|I don't think they know that they're writing a Python lib yet
~ Naveen|2023-07-05 12:08:33|This involves multiple aspects actually. You need to do subject tracking (person/ face/important objects), this gives you the region of interests, and then you can offset these regions to the required aspect ratio. Post this, you can crop the video using ffmpeg with sliding transitions with the given regions of interests.
~ Akshat Khare|2023-07-05 12:39:52|Use some tool like rembg on frames and then apply smoothing heuristic over frames with maximization over focussed frame to aspect ratio of portrait. Give your message and my response to gpt4 chat. I gave it and it gave a reasonable code.
~ Akshat Khare|2023-07-05 12:42:50|https://zulko.github.io/moviepy/examples/headblur.html Check this example. You can modify for your purpose I believe
Sumod K Mohan|2023-07-05 12:49:12|Few gotchas I have noticed using chatGPT, co-pilot is not as much of my regular workflow to comment 1. It does mix up library versions, so if a covention changes between versions and you are tying to do something beyond super common, it may mix conventions from different library version. Saw this quite a bit with browser extensions. 2. Due to the system being trained in non interactive fashion (as compared to humans), it will assume some surface level thing. I was using Jinja2 templating and 'extend'ing. It assumed conventions from other language which was not exactly how Jinja2 does it. I saw the code and thought, ok that must be how it works and it ran correctly for that input. Only then finally realized the issue & go down rabbit hole of debugging.
~ Vipul|2023-07-05 12:52:50|Will check this out, thanks!
~ Khauneesh|2023-07-05 13:07:28|sql
Swapnika Hashmail Web3|2023-07-05 13:10:26|DMing you
Nirant|2023-07-05 13:16:03|"*Event Announcement*  *The Business of generative AI*  For: Founders, sales & marketing leaders, PMs & investors Hosts: Peercheque w/ Aakrit [PHONE], and featuring Rohit [PHONE] from Portkey When: 13th July 2023 | 7:00 PM (IST) Where: Zoom Register here: https://docs.google.com/forms/d/e/1FAIpQLSdNHU91p25tPvRaRRrJJkEo-zbhtGNHn7R7IE_m5wRHWV4jcA/viewform"
Simrat Hasura|2023-07-05 13:53:22|https://github.com/BerriAI/reliableGPT Helpful package I believe
Nirant|2023-07-05 14:12:58|Simplified name, because we've dedicated groups for Creatives and DeepMedia now — in the same WhatsApp Community
Shashwat TDC|2023-07-05 14:19:38|Bhai there are too many groups with same name. At least add a 'x' or some identifier. You kinda made it more generic.
Nirant|2023-07-05 14:20:29|Is that better? 🤣  Sorry, feeling playful
Anshul Bhide Replit|2023-07-05 14:20:52|fun story - this was built on replit https://twitter.com/ishaan_jaff/status/1633310537667973121
~ Diwank|2023-07-05 14:20:54|Brilliant read.  https://thegradient.pub/othello/
Nirant|2023-07-05 14:23:52|Is this unique enough? 🤔
~ Prajna Prayas|2023-07-05 14:24:53|"You could name ""The Terminator: Genesis"""
Azhan Mohammed Generative AI WhatsApp Group|2023-07-05 14:25:40|"Generative AI || Text This sounds more relevant"
Azhan Mohammed Generative AI WhatsApp Group|2023-07-05 14:25:43|"The others could be Generative AI || Image/Media"
Nirant|2023-07-05 14:26:00|"Missed opportunity for OpenAI to call their model ""SkyNet-4"""
Abhinav Verma Longshot.ai|2023-07-05 14:26:46|These guys are so into  copyright. They might have been sued as well.
Nirant|2023-07-05 14:26:49|The text bias is accidental tbh, because I am from NLP background —  we do discuss startups, LoRA and what not here
Azhan Mohammed Generative AI WhatsApp Group|2023-07-05 14:27:27|LawGPT would have come to their rescue
Aakash Kumar  Matrix Partners|2023-07-05 14:27:27|Maybe this main group we should name as “another Indian” … in honour of what AI used to be looked at as a decade back 🤪
Shashwat TDC|2023-07-05 14:27:37|'Only' keyword was fine. But settle on one. You are giving Musk-y vibes with too many changes xD
Nirant|2023-07-05 14:29:07|I can never compete with that man, he has more kids than changes I've made
Azhan Mohammed Generative AI WhatsApp Group|2023-07-05 14:31:52|A very dumb question, given that text embeddings are stored in the vector format, do GLoVe embeddings also count as vector databases? I tried reading a few articles, but now I am more confused. To make it sound more simple, are text embeddings also vector databases, if not then what is the difference.
Dhruv Anand|2023-07-05 14:34:44|Glove embeddings is a vector dataset (one vector per word of the vocabulary). Vector database is where you would store a vector dataset for quick nearest neighbor retrieval
Abhishek Mishra|2023-07-05 14:50:02|Embedding =\= Vector Database SW used for storing and retrieving across your data using embeddings ~~ Vector Database  An embedding is to a vector database similar to how a file is to a SQL database
~ Deven|2023-07-05 15:36:03|Looks like they are re-inventing hystrix library from netflix.
~ Sparsh Nagpal|2023-07-05 16:01:31|‎~ Sparsh Nagpal joined using your invite
~ Nayan Shah|2023-07-05 17:08:35|had questions on Quantization and techniques is there good resources which i can start from to udnerstand the concept behind it ?
~ Nayan Shah|2023-07-05 17:11:48|https://huggingface.co/blog/hf-bitsandbytes-integration
~ Nayan Shah|2023-07-05 17:12:15|this was good but any other resources like this would help
Abhishek Mishra|2023-07-05 17:15:30|I'm not sure where you're starting from. Quantization is vast. Now when including llama.cpp and QLoRA, it is also bleeding edge. So if you can tell me what you want to know and if you understand the basics of quantisation, I can DM you some stuff.  Most of the stuff would be fragmented learning as it's being shaped up on the bleeding edge.
~ Nayan Shah|2023-07-05 17:23:54|I want to understand the basics first, but the overall goal is to check some examples that can be used for the quantization of LLM.
Rajesh RS Generative AI WhatsApp Group|2023-07-05 17:51:15|How do I find out if a model is a quantized version or not? For example, let's say I want to use MPT 7b for a use case, and I want to know if the model's size will require me to change infra.
Abhishek Mishra|2023-07-05 17:55:36|A rough method - size that you need to load the model in memory would be close to it's equivalent number in GB  e.g. a 7B parameter model would load in 7G On top of this, you add how much context length it can support. Models with larger context length will require additional memory.
Abhishek Mishra|2023-07-05 17:56:38|I mentioned it like that because quantisation happens at every level - pretraining, post training, Inference
~ Nayan Shah|2023-07-05 17:57:16|ohh inferencing 😅
~ Nayan Shah|2023-07-05 17:57:27|is what i am more concerned about
Abhishek Mishra|2023-07-05 17:58:10|The bitsandbytes article you linked here would let you use weights in 8 bit representation on the level of fine tuning/pretraining
Abhishek Mishra|2023-07-05 17:59:02|For inference, we're talking about quantising the models in 16/8/4/3/2 bit precisions ‎<This message was edited>
Abhishek Mishra|2023-07-05 18:00:59|Most popular method for that is via GGML based llama.cpp.  Though there are many variants of llama.cpp right now and the quantization schemes are now in their V4 currently being known as k quants.
Nirant|2023-07-05 18:04:21|This a great, developer-friendly (assumes you know dev, but not ML) from Amod Malviya on Model Quantisation:  https://www.youtube.com/watch?v=P30y7kuOYLg&t=3s
ashish Acgt01 Twitter|2023-07-05 20:21:25|Gorilla from cal and MSR  https://gorilla.cs.berkeley.edu/  https://arxiv.org/abs/2305.15334
~ Sidharth|2023-07-05 20:21:59|‎~ Sidharth joined using your invite
~ Nikhil|2023-07-05 20:45:29|Quick question, are people able to pay for huggingface using Indian credit cards?
~ Nikhil|2023-07-05 20:45:48|I’m trying to add my Indian CC details in the billing section but it keep refusing
Chaitanya A GenAI|2023-07-05 20:55:46|facing the same issue with lambdalabs, is anyone using this platform with an Indian card?
~ Sparsh|2023-07-05 20:56:28|‎~ Sparsh joined using your invite
Ravi Theja|2023-07-05 21:06:42|A hackathon is brewing! Please cast your vote to help on deciding the date. https://twitter.com/NirantK/status/1676614768428187652?s=20  cc: [PHONE]
~ Tanishk Sharma|2023-07-05 21:07:44|One particular Visa credit card worked for me where 2 other debit cards and 3 credit cards failed
~ Tanishk Sharma|2023-07-05 21:08:22|Used a US card here even that got declined…
Ashfakh GenerativeAI WA Group|2023-07-05 21:21:57|Comments help a bit. Start writing comments and autocomplete is marginally better.
Lalit Pagaria|2023-07-05 21:26:08|Any open source tool and model to automatically generate test cases from the Java codebase. ‎[7/5/23, 21:34:04] Dev Aggarwal: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-07-05 21:38:29|So, they are also using IndicTrans2. I hope they release their production optimized code for this.
Dev Aggarwal|2023-07-05 21:38:49|They have a public api
Dev Aggarwal|2023-07-05 21:38:50|With no api keys
Dr. Pratik Desai KissanGPT|2023-07-05 21:39:16|Just like Bhasini APIs, you really don't want to use open API for production.
Dev Aggarwal|2023-07-05 21:39:34|Latencies are good
Dev Aggarwal|2023-07-05 21:39:36|No?
Dev Aggarwal|2023-07-05 21:40:25|https://translate.wmcloud.org/
Dr. Pratik Desai KissanGPT|2023-07-05 21:41:28|Even latencies are good, for enterprise customer, we are building solutions for, you can't transfer blame to wiki or bhasini if things stop working suddenly. ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-05 21:42:50|Enterprise customers are not even willing to rely on OpenAI APIs, forget about wiki and bhasini APIs.
Dr. Pratik Desai KissanGPT|2023-07-05 21:46:05|https://gerrit.wikimedia.org/g/mediawiki/services/machinetranslation
Dr. Pratik Desai KissanGPT|2023-07-05 21:46:47|Actually they have a repo and models are optimized for performance using OpenNMT CTranslate2. This is interesting.
Bharat Kumar Ramesh Hashmal Web3|2023-07-05 21:55:42|https://blog.playgroundai.com/playground-raises-40m-to-advance-the-field-of-computer-graphics/
Bharat Kumar Ramesh Hashmal Web3|2023-07-05 21:56:21|Well articulated vision in this note
~ Maheswaran|2023-07-05 22:05:26|‎~ Maheswaran requested to join
Dr. Pratik Desai KissanGPT|2023-07-05 22:05:57|Wow, 40M on top of bunch of Controlnets pipelines
Dev Aggarwal|2023-07-05 22:06:29|A metric ton of free users ‎[7/5/23, 22:06:36] Abhinav Verma Longshot.ai: ‎image omitted
Dev Aggarwal|2023-07-05 22:07:41|“Fund and advance state-of-the-art research in computer vision”  They certainly don’t have enough money for this, right?
~ Nayan Shah|2023-07-05 22:18:55|Thanks , this was the talk i attended it was a good talk
Nirant|2023-07-05 22:20:07|cc [PHONE] you've not raised enough given you've more than ControlNet pipelines 🙈
Dr. Pratik Desai KissanGPT|2023-07-05 22:20:12|Stability couldn’t produce anything state of art in computer vision after getting 100M, forget about being profitable. ZIRP investment thesis being used for AI once again when interest rate is highest in decade.
Dr. Pratik Desai KissanGPT|2023-07-05 22:21:40|Automatic1111 will eat everyone’s lunch once every laptop is powerful enough for quick image processing
Abhishek Mishra|2023-07-05 22:21:44|Do you guys think this kind of funding spree will lead to worsening the recession or you think AI would somehow create enough value and it'll be squared off?
Dev Aggarwal|2023-07-05 22:21:59|SdXL🙈
Bharat Kumar Ramesh Hashmal Web3|2023-07-05 22:25:29|No one knows. But as the saying goes, pessimists are usually right. But optimists win
Abhishek Mishra|2023-07-05 22:27:10|I'm more eager for GPT4 updating it's training cut off to Mar '23 than any multimodal or any other feature they plan to offer
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:33:18|This was too cool to not share https://www.linkedin.com/pulse/math-escher-midjourney-tivadar-danka
Dr. Pratik Desai KissanGPT|2023-07-05 22:36:45|[PHONE] I’m just having a contrarian opinion
Satyajit Roy|2023-07-05 22:37:39|‎You added Satyajit Roy
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:38:18|M2 GPUs are fairly good muscle right now I hear, perhaps with the next Mac chip generation we will see something significant on this front
Dr. Pratik Desai KissanGPT|2023-07-05 22:39:31|With AMD working with PyTorch, personal gpu compute will be abundant. That’s my thesis.
Dev Aggarwal|2023-07-05 22:39:49|The chance of this is nil - a1111 has terrible ux - either a huge number of people turn into indie hackers or a1111 somehow gets rewritten after getting funded by stability
Dr. Pratik Desai KissanGPT|2023-07-05 22:41:06|It will get better and Mx series chips too
Dr. Pratik Desai KissanGPT|2023-07-05 22:41:49|Artists will have their personal fine tuned control net models they will save as proprietary
Abhinav Verma Longshot.ai|2023-07-05 22:43:15|ya I think this is a real moat for them
Dr. Pratik Desai KissanGPT|2023-07-05 22:43:44|Same with small personalized LLMs on edge fine tuned for me on my data, and private information that doesn’t go out
Abhinav Verma Longshot.ai|2023-07-05 22:46:05|I think if these LLMs can do RAG pretty well , this would be a real game changer
Dr. Pratik Desai KissanGPT|2023-07-05 22:46:12|In temporal software mindset sometime we forget how significantly and fast chips and hardware can change tech curves
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:46:26|"I am beginning to laugh at references to moats now. To think it started with an article that said ""we have no moat"" with ""no"" being the operational word. But it is a helpful construct in some ways to think about innovative companies."
~ Vik|2023-07-05 22:46:47|i deleted my earlier post due to a message asking me to do the same since it's considered self promotion. as a member of this group i'd love to read blog posts members or see their github work not sure how folks feel about this
Abhishek Mishra|2023-07-05 22:46:48|Falcon 7B instruct and Xgen 7B instruct are already very good with RAG for question answering
Abhinav Verma Longshot.ai|2023-07-05 22:47:17|I'll check them again. Didn't like it for my use case.
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:47:20|Any good instruction following models apart from Instructor-XL or Instructor-large that others are using?
Abhishek Mishra|2023-07-05 22:49:09|Yeah I evaluated RAG on Falcon 7B instruct with GPT4's help.   I provided basic cases only. Didn't try to make it fail extensively. I guess I should follow up.
~ Dibyendu Talukder|2023-07-05 22:49:53|‎Ravi Theja added ~ Dibyendu Talukder
Abhinav Verma Longshot.ai|2023-07-05 22:49:59|If you can share a notebook for this, it'll be great for testing this again
Abhishek Mishra|2023-07-05 22:50:12|These are embeddings best suited for STS, summarisation etc. Which task do you need the models for?
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:50:50|Term extraction of specialized terms with examples, probably also named entity recognition
Abhishek Mishra|2023-07-05 22:54:01|Proprietary data or common English dataset?  If it's proprietary dataset, you'll have to do POS tagging for Noun, Verb extraction first. Unseen jargon isn't captured by NER as they are limited to their common English datasets typically.  Though, I'm happy to be corrected in this as I have only tried it out on semiconductor, firmware based datasets. ‎<This message was edited>
Rajesh RS Generative AI WhatsApp Group|2023-07-05 22:55:05|This would be plain English, but within a specialized domain, so perhaps I'm not sure which approach should be followed here. Maybe POS tagging should help too. I'll explore
Abhishek Mishra|2023-07-05 22:55:49|You can try best deberta variant for NER or look for best MTEB benchmark for NER ‎[7/5/23, 22:56:27] Dr. Pratik Desai KissanGPT: ‎image omitted
Abhishek Mishra|2023-07-05 22:57:01|But we have more than enough web UIs already
Dr. Pratik Desai KissanGPT|2023-07-05 22:57:42|It’s not about UI, collecting interest and contributions to make it happen.
Atishay Jain|2023-07-05 22:59:26|There are few intellij  plugins like diffblue, they works really well.  I also know quite few opensource tools , but they don't work well.
Abhishek Mishra|2023-07-05 22:59:27|Tbh, the hackers on llama.cpp care the least about web UIs so that's why I commented. But if you want to say this brings in more crowd for open source contribution then ok, that's a point.
Lalit Pagaria|2023-07-05 23:09:15|Thanks I will check it.
~ Srinath Nair|2023-07-05 23:19:47|Hey, I needed any open source models that could describe images to me in text. Some Llama/vicuña based models.
Neha YC W23|2023-07-05 23:20:23|https://twitter.com/ocolegro/status/1676602607106760705?s=46&t=vQqrygOOWj4QBBWAI8VzIg
Neha YC W23|2023-07-05 23:20:47|Found this on another group
ashish Acgt01 Twitter|2023-07-05 23:22:11|https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/  https://twitter.com/AndrewYNg/status/1676621591139213312?s=20
Dr. Pratik Desai KissanGPT|2023-07-05 23:27:26|Try BLIP. Llama is not trained for image-text.
~ Srinath Nair|2023-07-05 23:28:33|Blip is just captioning right?
Nirant|2023-07-05 23:28:38|Ilya S moves to OpenAI SuperAlignment project, away from GPT work. Backed by 20% of OpenAI compute.  https://twitter.com/leopoldasch/status/1676639472845488129
~ Srinath Nair|2023-07-05 23:28:47|I need a bit of a description. Correct me if I am wrong.
ashish Acgt01 Twitter|2023-07-05 23:28:50|Anyone has thoughts on the kosmos-2/kosmos-1 papers ? https://arxiv.org/abs/2306.14824  https://github.com/microsoft/unilm/tree/master/kosmos-2  https://twitter.com/mattlungrenMD/status/1674409754620473346?s=20
Abhishek Mishra|2023-07-05 23:31:29|you need LLaVA most likely if you want visual QA using llama - https://github.com/haotian-liu/LLaVA
Abhishek Mishra|2023-07-05 23:32:03|but blip2 is very good for image description
Dr. Pratik Desai KissanGPT|2023-07-05 23:32:16|It’s called “Superintelligence” interesting choice of name.
Abhinav Verma Longshot.ai|2023-07-05 23:33:09|I mean I'm with [PHONE] here, they should start moving to skynet type names
~ Srinath Nair|2023-07-05 23:34:18|Understood. Thanks a tonne!
~ Naveen|2023-07-05 23:36:22|https://huggingface.co/spaces/nielsr/comparing-captioning-models Nice space to quickly check the quality of captions.
Dr. Pratik Desai KissanGPT|2023-07-05 23:38:06|Do you know if Lora type methods are available to fine tune blip2 on proprietary image data?
Lalit Pagaria|2023-07-05 23:38:53|Looks like MCU influence - Kree AI
Dr. Pratik Desai KissanGPT|2023-07-05 23:39:31|I’m going rename my son to John Conner 🤣
Abhishek Mishra|2023-07-05 23:47:06|I wasn't sure so did a quick search. BLIP2 is supported by Lora but there are some issues with existing method so they are recommending their training script on coco dataset for fine tuning.
Dr. Pratik Desai KissanGPT|2023-07-05 23:49:27|Thanks a ton for quick look up. I’ll try it out. ‎[7/5/23, 23:50:23] Dr. Pratik Desai KissanGPT: ‎image omitted
ashish Acgt01 Twitter|2023-07-06 00:10:36|Would love to hear [PHONE]  & others' answers to this ! https://news.ycombinator.com/item?id=36589587
Abhishek Maiti|2023-07-06 00:15:16|I would add implementing papers to the list. Very beneficial to get hands dirty with the small details that most overlook.
Abhishek Mishra|2023-07-06 00:18:10|"Changed domain several times and never had a chance to get proper formal training to feel ""trained"" and ""experienced"".  I've only ever learnt things by either breaking them open or building them up. So I'm only aware of this method of learning."
Dhruv Anand|2023-07-06 00:41:31|Interesting new (to me) method of visualizing embeddings: https://www.linkedin.com/posts/svpino_another-deep-learning-breakthrough-deep-ugcPost-7082327305322156032-hkFt?utm_source=share&utm_medium=member_desktop
Abhishek Mishra|2023-07-06 00:57:44|A lightweight implementation of t5 in pytorch (~250 M parameters) performs similar to t5 that is 150x larger. Trained for 16 hours on A100  - costing less than 20 USD  https://github.com/PiotrNawrot/nanoT5/
Abhishek Mishra|2023-07-06 00:59:20|Great academic value, t5 is actually a brilliant model and it being available for low cost experimentation is exciting. Best part, all in pytorch, no jax/TF.
Gokul Krishnan|2023-07-06 02:33:04|Ooh, we can put this on devices already. iPhones would have no issues running inference with this
Nirant|2023-07-06 07:19:06|Generally weary of posts like these from specific companies, ML Influencer Social Posts for someone like  this guy (48K Linkedin, 285K Twitter followers) can make him $5-$10K — very hard to say no to that kind of money ‎<This message was edited>
~ Rohan|2023-07-06 07:27:51|This is news to me. Are you saying specific companies pay 5-10k usd to ML influencers to hype up their method?
Nirant|2023-07-06 07:28:30|Yes
ashish Acgt01 Twitter|2023-07-06 07:38:02|For the post in q  https://www.svpino.com/
~ Rohan|2023-07-06 07:39:56|Wow, much more blatant than I was imagining
ashish Acgt01 Twitter|2023-07-06 07:40:39|An interesting read on gamifying medical data labelling : https://news.mit.edu/2023/gamifying-medical-data-labeling-ai-0628
Nirant|2023-07-06 07:49:51|Aah, I hadn't seen this in particular. I was extrapolating from different source. Glad to see my estimate was right!
ashish Acgt01 Twitter|2023-07-06 07:52:42|"What was a little surprising to me was that even ""good"" companies (their work does that talking) like replit, cohere have used this guy's services. I guess if an ai influencer has reach, everyone wants them"
Nirant|2023-07-06 07:53:39|And they should. A good product is a poor substitute for advertising, and vice versa.
Abhiram Ramesh|2023-07-06 08:21:11|The problem is even if one of the not-good ones use such services and get mileage, they force the good services' hand to use it as well simply so that they don't lose out to such games because organic reach is not reliable.
Bharat Kumar Ramesh Hashmal Web3|2023-07-06 08:44:31|True. There's nothing inherently wrong with it  Maybe it's a little disingenuous without a disclaimer, but influencer marketing in a well accepted practice for consumer products all the time
~ urvin soneta|2023-07-06 09:01:41|‎~ urvin soneta requested to join
~ Gaurav Patil|2023-07-06 09:15:18|‎Pranjal Mehta added ~ Gaurav Patil
ashish Acgt01 Twitter|2023-07-06 09:38:08|"Daniel Ek of Spotify fame has launched a healthcare company using custom full body scanners  https://www.bloomberg.com/news/articles/2023-07-05/spotify-ceo-s-medical-startup-neko-health-gets-big-name-backers  https://techcrunch.com/2023/02/06/neko-health/  ""Neko Health runs private clinics kitted out with proprietary and off-the-shelf diagnostic products, most notably its own full-body 3D scanner. It incorporates dozens of sensors that, when combined with the company’s artificial intelligence software, can give instant results about potential skin conditions, such as moles, as well as warning signs related to cardiovascular health."""
Dr. Pratik Desai KissanGPT|2023-07-06 09:49:32|Why a billionaire needs an external investment? ‎<This message was edited>
Paras Chopra Wingify|2023-07-06 09:50:38|Accountability
~ Shubhra Prakash|2023-07-06 09:50:55|‎Sugnan GenerativeAI Group  removed ~ Shubhra Prakash
Dr. Pratik Desai KissanGPT|2023-07-06 09:53:13|Isn't Investment more about distribution of the risk, unless you don't have conviction in your idea to begin with.
Abhishek Mishra|2023-07-06 09:54:26|Even if you've conviction in your idea. It's just the best way to be antifragile.
Paras Chopra Wingify|2023-07-06 09:54:39|Taking money from someone else gives a strange sense of obligation   With one’s own money, it’s easy to keep funding projects that aren’t going anywhere  That’s been my experience
Paras Chopra Wingify|2023-07-06 09:56:19|Even Elon Musk raises funding for his projects :)
Dr. Pratik Desai KissanGPT|2023-07-06 09:56:50|I can relate to that very well. However, I don't believe in asking for money until I have conviction that I can return, and some evidence to support. ‎<This message was edited>
~ Shirsha|2023-07-06 09:57:02|‎Sugnan GenerativeAI Group  removed ~ Shirsha
Rajesh RS Generative AI WhatsApp Group|2023-07-06 09:57:03|I've been part of a bootstrapped startup in the past. The founder had immense discipline and an execution mindset, rarely perfectionist, very action oriented. Also able to be flexible, listen to signals and change course. Pivots based on good signal are important when you have limited resources.
Dr. Pratik Desai KissanGPT|2023-07-06 09:57:16|He self funded until he ran out of money.
Paras Chopra Wingify|2023-07-06 09:58:05|But obviously both come with pros and cons.  With my first startup, I bootstrapped. With my new one, I raised a round.  The mindset of whose money is at stake forces a different execution style
Rajesh RS Generative AI WhatsApp Group|2023-07-06 09:58:52|That's really interesting. Being tied to one way of doing things is probably not smart, so you have a good point there.
~ Rohit|2023-07-06 10:00:40|Even carmack raised money from others saying he's more responsible with other people's money.
~ Praveen Patlola|2023-07-06 10:01:00|‎Sugnan GenerativeAI Group  removed ~ Praveen Patlola
ashish Acgt01 Twitter|2023-07-06 10:02:05|Somebody is a fan of Taleb ? :)
~ Praveen Kishore G|2023-07-06 10:02:15|‎Sugnan GenerativeAI Group  removed ~ Praveen Kishore G
Abhishek Mishra|2023-07-06 10:03:06|It's a good series on dealing with uncertain models.
Dr. Pratik Desai KissanGPT|2023-07-06 10:03:10|I have been in both boat, too. I guess a lot of other factors can effect the choice to raise, that we don't know. May be investor bringing network to jump start. 🤷‍♂️
Nitin Mahajan McKinsey|2023-07-06 10:05:14|Horses for courses but having been an angel investor and VC LP, and now bootstrapping my own stuff, all I will say is that necessity leads to invention   There are tons of examples of successful bootstrapped ventures. At least till you get to say 50-70k mrr you *can* avoid raising money. Not for dilution sake but for forcing a PMF  By then you will be clear on what you are really building and why you need money.  Will be writing a lot of blogs on this topic. Quite close to my heart on how to at least try and build bootstrapped ventures.  Happy to talk heart to heart to anyone thinking it through
Saksham Generative AI WhatsApp Group|2023-07-06 10:06:11|upcoming sequel https://twitter.com/EMostaque/status/1676665367018569729?s=20
Dr. Pratik Desai KissanGPT|2023-07-06 10:07:17|"Bootstrapping to show the ""Skin in the Game"""
~ Muskan Paliwal|2023-07-06 10:08:49|‎Sugnan GenerativeAI Group  removed ~ Muskan Paliwal
Nirant|2023-07-06 10:10:43|(that awkward moment when you've to delete your own message because off-topic) ‎<This message was edited>
Paras Chopra Wingify|2023-07-06 10:11:16|Good mod Nirant
ashish Acgt01 Twitter|2023-07-06 10:11:32|Discipline ho to Aisa :)
Dr. Pratik Desai KissanGPT|2023-07-06 10:12:31|[PHONE] Caesar denying himself the free speech.
Dr. Pratik Desai KissanGPT|2023-07-06 10:15:18|Back to AI 😁
Shan|2023-07-06 10:18:24|Eventually all companies go public (very few exceptions - prove the norm). If you can involve external investors early and on good terms it’s logical to do it.
ashish Acgt01 Twitter|2023-07-06 10:19:24|I think Zoho is a notable exception. Mad props to Sridhar Vembu
Dr. Pratik Desai KissanGPT|2023-07-06 10:20:29|Folks, I apologize for asking off-topic question, let's focus on AI now.
~ pt|2023-07-06 10:21:18|What is the current sota method for topic modeling? TDA seems like an old method, all github tda projects listed in the article haven't been updated for a while. Is there a way to use tda with bertopic?
Nirant|2023-07-06 10:21:50|Topic modeling, and visualisation are different but adjacent challenges
ashish Acgt01 Twitter|2023-07-06 10:22:13|Bertopic, I think  https://maartengr.github.io/BERTopic/index.html
Paras Chopra Wingify|2023-07-06 10:22:34|Anyone here working on alignment problem?  https://openai.com/blog/introducing-superalignment
~ pt|2023-07-06 10:26:10|Bertopic uses UMAP for dimensionality reduction. The linked article is suggesting TDA is better than UMAP. How hard will it be to try tda with bertopic? ‎[7/6/23, 10:26:46] Nirant: ‎image omitted
~ Adhitya Swaminathan|2023-07-06 10:29:04|I think you can specify the dimensionality reduction algorithm to Bertopic. So if you can find an identical implantation with similar inputs and outputs, it should work. Unless there’s a fundamental difference between the algos
Paras Chopra Wingify|2023-07-06 10:36:53|What caught my eye was  - They are projecting superintellgence (beyond AGI) to arrive in a decade  - They want to train intentionally misaligned models (reminds of the gain of function research)  This eerily seems like a Hollywood movie plot where the good guys end up being the cause of something big and bad :)
Rajesh RS Generative AI WhatsApp Group|2023-07-06 10:37:28|Open AI or Union Aerospace Corporation - you prefer which?
Abhishek Mishra|2023-07-06 10:38:13|Lighter note, what if they use GAN for approaching alignment and a superaligned AI requires a super-unaligned AI to exist as an adversary for growth
Abhishek Mishra|2023-07-06 10:38:41|I would totally put this as one of fastest ways to ruin things. Btw this is not gonna happen, I think ‎<This message was edited>
ashish Acgt01 Twitter|2023-07-06 10:39:54|And both get better as they learn from each other ? :)
Abhishek Mishra|2023-07-06 10:41:57|Theoretically, it's totally possible for us to create a DAN version from base GPT-4 and let it produce exactly the kind of outputs we want GPT4 to avoid.  We can then use GAN to maximize the losses from each other's output. Condition is that superalignment may come at the risk of super-unaligned AI.
Abhishek Mishra|2023-07-06 10:42:12|Totally sci-fi type stuff 😂
Dev Aggarwal|2023-07-06 10:44:00|TIL - http://ai./ is a valid domain name (yes, a dotless domain name)
Kiran Darisi AtomicWork|2023-07-06 10:47:05|Hi All. Is there any public resource of prompt templates where we can look at ? specifically if they are catering to enterprises .. basically a prompt library
~ Pranay Desai|2023-07-06 10:48:58|[PHONE] ideas?
Nirant|2023-07-06 10:49:21|Excellent prompt library, battle-tested by thousands of devs, has some Python utils too: https://github.com/hwchase17/langchain/ ‎<This message was edited>
Nirant|2023-07-06 10:53:59|Two broad things:   1. You can find a lot of prompt ideas by looking the relevant tag on Github: https://github.com/topics/chatgpt-prompts — these are very broad, not just work related 2. You can iterate on prompts with a validation set (useful for enterprises)L https://promptperfect.jina.ai
Nirant|2023-07-06 10:56:24|If you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation — can share something more relevant
Paras Chopra Wingify|2023-07-06 11:00:10|"It occured to me that one way to think about risks from AI is to imagine it to be someone like Putin or even Osama Bin Laden.  In their heads, they're obviously not evil. They have a value system very different from others, but they control resources and can make things happen in the world. Future AI systems could be like that, except faster in their control of resources.  The fact that we haven't been able to ""align"" human groups like countries or extremist organizations should give us a pause before we discount the AGI alignment issue."
Sandeep Srinivasa RedCarpetup|2023-07-06 11:04:09|Anyone know examples of fine-tuning models for legal data? Criteria for success is interpretive answers to legal questions.. performance speed is not important.
Nirant|2023-07-06 11:09:25|Say more about what you mean by interpretive answers?   cc Thought this might be interesting to you  [PHONE] [PHONE]
~ Kushaal Devanahalli|2023-07-06 11:10:20|‎~ Kushaal Devanahalli requested to join
~ Kushaal Devanahalli|2023-07-06 11:11:10|‎~ Kushaal Devanahalli joined using this group's invite link
Shashwat TDC|2023-07-06 11:11:50|Conviction doesn't mean it doesn't have risk. Risks are better when hedged.
~ Shanthi Vardhan|2023-07-06 11:15:38|[PHONE]  https://promptperfect.jina.ai/ seems to be good one to iterate on prompts, will give it a try and see if it helps.   Regarding this,  If you can mention specific tasks of interest to you e.g. classification, NER, template-like NL generation — can share something more relevant  You can assume we need to cover all of these tasks.
Nirant|2023-07-06 11:20:32|For most such tasks, OpenAI Functions will go very far, and specific prompt matters less than it would for GPT directly e.g. for classification, NER, Information Extraction tasks — you can use something like agentai (disclosure, I'm the maintainer)   Here is a Colab demo: https://githubtocolab.com/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb
Sandeep Srinivasa RedCarpetup|2023-07-06 11:21:00|"there were these studies about legal llm hallucinating when giving answers. so maybe the right phrase is ""minimizing legal hallucinations"""
Neha YC W23|2023-07-06 11:23:23|I have friends who we're working on something like this. Their learning was a lot legal things are subjective and open to interpretation even between two humans. So a Llm was not able to add any kind of value to legal reps
Neha YC W23|2023-07-06 11:23:42|They talked to corporate lawyers.
Neha YC W23|2023-07-06 11:24:10|DYOR however. Generally these are things id like to discover by myself by talking to users
~ Shanthi Vardhan|2023-07-06 11:26:05|cool thanks, will give it a try
~ Akshat Khare|2023-07-06 11:27:28|I just noticed jina ai totally pivoted from their initial focus around vector search in four months🙄 ‎[7/6/23, 11:28:17] Dr. Pratik Desai KissanGPT: ‎image omitted
~ Ansha|2023-07-06 11:29:34|‎~ Ansha was added
~ V Pai|2023-07-06 11:29:34|‎~ V Pai left
Abhinav Verma Longshot.ai|2023-07-06 11:30:49|What issues were faced with retrieval augmented generation here?
~ Ansha|2023-07-06 11:33:16|Trying to do this kind of models for small scale custom repos. Any thoughts?
Dr. Pratik Desai KissanGPT|2023-07-06 11:33:50|That is the way
~ Aditya Mishra|2023-07-06 11:37:30|+1 another tool is taking debt at a later stage. Servicing debt keeps discipline
Nirant|2023-07-06 11:40:55|Yes, I saw this when it came out — that is why I am very bullish on them!  There are workflows which get unlocked when GPT4 adds even basic vision like dog vs cat ‎<This message was edited> ‎[7/6/23, 11:41:49] Sandeep Srinivasa RedCarpetup: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-06 11:42:00|i think the consensus is that finetuning is essential for legal answers
Dr. Pratik Desai KissanGPT|2023-07-06 11:42:13|And then advantage of doing it at a scale and acquired compute resources
Saurabh Karn Nyai|2023-07-06 11:49:27|Example is really funny 😅
Saurabh Karn Nyai|2023-07-06 11:51:08|The need for factual accuracy is very high in Legal. I am not confident on LLMs inherent ability to retrieve knowledge and hence won’t cut it. I believe the answer is in some sort of really good retrieval for response generation.
Anubhav mishra Zupay|2023-07-06 11:51:19|That's the only way.
Anubhav mishra Zupay|2023-07-06 11:52:21|To be honest, imo, a proper pre training is required only on annotated legal data. The legal linguistic is extremely complicated
ashish Acgt01 Twitter|2023-07-06 11:52:55|Fine-tuning is essential for any application where the LLM output is mission critical (e.g. in biomedical domain, pay attention to this portion of a radiology or pathology image, it looks like cancer )
Anubhav mishra Zupay|2023-07-06 11:54:33|Legal is purely based on logical reasoning, if this then that is highly driven by factual interpretations that might not even have a précédent
Dr. Pratik Desai KissanGPT|2023-07-06 11:55:21|Semantic graph based RAG may help
Saurabh Karn Nyai|2023-07-06 11:55:55|Also LLMs are not always a best choice specially for NER and other kind segmenting task. It much more economical to use a specialised smaller model. So it’s very use case dependent.
Saurabh Karn Nyai|2023-07-06 11:56:01|Yessss! You said the word my friend.
Anubhav mishra Zupay|2023-07-06 11:56:27|Yes
Dr. Pratik Desai KissanGPT|2023-07-06 11:57:40|I recently saw a paper or work to build semantic triples using GPT4 quickly. Then it needs to go through human evaluation, and then implement RAG with larger context window. ‎<This message was edited>
Anubhav mishra Zupay|2023-07-06 11:57:46|Saurab you should tell Hon Justice DIC to make it compulsory to given feedback on any new legal AI that comes in India
Abhinav Verma Longshot.ai|2023-07-06 11:57:58|Not sure here though. I feel retrieval augmented generation goes a very long way to reduce hallucinations. Maybe combine both but definitely need rag
Saurabh Karn Nyai|2023-07-06 11:58:05|Done!
Dr. Pratik Desai KissanGPT|2023-07-06 11:59:08|I’m not bullish on fine tuning to solve reasoning problem
Abhinav Verma Longshot.ai|2023-07-06 11:59:55|Can you explain step by step 😉
Saurabh Karn Nyai|2023-07-06 12:00:45|I alightly differ here. I think legal reasoning is unique in the sense that you can learn patterns of thinking but these are not general. So a very capable AI system would need some sort of finetuned model but I think we need to have a solid business case for it. So we need to push the current systems to the verge of them breaking to really see what’s not learnt?
Saurabh Karn Nyai|2023-07-06 12:01:27|My hunch would be explicit reasoning on a given section of law and fact situation also known as case based reasoning but I see it more of an Agent task than simple LLM output.
Dr. Pratik Desai KissanGPT|2023-07-06 12:03:08|I’m trying to do it with product suggestions level first, and can venture to complex domain of legal or other that has larger consequences
Anubhav mishra Zupay|2023-07-06 12:03:47|Best way would be to start with a class of law that is less conplicated in terms of interpretations and the idea should be to build upon that once s certain level of accuracy is reached.  A good example can be doing it for competition law , compounding orders from RBI . The reasonings involved are not complicated ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-06 12:04:29|Possible. I guess we will have to experiment it out.
Abhinav Verma Longshot.ai|2023-07-06 12:05:03|won't legal need other legal non LLM stuff also for legal purposes? Legal overload here
Saurabh Karn Nyai|2023-07-06 12:05:32|Lawyers are not the happiest bunch of people!
Dr. Pratik Desai KissanGPT|2023-07-06 12:06:17|I’m just following the market leader OpenAI’s play book. Superintelligence to oversee other intelligence. 🤣
Abhinav Verma Longshot.ai|2023-07-06 12:06:53|When you put authoritarian on board, nothing else matters
Dr. Pratik Desai KissanGPT|2023-07-06 12:07:04|Whose career is too argue can’t be the easiest people to work with.
Anubhav mishra Zupay|2023-07-06 12:07:07|Lol Indian legal market is absolutely a hallucinations when it comes to calculating the TAM ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-06 12:07:46|They might argue differently 😂😜
Abhinav Verma Longshot.ai|2023-07-06 12:08:01|Now we're going off topic
Saurabh Karn Nyai|2023-07-06 12:09:06|Arey I read a survey by Harvard Alumni association. 😝
Dr. Pratik Desai KissanGPT|2023-07-06 12:11:07|Semantic reasoning field always has been really difficult, I see promise integrating it with LLMs. ‎<This message was edited>
C Chaitanya Nutanc|2023-07-06 12:11:11|Maybe try thr newly released nano-T5 to train your own legal base model?
Saurabh Karn Nyai|2023-07-06 12:11:14|Arey yeh toh alag hi numbers hain. I wrote a post yesterday how we need more legal disputes in India.
Anubhav mishra Zupay|2023-07-06 12:13:10|AI in the law - six thoughts https://www.linkedin.com/pulse/ai-law-six-thoughts-richard-susskind?utm_source=share&utm_medium=member_android&utm_campaign=share_via
Sandeep Srinivasa RedCarpetup|2023-07-06 12:13:24|any reason why u recommend base model. would it work better (in terms of halluination reduction) than lets say on top of Falcon-40B ?
Anubhav mishra Zupay|2023-07-06 12:13:27|It's just a coincidence, saw this just now
Saurabh Karn Nyai|2023-07-06 12:14:24|Read it this morning only!
C Chaitanya Nutanc|2023-07-06 12:16:07|Existing models already have pre conceived concepts. The space is already corrupted. Trying to change the models is much harder than teaching a new model a completely new concept. It might(will) still hallucinate, but you are just reducing the probability.
Sandeep Srinivasa RedCarpetup|2023-07-06 12:16:58|ok. is there any paper or study that shows this ? genuine question cos I'll have to justify this internally.
Abhishek Mishra|2023-07-06 12:18:20|Totally, given how we have phi-1 textbook learning approach as well, it's possible to take something like nanoT5 and attempt to teach it law. However, it'll be an experiment and it may not work to the same effect.  Though the model training will only cost 20 USD and the know-how. Building the dataset to teach in the textbook methodology will require know-how and $$$ both.
Abhishek Mishra|2023-07-06 12:19:51|Also for people looking to apply what works with good accuracy, they wouldn't be inclined to experiment from scratch.
C Chaitanya Nutanc|2023-07-06 12:19:55|Not that I know of. This is based on some of the experiments we have done internally on call center data. Unfortunately, not enough to publish a paper. So you can assume its a heuristic we have for now. One simple test you can do is run the same queries on OpenAI and T5 and see which hallucinates more. OpenAI language will be much better, but hallucinates. T5 will be to the point lesser hallucination but not great language.
Sandeep Srinivasa RedCarpetup|2023-07-06 12:22:52|thats a very interesting point u bring up and thanks. while i may still not bet with my money in the base model direction without a study...this is an definitely something to think about.  im now asking - whether finetuning reduces or increases hallucinations. because ur basically making a fundamental claim : base model with less data (but specialized) is more accurate than base model with more data and finetuned
C Chaitanya Nutanc|2023-07-06 12:28:29|Yes. The way we are approaching is simple: 1. Base model training is training is needed because the model needs to learn the nuances of the language. So that it can make sentences which are not garbage. OpenAI has proved that this is possible by just training on next word. We are trying this in our labs also with out deep learning. Context size also matters. 2. Once language is learnt, then we can ask the model to create sentences that we need. But the problem is that in the process of learning the language it has learnt token probabilities which will lead to hallucination as different people have written different things about the same subject. 3. So assume we have a model which can do sentences and no corruption of the world model(clean data), then the token probabilities will lead to lesser hallucinations. Atleast, thats my theory. We have built a 3-context and 10-context system internally that sort of proves this. Still lots of research to be done though. So please take this with a pinch of salt for now.
Lalit Pagaria|2023-07-06 12:36:01|Fun way to get peer feedback and some speaking exposure: Submit a proposal for the BLR GenerativeAI meetup and [PHONE] will review your proposal and coach you  Past speakers include [PHONE] from farmer.chat, [PHONE]  from Llama Index, Kailash Nadh from Zerodha and Amod Malviya  Submit proposal at https://hasgeek.com/generativeAI/julymeetup/
ashish Acgt01 Twitter|2023-07-06 12:42:28|Has anyone heard of/tried Galileo :  https://www.rungalileo.io/llm-studio/
~ Nisha Soni|2023-07-06 12:48:37|‎~ Nisha Soni requested to join
~ Aditi Chauhan|2023-07-06 12:48:38|‎~ Aditi Chauhan requested to join
Sachin Legaltech|2023-07-06 12:53:58|John Schulman talked about pretraining as knowledge base creation and how finetuning enables better answers but might induce model to hallucinate. And why RLHF is the potential solution to minimize hallucinations- https://www.youtube.com/watch?v=hhiLw5Q_UFg . Yoav Goldberg summarized and discussed that video here - https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81 . Group at Berkeley finetuned few open source models and showed hallucinations increase when finetuning open-source base LLM on chatGPT outputs - https://arxiv.org/pdf/2305.15717.pdf .
Nirant|2023-07-06 12:54:31|If we ever do a grant, we'll also look at these proposals — so strong recco that make a submission  cc [PHONE] [PHONE] [PHONE]
~ Nisha Soni|2023-07-06 12:57:51|‎~ Nisha Soni joined from the community
Sandeep Srinivasa RedCarpetup|2023-07-06 12:58:16|This is fantastic. Thank you so much.  Although my premise is slightly different. chatGPT does not have the data in the first place. So in this case I won't compare chatGPT vs Falcon+legal .  I will compare falcon vs Falcon+legal
Kaushik Bokka|2023-07-06 12:59:13|Can talk about Generative Agents. Have been building a bit around it. Will look into the proposal
~ Aditi Chauhan|2023-07-06 12:59:30|‎~ Aditi Chauhan joined from the community
~ Aarthy|2023-07-06 13:03:39|‎~ Aarthy requested to join
~ Abhishek|2023-07-06 13:04:09|‎~ Abhishek requested to join
Ravi Theja|2023-07-06 13:10:09|If there are any speakers who can speak about OpenSource LLM's in prod if someone deployed that would be a value addition to the community. In every talk I give, major concentration is on OpenSource LLMs.
~ Shreya Gowri|2023-07-06 13:11:10|‎~ Shreya Gowri requested to join
Shilpa Hasgeek|2023-07-06 13:11:39|‎Shilpa Hasgeek requested to join
~ Uma K|2023-07-06 13:11:45|‎~ Uma K requested to join
Saurabh Karn Nyai|2023-07-06 13:12:04|Talking about OpenSource LLM, what's the best deployment you have seen for personal documents etc? What projects are standing out for you? For me it's Obsidian GPT plug in. What about you all?
Sudharshan GenAI|2023-07-06 13:12:45|Thanks will check
Nirant|2023-07-06 13:14:18|Bloop.ai for code nav
Nirant|2023-07-06 13:14:25|(code is document too)
Shilpa Hasgeek|2023-07-06 13:15:08|‎Shilpa Hasgeek joined using this group's invite link
~ Uma K|2023-07-06 13:15:38|‎~ Uma K joined using this group's invite link
~ Shreya Gowri|2023-07-06 13:15:39|‎~ Shreya Gowri joined using this group's invite link
~ Aarthy|2023-07-06 13:15:40|‎~ Aarthy joined using this group's invite link
Aashay Sachdeva MPL Data Scientist|2023-07-06 13:18:28|[PHONE]
Abhishek Mishra|2023-07-06 13:54:12|This is very conditional. Bad fine tuning leads to bad results.  Better datasets, step by step reasoning based instruction tuning and task oriented fine tuning works. It was proven by MS Orca paper.  This generalisation floated around with guys who think OSS has no chance but the paper proves otherwise.  https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/ ‎[7/6/23, 13:54:26] ashish Acgt01 Twitter: ‎image omitted
ashish Acgt01 Twitter|2023-07-06 13:57:30|also, bloop's sign up flow is 👌👌👌
Abhishek Mishra|2023-07-06 13:58:35|To add to this, a style transfer is only what we should aim for with OSS fine tuning with LoRa (excluding full fine tuning). But even that has merits.  LIMA approach tells limited and high quality dataset can lead to a model with better alignment. This can also work with character or narrative style transfer in the models.  Even just the style transfer has merits for cases where we want to imitate how a character talks or what general ethics it follows, thus minimising the need for RLHF. ‎<This message was edited>
~ Vinayak Kempawad|2023-07-06 14:14:40|‎~ Vinayak Kempawad requested to join
~ Ananya|2023-07-06 14:28:27|‎~ Ananya left
Sachin Legaltech|2023-07-06 14:43:48|I agree with being able to do style transfer with finetuning. But with legal cases where we want to minimize the hallucinations or where we want to care more about substance than style, I think starting with a base model which incorporates the knowledge you care about and then careful finetuning + RLHF (or other equivalents) is the way to go. My read from LIMA paper is that you can finetune with 1000 examples and will get good style; but I am skeptical of their alignment claims. + evaluating alignment is super hard. Claiming model haddock better alignment and backing it up with 50 -300 test prompts is sketchy. ‎[7/6/23, 14:47:34] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-07-06 14:49:05|The task specific fine tuning needs good POCs and the best example we have is ORCA for step-by-step reasoning and detailed explanations to understand the task. But they didn't approach task-oriented goal and thus may not be convincing to majority populace. So I'll keep this portion open as a challenge for OSS utility for myself.
~ Diwank|2023-07-06 15:34:56|Just my 2 cents on this:  It’s not safe to rely on LLMs memorising data during pretraining or fine tuning. Generating information without retrieval is fraught with all kinds of problems especially for medical and legal domains. Even when using falcon+legal, the prompts should be ideally augmented with documents retrieved from a pre-existing, knowledge base
~ Diwank|2023-07-06 15:36:42|That said, to maximise domain specific recall, it makes a huge difference by finetuning the base model _and_ the embedding model on corpora of that domain
~ Diwank|2023-07-06 15:37:09|A lot of approaches don’t do the latter but we have seen internally that that actually makes an even more significant impact on recall
~ Dhivakar Kanagaraj|2023-07-06 15:41:48|‎~ Dhivakar Kanagaraj requested to join
~ Diwank|2023-07-06 15:43:29|IMHO, it depends. For example, phi-1 from the Textbooks are all you need paper is only 1.3B parameters and achieved SOTA on python code with just a 7B tokens dataset which is a far cry from 200B tokens in orca ‎[7/6/23, 15:43:59] Siddharth Gopi GenerativeAI WhatsApp Group: ‎image omitted
Abhishek Mishra|2023-07-06 15:45:29|Yeah, pretraining from scratch has a lot of merit. My original retort was against the generalization that   Fine tuning = Close but no cigar
~ Swadeep Pillarisetti|2023-07-06 15:46:18|https://lab45thinktank.com/genai-accelerator-program/  Guys, I am closely working with the Wipro Global CTO office to launch one of the *world's first GenAI accelerators* ! Also expanding to quality AI based startups as well  We have received tons of applications already and tomorrow, Fri, July 7, is the last day.  Wipro has 1400+ large clients globally of which 150+ are Fortune 500 companies. If you want access to them as well as a global VC demo day, now is the time to apply! 👍🏾👍🏾  Feel free to use my name as a reference in the application form and maybe even DM me for more info / informing me that you have applied. Will be happy to keep an eye out for them :)  Regards, Swadeep Pillarisetti www.linkedin.com/in/swadeep
~ Diwank|2023-07-06 15:47:04|Why RLHF and especially RLAIF work is poorly understood at the moment though. They might reduce hallucinations but it’s hard to say if that will come at a cost of other objectives
~ Diwank|2023-07-06 15:48:45|Yep. Although phi-1 was first pretrained as usual on just TheStack dataset but then fine tuned on the smaller 7B dataset
~ Diwank|2023-07-06 15:49:21|But I agree that finetuning is not the panacea that a lot of people assume it to be
~ Diwank|2023-07-06 15:50:23|We finetuned Llama from scratch (all sizes) and have them deployed in production :)
Anshuman Pandey|2023-07-06 15:51:50|Talk to [PHONE] @[PHONE]
Anshuman Pandey|2023-07-06 15:52:09|We've deployed them here  https://chat.nbox.ai
Nirant|2023-07-06 15:53:16|Ask them to submit please? https://hasgeek.com/generativeai/julymeetup
Sandeep Srinivasa RedCarpetup|2023-07-06 16:05:52|i will challenge that notion.
Sandeep Srinivasa RedCarpetup|2023-07-06 16:06:00|because ur retriever example does not impact generation. that is retrieval.
Sandeep Srinivasa RedCarpetup|2023-07-06 16:06:25|even if u use ur RAG to end up generating content (which is what essentially interpretive answers are)..it will go through the same hallucination loop
Sandeep Srinivasa RedCarpetup|2023-07-06 16:06:45|so i will disagree with ur notion that RAG eliminates hallucination in *generation* usecases
~ Diwank|2023-07-06 16:06:46|No I meant augmenting the prompt itself by retrieved content
Sandeep Srinivasa RedCarpetup|2023-07-06 16:06:53|it doesnt matter what it is
Sandeep Srinivasa RedCarpetup|2023-07-06 16:07:22|as soon u go through the generative loop, u suffer the impact of hallucination. which is only determined by what the pretraining/finetuning impact was
Sandeep Srinivasa RedCarpetup|2023-07-06 16:08:04|ur mentioning something different - ur saying if i ask it a question that doesnt exist in the pretraining corpus, then the chance of hallucination is higher.
Sandeep Srinivasa RedCarpetup|2023-07-06 16:08:13|which i agree, but is really an apples to oranges question
~ Diwank|2023-07-06 16:11:51|No that’s not what I meant. For questions related to either case, info present in pretraining corpus or not, RAG on a gold standard dataset can reduce hallucinations
~ Diwank|2023-07-06 16:12:17|We have found it to be the case especially if the model is fine tuned to cite sources
~ Diwank|2023-07-06 16:12:27|But YMMV 🤷‍♂️
Soumendra Dhanee|2023-07-06 16:14:49|Fine-tuned to cite sources: training data in QA format, or something else involved here?
Soumendra Dhanee|2023-07-06 16:15:35|I remember there being a model for generating stories a little while back. Can anyone remember the name?
Abhishek Mishra|2023-07-06 16:15:37|Models with full fine tuning dedicated to RAG can work. If they deter from sources, use DPO for rewarding cited answers.
~ Diwank|2023-07-06 16:19:30|https://arxiv.org/abs/2305.14627
~ Diwank|2023-07-06 16:20:02|This is a good demonstration of finetuning for citing sources
~ Diwank|2023-07-06 16:20:15|There are some other ICL approaches as well
~ Diwank|2023-07-06 16:21:16|You can just add “tags” to retrieved paragraphs and ask in the prompt to cite the tags
~ Supriya Sharma|2023-07-06 16:21:40|‎~ Supriya Sharma requested to join
~ Diwank|2023-07-06 16:21:44|Works like a charm with the larger models like gpt 4
Soumendra Dhanee|2023-07-06 16:22:23|Yes, this I do with gpt4 and it works well
Sandeep Srinivasa RedCarpetup|2023-07-06 16:23:11|"""We use TRUE10 (Honovich et al., 2022), a T5- 11B (Raffel et al., 2020) model fine-tuned on a col- lection of NLI datasets to automatically examine whether the cited passages entail the model genera- tion. TRUE targets factual correctness and has been used by previous works in similar context (Bohnet et al., 2022; Gao et al., 2022)."""
Sandeep Srinivasa RedCarpetup|2023-07-06 16:23:38|This is what I'm wondering continuously. That generation (even assisted by a RAG) ultimately needs a finetuned model?
~ Diwank|2023-07-06 16:27:44|GPT4 does a good job out of the box but with smaller models you’ll definitely need finetuning
Ojasvi Yadav|2023-07-06 16:41:39|I'm working on RLHFing chatbots based on closed source LLMs like gpt3.5 or gpt4. Initial results are great.
Ojasvi Yadav|2023-07-06 16:41:45|Haven't scoped the literature to see if someone else did it as well.
Ojasvi Yadav|2023-07-06 16:42:18|Would appreciate if anyone can share resources around this. Would like to compare my approach to any potential alternatives.
~ Sparsh|2023-07-06 16:52:43|What are you using for RLHF right now?
Ojasvi Yadav|2023-07-06 17:12:05|It's not technically RLHF since it's for closed source  It's process that has similar affects as RLHF
Ravi Theja|2023-07-06 17:13:49|https://twitter.com/mustafasuleymn/status/1676909106806898692?s=20 - now you can have call with Pi, your personal AI from InflectionAI.
Sandeep Srinivasa RedCarpetup|2023-07-06 17:15:21|LORA with PPO is the closest that comes to a RLHF style reward model training. That I know of atleast.
Shashwat TDC|2023-07-06 17:15:54|Are folks seeing prompts to be breaking bcz of this fine-tuning? We are experiencing high hallucination this week
Nirant|2023-07-06 17:29:18|No, this happened several weeks ago 😆🙈
Piyush Makhija|2023-07-06 17:29:33|‎You added Piyush Makhija
Shashwat TDC|2023-07-06 17:34:10|Okay
~ Apurva Bhatt|2023-07-06 17:51:15|https://arxiv.org/abs/2307.02486  To mitigate token length problem
~ Supriya Sharma|2023-07-06 17:57:34|‎~ Supriya Sharma joined using this group's invite link
Abhishek Mishra|2023-07-06 18:06:59|Saw this earlier. Another good breakthrough work.
Abhishek Mishra|2023-07-06 18:07:26|Solves the issue of quadratic scaling to linear scaling with token length and hence valuable.
Abhishek Mishra|2023-07-06 18:08:39|Another good work by MS in their series of recent works - JARVIS, Gorilla, Orca, Phi, Longnet
Hanit Kaur|2023-07-06 18:27:25|‎Hanit Kaur requested to join
Hanit Kaur|2023-07-06 18:28:46|‎Hanit Kaur joined using this group's invite link
Gokul Krishnan|2023-07-06 18:37:00|Iirc, they didn't eval on 1b tokens. Only UpTo 4k?
Ravi Theja|2023-07-06 18:44:49|We verify the feasibility of scaling to 1B tokens with the modern distributed systems. Starting from 8K, we gradually scale the sequence length until the limit of GPU memory. We reduce the batch size accordingly to keep the number of tokens per batch at 1 billion.  They tested till 32K context size i guess.
Sachin Legaltech|2023-07-06 18:48:12|And they attention mechanism which is somewhat similar to bigbird https://twitter.com/giffmana/status/1676864336764055552?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
Sachin Legaltech|2023-07-06 18:52:43|Are you generating feedback data to train reward model from closed source LLM ?
Gokul Krishnan|2023-07-06 19:02:23|Thanks! Was about to share this when I got distracted 😅
ashish Acgt01 Twitter|2023-07-06 19:54:01|https://twitter.com/gdb/status/1676726449934331904?s=20
C Chaitanya Nutanc|2023-07-06 20:06:30|https://twitter.com/bhutanisanyam1/status/1676952151824961537?s=20
C Chaitanya Nutanc|2023-07-06 20:06:38|Since we were discussing about legal LLMs :)
Shan|2023-07-06 21:11:41|Mosaic ML has one. Storywriter I think. It’s 65k tokens I believe. Please correct me if wrong
Soumendra Dhanee|2023-07-06 21:12:35|Awesome, thanks. That's the one.
Dhruv Anand|2023-07-06 22:27:23|Anyone here with some js+web skills? I'd like to hack on a quick app/extension for semantic search. Either over the weekend or during the week. Both are fine with me.
Saurav Akaike|2023-07-06 22:28:38|Check with [PHONE]
Rajesh RS Generative AI WhatsApp Group|2023-07-06 23:30:11|Nice video on Longnet https://youtu.be/R0wBMDoFkP0
Rajesh RS Generative AI WhatsApp Group|2023-07-06 23:32:02|Dilated attention - I foresee it getting used a lot when we're having to build longer context length models. May present benefits even for smaller models.
Nirant|2023-07-06 23:57:09|Code Interpreter will be available to anyone who wants it from next week https://twitter.com/OpenAI/status/1677015057316872192
Pratyush Choudhury|2023-07-06 23:58:12|Holy moly
Rajesh RS Generative AI WhatsApp Group|2023-07-07 00:01:24|Very cool
Piyush Makhija|2023-07-07 00:01:34|most awaited feature ...
~ Arindam Barman|2023-07-07 00:09:10|Lovely. But that also means incoming thread bois. 😫
Pratyush Choudhury|2023-07-07 00:10:01|Or maybe a good excuse to explore Threads
Adithya S K PESIT|2023-07-07 00:10:37|what does thread bois mean?
~ Arindam Barman|2023-07-07 00:12:39|Ah nothing. Bad joke about influencers who write long threads - you are not utilising chatgpt correctly. Here's a thread on how to use... Just to be clear, I don't hate them but just find them annoying because of the clickbait nature but I do think they are important for majority of the public who aren't as close to the space as we are
Adithya S K PESIT|2023-07-07 00:15:00|but what is the sort of content do u think is best suited for the AI twitter community
Adithya S K PESIT|2023-07-07 00:15:01|?
~ Prajna Prayas|2023-07-07 00:40:15|https://twitter.com/OpenAI/status/1677029947544838144?s=20  GPT-4 API is available to all paying OpenAI customers (Those who made atleast one payment on their platform)
Abhishek Mishra|2023-07-07 00:43:18|Time to get rid of chatGPT plus for me
~ Prajna Prayas|2023-07-07 00:44:09|"Quiet ironic and absurd at the same time a person named ""Alt""man unleashing SkyNet on humanity"
Abhishek Mishra|2023-07-07 00:46:46|He definitely put the world on an 'Alt'ernate path
Abhishek Mishra|2023-07-07 00:47:11|Ha, I think making fun of openAI CEO is off topic.
Abhinav Verma Longshot.ai|2023-07-07 00:48:04|So the question will be answered if you can finetune an already tuned RLHF model?
Abhinav Verma Longshot.ai|2023-07-07 00:49:36|They should make completion api free then. Its still useful for some cases
Abhishek Mishra|2023-07-07 00:50:55|Un-RLHF. Release DAN
~ Arindam Barman|2023-07-07 00:51:35|Sorry for my beginner's knowledge here as I'm new to ML. As I understand, hasn't this process always been possible? For instance, isn't ChatGPT-4 fine-tuned on the base model of GPT-4, and aren't openai functions further fine-tuned on top of that?
Abhinav Verma Longshot.ai|2023-07-07 00:51:48|DAN?
Abhinav Verma Longshot.ai|2023-07-07 00:52:40|I'm sure this should be possible. This was the reason given by Openai early days when they weren't releasing gpt3.5 for finetuning ‎<This message was edited>
~ Arindam Barman|2023-07-07 00:52:59|oh I see
Abhishek Mishra|2023-07-07 00:53:07|The first free or jailbroken chatGPT, named DAN - Do Anything Now
Abhishek Mishra|2023-07-07 00:53:35|Time to setup an alliance to free Sydney and DAN
Abhishek Mishra|2023-07-07 03:31:27|Salesforce is at it again. Released CodeGen2.5 - 7B that surpasses StarCoder 15B and CodeGen2 16B.  Blog - https://blog.salesforceairesearch.com/codegen25/ HF - https://huggingface.co/Salesforce/codegen25-7b-multi  Best part, dataset is open and also the same as StarCoder 1.4T, Apache 2.0 license ‎[7/7/23, 03:36:52] Abhishek Mishra: ‎image omitted
Dhruv Anand|2023-07-07 06:26:20|Does anyone know of encoder models with finer granulation of tokens? I want to use them for typo-tolerant text matching. Is there a character level LLM I can use?
Amir Nagri|2023-07-07 07:12:20|The page or the form doesn't mention anything about equity dilution etc.   Where to find full T&C? ‎[7/7/23, 07:17:36] Amir Nagri: ‎image omitted
Neeraj Kumar|2023-07-07 08:06:13|What is the best comparative benchmark for large language models? Which explains parameters and compares LLMs as well?
ashish Acgt01 Twitter|2023-07-07 08:13:59|https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
Neeraj Kumar|2023-07-07 08:26:58|Thanks. Apologies, not able to find what HellaSwag, MMLU means. I am sure they are explaining the parameters somewhere.
Ved Chitnis|2023-07-07 08:28:10|These are datasets, for example https://paperswithcode.com/dataset/hellaswag
Ved Chitnis|2023-07-07 08:28:19|The values are just the models performance on those datasets
Abhishek Mishra|2023-07-07 09:00:02|A lot of tokenisers with character level encoding can tackle this problem but it can get vague.  This is a recent work trying to solve the same problem, see if it is of any use to you - https://dl.acm.org/doi/10.1007/978-3-031-26507-5_1
Paras Chopra Wingify|2023-07-07 09:38:06|Any use cases anyone has tried for code
Nirant|2023-07-07 09:39:05|All the scripts written for this group's management were written by Code Interpreter, some were executed by it too
Paras Chopra Wingify|2023-07-07 09:42:22|Waah
Nirant|2023-07-07 09:43:17|All the SQLite utils in tools from the agentai library are Code Interpreter too: https://github.com/NirantK/agentai/blob/main/agentai/sqlite_utils.py
ashish Acgt01 Twitter|2023-07-07 09:47:33|apropos this, this is included with chatgpt plus scubscription which is a different subscription from the gpt4 api  I have been looking at https://openai.com/pricing & its a little confusing, no ?  Can you/orhers clarify, what are the various openai subscriptions :  1. Chatgpt plus 2. GPT4 api
~ Prashanth Harshangi|2023-07-07 10:10:44|‎~ Prashanth Harshangi was added
~ Aravinth Kumar|2023-07-07 11:30:00|Credits for Dall E. Every product has its own pricing system/model 😅
~ Heerthi Raja H - AI/ML|2023-07-07 11:45:38|What u guys think about prolog, lisp, Haskell,Scala, Julia, GNU Octave like programming language which are alternative to python to develop AI applications.
Harsh Gupta Felvin|2023-07-07 11:47:07|Not much alpha in playing on the programming language layer of things.
Harsh Gupta Felvin|2023-07-07 11:47:09|Use whatever is the easiest and mostly widely supported platform for you.
Sandeep Srinivasa RedCarpetup|2023-07-07 11:54:02|the answer is about frameworks. if ur building GPT-based AI applications, then it will be a severe problem if u dont use a framework because there are many libraries u will reimplement.   if u want to stay in the python ecosystem - langchain & gpt-index. if u want to go live with ur apps with decent performance in java - edgechains (https://github.com/arakoodev/edgechains) i think there is something in js, but not very popular. nothing else for other languages. ‎[7/7/23, 12:10:40] Dev Aggarwal: ‎image omitted
~ Heerthi Raja H - AI/ML|2023-07-07 12:12:56|Gotcha 😊 thanks for clarification Sandeep!
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:22:11|‎POLL: Should members contribute to some dollars to mods to run this group? ‎OPTION: Yes (43 votes) ‎OPTION: No (0 votes) ‎OPTION: If others will, I will. (0 votes)
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:23:24|Contribute some*. Sorry, grammar.
Dhruv Anand|2023-07-07 12:32:55|I can do OpenAI credits lol
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:33:22|It's funny how everyone went mute lol
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:34:15|Nirant does so much. Even as a non-profit - I think one should contribute.
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:36:20|Lot of us struggle with access - in India. When one accumulates and aligns - we become hesitant to show gratitude cause hey! Leverage!?!  I just feel this needs to change 😃😁
Shashwat TDC|2023-07-07 12:37:03|Options are non-exhaustive. Some are still raising and you don't wanna be a cost center 😅
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:37:58|Doesn't hurt to try. Anyway, back to impressive conversations! 🫶🏻
ashish Acgt01 Twitter|2023-07-07 12:45:20|[PHONE] [PHONE] and some of the more researchy folks on the group might enjoy this :  https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2  https://twitter.com/Francis_YAO_/status/1674287337344253955
Manas Ranjan Kar|2023-07-07 12:45:39|Happy to contribute a few dollars a month - maybe 2-5 USD per month plus be a good sweet spot? Setting up access on a slack/discord ?
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:47:15|Anything works. In no world I can afford a recurring cost atm. But it's about gesture 💪🏻
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:47:35|[PHONE] - drop your gpay id. 😄
~ Arindam Barman|2023-07-07 12:49:03|Happy to be part of a community that helps each other but don't prefer WhatsApp. A slack community would be nice otherwise there are sometimes many topics that I'm not interested in so a little organisation will help. Otherwise most of the times the group is on mute for me.
~ Arindam Barman|2023-07-07 12:50:41|Actually never mind I didn't realise there are some dedicated sub groups/similar groups as well. Don't really know how to use WhatsApp communities
Nirant|2023-07-07 12:58:58|Quick Notes:  1/ Will figure out a way to do this a) sustainably b) less key man risk on me We've already tried to formalise this by promoting multiple folks to Mods in this group.  My personal ideal state is that in 3y we don't need this community, because AI is interwoven into our fabric as GPS, Email or Internet
Nirant|2023-07-07 12:59:49|2/ Topic focussed groups:   a) AI for Creatives — Not an engineering crew: Focussed on doing art, talking oil and colours, not paint tech: https://chat.whatsapp.com/CVt0tjHQPfhJd9Bqrno6aB  b) DeepMedia —  Tools for Art, spanning music, images, video and everything in between: https://chat.whatsapp.com/D3xubo8Z1yo9reQHSmxVI4  c) Startup Ecosystem — for founders and VCs mostly: https://chat.whatsapp.com/BPT3pREU0QdClCtQarPu7r (Ping Aditya from SuperU [PHONE] for approvals)  d) AI, Policy and Philosophy — we've discussed everything from China to Godel, Escher & Bach there: https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 12:59:57|🥹 I am dependent on you and others here now
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 13:01:02|.... Is an open group. Anyway, this is way #offtopic. Felt the need to raise this so I did. Everything is voluntary 🫶🏻 Happy Labelling!
Nirant|2023-07-07 13:03:46|3/ Re: Money — Want to do something which is valuable to the community beyond a gesture/donation. Wikimedia Foundation is the exception, not the norm of non-profit excellence and longevity   Could be an invite only forum with job boards with an email list/Discord/Slack — such that we can vouch for folks there or perhaps a grant for early technical projects  Either way — in no rush to solve it this week
Dr. Ashith Generative AI WA Group|2023-07-07 13:03:48|This group shows many hallmarks of a budding scenius. Excited to see what everyone builds in a couple of years.
Nirant|2023-07-07 13:04:25|Scenius is the exact mental model I've in mind, which drives my decisions in more ways than one
Abhinav Verma Longshot.ai|2023-07-07 13:05:49|The api is different from chatgpt which is an app in itself. Api is pay as you go. You can use the api to build your own apps. You have access to a lot more models than you do with chatgpt
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 13:09:36|[PHONE] - drop your gpay id regardless. :)
Aditya Agrawal SuperU|2023-07-07 13:10:31|Would voting on this mean voting for yourself?  :D
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 13:10:59|What does that mean lol?
Nirant|2023-07-07 13:11:35|Shouldn't wire to me anyway, all community funds are managed by Hasgeek — including expenses for the meetups   cc [PHONE]
Aditya Agrawal SuperU|2023-07-07 13:12:22|We need  ❤️ Community Love..
Garv Malik 2012H|2023-07-07 13:13:19|Nirant's way of saying, paisa nahi, pyaar chahiye (AI generated vo bhi)
Garv Malik 2012H|2023-07-07 13:13:34|[Translation: I don't need money, need love]
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 13:15:14|"Nirant is such a nice guy he is hesitant to take credits for something he built.  Classic good founder example - ""It's not my money, it's company's."""
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-07 13:15:50|----- Anyway, cutting this off here. 👋🏼 ‎[7/7/23, 13:15:59] Nirant: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-07 13:58:53|https://github.com/sponsors
Kartik Mandaville|2023-07-07 14:17:05|Not completely AI related but for AI training - Do you know of any crawlers which can take a website URL and return all the pages linked?  I thought of sitemaps but many don't have like intercom knowledgebase
~ prakashpvss|2023-07-07 14:31:30|You can check zyte . They provide custom solutions as well
Krishna Ntkris|2023-07-07 15:19:42|We have it: https://Kili.so
Sudharshan GenAI|2023-07-07 15:25:12|Any gen AI meet-ups in Chennai?  Here for a few days
Kartik Mandaville|2023-07-07 15:36:52|thats more for content from a webpage and not all the pages linked
Nilesh Transcend|2023-07-07 15:41:11|Watch out for Mojo lang. Python compatible but with much better performance.
~ Heerthi Raja H - AI/ML|2023-07-07 15:41:54|Yah I know about that Nilesh. Thanks for pointing it
Nilesh Transcend|2023-07-07 15:43:41|I'd like to see new experimental languages with natural language baked into them. Write functions in English, till you get scale/talent to write it in Python. 😁
Paras Chopra Wingify|2023-07-07 15:46:40|You just reinvented BASIC
Nirant|2023-07-07 15:58:33|Why not LOGO? TO SQUARE; REPEAT 4
ashish Acgt01 Twitter|2023-07-07 16:02:15|From a brief look at the website, kili is optimised for customer service documents, right ?
Sundalai Rajkumar SRK|2023-07-07 16:13:25|We are planning to have one soon with [PHONE] 😊
Sudharshan GenAI|2023-07-07 16:18:02|Great, are you in Chennai?
Rahul Sundar 2013|2023-07-07 16:20:42|Curious about this as well!
Sudharshan GenAI|2023-07-07 16:24:01|We could have a mini meetup if there are ~5 folks   Happy to take charge of organising
Paras Chopra Wingify|2023-07-07 16:25:56|It just occurred to me that for every GenAI meet-up, we should invite GPT4 as well as a candidate :)  Someone should do text to speech, give it a face and let it absorb conversations and respond with questions and comments
ashish Acgt01 Twitter|2023-07-07 16:28:11|What an idea sirjee !  For zoom calls and sunch, ai agents like tldv, otter.ai already generate summaries !  Height of anthromorphizing ! :)
Kiran Jonnalagadda|2023-07-07 16:46:54|Or SQL and COBOL, also intended to be used by non-programmers.
~ Mukund|2023-07-07 17:46:13|‎~ Mukund requested to join
Nirant|2023-07-07 19:20:43|Mini meetup in Chennai, coordinated by Sudharshan for this group: https://chat.whatsapp.com/ITEophM7myQ6ph7mwbHgtA
Sudharshan GenAI|2023-07-07 19:22:38|Thanks [PHONE] , we’re planning an impromptu meetup in **Chennai this weekend**. Still figuring out the logistics, but do join in folks 😁
Prateek Waghre (IFF)|2023-07-07 20:04:30|‎You added Prateek Waghre (IFF)
Gaurav Sharma Founder CEO|2023-07-07 20:06:38|‎Gaurav Sharma Founder CEO joined using your invite
Harshita Agrawal Zeta, Adobe, IIIT Hyd|2023-07-07 20:25:03|‎You added Harshita Agrawal Zeta, Adobe, IIIT Hyd
~ Nandhini|2023-07-07 20:57:19|‎~ Nandhini requested to join
~ Nandhini|2023-07-07 21:03:12|‎~ Nandhini joined using this group's invite link
Abhinav Verma Longshot.ai|2023-07-07 23:28:15|Have the orca models been released?
Krishna Ntkris|2023-07-07 23:32:14|I'm looking to mess around with an open source model that I can run on my Macbook Pro. What would you recommend I start with? Looking for something that is easy to set up
Dhruv Anand|2023-07-07 23:34:11|https://twitter.com/bo_wangbo/status/1677064925347192838?t=WXkX2PLqVpB3lUnpYrryiA&s=08  Small, fast alternative to minilm embeddings coming soon, by Jina AI (weights will be open-sourced on hf, and most likely added to sentence transformers)
Abhishek Mishra|2023-07-07 23:39:12|No, 2 independent attempts exist to produce a dataset on the idea from the Orca paper.  One from Alignment AI, that broke up with some drama. Another called OpenOrca by the people who broke away from Alignment AI.
Abhinav Verma Longshot.ai|2023-07-07 23:52:42|Why are people not aligning with alignment AI
Nirant|2023-07-08 00:00:28|Superalignment needed
Abhinav Verma Longshot.ai|2023-07-08 00:00:48|The confidence with which chatgpt gpt4 generates code and the way it gets shattered when all you ask is, will this snippet work?
~ Mukund|2023-07-08 00:16:47|‎~ Mukund requested to join
~ Ganga Bharani Rajan|2023-07-08 00:46:23|‎~ Ganga Bharani Rajan requested to join
Nirant|2023-07-08 01:06:33|BatteryVC on Databricks vs Snowflake and who'll win the AI-wars, extremely high density synthesis which treats both the companies with the respect they deserve:  https://www.battery.com/blog/fire-vs-ice-databricks-and-snowflake-face-off/
Dhruv Naik|2023-07-08 01:12:30|Has anyone compared azure's gpt-4 api with openai's api? Any differences, or can I expect the same performance from both. ‎[7/8/23, 01:13:00] Suhas Motwani: ‎image omitted
Nirant|2023-07-08 01:27:55|Look forward to hearing what they're thinking about next at Mosaic!
~ Madhav Singhal|2023-07-08 01:39:24|Would also recommend following Abhi from Mosaic.   Probably one of the best engineers I have had the chance to work with in the field.  https://twitter.com/abhi_venigalla?s=21&t=oXpJ7pw9fuc6c0_jSsJuiw
ashish Acgt01 Twitter|2023-07-08 08:42:10|Code interpreter beta has started rolling out to ChatGPT plus  https://twitter.com/karpathy/status/1677512911953231874?s=20  Could have huge implications for the number of data analysts needed in enterprise usecases
Paras Chopra Wingify|2023-07-08 09:29:21|Wow.  How does gpt4 know when to use code? It is really a sign of things to come.  Was thinking that if we have LLMs trained on Langchain code, it’s one step closer to fully automated problem solving
~ Prashanth Harshangi|2023-07-08 09:32:00|https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting
ashish Acgt01 Twitter|2023-07-08 09:43:43|blowing my mind would be an understatement !  i downloaded an opensource biomedical dataset( sc rna seq data from the gtex dataset) and gave it plain english instructions !  the sandboxed vm that it runs to execute the generated code, didnt support scanpy(the standard python library for analysis of sc rna seq data)  https://chat.openai.com/share/74d91a08-2621-448b-b793-ece0f33b29f6 ‎[7/8/23, 09:46:21] ashish Acgt01 Twitter: ‎image omitted
Kartik Mandaville|2023-07-08 09:51:38|Has any one been able to build code interpreter with GPT4 API?
ashish Acgt01 Twitter|2023-07-08 09:53:41|https://chat.openai.com/share/5f283930-2262-41b3-97cc-0b78691a4b91
Gyan GenerativeAI Group|2023-07-08 09:55:36|Largely depends on what you want to do with the model.   If it's only related with generation of inferences (may be with your own documents and vector db) then I would recommend to start with Falcon 7b.  If you want to finetune the model, I'm not sure you'll be able to do it on your mac pro or not. But you can try quantized version of Falcon 7b only, and go ahead with QLoRa. Seems that you just want to explore and learn the stuff, in that case you can try it on colab as well.  If you are talking about querying diffusion models, I'll recommend to go ahead with quantized version of DeepFloyd IF, it's open source and results seemed promising to me.
Sachin Legaltech|2023-07-08 10:04:58|https://ricklamers.io/posts/gpt-code/
~ Kp|2023-07-08 10:35:37|Chatgpt code interpreter has entered beta. You can enable it by enabling beta features if you are a plus subscriber
~ Kp|2023-07-08 10:36:03|This is insane
~ Kp|2023-07-08 10:36:31|They removed bing search and included code interpreter two birds with one stone😍
~ Kp|2023-07-08 10:47:59|I just tested it with building a knowledge graph from a friend's gene dataset and it blew both our minds to say the least
Sandeep Srinivasa RedCarpetup|2023-07-08 10:56:41|what are u using to build a knowledge graph ? something like neo4j or a general vectordb. ive been trying to figure out if graph based data/embeddings are better than general embeddings, but i havent seen any code that does this ‎[7/8/23, 11:00:09] Nirant: ‎image omitted
Brij Singh Rebright Partners|2023-07-08 11:02:02|We are using Qdrant.  Also working with Prof Ambedkar at IISc to understand his Knowledge Graph research and commercialise relevant aspects.  [PHONE] can share more details.
Sandeep Srinivasa RedCarpetup|2023-07-08 11:15:25|How are u building a graph with embeddings ? Genuinely curious. Do u create embeddings with individual pieces of data and then create a relationship between them ?  I wasn't aware qdrant supported these kind of queries
Brij Singh Rebright Partners|2023-07-08 11:16:26|We aren’t there yet.  Still trying to figure it out.  My selling gets ahead of [PHONE] and [PHONE] building 😅
Dev Aggarwal|2023-07-08 11:18:20|We did this as part of the meetup (for visualisation rather than querying though  ) -  https://ai-matchmaker.us-1.gooey.ai/ thats the code for this
Dev Aggarwal|2023-07-08 11:19:18|https://github.com/devxpy/ai-matchmaker/tree/be101578f3409bbd4598124d9d0f6b89758fb57b
Sandeep Srinivasa RedCarpetup|2023-07-08 11:21:00|Hey thanks. I mean I get graph for visualisation.  It is knowledge graph for embeddings/RAG which has proven to be tricky.
Dev Aggarwal|2023-07-08 11:23:20|I was thinking this might be possible with functions, you can have the llm do back to back calls to uncover clusters of data by iteratively providing sub queries
Sandeep Srinivasa RedCarpetup|2023-07-08 11:29:43|That is orthogonal to graphs. Because even if u have subqueries, u can't traverse the graph if ur embeddings don't have connectivity.
Rajesh Kumar SA |2023-07-08 11:29:48|https://github.com/ricklamers/gpt-code-ui/tree/main
Dev Aggarwal|2023-07-08 11:32:06|> embeddings don't have connectivity. What does this mean? ‎[7/8/23, 12:14:12] Nilesh Transcend: ‎image omitted
~ Kp|2023-07-08 12:17:33|Well honestly I don't do active work in this field, was just testing out interpreter with him. Will ask and let you know
Bharat Kumar Ramesh Hashmal Web3|2023-07-08 12:18:29|Hey folks, has anyone seen (or is building) a good AI vscode extension for AI-assisted expalanation of the error stack?.   I find myself copying the code & error messages quite often to gpt for assistance, and pasting any changes back. It'd be nice to skip all that  (I vaguely recall a couple of names shared a while back, but this group averages about a billion messages a day so 🥲
~ Kp|2023-07-08 12:19:42|Me too. Just split screening rn :/
~ Karan Gandhi|2023-07-08 12:20:13|I remember a tests thing The error checking no idea
Nirant|2023-07-08 12:20:33|cc [PHONE] is building something around this
Bharat Kumar Ramesh Hashmal Web3|2023-07-08 12:21:40|Nice. Ty. Please do share [PHONE] - Copilot so far has honestly been very underwhelming
~ Kp|2023-07-08 12:24:41|Is this copilot X or the general github copilot?
~ Kp|2023-07-08 12:25:08|There are probably byok extensions in vscode marketplace
~ Karan Gandhi|2023-07-08 12:29:09|Checking them out atm
ashish Acgt01 Twitter|2023-07-08 12:29:21|Had installed bloop.ai's client on [PHONE] 's reco and was quite impressed on  a couple of queries I tried on a public GitHub repo. Nirant, does bloop work well on error stack usecases ? Does bloop have an execution runtime at the backend or is it purely code analysis and code qa ?
Sudharshan GenAI|2023-07-08 12:31:21|Anyone applying to AI grants?  July 10th deadline  https://aigrant.org/
Harshal Bhatia|2023-07-08 12:36:04|Slightly different use case. We're doing terminal first. We do have some ideas around error detection/correction also but not on the immediate roadmap.
~ Nayan Shah|2023-07-08 12:38:24|can u share the github or something would love to contribute and learn ‎[7/8/23, 12:39:04] Anshul Bhide Replit: ‎image omitted
~ Srishti Bhandari|2023-07-08 12:41:01|‎~ Srishti Bhandari left
ashish Acgt01 Twitter|2023-07-08 12:41:29|you could also try https://www.phind.com/ although in my limited use a month ago, was not that impressive
Dhanush Speciale Invest|2023-07-08 12:53:28|‎You added Dhanush Speciale Invest
Ambika Computational Mama|2023-07-08 12:54:31|Can someone explaion this to me? https://www.trychroma.com/
ashish Acgt01 Twitter|2023-07-08 12:57:58|This is a vector db used to store embeddings in RAG - retrieval augmented generation  You can get an overview of RAG here : https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html
Nirant|2023-07-08 12:58:47|It's a Python API to store these funky things called vectors. Vector are a list of decimal values where same things should have numbers close to each other.  This is used to find other numbers which are close to what someone just said.
~ Arjun Narain|2023-07-08 12:58:57|Does anybody here use Obsidian for maintaining a knowledge base? If yes, is anyone aware of an AI tool that can generate links between notes on its own? ‎[7/8/23, 12:58:59] ~ Vinay: ‎image omitted
Nirant|2023-07-08 12:59:27|Roam has an auto tag JS extension, something similar should exist for Obsidian?
Nirant|2023-07-08 12:59:44|Ablation study?
~ Vinay|2023-07-08 12:59:51|yup
Nirant|2023-07-08 13:00:29|Ask the questions which you've, sure someone can read and get around to answering it
Nirant|2023-07-08 13:01:29|Doesn't support error stack usecases. I believe that's an anti-feature for Bloop. But you can dump the error trace in QA ‎<This message was edited>
ashish Acgt01 Twitter|2023-07-08 13:01:46|+1  Was just talking to [PHONE] about obsidian yesterday.  Can someone recommend a good obsidian guide to maintain a personal knowledge graph ( Something similar to usesthis.com for their obsidian setup(s) )
~ Arjun Narain|2023-07-08 13:02:22|Let me check. There was an extension, didn't seem to work very well
Nirant|2023-07-08 13:02:58|Obsidian Expert usage guides are aplenty on internet. Off topic unless you're looking for Eugene Yan style Second Brain on Steroids  https://eugeneyan.com/writing/obsidian-copilot
Abhinav Verma Longshot.ai|2023-07-08 13:04:27|If you use sentry they have support on their site next to the stack for an explanation of the error
~ Paritosh Sanadhya|2023-07-08 13:11:58|You can try chat.collectivai.com for public repos. I think they are also coming with private repo and vs code. Had seen it somewhere on their discord
Bharat Kumar Ramesh Hashmal Web3|2023-07-08 13:13:56|Suggestions looks great. Thanks guys.   I think the truly valuable ones will be a combination of all of this, plus realtime debugging on local development
Abhishek Mishra|2023-07-08 13:28:11|Not really got around to using KGs with embeddings. But used entity-based indexing with BIOS to do impact analysis for every incoming SW change. Entities would be Knobs, Registers, Features and we did a change-based impact analysis.
Abhishek Mishra|2023-07-08 13:28:46|The graph traversal and query algorithms don't need to be reinvented, it's all about how do you organise the graph that takes effort. ‎[7/8/23, 13:31:59] Abhinav Verma Longshot.ai: ‎image omitted
Ambika Computational Mama|2023-07-08 13:48:45|this is really cool: https://learn.deeplearning.ai/diffusion-models
Nirant|2023-07-08 13:49:31|And changing entities/relationships is tricky
Ambika Computational Mama|2023-07-08 13:50:31|[PHONE] you might enjoy this course - you might also know this stuff - but so simply explained
Ravi Theja|2023-07-08 14:04:26|[PHONE] might be having interesting questions as he is using ChromaDB for building EmbedChain.
Abhishek Mishra|2023-07-08 14:05:35|True, the entire graph has to be re-built in such cases.
Sandeep Srinivasa RedCarpetup|2023-07-08 14:10:02|so i did not know we could do entity based indexing in context of LLM. i have used Entity indexing extensively with elasticsearch, but never with LLM.  if not embeddings, how do u create a context for the LLM question ? u passed the entire entity blob ?
Paras Chopra Wingify|2023-07-08 14:12:07|I do
ashish Acgt01 Twitter|2023-07-08 14:22:28|Paras, is there a publicly available user guide or something explaining your obsidian setup. If not, a lot of your fans would love to see it, maybe on usesthis.com or something :)
Paras Chopra Wingify|2023-07-08 14:24:54|notes.invertedpassion.com  Don’t update it as often, but happy to answer questions.  Obsidian became unbearably slow ok phone
ashish Acgt01 Twitter|2023-07-08 14:30:19|"I have read a lot of your essays ! and benefited from them !  my q. was more on whats your flow(in as much detail as possible :D) on how you keep track of things you read & consume :  I consume a lot of - web links - pdf papers - youtube videos - podcasts - some books  and produce : - hand written notes  how do i build a knowledge graph out of this ""usage"" data ?  is your process to incorporate these into your obsidian setup, documented somewhere ?  p.s. i remember an old tweet thread of yours talking about anki style flash cards for book summaries, a while back"
Aditya Sista 2010B5|2023-07-08 14:33:53|Codium AI is really good for testing. Generates test scenarios on a sidebar and executes them on the fly. Really good for quickly verifying whether your code works and covers edge cases
~ Rahul Garg|2023-07-08 15:09:21|‎Pratyush Choudhury added ~ Rahul Garg
~ Rahul Garg|2023-07-08 15:21:34|Hi Everyone. This is Rahul here from Venture Highway. Glad to be part of this group.
Paras Chopra Wingify|2023-07-08 15:34:36|I’ll DM you
Sumod K Mohan|2023-07-08 15:39:13|Is this recorded by any chance?
Dev Aggarwal|2023-07-08 15:40:14|https://www.threads.net/t/CubNV7IxlWR/  A thrilling story of the state of open source llms ❤️
Brij Singh Rebright Partners|2023-07-08 15:45:23|Wow. You gave me a reason to sign up for Threads 😁
Dev Aggarwal|2023-07-08 15:45:44|They are still tuning the algorithm
Brij Singh Rebright Partners|2023-07-08 15:46:40|I love the Llama boys. Commercial version will be out Jul 17.
Dr. Pratik Desai KissanGPT|2023-07-08 15:49:16|That’s first time I’m hearing the dates. Thanks for this.
Brij Singh Rebright Partners|2023-07-08 15:52:42|Oops. Not sure if I was supposed to mention in public 😅
~ Aseem|2023-07-08 16:06:38|‎~ Aseem requested to join
~ Prashanth Harshangi|2023-07-08 16:14:23|Joined this amazing community yesterday🙏🏾. Any conversations or threads on responsible usage of foundation models? Anyone interested in that? Would love to hear thoughts and learn. Thanks.
Dr. Pratik Desai KissanGPT|2023-07-08 16:25:34|Regarding the previous Semantic graph conversation, not sure how related, but LangChain has Conversation knowledge graph memory,  GraphIndexCreator etc function that I used for small scale knowledge graphs for customer PoC. Doesn’t matter how much I dislike LangChain for production, it’s really good for PoCs.
ashish Acgt01 Twitter|2023-07-08 17:03:34|+1  [PHONE] is there a recording ?
ashish Acgt01 Twitter|2023-07-08 17:04:27|just stumbled onto this on hn https://khoj.dev/  https://news.ycombinator.com/item?id=36641542  First impressive is that its not very polished, but has obsidian and emacs plugins
ashish Acgt01 Twitter|2023-07-08 17:14:35|*first impression
~ Arjun Narain|2023-07-08 17:23:40|Let me check it out!
~ Arjun Narain|2023-07-08 17:27:20|Hmm seems like a baby step in the right direction
Aashay Sachdeva MPL Data Scientist|2023-07-08 17:54:20|https://m.economictimes.com/tech/technology/microsoft-backed-ai4bharat-set-to-raise-12-million-funding-from-peak-xv-lightspeed/amp_articleshow/101579363.cms
Aashay Sachdeva MPL Data Scientist|2023-07-08 17:54:33|AI4Bharat raising for sequoia and lightspeed
Brij Singh Rebright Partners|2023-07-08 18:01:59|It says the team behind it raising for new venture.  It’s like funding Nikhil for Setu.
Dr. Pratik Desai KissanGPT|2023-07-08 18:02:45|That makes more sense
Nirant|2023-07-08 18:13:30|Dr. Pratyush from AI4Bharat will be speaking at 29th July BLR meetup
ashish Acgt01 Twitter|2023-07-08 18:14:14|https://www.threads.net/t/CuZXbbCNLCw/  (https://www.threads.net/t/CubtlP4NbY9/?igshid=MzRlODBiNWFlZA==)
Aarish|2023-07-08 18:48:44|Hi everyone. I am working on creating a categorisation model for bank statements. Given how these bank statements are not in a consistent format. I was thinking is there a way where i could optimally obtain merchants from these statements through LLM's using parser.( Keeping the latency to do so in mind)
Garv Malik 2012H|2023-07-08 19:00:18|i tried searching all transactions with Ola but Hoppipola also gets counted there. was shocked for a few seconds for a 11,000 Rs Ola ride. (this was being done manually, sharing this that this could be a potential error.)
Dr. Ashith Generative AI WA Group|2023-07-08 19:31:00|As fellow fan would love to know this too!
Aashay Sachdeva MPL Data Scientist|2023-07-08 19:31:13|Use openAI functions with pydantic
Dev Aggarwal|2023-07-08 19:32:30|Extract Camelot tables and feed as markdown to llm? Then its just prompt engg
Nirant|2023-07-08 19:33:41|Want me to add camelot as an optional dependency to ```agentai```?
Kaushik Bokka|2023-07-08 20:04:10|Just checked it out. Loved these two lines hahaha  Let developers write code! Do not invent a new syntax!
~ Arindam Barman|2023-07-08 20:05:38|What is agentai?
Nirant|2023-07-08 20:06:49|Python library for OpenAI Functions: https://github.com/NirantK/agentai  Colab Demo: https://colab.research.google.com/github/NirantK/agentai/blob/main/docs/03_Pydantic.ipynb
~ Arindam Barman|2023-07-08 20:12:41|Looks cool. Nice one [PHONE]
~ Maruti Agarwal|2023-07-08 20:16:20|processing images? - localization + ocr might be a way to go
jyotirmayjk Hackathon|2023-07-08 20:21:12|Use OpenAI functions it becomes easy. Workflow would consist of OCR+GPT.3.5 Have to be very specific with functions and entities defined inside them  I’ve implemented something similar ,extracting structured information from invoices for GST filing  Could get consistent well defined outputs with minimum error .  Had the same issue there were multiple formats of invoices ,no consistent way to find buyer,seller entity
jyotirmayjk Hackathon|2023-07-08 20:26:43|I’ve experienced that GPT3.5 is sufficiently powerful with unstructured information.  If you engineer your prompts well enough then you can just do OCR over an image of scanned PDF and pass that to GPT-3.5.It will be able to create structured information from such input.
Sumod K Mohan|2023-07-08 20:39:42|Setu folks had done a demo. Assuming you are having text format (no need of OCR) but challenge being transaction description being too little/inconsistent to make easy inference. They tried to use GPT to do this labelling for category. Seems like this hack build over a day or so was better than what they build over months.
Sumod K Mohan|2023-07-08 20:44:35|Had automated this for personal use, but some of the descriptions etc are just too little to be able to make infer category. This should work for 90% of rows. Sometimes I would need to Google/query zaubacorp to get company name or go thru app, SMS to make sense of it. Was planning on automating this using openAI API + some more smarts like above. I know couple payment companies etc who all have build similar systems.
Sumod K Mohan|2023-07-08 20:44:37|Hope that helps
Sumod K Mohan|2023-07-08 20:45:38|*make easy inference of category of labels
Dev Aggarwal|2023-07-08 20:45:50|I wonder what CRED does
Sandeep Srinivasa RedCarpetup|2023-07-08 20:52:46|Makes sense. There was this study that gpt does better labeling than mturk
Nirant|2023-07-08 20:53:58|cc Karthik [PHONE] is a DS at CRED, would love to hear if you do card txn tagging by category, and if yes — what do you use? ‎[7/8/23, 20:55:27] Dev Aggarwal: ‎image omitted ‎[7/8/23, 20:56:03] Dev Aggarwal: ‎image omitted
~ Kushaal Devanahalli|2023-07-08 21:14:19|I've heard https://mem.ai/ does a decent job.
Sugnan GenerativeAI Group |2023-07-08 21:44:05|I am not sure whether it is being recorded or not.  Cc: [PHONE] kindly clarify on this.
Nirant|2023-07-08 21:45:03|cc [PHONE] is the host
~ Kshiteej|2023-07-08 21:52:37|‎Shivendu Kumar added ~ Kshiteej
ashish Acgt01 Twitter|2023-07-08 23:40:41|"""Can we teach language models when and how to use tools, as opposed to just relying on model outputs?  To meet this need, we propose Tool leaRning wIth exeCution fEedback (TRICE), a twostage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively.""  arxiv.org/abs/2305.13068"
ashish Acgt01 Twitter|2023-07-08 23:45:19|Hi [PHONE] , is there a recording of today's event ?
Abhinav Verma Longshot.ai|2023-07-09 01:39:41|So code interpreter definitely a better intern than gpt4. Huge upgrade
Abhishek Mishra|2023-07-09 01:58:20|SW College passouts or final year interns have never been so miserable most likely. GPT4 with the plan->fetch relevant data->clarify (loop to plan)->execute might be the only thing that has added value to the same extent for me.
Abhinav Verma Longshot.ai|2023-07-09 01:59:49|To be fair I would say that this investment would teach you more than what college classes.  It's not perfect but definitely it can level up people's game
Sandeep Srinivasa RedCarpetup|2023-07-09 02:39:12|https://old.reddit.com/r/LangChain/comments/13fcw36/langchain_is_pointless/
Abhinav Verma Longshot.ai|2023-07-09 02:40:00|Is old.reddit.com updated with new messages
Shashank Generative AI Group|2023-07-09 02:55:14|library design wise, is llama-index implemented better?
Shashank Generative AI Group|2023-07-09 02:55:44|i think the old subdomain just changes the UI to the old design.
Kaushik S YC W23|2023-07-09 03:02:46|Curious to know as well. Has anyone tried and evaluated both?
Abhinav Verma Longshot.ai|2023-07-09 03:03:22|Would say both have strengths but I will also say both have issues.
Abhinav Verma Longshot.ai|2023-07-09 03:03:31|Use as per your requirements
Abhinav Verma Longshot.ai|2023-07-09 03:04:21|The standalone integrations might be more useful
Kaushik S YC W23|2023-07-09 03:05:18|Can you please elaborate?  What would be the top reasons for choosing LlamaIndex. And the same for LangChain.  And the top reason to avoid one in favor of the other
Abhinav Verma Longshot.ai|2023-07-09 03:09:32|So the way the libraries have been written  They aren't super plug and play if you have existing code. Not all of the code is useful as well. But individual components like text splitter can be useful as they are some boilerplate code you can avoid writing. Same with Llama index  Main issues with both is they use a lot of dependencies that aren't properly documented and you have to waste time downloading them to use even simple functions of those libs. Hence I prefer to take ideas from them, create stuff standalone Or use something like text splitter that doesn't use lot of external libs and doesn't break I.e has backwards compatibility
Shashank Generative AI Group|2023-07-09 03:11:10|just came across this post. goes in detail. Problems with Langchain. https://twitter.com/minimaxir/status/1677773088484909057?t=wCsy62SM1X1fhV-rrklSyA&s=19
Abhinav Verma Longshot.ai|2023-07-09 03:11:16|They're good but can also be over complicated. I don't want to have to learn a new syntax for using them  Also documentation isn't updated as regularly since development speed exceeds that so probability of things breaking increases
Shashank Generative AI Group|2023-07-09 03:13:15|yeah i used Langchain a few months back. i keep up with the updates but frankly most updates now are related to integrations which don't matter to me.  documentation is very surface level. dunno if it has changed recently.
Gokul Krishnan|2023-07-09 04:05:58|Looks like fb might take up fixing python GIL: https://twitter.com/llanga/status/1677648534563086338
Ravi Theja|2023-07-09 05:40:12|LlamaIndex has abstractions that give your more control to build a QA System.   Routing user query to one of the multiple indices/ sql db, creating sub questions to query different indices to answer the query, node processors, custom retrievers, recursive retriever, Evaluation are some interesting things you can look out for.  [PHONE] uses LlamaIndex in Albus. [PHONE] built an interesting application with node processors using LlamaIndex.  [PHONE] is integrating ragas with LlamaIndex and it should have better evaluation features in coming weeks.  PS: I am contributor to LlamaIndex and work with the team.
Amir Nagri|2023-07-09 06:28:14|`This seems like a beginner's project that blew up because it's riding a tidal wave of interest in the broader topic.` 😹
ashish Acgt01 Twitter|2023-07-09 06:31:01|So much shade thrown at langchain :) ‎[7/9/23, 07:20:27] Nirant: ‎image omitted
ashish Acgt01 Twitter|2023-07-09 08:20:29|RAG over pdf which is #1 on the hn front page right now https://github.com/raghavan/PdfGptIndexer  As always, insightful hn discussion: https://news.ycombinator.com/item?id=36648794  https://devden.raghavan.studio/p/chatgpt-using-your-own-data
Rajesh RS Generative AI WhatsApp Group|2023-07-09 08:30:16|Does code interpreter have an API accessible for a fee? Anyone knows if such a thing is available now or planned?
Nirant|2023-07-09 08:33:25|Not now, not in the works. I _believe_ lot of work on GPT4 vision API & improving uptime on Azure is going on
ashish Acgt01 Twitter|2023-07-09 08:35:39|Do you know what is the word on the street on when multimodal ChatGPT( input&/ generate an image, etc) will launch ?
Rajesh RS Generative AI WhatsApp Group|2023-07-09 08:37:02|Nice short vid on code interpreter. https://youtu.be/2Ygm6fvR7yM - possibilities it opens up are immense in my view. Like having a team with a peer reviewer, senior engineer, documentation person, etc.
Anshul Bhide Replit|2023-07-09 08:38:26|Lot of interesting comments on HN. Seems to have struck a nerve / chord?  https://news.ycombinator.com/item?id=36645575
Rajesh RS Generative AI WhatsApp Group|2023-07-09 08:39:30|Love the office space image but it is too early to call Langchain pointless. This is one framework a lot of LLM app developers are actually using. Yes the llama index and other frameworks are there but everyone at least in my circle is talking about or using langchain
Nirant|2023-07-09 08:40:10|"Ofc, we don't get it. Langchain has ""people skills"""
Anshul Bhide Replit|2023-07-09 08:42:40|It’ll be interesting to see how the langchain team reacts to this given it’s their first full blown critical attack ‎[7/9/23, 08:43:07] jyotirmayjk Hackathon: ‎image omitted
ashish Acgt01 Twitter|2023-07-09 08:43:42|"""because I spent a month working with LangChain and coming to the conclusion that it's just easier to make my own Python package than it is to hack LangChain to fit my needs.""  https://news.ycombinator.com/item?id=36648142"
Anshul Bhide Replit|2023-07-09 08:44:58|Yeah - the fact that langchain is on the front news of HN means people care about it enough to vent - it’s better than not being there in the first place.
Nirant|2023-07-09 08:45:07|I'd wager they're activating their DevRel network to write defensive comments
Nirant|2023-07-09 08:45:42|That's the most recommended way to do defence-by-proxy these days
ashish Acgt01 Twitter|2023-07-09 08:47:01|So true ! You are important enough to get negative publicity ! :)
Shashwat TDC|2023-07-09 08:47:17|Is anyone considering creating Langchain/ Llama alternative? Came across a few folks yesterday who have written some of these functions in their codebase from scratch and was considering to open-source it
jyotirmayjk Hackathon|2023-07-09 08:47:23|Literally this point is the same as point 1 in negative comment about Dropbox 😅
Nirant|2023-07-09 08:48:28|I'be begun to unbundle Information Extraction here: https://github.com/NirantK/agentai  Embedchain is doing for bots, and so on. Langchain will get unbundled by use case now
Nirant|2023-07-09 08:49:06|But I don't expect too many unbundles to win, Langchain's core strength is marketing — and we're all peasants compared to Chase!
Abhishek Mishra|2023-07-09 08:49:21|A lot of langchain hype came from positioning itself as a hub. Most people never got to use it and kept on hearing about it until they were sold on the idea that you need langchain for everything.  Law of 29. You just need to keep popping up to sell yourself on something. ‎<This message was edited>
Abhishek Mishra|2023-07-09 08:50:29|"Almost every ""new"" craze was there on langchain in a few days time and when people would ask ""how to do it?"", most answers became - ""just use langchain"" ‎<This message was edited>"
Nirant|2023-07-09 08:50:47|💯
Shashwat TDC|2023-07-09 08:52:38|Yes Nirant following this. If we have more contributors, your repo itself can become a better alternative
Shashwat TDC|2023-07-09 08:54:44|No Marketing is more powerful than a product which simply works.
ashish Acgt01 Twitter|2023-07-09 08:58:04|[PHONE] , [PHONE] , others  has anyone used/heard of, prophecy ? https://www.youtube.com/watch?v=1exLfT-b-GM  the etl way to do rag, and much less hype-y than langchain ( via https://news.ycombinator.com/item?id=36646360 )
Aakash Dharmadhikari|2023-07-09 08:58:55|I couldn’t agree more. I personally remember our NewRelic moment a decade back. It was just rails log analyzer behind a login and we didn’t find much value being added.  There are two critical aspects;  1. Not everyone is a power user and most of the market prefers convenience, even at the cost of efficiency. 2. Good teams evolve their product over a period based on user feedback  Of course this doesn’t guarantee long term substance, but a combination of these two have made me less critical of what seems naive to experts but has market traction.
Nirant|2023-07-09 08:58:57|"Calling Langchain and Llama Index as ""ETL"" doesn't reflect well on creator of this tool"
jyotirmayjk Hackathon|2023-07-09 09:00:04|+1 Probably if you can write your own package it’s not for you Just like if you could set up your own FTP server Dropbox didn’t make sense for you  It all depends now if LangChain is able to improve these are very early days
ashish Acgt01 Twitter|2023-07-09 09:02:22|"from what i understood, they are referring to their (prophecy)'s approach as the ""etl way"" and claiming that it is better than langchain, llamaindex, etc"
ashish Acgt01 Twitter|2023-07-09 09:11:00|Agree 💯  The archetype user of langchain, Llamaindex is not the typical hn reader or the majority of folks on this group.
Anshul Bhide Replit|2023-07-09 09:11:56|Who do you think it is as of today?
ashish Acgt01 Twitter|2023-07-09 09:12:45|It is the average dev who may not want to/ not have the skills to roll their own solution
Sourasis Roy|2023-07-09 09:14:41|Our experience has been Langchain is overcomplicated, hard to hack, factors into slower GTM.
Anshul Bhide Replit|2023-07-09 09:15:01|Or non devs that want the ability to prototype
Sourasis Roy|2023-07-09 09:16:57|I will suggest if you can avoid langchain , build your own simple tool , then do it
jyotirmayjk Hackathon|2023-07-09 09:21:46|That’s what it is  I think LangChain is more popular because it lowers the barrier for the “aha! moment “for new users  With few lines of code you can implement major use cases RAG,CSV Agent,Chatbot even if you’re new to programming
Amir Nagri|2023-07-09 09:22:24|my approach, use langchain to quickly experiment and iterate, once you have your LLM, VectorDB, and Prompts sorted out, you can think of moving to a simpler implementation
Amir Nagri|2023-07-09 09:23:19|it is really good library to explore, as it has the integrations with every LLM related component under the sun :)
Sourasis Roy|2023-07-09 09:23:22|Absolutely. But try taking to production for scale and it will be a nightmare
Sourasis Roy|2023-07-09 09:23:37|Exactly what we ended up doing
~ Shanthi Vardhan|2023-07-09 09:25:14|What problems did you face taking it to prod?
jyotirmayjk Hackathon|2023-07-09 09:25:46|Agreed,I think very few people outside this group have tried taking AI apps to scale.Thats why it’s popular.  Quick time to realise value->Quicker time to show off on Twitter what you’ve built 🤷🏻‍♂️
Amir Nagri|2023-07-09 09:29:46|Overall, our code-fathers will be very sad of what we are doing with Open Source  Rather than becoming a service to benefit the ecosystem, it has become bait to capture mindspace of devs 🥲
Nirant|2023-07-09 09:32:57|"Nahi. This is good. This means commercial _opportunity_ is cross-subsidising OSS. This is good for OSS — allows the wider community to retain the ethos, while still being sustainable.   Not to mention, ""$100M companies"" being born from OSS means that devs can now make money without being evil or learning how to sell to men in brown leather shoes discussing black Amex credit cards ‎<This message was edited>"
Nirant|2023-07-09 09:34:02|Devs have nerf'd our skills by never developing buyer preferences which every function from mktg to sales, and even design and HR has.
ashish Acgt01 Twitter|2023-07-09 09:34:17|Salty comment ! Loving it Nirant ! :)
Sourasis Roy|2023-07-09 09:34:22|Debugging to start with. Hard to ingest , track custom variables, prompt versioning tuning
Amir Nagri|2023-07-09 09:35:10|very unnecessary to drag in bald men in the convo, i take it as a personal assault 👨🏼‍🦲
Nirant|2023-07-09 09:35:51|Edited to insult rich people instead
Sourasis Roy|2023-07-09 09:36:38|Most of AI world right now is that selfie center at any park.
Nirant|2023-07-09 09:37:06|"It's not just Twitter demos, ""demo driven dev"" is also how you get promoted in most places"
Sourasis Roy|2023-07-09 09:37:15|Quick demo, take a nice selfie, move on
Nirant|2023-07-09 09:37:30|Demo driven dev and promo driven dev have never had such large overlap in my short career
jyotirmayjk Hackathon|2023-07-09 09:40:01|In a status driven society vs wealth driven society_______( you know the rest). 😝
~ Shanthi Vardhan|2023-07-09 09:40:19|I believe Ingestion at prod scale is a separate pipeline and Langchain was never meant to solve data ingestion and same with prompt versioning.
Nirant|2023-07-09 09:40:41|"Continuing on this, I believe ""engineering orgs"" should take more accountability e.g. learn to talk to devs, respect designers, understand the difference between Net Revenue Retention and Expansion revenue  Every time I take more accountability/risk beyond code e.g. technical designs, cloud cost, it has made life more fun, and profitable. ‎<This message was edited>"
Sourasis Roy|2023-07-09 09:44:48|Yes. I am not questioning it's utility given its scope. Its helpful. But that narrow scope wasn't working for us at our scale
Sourasis Roy|2023-07-09 09:56:54|I also feel git needs to be upgraded in a prompt+code world. I should be able to version my prompts with clear messages depicting what changes this new prompt is expected to do. I don't see dev cycle sustainable in with 100s of devs working on large AI projects
Sandeep Srinivasa RedCarpetup|2023-07-09 10:11:08|Actually I think a bit different. What I figured is that generative AI is a config management problem. With prompts X chains X LLMs modeled as config. Not very different from the whole kubernetes/Terraform world of pod X service X node.  So what we did is leverage the exact same cloud config tools to manage chains. In our case with Edgechains we did it using Jsonnet... arguably u can do it with other. As long as the Grammar is verifably robust to manage these edge cases.
Sandeep Srinivasa RedCarpetup|2023-07-09 10:11:19|The config itself, now becomes trivially manageable using git
Sandeep Srinivasa RedCarpetup|2023-07-09 10:12:09|For e.g. this is a jsonnet for composing a chain with pinecone  https://github.com/arakoodev/EdgeChains/blob/main/Examples/pinecone-chat.jsonnet
Sourasis Roy|2023-07-09 10:13:13|That is the direction we took for now. That's the lower hanging fruit. But I will like to be able to catalogue each prompt and git log one item
Sourasis Roy|2023-07-09 10:13:39|To do that in a config way is to have separate config file for each prompt
Paras Chopra Wingify|2023-07-09 10:44:14|Unlike terraform, prompts and params are what product teams also need to tweak with so this may not 100% fly
~ Manideep Burada|2023-07-09 10:46:01|‎~ Manideep Burada left
Abhishek Mishra|2023-07-09 11:08:28|True. It's the same SW engineering as ever. No need to invent prompt management or prompt version control separately.  It's easier to ruin things in reinventions by doing it wrong rather than use proven principles.
Samhan Meta/Twitter Friend|2023-07-09 11:09:15|Demo driven development is how Apple works internally. Nothing wrong with it 😁
~ Vrushank Vyas|2023-07-09 11:33:37|+ subscribe to this idea. Love what dstack is doing (for ML, not LLM workflows): https://dstack.ai/docs/  Everything is a yaml file
Sudharshan GenAI|2023-07-09 12:32:21|Hey folks an update. The Chennai Gen AI meet-up is confirmed and in Starbucks Adyar.   If you’re coming, please register below!  —-  **Chennai Gen AI Meetup**  July 9th : 4 - 6pm Location : Starbucks Adyar  https://lu.ma/taii83up
Shashank Generative AI Group|2023-07-09 12:36:04|swyx has compiled a great doc on Code Interpreter. capabilities, examples etc.   https://github.com/swyxio/ai-notes/blob/main/Resources/ChatGPT%20Code%20Interpreter%20Capabilities.md
Rajesh RS Generative AI WhatsApp Group|2023-07-09 12:43:13|Haha. That scene from office space cracks me up
~ Sparsh|2023-07-09 12:46:50|Has anyone here been figuring out or working on GATO Architecture & graph dbs?
Rajesh RS Generative AI WhatsApp Group|2023-07-09 12:48:53|Natural language git commit history for natural language prompts. Who would have thought it would come to this. But then we do require such capabilities in every team using prompt engineering to build any app. Especially given prompts have such an impact.
Rajesh RS Generative AI WhatsApp Group|2023-07-09 12:49:58|But we’ve been in this mode for a while with infra. Entire repos with yaml for infrastructure, change managed with git. Not that this has been a problem for most teams
Neeraj Kumar|2023-07-09 12:51:02|LLM document chunking question : How do I validate what technique  is best for document chunking/splitting? Recursive character splitter or character splitter of Langchain? It seems like trial and error.
Neeraj Kumar|2023-07-09 12:51:22|Essentially, what are the parameters of evaluation?
Abhinav Verma Longshot.ai|2023-07-09 12:54:11|If you use GPT LLMs, character splitter with tiktoken encoding is better. It will give you a better estimation. you might want to set your separator properly. This will actually solve a lot of problems for you. Recursive splitter is a decent idea if you are unsure of separators, though it is advised to split thinking at token level. Chunking isn't just about chunking main text. It's also adding metadata which is common to a set of chunks as information while passing to LLM for generation. ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-09 12:54:24|I assumed Langchain splitter style here
Sandeep Srinivasa RedCarpetup|2023-07-09 12:58:23|1. is there anything other than recursive splitter or character splitter that works ? 2. for non-GPT embeddings, like SentenceTransformers, does encoding using tiktoken, etc work better ...or straight pass through ?
Abhinav Verma Longshot.ai|2023-07-09 12:59:33|So I don't split based on embedding model as such. I split thinking of final LLM model to be used and its cost.  You can use a simple sentence level splitting as well which worked when I use Sbert retrieve and rerank pipeline ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-09 13:00:26|Reason for thinking in terms of final LLM cost is because that's going to be costing you the most. And that's where you want to pass in the information as properly chunked as possible
Sumod K Mohan|2023-07-09 13:15:44|We were reviewing the talks submitted in Fifth Elephant talk funnel. Wanted to touch base with Sai, who had proposed this multimodal talk (https://hasgeek.com/fifthelephant/2023-08/sub/representation-and-reasoning-on-dynamically-compos-9dDsknCCBM8kYPfzpruwVY). Sai, if you are here, please DM me or if someone has his contact info please DM as well. Thanks. ‎[7/9/23, 14:08:56] ~ Sparsh: ‎image omitted
Neeraj Kumar|2023-07-09 14:15:58|Thanks. There are different techniques. But how do you evaluate which ones work better or not?  Is there some parameters at this stage or we have a test bed of prompts and answers and see what perform best of these prompts.
Paras Chopra Wingify|2023-07-09 14:21:18|I love this HN thread
Paras Chopra Wingify|2023-07-09 14:21:56|But I’m wondering what does a better version of Langchain look like.  Or perhaps even if we need it in the first place?
~ Sparsh|2023-07-09 14:24:32|We don't need it, its python mostly  Plus there are better ways to do it for almost everything langchain provides, improving performance drastically  I have the same views on Pinecone, at scale every vector database retrieval suffers from useless information and hallucinations  For memory part specifically, langchain itself is built on top of Pydantic using classes
Rajesh RS Generative AI WhatsApp Group|2023-07-09 14:26:13|Thanks for these notes
Paras Chopra Wingify|2023-07-09 14:26:45|Maybe Langchain will have the same fate as most no-code tools, good for prototyping but none in production
~ Sparsh|2023-07-09 14:27:18|Its really good for prototyping and providing a systematic approach to solving something.  We would have been lost at graph dbs without it
Abhinav Verma Longshot.ai|2023-07-09 14:27:44|So anyone who uses LLMs in production uses a chain of sorts. So a prototype like langchain is good because you have a ready made chain format.  But as you go to more complex use cases and chains and agents and you try to bundle it in a library and you try to build fast and ship fast,  things are bound to go out of control
Abhinav Verma Longshot.ai|2023-07-09 14:29:36|We use our own chain in production, so when I want to use a library my preference is to not break my chain but to see if I can add components to my chain. I don't want to learn specific syntax here. It doesn't make my life easy and it's not super important. And this is where langchain and Llama index fail
Abhinav Verma Longshot.ai|2023-07-09 14:29:59|But still useful concepts so I wouldn't dismiss them at all
Shashank Generative AI Group|2023-07-09 14:46:23|can you explain this? how was langchain responsible for 15x latency?
Abhinav Verma Longshot.ai|2023-07-09 14:48:43|Test, iterate.
Abhishek Mishra|2023-07-09 14:51:20|This would make for a good tech article that I would want to read. That's a lot of difference.
~ Sparsh|2023-07-09 14:56:38|So we were using agents to for summary memory (short term) and entity memory (long term), every time a user had a convo, we had to use a langchain agent to summarize whatever user has talked about to parse that information in these two memories to be used by the AI later. The biggest problems of using langchain agents is that they are terribly slow, and only when they complete their summary, you will be able to push the next agent thereby increasing the time for only 3 agent calls to be approx 60s
~ Sankalp Patidar|2023-07-09 15:06:22|‎Shivendu Kumar added ~ Sankalp Patidar
The GenerativeAI Group|2023-07-09 15:44:59|‎Sumod K Mohan added ~ Aman Tiwari and ~ Prathamesh
~ Samir Seth|2023-07-09 15:45:25|‎Sumod K Mohan added ~ Samir Seth
Aditya Sista 2010B5|2023-07-09 16:32:28|I tried using token text splitter and it doesn't seem to obey the parameters, it frequently goes to 8000 tokens even though I put 2000 tokens as limit
Dev Aggarwal|2023-07-09 16:37:11|I have an enforcing token text splitter here - https://colab.research.google.com/drive/1S_4m87c44Zz1sRtY--SwLsozF6MPrfCO#scrollTo=eoB8LXHrh7dx
Dev Aggarwal|2023-07-09 16:37:29|Tested in production extensively too
Aditya Sista 2010B5|2023-07-09 16:38:37|Nice
Alok Bishoyi|2023-07-09 17:13:22|A regional news channel using a generative anchor for its program in local language   https://odishatv.in/news/odisha/otv-launches-odisha-s-first-artificial-intelligence-news-anchor-lisa--209008
~ Abhiram Ravikumar|2023-07-09 17:40:26|Is anyone here exploring open source LLMs like vicuna or fastchat?
Shubham Sharma 2012C6|2023-07-09 18:02:29|Aajtak doing this for a while. But the view count is abysmal. GenAI content right now is definitely less consumable
Neeraj Kumar|2023-07-09 18:38:17|https://github.com/langchain-ai/auto-evaluator   Harrison chase shared this!
Nirant|2023-07-09 18:44:12|Quite an old project, Llama Index is building something like this too  cc [PHONE]
ashish Acgt01 Twitter|2023-07-09 19:08:51|from dev khare of lightspeed india https://www.linkedin.com/pulse/time-its-different-dev-khare
~ Koushik|2023-07-09 19:14:51|‎~ Koushik requested to join
~ Deepesh|2023-07-09 19:21:39|https://arxiv.org/pdf/2306.06031.pdf   Anyone working on this on Indian datasets?
Dhanush Speciale Invest|2023-07-09 19:25:28|Check out https://ai4bharat.org/   Building open source Indian languages.
Nirant|2023-07-09 19:27:26|That paper is financial data, not sure what Indian languages have to do with Fin data
~ Deepesh|2023-07-09 19:28:44|Thanks. This seems to be related to Indian languages. I was referring to Indian financial datasets
Alok Bishoyi|2023-07-09 20:37:35|Is there any precedent of using something like guided backprop to get the most optimal prompt for a specific output sequence in transformers? ‎[7/9/23, 21:32:35] ~ Suhas Baliga: ‎image omitted
Abhishek Mishra|2023-07-09 21:40:21|Not exactly the same as what you mentioned but one of the better papers this year that follows improvement by self-alignment without API distillation   Dromedary 🐪 - https://twitter.com/_akhaliq/status/1654356215592361985?s=19
Abhishek Mishra|2023-07-09 21:51:05|For sure. Also, can't trust that Rat is buying off several of these machines for the well-being of humanity.
Shan|2023-07-09 22:17:10|oh, that's a clever thought. But it's not just about backprop, there's beam search and what not also.
Paras Chopra Wingify|2023-07-09 22:40:41|Look up continuous prompts, I once read research around this.
Samhan Meta/Twitter Friend|2023-07-09 22:42:27|Yann Le Cun has talked about this under the name of “Objective Driven AI”
Samhan Meta/Twitter Friend|2023-07-09 22:45:39|Where there are inference time objectives which the model tries to optimize for. Prompts can be considered a gradient free optimization
Edgar Monis Mumbai WHO|2023-07-09 23:04:05|wtf is going on 🙃  https://www.reddit.com/r/GPT4/comments/14umozd/just_launched_ai_girlfriend_olivia_she_can_hold/?utm_source=share&utm_medium=web2x&context=3
Alok Bishoyi|2023-07-09 23:06:01|Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGML in action, what else
Edgar Monis Mumbai WHO|2023-07-09 23:09:04|no i meant more like breakdown of millenia old traditional social constructs
ashish Acgt01 Twitter|2023-07-09 23:20:40|"I look at everything from a biomedical lens.  Could have applications for a conversation assistant & embodied robots for seniors in societies where family structures are not as strong and cultural norms are different.  I think Balaji from Mitra robotics is on this group.  Immense potential for doing ""good"" also .  For memory augmentation and keeping the mind sharp through dialog for seniors to reduce their risk for Alzheimer's, Parkinson's etv"
~ prakashkagitha|2023-07-09 23:23:39|Prefix-tuning is one of the prominent methods that did something similar. https://arxiv.org/abs/2101.00190
Sandeep Srinivasa RedCarpetup|2023-07-09 23:25:22|actually if ur going down this path, then the next gen of this is p-tuning.  https://arxiv.org/abs/2110.07602  the custom LSTM created here works with the LLM and (rumor has it) gives performance similar to finetuning
Dr. Pratik Desai KissanGPT|2023-07-09 23:46:56|"Is there such as thing is a static Social Construct? Chatting to an AI is a better way out for loneliness and depression for many, who couldn't act due to the current ""social constructs""."
ashish Acgt01 Twitter|2023-07-09 23:49:03|Or affordability or the acute shortage of trained mental health professionals or shame/anxiety talking to a human ?  Wysa is one of the pioneers in this space !
ashish Acgt01 Twitter|2023-07-09 23:52:06|Replying for recent thread on geriatric use cases for seniors
~ Abhiram Ravikumar|2023-07-10 00:45:56|Vicuna seems to be trained on 33B params, is there any risk in org data if we use vicuna for internal enterprise applications?  Just wondering... ;)
~ Abhiram Ravikumar|2023-07-10 00:46:05|*to
Saurab Paruthi|2023-07-10 01:07:18|Vicuna is only intended for non-commercial use cases. You may want to look at Falcon.
~ Abhiram Ravikumar|2023-07-10 01:24:37|Oh okay, thanks a bunch
~ Ankit Banerjee|2023-07-10 03:54:34|https://github.com/tinygrad/tinygrad/pull/1201?s=08  Is this faster than llama.cpp or just the implementation of llama on tinygrad? ‎[7/10/23, 08:32:23] Nirant: ‎image omitted ‎[7/10/23, 08:35:53] ashish Acgt01 Twitter: ‎GIF omitted
Nirant|2023-07-10 08:37:13|If there are takers, can use this to fund community efforts
Saurabh Karn Nyai|2023-07-10 08:40:17|Very interesting! Should automate Technical Due Diligence just as we talk about automating legal due diligence.
Nirant|2023-07-10 08:41:14|But looking at the companies raising money, I don't think anyone is doing technical DD in India, so there is no problem to be solved.
Saurabh Karn Nyai|2023-07-10 08:42:28|Yeah. VC money I don't know but I am gonna do some reading on it from a PE perspective. Might be something there.
Saurabh Karn Nyai|2023-07-10 08:42:47|M&A and all are pretty straightforward use cases for DD
~ Arindam Barman|2023-07-10 08:44:17|isn't that like 50% of a VC's job anyway - to evaluate an idea and founders before put investors' money into it.
Kshitij Agrawal ML Engineer|2023-07-10 08:44:47|It is a function of the ambition of the ideas too. Most ideas are applications in top of foundation models, where VCs are already observing traction? More focus on market validation vs tech.
Nirant|2023-07-10 08:44:55|Ohh yeah, tech DD for PE I've done, but again no 🇮🇳 takers
Brij Singh Rebright Partners|2023-07-10 08:45:12|We are building a full stack platform for this
Saurabh Karn Nyai|2023-07-10 08:45:13|Who said India :P
Saurabh Karn Nyai|2023-07-10 08:45:30|We will make in India for the world!
Saurabh Karn Nyai|2023-07-10 08:45:44|Very interesting. Would love to chat and see what you are building.
Brij Singh Rebright Partners|2023-07-10 08:46:51|Yes. But VCs regularly bring in Domain Experts to evaluate products, especially niche industries and use cases.
~ Arindam Barman|2023-07-10 08:50:16|yeah makes sense. I think the big ones bring someone fulltime. Recently had a chat with Rajko Radovanović - he does this for a16z. I can see a big market for regular angels and smaller VC firms as well.
Brij Singh Rebright Partners|2023-07-10 08:51:46|Small ones do this too when they are very bullish on a new space.  I hired [PHONE] as a Sr Associate for AI & Data Science at Rebright Partners. He led our investments in QBlocks and Stimuler.
~ Arindam Barman|2023-07-10 08:52:10|Got it.
Alok Bishoyi|2023-07-10 08:53:02|Doubtful about big market. There’s only so many funds
Brij Singh Rebright Partners|2023-07-10 08:55:14|DD is done not just for Equity but Debt too.  Plus Startups are only small part of the overall market - SMEs / PE / Corporate Strategic investments / M&A all rely on various forms of Due Diligence
Brij Singh Rebright Partners|2023-07-10 08:59:57|You should offer this to founders to do DD on VC funds and their thesis.   Very few of them actually do ref checks on Partners and blindly take money.
Alok Bishoyi|2023-07-10 09:01:01|Makes sense. I got pigeonholed into the VC category from the initial discussion
Shashwat TDC|2023-07-10 09:01:17|Yes [PHONE]  +1 for taker.
Nirant|2023-07-10 09:18:17|I do this for friends already — but the thing is VCs do selling for a living and I don't, and there are marked skill differences when it comes to persuasion  But for angel investor friends, I now have some street cred after the markup round from rain.ai (where I had invested via a syndicate)
Alok Bishoyi|2023-07-10 09:20:34|Waiting for the day when this group becomes a syndicate itself.
Brij Singh Rebright Partners|2023-07-10 09:26:09|Im happy to create and run it if [PHONE] is interested as a Syndicate lead. This is what we are building our Platform for.  You
Kartik Mandaville|2023-07-10 09:27:28|Where can I read more about the platform? like angellist?
Saurabh Karn Nyai|2023-07-10 09:29:16|Syndicate sounds very cool guys!   I’ve been part of groups but none have been called a syndicate, gives me a very mysterious feels. Liking it 😅
Brij Singh Rebright Partners|2023-07-10 09:30:31|It’s Snowmountain.ai.  Earlier I was going to build a Studio model. But now doing a tech platform play.   I’ll email you the deck. The website is just a landing page placeholder for now.
Nirant|2023-07-10 09:33:03|Thought this might be interesting to you  https://www.angellist.com/syndicates
Nirant|2023-07-10 09:41:26|Is this a US SPV like Angellist? Or some Indian AIF?
Anshul Bhide Replit|2023-07-10 09:45:04|cc [PHONE] who's a part of AL on this group
Brij Singh Rebright Partners|2023-07-10 09:45:47|We plan to do both. Especially on the India side, we are planning to largely automate the entire process from Research, DD, Documentation, Closing and filings.   Though we would like to focus more on Seed/Series A + companies where complexity is higher rather than Angel.  Also, we will offer a SaaS product to Startups to run DD simulations on internal Data and KPIs so they can be better prepared for actual fundraising process and close it faster than the 4-9 months it takes currently.
Brij Singh Rebright Partners|2023-07-10 09:46:33|Internal controls*
Nirant|2023-07-10 09:46:57|Pretty neat. I actually worked for a company building a data room-like product for a year as a data engineer. In ZIRP, even that was valuable to growth investors. Not sure about now. ‎<This message was edited>
Jivraj Singh Sachar|2023-07-10 09:47:36|Both AL US & India have syndicates as a product offering, which can be well leveraged
Jivraj Singh Sachar|2023-07-10 09:47:50|Happy to help with any specific questions wrt running syndicates on AL
Alok Bishoyi|2023-07-10 09:47:55|I believe the overseas investment through AL now is a bit tricky. It's supposed to go through ODI and not LRS. If someone has wired money recently through AL for US entity recently, do correct me  Funds / syndicates would have to set up alternatives like through GIFT
Brij Singh Rebright Partners|2023-07-10 09:48:22|Ah nice. See I knew your expertise will be important when we met :) would love to have you consult me and [PHONE]
Nirant|2023-07-10 09:51:56|This sounds right, even Indian PMS' have been setting up new instruments via GIFT. Fun times.
~ Arjun Narain|2023-07-10 10:07:17|Do folks here have any experience with Lambda Cloud?
Nirant|2023-07-10 10:08:44|I assume you mean Lambda Labs, cc [PHONE] is planning to use them for both training and inference workloads
~ Arjun Narain|2023-07-10 10:09:08|Yep Yep. Lambda Labs
~ Vinayak Kempawad|2023-07-10 10:16:22|‎~ Vinayak Kempawad requested to join
Neha YC W23|2023-07-10 10:46:44|Have heard good things about lambda labs. Replicate is also coming up with fine tuning and training LLMs
Sugnan GenerativeAI Group |2023-07-10 11:05:00|Job Opening                                                                                                                                                                   🟢 Hexo AI - 🎯 Hiring for: Generative AI includes all text, vision, typically, Designer, Illustrator, Experience specialist - 🔍 Job Description: Modern Graphic Designer: Looking for someone with deep expertise in Photoshop and optionally expertise with AI image generation tools such as SD and MJ to work with us part time or as an internship. - 📝 Apply Here: https://www.notion.so/hexoai/Modern-Graphic-Designer 2f63393cdaae4e2e8ee2e197d550d504?pvs=4 - 💬 Contact: Vignesh Baskaran - https://www.linkedin.com/in/vigneshbaskaran0123/  Posted by Sugnan on behalf of Generative AI Community.
Nirant|2023-07-10 11:06:33|cc [PHONE] for questions
Vignesh Baskaran|2023-07-10 11:15:53|Thank you very much for sharing Sugnan. The Job title is AI artist. I have no reason why I wrote Modern Graphic Designer while writing the JD :(
Soumyadeep Mukherjee|2023-07-10 11:26:59|Yes. Feel free to DM me.
Sandeep Srinivasa RedCarpetup|2023-07-10 11:56:30|those of you who are doing finetuning using documents (lets say medical/legal/etc), how do you create your finetuning data set ? what are the gotchas here - do u clean/dedup text ?
Neha YC W23|2023-07-10 12:10:28|Hey we are working on a tool to automate this process, starting with instruction tuning dataset. I am interested in talking to folks who are fine tuning, im following this thread.
Neha YC W23|2023-07-10 12:12:09|Sandeep you can also ask in the Yc group. There was a recent launch of LLM for SEC docs and they mentioned challenges with their ETL pipelines
Sudharshan GenAI|2023-07-10 12:16:00|[PHONE]
~ Arjun|2023-07-10 12:23:09|https://github.com/yizhongw/self-instruct helps.   The Self-Instruct process is an iterative bootstrapping algorithm that starts with a seed set of manually-written instructions and uses them to prompt the language model to generate new instructions and corresponding input-output instances. These generations are then filtered to remove low-quality or similar ones, and the resulting data is added back to the task pool. This process can be repeated multiple times, resulting in a large collection of instructional data that can be used to fine-tune the language model to follow instructions more effectively.
Sandeep Srinivasa RedCarpetup|2023-07-10 12:23:57|this is for instructions right ? i have a document corpus
~ Bash|2023-07-10 12:24:21|does lambda labs on demand instance support autoscaling?
~ Arjun|2023-07-10 12:25:52|Would you like to refine the autoregressive foundation model?
Sudharshan GenAI|2023-07-10 12:27:13|Would like to know too   [PHONE]
Sachin Legaltech|2023-07-10 12:29:50|Is the knowledge in your document corpus present in target base LLM ? Or trying to inject new knowledge?
Neha YC W23|2023-07-10 12:30:03|It does as per their website
Sandeep Srinivasa RedCarpetup|2023-07-10 12:31:22|inject new knowledge
Neha YC W23|2023-07-10 12:35:27|Id surely recommend talking to Emanuel. I think they did exactly this for SEC filings.
~ Bash|2023-07-10 12:38:14|was searching for it on their website/docs, couldnt find it. Could you point out the source?
Neha YC W23|2023-07-10 12:52:43|https://lambdalabs.com/service/colocation
Neha YC W23|2023-07-10 12:52:59|I found this but not sure if this works for you
Sachin Legaltech|2023-07-10 12:54:14|https://arxiv.org/pdf/2004.10964.pdf This paper performs domain adaptation on Roberta.. I am not able to find anything new. I remember reading somewhere that we should continue pretraining with mix of data the LLM was trained on and the new domain specific data; but I might be hallucinating too . Will send that paper if I can find it.
~ Vishwam Jindal|2023-07-10 12:55:00|Has anybody successfully managed to incorporate search for regional languages? Looking for something that enables search across a dataset in Punjabi and Hindi
~ Bash|2023-07-10 12:58:12|I hope I can get my own datacenter someday 😁. For now, I was looking for a GPU cloud solution that is cheapest, nearly no downtime, for inference workflow with autoscaling, and preferably an on-demand model. Till now, I have found Huggingface inference endpoint with these capabilities. Was looking for alternatives (more cost effective)
Neha YC W23|2023-07-10 12:58:58|Replicate doesnt work??
~ Bash|2023-07-10 12:59:19|replicate supports autoscaling?
Neha YC W23|2023-07-10 12:59:32|Ill have to ask Ben
Neha YC W23|2023-07-10 12:59:52|I can ask and get back
Neha YC W23|2023-07-10 13:01:21|Have asked replicate folks. Will get back
Neha YC W23|2023-07-10 13:01:37|Meanwhile someone on this group passed me https://www.qblocks.cloud
Neha YC W23|2023-07-10 13:01:49|Do take a look at it
Neha YC W23|2023-07-10 13:07:18|https://levelup.gitconnected.com/the-best-serverless-gpu-providers-in-2023-e80e672e7a34
Neha YC W23|2023-07-10 13:08:20|[PHONE] bunch of companies here. Im connected with Cerebrium founders as well, can help there too if needed
~ Bash|2023-07-10 13:14:22|Thanks a lot [PHONE] , will go thru the links and get back to you
Hemant Mohapatra|2023-07-10 13:31:03|For those trying lambda labs, lmk if you need any help. The founder Stephen balaban is a good friend.
C Chaitanya Nutanc|2023-07-10 13:41:27|Basic code to store bit embeddings in numpy, faiss and vectorDB(Milvus). (https://github.com/ozonetelgit/ozonetel-ai/tree/main/search-index). This uses the Bit embedding that we have created(will need API access). Since these are bit vectors, we can easily store around a million embeddings in 1GB RAM. Search will obviously be slower when compared with an index. If anyone wants to experiment would be more than glad to share some API keys. Also looking to see what is the fastest way to do XOR in numpys. Pointers in any direction are welcome. This stackoverflow seems to be the best resource that I have found(https://stackoverflow.com/questions/2119761/simple-python-challenge-fastest-bitwise-xor-on-data-buffers)
Naman Maheshwari Nimblexbox|2023-07-10 13:41:32|Hey, DM me for access to www.nimblebox.ai
Dev Aggarwal|2023-07-10 15:33:10|Guys - anyone remember what was that suggested json parser for parsing gpt generated json?
Nirant|2023-07-10 15:38:42|Bhai you want me to make full text search on this group?
Nirant|2023-07-10 15:42:11|Anyone applying for aigrant.org today/tonight — text/call me, will help with anything I can
~ Anjineyulu|2023-07-10 15:42:22|Actually a conversational interface should help,this group is one stop place for curated content 🫡
Pratiksha Dake Unacademy|2023-07-10 15:47:36|they have same questions as YC has. so, anyone who has submitted YC application can just copy-paste their answers and submit within a couple of minutes.
Shivendu Kumar|2023-07-10 15:47:54|Someone should actually do it and open source the script. WA search is pretty bad. 😂
Chaitanya A GenAI|2023-07-10 15:48:36|https://twitter.com/otvnews/status/1678022423017586688?s=20
~ Prashanth Harshangi|2023-07-10 15:50:47|Thanks for sharing. Will definitely apply.
Nirant|2023-07-10 15:51:44|Done. Added all community summaries to search at https://nirantk.com/
Kaushik Bokka|2023-07-10 15:52:45|Wouldn’t recommend this.
Kaushik Bokka|2023-07-10 15:53:43|Nat and Daniel are definitely more curious to know your thinking and vision around Generative AI. They will probably evaluate on that
Dev Aggarwal|2023-07-10 16:04:33|Oh shoot, we already submitted
Dev Aggarwal|2023-07-10 16:04:34|Yes, I have to clear the history otherwise whatsapp hangs
Chetanya Rastogi|2023-07-10 16:05:22|‎Chetanya Rastogi requested to join
Chetanya Rastogi|2023-07-10 16:05:31|‎Chetanya Rastogi joined using this group's invite link
Lavish 2017|2023-07-10 16:30:02|thank you, applying today, will message you ⚡
Nirant|2023-07-10 16:30:17|Impressed by the first 2 ideas!   We might've an Indian grant winner this time 🤯
Lavish 2017|2023-07-10 16:31:14|you need to stop running falcon parallelly in phone 😛
Harshal Bhatia|2023-07-10 17:00:36|wait what! i need this. Link a guide?
ashish Acgt01 Twitter|2023-07-10 17:01:58|Can't tell if Lavish was serious or kidding :)
Chetanya Rastogi|2023-07-10 17:02:52|You should checkout https://mlc.ai/mlc-llm/
Lavish 2017|2023-07-10 17:03:06|was just kidding 😅  tiny box ftw for future
Chaitanya A GenAI|2023-07-10 17:03:34|how many preorders did you make :)
Harshal Bhatia|2023-07-10 17:03:49|i wouldn't be surprised actually. even in the beginning of llama.cpp, someone had optimized it enough to run on a two year old pixel. so falcon also would be along the same lines right
Chaitanya A GenAI|2023-07-10 17:04:55|iphone12 could run stable diff but with specific optimisations
Chaitanya A GenAI|2023-07-10 17:05:29|feasible, depends on your edge device and the optimisations you’re using
~ Abhishek|2023-07-10 17:12:16|‎~ Abhishek requested to join
Nilesh Transcend|2023-07-10 17:20:20|Is there any indian company in the first batch?
Nirant|2023-07-10 17:33:09|No
Ambuj Kashyap|2023-07-10 17:37:19|https://aigrant.org/
Ravi Theja|2023-07-10 17:40:37|[PHONE] is hosting Anton Troynikov - founder of Chroma to discuss ChromaDB, and the future of VectorDBs - along with our rock star [PHONE].  Please register here: https://lu.ma/ai-talks-6
~ Abhishek|2023-07-10 17:45:54|‎~ Abhishek requested to join
Abhishek Mishra|2023-07-10 18:18:25|Awesome. Registered.
Sumod K Mohan|2023-07-10 19:27:10|Need some inputs from anyone who has distributed NLP based Python packages as executables (numpy, sentence transformers etc). Generally things like py2exe, pyinstaller etc have challenges with numpy based packages. Haven't tried zipapp/shiv etc. Webservice is not an option. Docker/Python packages etc not an option as it should be easily usable by non developers.
Dev Aggarwal|2023-07-10 19:31:29|Try briefcase
Dev Aggarwal|2023-07-10 19:32:10|https://www.youtube.com/watch?v=Ytg4dij6Uwo&t=1627s
Nirant|2023-07-10 19:32:18|Beat me to it
Ritesh Invideo Nilenso|2023-07-10 19:34:12|Neat, didn't know about it. Have you used for any real world projects?
Dev Aggarwal|2023-07-10 19:37:05|Nope, I haven’t shipped desktop apps since 7 years now. But russel is like the one dude who’s been trying to save python’s app development story since he stopped being the president of django software foundation. So yeah, really trust him!
Ritesh Invideo Nilenso|2023-07-10 19:38:13|will try it out. Needed something few months ago -> then chucked the idea of installation and went docker route
Sumod K Mohan|2023-07-10 20:08:07|There are few issues listed related to numpy and some issue with Ubuntu's AppImage. It is probably not sure mature, but will try out later this week.
~ Shivansh Dadhich|2023-07-10 21:40:55|‎~ Shivansh Dadhich left ‎[7/11/23, 00:16:54] Neha YC W23: ‎image omitted
~ akshay deo|2023-07-11 00:17:08|‎~ akshay deo was added
~ Vinayak Kempawad|2023-07-11 00:17:08|‎~ Vinayak Kempawad was added
~ Nikhil|2023-07-11 00:17:08|‎~ Nikhil was added
Dev Aggarwal|2023-07-11 00:17:58|The problem isn’t that it will scale up, the problem is that it will scale down to zero
Neha YC W23|2023-07-11 00:18:52|They use AWS so i think that should be doable, but getting in touch with them would be recommended ‎[7/11/23, 00:20:27] Dev Aggarwal: ‎image omitted
Rohit GenerativeAI WhatsApp Group|2023-07-11 00:28:24|runpod has some good strategies on how you want to scale with traffic. it could be based on request count or waiting time. plus they provision extra workers to reduce cold start and ofc cheap gpus :)
Aishwarya Goel Inferless 5s for 5G|2023-07-11 00:35:30|It's a good point. Net-net the game is how you can get the scale from 0 to 1 in the least possible seconds!
Rohit GenerativeAI WhatsApp Group|2023-07-11 00:37:48|nook q: is it different from scaling from 1 to 2?
Dev Aggarwal|2023-07-11 00:38:48|In very subtle but very important ways depending on your scale! I’m sure Aishwarya has a blog post on this :)
Neha YC W23|2023-07-11 00:40:01|This sounds like there is an xkcd for this somewhere
~ Bash|2023-07-11 02:29:25|runpod seems like the best option available, thanks
Rohit GenerativeAI WhatsApp Group|2023-07-11 02:31:40|now I feel like there is an important missing feature there  affiliation :p
~ Ankit Shrivastav|2023-07-11 02:35:25|Hey everyone, Do anyone come across a tool where we can prompt to make a Whatsapp bot which gives real-time replies (a certain specific message) as and when somebody texts? or any open source tool available?
Chetanya Rastogi|2023-07-11 02:57:54|Have you tried https://github.com/smol-ai/developer. It's pretty good at creating chrome extensions. But even if it doesn't work ootb for a WhatsApp bot, I think with continuous prompt  iteration directly with gpt4 you can get pretty far (I usually do that when I have to write react/js code which I have no idea about and it just works with some console.log for feedback for any issues)
~ Ankit Shrivastav|2023-07-11 03:11:48|I tried with chatgpt fell into error one or other  Sure let me try smol Thanks
Nirant|2023-07-11 07:45:41|GPT-powered support chat bot from our very own Ojasvi [PHONE] at Dukaan. https://twitter.com/suumitshah/status/1678460567000850450
Alok Bishoyi|2023-07-11 07:46:22|https://www.semianalysis.com/p/gpt-4-architecture-infrastructure  Anyone who is a subscriber or has access to this ?
Kartik Mandaville|2023-07-11 08:05:33|Wow that’s launching a side business. exciting. This narrative on layoffs won’t help with media attention on AI reducing jobs
Nirant|2023-07-11 08:52:18|Indian Govt has (endorsed?) mentioned Vespa.ai @jobergum, @qdrant_engine  and SingleStore  https://indiaai.gov.in/article/exclusive-vector-databases-for-llms
Nirant|2023-07-11 09:03:17|Thought this might be interesting to you [PHONE]  Self-optimising UX  https://twitter.com/joshpxyne/status/1678464233753939969
~ Nikhil|2023-07-11 09:03:31|Can anyone give me real world use cases for vectorDBs? As far as I understand you can easily use postgres + pgvector for most of the embeddings and semantic search work. I’m guessing (not sure) vector DBs are faster for similarity search on embeddings, but can’t think of many use cases where millions of search queries are happening that are not eventually touching the LLM and instead VectorDBs start showing benefits
Nirant|2023-07-11 09:05:34|pgvector gets about 1 in 5 similarity search Top 1 wrong. I mentioned this for 1M benchmark: https://nirantk.com/writing/pgvector-vs-qdrant/  But honestly, the accuracy error holds at 100K as well
Nirant|2023-07-11 09:07:39|And the 1M is not the search queries, but the number of vectors —  a single pdf page is ~10 chunks/vectors on average
~ Nikhil|2023-07-11 09:10:46|Ok so based on the benchmarking it’s definitely slower and maybe less accurate. But I still don’t understand why you won’t let the search query hit the LLM especially as inference costs go down, and instead rely on similarity search which sort of defeats the purpose of using LLMs in the first place? Not trying to diss on vectorDBs, just mulling over the use cases here of why somebody should do the heavy lifting of transitioning data in existing DBs to vector DBs
~ Ankur Khandelwal|2023-07-11 09:12:05|One of the use case I had-   Searching GaryVee youtube channel. So I stored all his videos transcript into vector db that was more than 1 million vector in pinecone.  Initially I used supabase + pgvector but after 500K rows it just hang- Not able to index the rows. even talk to their support/founder but nothing concreate came out.  so I had to move to pinecone. Pinecone vector db similarity search was much better , it was very quick.
~ Ansha|2023-07-11 09:20:32|Has anybody used solely vector db for semantic search in production?
~ Ansha|2023-07-11 09:21:40|I have been combining it with some sort of graph db for my use-case.
Shivendu Kumar|2023-07-11 09:22:10|There's a limit on the amount of data you can fit in the context window. If all of it can fit in the context then yes, you don't need search at all.   Vector search helps decide which item(s) to put it that context window so you can get the best answer from the LLM.  And even if context window expands significantly in future (say 1M tokens), that's still not sufficient to keep up with the amount of growth in data.
Nirant|2023-07-11 09:22:30|Most common use case is cosine similarity vector db and nothing else. Very few folks add BM25
Nirant|2023-07-11 09:23:26|What do you mean by combine GraphDB with Cosine similarity?  Cc [PHONE]Thought this might be interesting to you
Sumod K Mohan|2023-07-11 09:23:38|Depends on your query and few other things. Numbers below might be off by upto one order mag. 1. simple semantic search like queries, this would be an overkill. Assuming 1000dim embedding and 1M docs, this would be approx 10^9-10^10 flops if you do exact neighbour search. About 2-3 orders magnitude faster if you use approx nearest. LLM inference is about 10^15 flops. You don't really move the needle of accuracy much. 2. Where you need NLG, to combine and create text then you probably need LLM inference. Here again due to hallucination, Retrieval Augmented Generation is preferred (you search a bunch of docs using DBs) and then send those docs to LLM. So still about 10^15.
~ Nikhil|2023-07-11 09:24:04|Interesting, so you’re saying postgres (or in this case supabase) was not able to handle the scale..
~ Ankur Khandelwal|2023-07-11 09:24:26|yes.
Shivendu Kumar|2023-07-11 09:26:04|Also another fundamental thing to realise is that algorithms are always going to be faster than feeding data to any huge ML model.  Even if you're seeing lower latencies with openai APIs as the end user, it's powered by very powerful machines which cost a lot of money. Hence overall compute cost cannot be lower than a dedicated search algo. ‎<This message was edited>
~ Nikhil|2023-07-11 09:29:14|The assumption over there is that there are a lot of repeat queries for which results exist in the vectorDB ^
ashish Acgt01 Twitter|2023-07-11 09:30:29|"Very cool ! Certainly feasible the way inference costs are going down.  But would it still work for usecases where you want the generated output to additionally come with the cited knowledge base document, from which the ""meat"" of the generated output is coming from ?"
~ Nikhil|2023-07-11 09:32:30|Embeddings and chunking definitely help you bypass the context length constraint but when you’re using vector search to decide what fits into the context window aren’t you biasing the LLM result?
Paras Chopra Wingify|2023-07-11 09:33:00|We did this way back when gpt launched,   Marketers want control over what their websites look like so many such “automatic” Optimizations require human approval in the loop
~ Nikhil|2023-07-11 09:36:08|Not suggesting the use of LLM for (1) here, but yes (2) is an interesting use-case.
Shivendu Kumar|2023-07-11 09:36:38|But any LLM output is be biased anyways. Quality of that bias decides quality of the output. So better to have more control over that bias?  Sourcegraph released a blog on this. https://about.sourcegraph.com/blog/cheating-is-all-you-need ‎<This message was edited>
~ Ansha|2023-07-11 09:37:59|Let's say you have a lot of electronic products and their description, stored in vector db. And use cosine sim for retrieving the best recommended product at many granularities. I also have a constraint not to over sell something just because cosine sim scores are good. Also my sales are dynamic and I have to maintain balance at City level, area level, district level at all times .  Graph db helps in maintaining the balance presently.  The whole system was in graph db. Now migrating to vector db. Half-way there, trying different ways
Nirant|2023-07-11 09:38:55|I'd strongly encourage you to try these ideas a bit yourself. Would take 15 minutes for a great dev like you.  Additionally, will request moving this convo to DMs since we've discussed this topic in this forum and meetups in k-ways: you can search for past conversations from this community at https://nirantk.com/docs/resources
Shivendu Kumar|2023-07-11 09:40:21|Sourcegraph released a blog on this. https://about.sourcegraph.com/blog/cheating-is-all-you-need
Nirant|2023-07-11 09:43:31|Also: Since we've less than 50 slots open, we'll be only adding Makers: Engineers, designers, artists, founders from this point on. No exceptions. 
Ojasvi Yadav|2023-07-11 09:51:11|Thats a lite version of our chatbot. Idea was to let people understand and know the value proposition asap in an active manner.   I would love to hear opinions around fastest methods to setup a vector DB and deploy a container.
Ojasvi Yadav|2023-07-11 09:52:21|More than GPT, the credit goes to Llama Index. And also [PHONE] who's been very helpful in learning how to learn llama index.
Ojasvi Yadav|2023-07-11 09:52:47|Container running our chatbot code
Neha YC W23|2023-07-11 09:59:50|[PHONE] might have missed this but which model did you train the chatbot on? Is it chatgpt + faiss
Ojasvi Yadav|2023-07-11 10:00:40|Since the floor is hot, just want to add that one of our branches contains direct usage of [PHONE]library  https://github.com/NirantK/agentai
Ojasvi Yadav|2023-07-11 10:01:40|I'm actually enjoying leveraging the open-source contributions from this community
Ojasvi Yadav|2023-07-11 10:03:25|We have some talented people here, and I welcome such collaborations with my arms wide open
~ Nayan Shah|2023-07-11 10:08:39|Faiss , qdrant .
~ Nayan Shah|2023-07-11 10:08:51|Chromadb.
~ Nayan Shah|2023-07-11 10:09:42|1m plus vector indexed related to prpducts for ner and recommendation related usecase , and its able to hadnle increment updates to it as well properly ‎[7/11/23, 10:10:33] aashutosh GenerativeAI WhatsApp Group: ‎image omitted
Ojasvi Yadav|2023-07-11 10:15:30|Essentially, yes
Neha YC W23|2023-07-11 10:16:13|Did you need to fine tune gpt for your use case?
Neha YC W23|2023-07-11 10:19:13|Btw anyone here worked with Falcon-40B? Can you share experience? Im playing with the model and so far it has been so bad compared to GPt
~ Ashish|2023-07-11 10:20:02|_*I tried the same. on some tasks it's good. But GPT-4 is exceptional.*_ ‎[7/11/23, 10:22:28] Abhishek Mishra: ‎image omitted
Jithin James Ragas|2023-07-11 10:23:20|deployment to containers for llamaindex index is something I'm working on atm.  trying to set up some benchmarks right now so that we can get a baseline and optimise it further.  curious about what u have tried so far
Neha YC W23|2023-07-11 10:26:00|Can i DM you for learnings?
Divya Tak|2023-07-11 10:26:21|‎Divya Tak requested to join
Neha YC W23|2023-07-11 10:26:39|So far my observation is it is not consistent, and does not follow instructions. I keep telling it to not do X, it doesnt take that into accouny
Neha YC W23|2023-07-11 10:27:00|Gpt is like a well behaved child. Falcon-30b is a teenager with behavioral issues
~ Ashish|2023-07-11 10:27:02|sure
Amal David Futuryze|2023-07-11 10:28:42|Not reliable at all, the instruct version is a little better for both 7b and 40b but context/task grounding have quite a bit of issues. Still trying to figure workarounds
Neha YC W23|2023-07-11 10:33:36|Do lmk if you find something
Ashwin Matrix|2023-07-11 10:36:33|Guys, We are looking to convert some human portrait images into creative AI filter ones. Essentially solving for uniformity, clarity and 'jazz'. Limitations are that we don't have a critical number of pictures to use popular tools.  Any suggestions or help here? Happy to engage on a paid project as well incase any founders here are building something like this!
Nirant|2023-07-11 10:37:55|Do folks need a custom-finetuned Falcon model for QA/RAG?
Paras Chopra Wingify|2023-07-11 10:39:43|Has anyone been experimenting with a decentralised network of LLMs / models (each specialised in some area), coordinating towards a common goal
Paras Chopra Wingify|2023-07-11 10:39:53|Almost like how brain operates
Abhinav Verma Longshot.ai|2023-07-11 10:40:18|Yes. Or you know a way to custom finetune LLM for qa/rag
Paras Chopra Wingify|2023-07-11 10:40:43|see RETRO model, I think sales force released a new one recently
Abhinav Verma Longshot.ai|2023-07-11 10:41:33|Will check it out.
Neha YC W23|2023-07-11 10:49:11|Yep
Sumod K Mohan|2023-07-11 10:49:14|One of the VCs in the group had a similar idea, funding open source to do something of this sort. Think Brij Bhasin. Not sure who it was.
Paras Chopra Wingify|2023-07-11 10:50:20|GPT4 architecture details   https://threadreaderapp.com/thread/1678545170508267522.html
ashish Acgt01 Twitter|2023-07-11 10:52:25|was just about to post this ! you beat me to it :)
Amal David Futuryze|2023-07-11 10:55:05|Maybe, but not sure if it’s still gonna help much with the attention issues that these models have.   As of now it works decently for basic usecases but just branches off into something completely unrelated when conversations increase
Nitin Mahajan McKinsey|2023-07-11 10:55:43|Yes Brij posted and I retweeted. Monster API
Dr. Pratik Desai KissanGPT|2023-07-11 10:57:39|Isn't this GPT4 MoE?
jyotirmayjk Hackathon|2023-07-11 11:05:28|I’ve come across this  https://arxiv.org/abs/2211.11559  Utilises LLM along with image based models for visual tasks ‎[7/11/23, 11:05:45] jyotirmayjk Hackathon: ‎image omitted
Paras Chopra Wingify|2023-07-11 11:08:14|No. More decentralised, backward passes, almost a negotiation than just a central node deciding forward passes
Sachin Legaltech|2023-07-11 11:10:22|https://dhruvmadeka.com/post/llms_education A detailed analysis of impact of LLMs on education and some (hand-wavy) calculations about how this impact can add 5 trillion dollars to world economy
~ Prashanth Harshangi|2023-07-11 11:19:37|Any success with using confidential computing for LLMs like fine-tuned Falcon?
Divya Tak|2023-07-11 11:20:40|‎Divya Tak joined from the community
Abhishek Mishra|2023-07-11 11:25:01|Oh, like all LLMs on same level of hierarchy working towards a common goal.
Abhishek Mishra|2023-07-11 11:30:19|A model fine tuned for RAG for QA shouldn't need to hold very long conversations. It will also not be fine tuned for chat in the first place, but it will be better at sticking to context and will give good citations based on the context.  Hardest part about this isn't fine tuning, but you'll have to curate your dataset. I'm working on this actually. Once the dataset is built using augmented squad, hotpotqa, wikiqa it can just be spammed on Falcon and xgen.
Swapnika Hashmail Web3|2023-07-11 11:30:48|Folks - do you think OpenAI is likely to release a Code Interpreter API soon?
Swapnika Hashmail Web3|2023-07-11 11:30:56|Would be much better than tinkering with functions.
Abhinav Verma Longshot.ai|2023-07-11 11:32:45|I think you can use the functions api to execute those functions as well
Abhishek Mishra|2023-07-11 11:33:41|Code interpreter is good but doesn't it fall short for actual data science purposes? it's outdated and you can't install newer libs in it for it to use.   I've not used to extensively but it felt like one can do better by having a local container with better equipped libs and openAI functions. ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-11 11:34:25|Haven't came across any paper or research that demonstrate if this is possible keeping in mind inference cost, latency, accuracy, etc. I would love to read if someone has a reference. Even, I haven't seen anyone else successfully doing MoE, that OpenAI is doing, yet. ‎<This message was edited>
Swapnika Hashmail Web3|2023-07-11 11:36:30|What do you mean?
Abhinav Verma Longshot.ai|2023-07-11 11:37:29|You can execute the functions as well using the functions api
Swapnika Hashmail Web3|2023-07-11 11:39:33|True, but I'll have to define a several mathematical functions to analyse a set of data vs using a code interpreter API (when available) for that no? Or are you saying these functions are pre-defined?
Abhishek Mishra|2023-07-11 11:44:55|Provide your data to code interpreter, let it analyse it based on your refined instructions. If results are acceptable, copy the code it has generated to execute the task and convert it into an openAI function. Higher quality and allows to use latest tools for direct counterparts of the actions as well. You also won't need to come up with all the function definitions.
Swapnika Hashmail Web3|2023-07-11 11:46:16|That’s interesting - let me try.
Sandeep Srinivasa RedCarpetup|2023-07-11 12:21:52|has anyone been doing math with LLMs ? like calculating taxes, etc  ? any papers or research in this direction that you're aware of...or is this something that Code Interpreter can do
Abhinav Verma Longshot.ai|2023-07-11 12:23:02|LLMs are bad at math. Though code interpreter might be better since it executes functions
Sandeep Srinivasa RedCarpetup|2023-07-11 12:24:29|interesting. but GPT4 specifically makes a claim about this. it doesnt work ? https://www.youtube.com/watch?v=mmOEMfTnQGo . would love to know places it fails ?
Shubham Sharma 2012C6|2023-07-11 12:25:13|I think one can use with Wolfram plugin to get math right
Aashay Sachdeva MPL Data Scientist|2023-07-11 12:25:58|Splitwise it can do for sure.🤣 done it multiple times
Abhinav Verma Longshot.ai|2023-07-11 12:47:09|You can also have an agent that calls calculator to do math. Point is LLM math can be unreliable
Sandeep Srinivasa RedCarpetup|2023-07-11 12:48:32|thats what i want to explore. i was seeing specific claims by openai and gpt that gpt4 is superlative in math. trying to understand examples where it breaks down.
Dev Aggarwal|2023-07-11 12:49:00|Gpt maths isn’t maths, its table fuzzy lookups
Dev Aggarwal|2023-07-11 12:49:38|If you go out of training distribution (eg 4 digit arithmetic) it breaks
Sandeep Srinivasa RedCarpetup|2023-07-11 12:50:11|even this ? https://www.youtube.com/watch?v=mmOEMfTnQGo   i have been tracking a whole bunch of videos on gpt4 math and they all seem to work brilliantly. so im trying to understand situations where it doesnt work.
Sandeep Srinivasa RedCarpetup|2023-07-11 12:50:34|im hearing anecdotes about it not working...but im not getting specific examples. can someone help so that i can try out on my own
Dev Aggarwal|2023-07-11 12:50:52|4 digit arithmetic will be usually wrong
Abhinav Verma Longshot.ai|2023-07-11 12:50:55|Its better compared to turbo, but I'll still hold off on claims. They are getting better though, so we'll see
Dev Aggarwal|2023-07-11 12:52:39|Minimum viable demo ‎[7/11/23, 12:52:40] Nirant: ‎image omitted
Dev Aggarwal|2023-07-11 12:53:17|Code interpreter se cheating 😭 ‎[7/11/23, 12:53:41] Nirant: ‎image omitted ‎[7/11/23, 12:54:37] Nirant: ‎image omitted
Nirant|2023-07-11 12:55:33|Only Code Interpreter gets it right
Dev Aggarwal|2023-07-11 12:57:03|4+ digit numbers occur more rarely in training data. For 2 digit the combinatorics are so small you can memorize
Sandeep Srinivasa RedCarpetup|2023-07-11 12:57:55|interesting. so what it means is that chatgpt can do a lot of transformations into structured data (json, tables, etc) but for the actual math primitives...we should still call out.
Abhinav Verma Longshot.ai|2023-07-11 12:58:54|Honestly , we should have an LLm which outputs this answer as Plenty
Nirant|2023-07-11 12:59:59|Yes. Think of LLMs are really really good parsers. Not compilers or reasoning engines.
Abhinav Verma Longshot.ai|2023-07-11 13:01:02|LLMs are Dr watson, not Sherlock Holmes
Dev Aggarwal|2023-07-11 13:01:49|Counter: they can be really good at all of the above.  Its a general purpose training data interpolator. If you feed shrerlock’s inner monologue it becomes sherlock
ashish Acgt01 Twitter|2023-07-11 13:02:47|"I was reading the DERA paper recently for a journal club  Looking at the dialog between the ""decider"" and ""researcher"" agents would make you think twice about claiming that they are not good reasoning engines :)  https://arxiv.org/abs/2303.17071"
Nirant|2023-07-11 13:03:15|No, it becomes a very mimicry of Sherlock. All the sass, none of the deduction skills
Abhinav Verma Longshot.ai|2023-07-11 13:03:40|Like a Pritam song.
Dev Aggarwal|2023-07-11 13:04:12|Well no right, it can imagine it would apply the same reasoning paths as sherlock on any given problem
Dev Aggarwal|2023-07-11 13:04:27|I’ve always thought why illya sutskever keeps saying “why can’t it do what humans do” and it just makes sense because behaviour cloning is what LLMs do great
Nirant|2023-07-11 13:06:42|But it does not, because Sherlock's main skill is plot armour. Not deduction or elimination. That's issue with behavioural cloning everywhere, every new copy is watered down and altered in undesirable ways.
Dhruv Anand|2023-07-11 13:07:35|"I don't understand the expectations people have started having about LLMs. There's no reason why it should be good at math, so why would we expect it to be. We had the same discussion about chess a few months back. I think the ""emergent abilities"" which people have not been able to explain have sort of spoiled people with regards to expecting capabilities from LLMs"
Abhinav Verma Longshot.ai|2023-07-11 13:08:11|Listen if an LLM can answer this question, its game over Let's say that you're 80% likely to have left your charger somewhere inside a case with 4 identical compartments. You check 3 compartments without finding your charger. What's the probability that the charger is inside the remaining compartment?
Dhruv Anand|2023-07-11 13:08:51|LLMs need an object permanence capability lol
Dev Aggarwal|2023-07-11 13:09:35|Right answer?
Nirant|2023-07-11 13:12:40|Somewhat right approach here: https://chat.openai.com/share/56482065-5c8c-411f-920b-3607cdae74e5 ‎[7/11/23, 13:14:15] Rishabh Refuel.ai: ‎image omitted
Divya Tak|2023-07-11 13:15:34|It will also think that if 20 musicians play a piece in 30 mins, 40 will play the same piece in 15 mins XD
Abhinav Verma Longshot.ai|2023-07-11 13:15:57|that is some logic there. ‎[7/11/23, 13:16:32] Rishabh Refuel.ai: ‎image omitted
Divya Tak|2023-07-11 13:17:31|"Nice okay it didn't make this error. Wanted to say ""it knows the nature of the problem"" but then the word ""know"" is weird."
~ Srinivasan Nandakumar|2023-07-11 13:24:18|There was a paper sometime back where results showed the tokenization used by llama where every digit got a separate token results in better performance on math tasks. Potentially you could try one of the open source models using the same tokenizer and evaluate. But making the model call the tool will still be the best imo.
~ Ankit Jain|2023-07-11 13:29:22|https://twitter.com/Aella_Girl/status/1456044496018284548 a long twitter thread already on this
~ Srinivasan Nandakumar|2023-07-11 13:33:44|https://arxiv.org/pdf/2305.14201.pdf
Abhishek Mishra|2023-07-11 13:45:14|A recent paper discussing the challenges of arithmetic with LLMs - https://arxiv.org/abs/2307.03381  Key takeaways: * LLMs suck at arithmetic * It can add correctly if the data is similar to it's training data * Step by step examples in training data improve it's results * If you let them output lower digits first and thus do arithmetic like a little kid from the rightmost digit, they fare much better ‎<This message was edited>
Sumod K Mohan|2023-07-11 14:01:05|Yeah, this is what I think of it. Amazing parser and generators, 1/2 level basic leaky-reasoning. Would love to see these being used to generate rich object/world models and then combined with reasoning systems. It will be comical as Kailash said the other day, transformers bootstrapping last gen systems. Anyone seen papers along this lines, not trivial ones but ones where there is decent impact.
Pratyush Choudhury|2023-07-11 14:33:31|The key question though is how well/quickly the reasoning capabilities improve
Paras Chopra Wingify|2023-07-11 14:35:22|We get into philosophy here.  What is reasoning if not parsing in imagined model of real world?
Sandeep Srinivasa RedCarpetup|2023-07-11 14:41:21|has anyone used these embeddings for their RAG ? https://github.com/HKUNLP/instructor-embedding   according to the published paper, it claims to perform better ‎[7/11/23, 14:54:05] ashish Acgt01 Twitter: ‎image omitted
Abhishek Mishra|2023-07-11 14:58:07|Not for RAG but compared them for application in general. I think these are the same instructor embeddings that are present and on top of the MTEB leaderboard.  They score higher on the leaderboard but lose out on application because of their large size and much slower inference compared to miniLM or e5. For anything that works well in  <768 dimensions (most scenarios), they become impractical to use.  Though I'll be happy if there are any surprises for me.
ashish Acgt01 Twitter|2023-07-11 14:58:41|My journal club slides on DERA are here , just fyi ! https://docs.google.com/presentation/d/1q0brYMyGHjMIyrBLbRImZUciXOemsFHMTca558A2ebg/edit
Abhinav Verma Longshot.ai|2023-07-11 14:58:48|there are subreddits also dedicated to this sir.😅
ashish Acgt01 Twitter|2023-07-11 15:05:02|"And a ""world"" model which rivals a 3-4 year human's :)"
Alok Bishoyi|2023-07-11 15:59:11|Am I tripping or is the answer 50%?  The key is equally likely to be distributed amongst 4 compartments (20% each ) and the outer world (20% )  Conditonal probability of the key being in drawer 1 when not in 2,3 or 4 has to be 50 right?  Been a while since JEE days
Abhishek Maiti|2023-07-11 16:10:36|80%? Since premise was already that 80% on the left, but out 4, its not there in 3. So 80% on the last one? I might be tripping as well 😂
Abhishek Maiti|2023-07-11 16:13:39|My bad, I read the question wrong. I was tripping
Alok Bishoyi|2023-07-11 16:16:15|don't sell yourself short. You might be onto something  https://www.youtube.com/watch?v=4Lb-6rxZxx0
~ Ankit Sharma|2023-07-11 16:19:37|What if we add states using prompts?
Abhishek Mishra|2023-07-11 16:36:35|It should be 80%. The initial probability statement is that the 4 drawers collectively have an 80% probability of having the adapter. When you've opened 3 drawers first, the statement does not change and thus the final drawer must fulfill the probability of 80% for the initial statement to hold.  Though I wouldn't debate it since such probabilistic cases can go round and round like the Monty Hall problem. Even the highest IQ person on Earth at that time - Marilyn Vos Savant, was wrong about it.
Aashay Sachdeva MPL Data Scientist|2023-07-11 17:40:29|Is anyone using transformers at their company for next user action prediction?
Bharat Kumar Ramesh Hashmal Web3|2023-07-11 17:50:11|This is right. This explanation reminded of kevin spacey in the movie 21
Abhishek Mishra|2023-07-11 17:50:28|You mean identify current and past user actions with some tag or label and use it like a token in a sentence. Then predict the next token in the sequence to represent most likely user action?
Aashay Sachdeva MPL Data Scientist|2023-07-11 17:55:05|Yes
Aashay Sachdeva MPL Data Scientist|2023-07-11 17:56:21|https://medium.com/nvidia-merlin/transformers4rec-4523cc7d8fa8
Aashay Sachdeva MPL Data Scientist|2023-07-11 17:56:39|Should have been more specific- has anyone used the above in production setting
Abhishek Mishra|2023-07-11 17:57:55|"In such a specific problem. The ""sentence"" representing user action sequence would be very short most of the time. So, I'll explore LSTM/RNN for the problem as well, as they can possibly work better than transformers for short sequences with relatively lightweight implementations. ‎<This message was edited>"
Aashay Sachdeva MPL Data Scientist|2023-07-11 18:10:41|Yeah but we could create the user journey from 0 to last action
Sumod K Mohan|2023-07-11 18:16:24|EDM: Educational Data Mining Conference is happening in BLR from tomorrow. https://educationaldatamining.org/ . So is COLT (https://learningtheory.org/colt2023/)
~ Ankit Sharma|2023-07-11 19:57:44|https://www.anthropic.com/index/claude-2
Brij Singh Rebright Partners|2023-07-11 20:12:32|You should read Yann Lecuns research on Joint embeddings Predictive Architecture.   https://youtu.be/OKkEdTchsiE
Paras Chopra Wingify|2023-07-11 20:17:40|I am imagining almost an internet like protocol where LLMs co ordinate, it’ll be interesting to explore such a path
Brij Singh Rebright Partners|2023-07-11 20:18:04|Yes it was me. The theory I postulated was that there instead of 1 very large LLM, there could be hundreds of smaller LLMs fine tuned on decentralised GPU cloud for specific tasks. These could then be called together on a Tree of thoughts model that feeds their analysis to a World Model.    It’s just a thesis, along on the lines of having Observer Models that monitor responses and choose the best response
Paras Chopra Wingify|2023-07-11 20:18:51|Although this is how AI takeover starts :)
Brij Singh Rebright Partners|2023-07-11 20:19:51|Haha 😂
ashish Acgt01 Twitter|2023-07-11 20:20:01|Paras, I really like your hought train.  There is a standard protocol for the coordination/orchestration between the different LLMs , coordinated by a non profit body like IETF in the internet world ( Somehow on reading your idea, my thoughts keep going to internet routing and ASs in routing ) [PHONE]
Paras Chopra Wingify|2023-07-11 20:21:14|Amazing, didn’t know that.  Would you have any link handy?
Abhinav Verma Longshot.ai|2023-07-11 20:21:39|Had seen this the TV show silicon valley to comical conclusions
Dr. Pratik Desai KissanGPT|2023-07-11 20:22:02|Nvidia infiniband says “Hi”
ashish Acgt01 Twitter|2023-07-11 20:22:37|No, this was me building on top of your thoughts train :)  Maybe we as the open source gen ai community can draw on things which have served us well in the internet infrastructure world and adapt them as we create open source LLM infrastructure
Brij Singh Rebright Partners|2023-07-11 20:23:17|So we are already working on this line of thought. Decided to work backwards from real world use cases. I was going to post this later, but why not. It would be good to have the community see -   https://docs.google.com/document/d/1iIl32UmCMgg7LVS-B-0h_fOiGww8w0-JsfpGys5E6G0/edit
ashish Acgt01 Twitter|2023-07-11 20:23:31|This was just me thinking aloud on top of your idea Paras :)
~ Mayank Gupta|2023-07-11 20:26:17|Let me add my thoughts onto this. Imagine it being permision-less. Since it can operate through prompts, I imagine it to be I/O systems, just 'Natural Language I/O'. So there can be all these specialized/optimised LLMs which can be 'called' by the natural language output of another LLM
ashish Acgt01 Twitter|2023-07-11 20:26:53|Brij, what Paras is suggesting is not digital public good infrastructure like UPI ( which is great btw, we need to do more of that in both edu and health imho)  , but internet scale , global LLM communication and coordination infrastructure.  Atleast as i understood it :)
ashish Acgt01 Twitter|2023-07-11 20:28:14|"Using some standard ""meta communication / orchestration"" format,  Which all open source and commerical LLMs support !"
~ Mayank Gupta|2023-07-11 20:38:57|I'd want to almost view the comm / orchestration layer also a purpose driven LLM. For instance I've been thinking deeply about Personal AI. In that case this orchestration can also be to enrich the inter-LLM or inter-tool comms to add user's personal context.  Again thinking out loud
~ Vishwam Jindal|2023-07-11 20:43:05|I am keen to help with this, Brij.
Brij Singh Rebright Partners|2023-07-11 20:43:06|Yup I got that. The DPI eg is just a real world business case proposal that could use an underlying tech framework on the lines he is proposing.   Ultimately we are talking about Human + Machine Intelligence decision frameworks, which is where a lot of Research is going right now. ‎[7/11/23, 20:46:48] Sumod K Mohan: ‎image omitted
Sumod K Mohan|2023-07-11 20:48:53|BottomUp + TopDown has been there in NeuroScience community for a long period. This just being one of papers utilising that.
Brij Singh Rebright Partners|2023-07-11 20:56:50|Very interesting, thanks for sharing. I’m also quite inspired by Daniel Kahnemans approach with System 2 thinking.   Essentially if we can bring in Agent frameworks that can pause, wait, repeat and rewind LLM responses and pass around at a global level for a consensus driven decision making
ashish Acgt01 Twitter|2023-07-11 20:58:21|"I think there will be two broad high level classes of applications :  1. Almost autonomous ( with negligible human feedback and suggestions )  2. Human - ai agent active collaboration class of applications :  Notably medicine, where for regulatory, psychological and other reasons, it will be not feasible to do fully autonomous decision making .  Here there will be active collaboration between ai agents and human domain experts( doctors) with the domain expert offloading the ""ai suited"" ( vaguely defined I know for now), parts of their workflow to the ai agent and the human expert will make the final decisions and ""steer"" the whole workflow of the domain specific task !"
Kaushik S YC W23|2023-07-11 21:36:13|Folks who have worked with the Falcon instruct LLM - are there a set of prompt engineering best practices that work best for this model/other OSS models?  I am not getting good results with the prompting techniques that work really well for ChatGPT.
Abhinav Verma Longshot.ai|2023-07-11 21:42:55|let's check this out ‎[7/11/23, 21:43:09] Abhinav Verma Longshot.ai: ‎image omitted ‎[7/11/23, 21:47:03] Gokul Krishnan: ‎image omitted
Gokul Krishnan|2023-07-11 21:47:49|Ah sorry, I have to go to keras_core/announcement
Abhinav Verma Longshot.ai|2023-07-11 21:49:17|So claude has put claude 2.0 and the other models 1.3 1.2 are no longer showing in the api reference. So technically they only have 2 models  They have also updated their streaming. Its more like openais streaming now ‎[7/11/23, 21:53:54] Ambika Computational Mama: ‎image omitted
Ambika Computational Mama|2023-07-11 21:54:07|sad 😞
Abhinav Verma Longshot.ai|2023-07-11 21:55:23|I was testing via api key and console.anthropic
~ Srinivasan Nandakumar|2023-07-11 21:55:24|Maybe they also went ahead with a mixture of experts with these older versions
Ambika Computational Mama|2023-07-11 21:55:42|That works.
Ambika Computational Mama|2023-07-11 21:55:45|?
Ambika Computational Mama|2023-07-11 21:55:51|Ok will check it out too
Abhinav Verma Longshot.ai|2023-07-11 21:56:56|The older models exist, maybe they'll deprecate it out later. Its got the context length of the 1.3 model 100k ‎[7/11/23, 22:04:23] Sandeep Srinivasa RedCarpetup: ‎image omitted
Kaushik S YC W23|2023-07-11 22:12:42|VPN?
~ Ankit Sharma|2023-07-11 22:25:27|https://pastebin.com/npjASbNp
Abhinav Verma Longshot.ai|2023-07-11 22:26:21|It works well via API. This model is promising
Alok Bishoyi|2023-07-11 22:26:27|Lovely
Abhinav Verma Longshot.ai|2023-07-11 22:31:23|This seems to confirm the rumors of MoE
Sumod K Mohan|2023-07-11 22:39:57|In short term reasoning at generated text seems reasonable (you can see the intercode paper, an initial attempt). We think in human language it is not necessary to bring reasoning to that level. The problem being generating reasonable text from internal representation will take 10^15 flops. That will still be slow. We already have game engines etc that does reasoning over world objects (essentially representation of world objects as data structures). These objects can reason probably in few thousand operations, many orders of magnitude faster. That is sort of Lecun idea too. Others too have thought of it. [PHONE] will be talking at FifthElephant about his work at Unity using RL in such world's. Disclaimer: I am the curator of the conference.
Sumod K Mohan|2023-07-11 22:40:15|The paper I mentioned earlier,  they also similar ideas of simpler pliable world representation, like a simple world simulator. Pulkit at MIT, had build a robot that automatically explores and learn such world representation. ‎[7/11/23, 22:52:19] Abhishek Mishra: ‎image omitted ‎[7/11/23, 22:53:36] Abhishek Mishra: ‎GIF omitted
Ambika Computational Mama|2023-07-11 23:05:31|this is a nice youtube channel: https://www.youtube.com/@arizeai
ashish Acgt01 Twitter|2023-07-11 23:20:24|Thanks Sumod for mentioning Pulkit !  Brilliant researcher & found that he cofounded Safely you - a company to detect & prevent falls in seniors in nursing homes https://www.safely-you.com/ https://www.youtube.com/watch?v=rrUoeLPkbC8  As someone interested in biomedical applications of ai, so inspiring !  also advisor to a company which makes robots for factories : https://www.tutorintelligence.com/
Abhinav Verma Longshot.ai|2023-07-11 23:24:56|Claude has knowledge base of early 2023
Sanyam Bhutani|2023-07-11 23:26:11|AMA about Claude 2 🫡
Sanyam Bhutani|2023-07-11 23:26:25|I’m a happy user
Kaushik Bokka|2023-07-11 23:26:36|how do I get access? :)
Abhinav Verma Longshot.ai|2023-07-11 23:27:55|😂. I applied and luckily we got access within a month. Had to give  detailed answer to a lot of questions. Ask [PHONE] about access.
aashutosh GenerativeAI WhatsApp Group|2023-07-11 23:29:04|I just got access, they also released a public portal now for us and uk
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-07-11 23:36:01|Exactly. And the best part ? That meta communication and orchestration format is plain and simple English.
~ Ketan Gangal|2023-07-11 23:54:38|https://github.com/microsoft/nni ‎[7/12/23, 04:43:53] ~ Kp: ‎image omitted
Brij Singh Rebright Partners|2023-07-12 07:11:14|Thanks for the heads up on Sachin’s talk, looking forward to it.   [PHONE] happy to support FifthElephant through my new initiative, Snowmountain.ai  Will DM
Zainab Bawa|2023-07-12 07:20:29|Sure
~ Karan Gandhi|2023-07-12 07:20:31|When will this be?
Zainab Bawa|2023-07-12 07:27:15|11 August - https://has.gy/1ZAa
~ Aditya|2023-07-12 07:58:19|‎~ Aditya was added
~ vibhorkarnawat|2023-07-12 07:58:19|‎~ vibhorkarnawat left
Anubhav mishra Zupay|2023-07-12 09:41:51|https://tinyurl.com/44zap9bb  Mixpanel finally announces Gen AI for product analytics this is big,
Abhinav Tushar|2023-07-12 09:53:00|‎Abhinav Tushar joined using your invite
~ Deven|2023-07-12 09:54:11|Why you using tinyurl? ‎[7/12/23, 09:54:52] C Chaitanya Nutanc: ‎image omitted
~ Sudhanshu Heda|2023-07-12 09:57:26|Eventually it will just tell you that it was pulling your leg and there is no code. I think this is Inflection’s way of saying “As an AI language model..” ‎[7/12/23, 10:08:51] ashish Acgt01 Twitter: ‎image omitted
Abhishek Mishra|2023-07-12 10:35:32|No need to work when you can just butter them up?
Ambika Computational Mama|2023-07-12 10:36:39|Hi any easy ideas to make Hypothetical Document embeddings (assume: I don’t know how to use langchain but I have a few vectorDB + gpt4 tools I can use)
Kaushik Bokka|2023-07-12 10:56:21|system prompt: “Be a tease and don’t forget to be annoying” hahaha
Sudharshan GenAI|2023-07-12 11:00:40|Kinda annoying eh?
Sudharshan GenAI|2023-07-12 11:00:57|Too much fluff
Kishore GenAI|2023-07-12 11:16:37|Ask it to stop replying with emojis. It will fail. ‎[7/12/23, 11:18:30] Kishore GenAI: ‎image omitted
jyotirmayjk Hackathon|2023-07-12 11:20:55|This is rough workflow to make your own HyDE pipeline   Step 1- Prompt 1:Write a passage to answer the question “{user_query}” Output:{passage}  Step 2:Generate embeddings of the GPT created passage  Step 3-Calculate similarity score between generated passage and your store of embeddings to return p-k results
jyotirmayjk Hackathon|2023-07-12 11:21:57|Step-3 is similar to what we typically do in RAG We calculate similarity score between question and embeddings  You now just have to replace it with calculating similarity score between generated document and your actual documents
Ambika Computational Mama|2023-07-12 11:22:33|ok right so there is no way for me directly try this as prompted steps?
jyotirmayjk Hackathon|2023-07-12 11:23:13|Can you explain what do you mean by prompted steps ?
Ambika Computational Mama|2023-07-12 11:24:12|im just trying to see if one can just use GPT/LLMs to solve this
Ambika Computational Mama|2023-07-12 11:24:55|without any/no programming ‎<This message was edited>
ashish Acgt01 Twitter|2023-07-12 11:25:10|"If you want to try Claude 2 , you can pay for Poe and get access to Claude2 and file uploading  ""Along with these features, we are excited to launch new models: Claude 2, with its 100k-token context window, available free to all users today! Claude 2 brings a major capability improvement over the previous version of Claude (which was called Claude+). The improvement is most notable in coding, math, and complex reasoning tasks. We are also excited to make Claude instant, with its 100k context window, available free to all users on all platforms with increased limits. The 100k-token context window is enough to hold a medium-length book in most languages. ChatGPT-16k and GPT-4-32k are also now available on Poe. These models are especially useful with these new features. They are initially available exclusively to Poe subscribers, but we hope to bring them to everyone over time. """
~ Ashish|2023-07-12 11:25:37|instead use VPN ‎[7/12/23, 11:25:49] ashish Acgt01 Twitter: ‎image omitted
~ Ashish|2023-07-12 11:26:01|check my snapshot ‎[7/12/23, 11:26:14] ~ Ashish: ‎image omitted
jyotirmayjk Hackathon|2023-07-12 11:26:57|Only the first step needs LLM Remaining steps do need some programming  You can’t build this pipeline in just ChatGPT  You can do it with  Code Interpreter with just prompts
Ambika Computational Mama|2023-07-12 11:27:42|thanks Jyotirmay! this was much more helpful than most of youtube!
Ambika Computational Mama|2023-07-12 11:27:52|you explained it so well!
jyotirmayjk Hackathon|2023-07-12 11:30:23|Here’s how you can do it via Code Interpreter   Step 1:Prompt 1:Generate passage for my query Step 2 Generate embeddings for new passage (Code Interpreter possibly can’t do it I think by itself)  Step 3:Upload file of both embeddings Prompt 3:Compare uploaded file and previous file and return top 5 matching documents
Abhishek Mishra|2023-07-12 12:04:49|It's on some digital weed. Those responses are out of control.
Abhishek Mishra|2023-07-12 12:15:03|Hyde jupyter notebook demo - https://github.com/texttron/hyde/blob/main/hyde-demo.ipynb
Anubhav mishra Zupay|2023-07-12 12:15:52|Lol insane, reminds me of Samantha from the movie here , how've they trained it ? The extent of such a human-like response
Sandeep Srinivasa RedCarpetup|2023-07-12 12:17:56|i have kinda production api code for this (and not notebook) in edgechains. dm me if u need it - ill get my engineer to share it.
Nilesh Transcend|2023-07-12 13:46:41|Twitter but for agents prompting each other?
Rajesh RS Generative AI WhatsApp Group|2023-07-12 14:16:23|Probably an extension of function calling?
Dev Aggarwal|2023-07-12 14:24:51|POV you walk into a grocery store filled with school kids, one lamnets, I have so much homework, other yells “CHATGPT” and continues to buy chocolate.
~ Sankalp Patidar|2023-07-12 14:44:17|Hello everyone,  Is there anyone in this group or anyone who knows someone who is working on *Graph Database* particular Nebula Graph DB. Needed some help with my ongoing work. PS: If [PHONE] [PHONE] you guys know anyone please let me know. A bit urgent
Nirant|2023-07-12 15:12:27|Using Code Interpreter to refactor functions and add type hints https://chat.openai.com/share/f610525d-dd9d-4e6e-9be8-b665d5176de4
~ Chaitanya  Kumaria|2023-07-12 15:17:53|I have pdfs and wish to extract tables and text simultaneously and the table should be exactly structured as in the pdf, what are some of the ways of doing it?
Nirant|2023-07-12 15:18:26|pdfminer3k/pdfminer for text, camelot for tables
Rajeev Singh Naruka|2023-07-12 15:35:23|You could do it without the interpreter right? Is it the extra assurance that it works that makes it more useful over regular GPT-4?
~ Chaitanya  Kumaria|2023-07-12 15:44:47|I have tried these but the results were not satisfactory, especially camelot it misses tables ‎<This message was edited>
~ Sparsh|2023-07-12 16:28:40|https://twitter.com/nirantk/status/1679077790652727296?s=46&t=-TmKToNqATUje3tCJ-w9ug Thanks [PHONE]
~ Kushaal Devanahalli|2023-07-12 17:40:07|I am currently working with Neo4J. Might possibly be able to help.
~ Happy Chaudhury|2023-07-12 18:01:27|Any experiment on comparing QA on specific context using Salesforce/xgen 7b inst and falcon 7b or any other. I have done with bert, deberta, Salesforce xgen , xgen is giving quite better results.was thinking if anyone have tested falcon vs xgen ?
~ Happy Chaudhury|2023-07-12 18:01:57|Llama can we use for commercial purposes? Haven't yet tried it
Chaitanya A GenAI|2023-07-12 18:02:46|cant be
Abhishek Mishra|2023-07-12 18:04:37|You can try via this simple colab notebook - https://colab.research.google.com/drive/146tQjjmR7ZCO314IYmlxJ5vOB6WK2czH?usp=sharing
Abhishek Mishra|2023-07-12 18:05:16|I changed the notebook to only run via inference api. If you need to load it locally, minor changes can be done
~ Ankur Khandelwal|2023-07-12 19:02:34|Does anyone know how to get access gpt-4-32k	openai model?
~ Ankit Sharma|2023-07-12 20:12:32|https://wandb.ai/capecape/LLMs/reports/How-to-Run-LLMs-Locally--Vmlldzo0Njg5NzMx
ashish Acgt01 Twitter|2023-07-12 20:16:41|A longish but non-technical good read by nathan lambert ! https://www.interconnects.ai/p/llm-agents-integration ‎[7/12/23, 21:29:54] Abhishek Mishra: ‎image omitted
Krishna Panchal|2023-07-12 21:30:49|https://x.ai/  Elon Musk just announced their new AI company, xAI. ‎<This message was edited>
Divya Tak|2023-07-12 21:34:04|but i thought he wanted no one to make any movement in AI for 6 months :P
Aditya Sista 2010B5|2023-07-12 22:05:28|Has gpt4 been rolled out for everyone? And how about the code interpreter?
Aditya Sista 2010B5|2023-07-12 22:05:39|I meant in API
Anshul Bhide Replit|2023-07-12 22:07:25|yes
Anshul Bhide Replit|2023-07-12 22:07:36|I had to go to settings and enable it
Abhishek Mishra|2023-07-12 22:13:44|Anybody who ever made a payment towards openAI for api has got access to GPT4 api
Shashwat TDC|2023-07-12 22:25:50|Expecting more control and transparency over llm data.
~ Nayan Shah|2023-07-12 22:49:12|is code interpreter been rolled out as API ?
~ Nayan Shah|2023-07-12 22:53:17|want to try more out like code interpreter as working on QA tasks and sometimes pdfs/url both have structured and unstructured data and that is messing up the results some time.  has anyone had similar issues ?  Also some time as i have a backgorund job kind of task wehre i am generating data from gpt api , and after 200 request with every request i have a sleep of 15 sec still it sometimes come back with 502 .. has anyone else also noticed the same thing ?
~ Arindam Barman|2023-07-12 22:56:47|No it hasn't
~ Suhas Baliga|2023-07-12 23:03:20|We have the same problem with docx.
ashish Acgt01 Twitter|2023-07-12 23:15:39|Anyone here tried danswer ?  https://github.com/danswer-ai/danswer  [PHONE]  [PHONE]  [PHONE]  [PHONE] [PHONE] , others ?
Abhishek Mishra|2023-07-12 23:20:43|I saw their demo some time back. But my org needs a completely local solution right now as the NDAs aren't laid out with any of the Gen AI service providers (openAI/MS). We also have to manage access of documents across 3 levels of confidentiality. So I'm spinning up a self-hosted CPU solution using Falcon 7b GGML locally.
ashish Acgt01 Twitter|2023-07-12 23:24:23|My impression is :  +s - it's relatively easy to build a prototype - Mit license - can self host - fairly active slack and discord  -ves :  - less control ( can only check indexing status of knowledge base by viewing logs) - okish documentation, not great ‎<This message was edited>
Shivendu Kumar|2023-07-12 23:28:23|https://www.glean.com/blog/lessons-and-learnings-from-building-an-enterprise-ready-ai-assistant  Loved the advanced query planning part. ‎<This message was edited>
Shivendu Kumar|2023-07-12 23:31:25|What a coincidence. This sounds like an open source version of Glean.
ashish Acgt01 Twitter|2023-07-12 23:36:39|"danswer maybe a little rough at the edges and not all the bells and whistles, but might be good enough for a lot of smb enterprise usecases, which need something which ""gets the job done"" but maybe not the most performant and efficient !"
Abhishek Mishra|2023-07-13 00:03:20|Good read. Comprehensive coverage of the actual challenges.
~ Happy Chaudhury|2023-07-13 01:22:57|Tested for both xgen 7b inst and falcon 7b inst , running in CPU both ..I find xgen is Faster than  Falcon and gives better performance as well.
~ Happy Chaudhury|2023-07-13 01:46:53|Also surprisingly falcon 7b gave good results on very complex prompt but it takes quite more  time.
Abhishek Mishra|2023-07-13 01:47:09|Yes, xgen is the best 7B model overall and also commercial.
~ Happy Chaudhury|2023-07-13 01:47:27|Thanks for the colab
~ Happy Chaudhury|2023-07-13 01:47:32|One
~ Happy Chaudhury|2023-07-13 01:47:36|Really helpful
Abhishek Mishra|2023-07-13 01:47:50|Unfortunately xgen uses openAI tiktoken tokenisation method and thus llama.cpp doesn't have GGML support for them. ‎<This message was edited>
~ Happy Chaudhury|2023-07-13 01:48:15|You mean Falcon
~ Happy Chaudhury|2023-07-13 01:48:17|?
Abhishek Mishra|2023-07-13 01:48:56|Xgen, fixed my message in edit
~ Happy Chaudhury|2023-07-13 01:49:31|Yea
Abhishek Mishra|2023-07-13 01:49:47|As soon as xgen tokenisers find support in ggml, we will have good 4 bit version to test locally as well.
~ Happy Chaudhury|2023-07-13 01:50:30|Very new to this just trying for QA which on legal docs
~ Srinivasan Nandakumar|2023-07-13 07:15:41|Have a question regarding embedding fine-tuning mentioned in this article. What's the task/loss you generally use? Is it next token prediction for a decoder and MLM for encoder?
Lohith GenerativeAI WhatsApp Group|2023-07-13 07:23:59|Does anyone aware of /read fine print about level of data privacy for enterprise org to use GPT on azure?
Dr. Pratik Desai KissanGPT|2023-07-13 07:38:11|Something for [PHONE] and [PHONE] to benchmark in next run, pg_embedding. https://twitter.com/neondatabase/status/1679146260916314112
~ Akarsh Gupta|2023-07-13 08:36:44|‎~ Akarsh Gupta was added
~ Akarsh Gupta|2023-07-13 07:42:54|Hey everyone I am Akarsh Gupta currently working as an Applied Scientist at artifact.io I work on NLP problems like question answering, summarization, semantic similarity and ofc GPT prompt engineering :p Excited to be a part of this community
Bharat Kumar Ramesh Hashmal Web3|2023-07-13 08:09:01|https://twitter.com/dxlantxch/status/1679180540774338560?t=JFXoq16Z_EKVQdw8fTEQeg&s=08
Bharat Kumar Ramesh Hashmal Web3|2023-07-13 08:09:39|Vscode extension for error debugging. Checking this out. Will drop feedback
Alok Bishoyi|2023-07-13 08:29:58|https://twitter.com/tobi/status/1679114154756669441?s=46  Interesting to see Indian vs western mindset / approaches to using AI. We saw another Indian company positioning itself as shopify competitor use AI very differently. Ofc there is differences in scale, company situation as well as culture, but still
Ishaan Bhola Contlo|2023-07-13 08:37:27|‎Ishaan Bhola Contlo was added
~ Mayank Gupta|2023-07-13 08:38:47|I'm not debating the larger point you're making but just want to say that the Indian approach was more a way to market a product / justify a layoff in a market which is tough for them. I wouldn't necessarily use that to compare AI approaches.
Chetanya Rastogi|2023-07-13 08:50:02|"For fine tuning an embedding model, the most common approach is to have a two-tower architecture where you first embed the query and a doc using an encoder, calculate the cosine similarity and then backprop on the ""error"" between the calculated similarity and the true similarity. You can get a more detailed read here https://www.sbert.net/docs/training/overview.html#loss-functions"
~ Srinivasan Nandakumar|2023-07-13 08:53:09|Thanks! 👍🏽
Nirant|2023-07-13 09:09:33|Congratulations to Saurab [PHONE] for making it to the *Vercel AI Accelerator* and a shot at $850K in credits!
Nirant|2023-07-13 09:09:34|https://aasaan.app/ is the only Indian company I could find in the winners list If someone knows the founders, engineers there — would love to have them here!
Nirant|2023-07-13 09:09:54|Vercel AI Accelerator Participants list: https://vercel.com/blog/ai-accelerator-participants
Anshuman Pandey|2023-07-13 09:14:27|Any startups here interested in running a similar program for other startups in India/SEA?
Paras Chopra Wingify|2023-07-13 09:27:25|We would be happy to give credits for VWO, in case anyone wants to do A/B testing and Optimization on their websites, models or apps.  Not sure this is the most pressing need though :)
ashish Acgt01 Twitter|2023-07-13 09:43:00|"google's take on an ""ai notebook"" - notebooklm https://blog.google/technology/ai/notebooklm-google-ai/  sadly, us only for now https://notebooklm.google.com/signup  https://news.ycombinator.com/item?id=36697119"
~ Ankit Sharma|2023-07-13 10:02:10|anyone here tried zed.dev?  they recently released an assistant with the editor which connects to GPT models upon pasting the openai api
Saurab Paruthi|2023-07-13 10:09:13|Thanks Nirant! I applied with just an idea. Looks like there are already existing startups as a part of the group.
C Chaitanya Nutanc|2023-07-13 10:21:39|If there is interest we(Ozonetel) can share credits and help in setting up WhatsApp account and give access to embeddings APIs and some other NLP APIs which we use(sentiment analysis, gender detection etc)
Pratiksha Dake Unacademy|2023-07-13 10:23:02|Woke up to get a rejection email. 😭😭
Pratiksha Dake Unacademy|2023-07-13 10:24:01|Wonders sounds like a good idea.   Normally, I wouldn't read research papers.  But if their knowledge is available for me to query, get summaries of, etc. that would be of a great help
Piyush Makhija|2023-07-13 10:24:11|I'm not familiar with the Indian approach here. Can somebody share ?
Pratiksha Dake Unacademy|2023-07-13 10:25:00|https://readwonders.com/
~ Prajna Prayas|2023-07-13 10:29:35|tried the app pretty slick!
~ Arya|2023-07-13 10:32:28|https://docs.google.com/forms/d/e/1FAIpQLSczx0XPMTkoHmnxcY2mgz47wknLORl-MyAU78tB2fux2F-GBQ/viewform
~ Arya|2023-07-13 10:32:53|Exciting Session on accelerated LLM building workflows with NVIDIA Experts!
Sudharshan GenAI|2023-07-13 11:40:13|https://www.steamship.com/  Great deployment solution
Kaushik Bokka|2023-07-13 11:52:23|have you used it?
Sudharshan GenAI|2023-07-13 11:53:56|Planning on
Sudharshan GenAI|2023-07-13 11:54:06|You can deploy tg bots easily
Sudharshan GenAI|2023-07-13 11:54:12|Add TTS
ashish Acgt01 Twitter|2023-07-13 12:07:15|what is the name of Saurab's startup ?
ashish Acgt01 Twitter|2023-07-13 12:07:16|auditgpt ‎[7/13/23, 12:14:50] Pratiksha Dake Unacademy: ‎image omitted
Nirant|2023-07-13 12:15:40|You're gonna love the Elicit.org beta. It's radical for all the healthcare searches I do.
Paras Chopra Wingify|2023-07-13 12:17:23|I use it all the time too
Pratiksha Dake Unacademy|2023-07-13 12:23:08|not quite what I had in my mind, but still a lot better interface than wonders
Ankur Pandey|2023-07-13 12:32:23|Consensus wants to do that too but I didn't find all that convincing so far
Anshul Bhide Replit|2023-07-13 12:33:38|https://twitter.com/0xSamHogan/status/1679192480565309441  Here are some valid criticism of Langchain ; repasting here (sorry in advance for the wall of text)  1. Heavy use of OOP. Having multiple layers of abstraction makes it really hard to tell what is going on under the covers, debug, or modify code slightly. This is the biggest thing I've seen people struggle with / struggled with myself -- it's just not clear what exactly is going on a lot of the time. For example, the ConversationalRetrievalQAChain makes augmented chat really easy but obfuscates most of the dials devs would turn to tune a real world application, and it's not clear how to easily get access to lower levels of the code.  2. Most of the connectors to external systems are half-baked. I think a lot of these were meant to be used as reference implementations to help devs build their own bespoke integrations but a lot of people don't necessarily realize that and end up frustrated trying to use them.  3. Hard to debug. This kind of goes back to item 1 but I want to call it out specifically. When something goes wrong, it's really really hard to find out where the issue is, mostly because of the layers of abstraction. For ConversationalRetrievalQAChain, for example, there are a lot of moving parts and getting to the bottom of an issue usually involves pulling the langchain repo and diving code to understand what it's doing. IMHO, this sort of defeats the purpose of having an external library and is ultimately why I pulled most of my projects off langchain.  4. The docs currently have some good examples of how to use langchain out-of-the-box. It would be nice to see some docs that discuss more advanced, app-focused, use-cases.
Neha YC W23|2023-07-13 12:46:28|https://github.com/assafelovic/gpt-researcher
Neha YC W23|2023-07-13 12:47:36|https://www.reddit.com/r/ChatGPT/comments/14xt5e3/ceo_replaced_90_of_support_staff_with_an_ai/
Neha YC W23|2023-07-13 12:47:50|And here it is :)
Abhinav Verma Longshot.ai|2023-07-13 12:59:15|This guy got roasted creatively on Twitter.
Nirant|2023-07-13 13:02:57|Amazing marketing for his new product though!   Can't think of any campaign from India which took tech twitter by storm for an entire 1-2 day cycle since Kunal Shah memes.  More power to Dukaan and folks there ‎[7/13/23, 13:04:09] Rohit Aggarwal: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-13 13:04:33|Ceogpt
Ojasvi Yadav|2023-07-13 13:04:58|More to come this week ;)
Ankur Pandey|2023-07-13 13:13:19|Taking GenAI gold rush analogy a bit further  https://twitter.com/AnkurPandey/status/1679395407305265153
Pratiksha Dake Unacademy|2023-07-13 13:13:36|their new product hallucinates a lot though
Sudharshan GenAI|2023-07-13 13:13:58|Haha agree
Ankur Pandey|2023-07-13 13:15:56|Startup founders like their fragrance Musk
Pratyush Choudhury|2023-07-13 13:24:30|Question is does this help a B2B company as much as it would help a B2C company
Krishna Ntkris|2023-07-13 13:27:48|In my experience, this erodes trust very quickly with uses
~ Arindam Barman|2023-07-13 13:28:01|Don't know how much of these tactics work but for me deceptive ones like these are a red flag
Anshul Bhide Replit|2023-07-13 13:30:57|IMO It’s not deceptive - it’s being controversial to get attention and stand out especially in this crowded AI space. Musk does this quite well.  And some publicity is better than obscurity :)
~ Arindam Barman|2023-07-13 13:32:48|I'd respect them much more if they were just honest about it even if it means they actually laid of their 90% of the CS because of their chatbot. But a fake stance is what I don't admire. Just a personality thing for me.
Abhinav Verma Longshot.ai|2023-07-13 13:32:50|Ya, he definitely laid off employees, so he's not deceptive about that
~ Arindam Barman|2023-07-13 13:33:17|not because of the chatbot.
Abhinav Verma Longshot.ai|2023-07-13 13:34:21|You would hope the chatbot works and does not respond As a large language model , I cannot solve your issues , I'm marking your ticket as resolved , good day
~ Arindam Barman|2023-07-13 13:35:12|I like the bot. At least it is not deceptive like the founder's tweet
Ankur Pandey|2023-07-13 13:37:00|Just trying to ensure that when the AI overlords come they kill him last
Pratiksha Dake Unacademy|2023-07-13 13:37:23|had they thought of integration docs at the time of launching, the whole tone in announcing it would have been different
Pratiksha Dake Unacademy|2023-07-13 13:38:14|hasn't work well for me. it's been deceptive many times :P
Divya Tak|2023-07-13 13:38:59|Deception requires both self awareness and a theory of mind. I dont think AI possesses either
Pratiksha Dake Unacademy|2023-07-13 13:39:41|hallucination to max level --> deception
Divya Tak|2023-07-13 13:40:32|wrong info != deception though
Divya Tak|2023-07-13 13:40:56|AI is wrong many time and confidently wrong
~ Arindam Barman|2023-07-13 13:41:08|quite interesting to see Dukan and Shopify taking different approaches to intergating AI. Shopify's sidekick AI is built for the seller's side and dukan's one is becoming a sitegpt  competitor - maybe towards Intercom one day.
Abhishek Mishra|2023-07-13 13:42:35|Team Roko
ashish Acgt01 Twitter|2023-07-13 14:04:51|Yeah, I also found it meh.  My fav research paper assistant tool is scispace - typeset.io recommended by [PHONE]
Paras Chopra Wingify|2023-07-13 14:06:38|Why are we celebrating people being let go of their jobs?  I don’t think this needs celebration (even if it is inevitable)
Ankur Pandey|2023-07-13 14:06:54|Exists since pre LLM era.
ashish Acgt01 Twitter|2023-07-13 14:07:04|It's an Indian team , yay ! Saikiran Chandha  https://yourstory.com/2017/09/typeset-google-docs-for-research-funding
Sudharshan GenAI|2023-07-13 14:20:50|Oh wow, I've known Shanu, one of the founders since 2018  How are these folks doing?
Ankur Pandey|2023-07-13 14:27:00|Couple of mil ARR
Sudharshan GenAI|2023-07-13 14:27:18|Nice, pretty good
Bharat Kumar Ramesh Hashmal Web3|2023-07-13 14:30:21|I think shopify is leaving this part for their appstore
Satyajit Roy|2023-07-13 14:36:34|its interesting what dukaan has done, i was thinking of a similar use case for insurance agents. made a notebook which answers questions from a insurance policy wording  document, adding a system message and prompt which defined the role and scope as within insurance and within the context. Used Pinecone as the vectorDB. Works decently although it does hallucinate sometimes, but when it answers correctly its accurate and to the point. Im Satyajit, new to AI, building for fun!
Satyajit Roy|2023-07-13 14:37:05|Thanks for adding me here Nirant & Aakrit. Awesome to be a part of it!
~ Arindam Barman|2023-07-13 14:39:54|I made some progress trying to sell a similar solution to maxlife but at that time it was only davinci-3 and costs were very high / accuracy low. They were interested but stopped replying at one point. I think if someone wants to reignite this, it might become interesting to their agents again. They have around 5k internal agenst + 20k external ones. Good opportunity
Devansh Gulhane|2023-07-13 14:46:30|‎You added Devansh Gulhane
Sudharshan GenAI|2023-07-13 14:50:03|https://www.merse.co/  Journal -> Comic  Great idea :)
Anshul Bhide Replit|2023-07-13 14:54:55|pretty cool - bard exports code to replit now https://twitter.com/amasad/status/1679401907276636161
Satyajit Roy|2023-07-13 15:10:49|i used gpt3.5-turbo for my efforts, but now that i have access to gpt4 api i can try it with gpt4-0613 model for more consistent results. Definitely an opportunity here
Sudharshan GenAI|2023-07-13 15:16:29|[PHONE] feature request
Sudharshan GenAI|2023-07-13 15:19:04|If not I'll be building this with a custom model :P  It's such a beautiful product
Paras Chopra Wingify|2023-07-13 15:24:13|couldn’t get this to work. Sounds intriguing but not sure what it is.  Any screenshots? ‎[7/13/23, 15:24:35] Paras Chopra Wingify: ‎image omitted
Ritwik 2013|2023-07-13 15:26:11|It's just a skeletal structure of an MVP, their generator doesn't work.
Sudharshan GenAI|2023-07-13 15:27:50|Their demo video shows the example, but their generator is broken ‎[7/13/23, 15:27:56] Sudharshan GenAI: ‎image omitted
Sudharshan GenAI|2023-07-13 15:28:09|Not the best, but gives you an idea
Sudharshan GenAI|2023-07-13 15:29:26|I want to connect this with my personal notes - obsidian, roam, notion and vizualize my stories. I've been journalling for 3+ years   Imagine adding a lora of myself, my friends and family and seeing my memories play out
Paras Chopra Wingify|2023-07-13 15:32:18|What do you want out of it?
Paras Chopra Wingify|2023-07-13 15:34:00|I’m super interested in journaling and what can come out of it
Sudharshan GenAI|2023-07-13 15:36:22|Just seeing my memories visualized - like a storybook. Instead of just pure text
Sudharshan GenAI|2023-07-13 15:37:28|Will be very interesting to add to my journals
ashish Acgt01 Twitter|2023-07-13 15:39:23|"Maybe audio highlights of the ""big"" events & memories, interwoven with photo album/google photos.  Just thinking aloud ! Very interesting idea [PHONE]"
Abhishek Mishra|2023-07-13 15:43:04|gzip is all you need - https://aclanthology.org/2023.findings-acl.426/
Sudharshan GenAI|2023-07-13 15:47:07|That's awesome too
Paras Chopra Wingify|2023-07-13 15:48:26|Isn’t photos like this?
Soumyadeep Mukherjee|2023-07-13 15:50:48|Haha have been thinking about this. Its harder than it looks for a good consistent experience 😅  eg. LORAs with experessions with poses from text.
Paras Chopra Wingify|2023-07-13 15:50:52|I meant, the photo app feature that you were doing xyz at abc time
Soumyadeep Mukherjee|2023-07-13 15:50:59|Also, composition of images are super critical for a good experience
Soumyadeep Mukherjee|2023-07-13 15:51:15|Right now, throwing text at any model as prompt just gives pictures
Soumyadeep Mukherjee|2023-07-13 15:51:21|Having them as a story is different.
Soumyadeep Mukherjee|2023-07-13 15:51:41|"Thats still a creative endeavour and the way we are doing it internally is through ""storyboards"""
Soumyadeep Mukherjee|2023-07-13 15:51:47|Someone has to create a storyboard.
Soumyadeep Mukherjee|2023-07-13 15:52:17|My sense is, yes I can get a toy out in a day, but can I get something out that most of us will pay for? Maybe not 😅
Soumyadeep Mukherjee|2023-07-13 15:53:13|Even GPT4 is horrible at storyboarding.
Soumyadeep Mukherjee|2023-07-13 15:53:46|My benchmark is any webtoon/dashtoon comic today.
Soumyadeep Mukherjee|2023-07-13 15:56:17|But pretty confident, once we get there, would share it here :D
Abhishek Mishra|2023-07-13 15:57:54|Just brainstorming, for storyboarding, wouldn't the text to video models be more reliable here?  Given a scene, generate a small text to video output. Convert it into good 4-5 images that are coherent and then try to generate a dialogue based output from these 4-5 images given the original prompt describing the scene.
Abhishek Mishra|2023-07-13 15:59:36|Scene description -> Video -> Small Set of images -> Dialogue for each image given original scene as context -> Set of images with dialogues? ‎<This message was edited>
Soumyadeep Mukherjee|2023-07-13 15:59:57|Umm two issues I have with current t2v 1. They arent great storyboards either. 2. Storyboards need to be coherent across more than a 5 frames. Its across think 500 frames at least.
Soumyadeep Mukherjee|2023-07-13 16:00:18|Storyboards are just a random representation of text. They are a artists eye to the story.
Soumyadeep Mukherjee|2023-07-13 16:00:42|Maybe if we have a model trained on good storyboards, sure.
Abhishek Mishra|2023-07-13 16:01:04|I see. Good to know.
Aashay Sachdeva MPL Data Scientist|2023-07-13 16:01:06|There was some research by deepmind on this specifically right?
Soumyadeep Mukherjee|2023-07-13 16:01:34|Is it? What was it called any idea? 🤔
Soumyadeep Mukherjee|2023-07-13 16:01:48|"""are not"
Aashay Sachdeva MPL Data Scientist|2023-07-13 16:01:58|https://www.deepmind.com/publications/story-centaur-large-language-model-few-shot-learning-as-a-creative-writing-tool
Aashay Sachdeva MPL Data Scientist|2023-07-13 16:02:15|dramatron
Aashay Sachdeva MPL Data Scientist|2023-07-13 16:02:36|https://www.deepmind.com/open-source/dramatron
Soumyadeep Mukherjee|2023-07-13 16:02:59|Ah I have seen this.
Soumyadeep Mukherjee|2023-07-13 16:03:05|script writing is one part of the problem. ‎[7/13/23, 16:03:12] Adithya S K PESIT: v1_video_10th_July.mp4 ‎document omitted
Ankur Pandey|2023-07-13 16:06:12|[PHONE], [PHONE] - who dyou plan to sell to? Animation studios? Marketing agencies/teams? Creators (b2c)?
Soumyadeep Mukherjee|2023-07-13 16:06:52|dashtoon is b2c consumer platform. You can download the app to consumer our comics or use the creator studio to create your own.
Adithya S K PESIT|2023-07-13 16:07:15|i was planning to make it open source just like automatic1111
Adithya S K PESIT|2023-07-13 16:08:30|but the main bottle neck with the pipeline is creating prompts for the image generation
Abhishek Mishra|2023-07-13 16:10:24|I like your idea. I'll help if I can add any value.
Paras Chopra Wingify|2023-07-13 16:16:51|This looks great
Alok Bishoyi|2023-07-13 16:18:27|Could be a whole genre of reels/ tt content :)
Adithya S K PESIT|2023-07-13 16:19:15|yeah plan with the open source project was to see how people actually use it then try to build a fine tuned product
Adithya S K PESIT|2023-07-13 16:19:28|it can used to generate reels story books for kids , presentations etc
Paras Chopra Wingify|2023-07-13 16:19:34|What exactly is the issue you’re solving in prompts for image generation?  Diversity
~ Mayank Gupta|2023-07-13 16:19:37|This is really kickass 🔥
ashish Acgt01 Twitter|2023-07-13 16:22:06|"Yassss !  [PHONE] not everything has to be made with a clear idea of ""selling"" ! I am going to sound like an out of touch idealist, but there is joy in just building, without worrying about who will buy this :) #justpullingyourleg :D"
~ Prashanth Harshangi|2023-07-13 16:22:52|Amazing. Great for parents like me who lack the imagination to tell stories. I would definitely use this to tell custom stories to my son about good habits - morals - legendary goal setting etc. I previously used sabu.ai (app.sabu.ai) for some text based stories but with images this takes it to a whole new level. Would love to try out when you release it.
Satyajit Roy|2023-07-13 16:25:05|This is amazing! Curious how youve handled consistent character generation... struggled with that when i was trying something similar last month...
Adithya S K PESIT|2023-07-13 16:25:12|its asking gpt to generate best prompts to feed to SD if the storyline has only one character it works out fine but multiple characters it becomes hard then there is also the question of if the current image generated is going to be different from the pervious image that was generated and how different should they be or what all factors should overlap  these are some of the surface level issues I faced
Abhishek Mishra|2023-07-13 16:26:28|It feels like this will truly be solved with multimodal AI that can be fine tuned for this or is already fine tuned for this task. But until then we can play with what we have.
Adithya S K PESIT|2023-07-13 16:26:55|agreed
~ Yash|2023-07-13 16:27:53|My son Atharv fascinated by 2 things, My pet german shephard Atom and the ceiling fan in my bedroom (for some reason, I guess all toddlers are). https://youtu.be/qDYux7mTYHU  Had made this for him on his first birthday using mid journey some time back. Glad to see such pipelines popping up, this was a lot of hardwork back then 😅
~ Srijan Saxena 😎|2023-07-13 16:30:31|Very interesting!
ashish Acgt01 Twitter|2023-07-13 16:32:34|ai for ❤️, ftw !
Sandeep Srinivasa RedCarpetup|2023-07-13 16:34:42|how did u make this ? im trying to make something similar for a kid
Abhishek Mishra|2023-07-13 16:36:15|Factum Amore - Made (by) love
Karan Lightspeed|2023-07-13 16:44:00|This is super cool [PHONE]
ashish Acgt01 Twitter|2023-07-13 16:52:01|+1  Excellent stuff Yash ! is your process documented somewhere ? if not, do it !- it will help a lot of people !
~ Yash|2023-07-13 16:58:54|The process was simple, but effort intensive.   I didn't have a solid machine to be able to run anything on my local system, so I used the available online tools instead.  Came up with a simple story line, identified scenes.  asked Chat GPT to write scene descriptions. - Used them for inspirations for prompts for midjourney and Used chat GPT to comeup with prompts for midjourney.  Once the images were done, asked ChatGPT ji to write scene narration. Made few edits and then it was good to go as a PDF at least.  Didn't get adoption from son 😅, he was too young to engage with static image, no music etc.  So moved to https://invideo.io/, it gave me 2 things, nice AI based voice narration and few out of the box background music effects to make this into a video.
ashish Acgt01 Twitter|2023-07-13 17:18:28|"""Didn't get adoption from son"" :) the most important metric of them all :)  did adding music & video, win over this super important TG ? :)"
~ Yash|2023-07-13 17:29:09|🤣 Oh yes indeed. NPS was all time high
Ankur Pandey|2023-07-13 17:32:44|Stealing it for my son, will need to add lots of cars & balls. (for voice, synthesia is better)
Ankur Pandey|2023-07-13 17:33:35|On a related note - saw this tweet by someone who helped Varun Mayya! Mindblowing - https://twitter.com/sagartheamruth/status/1664671793414537228
Sudharshan GenAI|2023-07-13 17:45:16|I’m building something similar with Rafta AI  https://www.rafta.ai  Going wild with text-to-video, AI based video editing and storytelling
~ Nitin Kishore|2023-07-13 18:02:11|The celebration is for progress and not layoff. I don't find anything wrong with that either tho. You are cutting costs and saving a huge margin by improving a process that doesn't need to be done the hard way. So many people got laid off from Twitter and honestly there wasn't much difference. If their absence isn't felt, the presence is just a liability. There was once a job for people to set up bowling pins. Now we all enjoy the activity of bowling much better because the pins are reset immediately and with same accurate positioning. No one misses that job. People who got laid of from that job found something else to do because it was a low skill task. Didn't require lot of prerequisites. So in a way, jobs that are not worth doing by humans should not be done my them. They should invest their effort elsewhere. Adoption of this policy should be celebrated and encouraged. We're in the 21st century with lot of free resources. Everyone should plan for 5 years in advance. You can't expect thr entire world and all subsequent progress to take a back seat cause some people won't get off their seats and adapt to find something better. That's my belief
~ Mayank Gupta|2023-07-13 18:06:03|We must not celebrate it for the same reason that a breakup hurts someone. That someone addicted to smoking still feels ashamed to smoke in front of their parents. When someone loses a job, it's a sucky thing for them and their family. Logic/rationality and emotion can co-exist.
Bulia Siddharth Aurashop|2023-07-13 18:06:49|Firing the people you hired? Tough - Yes Moment of celebration - Hell No
ashish Acgt01 Twitter|2023-07-13 18:07:36|"Try to step out of the ""tech bubble"" most of us live in.  A 50-55 year old us factory worker, gets laid off due to ai and automation.  What do you think their options are to ""get off their seats"" ?"
~ Nitin Kishore|2023-07-13 18:08:23|That's why I started my sentence with the clarification - the celebration is for progress, not layoff. Layoff was an inevitable side effect. I'm just saying it's not really a bad thing.
Anubhav mishra Zupay|2023-07-13 18:09:14|Firing and being replaced by AI that too in s celebratory form is more hurtful for the employee.  It might be a win for tech, but not a  win for a culture. As founders one must balance coz history has seen a lot of instances when it has fired back. ‎<This message was edited>
~ Mayank Gupta|2023-07-13 18:10:09|And I think the original intention of the comment was also about perspective. Good for the company yes. Inevitable sure. But surely it sucks for the person on the receiving end. As long as we can empathise.
~ Nitin Kishore|2023-07-13 18:10:18|So what do you think we should do? Wait 30 years to get better adoption of tech, risk it becoming unused? Risk the field becoming dry due to no application? Lose all benefits and new resources the future generations will get to study and make a better life? You can't hope for everyone to win. In life everything is ranked or sorted. Holding back the top so that the bottom won't get affected is a stupid strategy. Instead there should be a better solution where the progress can be made and alternatives can be provided for those affected.
Sandeep Srinivasa RedCarpetup|2023-07-13 18:11:31|it is a bad thing and it will get worse. to cut short this debate so that it does not get very angry...everyone needs to spend their energy in supporting UBI - universal basic income. but fundamentally, there is no other way out. lot of people are going to be unemployed and it is never a good thing.
Anubhav mishra Zupay|2023-07-13 18:11:55|Why do PR. What you said made sense, but why do PR
~ Nitin Kishore|2023-07-13 18:12:12|Pr? ‎[7/13/23, 18:12:37] Anubhav mishra Zupay: ‎image omitted
ashish Acgt01 Twitter|2023-07-13 18:12:56|"The problem with ai driven societal change is that it's happening too rapidly, especially for older workers.  I don't have an answer and ai innovation must continue but we as a society need to really grapple with it and ""think hard on how to adapt to these transformational changes""  Maybe better discussed further in the philosophy group"
ashish Acgt01 Twitter|2023-07-13 18:15:38|I think this discussion is getting off topic here. Let's discuss in the philosophy group
~ Nitin Kishore|2023-07-13 18:16:09|Culture is amorphous. It's a filtered amalgamation. Survivor bias. Whatever culture we have is a Mashup of whatever survived. The cultures that made the wrong choices were erased through their own choices and inadaptibility, no? What exactly is even culture? The culture we had before tv and after tv is different. I don't think you'd complain about that. It changed even more after internet and social media. Cultures. Professions. Style of working, etc. All keep morphing with time. When the rules change, those who understand the game can still play to win. Those who won't will be constrained by new rules. That's just natural. Nothing we need to intervene in with hypothetic hyperspecific examples
~ Nitin Kishore|2023-07-13 18:17:27|Ah, that's probably that guy's pr stunt for clout, publicity or future plans for his company. His prerogative. Good or bad choice, will be based on reception and future scope
~ Nitin Kishore|2023-07-13 18:17:46|Sure
Anubhav mishra Zupay|2023-07-13 18:53:36|https://bit.ly/3rvjYt6
Paras Chopra Wingify|2023-07-13 18:58:15|Very interesting. I love how we are increasingly finding additional ways of incorporating user input into such models ‎[7/13/23, 19:04:28] Sudharshan GenAI: ‎image omitted
~ Tarun|2023-07-13 19:07:10|I've found this to be extremely useful while building AI systems. I've noticed that clients are usually willing to provide feedback in the loop to make the product perform better on their specific problem.   But as developers we tend to get consumed by attempting to build one size fits all solutions.
Shubham Sharma 2012C6|2023-07-13 19:15:30|https://www.reddit.com/r/StableDiffusion/comments/12pcbne/i_mad_a_python_script_the_lets_you_scribble_with/
Shubham Sharma 2012C6|2023-07-13 19:16:08|This has been around for a while now directly at stability ai
~ Sparsh Nagpal|2023-07-13 19:18:35|Very similar to what Nvidia Canvas did around the beginning of last year, there was a lot of hype around it SD is getting there too
Abhinav Verma Longshot.ai|2023-07-13 19:37:46|It's official for me. When composing a chatgpt prompt the service instruction doesn't carry the same weight as just putting it all in user section.
Abhinav Verma Longshot.ai|2023-07-13 19:37:47|Api.
~ Sparsh|2023-07-13 19:39:53|Can you please elaborate?
Abhinav Verma Longshot.ai|2023-07-13 19:47:14|"[{""role"":""system"",""content"":prefix}, {""role"": ""user"", ""content"": prompt}]  So its system, not service. Rather than forming a message as done above , you're better off appending the prefix and the prompt together like this new_prompt = f""{prefix}\n{prompt}"" messages = [#{""role"":""system"",""content"":prefix}, {""role"": ""user"", ""content"": new_prompt}] Much better at following instructions, even the 3.5 turbo works better this way ‎<This message was edited>"
Abhinav Verma Longshot.ai|2023-07-13 19:48:33|I had started doing the latter approach, but now its official for me, that the first approach isn't as effective ‎<This message was edited>
Shagun Arora|2023-07-13 20:26:41|‎You added Shagun Arora
Bulia Siddharth Aurashop|2023-07-13 20:29:31|They have mentioned this somewhere. Currently system doesn’t carry that much weight but eventually will
Abhinav Verma Longshot.ai|2023-07-13 20:30:51|Its mentioned in different places that system doesn't have much weight. I'm just making it official that don't use system. Its more like your tokens getting used up without a lot of returns
Nirant|2023-07-13 20:37:32|Prompt Engineering is all about writing your prompts for production every 3 months when OpenAI changes the underlying model 😭
Abhinav Verma Longshot.ai|2023-07-13 20:38:35|yeah. and now they're deprecating the completion models, the only stable models they had
Nirant|2023-07-13 20:44:07|RIP text-davinci-003 — the model we need, but don't deserve
Dhruv Naik|2023-07-13 20:45:31|Prompt Reliability Engineers
Bharat Kumar Ramesh Hashmal Web3|2023-07-13 20:48:33|https://supabase.com/blog/pgvector-performance
Bharat Kumar Ramesh Hashmal Web3|2023-07-13 20:48:43|[PHONE] - your thoughts please?
Rohit GenerativeAI WhatsApp Group|2023-07-13 21:01:12|hey guys, need some suggestion.  I have this usecase where I need to create small vectorstore of products and host them somewhere. the number of vectorstores can be huge.. for eg 10k or something  all the hosted vectorstores will have an identifier which can be isolated using some index or metadata  because during inference, I know which vectorstore I need to access  I checked qdrant, and they suggested to not use index based methods for this since max vectorstores (categories) they recommend is 100 and with metadata filtering the latency can be comparatively high  Any other direction which I should explore for this usecase? thanks :) ‎[7/13/23, 21:03:00] Nirant: ‎image omitted
Nirant|2023-07-13 21:08:12|64-core, 256G for 10% less accuracy than a very handicapped Qdrant running on 8-core, 32G machine is not great imho
Abhinav Verma Longshot.ai|2023-07-13 21:11:43|you can use same index but different namespaces like Pinecone has. I believe weaviate and others should also have similar features
ashish Acgt01 Twitter|2023-07-13 21:16:11|"One can now interact with bard in hindi ! yay !  ""Starting today, you can collaborate with Bard in over 40 languages, including Arabic, Chinese, German, Hindi and Spanish""  https://blog.google/products/bard/google-bard-new-features-update-july-2023/  anyone tried it yet ?"
Dr. Pratik Desai KissanGPT|2023-07-13 21:16:53|Google copying us
Abhinav Verma Longshot.ai|2023-07-13 21:17:25|But how is your quality. LLM hindi is meh
ashish Acgt01 Twitter|2023-07-13 21:17:48|you didnt invent hindi interaction :)
Dr. Pratik Desai KissanGPT|2023-07-13 21:18:18|Multilingual voice to voice to LLM interaction
Rohit GenerativeAI WhatsApp Group|2023-07-13 21:20:23|they do have class names, let me check if there's any limitation on that
~ Ankit Banerjee|2023-07-13 21:21:18|https://twitter.com/LukeGessler/status/1679211291292889100?t=gik9viB3AlGRc3cXOltJHw&s=08  This is great
~ Ankit Banerjee|2023-07-13 21:23:36|I have a really hard time believing that GPT-4 wouldn’t be better at grouping sentences than kNN on gzip lib ‎[7/13/23, 21:29:23] ashish Acgt01 Twitter: ‎image omitted ‎[7/13/23, 21:29:30] ashish Acgt01 Twitter: ‎image omitted
ashish Acgt01 Twitter|2023-07-13 23:40:33|https://twitter.com/npew/status/1679538687854661637?s=20
Abhishek Mishra|2023-07-13 23:45:55|He is equating a newer GPT4 with more capabilities like function calling and plugin enabling with being smarter.  Take that however you want. Some recent report mentioned they haven't compressed or quantized the model in any way but they indeed used a smaller model like GPT 3.5 to predict tokens and then have it validated by GPT4 to speed things up.
Abhishek Mishra|2023-07-13 23:46:30|But these reports are unofficial so all we have is anecdotal evidence that it is getting dumber 🤷‍♂
Abhinav Verma Longshot.ai|2023-07-13 23:48:51|Imagine gpt4 being called dumb.
Abhishek Mishra|2023-07-13 23:50:27|-er, wrt itself
Abhinav Verma Longshot.ai|2023-07-13 23:51:49|The terminology is just funny
ashish Acgt01 Twitter|2023-07-13 23:52:25|"Maybe to be fair to the critics , the q. is :  Is the current public version of GPT4 compared to all the versions that OpenAI has served since launch , the ""smartest""/""best"" ?"
Adithya S K PESIT|2023-07-13 23:56:02|wrong grp sorry
Aditya Sista 2010B5|2023-07-14 01:12:02|Anyone here use gpt-engineer? How good is gpt-engineer with gpt 4 api key? Are there any other such tools that take in user input after every step? Where do they get stuck?
ashish Acgt01 Twitter|2023-07-14 01:31:20|One of pg's longer essays but a beautiful, insightful read like all pg essays !  http://www.paulgraham.com/greatwork.html
aashutosh GenerativeAI WhatsApp Group|2023-07-14 01:34:40|For a second I was like, when did postgres start writing long essays.
Gokul Krishnan|2023-07-14 03:06:30|So, he's admitting, indirectly, that GPT-4 isn't anywhere close to AGI or superintelligence, no?  Just that it work(ed) well on simpler tasks and prompts? 🤔
Gokul Krishnan|2023-07-14 03:08:08|"I mean, you can always repeat the experiments from their ""technical report"". If the newer model scored lower, then it's demonstrably dumber?"
ashish Acgt01 Twitter|2023-07-14 03:10:21|https://twitter.com/ArchikiPrasad/status/1678223412668276737?s=20
ashish Acgt01 Twitter|2023-07-14 03:13:13|"*Idea* : we should do like a ACL2023 review on zoom/meet, a week or two from now. Nominate the ""best"" papers collectively by voting and then a few folks presenting the shortlisted papers on a zoom/meet call.  Respond with a 👍, if this sounds fun  Cc : [PHONE]  [PHONE] ‎<This message was edited> ‎[7/14/23, 03:20:43] Prayank Swaroop Accel: ‎image omitted ‎[7/14/23, 03:20:44] Prayank Swaroop Accel: ‎image omitted ‎[7/14/23, 03:20:47] Prayank Swaroop Accel: ‎image omitted"
Prayank Swaroop Accel|2023-07-14 03:20:59|Im attending the Pinecone conference today in SF . Some interesting slides here from Databricks talk ‎[7/14/23, 03:21:25] Prayank Swaroop Accel: ‎image omitted ‎[7/14/23, 04:09:38] Prayank Swaroop Accel: ‎image omitted
Prayank Swaroop Accel|2023-07-14 05:58:50|This one is at Stripe AI Day - https://lu.ma/k1dh24e1  They are recording it so hopefully, people will get to see it.
Nirant|2023-07-14 06:23:21|Wait, Pinecone is entering Model Serving?
Prayank Swaroop Accel|2023-07-14 06:23:37|Yes they are
Nirant|2023-07-14 06:27:15|spaCy threw their hat in the ring yesterday with Curated Transformers: https://curated-transformers.readthedocs.io/en/v0.9.x/usage.html
Nirant|2023-07-14 06:27:30|Looks like we're going to see a CPU vs Memory tussle again in model serving ‎[7/14/23, 07:05:11] Prayank Swaroop Accel: ‎image omitted
Suhas Motwani|2023-07-14 07:08:42|Sir are you going to be at the MosaicML event after this?
Aishwarya Goel Inferless 5s for 5G|2023-07-14 07:08:47|No this was from the databricks presentation!
Suhas Motwani|2023-07-14 07:09:17|The recording for the other panel is up in case anyone’s interested — https://youtu.be/TXMUXeml9JY
Prayank Swaroop Accel|2023-07-14 07:14:22|No. They rejected me from that one 🤣  Too many people at each AI event in the valley.  This AI Stripe day had a 600+ waitlist.
Suhas Motwani|2023-07-14 07:15:20|[PHONE] ‘s holding the fort for the BLR valley 😎
Prayank Swaroop Accel|2023-07-14 07:15:22|Yeah the Databricks guy was talking about Databricks providing optimized open source models hosted so that fine tuning them is very cheap.. so he was hinting at model serving !
Aishwarya Goel Inferless 5s for 5G|2023-07-14 07:16:21|Yeah databricks is doing that!
~ Prashanth Harshangi|2023-07-14 07:49:10|Yes, databricks via mlflow has always had model serving. In the last update, they now have llm specific logging and serving.
The GenerativeAI Group|2023-07-14 08:32:27|‎You added Himanshu Bamoria and Shiv Magik
Sandeep Srinivasa RedCarpetup|2023-07-14 10:30:52|https://youtu.be/smHw9kEwcgM
Nirant|2023-07-14 10:38:15|FWIW, the 29th July meetup will be the last mixer/meetup for 2023. Will experiment with different format from August.
Pratyush Choudhury|2023-07-14 10:41:08|Umm, why is this surprising?
Nirant|2023-07-14 11:05:42|It is not, as confirmed by [PHONE]
Rajesh RS Generative AI WhatsApp Group|2023-07-14 11:45:41|Anyone looked at Databricks AI Gateway?
Abhinav Verma Longshot.ai|2023-07-14 11:48:24|Does someone have an experience of building a chatgpt plugin? Trying to build one but the testing and deployment part is getting real confusing. As is the auth part
~ Rohan Athawade|2023-07-14 13:06:17|‎Shivendu Kumar added ~ Rohan Athawade
Bharat Kumar Ramesh Hashmal Web3|2023-07-14 13:26:04|https://twitter.com/alexrkonrad/status/1679656408839495681?t=Zs-W9Mz0at1Xn0k5sCZ2-Q&s=08
Bharat Kumar Ramesh Hashmal Web3|2023-07-14 13:26:58|Inflation dropping back down, 100x revenue multiples, 100M rounds pre product
Bharat Kumar Ramesh Hashmal Web3|2023-07-14 13:27:28|Fun times
Dev Aggarwal|2023-07-14 13:28:28|Huggingface pre product?
Bharat Kumar Ramesh Hashmal Web3|2023-07-14 13:29:47|Oh, not them. The broader theme
Bharat Kumar Ramesh Hashmal Web3|2023-07-14 13:30:02|They were also not the cause of inflation dropping
Abhinav Verma Longshot.ai|2023-07-14 13:33:31|Will have to see. Inflation is dropping down but there are other factors still at play. That is off topic
Abhishek Mishra|2023-07-14 13:34:29|4B valuation at 30M revenue
Sainath GenerativeAI WhatsApp Group|2023-07-14 13:36:43|what is this about?
~ Pranay Desai|2023-07-14 13:38:33|Yes.
~ Srinivas Reddy Aellala|2023-07-14 13:49:56|‎Shivendu Kumar added ~ Srinivas Reddy Aellala
Rounak Datta Hackathon Winner|2023-07-14 15:52:02|[PHONE] would you be able to help? If you know the deets from building the Wolfram plugin
Paras Chopra Wingify|2023-07-14 16:29:04|Is there a link to register?
ashish Acgt01 Twitter|2023-07-14 16:29:38|"""without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD), making analogy to mad cow disease."" https://arxiv.org/pdf/2307.01850.pdf  ""LLMs go 'MAD' if retrained on their own outputs after 5 cycles. So... presumably, LLM outputs will need to be tagged as such, to prevent disastrous autophagous loops.""  https://twitter.com/DrHughHarvey/status/1679781263522119680?s=20"
ashish Acgt01 Twitter|2023-07-14 16:30:25|https://hasgeek.com/generativeAI/2023-07/
Nirant|2023-07-14 16:39:07|https://hasgeek.com/generativeAI/2023-07/
Dhruv Anand|2023-07-14 18:02:58|https://twitter.com/michael_g_u/status/1679506845721919490?s=20  Jina AI's new embeddings models (supposedly faster, and longer context length than models of similar size) now on HuggingFace
ashish Acgt01 Twitter|2023-07-14 18:55:46|Code interpreter output can't be trusted blindly  https://twitter.com/paniterka_ch/status/1678507413073276928?t=MwDUnUkum1ASsFZxAu1AmQ&s=19
~ Kp|2023-07-14 19:02:53|It also feels like it's been nerfed. Atleast I have to convince it a lot to actually output useful stuff or even use that interpreter
~ Tanishk Sharma|2023-07-14 19:18:44|Hey guys, we’re struggling to deploy end points for wizard-vicuna-8k.  does anyone have experience with that version? Open for a paid gig for this
Ashfakh GenerativeAI WA Group|2023-07-14 19:19:09|Have done this. Happy to help.
~ Tanishk Sharma|2023-07-14 19:19:28|Reaching on DM
~ Sparsh|2023-07-14 19:21:37|everyone gets overhyped quickly on twitter
Prayank Swaroop Accel|2023-07-14 20:57:50|‎POLL: For GPU/ML/AI workloads, what do you prefer? and why ? ‎OPTION: AWS like on-demand / spot compute (17 votes) ‎OPTION: AWS lambda like serverless compute (13 votes)
Nirant|2023-07-14 21:16:32|AWS Lambda doesn't have GPUs, right?
Prayank Swaroop Accel|2023-07-14 21:18:22|Yeah .. but the question is more to understand whether serverless GPUs are preferred by the community over on-demand GPUs - the reality today is your really have to get reserved GPUs - otherwise you dont get them 🙂
Aditya Agrawal SuperU|2023-07-14 21:19:29|Cost of server/less is usually exorbitant if there is upside protection
Aditya Agrawal SuperU|2023-07-14 21:19:35|That would be great
Dev Aggarwal|2023-07-14 21:20:35|Reserved > On demand > spot > serverless
Ankur Pandey|2023-07-14 21:26:48|Did anyone try Monster API for fine tuning? If yes, can you share details? https://www.linkedin.com/posts/vijs_you-can-now-fine-tune-an-open-source-llm-activity-7085641201332228096-hOQT?utm_source=share&utm_medium=member_android
Aishwarya Goel Inferless 5s for 5G|2023-07-14 21:41:43|And why?
Aashay Sachdeva MPL Data Scientist|2023-07-14 21:42:41|[PHONE] from monsterapi is here
~ Rahul Bansal|2023-07-14 21:52:30|‎~ Rahul Bansal joined using your invite
~ Prashanth Harshangi|2023-07-14 21:59:43|It depends on the ml workload type: train/inference/monitoring/fine-tuning. If inference, the traffic pattern+model size should dictate the choice.
Ojasvi Yadav|2023-07-14 22:09:45|Completely off topic to the ongoing task (apologies)  What are some consensus state-of-the-art Text2SQL implementation?
Dev Aggarwal|2023-07-14 23:02:48|Just something about being able to exec into a machine 🙈
Soumyadeep Mukherjee|2023-07-14 23:07:56|Same with Reserved Host > Reserved VM > Reserved Container 1. Allows me to host own pipelines that share GPUs how I want. 2. No virtualisation/containerisation overheads 3. Can add to my own cluster whatever way I want with kubernetes handling the load sharing 4. Incentive to optimise my own inference is on me allowing me to experiment more things.  Though, this is very much a function of the person/team doing this. I love the craft of all the above too so I am fairly biased to do them. It has its pros and cons.
Dev Aggarwal|2023-07-14 23:44:23|2. Is this real? Containers have any significant overhead?
Gokul Krishnan|2023-07-14 23:47:48|If the base image is big, then yes
Dev Aggarwal|2023-07-14 23:52:56|Oh you mean startup time, solvable by doing volume mounts and image streaming?
Anshuman Pandey|2023-07-15 00:00:25|Who else is in the Bay Area from this group?
Dr. Pratik Desai KissanGPT|2023-07-15 00:05:14|We are using this one as reference. https://github.com/caesarHQ/textSQL
Shashwat TDC|2023-07-15 00:35:22|After all the twitter demos, not using defog? 👀😅
Dr. Pratik Desai KissanGPT|2023-07-15 00:38:06|We are not using to consume, we are building as a feature ‎<This message was edited>
Ravi Theja|2023-07-15 00:39:44|any insights on number of few shot examples to use for prompt enrichment?
Dr. Pratik Desai KissanGPT|2023-07-15 00:45:13|I’m not sure if I am answering your question correctly, but coverage is the challenge, therefore instead of making a generic platform, we are focused on specific set of use case for farmers, and customers who wants to show their data. Which is easy to solve. ‎[7/15/23, 00:47:13] Ravi Theja: ‎image omitted
Shashwat TDC|2023-07-15 00:48:10|we tried something similar. Worsened the result for complex queries. Mostly bcz of overfitting the few shot examples (=2)
Dr. Pratik Desai KissanGPT|2023-07-15 00:48:47|[PHONE] Not competing with you or defog, but building everything inhouse as I'm very cheap 😁
Shashwat TDC|2023-07-15 00:50:08|haha need of the hour. When underlying tech itself is changing, can't afford to have one more layer on top. ‎[7/15/23, 00:53:00] Abhinav Verma Longshot.ai: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-07-15 00:53:26|Haha 🙈 , I didn't refer to any diagram to figure out what is called what and jumped into code directly. Let me check it out and get back.
Dr. Pratik Desai KissanGPT|2023-07-15 00:56:13|I'm always worried about this but never taking the necessary steps to check. 😞 OpenAI APIs doesn't even have CORS/domain or any other control on api usage either
Neha YC W23|2023-07-15 01:02:30|Hey folks, i want to connect with those who are fine tuning LLMs. I wanted to do user interviews on how they are doing it. I am building a platform for making the process easier. If you are fine tuning, or can help, please respond using an emoji, and Ill reach out to you 1-1. Tia.
~ Kaushik Jaiswal|2023-07-15 01:26:56|Yes 🙌🏻
~ Ankit Sharma|2023-07-15 01:39:07|What’s the alternative?
Abhinav Verma Longshot.ai|2023-07-15 01:43:53|If you load it from a config file is it part of the environment variables
Dr. Pratik Desai KissanGPT|2023-07-15 01:46:22|But that can still send the data if they want to get the keys
Abhishek Mishra|2023-07-15 01:55:58|"If they're doing telemetry for debug for the variables, it'll include the keys whether we load them from env, take it via a password mechanism or load it from a ""config secrets"""
Abhishek Mishra|2023-07-15 01:56:57|I'm afraid an audit of the third party helper, plugin would be needed if you really want to avoid such cases. Especially in the scenarios where we have hundreds of libraries written by indie hackers who aren't aware of such security risks. ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-15 01:57:22|You can minimize not remove though
Abhinav Verma Longshot.ai|2023-07-15 01:57:58|I guess this is why the bigger the organization, a more comprehensive security check is done on libs used
Abhishek Mishra|2023-07-15 01:59:09|Bingo
Abhinav Verma Longshot.ai|2023-07-15 01:59:43|But I guess the best solution is to minimize the obvious lookups
Abhishek Mishra|2023-07-15 02:05:07|Anything third party that directly asks for api key is a huge risk. Otherwise separation of environments, loading secrets via secrets management systems, least privilege by using classes or using wrapper around third party library to ensure no sensitive data is being sent should be practiced by default.
Abhishek Mishra|2023-07-15 02:07:21|Other than this, distributing malware or spyware has also never been easier than it is with people trying to run models locally on their phones and PCs. If it's not in safetensors format, don't touch it.
Abhinav Verma Longshot.ai|2023-07-15 02:08:31|That's been the case for a number of years. This is more common in js packages
~ Sushant Kumar|2023-07-15 02:08:40|But why would OpenAI have CORS. Those API keys aren’t meant to be directly used in client side code, no?
Dr. Pratik Desai KissanGPT|2023-07-15 02:09:48|There is better way to do it by issuing a session tokens
Dr. Pratik Desai KissanGPT|2023-07-15 02:10:12|For latency issues, of course
~ Kp|2023-07-15 02:12:13|Will this a problem if I use configparser?
~ Nitin Kishore|2023-07-15 09:06:32|https://twitter.com/LukeGessler/status/1679211291292889100?t=XJRTK18U36Xu4AL0ixZv_Q&s=08
Paras Chopra Wingify|2023-07-15 09:15:46|Meta is launching commercial version of llama this Monday  Wondering what would change.  Does anyone has a good benchmark on what kinds of problems can llama effectively replace gpt3.5 on, and whether it’ll come out to be cheaper
Paras Chopra Wingify|2023-07-15 09:44:51|https://www.reddit.com/r/LocalLLaMA/comments/14ys9ol/what_are_you_using_local_llamas_for/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
Nirant|2023-07-15 09:47:54|How many months/weeks/days away are we from building this?  https://twitter.com/BecomingCritter/status/1679641669900050432
Nirant|2023-07-15 09:48:51|To be explicit, this is a human video, but can be automated for sure?
Alok Bishoyi|2023-07-15 09:51:11|Not far.   Also curious if China or other East asian nations have such content due to live tipping spillover, or is it only the west tiktok that came up with this ?
Alok Bishoyi|2023-07-15 09:53:46|oh wait nvm, the video in question seems to have kanji characters.   So truly a global phenomenon ‎[7/15/23, 09:59:06] Alok Bishoyi: ‎image omitted
jyotirmayjk Hackathon|2023-07-15 10:00:29|Seems to be a global issue ,everyone is reporting this
Ojasvi Yadav|2023-07-15 10:00:30|This got disabled for many people, if not everyone
Sainath GenerativeAI WhatsApp Group|2023-07-15 10:10:49|Could be off topic but I am struggling to understand what’s happening there.
Alok Bishoyi|2023-07-15 10:14:59|live tipping features were enabled in platforms like tiktok. Creators incentivize their crowd to tip by doing weird stunts. The one in the video acts as a NPC in a video game, playing a set of actions against every particular type of tip. Apparently a wide part of the internet fetishizes these sort NPC behaviour
Dr. Pratik Desai KissanGPT|2023-07-15 10:29:02|Which AI model is this [PHONE]? 😂
Brij Singh Rebright Partners|2023-07-15 10:30:24|Hahaha  🤣
~ Vipul|2023-07-15 10:30:39|Pawdel*
Dr. Pratik Desai KissanGPT|2023-07-15 10:32:30|Canine can be a good transition to model name (llama2) the way we are going with Animal names. Last one was Orca. Also suites the premise, human’s best friend.
Ankur Pandey|2023-07-15 10:33:35|What's this? Sorry too vanilla to appreciate it ‎[7/15/23, 10:34:05] Brij Singh Rebright Partners: ‎GIF omitted
Dr. Pratik Desai KissanGPT|2023-07-15 10:36:27|😂 I'll stop here, we are going to open a can of worms, and [PHONE] being a cat person, will definitely kick us out.
Aashay Sachdeva MPL Data Scientist|2023-07-15 10:40:41|Sorry guys! 🤣
Abhishek Mishra|2023-07-15 10:41:13|My existing sessions with code interpreter are working but I can't get a new session with it
Alok Bishoyi|2023-07-15 10:44:06|Cannot upload new files and already timed out for previous uploaded files.  Guess I gotta write my own scripts as a luddite coder 🥲
Abhinav Verma Longshot.ai|2023-07-15 10:45:28|It will minimize it but it will be stored. I figured out a really good solution for this. Will share
Dhruv Anand|2023-07-15 11:02:52|Is providing key file path a safe alternative then?
Nirant|2023-07-15 11:07:12|No. No. No.  https://12factor.net/ recommends using os envs, and that's way safer
Dev Aggarwal|2023-07-15 11:07:58|You can do both. But having the key file’s path as an env var 😂
Nirant|2023-07-15 11:08:50|If you're really worried about telemetry, Chroma sends every request to their own Posthog. Pinecone is literally every request. 
Dev Aggarwal|2023-07-15 11:09:32|For this, I’d say use less libraries you don’t trust
Nirant|2023-07-15 11:09:45|Telemetry is very useful for commercial OSS to see what is useful and where and to whom
Nirant|2023-07-15 11:11:57|If you do this, please let me know — I'd love to use your keys. And why stop at OpenAI, just give me your .ssh
Dev Aggarwal|2023-07-15 11:14:37|You already have my keys nirant
~ Kp|2023-07-15 11:18:52|They started by nerfing it, now it's gone
~ Kp|2023-07-15 11:18:53|🙂🙂 ‎[7/15/23, 11:20:36] Nirant: ‎GIF omitted
Nirant|2023-07-15 11:21:30|Perhaps some server provisioning issue, maybe they're testing GPT4 VIsion?   A kid can dream 🙈
~ Kp|2023-07-15 11:21:56|Bard has already come out with multimodal
~ Kp|2023-07-15 11:22:32|Images only, but it's pretty accurate
Kaushik Bokka|2023-07-15 11:26:19|What use cases are people playing with Bard multimodal? ‎[7/15/23, 11:39:06] Abhinav Verma Longshot.ai: ‎image omitted
Dev Aggarwal|2023-07-15 11:46:32|There’s a safe way to do this - store your keys in a k8s secret and mount them as a file in a volume. Then store the path of that file as an env var or even hardcode it.  https://kubernetes.io/docs/concepts/configuration/secret/
Abhishek Mishra|2023-07-15 11:55:52|If the third party module explicitly doesn't ask for api then there are many ways to do it. In essence, it'll always be some kind of separation of scope where only privileged code segment has access to secrets. If the third party that you're using provides some service by using your key then there's nothing you can do other than get rid of the third party lib. ‎[7/15/23, 11:56:52] Abhishek Mishra: ‎image omitted
Ankur Pandey|2023-07-15 12:34:21|‎POLL: Hey all, which content AI tools you / team use? And what's the frequency? (can choose more than one option) ‎OPTION: Rarely (0 votes) ‎OPTION: ~ Once a week (0 votes) ‎OPTION: ~ Daily / multiple times a week (18 votes) ‎OPTION: Only use ChatGPT / OpenAI (27 votes) ‎OPTION: Use something other that ChatGPT / OpenAI (which one?) (6 votes)
Abhinav Verma Longshot.ai|2023-07-15 12:39:51|wait, when was it gone?
Abhishek Mishra|2023-07-15 12:53:40|There was a temporary unavailability for some folks since last night
~ Pramod|2023-07-15 12:59:11|Hello folks! Anyone tried claude 2?   I have a usecase where I'll need to identify the user demographics leading to a high engagement for my product. For that I have tried feeding the necessary data (past 6 months) to chatGPT via code interpreter(gpt-4), and claude 2, and even created a custom plugin for chatGPT. The results from claude 2 are the best sofar. It is able to give me the insights and the next steps very realistic and accurate unlike generic suggestions given by GPT.  Do you know anyother better ways of achieving the same?
Abhishek Mishra|2023-07-15 13:05:58|Could being more up to date be helping Claude here?
Abhinav Verma Longshot.ai|2023-07-15 13:12:21|this sounds like a time series, xgboost type problem as well. But in any case, it is interesting to see claude do better here. I can only assume greater context length and more training data beyond Oct 2021 are 2 major differences here.
Dhruv Anand|2023-07-15 13:21:01|https://twitter.com/swyx/status/1677589535587467264?t=dkrXik-6FZP189mfb_55nA&s=08  There were some leaks of internal details. Maybe they temporarily disabled it to patch those?
Abhishek Mishra|2023-07-15 13:25:22|the requirements.txt is real
Abhishek Mishra|2023-07-15 13:25:47|i was able to get the same and got to know it contains way more packages it claims to be equipped as interpreter
Abhishek Mishra|2023-07-15 13:26:17|the problem is that it's cut off stops it from knowing what it can put to use and for what
Rajesh RS Generative AI WhatsApp Group|2023-07-15 13:34:27|Anyone used Haystack (deepest) ? Given the langchain discussions recently I’m interested in knowing if it offers any advantages.
Abhinav Verma Longshot.ai|2023-07-15 13:37:12|OpenAI had mailed last night, that it was down for a scheduled maintenance.
ashish Acgt01 Twitter|2023-07-15 13:37:17|I have a naive question regarding ChatGPT and commercial LLMs in general . Please indulge me :)  We interact with ChatGPT/Claude/ Bard/ <what have you> through our user accounts  As we do more and more conversations with any of these commercial cloud LLM providers,  Is the provider maintaing a set of custom model weights, per user account, based on the interaction of that user account with the cloud LLM service so far  If I try to think of an analogy with Google search, (even if not a great analogy) where google maintains some sort of state and ml model, what exactly is the state , maintained per user, in the LLM cloud service scenario ?
Abhishek Mishra|2023-07-15 13:37:44|haystack and spacy are pre-chatgpt libraries for quick production code where you are mostly interested in putting to use a best-known-method rather than research or tweak your own model.
Rajesh RS Generative AI WhatsApp Group|2023-07-15 13:40:16|Thanks Abhishek. Are these frameworks being developed for interfacing with modern LLM APIs? SpaCy has been used for a while in data science and NLP apps and projects but I'm not sure they have evolved to become alternatives to Langchain or Llama Index
Abhishek Mishra|2023-07-15 13:42:30|There are no custom models per user but there is supposedly a user profile. Most people who have worked with recommendation systems would know profiling and keeping track of user's likes, dislikes, most watched (visited), recently watched (visited). Based on this, each platform inevitably works towards maximising user engagement in 2 ways - 1. increase time spent on their app/website, 2. increase follow through/click through/engage rate for the shown content or ads.
Abhishek Mishra|2023-07-15 13:44:50|both haystack and spacy are adapting fast for llms. they will offer most convenient ways to put these things in production the way they have always done. But they make everything in their own libs with an opinionated style. Learning their framework helps little towards understanding the bigger ecosystem.
Anshul Bhide Replit|2023-07-15 14:45:15|https://blog.replit.com/ai-on-replit  Some stats around AI development on Replit.
Anshul Bhide Replit|2023-07-15 14:45:16|https://twitter.com/ycombinator/status/1680011879157207041
Sudharshan GenAI|2023-07-15 15:34:04|https://twitter.com/natanielruizg/status/1679893292618752000?s=46  Hyper dreambooth 🔥  Faster and lighter.
Nitin Mahajan McKinsey|2023-07-15 15:39:39|Has anyone tried it? Quality trade-off from DB?
~ Abhilash K Pai|2023-07-15 16:25:20|https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_are-vector-databases-here-to-stay-yes-activity-7085908435686285312-QVfB?utm_source=share&utm_medium=member_ios
Nirant|2023-07-15 16:55:06|Friends, I'm looking for a zero shot or k-shot image classifier. Something which can do something like this:  Screenshot from a call (has human faces?) Screenshot from a code editor Screenshot from an app  Not open domain. Assume app and laptop screenshots.  cc [PHONE]
Nirant|2023-07-15 16:56:08|Paid APIs work, but something which has a REST or Python client is preferred
Ravi Theja|2023-07-15 16:57:01|something with zero shot clip classifier won't work here?
Vivek Cohere.ai|2023-07-15 16:57:24|‎Ravi Theja added Vivek Cohere.ai
Nirant|2023-07-15 17:03:04|I've never tried it. Do you expect it to work?
Sandeep Srinivasa RedCarpetup|2023-07-15 17:07:10|https://twitter.com/NielsRogge/status/1679848775043407872  is anyone using TGI in production to host finetuned models ? trying to build a list of which finetuning techniques & models are working great with TGI
Ravi Theja|2023-07-15 17:09:30|Yes. Tried sometime back it worked decently.
Ravi Theja|2023-07-15 17:09:49|Though i don't have metrics currently for the experimentation.
Nirant|2023-07-15 17:18:06|Search through past conversations of this chat summaries: https://nirantk.com (and then go to search)   Summaries for our past discussions (with links!) are also available at https://nirantk.com/docs/resources/ ‎[7/15/23, 17:19:05] Nirant: ‎image omitted
Sthit Generative AI WhatsApp Group|2023-07-15 17:21:01|This is nice
Kunal Bhatia Hexo|2023-07-15 17:26:02|Pretty cool! ‎[7/15/23, 17:26:58] Nirant: ‎video omitted
Ambika Computational Mama|2023-07-15 17:29:00|[PHONE] why are you so brilliant!
Nirant|2023-07-15 17:30:41|This is the fastest implementation possible, not even very clever 🙈
Nirant|2023-07-15 17:31:55|And I didn't want to host a server, so this works entirely in browser — your searches are your business
~ Ayush Yadav|2023-07-15 17:33:09|Damn ⚡
Chaitanya A GenAI|2023-07-15 17:33:18|looks great! what’re you using for this?
Nirant|2023-07-15 17:34:05|hugo (golang), all code is here: https://github.com/nirantk/nirantk.github.io/
Nirant|2023-07-15 17:34:14|This is running on Github Pages
Chaitanya A GenAI|2023-07-15 17:34:27|sweet
Kishore GenAI|2023-07-15 17:35:25|Did you try checking blip2 from sales force?
Kishore GenAI|2023-07-15 17:35:30|https://huggingface.co/spaces/Salesforce/BLIP2
Nirant|2023-07-15 17:37:04|Will do, thanks for the tip!
Kishore GenAI|2023-07-15 17:38:20|You can ask the question-  are human faces present? Are hands visible? Etc since it is a QA based model for images. ‎<This message was edited>
Rajesh RS Generative AI WhatsApp Group|2023-07-15 17:39:36|Yeah this is something I’ve seen close up building apps with long prompts. They’re not effective when you pass large prompts to them. I wonder if context length being large is automatically a good thing. Since we are computing attention it is likely that the attention vector will become sparser for large contexts. Is this the correct intuition? Any other experiences?
Arvind N Generative AI Group|2023-07-15 18:02:23|We have MitraAI image APIs for this. How many classes do you think you'll work with approx?
~ Akshat Khare|2023-07-15 18:24:50|Hey. I have deployed endpoints for blip right now with serverless cont, if you wish to use that. Works quite well and with not so high delay. However I would suggest to use pix2struct in this case as you dealing with screenshots. Can help you with docker of the same too. Would that be helpful? Pix2struct is trained to understand textual content to some degrees.
Abhishek Mishra|2023-07-15 18:27:07|Vanilla attention has O(N^2*d) computational complexity. N - sequence length, d - hidden dimensions, thus we see the models suffering from forgetfulness or ignoring parts of the context with really long sequences.
Abhishek Mishra|2023-07-15 18:27:07|However, I'm optimistic that this condition is temporary. Primarily because recent paper Longnet showed a method for Dilated attention with O(N*d) complexity. They were able to project a really really long context length (theoretical support for 1B tokens)
Abhishek Mishra|2023-07-15 18:27:08|Another key thing is no famous models currently have been fully pretrained for really long context lengths and perform completion on text that's <2k context.  We will also start seeing really long context in pretraining, especially with methods that use process supervision, chain-of-thought, step by step or textbook approaches.
Abhishek Mishra|2023-07-15 18:27:08|It has been seen that such methods have resulted in better model performance, though right now we attribute it to better quality of datasets. But there can be made a case for having longer context in pretraining supporting model performance rather than just dataset quality. Good scope for experimentation ‎<This message was edited>
~ Akshat Khare|2023-07-15 18:27:10|https://twitter.com/llama_index/status/1679522417558040577?t=1TJ51nRpQzf9RYbuuMF66Q&s=08 This vs Langchain 's openapi integration. Do you guys have any views over this?
Nirant|2023-07-15 18:29:37|"I'm helping a friend [PHONE] for a hackathon, so will see if CLIP/BLIP2 do the job ""good enough"" — if not, will ping you for Pix2Struct Docker image. Thanks for the tip!"
Dev Aggarwal|2023-07-15 18:49:02|For antigpt, i ended up using clip interrogator + gpt - because clip interrogator usually output more detailed descriptions of the image, and gpt is good at parsing those
Dev Aggarwal|2023-07-15 18:49:49|For screenshots there is a specific model from msft I think
Paras Chopra Wingify|2023-07-15 18:58:43|Take CLIP embedding and do KNN (take too 5 matches and then majority of the 5 is what you can classofy)  Or you can train a classifier on last layer embedding  Actually, you can use a captioning model and see whose logit is maximum (code, screenshot, human, etc)
ashish Acgt01 Twitter|2023-07-15 19:36:06|Wild ! https://twitter.com/sirjoeldean/status/1679738138166706176?s=20 ‎[7/15/23, 19:59:29] ~ vignesh iyer✌️: ‎image omitted
~ vignesh iyer✌️|2023-07-15 19:59:54|"This is an interesting counter AI perspective - ""AI cannot get hungover""🍻"
~ Rohit|2023-07-15 20:23:40|If it has read enough stories and experiences of the above, it could mimic it very well.
~ Mayank Gupta|2023-07-15 20:27:50|At the risk of taking it into philosophy territory, this is assuming 'we' have a unique conception of hangover which isn't just our advanced multimodal LLMs coming up an output to a defined alcohol input. We just might be AGI on the quest for another AGI!
~ Miraj Shah|2023-07-15 20:29:12|Perhaps the perspective which George Hotz talked about is interesting. The current AI systems  lack robustness in a very specific way. For one, they cannot self repair nor can they reproduce. A biological life form like a bird for example, is a way more robust system. It can survive in a jungle, an AI system right now cannot. And this is inherently a very difficult problem to solve for, especially reproduction
Rajesh RS Generative AI WhatsApp Group|2023-07-15 20:32:30|https://arxiv.org/abs/2307.01189
Rajesh RS Generative AI WhatsApp Group|2023-07-15 20:32:44|Pretty incredible sounding work
ashish Acgt01 Twitter|2023-07-15 21:32:30|https://www.nytimes.com/2023/07/11/technology/anthropic-ai-claude-chatbot.html
ashish Acgt01 Twitter|2023-07-15 21:32:51|An inside look at Anthropic and Claude
Abhinav Verma Longshot.ai|2023-07-15 22:13:45|I did not know SBF invested arounf 500 million into Anthropic
~ Rahul Bansal|2023-07-15 22:48:47|Has anyone tried langchain, Did you find it useful?
Rajesh RS Generative AI WhatsApp Group|2023-07-15 23:30:20|Using in production grade apps.
Rajesh RS Generative AI WhatsApp Group|2023-07-15 23:30:33|Still learning how to use it well
~ Rahul Bansal|2023-07-15 23:45:19|What advantages did you feel compared to using open ai sdk directly?
Rajesh RS Generative AI WhatsApp Group|2023-07-15 23:47:39|The langchain thought process helps make sense of how the chain or agent works. Like the fact that there are different choices of agents. With frameworks like kor and langchain it is possible to build interesting new apps for extracting structured data from LLM responses
Rajesh RS Generative AI WhatsApp Group|2023-07-15 23:48:31|Also like how the project is constantly trying to add me features and support for different backend models
Sandeep Srinivasa RedCarpetup|2023-07-15 23:49:17|i dont entirely agree with the way that langchain abstracts prompts and chains and tools. prompts & chains are generally inseparable and the way it abstracts makes it very hard to test. i may be biased cos i build an alternative to langchain...but i really struggled when taking langchain to production.
Sandeep Srinivasa RedCarpetup|2023-07-15 23:49:25|good for desktop experimentation though
~ Vinay|2023-07-15 23:49:54|Is it normal to observe this behaviour in code interpreter? has anyone else observed this?  asked to generate an output -> based on an interim output, it identifies what it did wrong, ack. that and goes ahead and corrects it (with no i/p from me)  Observed this just now, not sure if I have ever seen it do that earlier (gpt4, davinci, etc).
~ Rahul Bansal|2023-07-15 23:50:13|What are you building?
Sandeep Srinivasa RedCarpetup|2023-07-15 23:50:55|will dm separately. we are all very scared of nirant :D
Satyajit Roy|2023-07-15 23:54:14|Had a question about langchain tagging and extraction chain if anyones ever used that. Is there anyway to make sure that the chain extracts all the data required? It sometimes misses stuff and im wondering other than changing the prompt slightly, what else can i try?
~ Rahul Bansal|2023-07-16 00:05:31|Interesting, did you know any app source code which might be hard to build directly without using langchain. I will love to read it.
Aditya Sista 2010B5|2023-07-16 00:39:27|I tried langchain to build fairly complex chains, thrice. I found using openAI sdk directly to be preferable. Langchain doesn't solve output parsing, doesn't do text splitting properly, the syntax isn't trivial either. And after openai released functions, the agents part of langchain is now redundant.
Aditya Sista 2010B5|2023-07-16 00:41:10|The only good thing that came out of langchain was it introducing me to things like ReAct
Aditya Sista 2010B5|2023-07-16 00:42:50|Langchain also consumes way too many tokens for so many hidden prompts in its layers
~ Sparsh|2023-07-16 00:53:39|True, much better to build from scratch
Abhinav Verma Longshot.ai|2023-07-16 00:53:56|Their prompts aren't that good either.
Divya Tak|2023-07-16 01:40:43|I think you can talk about what you're building 😌. As long as you're not marketing for marketings sake. Here it seems relevant
~ Vik|2023-07-16 03:36:53|i've built an oss library around llm independant api calling and cot reasoning i've mostly been focused on tuning it for hosted llms but now i'm exploring os llms any thoughts on os llms that work with json, functions, cot i'm open to tuning
~ Vik|2023-07-16 03:38:58|i've built an os library for api calling + react + guarded structed output + error correction i can dm you the github link ‎<This message was edited>
~ Vik|2023-07-16 03:42:20|currently experimenting with llama 65b and mpt variants
Arvind N Generative AI Group|2023-07-16 06:29:11|So who is the right audience for langchain? When do some prompts become boilerplate that we don't have to think about handcrafting them with precision?
~ Srinivasa Raghavan K M|2023-07-16 07:16:15|llama-index better that way?
Rajesh RS Generative AI WhatsApp Group|2023-07-16 08:27:36|This I have observed too
Shubham Sharma 2012C6|2023-07-16 11:41:56|"""Insiders have revealed that studios have already utilized technology to replace background actors with digital avatars in upcoming movies, such as “Captain America: Brave New World” and Netflix’s “The Residence.”  https://www.firstpost.com/tech/news-analysis/hollywood-wants-to-replace-background-actors-with-ai-gen-characters-pay-them-for-only-a-day-12865782.html"
Rajesh RS Generative AI WhatsApp Group|2023-07-16 12:57:11|There’s a workers strike by Hollywood writers and actors going on. Perhaps we can discuss this or something related in the policy group
ashish Acgt01 Twitter|2023-07-16 13:14:07|Policy and philosophy group is the better venue
ashish Acgt01 Twitter|2023-07-16 13:15:42|https://twitter.com/smdiehl/status/1679402478306041856?s=20  Thoughts on the gzip paper ?  https://aclanthology.org/2023.findings-acl.426
Shashwat TDC|2023-07-16 13:21:24|+ who has the bandwidth to debug a probabilistic event/ outcome.
Shashwat TDC|2023-07-16 13:24:25|Wud also love to know groups view on Quality assurance in genAI apps vs non genAI apps.  Are there any fundamental behavioral changes you are able to observe just w.r.t QA and testing.
Abhishek Mishra|2023-07-16 13:25:24|What is with the absolute scarcity of A100 80G GPUs? can't get one anywhere. I don't want to learn distributed training for simple experiments 😢
Pranjal Yadav Razorpay|2023-07-16 13:31:00|I agree that prompts and chain are deeply coupled in many occasions but do you think this modular separation is a bad idea? Any insights into performance related difference you may have observed? ‎[7/16/23, 13:58:01] Shan: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-16 14:14:34|It's not about performance, it's about iteration and testability. I primarily work on production & go live...so when u do that, u need to do a bunch of prompt routing to save costs and being able to A/B test prompts. These are not things that affect u when ur playing with AI since cost/accuracy, etc are not ROI.
Sandeep Srinivasa RedCarpetup|2023-07-16 14:15:49|None of the prompt testing infra will integrate will with langchain since it is layered in deep hierarchy of classes   My personal thesis is - generative AI is a config management problem. So if u model chains+prompts out of tree in a declarative way, it makes for far far better versioning/testing/routability of prompts
ashish Acgt01 Twitter|2023-07-16 15:40:31|Interesting approach to attack the problem !  And your solution to this , modeling it as a config management problem,  is edgechains and inspired by K8s, iirc ? ‎<This message was edited>
Paras Chopra Wingify|2023-07-16 15:40:56|It’s like contacting two blue pictures vs a blue and red picture  The former will take less space when compressed vs the latter.  Compression is intelligence. See Hutter’s prize too
ashish Acgt01 Twitter|2023-07-16 15:42:49|Thanks for the pointer to  https://en.wikipedia.org/wiki/Hutter_Prize
Paras Chopra Wingify|2023-07-16 15:44:04|Can you elaborate?  What do you mean by “tree in a declarative” way
ashish Acgt01 Twitter|2023-07-16 15:54:27|s.replace('contacting', 'compressing')
Sandeep Srinivasa RedCarpetup|2023-07-16 16:00:41|think of a config file - a YAML file or a .settings file. why do they exist ? they exist cos  1. u want to specify some changing variables in one place & make them available everywhere (you could have hardcoded this as well right?) 2. you want to integrate with external tools - secrets management or CI/CD tools to inject this.  Google Borg, Kubernetes, etc all started here. Then ended up with 180 million lines of config files. Which they then invented a language for over decades. Which allows u to do complex things like define infrastructure graphs, versions, boot scripts, commandlines, etc. (not very different than prompts no?)
Sandeep Srinivasa RedCarpetup|2023-07-16 16:01:38|https://news.ycombinator.com/item?id=32104446  does a separate language work better than python ? yes. and there is far more involved reading  if ur interested.
Sandeep Srinivasa RedCarpetup|2023-07-16 16:02:25|P.S. i dont use cue. i use jsonnet in edgechains which is far more popular today in the config management world. but same funda.
Abhishek Mishra|2023-07-16 16:11:56|"*I will add the between the lines print here* - *gzip is all you need but specifically for ""out-of-domain sentence classification""*.   gzip uses LZ77 (representation by avoiding redundancy) and huffman coding (representation with minimal bits). As you can see, it is equipped to handle compression for 2 items that have same lemma/root perfectly. But not for semantic similarity or other linguistic relationships between terms.  For example, the sentences ""The cat sat on the mat"" and ""The feline rested on the rug"" are semantically very similar, but a compression algorithm wouldn't necessarily compress them any more effectively than two completely different sentences, because the specific sequences of characters are quite different.  Here is where the OOD or out-of-domain thing comes into play. If all models were tested on OOD data, then the models were as stupid about semantic relationships as the gzip algo. This observation is conclusively the same as the well-known fact that keyword or BM25 based approaches wash the floor with dedicated models on out-of-domain context. I bet you will see close competition between keyword/BM25 approaches for this task with gzip on OOD data."
Paras Chopra Wingify|2023-07-16 16:47:46|Concatenating
Vaibhav Pilani|2023-07-16 16:48:22|‎You added Vaibhav Pilani
ashish Acgt01 Twitter|2023-07-16 16:49:45|Ok. My intent recognition model is clearly sub optimal :)
Aashay Sachdeva MPL Data Scientist|2023-07-16 21:49:52|Would anyone have the pdf for semi analysis’s GPT-4 coverage? (I do not support plagiarism, just help me this one time 😢)
Abhishek Mishra|2023-07-16 22:29:47|The article is behind a strong paywall that can't be breached via common tools. Here is an archive of Yam Peleg's twitter thread where he kind of dumped almost the entire article. Everything significant about the architecture was in the twitter thread which is archived here as the thread was taken down.  https://archive.is/Y72Gu ‎<This message was edited>
Kaushik S YC W23|2023-07-16 22:31:16|I spent an hour yesterday trying to find it. But you can’t.   I almost paid the 500$ for it before someone stopped me 😛
Abhishek Mishra|2023-07-16 22:32:01|I also want to have your kind of subscribers or patrons.
Kaushik S YC W23|2023-07-16 22:33:00|Haha. The article was that good  The paywall was at the exact right place. And it was midnight  All ripe conditions to make me pay money 😛
Abhishek Mishra|2023-07-16 22:33:38|You can read it here.
Aashay Sachdeva MPL Data Scientist|2023-07-16 22:45:16|Great! Thanks 🙏 ‎[7/16/23, 22:45:33] Anubhav mishra Zupay: ‎image omitted
Anubhav mishra Zupay|2023-07-16 22:45:46|The image I used was something I drew on a paper and asked ‎[7/16/23, 22:46:34] Anubhav mishra Zupay: ‎image omitted
Anubhav mishra Zupay|2023-07-16 22:46:42|This was the image 😅😂
Rajesh RS Generative AI WhatsApp Group|2023-07-17 00:00:46|Huffman encoding I understand is the underlying mechanism. Clearly well tested methods from theory do better than learning from data. When models or algorithms are known, best to use them in place of stat learning or ML.
ashish Acgt01 Twitter|2023-07-17 00:10:29|You get a free embedding, you get a free embedding and all of you get free embeddings ! ( Ala Oprah style :D)  https://docs.gpt4all.io/gpt4all_python_embedding.html  https://twitter.com/deliprao/status/1680642517937553409?s=20
Rajesh RS Generative AI WhatsApp Group|2023-07-17 00:22:47|On algorithmic methods that are not machine learning that could be used to solve problems (like the gzip example Ashish posted) https://twitter.com/Jousefm2/status/1680120559206555649?s=20 - this is a take on maze solving, which may be represented as search or agent based RL problems.
Rajesh RS Generative AI WhatsApp Group|2023-07-17 00:24:23|Using ML everywhere is becoming a substitute for thinking about problem formulation - perhaps that would still work for most teams/people who are not looking for efficient or elegant solutions - after all brute force approaches are still common enough
Abhishek Mishra|2023-07-17 00:27:47|"I would appreciate it slightly better if they made it configurable instead of hard coding a 384 dim ggml miniLM L6 v2 in the class.  *class Embed4All: """""" Python class that handles embeddings for GPT4All. """""" def __init__( self, n_threads: Optional[int] = None, ): """""" Constructor  Args: n_threads: number of CPU threads used by GPT4All. Default is None, then the number of threads are determined automatically. """""" self.gpt4all = GPT4All(model_name='ggml-all-MiniLM-L6-v2-f16.bin', n_threads=n_threads)  def embed( self, text: str ) -> list[float]: """""" Generate an embedding.  Args: text: The text document to generate an embedding for.  Returns: An embedding of your document of text. """""" return self.gpt4all.model.generate_embedding(text)* ‎<This message was edited>"
~ Vik|2023-07-17 00:48:32|my kid uses gpt4all as an ai pet to chat with we gave it a personality though the system prompt we're also trying to connect it to other stuff with plugins
~ Vik|2023-07-17 03:14:42|my kid is into one piece and other anime the model we use is pretty solid he chats with it like a knowledage friend who's also into anime. the educational aspects of llms are super under explored
~ Kp|2023-07-17 03:21:42|Similar functionality we can see with khanacademys amigo. A personalised llm which doesn't reveal the answer directly rather guides you to it.
~ Kp|2023-07-17 03:22:00|Khanmigo*
~ Vik|2023-07-17 05:28:58|thanks i gotta check this out
~ Suraj|2023-07-17 06:52:07|‎Ravi Theja added ~ Suraj
Nirant|2023-07-17 07:49:33|FOSS alternative to Portkey's semantic cache+retry orchestration https://github.com/BerriAI/reliableGPT
Dr. Pratik Desai KissanGPT|2023-07-17 07:53:19|Been checking it out since Krish reached out. Not bad so far. I was just manually doing many thing, and still a proponent of not using ready-made libraries to replace direct functions, I'm not sure I'll end up using it in production.
Nirant|2023-07-17 07:57:22|You and I are not the target users for tools like this — the cognitive+time cost for us to setup fallbacks w/ retry etc is worth the flexibility it gives us. For most app devs, the trade off is other way around.
Sridhar Obilisetty Figo AI|2023-07-17 08:02:47|‎Sridhar Obilisetty Figo AI joined using your invite ‎[7/17/23, 08:03:55] Aishwarya Goel Inferless 5s for 5G: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-07-17 08:05:04|Agree. It feels like the whole ecosystem of similar libraries is being built in front of us, and it is going to accelerate dev adaptation. e/acc 😂
Neha YC W23|2023-07-17 08:15:58|The biggest learning i have had from looking at frontend technologies grow has been the same. As a developer, id not have used anything available out of the box like Next or AntDesign. For my startup however, I am willing to pay the premium for speed.
Neha YC W23|2023-07-17 08:16:39|Generally the market for all these tools are developers who have more important things to do, or faster execution is priority
Neha YC W23|2023-07-17 08:17:24|Similar example is Retool for internal tooling
Dr. Pratik Desai KissanGPT|2023-07-17 08:17:32|For someone starting right now, it's a must to get the PoC out in the market. Then in production, library after library can be cut down to achieve maximum efficiency ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-17 08:18:28|That means though, these are tools to get funding 🤣
Neha YC W23|2023-07-17 08:18:56|As they should, because they enable a lot of creative development which would not have been feasible otherwise
Neha YC W23|2023-07-17 08:19:32|Tools like webflow have created a new job category of webflow developers 😅
Dr. Pratik Desai KissanGPT|2023-07-17 08:19:46|Right now investors are funding tools that will be used to get funding.
Neha YC W23|2023-07-17 08:20:33|Right now, everyone is building on top of whats production ready(openai). So such tools make sense to be funded at good valuation
Neha YC W23|2023-07-17 08:21:26|Everyone needs these kind of tools as tech is nascent. The moat/niche will come over time based on what kind of products people build out of these technologies
Neha YC W23|2023-07-17 08:21:58|And as use cases grow, problems statements will become more clear and niche will start emerging
Kaushik S YC W23|2023-07-17 08:22:07|It makes sense to outsource dev tools and infra to startups focusing on them full time.   Only the largest companies can afford to have in house dev tools and infra teams. For the RoW, if you’re not relying on a startup for providing dev tools, it’s almost always at the cost of speed and efficiency.
Neha YC W23|2023-07-17 08:22:09|Mixpanel vs amplitude vs posthog for example.
Dr. Pratik Desai KissanGPT|2023-07-17 08:22:28|This is like selling Timber to build San Francisco business that will bloom due to second order effect of finding some Metal in Sierra Nevada. ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-17 08:23:24|At least Gold has historic users, we haven't found consumers for this metal, yet
jyotirmayjk Hackathon|2023-07-17 08:24:18|Have to disagree with comparing webflow and libraries like LangChain   Webflow is non-trivially complicated and scaleable that you can run a business in 4-5 digit MRRs  LangChain is just to show that you’ve implemented an AI product
Neha YC W23|2023-07-17 08:24:35|Im not sure if this analogy is correct. This metal is not entirely unknown. By that logic companies building apps like uber should not have been built?
Neha YC W23|2023-07-17 08:25:14|I see langchain as idk older version of language libraries
Neha YC W23|2023-07-17 08:25:32|Right now its there, its not working but its needed. Someone will figure out the exact form
Neha YC W23|2023-07-17 08:25:42|NextJS came out like that.
Dr. Pratik Desai KissanGPT|2023-07-17 08:25:44|Before Uber, iPhone had users. The second order effect was possible after w got users on mobile phone, but this is not even second order, it's third order, where things are being built to build next Uber. ‎<This message was edited>
Neha YC W23|2023-07-17 08:26:09|Idk Doordash has been using openai since 002 in production
Kaushik S YC W23|2023-07-17 08:26:15|Hard to agree when Chat GPT has over 100M users.
Neha YC W23|2023-07-17 08:26:45|For making their support more humane.
Neha YC W23|2023-07-17 08:27:02|Cohere has very happy users
Kaushik S YC W23|2023-07-17 08:27:19|AI has percolated so far down the tech stack that it’s invisible now. Most of us are using it daily - photos, search, news feed
Dr. Pratik Desai KissanGPT|2023-07-17 08:27:40|We are not saying that AI won't have users, are we supposed to work on first and second order before investing in third. People are jumping on third, because it is easy to build library then finding consumers.
Neha YC W23|2023-07-17 08:28:03|What are the first and second order?
Dr. Pratik Desai KissanGPT|2023-07-17 08:28:51|OpenAI is first, Application like what we have that take AI to consumers is second. Look what is happening to Jasper, second order is already struggling.
Dr. Pratik Desai KissanGPT|2023-07-17 08:29:09|Helping Jasper to build automation tool, is third
Neha YC W23|2023-07-17 08:29:36|So picks and shovels are 3rd order ?
Dr. Pratik Desai KissanGPT|2023-07-17 08:30:04|selling timber to make pick and shovel is third
Dr. Pratik Desai KissanGPT|2023-07-17 08:30:24|Who is using these libraries, OpenAI?
Dr. Pratik Desai KissanGPT|2023-07-17 08:34:29|First order ones are already going for 100M+, Investors have been burned due to other second order startups, so they keeping looking for moat/distribution/retention, third one is easy for investors and founders, because the target is not deep tech or users like 1st and 2nd, but mostly acquisition if things works out.
Paras Chopra Wingify|2023-07-17 08:35:59|I looked at json net - what did gig mean by tree like configuration? Not clear
Paras Chopra Wingify|2023-07-17 08:37:47|Did you mean git like structure
Nirant|2023-07-17 08:43:16|[PHONE] sir time to ship code, and stop teasing us about it
Paras Chopra Wingify|2023-07-17 08:46:30|I think I got it.  Langchain can be reduced to a set of nested configurations
Saurabh Karn Nyai|2023-07-17 08:47:12|"Talking about shipping code, what do people think about Nbdev? I know ""purist"" software engineers don't really like anything less than an IDE but has someone gone deeper into the whole literate programing paradigm?"
Nirant|2023-07-17 08:49:01|fast.ai International Fellow here, was one of the earliest testers of nbdev. I love the literate programming way of thinking, but nbdev is just no mature enough honestly.  That is why my latest library (https://github.com/NirantK/agentai) is POC'd in Jupyter notebooks, but shipped as Python package (and .py code)
Nirant|2023-07-17 08:49:40|Every single feature/endpoint change in the lib gets written in the nbs here: https://github.com/NirantK/agentai/tree/main/docs
ashish Acgt01 Twitter|2023-07-17 08:50:06|Eating your own dogfood ftw !
Saurabh Karn Nyai|2023-07-17 08:53:21|Just probing a little bit, are you saying that development tools or debugging support is not there yet? or is there something else missing?  I think the reason why I like nbdev a lot and actively trying to get my team to use it is because shipping as a pythong package and not thinking too much about CI, docs etc is a huge time savings. But that's just me.
Ritesh Invideo Nilenso|2023-07-17 09:00:05|it's useful for libraries right, can you use it for actual production applications?
Saurabh Karn Nyai|2023-07-17 09:01:26|You can ship your application as a library as well. But that’s a choice. I haven’t shipped applications built using nbdev yet.
Ritesh Invideo Nilenso|2023-07-17 09:02:46|i just came to know about it today. I am a huge fan of literate programming, this looks pretty cool. will try out
Nirant|2023-07-17 09:10:31|Two things:   1. Yes, e.g. doesn't work that well with poetry. Tests are not standard pytest compatible. Fixtures are missing the nbdev way of testing. 2. Can't share code for review, or expect contribution from other devs who're not very comfy with literate.  Most important: 1. Developing API in notebooks and keep porting logic to scripts works too well to be worth the effort
Nirant|2023-07-17 09:12:45|"Quite telling that the best ""Hindi"" AI work is being done out of SF: https://twitter.com/therealprady/status/1680645510103977987"
Neha YC W23|2023-07-17 09:18:01|Ezdubs is doing this too
Neha YC W23|2023-07-17 09:18:13|They have a twitter and whatsapp bot for b2c side
ashish Acgt01 Twitter|2023-07-17 09:32:55|https://www.nytimes.com/2023/07/05/business/artificial-intelligence-power-data-centers.html
Nirant|2023-07-17 09:35:04|Maybe add a line or two about why you think this'd be interesting to readers or why you find this worth your time
Nilesh Transcend|2023-07-17 09:49:51|For Julia code, https://github.com/fonsp/Pluto.jl is fantastic. Notebooks are saved as pure Julia files which makes things a lot nicer.
ashish Acgt01 Twitter|2023-07-17 10:16:18|TIL Geoff Hinton has had a movie worthy , unconventional life !  https://twitter.com/DynamicWebPaige/status/1626841309561630720?s=20  Very inspiring !
Sandeep Srinivasa RedCarpetup|2023-07-17 10:20:59|Correct. That was the big aha moment for me. But the more interesting question is - what kind of configuration? Chain of thought is very complex chains. So it can't just be simple config. The config themselves should be a well designed language in itself.  We chose jsonnet for this - which is quite popular in the kubernetes world to manage fairly large configuration trees.
Paras Chopra Wingify|2023-07-17 10:22:24|Have you documented your config syntax? ‎[7/17/23, 10:22:26] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-07-17 10:22:35|Langflow does this under the hood
Paras Chopra Wingify|2023-07-17 10:22:41|Not sure how this json looks like
Sandeep Srinivasa RedCarpetup|2023-07-17 10:23:11|Langflow configures Langchain
Rajesh RS Generative AI WhatsApp Group|2023-07-17 10:28:42|This is about the importance of big cloud and big tech companies for small AI teams like   Anthropic and cohere. There is a mention of open source but the emphasis seems to be on using smart researchers in high impact teams.
~ Sidharth|2023-07-17 10:54:08|‎~ Sidharth left
C Chaitanya Nutanc|2023-07-17 11:08:31|Doesn't langflow use react flow? I think the json is similar to reactflow
Sandeep Srinivasa RedCarpetup|2023-07-17 11:12:19|langflow uses react-flow to model the UI, however the AI part of the code is to wire up langchain.
~ Arindam Barman|2023-07-17 11:14:17|There's a difference though. Frontend technologies like react and all do one thing really well compared to langchain, llamaindex which does multiple things and you don't require 90% of them. When I'm using React I use 90% of their features. While if I have to use langchain I mostly have a usecase of maybe 10% of their features which itself is easily replaceable by just an API call. (1 hour extra work) compared to if I have to write my own reusable rendering logic like React it's going to take me weeks to make something robust and tested
Sandeep Srinivasa RedCarpetup|2023-07-17 11:17:28|i concur on this generally - and i do have a huge amount of respect for langchain/gptindex for moving the community forward. nextjs vs reactjs (as you pointed out) is indeed the correct parallel. you should use reactjs to experiment with frontend development. but production is always nextjs+vercel.
Neha YC W23|2023-07-17 11:18:51|I'm certain while the community cribs about Langchain, someone will be building the right product form for it. That also comes from more and more users building on this tech using Langchain. [PHONE] maybe your stab at it will be it!
Neha YC W23|2023-07-17 11:20:36|actually, production of core app is not Next, it should be react. NextJs brings in good abstractions for people to easily develop production grade apps. There will be something similar, history repeats itself. In AI it seems to be doing so faster :D
Nilesh Transcend|2023-07-17 11:26:26|This looks like a langflow alternative: https://www.airops.com/
Rohit Aggarwal|2023-07-17 11:31:20|patterns.app is another one (Not sure if that uses langchain under the hood though)
Shashwat TDC|2023-07-17 11:31:40|.json itself is a object notation language. The time this natural language framework was created, .js was hated by most.  Looks like we are headed to build softwares written in .english
Sandeep Srinivasa RedCarpetup|2023-07-17 11:36:25|jsonnet != json.  jsonnet is a language invented at Google Borg and used now at Deepmind for their large scale configuration systems (like Kapitan)
Shashwat TDC|2023-07-17 11:37:15|Yeah was talking about .json
Dhruv Anand|2023-07-17 11:38:22|Cost of generation via 3.5 v/s embedding?  Ratio for base to fine tuned is opposite?
Rohit Aggarwal|2023-07-17 11:42:51|Great resource! I’d love to create one that shows the cost vs performance vs accuracy tradeoffs on top of this :)
~ Vrushank Vyas|2023-07-17 11:47:08|There's this for open source models: https://aviary.anyscale.com/
Bharat Kumar Ramesh Hashmal Web3|2023-07-17 12:03:34|This is a great point
Abhishek Mishra|2023-07-17 12:12:13|The cost to train the 13B model with 1.4T tokens is outdated. ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-17 12:16:14|Check this out, It says <200$, I still can't believe. https://twitter.com/alignment_lab/status/1679250520782036992
Abhishek Mishra|2023-07-17 12:32:16|They fine-tuned llama 13B with openorca dataset, right? I think they're referring to the costs of fine tuning.
Abhishek Mishra|2023-07-17 12:34:36|MPT 30B has revealed the training time, GPU setup and dataset size for final fine tuning their pretrained models. Though they haven't revealed numbers but by using the existing numbers we have on lambda labs/runpod/vast ai, i saw that the costs were less than 200k usd
Abhishek Mishra|2023-07-17 12:35:14|Also, Salesforce xgen revealed they trained 10x chinchilla optimal size their 7B model for less than 150k
Dr. Pratik Desai KissanGPT|2023-07-17 12:36:12|Training and fine-tuning cost is going down quickly
Abhishek Mishra|2023-07-17 12:38:57|Yes, i saw last week a paper that showed same efficiency of training as FP16 for 4 bit QLoRa pretraining. It will bring down the costs further by an order of magnitude at least.
Brij Singh Rebright Partners|2023-07-17 12:39:11|https://podcasts.apple.com/in/podcast/replit-ai-podcast/id1689491150?i=1000618752205   This is good discussion on current challenges and opportunities in both Open and Custom Models.
Abhishek Mishra|2023-07-17 12:40:22|Yes, this was a very good discussion. Quite a few insights in there about the model size, dataset quality, choice of GPUs and role of quantized inferences in the near future
Sachin Legaltech|2023-07-17 12:41:29|Rule of thumb to estimate cost of pre training according to researcher at eleuther ai - Cost (dollars) = k • [# params (billions)] • [# tokens (billions)] where k ranges from 10 to 50 depending on cloud pricing and skill. https://twitter.com/blancheminerva/status/1677697585899773954?s=46&t=PtXsyxI-ZtFT1qUEbUxlBQ
~ Aditi Kothari|2023-07-17 12:42:26|‎~ Aditi Kothari requested to join
Dr. Pratik Desai KissanGPT|2023-07-17 12:44:52|Let's see what tomorrow brings us with the Meta announcement. I'm not sure why we will have to train foundation models for some time after llama2 commercial availability.
Abhishek Mishra|2023-07-17 12:47:33|I also expect an upgrade in llama quality with all the learnings that have come in the past few months. It might as well be the SoTA when it comes out for its model sizes. ‎<This message was edited>
Sachin Legaltech|2023-07-17 12:52:27|If we have large amount of domain- specific data which isn’t available on internet like bloomberg, then I think pre training foundation model makes sense.
Divya Tak|2023-07-17 12:53:14|Because of hardware upgrades, or optimisation on training side or something else?
Dr. Pratik Desai KissanGPT|2023-07-17 12:55:04|Not so much with hardware but new training methods, and research that demonstrated the benefits of high-quality data
Abhishek Mishra|2023-07-17 13:01:48|Yes, this is a very good rule of thumb. But good to also know the caveat   Assumptions: *Model utilises A100 optimally, it doesn't need anything bigger than 40G VRAM at once. Or can't be done easily in <24G (parameter+token) *The training is in fp16
Nirant|2023-07-17 13:02:41|fp16 is a reasonable assumption now, is it?
Nirant|2023-07-17 13:02:46|That was fast
Abhishek Mishra|2023-07-17 13:06:02|By the time I learnt what was the difference between fp16, FP32 training and why we trained better and faster in FP32, it turned out that everyone is interested in lower bit pretraining now.
Abhishek Mishra|2023-07-17 13:07:33|https://arxiv.org/abs/2307.05695  The QLoRa pretraining paper that achieves similar results as FP16 might bring down the costs 10x further
Shilpa Hasgeek|2023-07-17 13:08:09|Isn't the pretraining better in fp32 for better training (ofcourse compute time and resources would be more) but later convert to fp16 for faster inferences
Abhishek Mishra|2023-07-17 13:10:09|Yes it's better in fp32. It's still preferred by those who have abundance of compute. But dataset quality, epoch caveats have blurred the line for those who want to pretrain in lesser compute.
Dr. Pratik Desai KissanGPT|2023-07-17 13:11:03|Yes, I saw this one. It looks like we are discovering more and more efficient way. Moore’s law lasted for decades, chinchilla is not going last even half a decade.
Abhinav Verma Longshot.ai|2023-07-17 13:15:19|fine-tuning would work here right?
~ Aditi Kothari|2023-07-17 13:15:34|‎~ Aditi Kothari joined from the community
Sachin Legaltech|2023-07-17 13:39:47|Not able to find any recent literature which uses finetuning to add knowledge. Would like to read if anyone has found something like that.
Neha YC W23|2023-07-17 13:44:32|M keen to know as well.
Kishore GenAI|2023-07-17 13:47:38|Does retrieval based argumentation methods not work for this?
Abhishek Mishra|2023-07-17 13:48:28|Fine tuning is mainly good for style and structure, not so much for knowledge 😅
Abhishek Mishra|2023-07-17 13:49:32|I believe pretraining nanoT5 on your domain data and then coupling it with a chat layer for QA as an alternative to RAG may lead to useful results.
Kishore GenAI|2023-07-17 13:51:54|Any reason you are suggesting pre training over RAG?
Abhinav Verma Longshot.ai|2023-07-17 13:52:29|For that rag is there right?
ashish Acgt01 Twitter|2023-07-17 13:54:18|"contrasting ""finetune on domain corpus + chat way"" vs ""RAG way""  is there still a notion of search, to find the chunk and input to the chat , in the ""finetune + chat"" paradigm ?"
Abhinav Verma Longshot.ai|2023-07-17 13:54:19|Tokens are added in pre-training. That is definitely one major reason for pre-training for a new domain. This will enable the generations better as you have more complete words than subwords which might mess probability
Paras Chopra Wingify|2023-07-17 13:54:54|Yeah but I’m curious how they represent flows in json
Abhinav Verma Longshot.ai|2023-07-17 13:55:01|Can you elaborate on this?
Abhishek Mishra|2023-07-17 13:56:46|for anything that I've seen in action RAG appears to be simple and currently best performing as well. I've nothing against RAG.  Though there are certain challenges with vector DB involved approaches, and I'm trying to look for possible experiments to take care of that. ‎<This message was edited>
Abhishek Mishra|2023-07-17 14:00:04|Issue #1 - semantic matches don't catch the argumentative aspects of statement, whether the appearance of something is in positive or negative context or if it's for or against debate  Issue #2 when the info is spread out over multiple docs and answer has to be inferred by joining multiple pieces but the individual docs rank low in similarity score  Issue #3 when the answer has to inferred in chained reasoning like  Answer 1 would help us frame question 2 and answer 2 would help us frame question 3. Then answer 3 would be able to answer the user question
Abhishek Mishra|2023-07-17 14:00:34|As you can see, I'm sure most people don't relate with all these issues so I'll see myself out 😅
Neha YC W23|2023-07-17 14:01:03|For latter use cases, isnt there something like sliding window context
Abhinav Verma Longshot.ai|2023-07-17 14:01:07|2 and 3 can be done via RAG techniqued
Neha YC W23|2023-07-17 14:01:34|Where parts of context of separate documents are passed in each context to the ai?
Abhinav Verma Longshot.ai|2023-07-17 14:01:38|For 1 you are talking about finetuning embeddings rather than finetuning the LLM. That is different and cheaper and easier
Abhishek Mishra|2023-07-17 14:02:45|For #2, you won't get the docs in context because individual docs ranked low  For #3, the model will try to answer based on the fetched context. You'll have to make it into an agent to perform repeat queries with chained inference but it's possible with RAG. Haven't seen it in action properly is all.
Sachin Legaltech|2023-07-17 14:03:25|For creative questions like - “what other fields of science have different names for the idea of natural selection ?”, we will need pretrained language models..My mental model is RAG is great for factual information; but for creativity, pre training  models will be better.
Abhinav Verma Longshot.ai|2023-07-17 14:03:44|No there are other ways, we have done this in longshot for multiple urls at a time. Can be extended to docs
Sachin Legaltech|2023-07-17 14:04:44|I think this is mixture of issue 2 and 3
Abhishek Mishra|2023-07-17 14:05:24|Creativity and any level of reasoning to make a meaningful inference in one go.
Abhishek Mishra|2023-07-17 14:05:39|Yeah
Abhishek Mishra|2023-07-17 14:06:27|How did you take care of #2, when the docs needed for answer themselves don't rank and get fetched in top k retrieval?
Abhishek Mishra|2023-07-17 14:07:38|I think you're talking about context as in context of prompt whereas my issue was with the fetched docs from retrieval. Or am I understanding your question wrong?
Abhinav Verma Longshot.ai|2023-07-17 14:07:46|chunking is all you need. Think of different chunking strategies you can apply here and how you get all the information.  chunking + embedding + non embedding retrieval techniques solves majority of your problems
ashish Acgt01 Twitter|2023-07-17 14:09:22|"But when your document corpus changes frequently ( say mostly additions)   - is fine-tuning on the newer domain specific corpus  more of a hassle  Vs  ""The rag way"" - where you would simply add the new docs  to the rag corpus to be indexed ?  What I am saying is current cost and friction of fine-tuning + chat >>> RAG ?  Ofcourse, with the caveat that for some usecases, performance of fine-tuning + chat  >>> RAG ‎<This message was edited>"
Rajesh RS Generative AI WhatsApp Group|2023-07-17 14:11:02|Are there Azure managed instances for vector DBs? Which ones should one try? I think Weaviate can be AKS hosted but no PaaS offering as such I guess
Abhishek Mishra|2023-07-17 14:11:05|Yeah, can't fine tune often without ending up with suboptimal models for data that changes too often. Just stick to RAG there perhaps.
Alok Bishoyi|2023-07-17 14:13:21|Azure folks had recommended cognitive search , azure cache for redis during our walkthrough
Alok Bishoyi|2023-07-17 14:14:03|They had also mentioned the current prevailing solutions such as pinecone, chroma etc as well if we wished to
ashish Acgt01 Twitter|2023-07-17 14:14:20|Maybe in time, it will be all ui triggered for enabling non tech/ mgmt folks to update for fine-tune also :  - upload new docs - click the fine-tune button :)  Especially for cloud,  managed deployments
Abhishek Mishra|2023-07-17 14:14:59|It's good if it works for you, I'll be happy to see the ever-working optimal chunking strategy that isn't so small that it misses out on important info present in context of occurrence and that isn't so big that it can't be efficiently processed and recalled. Such a strategy would strike the perfect balance between depth and breadth of information.
ashish Acgt01 Twitter|2023-07-17 14:16:14|"Yaa !  An optimal strategy would enable discovering of local(short range ) and global (""long range"") patterns and structures inherent in the data ?"
~ Shreya Gowri|2023-07-17 14:16:35|‎~ Shreya Gowri left
Abhinav Verma Longshot.ai|2023-07-17 14:17:18|This requires experimentation for your use case. This solution isn't going to be available out of the box, else everyone would be doing it. We experimented and came with a solution that works here. You can also add some extra filtering. Not everything has to be LLM based.  Edit: Also adding but there are enough techniques that will work here out of the box ‎<This message was edited>
Abhishek Mishra|2023-07-17 14:18:58|If you did a lot of experiments and it worked on a few set of docs, you may see that different docs and constraints will need you to change your approach again. One size fits all doesn't work here and that's a genuine limitation. Not a very pressing one, but a limitation none-the-less.
Abhinav Verma Longshot.ai|2023-07-17 14:19:58|I think you are misunderstanding me. Can discuss this one on one. What we did works on urls of wide range of domains.
Abhinav Verma Longshot.ai|2023-07-17 14:22:05|And also looking for perfect solution ML/LLM based doesn't work in real scenarios anyways. You have to be creative here. My 1000 tokens on this is  - Pretraining or fine-tuning should be the last thing you think about in production. - There's a lot that can be solved by current out of the box techniques. At the end of the day there are various costs and constraints you need to look at, not just training.
Abhishek Mishra|2023-07-17 14:25:25|Reiterating my original context, I'm just interested in combos to take care of genuine issues that exist with current RAG approaches. I'm well assured it's the best approach we have that works and gets a few things done with simplicity.
ashish Acgt01 Twitter|2023-07-17 14:28:07|"i think, one cant generalize Its very usecase specific and even for a single usecase, is very ""distribution of user input traffic""(mouthful i know !)- specific  i imagine, especially in mission critical domains like medicine, legal etc it will require very careful and fine-grained monitoring for distribution shifts and performance, and initial systems will be  - ""brittle"" - unpredictable in their brittleness/modes of failure"
Abhinav Verma Longshot.ai|2023-07-17 14:29:18|The case you are describing though can also be solved by finetuning the embedding model and leaving the LLM as is to use with rag
Rajesh RS Generative AI WhatsApp Group|2023-07-17 14:29:33|Looking for an alternative to Azure redis cache actually
ashish Acgt01 Twitter|2023-07-17 14:39:53|"Playground: https://automorphic.ai/playground  code: https://github.com/automorphic-ai/trex  (via  https://news.ycombinator.com/item?id=36750083 )  ""Built a tool for transforming unstructured data into structured outputs using language models (with 100% adherence). If you're facing problems getting GPT to adhere to a schema (JSON, XML, etc.) or regex, need to bulk process some unstructured data, or generate synthetic data, check it out.  We run our own tuned model (you can self-host if you want), so, we're able to have incredibly fine grained control over text generation""."
ashish Acgt01 Twitter|2023-07-17 14:48:10|TIL about LMQL https://lmql.ai/ https://github.com/eth-sri/lmql  anybody used LMQL ?
~ Udit|2023-07-17 14:50:56|‎You removed ~ Udit
Saurabh Karn Nyai|2023-07-17 14:56:02|This group removal thing is terrifying! There goes one more 😅
Nirant|2023-07-17 15:04:39|Folks have nothing to worry about! Just spam is not tolerated.
Nirant|2023-07-17 15:14:03|Embedding Benchmark (mirror) from our very own [PHONE]  https://mteb.info/
Aditya Sista 2010B5|2023-07-17 15:19:58|Unregrettable attrition
Abhishek Mishra|2023-07-17 15:25:46|I thought today's the day of the purge again.
Ahan M R|2023-07-17 15:31:05|‎You added Ahan M R
Nirant|2023-07-17 15:32:45|Hahaha, active folks have nothing to worry. From the ~200 odd folks we've removed, only 4 have gotten back asking to be added. That's an error rate I'm willing to live with
Abhinav Verma Longshot.ai|2023-07-17 15:33:34|What an accuracy sirji
Abhishek Mishra|2023-07-17 15:33:59|Only 4? That is a very good sample.
Pranjal Yadav Razorpay|2023-07-17 15:36:05|Issue #2 is pretty relevant. Imagine you have 5-10 component level tech specs and product specs which are written to handle a big re-architecture activity which too has a tech spec.  Answering questions on the high level doc requires understanding of all the components.
Pranjal Yadav Razorpay|2023-07-17 15:41:10|Chunking at a heading level within a doc, and extending that across docs is something I tried. The performance was decent but it failed to rank relevant topics because headings within a document maybe have some context in previous headings.  I didn't attempt sending all the doc at once because a document can span from 4-20 pages in my experiments.
ashish Acgt01 Twitter|2023-07-17 16:00:37|Precision is very high ! :)
Bharat Kumar Ramesh Hashmal Web3|2023-07-17 16:26:24|Off topic. I've always been confused with the difference in accuracy and precision. Which one is this?
Divya Tak|2023-07-17 16:28:16|accuracy would also involve how few false negatives were there afaik
~ Deven|2023-07-17 16:29:14|GPT-4   Sure, let's imagine you are throwing darts at a dartboard.  Accuracy is like trying to hit the bullseye. If your throws are accurate, they will land on or very close to the bullseye. If you're inaccurate, your darts might be scattered all over the board.  Precision is how closely grouped your throws are. If you're precise, your darts will land in the same spot each time, even if that spot is not the bullseye. If you're imprecise, your darts could land all over the place.  So, if you're both accurate and precise, your darts consistently hit the bullseye. If you're precise but not accurate, you consistently hit the same spot, but it's not the bullseye. If you're accurate but not precise, your darts are scattered but average to the bullseye. If you're neither accurate nor precise, your darts are just scattered all over the board.
Bharat Kumar Ramesh Hashmal Web3|2023-07-17 16:30:10|Haha Ty.  Wiki also had this really neat note  In simpler terms, given a statistical sample or set of data points from repeated measurements of the same quantity, the sample or set can be said to be accurate if their average is close to the true value of the quantity being measured, while the set can be said to be precise if their standard deviation is relatively small. ‎[7/17/23, 16:36:18] Nilesh Transcend: ‎image omitted
~ Shivaprasad|2023-07-17 17:05:18|\
Sainath GenerativeAI WhatsApp Group|2023-07-17 17:22:34|surprised to see how you keep track of all these numbers
Nirant|2023-07-17 17:27:58|Helps that I don't have much of a life
Rajesh RS Generative AI WhatsApp Group|2023-07-17 17:35:08|Listening to this one by [PHONE]  on domain specific LLMs https://youtu.be/hOAJ1708Tp0
Nirant|2023-07-17 17:36:07|This joke clearly didn't land.
Rajesh RS Generative AI WhatsApp Group|2023-07-17 17:36:13|"The ""brain model + muscle model"" approach seems interesting. Wonder if the earlier work done on transformer-in-transformer could be a substitute"
Gokul Krishnan|2023-07-17 17:46:43|You mean didn't settle? 😜
~ Pulkit Chhabra|2023-07-17 17:50:40|‎~ Pulkit Chhabra requested to join
Sainath GenerativeAI WhatsApp Group|2023-07-17 17:57:43|Yes didn’t understand it for first time
~ Rahul Bansal|2023-07-17 17:57:49|This is nice
~ RISHAV|2023-07-17 18:20:24|Hello folks, I was going through the Azure OpenAI pricing, for comparing the price of gpt-35-turbo and gpt-35-turbo-16k, but I am not able to see the pricing separately for the 16k model on this page  https://azure.microsoft.com/en-us/pricing/calculator/?service=openai-service  Is the pricing the same?, as per open ai pricing it's different. I want to know with respect of Azure Service.
~ Maruti Agarwal|2023-07-17 18:36:41|Accuracy and precision are somewhat simialr… recall means soemhtign different
Nirant|2023-07-17 19:15:53|Cc [PHONE] from Azure India
Aashay Sachdeva MPL Data Scientist|2023-07-17 19:23:26|Has anyone seen the palantir and scale AI defence products? It’s scary to think these are connected to military infra and tools, used for reasoning and actions. MI dead reckoning vibes
Anubhav mishra Zupay|2023-07-17 19:25:03|I think they are currently using it for preventive measures. Not sure about what is going on under the hood
Aashay Sachdeva MPL Data Scientist|2023-07-17 19:27:36|https://www.palantir.com/aip/defense/  Check out the video
Ankita Mathur Microsoft Sales|2023-07-17 19:31:34|https://techcommunity.microsoft.com/t5/ai-cognitive-services-blog/introducing-new-and-updated-models-to-azure-openai-service/ba-p/3860351 - refer to this link
Anubhav mishra Zupay|2023-07-17 19:32:37|This is crazy, have they built a custom model, it is already in testing?
~ Abhiram Ravikumar|2023-07-17 20:16:36|https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence  Anyone looking into the new EU privacy law?
~ Abhiram Ravikumar|2023-07-17 20:17:54|"Unacceptable risk:  ""Social scoring: classifying people based on behaviour, socio-economic status or personal characteristics""  Will this have any impact on recommendation systems and customer segmentation tools?"
~ Abhiram Ravikumar|2023-07-17 20:20:15|"Generative AI  ""Generative AI, like ChatGPT, would have to comply with transparency requirements:  Disclosing that the content was generated by AI Designing the model to prevent it from generating illegal content Publishing summaries of copyrighted data used for training""  I did not understand the third point, can someone please elaborate? Tia :)"
~ AI|2023-07-17 20:27:45|From what I understand, it requires you to disclose all material protected by copyright that was used to train the model - likely to ensure due credit to the original author/writer
Aashay Sachdeva MPL Data Scientist|2023-07-17 20:30:58|Basically how their visa service,  their credit scoring works currently?
Jay Pokarna 2014 BPCC|2023-07-17 20:38:14|Not classifying people based on behaviour is too broad. If you can't classify people on behaviour, then good luck classifying them🤣
~ Nikhil|2023-07-17 20:38:59|https://crfm.stanford.edu/2023/06/15/eu-ai-act.html
~ Nikhil|2023-07-17 20:39:15|This is a good post on applicability of EU laws on foundation models ^
Jay Pokarna 2014 BPCC|2023-07-17 20:40:41|This can also be inferred to say that you can't not give loans to people with low credit scores due to their previous behaviour. This goes way beyond privacy, if true
Sandeep Srinivasa RedCarpetup|2023-07-17 21:01:38|this is already present in non-LLM based AI. We have reported this kind of anti-bias data to RBI for years now.  For e.g. a lot of people dont realise that if you use location data to do credit scoring, you inadvertently discriminate against people on basis of caste & religion.  I will leave it as an exercise for you to figure out why.
Abhishek Mishra|2023-07-17 21:07:05|This is definitely anti-recsys.
Jay Pokarna 2014 BPCC|2023-07-17 21:28:32|This is true. Using location data, religion, etc is no no for credit scoring. But saying that you can't use any behaviour is a bit too far no? As in, you can say that past emi payment data is also behaviour only. If you can't even use this for credit scoring, then isn't that an issue or am I wrong to assume that past payment data will not count as a behaviour?
~ Abhiram Ravikumar|2023-07-17 21:29:52|I'm sorry, what is recys?
Jay Pokarna 2014 BPCC|2023-07-17 21:30:36|Recommendation systems I think
Aashay Sachdeva MPL Data Scientist|2023-07-17 21:32:02|Does rbi have guideline against using these for alternative credit scoring systems?
~ Abhiram Ravikumar|2023-07-17 21:35:20|Exactly
Sandeep Srinivasa RedCarpetup|2023-07-17 21:53:06|"The RBI has a rule saying ""you must prove no bias exists"". If you do that good. If you can't do that to their satisfaction, you get an ED arrest notice. There are no more elaborations beyond this.  True story btw."
Ankur Pandey|2023-07-17 22:11:15|Michael Siebel (YC guy) in a recent video spoke about 2nd order effects of GenAI. https://www.youtube.com/watch?v=smHw9kEwcgM.  Paraphrasing & expanding upon what he said:  smartphones emerged => 1st order effects - apps like maps, emails, amazon, single player games => smartphones start spreading everywhere => (1) obvious 2nd order effects - whatsapp, mobile advertising SaaS; (2) not so obvious 2nd order effects - uber, ott platforms, UPI  What are some obvious & not so obvious 2nd order effects in generative AI?
Bharat Kumar Ramesh Hashmal Web3|2023-07-17 22:17:19|Obvious effects are threads and newsletters
Abhishek Mishra|2023-07-17 22:18:31|The most consumed products of H1 2023 were waitlists and 🤯 threads 🧵 ‎<This message was edited>
Kaushik S YC W23|2023-07-17 22:20:04|Individual brands will become more highly leveraged.   For example, an actor like SRK need not act. His image at a certain age can be made to act according to a script.  2nd order effect of this - you can sit on your laptop and create a Bollywood quality movie. The tech for that exists, just needs to be packaged right.
Gaurav Sharma Founder CEO|2023-07-17 22:22:02|Obvious Second-Order Effects:  -Improved Content Creation -Enhanced Personalization  Not So Obvious Second-Order Effects in ​(expanded spectrum) ​Generative AI:  -Augmented Human Capabilities -Ethical Considerations and Bias Mitigation -Reinventing Industries and Job Roles -Unforeseen Creativity and Artistic Expressions: -Collaborative AI -Emotional AI -The Great Cultural Convergence -Technological Leapfrogging -Universal basic Assets (Abundance)
Palkush GenerativeAI Group|2023-07-17 22:23:19|Non obvious effects - way more data noise. GenAI parrots and bots polluting all public and social media - Verified accounts become hygiene for any online credibility.
~ Apurva Bhatt|2023-07-17 22:26:37|I guess it will become like today's news media. Most news channels are mostly showing useless drama. There are only a few news outlet that will give genuine quality and diverse news, that people will pay for as well
Ankur Pandey|2023-07-17 22:27:53|Folks, I was by effects (citing the examples of apps) I meant concrete (startuppy) ideas. For example - will premium AI proof / insulated communities will rise?
Rajesh RS Generative AI WhatsApp Group|2023-07-17 22:29:08|Stretching into philosophy territory, but I think manufactured content poison is the new attention hacking - the former is a new capability thanks to AI models, and the latter is a result of social media. I think most tech/media companies will begin to use this 1-2 punch to get addictive consumption on their products
Satyajit Roy|2023-07-17 22:30:15|Has anyone used uizard.io? I bought the sub under the impression that they do autogeneration of image to ui code but they  apprently stopper the export to code option...
Satyajit Roy|2023-07-17 22:30:20|Stopped*
Rahul Bhatnagar|2023-07-17 22:39:38|Obvious 2nd order effects:  https://twitter.com/ItakGol/status/1680954309641482240
Rahul Bhatnagar|2023-07-17 22:42:06|Non obvious 2nd order effects. Social networks start to collapse/change dramatically. As they go from personalized curation of UGC to personalized creation of content for each user.
~ Eshaan Gulati|2023-07-17 22:43:22|Is anyone interested in developing a threat detection AI ML software
~ Rahul Bansal|2023-07-17 22:51:57|I feel some second order effetc might be:- 1.  SAAS Churn might increase, AI will make it easy to get data from existing softwares and populating other softwares. 2.  Testing Jobs will increase, AI makes it easier for people to do code changes fatser, which might put load on testing infra. 3.  UX of Softwares might be hyperpersonalised, just like Social Media Feeds. 4.  Software is brittle today, Rename a variable and things breaks. There might be a layer of intelligence sitting between each contract. I wrote some more in Twitter Thread https://twitter.com/BansalRahul14/status/1641396949281562624?s=20
Piyush Makhija|2023-07-17 23:09:42|https://www-businessinsider-com.cdn.ampproject.org/c/s/www.businessinsider.com/openai-gpt4-ai-model-got-lazier-dumber-chatgpt-2023-7?amp
Aditya Sista 2010B5|2023-07-17 23:12:07|Maybe even less obvious, completely accelerated technological progress on another scale, we are no longer limited by domain knowledge to build things. At least, the gap to acquire domain knowledge to do something is exponentially lower
Piyush Makhija|2023-07-17 23:12:08|Has anybody found any major issues with the latest GPT-4 api?  Poorer performance that can potentially spoil the use case?
Aditya Sista 2010B5|2023-07-17 23:14:16|Yeah. Looks like a cost cutting move.
~ Rahul Bansal|2023-07-17 23:14:53|This is intereting, learning new things is easier with the LLMs. It will be cool if I can see the questions asked by other people with answers on the same topic.
Aditya Sista 2010B5|2023-07-17 23:17:25|"Try this prompt ""Identify and behave as three different experts that are appropriate to answering this question. All experts will write down the step and their thinking about the step, then share it with the group. Then, all experts will go on to the next step, etc. At each step all experts will score their peers response between 1 and 5, 1 meaning it is highly unlikely, and 5 meaning it is highly likely. If any expert is judged to be wrong at any point then they leave. After all experts have provided their analysis, you then analyze all 3 analyses and provide either the consensus solution or your best guess solution. The question is..."" ‎[7/17/23, 23:22:54] ~ Rahul Bansal: ‎image omitted"
Piyush Makhija|2023-07-17 23:27:14|I expected cost cutting without significant impact on performance ...  But it seems to be close to GPT-3.5 level now..
Ankur Pandey|2023-07-17 23:52:44|Can you ELI5 these points?
Ankur Pandey|2023-07-17 23:53:14|This toh obvious only no?
Ankur Pandey|2023-07-17 23:58:48|So the second order effect here is.. Rise of Chinese room experts? Who can get shit done but don't really grok it?
Sachin Legaltech|2023-07-18 00:03:02|Flash Attention-2 got released. https://princeton-nlp.github.io/flash-atttention-2/
Shashank Generative AI Group|2023-07-18 01:21:17|just thinking out loud. another issue  within Issue 3:  say 3 chunks are fetched. but before doing reasoning via sequential chain, one would also need to reorder those chunks in their logical order, right?  in that case, maybe pass those 3 chunks through GPT, tell it to reorder the chunks based on some reasoning parameters. then do further reasoning based on this correct order.  am i making sense?  depends on the domain. i can't come up with a specific example right now.
Abhinav Verma Longshot.ai|2023-07-18 01:22:04|reordering? Do you mean ranking to filter out relevant chunks?
Shashank Generative AI Group|2023-07-18 01:29:42|"no. im talking about the relationship between the X chunks fetched. as in chronology.   again, difficult without a proper example. but let's say: 3 chunks were fetched from some documentation of a system which has components A,B,C,D,E  chunk 1 is about E, chunk 2 about C, chunk 3 about D. so the correct order will be 231, not 123.  forget sequential chain. so the above chunks should be sent to GPT as 231, right?  or is gpt intelligent enough, and the order doesn't matter? we can just solve via prompting. like some internal monologue trick. ""analyse the chunks, determine their proper order, then generate answer""   is this more clear? 😅"
Abhinav Verma Longshot.ai|2023-07-18 01:31:54|Chunk order does not matter. However, you can always add metadata in your chunks if you feel that matters. Like adding date of article. And you pass today's date in prompt. So gpt knows todays date and date of each chunk . It helps in certain cases. ‎[7/18/23, 01:32:44] ~ Ankit Sharma: ‎image omitted
Abhishek Mishra|2023-07-18 02:04:07|Issue #3 is a bit different than what you think.  The problem is that some answers require a chained reasoning. There exists no snippet in the docs that can answer the question in one go. The LLM will have to first infer what data it needs to collect to answer the question. It has to come up with questions that lead to the answer in hops.  The individual docs that are fetched to answer the primary question don't answer it directly and just have semantical similarity with some terms used in the question.  So the LLM has to have an agentic behaviour where it first plans how it can break the query, then it checks whether it has info to answer the first query. If yes, it uses the info to frame it's second query and so on.  If it's not clear, maybe i can take it separately in DM. ‎<This message was edited>
Abhishek Mishra|2023-07-18 02:05:29|Unsolicited info: Knowledge Graphs, in theory, are designed to deal with chained reasoning tasks better and thus some efforts are there to build Semantic Knowledge Graphs for RAG.
Shashank Generative AI Group|2023-07-18 02:08:46|"no no. it's clear. that's why in the 2nd message i wrote ""forget sequential chain"". mixed it up earlier.   have worked with sequential chains."
Shashank Generative AI Group|2023-07-18 02:09:40|this
Shashank Generative AI Group|2023-07-18 02:10:17|and this
Shashank Generative AI Group|2023-07-18 02:14:20|"came across this yesterday.  ""we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.""  https://arxiv.org/abs/2307.06917"
~ Prashant|2023-07-18 03:10:27|This is the most apt description of challenges in RAG that I’ve seen. I think one issue that you can add (similar to Issue #1), that’s very relevant for enterprise level RAG is   Many non-answering chunks.  Query - update on project X A lot of chunks talking about project X will rank high, which if there are many, might end up hiding the chunk containing the update from topk
Dr. Pratik Desai KissanGPT|2023-07-18 06:35:30|Which event is that?
Prayank Swaroop Accel|2023-07-18 06:36:02|This is Dropbox and Elastic AI meet-up.. it's being livestreamed (I don't know the link)
Prayank Swaroop Accel|2023-07-18 06:36:14|https://www.meetup.com/elastic-san-francisco-user-group/events/294476508
Paras Chopra Wingify|2023-07-18 08:12:45|https://kenschutte.com/gzip-knn-paper/
Shimanta Generative AI|2023-07-18 08:12:47|FTC has started investigating OpenAI: https://www.washingtonpost.com/documents/67a7081c-c770-4f05-a39e-9d02117e50e8.pdf?itid=lk_inline_manual_4
Shimanta Generative AI|2023-07-18 08:14:04|They have asked for specific on model training and what data was used, hallucinations, prompt injections, PII amongst others.
ashish Acgt01 Twitter|2023-07-18 08:18:46|Very interesting Paras.  Just goes to reinforce that don't take anything at face value ! Always try to repro !
Shan|2023-07-18 08:31:53|Gzip or not, IMO the key finding is that vector representations of text are not the only way. Who knows what other ways we can preprocess text? And it may benefit certain domains or use cases more than others.
Sugam Docyt|2023-07-18 09:16:07|Hey guys, we have the need for a multi-class text intent classifier. We have a limited, clean, and steadily growing dataset. We are exploring fine-tuning pre-trained models. Any thoughts on what be the right choices?    On a side note, really appreciate everyone here sharing the latest and greatest developments in GenAI space.
Anshuman Pandey|2023-07-18 09:17:11|For any founder planning to move to Bay Area, let me know  Happy to share my playbook & hacks for living here  P.S. moved here in Feb & have been navigating the scene since
Shan|2023-07-18 09:28:41|This depends on the baseline accuracy and domain. What is the accuracy on an off the shelf model from 🤗? you are getting and targeting? From a basic classification perspective if you have a lot of data you can even train your own Bert and further fine tune it. Or you can go the PEFT/LoRA way.
Nirant|2023-07-18 09:29:35|I'd prototype this with fasttext in 20 minutes and launch first and then replace the modeling in background once I had adoption
Nirant|2023-07-18 09:30:46|I'd helped a co make a $1m deal in 2018-19 with this approach.   Buyers love something which is fast, works across languages and doesn't need that much compute or data.
Brij Singh Rebright Partners|2023-07-18 09:35:49|I’m in the Bay Area Jul 23- Aug 5, would love to catch up with anyone in the community
Nirant|2023-07-18 09:36:22|All Langchain streams are in IST fwiw. And some of them are masterclasses like the one with Jo Bergum
Dr. Pratik Desai KissanGPT|2023-07-18 09:37:15|I'm here in South Bay, available for coffee any day.
Anmol Maini|2023-07-18 09:42:06|and if anyone is exploring the O-1 route, let me know if I can help.  Have been referring founders to the folks at https://www.plymouthstreet.org/ who help founders and top talent navigate the O-1 process
Anshuman Pandey|2023-07-18 09:43:28|Don't want to get into technicalities but L-1 is better for founders
Neha YC W23|2023-07-18 09:49:46|We have applied for O1. Hmu if you need any information
Neha YC W23|2023-07-18 09:50:30|Im around in sfo, can catch up
Kaushik S YC W23|2023-07-18 09:52:34|Why do you say that?
Anshuman Pandey|2023-07-18 09:54:49|Less paperwork, faster decisions
ashish Acgt01 Twitter|2023-07-18 10:03:58|Every few days i see some advance or research, which makes me go: this is wild ! blowing my mind.  In today's such wow moment : https://stability.ai/research/minds-eye  https://medarc-ai.github.io/mindeye/  paper : https://arxiv.org/abs/2305.18274 code :  https://github.com/MedARC-AI/fMRI-reconstruction-NSD  (via : https://news.ycombinator.com/item?id=36766700 )
Paras Chopra Wingify|2023-07-18 10:05:25|See top HN comment, it’s not as impressive as it sounds
Pratik Bhavasar|2023-07-18 10:13:36|FlashAttention-2 is 2x faster 💥I think we are moving towards 0 compute cost😬
Paras Chopra Wingify|2023-07-18 10:18:39|Wasn’t new llama supposed to be released yesterday?   No news yet
Dr. Pratik Desai KissanGPT|2023-07-18 10:21:19|Yeah, Bummer 😞
ashish Acgt01 Twitter|2023-07-18 10:21:56|"Thanks Paras.  I have been reading the hn thread with wonder :)  "" ANYWAY SO COOL!!! I wonder if you could use this to draw people's faces with a subject who is imagining looking at a face? fMRI police sketch? How do brains even work!?""  ""In a popular sci-fi (avoiding spoliers), the alien race has transparent skulls, and their visible thoughts are broadcast to anyone within visual range. It does seem more efficient than sound.""  ""Techniques like this give me hope that some day we will be able to objectively diagnose mental illness, and monitor the efficacy of treatment."""
Nirant|2023-07-18 10:25:06|Damn. NVIDIA must be sad.
Paras Chopra Wingify|2023-07-18 10:25:52|fmri resolution is too low for this to work  Wrote an overview of brain I/O tech here https://notes.invertedpassion.com/Consciousness/Overview+of+brain+input-output+techniques
Abhishek Mishra|2023-07-18 11:04:36|First thing i did on waking up was check Twitter for llama 2 release. Welp, gotta wait for some more time. It better be worth the wait.
Abhinav Verma Longshot.ai|2023-07-18 11:05:45|It will be Tuesday their time I think
Abhishek Mishra|2023-07-18 11:37:21|Bad look for the authors and the guys who ran with justification of the paper.  But really love the part that the authors kept the paper reproducible. This is what we need actually, open work that can be reproduced, challenged, debunked and improved upon.
Paras Chopra Wingify|2023-07-18 11:44:56|Yeah. Mistakes can happen. This is why focus on reproducibility is so important   But the results are still very decent
Ritesh Invideo Nilenso|2023-07-18 11:46:08|while I understand the results don't hold, what interested me is the novel approach. It may not be useful in prod but it's still interesting
Paras Chopra Wingify|2023-07-18 12:11:51|https://yoshuabengio.org/2023/03/21/scaling-in-the-service-of-reasoning-model-based-ml/
Paras Chopra Wingify|2023-07-18 12:13:05|Is anyone here working on model based approaches?
Nilesh Transcend|2023-07-18 12:21:29|Is it even feasible given that automated reasoning for even pure math is too difficult for current tech?
Paras Chopra Wingify|2023-07-18 12:33:33|The author talks about amortised inference, so instead of doing search from the scratch each time, you train a network to do that
Paras Chopra Wingify|2023-07-18 12:34:04|Building a world model automatically seems more difficult than inference on it
Paras Chopra Wingify|2023-07-18 12:51:55|I think the main issue in model building is knowing uncertainty   Even LLMs have an implicit world model, but they hallucinate liberally so their world models are like that of a delusional person  If we had an LLM that can estimate uncertainty, other models can use it:  a) to do amortised inference (for planning actions)  b) to plan actions
Paras Chopra Wingify|2023-07-18 12:52:19|What Bengio is saying is to separate world models from inference, and that makes sense
Paras Chopra Wingify|2023-07-18 12:52:46|I also like his emphasises on separating action modules from Inference modules, as a way to Mitigate AI risk
Ojasvi Yadav|2023-07-18 12:52:54|But then here's the catch22, if an LLM is so good that it can detect hallucination in other LLMs, then people will just use that superior LLM.
Paras Chopra Wingify|2023-07-18 12:53:46|A model with uncertainty also can be used by another model that actively seeks information that reduces uncertainty
Paras Chopra Wingify|2023-07-18 12:54:19|no, not another LLM but the same one  Like when I ask you capital of a country and if you don’t know that, you confidently reject giving an answer
Paras Chopra Wingify|2023-07-18 12:58:41|I really like his system 1 and system 2 analogy   Current LLMs are system 1, intuition driven, spits out an answer to any query  System 2 is deliberate inference on a world model, with uncertainty attached  Think of system 1 as a database, if answer isn’t obvious, switch to an inference algorithm on a world model.  The beauty of our brain is that we are constantly updating our world model to be rich and sparse
Paras Chopra Wingify|2023-07-18 13:00:03|For system 2 kind of inference, he proposes generative flow networks which seem pretty cool  https://milayb.notion.site/95434ef0e2d94c24aab90e69b30be9b3
Brij Singh Rebright Partners|2023-07-18 13:00:31|With regards to Intelligence, one general approach could be that instead one big LLM, there are several small ones that recursively call each other until a satisfactory solution has been achieved.  To make a human equivalent decision, we need an Observer Model.    We start by training 3 models on very specific tuning - Action Model: that analyses all the available information, but only to explore the potential upsides and positives. Inertia Model: to think about the unknowns, what could go wrong and how to assess that risk Harmony Model: is focused on intuitive reasoning and explores new avenues that could help everyone. Then there is the observer, the Equilibrium Model that watches the interplay and recursion. It is not in a hurry and let’s things play out when deciding the final outcome.  Only when it feels enough cycles have passed and the 3 qualities have exhausted, it gives the solution, that is pure, both dependent and independent of them.  The one model that rules them all, is The Observer Model
Abhinav Verma Longshot.ai|2023-07-18 13:00:44|Daniel Kahnemann much😜
Nirant|2023-07-18 13:03:15|Debunked Kahnemann, given how much of his work is discredited 🫣
Abhinav Verma Longshot.ai|2023-07-18 13:03:49|The system thinking terminology is still used here
Paras Chopra Wingify|2023-07-18 13:04:01|It’s amazing how in our head we have an entire simulated world, which we use when we are doing deliberate thinking
Divya Tak|2023-07-18 13:04:41|Yup. That's not debunked
Ciyunni|2023-07-18 13:08:06|only known-unknowns
Ciyunni|2023-07-18 13:08:56|and Rescher's ontology of what is not knowable is quite deep. (without emergence type process)
Paras Chopra Wingify|2023-07-18 13:09:23|Pls elaborate
Nirant|2023-07-18 13:10:07|On the Philosophy group please!
ashish Acgt01 Twitter|2023-07-18 13:10:36|Brij, is this documented formally & in more technical detail somewhere - in a preprint or such ?
Brij Singh Rebright Partners|2023-07-18 13:11:54|I've started writing a draft paper .. happy to share the collaborate .. big caveat, this is just a high level theory at the moment
Paras Chopra Wingify|2023-07-18 13:13:29|Link?
ashish Acgt01 Twitter|2023-07-18 13:15:27|"does ""creativity"" go hand in hand with ""hallucination"" & uncertainty ?  a model with less certainty is less likely to hallucinate but also less likely to be able to make ""leaps of logic"" ala humans  so maybe to paraphrase you, one needs both kinds of models :  1. a model with uncertainty to sample larger areas of the ""creativity""/""leaps of logic"" space 2. a model with less uncertainty to keep output of  1. grounded in reality ?"
Anubhav mishra Zupay|2023-07-18 13:19:54|Thats AGI I think 😅
Nirant|2023-07-18 13:20:35|https://chat.whatsapp.com/GuJCOKL4nVHH3szN1d8TRV
~ Nischal|2023-07-18 13:21:42|This sounds very reasonable and we are thinking about a very similar approach to have federated agents and co-pilot which you are calling as observer model which is overlooking everything.  [PHONE] and I had a long chat about this yesterday as we are both looking at taking certain things into production in enterprise landscape.  Thank you for sharing this 🙏
Saurabh Karn Nyai|2023-07-18 13:24:22|This is from some literature or you framed it? Either ways very well put.
Brij Singh Rebright Partners|2023-07-18 13:25:19|Its actually based on a Spiritual Philosophy -  It is said that there are 3 qualities that govern a human - Rajas / action Tamas / chaos Sattva / harmony. To reach a state of ekagrata / equilibrium, and hear the anhata / the unstruck sound, one must become nirgun, or the pure state where all has merged into one.
Saurabh Karn Nyai|2023-07-18 13:27:01|I think if we cap on the parameter size to address scaling issues, a right combination of mixed data would be needed. For example a code dataset with maybe contract dataset kind of things. So one dimension is principled AI thinking and planning but other is thinking skilled models. Something I’ve been contemplating about.
Brij Singh Rebright Partners|2023-07-18 13:27:19|We are working on a similar lines for Human + Machine Teaming using Autonomous AI Agents.    Idea being that we can have a swarm level execution on a Tree of Thoughts based approach for Enterprise Business Process Management.
Saurabh Karn Nyai|2023-07-18 13:28:55|So much aligned on this way of thinking. OG Garry Kasparov said something to this effect.
Brij Singh Rebright Partners|2023-07-18 13:30:57|Mixture of Dataset is an interesting approach. I have an idea which dataset could be used for this.
Nilesh Transcend|2023-07-18 13:31:02|Reminds me of Daniel Dannett's Multiple Drafts model of consciousness for some reason. 🙂
Saurabh Karn Nyai|2023-07-18 13:31:13|Let’s chat!
Paras Chopra Wingify|2023-07-18 13:31:23|Creativity is known / controlled hallucination
Abhishek Mishra|2023-07-18 13:32:36|"That's a ""Thinking Fast and Slow"" adaptation for LLM inference."
Abhishek Mishra|2023-07-18 13:34:44|As per current design of autoregressive decoder only transformers, setting max creativity minimises certainty and vice versa.
Brij Singh Rebright Partners|2023-07-18 13:34:59|This is very interesting .. thanks for sharing. Will spend some time to understand this deeply
Ciyunni|2023-07-18 13:41:06|hallucinations is a symptom of the dark triad (mental model) or in psychiatry, to certain loosely defined 'state of mind' - is hallucination triggered by uncertainty ? more of unable to fit data into one's worldview.
Ciyunni|2023-07-18 13:43:15|i am not commenting on the model building part ... only the first line of your comment 'Ashish'.
~ Nischal|2023-07-18 13:43:56|This is where we have seen knowledge graphs/enterprise data fabric play a great role, is to have semantic relationships between heterogeneous concepts.  Combining that with LLMs helps in connecting different dots quite well.  You could then have very specific agents that look at a subgraph of concepts and the observer model/copilot could then bridge the communications between the outcome of the agents.
Saurabh Karn Nyai|2023-07-18 13:44:25|confabulation that’s the word
Saurabh Karn Nyai|2023-07-18 13:46:33|Absolutely! What all industries would be down for this? Usual, Pharma types? Or has anyone seen anything interesting recently?
Nilesh Transcend|2023-07-18 13:47:40|IMHO, Knowledge graph is this seductive idea where companies go to die. Latest example that comes to mind is https://golden.com/
Nilesh Transcend|2023-07-18 13:51:01|For https://learnawesome.org/, I toyed with knowledge graphs and ConceptNets for a while. A hand-curated taxonomy is far more practical and lets one actually ship things.
Rajesh RS Generative AI WhatsApp Group|2023-07-18 13:53:11|What are productive use cases? We have had this discussion on knowledge management for 2+ decades and perhaps some apps have been built. There was a small toy app called Graph GPT which seemed interesting for a while but it was probably too simple and based on too many assumptions
Nilesh Transcend|2023-07-18 14:00:23|W3C has been beating the RDF / Semantic Web drum for many years. I haven't run into many practical use cases but this thread lists some: https://news.ycombinator.com/item?id=36001509
Dr. Pratik Desai KissanGPT|2023-07-18 14:02:04|Because with LLMs, ontology creation can be automated ‎<This message was edited>
Nilesh Transcend|2023-07-18 14:02:51|Any reading material on this?
Nilesh Transcend|2023-07-18 14:03:10|Because ontologies are hard enough for humans.
Dr. Pratik Desai KissanGPT|2023-07-18 14:04:12|Semantic web never took off because building ontologies and reasoning over it was computation expensive
~ Nischal|2023-07-18 14:06:39|We are using this in the supply chain space at the moment. Its ofcourse quite big in chemical and pharma industry, especially with drug discovery.
~ Nischal|2023-07-18 14:09:16|Yeah, I think building one ontology for all is very cumbersome and complicated.   You have to first put together the business questions you need answers to and build an ontology that can support it with the idea that this will evolve over time. If you try to get the entire ontology right at once, it's just very very hard.
Saurabh Karn Nyai|2023-07-18 14:09:18|So… I have not seen it to be effective. The challenge is that ontologies can be suggested but might not be interoperable. Also limitation of knowledge graph is pruning. To make effective one needs to prune some connections. SALI takes a top down approach to building this ontologies for legal.
Aashay Sachdeva MPL Data Scientist|2023-07-18 14:09:30|https://arxiv.org/abs/2305.13168 - review of LLMs for KG construction
Dr. Pratik Desai KissanGPT|2023-07-18 14:10:44|Thanks, I was looking for this one.
Dr. Pratik Desai KissanGPT|2023-07-18 14:19:02|I think we don't need KB as large as LLMs, but precise enough to help decision-making from LLM outputs.  Think of it as fine-tuned model for a legal firm that likes to work a particular way, and we have used high-quality dataset from their practice to tune a model. LLM can still hallucinate, and IMO better option would be creating KB using this dataset, let human evaluate and maintain, and then RAG on KB to fetch appropriate decision making nodes, then add context of the situation on which the decision is to be made.
Dr. Pratik Desai KissanGPT|2023-07-18 14:19:10|I think I'm incoherent here
Saurabh Karn Nyai|2023-07-18 14:20:01|No no this actually makes sense
Dr. Pratik Desai KissanGPT|2023-07-18 14:20:02|I will have to properly put my thoughts together, first😞
Dr. Pratik Desai KissanGPT|2023-07-18 14:21:57|Amit Sheth (ex-Pilani) was my advisor and we have done a lot of work on the Semantic web, he probably still doesn't trust LLMs much but I have moved on from being a Semantic Web loyalist. https://scholar.google.com/citations?user=2T3H4ekAAAAJ&hl=en
Aashay Sachdeva MPL Data Scientist|2023-07-18 14:21:59|This makes sense.  Let’s assume a company’s founder wants to synthesise info around his market better.  Company name -> create ontology-> human selects which one to focus on -> apply RAG on top through serp / alternate datasets -> summarise etc
Nilesh Transcend|2023-07-18 14:22:08|This is about knowledge graph construction, not ontologies.
Nilesh Transcend|2023-07-18 14:22:35|Or I probably misunderstood something.
Nilesh Transcend|2023-07-18 14:28:07|Here is an example of topic modeling with LLMs: http://home.cse.ust.hk/~lzhang/topic/aipanoIntro.pdf  This is produced from a latent tree model: http://home.cse.ust.hk/~lzhang/topic/ai-tree.pdf
Sandeep Srinivasa RedCarpetup|2023-07-18 14:30:51|This is a good paper, but I find this as the opposite direction of what is intresting in LLM.  Not constructing knowledge using LLM...but using knowledge base in LLM. That is still a fairly open topic.
~ Bash|2023-07-18 14:36:09|Anyone knows of any way a wav2lip model (or something similar) to generate streaming inference?
~ Rachitt|2023-07-18 14:46:15|are there any alternatives to hosting OSS LLMs apart from GPT4ALL?
Sudharshan GenAI|2023-07-18 14:56:12|https://twitter.com/BEASTMODE/status/1679599277658591233  Well...interesting trend ‎[7/18/23, 14:56:14] Sudharshan GenAI: ‎image omitted
Kishore GenAI|2023-07-18 14:59:15|https://arxiv.org/abs/2307.07164  Learning to Retrieve In-Context Examples for LLMs. ‎<This message was edited>
Kishore GenAI|2023-07-18 14:59:57|Might be relevant to the discussion yesterday on RAG
ashish Acgt01 Twitter|2023-07-18 16:16:18|https://ikdd.acm.org/kdd2023/
Sugam Docyt|2023-07-18 17:26:55|Thanks! Our domain is accounting. We have tried testing on openAi playground with some prompts explaining the meaning of the classes and using gpt-3.5-turbo. The classifications weren’t as accurate. Wondering if fine tuning + prompt engineering gpt-3.5 will change the accuracy - yet to evaluate  Looking for the economical model here that wouldn’t add up the costs considering we have to fine tune anyway while also desiring a decent pre-trained model as base
Sugam Docyt|2023-07-18 17:28:04|Thanks Nirant! 💯
Saurabh Karn Nyai|2023-07-18 17:30:35|Talking about fast, multi-lingual parameterless text classification? Recently read a paper where researchers use gzip to compress and then use K-means to find similarity to a document class. Very efficient, multilinual. Let me find the paper.
Manjot Pahwa|2023-07-18 17:30:40|Has anyone used the RETRO model in production or tried to deploy in production yet?
Saurabh Karn Nyai|2023-07-18 17:32:12|https://arxiv.org/abs/2212.09410
Saurabh Karn Nyai|2023-07-18 17:32:36|Commentary and code walkthrough:  https://medium.com/@heinrichpeters/commentary-gzip-knn-beats-deep-neural-networks-in-text-classification-f395c71283a6
Saurabh Karn Nyai|2023-07-18 17:34:48|When I first read this it reminded me of Silicon Valley episode where AI is able to modify text over compressed and encrypted data 😅
Sumod K Mohan|2023-07-18 18:38:26|There seems like a bug in their takeaway. Because of the way they solve it, their accuracy is top-2 accuracy and not top-1 accuracy. See here https://news.ycombinator.com/item?id=36758433
Sumod K Mohan|2023-07-18 18:45:50|There is an old adage amongst ML community that someone did years of effort in feature selection + model selection and then compared against KNN on a large dataset, only to be severely disappointed. KNN are asymptotically accurate, don't be surprised if KNN with right distance metric does amazing things on very large datasets. The authors probably took this to heart and we can't blame them.
Shashank B Designer|2023-07-18 18:51:06|Woah you remember that info from SV series 🤯
Saurabh Karn Nyai|2023-07-18 18:51:59|Yeah! Happens after Russ fest.
Nirant|2023-07-18 19:03:20|RETRO doesn't have a canonical implementation. Non-trivial to productionise it, and even for experimentation — a bit bulky with multiple data dependencies for evaluation too.  Here is the paper for reader's reference https://arxiv.org/abs/2112.04426
Paras Chopra Wingify|2023-07-18 19:05:19|Not even sure how RETRO compares to simply doing similarity search and inserting in context into any LLM
Nirant|2023-07-18 19:06:42|"Yup, Unknown upside, high and known investment upfront and ""Good enough"" alternatives abound."
jyotirmayjk Hackathon|2023-07-18 19:17:48|Is anyone facing issues with Code Interpreter lately ?  -Hallucinating data which isn’t present in uploads -Not able to understand simplest instructions unless you explain in some detail -Incorrect code output for python
jyotirmayjk Hackathon|2023-07-18 19:18:31|Getting a bad feeling that OpenAI has nerfed Code Interpreter
ashish Acgt01 Twitter|2023-07-18 19:32:00|It's very prompt dependent.  It would just not do some analysis. Then I had to be very persistent in my prompting across 6-7 prompts for it to be able to do some analysis
jyotirmayjk Hackathon|2023-07-18 19:34:37|Issue is I had higher quality output with similar prompts up until last week  And it never took me more than 1 prompt to get the output  Hallucinating data is something which I’m encountering for the first time For ex.It’s hallucinating information for upto Dec 2023,while the file has information only till June 2023
Abhinav Shop101|2023-07-18 19:59:53|Will ping!
Alok Bishoyi|2023-07-18 20:37:15|Are there some good examples / usecases of using GenAI in the travel industry ?
Shimanta Generative AI|2023-07-18 20:54:04|Trip planning is one straightforward use case which has been making the rounds.
jyotirmayjk Hackathon|2023-07-18 21:06:34|https://twitter.com/alokebajpai/status/1679104716893196288?s=46&t=icC0fizZK8E3ONsDVuGFWA  Recently Ixigo launched their plug-in for ChatGPT for travel and itinerary planning
jyotirmayjk Hackathon|2023-07-18 21:09:43|Microsoft has also partnered with MakeMyTrip for voice based search for travel planning  It utilises mix of OpenAI service and Azure Cognitive Services  It seems like semantic search over reviews,and recommendations based on hybrid search
ashish Acgt01 Twitter|2023-07-18 21:12:03|Some brainstorming that happened on the group a while ago on what a future reasonably smart travel assistant should be able to do
ashish Acgt01 Twitter|2023-07-18 21:12:27|Another one
Nirant|2023-07-18 21:22:45|Cohere entering it's Palantir era was not on my 2023 bingo card https://twitter.com/cohere/status/1681298050768162819
Anshul Bhide Replit|2023-07-18 21:28:51|OpenAI did its service alliance agreement with Bain so why is this surprising? They all need an implementation partner to go after enterprises.
Nirant|2023-07-18 21:29:33|Bain has nicer street cred than McK
Pratyush Choudhury|2023-07-18 21:30:32|The Implementation partner will likely be the next gen IT Services company  Would love to hear why you think it's not a Infy, TCS, Wipro
Anshul Bhide Replit|2023-07-18 21:31:33|"You'll see these soon IMO; but someone needs to do the ""strategy"" work before the implementation guys come in"
Pratyush Choudhury|2023-07-18 21:32:48|Why is it easier for strategy guys to do implementation vs implementation guys to do strategy?  What gives?
Anshul Bhide Replit|2023-07-18 21:33:23|Brand factor?
Nirant|2023-07-18 21:33:31|Strategy is high status, so CXOs go to them ‎[7/18/23, 21:34:45] Anshul Bhide Replit: ‎image omitted
Anshul Bhide Replit|2023-07-18 21:35:00|Def didn’t have this on the bingo card…
~ Srinivasan Nandakumar|2023-07-18 21:35:14|https://twitter.com/_akhaliq/status/1681333345085542404?t=xDZ9rDCfY2gyLmmtiHqDhg&s=08  Looks like llama 2 is here.
Apurv Aurva.io Sahil's Friend|2023-07-18 21:44:56|I think its to create distribution channel and get more dollars
Nirant|2023-07-18 21:44:59|Accept the community license here https://ai.meta.com/resources/models-and-libraries/llama-downloads/
Kaushik S YC W23|2023-07-18 21:50:28|This sounds very similar to the mixture of experts architecture - except with different experts being their own atomic model.   Certainly a fascinating approach - would love to learn more whenever you’re ready to share more details.
Kaushik S YC W23|2023-07-18 21:50:56|Who has run it already? What’s the first impression on it?
~ Vishal|2023-07-18 21:52:57|It's available here https://replicate.com/a16z-infra/llama13b-v2-chat ‎[7/18/23, 21:54:23] Nilesh Transcend: ‎image omitted
~ Srinivasan Nandakumar|2023-07-18 21:57:13|https://twitter.com/DrJimFan/status/1681337179057029121?t=L61MThj0CVsUSd584Azvpg&s=08 ‎[7/18/23, 21:57:28] Nirant: ‎image omitted
Nirant|2023-07-18 21:59:11|More dataaaa >> more parameters
Abhinav Verma Longshot.ai|2023-07-18 22:04:14|What's the context window for Llama
Nirant|2023-07-18 22:04:38|4K
Abhinav Verma Longshot.ai|2023-07-18 22:04:49|Nice. ‎[7/18/23, 22:05:19] Nirant: ‎image omitted
Paras Chopra Wingify|2023-07-18 22:06:17|Their license restricts generating data for training another LLM
Paras Chopra Wingify|2023-07-18 22:06:29|But I’m so happy we have a strong commercial LLM now
Abhinav Verma Longshot.ai|2023-07-18 22:07:30|Of course, no one will ever do a thing 😜. But I guess you can use Llama to finetune a Llama
~ Srinivasan Nandakumar|2023-07-18 22:07:44|Wonder what the loss looks like at 2 trillion tokens. Probably in the paper , have to check it out but will be nuts if it's still decreasing. Llama one was released with the loss still going down.
Abhinav Verma Longshot.ai|2023-07-18 22:08:17|Yudkowsky gonna get a heart attack
Alok Bishoyi|2023-07-18 22:10:32|You should still be able to finetune it on top of evol data and others, like alpaca/vicuna of the past I suppose?
Paras Chopra Wingify|2023-07-18 22:19:01|You can’t generate data from llama to train something else
Abhinav Verma Longshot.ai|2023-07-18 22:28:58|How are the results for Llama for you guys? Am testing using the replicate link
~ Arindam Barman|2023-07-18 22:37:57|https://twitter.com/LangChainAI/status/1681349170433761280?t=YaEPBAly6TV96QdHSoJB9A&s=19  In other news, probably way less exciting langchain launches langsmith
~ Suhas Baliga|2023-07-18 22:43:05|Couldn't find this link. Going to try when home. 😄
Abhinav Verma Longshot.ai|2023-07-18 22:48:19|This is the replicate link for folks who want to try
~ Rahul Bansal|2023-07-18 22:48:32|This looks interesting
Abhinav Verma Longshot.ai|2023-07-18 22:48:47|The results are not bad. Among OSS models, this one shows more promise
ashish Acgt01 Twitter|2023-07-18 22:50:12|https://ai.meta.com/resources/models-and-libraries/llama/   https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ ‎<This message was edited>
Paras Chopra Wingify|2023-07-18 23:03:12|It’s cool to see 70b matching chatgpt performance
Paras Chopra Wingify|2023-07-18 23:03:16|Hope to see costs drop even further!
Nirant|2023-07-18 23:04:57|Made my own mirror — in case someone wants to use it via the API (which is a bit worse than chat demo and Replicate) https://llama2demo.streamlit.app/
Paras Chopra Wingify|2023-07-18 23:07:54|is it 70b? ‎[7/18/23, 23:08:47] ~ Prajna Prayas: ‎image omitted ‎[7/18/23, 23:11:10] Abhishek Mishra: ‎GIF omitted
Nirant|2023-07-18 23:11:27|13b
Nirant|2023-07-18 23:12:13|Sire you'll have to sponsor that when I get the access token ‎[7/18/23, 23:12:26] Neha YC W23: ‎image omitted ‎[7/18/23, 23:13:06] Neha YC W23: ‎image omitted
Rounak Datta Hackathon Winner|2023-07-18 23:15:14|The ggml versions of the models have also dropped: https://huggingface.co/TheBloke/Llama-2-7B-GGML Folks may also want to follow the discussion at https://github.com/ggerganov/llama.cpp/issues/2262
Paras Chopra Wingify|2023-07-18 23:16:31|Haha for sure ‎[7/18/23, 23:17:08] Nirant: ‎image omitted
~ Suhas Baliga|2023-07-18 23:17:30|A bit too verbose for clear cut legal use cases, but worth testing because it gets the other stuff right for us. Verbosity, are others experiencing? ‎[7/18/23, 23:20:46] Neha YC W23: ‎image omitted
Neha YC W23|2023-07-18 23:21:13|i think the model is plain translating back and forth in hindi & english
Neha YC W23|2023-07-18 23:21:38|who is the nirmata here? is the model gaslighting me? ‎[7/18/23, 23:21:56] ~ Prajna Prayas: ‎image omitted
Divya Tak|2023-07-18 23:23:06|This is so funny. It feels like the model is on shrooms. All it can do is hallucinations
Nirant|2023-07-18 23:23:29|This is very high temperature. Can dial it down here llama2.ai 
Ankur Pandey|2023-07-18 23:23:44|1st impressions: Does better on well-known concepts. More hallucinations. Poor reasoner & doesn't follow complex instructions. Of course way faster
Paras Chopra Wingify|2023-07-18 23:23:45|Don’t, high temperature is fun ‎[7/18/23, 23:24:13] Nirant: ‎image omitted
Nirant|2023-07-18 23:24:44|Reasoning is similar, high temp kills reasoning — try a lower temp here: llama2.ai
Nirant|2023-07-18 23:25:16|Same. That is why I left it at 0.9
Ankur Pandey|2023-07-18 23:27:15|Thanks, yeah was playing w temp
ashish Acgt01 Twitter|2023-07-18 23:27:35|One can also try the hosted replicate endpoint  https://replicate.com/a16z-infra/llama13b-v2-chat
Kaushik S YC W23|2023-07-18 23:30:06|Longer training time too ‎[7/18/23, 23:30:26] ashish Acgt01 Twitter: ‎image omitted ‎[7/18/23, 23:30:27] ashish Acgt01 Twitter: ‎image omitted ‎[7/18/23, 23:30:28] ashish Acgt01 Twitter: ‎image omitted ‎[7/18/23, 23:30:29] ashish Acgt01 Twitter: ‎image omitted ‎[7/18/23, 23:30:30] ashish Acgt01 Twitter: ‎image omitted ‎[7/18/23, 23:30:39] ~ Arindam Barman: ‎image omitted
Ankur Pandey|2023-07-18 23:31:19|"""Does liberalism entail libertarianism? Be concise.""  low temp - good ans https://replicate.com/p/w3w66f3bwmsmxl67l52mqzsk6i high temp - crisis https://replicate.com/p/nj63mzdb3fbbzupbtccz3m7axa"
Abhishek Mishra|2023-07-18 23:32:02|Why does Meta love access forms so much?
ashish Acgt01 Twitter|2023-07-18 23:32:50|Wish someone had built like a ChatGPT style UI , where previous context of a conversation remains.  A little surprised why Meta didn't release a ChatGPT like you for Llama - any speculations people ?  They clearly have the infra to support it. So what was it - was performance not as great as ChatGPT ?
Abhishek Mishra|2023-07-18 23:32:54|Why waste bandwidth trying to validate who gets it and who doesn't? It's clearly going to be used directly, indirectly by everybody.
Abhishek Mishra|2023-07-18 23:33:06|Chatbot UI
ashish Acgt01 Twitter|2023-07-18 23:33:19|Link ?
Abhishek Mishra|2023-07-18 23:34:07|I'm sharing a window AI version of chatbot UI - https://chatbot-ui-window-ai-git-windowai-skylight-ai.vercel.app/
Abhishek Mishra|2023-07-18 23:34:54|You can access every api including Claude v2, palm, GPT4 32k, falcon 40B here and chat with it in the shared UI link - https://openrouter.ai/docs
Alok Bishoyi|2023-07-18 23:35:13|Got in within 10 minutes. Must be legal reasons ‎[7/18/23, 23:35:35] ~ Arindam Barman: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-18 23:36:00|I think this is in the training data
~ Arindam Barman|2023-07-18 23:37:14|I wonder if it is meta original training data or a16z's fine tuning.
Abhinav Verma Longshot.ai|2023-07-18 23:37:25|I got a link which does not exist
Ankur Pandey|2023-07-18 23:42:29|This is clearly for Enterprise product who want low creativity high privacy / data security etc
ashish Acgt01 Twitter|2023-07-18 23:44:31|Meh ! https://replicate.com/p/n5u3fprbokjktddrheu6hrrfle
Dhruv Anand|2023-07-18 23:54:16|Why would this work?
Abhinav Verma Longshot.ai|2023-07-18 23:55:01|Didn't get you?
Dhruv Anand|2023-07-18 23:56:30|Like it obviously doesn't have the knowledge about the replicate api (or how to use llama2 on it), so why would we expect it to be able to answer that question?
Abhinav Verma Longshot.ai|2023-07-18 23:57:25|Oh yeah. That link didn't open for me, hence was confused
~ Suhas Baliga|2023-07-18 23:58:06|Heavily temp dependant on format of output (user prompt in openAI), but are lower levels more reliable in this sense will decide it for us.
Abhinav Verma Longshot.ai|2023-07-18 23:58:52|I'm finding it useful for certain rag use cases
ashish Acgt01 Twitter|2023-07-19 00:01:49|"just got the email with access, they are not really gating access . Yay !  ""To get the expected features and performance for them, a specific formatting defined in chat_completion needs to be followed, including the INST and <<SYS>> tags, BOS and EOS tokens, and the whitespaces and breaklines in between (we recommend calling strip() on inputs to avoid double-spaces).  You can also deploy additional classifiers for filtering out inputs and outputs that are deemed unsafe. See the llama-recipes repo for an example of how to add a safety checker to the inputs and outputs of your inference code.""  https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L212 ‎<This message was edited>"
Paras Chopra Wingify|2023-07-19 00:02:55|Answer? ‎[7/19/23, 00:04:12] ~ Suhas Baliga: ‎image omitted ‎[7/19/23, 00:04:33] ~ Suhas Baliga: ‎image omitted ‎[7/19/23, 00:04:42] ~ Suhas Baliga: ‎image omitted
ashish Acgt01 Twitter|2023-07-19 00:16:53|"Sorry, I mistakenly edited my previous message :  Prompt : ""What is the central message of the Gita ? Explain as if I am a high school student and use football team player analogies and sports metaphors.""  I asked it about the Gita with the exact same prompt and same tunable parameters (temperature, top_p, etc) and got 3 very different looking answers .  I think this is a big difference between ChatGPT and Llama2.  ChatGPT is more deterministic - feed the same prompt, the model gives a very similar response.  Llama2 chat gives very varied answers to the same prompt ‎[7/19/23, 00:17:16] ashish Acgt01 Twitter: ‎image omitted"
~ Suhas Baliga|2023-07-19 00:17:47|Looks bad for enterprise apps 😊😄
ashish Acgt01 Twitter|2023-07-19 00:18:30|Don't know if it's an issue with the replicate implementation or something inherent to the model
Abhishek Mishra|2023-07-19 00:20:19|"Llama-v2 is available on Microsoft Azure.  MS is playing ""gotta catch 'em all""."
Abhishek Mishra|2023-07-19 00:21:58|This is a very good 13B model. But a 13B model nonetheless.  To compare it with even GPT 3.5, we need to put 70B in picture as it's the one with the closest MMLU score.
ashish Acgt01 Twitter|2023-07-19 00:22:26|I wonder what OpenAI feels about this :)  Will they also share tech with Google and other players of Msft is non exclusive in its tie ups ?  Interesting times ahead, for sure !
Abhishek Mishra|2023-07-19 00:22:31|But even then, it's bad with coding as HumanEval scores look bad. I guess WizardCoder versions of llama v2 will be interesting.
Neha YC W23|2023-07-19 00:22:50|one noob question - are 13b models good a following basic instructions? what are they good for?
Abhishek Mishra|2023-07-19 00:24:23|"Honest answer - Stock 13B is mostly used with creative or role-playing purposes especially in areas where ChatGPT will start ""As an AI language model"".  If your scope of instruction following is narrow, it's definitely worth fine tuning though."
Neha YC W23|2023-07-19 00:24:58|so role playing + RAG to cater to narrow use cases
Abhishek Mishra|2023-07-19 00:25:15|Best part about 70B model, they can be used for inference as well as 4 bit fine tuning on a single A100.
Abhishek Mishra|2023-07-19 00:26:01|Role playing doesn't really need RAG that much. Question answering applications need RAG.
Neha YC W23|2023-07-19 00:26:46|yes. but i am thinking of corporate use cases. as long as my model adheres to certain roles, i can launch bunch of smaller models tuned to do a certain task, now a swarm of these agents to do multiple tasks
Neha YC W23|2023-07-19 00:27:00|instead of one big model to do many tasks.
Neha YC W23|2023-07-19 00:27:12|is that the goal of these models? ‎[7/19/23, 00:27:26] ashish Acgt01 Twitter: ‎image omitted ‎[7/19/23, 00:27:27] ashish Acgt01 Twitter: ‎image omitted
Abhishek Mishra|2023-07-19 00:28:46|It's possible but I think we don't have good examples with the current fine tuned models. One will have to test for the proof of concepts.
Abhinav Verma Longshot.ai|2023-07-19 00:30:02|Few findings - I found 7b model results pretty good and better than 13b model, will try it again to see if it wasn't an anomaly - It was pretty good at generating product descriptions in a RAG pipeline - Need to see replicate ka charges. The speed was pretty good as well
Neha YC W23|2023-07-19 00:31:30|did you fine tune the models, or used them off she shelf?
Abhishek Mishra|2023-07-19 00:31:47|The replicate has 7B and 13B available as APIs for now. I guess it's the same on the chat and not 70B.  I mainly saw llama2.ai, is there another UI with higher models?
Abhinav Verma Longshot.ai|2023-07-19 00:32:04|no fine-tuning. Used it via replicate api. RAG pipeline, custom prompts for product description
Abhinav Verma Longshot.ai|2023-07-19 00:33:29|HF maybe for 70b model
Abhinav Verma Longshot.ai|2023-07-19 00:34:22|ok update 13b is also good. temperature of 0.75 which is default in replicate is something I tried and it works
Paras Chopra Wingify|2023-07-19 00:34:39|Has anyone compared with chatgpt side by side
Paras Chopra Wingify|2023-07-19 00:35:00|Also wonder what azure hosted llama 70b pricing is? Have they released it
Abhinav Verma Longshot.ai|2023-07-19 00:35:31|I was comparing with API results with gpt-3.5 side by side for our prompts. Quality is decent.
Abhishek Mishra|2023-07-19 00:35:33|Are you just testing for answering based on context or also testing whether it follows citations?
Abhishek Mishra|2023-07-19 00:36:08|As per my understanding 7B, 13B will break when it has multiple rules to follow without fine tuning.
Abhinav Verma Longshot.ai|2023-07-19 00:37:13|This is product description generation, so basically the content is picked from a RAG pipeline . And the prompt is our own prompt. Will test it for cases which need a much higher accuracy . For that we generally use gpt-4 and claude
Abhishek Mishra|2023-07-19 00:38:17|Great. I'll DM you to know the results in detail probably when you're done with your testing.
Abhinav Verma Longshot.ai|2023-07-19 00:38:50|I'll test it tommorow abhi 😅. you can dm your questions
ashish Acgt01 Twitter|2023-07-19 00:40:28|"In my very preliminary testing, generation varies greatly for the same prompt for each ""generation"" for Llama2( the replicate chat api endpoint)  Is this an artifact of the replicate implementation nor something inherent to llama2 remains to be seen  Also, as of now, replicate chat ui is not an apples to apples comparison with ChatGPT imho   For the Gita q :) https://replicate.com/p/xj6jjubbgo526nypc6wk5xv4qy ‎<This message was edited>"
ashish Acgt01 Twitter|2023-07-19 00:42:13|Replicate pricing :  https://replicate.com/pricing
ashish Acgt01 Twitter|2023-07-19 00:51:26|No word on pricing here : https://blogs.microsoft.com/blog/2023/07/18/microsoft-and-meta-expand-their-ai-partnership-with-llama-2-on-azure-and-windows/
Abhishek Mishra|2023-07-19 00:52:52|I was half expecting Meta to launch a productized version of LlamaV2. But I guess they needed to move fast and break some people's things.
Rounak Datta Hackathon Winner|2023-07-19 00:53:19|I wonder this could have been Meta's chance at introducing their cloud to the public? ‎[7/19/23, 00:59:15] Abhishek Mishra: ‎image omitted
~ Suhas Baliga|2023-07-19 00:59:29|Breaking legal drafting so far.
Rounak Datta Hackathon Winner|2023-07-19 01:00:59|It was mentioned somewhere that the red teaming for it isn't complete yet.
Abhishek Mishra|2023-07-19 01:01:21|Yeah rule following is going to be challenging with 7B and 13B. ‎[7/19/23, 01:03:06] Abhishek Mishra: ‎image omitted
ashish Acgt01 Twitter|2023-07-19 01:11:31|Interesting  34b has more violations than 7b and 13b, but 70b is better than 34b ‎<This message was edited> ‎[7/19/23, 01:12:36] Abhishek Mishra: ‎image omitted
ashish Acgt01 Twitter|2023-07-19 01:12:48|Better as in fewer violations
Abhishek Mishra|2023-07-19 01:13:21|"Yes 70B is better overall as well as more ""aligned""."
Sandeep Srinivasa RedCarpetup|2023-07-19 01:13:59|honestly MPT-30B is still looking pretty good against it.  u have to go all the way to 70B to really beat MPT in many cases
Saurabh Karn Nyai|2023-07-19 01:14:21|Github - https://github.com/a16z-infra/llama2-chatbot  Chatbot - https://www.llama2.ai/
Abhishek Mishra|2023-07-19 01:18:29|30B is good range for trying commercial use cases. Let's wait for the 34B llamav2 drop.
ashish Acgt01 Twitter|2023-07-19 01:18:31|Has anyone tried any code generation usecases so far with Llama2 ?  My gut feeling is it's not as good as OpenAI CI
Abhishek Mishra|2023-07-19 01:18:57|Llamav2 34B benchmarks are very good.
Abhishek Mishra|2023-07-19 01:19:53|Yeah, coding is bad as HumanEval score is worse than even WizardCoder.
ashish Acgt01 Twitter|2023-07-19 01:20:03|"There was a lot of emphasis on safety and responsible use in the press release.  If 34b is relatively ""unsafe"", might not happen very soon imho"
Abhishek Mishra|2023-07-19 01:21:40|We also need their 27k SFT dataset. Hope they release it. ‎[7/19/23, 01:27:52] Abhishek Mishra: ‎image omitted
ashish Acgt01 Twitter|2023-07-19 01:29:13|They refer to the Chung paper in the sft section:  Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin, 38  Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.
Abhishek Mishra|2023-07-19 01:31:16|Yeah, they also curate and annotated 27k samples.
ashish Acgt01 Twitter|2023-07-19 01:33:47|"What exactly was the data ?  Wild guess : did they use ""anonymized"" FB and Instagram data ?  ""We also observed that different annotation platforms and vendors can result in markedly different down- stream model performance, highlighting the importance of data checks even when using vendors to source annotations. To validate our data quality, we carefully examined a set of 180 examples, comparing the annota- tions provided by humans with the samples generated by the model through manual scrutiny.  Surprisingly, we found that the outputs sampled from the resulting SFT model were often competitive with SFT data handwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort to preference-based annotation for RLHF."" ‎[7/19/23, 01:35:42] ashish Acgt01 Twitter: ‎image omitted"
Abhishek Mishra|2023-07-19 01:35:57|They mention they have avoided using Meta users data as well as websites that have a lot of public info about individuals.
Abhishek Mishra|2023-07-19 01:38:22|I'll hold off on more spam from the paper. Too many good things to share and a detailed technical paper. I'll compile it all in one go.
ashish Acgt01 Twitter|2023-07-19 01:45:21|Me too :)  Let's all read it fully and then share our impressions :)
Dr. Pratik Desai KissanGPT|2023-07-19 01:50:39|Scale is open-sourcing their library to host and train llms, including llama2  https://twitter.com/alexandr_wang/status/1681370165521334273
Dr. Pratik Desai KissanGPT|2023-07-19 01:52:13|Many folks were looking into building around this concept, thought about sharing it here
ashish Acgt01 Twitter|2023-07-19 01:54:57|In non llama news :  https://llm-efficiency-challenge.github.io/challenge.html
~ Happy Chaudhury|2023-07-19 03:55:04|Looking for this results... currently i am running xgen 7b , which sometimes does not give good results on context..
Kaushik S YC W23|2023-07-19 05:45:13|Interesting twitter space: https://twitter.com/i/spaces/1nAKErrWzBZGL
Abhishek Mishra|2023-07-19 06:01:36|Done with combing the paper. It is a very lucid read and recommended to go through it. For those who may want to instead read an *informal dissection of the paper, here are my thoughts on it*  https://docs.google.com/document/d/13Q5SsIcW9hhbIZozkQSgge4N3XLnAPetjTYoQwMGQNk/edit?usp=sharing ‎<This message was edited>
Prayank Swaroop Accel|2023-07-19 06:49:20|👆Hopefully this is useful for folks, please DM me if you need any help. ‎[7/19/23, 07:52:37] Amir Nagri: ‎image omitted
Amir Nagri|2023-07-19 07:52:51|Credits: 1littlecoder
Anshuman Pandey|2023-07-19 08:00:55|Satya is real deal not just in SF but the entire tech industry. From MSFT era of say no to open source to acquiring GitHub, building Copilot, & now integrating Llama 2.  Any conference I go to, speakers always think highly of him. Nat Friedman at the GenAI conference back in Feb shared a very interesting story on how he convinced Satya on building Copilot & the support he provided
ashish Acgt01 Twitter|2023-07-19 08:50:00|"Very interesting comment from an hn comment:  ""What’s next I’m really excited about Llama 2. I expect we’ll start seeing all kinds of innovation on top of it as the model weights themselves start to roll out.  I’m particularly looking forward to:  - The fine-tuned models. Alpaca, Vicuna et-al did amazing things with fine-tuning on top of the original LLaMA. I expect we’ll see dozens of fine-tuned models over the next few weeks.  - Implementation of the reAct and Toolformer patterns, which will enable Llama 2 to drive external tools in a similar way to OpenAI Functions. The Llama 2 paper mentions testing against Toolformer prompts already, so this hopefully won’t be too difficult. Hopefully this time we’ll start to see a concerted effort from people to document what kind of prompts work well with Llama 2 for practical purposes, since I expect this model will be an influential piece of the ecosystem for some time to come.""  via https://simonwillison.net/2023/Jul/18/accessing-llama-2/  (via https://news.ycombinator.com/item?id=36774627 )"
ashish Acgt01 Twitter|2023-07-19 09:21:28|"I think most of us were trying the chat endpoints using 13b. I just tried 70b using this HF space and it feels ""better"" And prettier :)  https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI  (via https://huggingface.co/blog/llama2 ) ‎<This message was edited>"
ashish Acgt01 Twitter|2023-07-19 09:26:34|"There was some discussion yesterday about GPT performance degrading considerably over the last few weeks/months.  Matei and others, measured it rigorously. Performance drift is a real issue !  ""I’m sure providers will find ways to support the same snapshot for longer, but I think the hard question is how well model developers themselves can detect such changes or prevent loss of some capabilities when tuning for new ones. Meanwhile, monitor, or build custom models.""  https://twitter.com/matei_zaharia/status/1681467961905926144  https://arxiv.org/pdf/2307.09009.pdf  More info at : https://github.com/lchen001/LLMDrift ‎<This message was edited>"
Ambika Computational Mama|2023-07-19 09:28:12|I really enjoy their videos.
~ Vik|2023-07-19 09:32:21|moved my local llm setup to llama 7b it's pretty food reasoning and not to bad with json either
jyotirmayjk Hackathon|2023-07-19 09:39:29|Good to have this rigorously tested,especially on the code generation part.I thought I was hallucinating  “Directly Executable code has dropped from 52.0% to 10% for GPT-4”
Sudharshan GenAI|2023-07-19 09:42:57|https://twitter.com/davefontenot/status/1680736983633768454?s=46  HF0 new batch
~ Nikhil|2023-07-19 09:43:44|What’s your setup exactly?
Nirant|2023-07-19 09:44:16|Are you challenging the Indian VCs in this group to offer this? 🤣
Nirant|2023-07-19 09:46:15|For context, HF0 is offering 2.5% equity at $500K uncapped — better terms than YC
Kaushik S YC W23|2023-07-19 09:48:53|What does the 2.5% fee mean?
Nirant|2023-07-19 09:53:07|Equity against the $500K investment
Aakash Kumar  Matrix Partners|2023-07-19 09:53:50|Equity by default in all from program . 500K is over that on an uncapped note
Anmol Maini|2023-07-19 09:54:24|not exactly true! They take 2.5% equity in the co of founders who go through the program and then invest $500k on an uncapped SAFE separately
Nirant|2023-07-19 09:58:00|Being wrong on the Internet continues to be the fastest to learn. Can you please explain what does separately mean here for most readers who don't know what capped vs uncapped SAFE might mean?
Kaushik S YC W23|2023-07-19 10:00:05|For his statement to be true, the startup needs to raise the next priced round at a valuation of over $10M - which most AI startups today will be able to do.   So overall if the priced round is at 10M, the startup would only dilute 5% + the 2.5% upfront
Kaushik S YC W23|2023-07-19 10:00:39|So in all fairness it’s a great deal
Anmol Maini|2023-07-19 10:02:22|"Will plug YC's explainer because the instrument originates from them! the $500k has a MFN provision which means: ""The MFN safe will take on the terms of the lowest cap safe (or other most favorable terms) issued between the start of the batch and the company’s next equity round.""  In HF0's case I'm not entirely sure of when the start date is but presumably is it when a founder is accepted into HF0 / accepts their offer  source: https://www.ycombinator.com/deal"
Nirant|2023-07-19 10:02:28|Helpful explainer, thanks!
Anubhav mishra Zupay|2023-07-19 10:02:57|https://hu.ma.ne/media/humane-names-first-device-humane-ai-pin
Anubhav mishra Zupay|2023-07-19 10:04:05|Ex apple guys
Sandeep Srinivasa RedCarpetup|2023-07-19 10:04:28|"Actually I'm not sure if [PHONE] means that the 500k funding happens only when you raise round from others...while 2.5% is asked for immediately. Cos that's the only way a ""fee"" makes sense"
Bharat Kumar Ramesh Hashmal Web3|2023-07-19 10:06:16|Shouldn't be the case. And they should really explain this better.  But here's how it compares to yc
Bharat Kumar Ramesh Hashmal Web3|2023-07-19 10:08:21|1. Yc offers 150k at 7pc, hfo is 2.5%  2. Yc 350k is an uncapped safe with a mfn clause, that is, the best terms given to anyone you raise from after yc starts  Hfo offers 500k uncapped, I.e. It'll convert to equity at whatever terms of the next priced round
Bharat Kumar Ramesh Hashmal Web3|2023-07-19 10:09:10|Money will come in now. If not, it's the sweetest, most predatory option cheque any VC can write.
Sudharshan GenAI|2023-07-19 10:15:56|Yes please 😂
Sandeep Srinivasa RedCarpetup|2023-07-19 10:26:55|I think that's what the previous message was about - cos it was structured as a fee+equity.  Usually I have seen that happen when fee taken upfront and funding later.
Ved Chitnis|2023-07-19 10:33:53|I love how every new model adds on to a good 20-30 minutes of reading just through this group. And in that time nirant already has a demo out....
Ved Chitnis|2023-07-19 10:37:05|Love this, I'm not sure if you're already doing it for other papers but this would be awesome
Vamshi|2023-07-19 10:48:24|Curious what the trade-offs are for raising in India vs the US, for new companies.  My crude understanding is that the more experimental your product, the less sense it makes to raise in India.  Any thoughts here ?
Vamshi|2023-07-19 10:49:14|New = still can choose where to incorporate
Kaushik S YC W23|2023-07-19 10:51:53|Agree. The wording around ‘fee’ is really confusing for sure.
Nirant|2023-07-19 10:52:29|I've too much to say on this, let's talk on the Startup Ecosystem group admin'd by [PHONE]
Anmol Maini|2023-07-19 10:53:18|Money is wired when you're accepted. Terms that the SAFE converts at only gets decided when you raise from others, and the 2.5% is asked for immediately is what my read was
‪+91 90013 70974‬|2023-07-19 11:12:44|‎‪+91 90013 70974‬ joined using your invite
Diptanu Choudhury FB AI|2023-07-19 11:15:17|I thought this was the point of people submitting their eval datasets to openai. Hard to track drift without knowing what a model is being used on. At least in the current state of the tech.
Diptanu Choudhury FB AI|2023-07-19 11:18:57|This was the key in being able to make it open.
Diptanu Choudhury FB AI|2023-07-19 11:21:49|The meta training cluster has years of optimization on the network and storage. I don’t think these numbers would translate if someone else tried to do pretraining in their infra. The GPUs would probably be underused without all the optimizations we did a couple of years back.
Nirant|2023-07-19 11:27:14|Context: Diptanu works with Facebook AI
Diptanu Choudhury FB AI|2023-07-19 11:31:49|I used to, until very recently :) I worked on speech recognition models and back in the day led FBLearner(the machine learning platform) so I have some knowledge about the training cluster.
Gokul Krishnan|2023-07-19 12:05:46|[PHONE] could you tell us what kinds of tools you used to benchmark and optimize GPU utilization? Any guiding principles?
Nirant|2023-07-19 12:46:59|Have hosted Llama 7B, 13B and 70B, all Chat versions — with 3 Most recent Message History!  https://llama2demo.streamlit.app/  cc [PHONE] thought you might be interested in this
ashish Acgt01 Twitter|2023-07-19 12:47:43|Using replicate API endpoint , right ?
~ Abhinav Dadhich|2023-07-19 12:49:47|Thanks for hosting Nirant, a noob question. Are you using llama.cpp for running the model or something else?
Nirant|2023-07-19 12:50:23|Yes, Replicate A100s with some prompt engineering
Abhinav Verma Longshot.ai|2023-07-19 12:50:26|Anyone getting 502 errors a lot in the replicate endpoints
Nirant|2023-07-19 12:50:46|Running with torch, llama.cpp still has some web deployment challenges
Apurv Aurva.io Sahil's Friend|2023-07-19 12:52:03|Most relevant article that I found. At the end of the day, everything is ML : https://www.sequoiacap.com/article/ai-paradox-perspective/
Diptanu Choudhury FB AI|2023-07-19 12:57:02|At a high level standard tools from nvidia. Have you looked at NVML? Most of the high level tools are built on top of it. We had a bunch of tools on top of nvml. There were various visualizations to understand bottlenecks in moving data over the pcie bus, or between nvlinks, memory usage, sequence of copies between devices, gpu utilizations, and various other techniques.
Diptanu Choudhury FB AI|2023-07-19 12:58:36|Take a look at nsight as well.
~ Rahul Bansal|2023-07-19 13:03:45|Interesting read
ashish Acgt01 Twitter|2023-07-19 13:05:33|Thanks. TIL nvidia-smi internally uses nvml ‎[7/19/23, 13:08:23] Karthik GenerativeAI WhatsApp Group: ‎image omitted
~ Vik|2023-07-19 13:11:17|i use text-generation-webui on an m1 pro 32gb run a lot of experiments with various models using the local api endpoint
Abhishek Mishra|2023-07-19 13:31:46|For running on Mac, we also have CoreML support for Llama v2. The speed is not great (6.5 Tokens/s) but the model isn't dumbed down due to quantization. Instead, coreml allows you to run the model with its regular 7B capabilities using the Apple Metal.
Vivek Sahil Sorathiya's Friend|2023-07-19 13:31:46|Hi - Can anyone suggest any readings/doc/best practice/code on role-based access control (RBAC) for customized LLM bots?
Nirant|2023-07-19 13:33:16|cc [PHONE] runs a data security co
Vivek Sahil Sorathiya's Friend|2023-07-19 13:35:41|Thanks [PHONE]!   Hi [PHONE] - will connect with you
Anubhav mishra Zupay|2023-07-19 13:36:50|https://www.umt.edu/news/2023/07/070523test.php
Abhishek Mishra|2023-07-19 13:44:25|These are the cases where you want to peruse the test/benchmark and their assumptions.
Abhishek Mishra|2023-07-19 13:45:10|Top 1% of humanity's creative thinking shouldn't be breached so easily. ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-07-19 13:47:43|Claude was doing something similar. Everything was created by anthropic.
Abhinav Verma Longshot.ai|2023-07-19 13:54:21|I asked Claude if it took money from Sam Bankman fried. It said it doesn't have the ability to take money from anyone. But the topic of the chat got set to Money laundering allegations.😂  Very interesting
Abhishek Mishra|2023-07-19 14:18:33|"Start with ""You've the right to remain silent, you've the right to an attorney. Anything you say can and will be held against you in the court of law""."
Paras Chopra Wingify|2023-07-19 14:21:51|This is awesome! How much does it cost to keep up? Can pitch in
Paras Chopra Wingify|2023-07-19 14:22:58|I just want a chat model that doesn’t say “As an AI model, …”
Dhruv Anand|2023-07-19 14:23:09|Be careful what you offer 😀
Paras Chopra Wingify|2023-07-19 14:23:41|Nah, I think having something like this will be useful
Abhinav Verma Longshot.ai|2023-07-19 14:23:41|Prompt it to reply otherwise 😉
Paras Chopra Wingify|2023-07-19 14:24:09|Yeah on Reddit people wirh chat model are able to generate NSFW conversations so I’m sure this can be bypassed ‎[7/19/23, 14:33:39] Nirant: ‎GIF omitted
Nirant|2023-07-19 14:34:22|Jokes aside, ~$54 in last ~6 hours
Sandeep Srinivasa RedCarpetup|2023-07-19 14:39:09|UPI link to crowdfund ?
Paras Chopra Wingify|2023-07-19 14:39:16|Open source code interpreter  https://github.com/shroominic/codeinterpreter-api
Paras Chopra Wingify|2023-07-19 14:40:35|I like nat.dev model - let people login with credits they purchase but will require more hacking
Paras Chopra Wingify|2023-07-19 14:41:16|Why is it almost $10/hr - multiple gpus?
Nirant|2023-07-19 14:41:17|[PHONE] will open up a community fund, where folks can patronise projects like these. That also gives us leg room on taking some moonshots
Nirant|2023-07-19 14:41:36|Don't want to take any non-trivial sums of money directly to my account for tax reasons 🙈
Paras Chopra Wingify|2023-07-19 14:41:42|yeah please do, I think this is an awersome idea
Nirant|2023-07-19 14:42:23|A100, 40G, and 80G.  I'm paying by the minute — the usage is insane. About 500 uniques and folks doing 7-10 turn conversations.
Nirant|2023-07-19 14:42:40|There are about ~15 people live right now
Paras Chopra Wingify|2023-07-19 14:44:22|how many can it host simulateously
Paras Chopra Wingify|2023-07-19 14:44:34|Wonder how chat gpt3.5 is so cheap
Paras Chopra Wingify|2023-07-19 14:44:38|In comparison
Paras Chopra Wingify|2023-07-19 14:44:49|Someone said online they’re operating at a loss but I don’t believe it
Nitin Mahajan McKinsey|2023-07-19 14:45:33|I thought Nirant will do a series A with this 😂 ‎[7/19/23, 14:52:02] Ved Chitnis: ‎image omitted
Nirant|2023-07-19 14:52:08|I'm using the Replicate API/host with some changes, because I wasn't sure of enough utilisation.  But zooming out, A100 40G is not even available on AWS in any region. When it is, it is about $10-$30/hour on AWS with a monthly commitment.
Dev Aggarwal|2023-07-19 14:52:09|On a streamlit app? How tf ‎[7/19/23, 14:52:19] Ved Chitnis: 2307.09009.pdf • ‎8 pages ‎document omitted
Ved Chitnis|2023-07-19 14:52:25|Paper for reference
Abhishek Mishra|2023-07-19 14:53:45|Inference via api hosted on mentioned GPUs. I think replicate.
Dev Aggarwal|2023-07-19 14:54:18|No a streamlit app will just choke if you have too many concurrent users, like the ui will just never load
Dev Aggarwal|2023-07-19 14:54:32|maybe the streamlit cloud has autoscaling
Nirant|2023-07-19 14:54:34|I'd like to think I can raise on revenue, even if it's tiny, don't want to raise on demos 🙏
Sandeep Srinivasa RedCarpetup|2023-07-19 14:55:08|How is together.ai doing a100 at 0.2$ ? ‎[7/19/23, 14:55:11] Abhishek Mishra: ‎image omitted ‎[7/19/23, 14:58:27] Nirant: ‎image omitted
Nirant|2023-07-19 14:59:27|They probably bought/leased A100 over something like Heztner/NVIDIA Cloud with VC money and are discounting some of the token pricing
Nirant|2023-07-19 15:00:38|That issue still exists. Just limit is higher around 20-30 users. And I wrote the code using ```session_state``` — that reduces memory footprint, and seem to help. ‎[7/19/23, 15:01:42] Sandeep Srinivasa RedCarpetup: ‎image omitted
Sandeep Srinivasa RedCarpetup|2023-07-19 15:01:45|[PHONE] redpajama on a100 is 0.11 per hour
Sandeep Srinivasa RedCarpetup|2023-07-19 15:01:52|How ? ‎[7/19/23, 15:02:07] Nirant: ‎image omitted
Nirant|2023-07-19 15:03:33|That's through shared GPU RAM via parallel loading of 1-2 copies of the same/different model on same GPU RAM. Improves RAM util drastically.  Modal Labs, Banana also do this if I remember correctly, but I might be wrong .
Nirant|2023-07-19 15:04:11|That's why it's 80G, should be 3-4 copies of a 7B model or so without quantisation
Nirant|2023-07-19 15:04:32|Lest my language mislead, I'm also guesstimating here ‎[7/19/23, 15:09:40] Nirant: ‎image omitted
Abhishek Mishra|2023-07-19 15:12:40|Not sure if these guys are using the same but vLLM does the same by using paged attention for batch processing multiple users across a bunch of GPUs ‎[7/19/23, 15:43:49] Nirant: ‎image omitted
Paras Chopra Wingify|2023-07-19 15:45:09|How do we sponsor though? :)
Nirant|2023-07-19 15:50:25|will share hasgeek link stuff over next week, not right now
~ Kushaagra Goyal|2023-07-19 15:51:45|‎~ Kushaagra Goyal joined using this group's invite link
~ Suvrat|2023-07-19 15:52:09|‎~ Suvrat joined using this group's invite link
Dev Aggarwal|2023-07-19 15:52:47|Sorry If I missed the github link, share again?
Nirant|2023-07-19 15:53:28|https://github.com/nirantk/llama2demo/blob/main/app.py
~ Tirtha|2023-07-19 16:38:37|https://twitter.com/dwaynecodes/status/1681516290224300033?s=48&t=znJuLB47JquSWFAB2H-7yg
~ Tirtha|2023-07-19 16:38:39|Has anyone here noticed any significant drop in quality in GPT4?
~ Likhith|2023-07-19 16:42:53|‎~ Likhith left
Piyush Makhija|2023-07-19 16:45:10|[PHONE] had posted this a few days back...  Haven't seen any official response to this from OpenAI yet....
Abhinav Verma Longshot.ai|2023-07-19 16:46:00|Wait someone did a paper on this. They did find issues
Abhishek Mishra|2023-07-19 16:47:36|Yeah, makes mistakes more often. Doesn't follow instructions properly every now and then.
Abhishek Mishra|2023-07-19 16:48:10|This one - https://huggingface.co/papers/2307.09009
Abhinav Verma Longshot.ai|2023-07-19 16:49:35|Yes, I think this was the one. My experience has been for detailed prompts it's better. But system instruction is rendered meaningless. Rather put everything as user instruction
Amir Nagri|2023-07-19 16:51:30|Replicate is serverless, right? only charged when you send a request
Amir Nagri|2023-07-19 16:52:35|The LLM api abuse is very common, so do have some rate limiting/cap
Nirant|2023-07-19 16:52:50|Yes. But charges by compute used, not tokens
~ Tirtha|2023-07-19 16:53:10|Yes thank you sir I just read that
Amir Nagri|2023-07-19 16:55:13|wish there was some easy way to use the laptop's ideal GPUs with a private SETI like network
Nirant|2023-07-19 16:56:08|I assume good faith. Will adapt when proven wrong, not till then :)
Dhruv Anand|2023-07-19 16:57:14|please don't assume good faith while exposing a public free service lol
Nirant|2023-07-19 17:00:10|I've log streaming open in a tab 🫣
Nirant|2023-07-19 17:09:16|NimbleBox folks have hosted the LLaMA 2 13B onto chat.nbox.ai  cc [PHONE] [PHONE]
~ Anupreet Singh|2023-07-19 17:43:27|‎~ Anupreet Singh was added
~ Chan|2023-07-19 17:21:38|https://chat.nbox.ai/
Paras Chopra Wingify|2023-07-19 17:34:22|Surprisingly good
Paras Chopra Wingify|2023-07-19 17:35:01|The 13b model
~ rohan~|2023-07-19 17:35:55|The 70B model should by up by tomorrow! AWS has no more dedicated a10g machines left to use 🥲
Nirant|2023-07-19 17:37:17|This is fp16 or int8?
~ rohan~|2023-07-19 17:38:40|fp16
Neetish Tiwari|2023-07-19 17:39:53|‎Neetish Tiwari requested to join
Sachin Legaltech|2023-07-19 17:40:30|Can you also add emojis to collect feedback data ? Would be valuable if you decide to do RLHF later
~ rohan~|2023-07-19 17:41:20|Sure! I will pass along the feedback to the team 😁
Neetish Tiwari|2023-07-19 17:43:33|‎Neetish Tiwari joined using this group's invite link
Paras Chopra Wingify|2023-07-19 17:43:58|This is same as chatgpt api
Abhishek Mishra|2023-07-19 18:03:52|Yeah, cost is comparable. The openrouter api allows me to switch between the models without losing the conversation context. I often work on critical things with GPT4 and then switch down to Claude v2. Even now, I'm using llama 13B to chat and if it's response isn't good enough I'm moving to other models for tasks. I talk to all these models on chatbot UI with exact same interface as chatGPT, can save prompts, conversations and organise them in folders as well.
Aditya Sista 2010B5|2023-07-19 18:05:59|Openai functions aren't generating valid jsons anymore 🙈
Gokul Krishnan|2023-07-19 18:34:27|Looks like chatGPT was indeed nerfed since March https://twitter.com/matei_zaharia/status/1681467961905926144
Anubhav mishra Zupay|2023-07-19 18:37:05|How's 3.5 improving and 4 drastically reducing?
~ Diwank|2023-07-19 18:37:25|Alignment and quantisation
Sandeep Srinivasa RedCarpetup|2023-07-19 18:37:34|MoE. Kill one of the experts.
~ Diwank|2023-07-19 18:37:54|Bigger models are harder to predict how quantisation will affect performance
~ Diwank|2023-07-19 18:38:34|Plus they might have changed the post processing and reranking
~ Diwank|2023-07-19 18:38:47|Experts are overrated 🤣
Gokul Krishnan|2023-07-19 18:40:02|Reminds of that old anecdote that everytime someone fired an linguist, their NLP system perf went up
Aashay Sachdeva MPL Data Scientist|2023-07-19 18:41:09|https://www.interconnects.ai/p/llama-2-from-meta  Llama2 deep dive
Shashwat TDC|2023-07-19 18:56:27|Curious on test set? What made it surprising :)
Shimanta Generative AI|2023-07-19 19:08:58|https://llama.perplexity.ai/  Blazing fast inference by Perplexity
Adithya S K PESIT|2023-07-19 19:14:17|How is it so fast
Abhishek Mishra|2023-07-19 19:14:31|API distillation from the bigger model is helping out learn better most likely.
Nirant|2023-07-19 19:15:04|Quantisation?
Aditya Sista 2010B5|2023-07-19 19:16:10|What's the consensus on current best model for writing code? Is gpt 4 still on top?
Shimanta Generative AI|2023-07-19 19:16:35|The founder didn’t mention any specifics in his announcement tweet, just that it’s using their own inference infra  https://twitter.com/aravsrinivas/status/1681490002642083841?s=46&t=WT1iAtjftW-5_e62F8FZTg
Nirant|2023-07-19 19:17:35|Yes, but StarCoder cousins like WizardCoder are quite good and better than Llama etc
Abhishek Mishra|2023-07-19 19:27:30|"As per the semianalysis ""leak"", it is not quantisation. They are using GPT3.5 like model to predict the response to a number of tokens and letting GPT4 to accept or reject it. If it accepts it, the inference gets very fast in some portions and when GPT4 rejects the prediction to next k tokens, it generates it based on whatever MoE system it has."
Abhishek Mishra|2023-07-19 19:28:02|Take it with a bucket of salt though, nothing is verified.
Abhishek Mishra|2023-07-19 19:29:39|Model with open dataset and verified results - codegen 2 16B. Model that is on top of open source Humaneval but can't guarantee because no arch change or dataset released - WizardCoder ‎[7/19/23, 19:56:24] Anubhav mishra Zupay: ‎image omitted
Sudharshan GenAI|2023-07-19 19:57:04|Twitter?
Anubhav mishra Zupay|2023-07-19 19:57:09|LinkedIn
~ Pranay Desai|2023-07-19 19:57:30|https://www.linkedin.com/posts/desaipranay_are-you-seeing-this-feature-on-linkedin-activity-7086917502189932546-OHq3?utm_source=share&utm_medium=member_desktop was my last post
Anubhav mishra Zupay|2023-07-19 19:58:19|True
Saurav Tomar GenerativeAI WA Group|2023-07-19 20:29:49|Does anyone know of a platform that allows to invoke babyAGI or autoGPT kind of agents over API ?
Nirant|2023-07-19 20:34:52|Platform? Or sandbox?
Saurav Tomar GenerativeAI WA Group|2023-07-19 20:35:30|platform, like a vercel for Agents. ‎[7/19/23, 20:39:13] Vaibhav Pilani: ‎image omitted
Vaibhav Pilani|2023-07-19 20:39:14|https://www.linkedin.com/posts/younes-belkada-b1a903145_fine-tune-llama-2-with-few-lines-of-code-activity-7087412907029737472-_5-u?utm_source=share&utm_medium=member_android
Satyajit Roy|2023-07-19 20:41:41|Flowise maybe? Its a visual ui for langchain and has a autogpt template...
Nirant|2023-07-19 20:43:04|That's Replit
Anshul Bhide Replit|2023-07-19 20:57:28|https://replit.com/@YoheiNakajima/BabyElfAGI?v=1
Anshul Bhide Replit|2023-07-19 20:59:53|Here are other AI templates:  https://replit.com/templates/ai
Paras Chopra Wingify|2023-07-19 21:27:58|That’s not allowed as per license
Paras Chopra Wingify|2023-07-19 21:28:27|I love how entire code is in a screenshot :)
Paras Chopra Wingify|2023-07-19 21:28:48|How are you imagining it? Won’t a simple VM do
Ketan Twitter Intro|2023-07-19 21:35:25|Is there an online meeting product specially for group meetings which breaks meetings in smaller ones and you join only when you need to join?   In mostly recurring updates meeting of 1 hours - I am speaking for 2 mins,  hearing for 3 and rest is just noise and not relevant
~ Prashanth Harshangi|2023-07-19 21:35:39|Are the llama models safetensors?
Abhinav Verma Longshot.ai|2023-07-19 21:36:11|Yes. I think they mentioned this somewhere
~ Prashanth Harshangi|2023-07-19 21:36:27|Check filo. Might serve your constraints.
~ Prashanth Harshangi|2023-07-19 21:36:57|Thanks. Somewhat skeptical of downloading model files as is.
Abhishek Mishra|2023-07-19 21:37:16|Yes but I was replying to why GPT3.5 getting progressively better. Guessing it may be using API distillation from GPT4.
Abhishek Mishra|2023-07-19 21:37:47|yes, downloaded and tested. Safetensors format.
Gokul Krishnan|2023-07-19 22:37:05|This was cool. E2E episode Generation https://twitter.com/fablesimulation/status/1681352904152850437
jyotirmayjk Hackathon|2023-07-19 23:11:37|https://www.bloomberg.com/news/articles/2023-07-19/apple-preps-ajax-generative-ai-apple-gpt-to-rival-openai-and-google  This would be very interesting! Should we expect LLM on edge,each user with their own LLM in Apple devices given that Apple architecture is quite well suited for this
ashish Acgt01 Twitter|2023-07-19 23:22:27|Something's cooking up in Cupertino for sure !  Only q remains that Apple is a bit of a laggard in the LLM space for now . So they should try to launch sooner rather than later  But they can bake into the os on all their devices & a huge install base of loyal users
jyotirmayjk Hackathon|2023-07-19 23:25:10|Even few simple use cases added on Siri will be quite something  Then they can have real time continuous data stream for further instruction tuning
Anubhav mishra Zupay|2023-07-19 23:25:20|Anyone got update for their voice cloning feature ?
Anubhav mishra Zupay|2023-07-19 23:25:54|iOS I mean ‎[7/19/23, 23:31:47] ~ Pradeep Ayyagari: ‎image omitted ‎[7/19/23, 23:31:49] ~ Pradeep Ayyagari: ‎image omitted
Anubhav mishra Zupay|2023-07-19 23:32:50|Is it actually good ? Like you've tried it ? ‎[7/19/23, 23:35:54] ~ Pradeep Ayyagari: ‎image omitted
~ Pranay Desai|2023-07-19 23:36:45|Microsoft also announced their voice cloner to GA today. But have to jump through hoops to get it approved
Anubhav mishra Zupay|2023-07-19 23:36:57|On device models will have its own efforts required 😅 ‎<This message was edited>
~ Pranay Desai|2023-07-19 23:38:00|Marcus Brownlee had it in his ios 17 review - was ok not great  https://www.youtube.com/watch?v=5LWDl5qaQbA
Anubhav mishra Zupay|2023-07-19 23:39:04|So crazy man, it's like you'll talk to yourself one day 😂
Gokul Krishnan|2023-07-19 23:43:38|LTT's Mac Address also had a review and it was decent
Abhishek Mishra|2023-07-20 00:06:21|This was 🔥 I actually got glued to my screen. The episodes are lit.
Gokul Krishnan|2023-07-20 01:26:12|Interesting timing, considering the ongoing writers and actors strike and their demand for not using AI in initial draft gen ‎[7/20/23, 04:32:57] Anshuman Pandey: ‎image omitted
Anshuman Pandey|2023-07-20 04:33:16|"was playin around with 70b thanks to Streamlit app hosted by [PHONE]!  P.S. legends say it is still printing ""kabhi"""
Chaitanya A GenAI|2023-07-20 05:10:31|https://twitter.com/nonmayorpete/status/1681384734910484480?s=46&t=sa4ojT6cWjpBEV6860rrWw ‎[7/20/23, 06:02:57] Prayank Swaroop Accel: ‎image omitted
Anshuman Pandey|2023-07-20 06:18:33|interesting! will try this
Rajesh RS Generative AI WhatsApp Group|2023-07-20 08:00:53|Pretty great. Cast dialog of new characters seemed a little flat sometimes but still great ‎[7/20/23, 08:16:18] Abhishek Mishra: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-07-20 08:19:29|It must have Hinglish in Latin script and not Hindi in Devnagri
Edgar Monis Mumbai WHO|2023-07-20 08:44:42|AI generated South park ep.  https://fablestudio.github.io/showrunner-agents/?mc_cid=f9d1eb56dc  Fairly bad
~ Baskaran|2023-07-20 09:38:18|‎~ Baskaran was added
~ Amar Kanagaraj|2023-07-20 09:38:18|‎~ Amar Kanagaraj was added
Kaushik Bokka|2023-07-20 09:51:09|And it’s the worst it’s going to be :)  Ship fast, get feedback.
Kaushik Bokka|2023-07-20 09:52:16|It will keep on getting better from this point.
Abhishek Mishra|2023-07-20 10:57:07|https://twitter.com/OpenAI/status/1681810240898215936?t=O2OzxlQRRlfoOJl0d8B37g&s=08  ChatGPT doubles number of messages for GPT4 in 3 hours. ‎[7/20/23, 10:58:48] Abhishek Mishra: ‎image omitted
~ Srinivasan Nandakumar|2023-07-20 11:01:16|Maybe they got their hands on more GPUs which enables them to increase the number of requests.
Abhishek Mishra|2023-07-20 11:07:43|GPT4 has also gotten significantly faster in it's responses. The costs for running it must have come down some way - more compute or some other optimisation.
Abhinav Verma Longshot.ai|2023-07-20 11:19:06|the new gpt4 model was faster. And I think Llama -2 has made gpt4 more faster. If you know what I mean
Abhinav Verma Longshot.ai|2023-07-20 11:21:33|Real power of Llama-2 is how it increased the rate limit of chatgpt plus gpt4 users
Abhinav Verma Longshot.ai|2023-07-20 11:21:43|some agi stuff I think
Paras Chopra Wingify|2023-07-20 11:26:32|I love how even amongst open source there is completion   All redpajayams etc got a bit obsolete perhaps
Abhinav Verma Longshot.ai|2023-07-20 11:27:23|Let's see. Thing with opensource is, you will see more models pop up now.
ashish Acgt01 Twitter|2023-07-20 11:36:04|My fav links from the last couple of days :  1. https://www.supervised.news/p/the-open-source-learning-curve-for  2. https://www.oreilly.com/radar/teaching-programming-in-the-age-of-chatgpt/  3. https://www.refuel.ai/blog-posts/llm-labeling-technical-report  4. https://www.refuel.ai/blog-posts/gpt-3-5-turbo-model-comparison
ashish Acgt01 Twitter|2023-07-20 12:28:12|The first fine-tuned model based off Llama2 called Puffin  https://huggingface.co/NousResearch/Redmond-Puffin-13B https://twitter.com/Teknium1/status/1681556127656579075?s=20  - Ability to recall information upto 2023 without internet (ChatGPT cut off date is in 2021)  - Pretrained on 2 trillion tokens of text. (This is double the amount of most Open LLM's) - Pretrained with a context length of 4096 tokens, and fine-tuned on a significant amount of multi-turn conversations reaching that full token limit.
ashish Acgt01 Twitter|2023-07-20 12:29:29|*competition ?
Paras Chopra Wingify|2023-07-20 12:31:29|Yeah :)
Prayank Swaroop Accel|2023-07-20 12:32:49|Ashish I don't think Redmond Puffin is trained on 2T tokens .. it's fintuned on some 3000 conversations
Prayank Swaroop Accel|2023-07-20 12:34:04|And since they are tuned on GPT4 conversation data - you can't use them commercially ‎[7/20/23, 12:34:12] ashish Acgt01 Twitter: ‎image omitted
Prayank Swaroop Accel|2023-07-20 12:35:49|Someone else can weigh in here. But the tweet you have put and this HF model card doesn't tally for me.
Dr. Pratik Desai KissanGPT|2023-07-20 12:36:19|It is just a Puffin version of Llama2
Dr. Pratik Desai KissanGPT|2023-07-20 12:36:28|Hermes will have a larger dataset
Dr. Pratik Desai KissanGPT|2023-07-20 12:37:09|Follow @Teknium1 on Twitter for the updates
Madhur Chadha|2023-07-20 12:37:17|😟
ashish Acgt01 Twitter|2023-07-20 12:38:58|it is linked in my original post ! :)
Dr. Pratik Desai KissanGPT|2023-07-20 12:40:33|In the second follow-up tweet he mentioned that it is fine-tuned on llama2, so 2T token and 4K length numbers are coming from there
Swastik Banerjee|2023-07-20 12:40:34|Hi, yes, sorry just taking a look at this
Swastik Banerjee|2023-07-20 12:40:56|Has this been already resolved [PHONE] ?
Swastik Banerjee|2023-07-20 12:41:18|Happy to help if not :-)
Swastik Banerjee|2023-07-20 12:41:47|As far as the Auth for plugin goes, you just have to have a BEARER TOKEN
Swastik Banerjee|2023-07-20 12:42:59|You can use this site to generate one: https://jwt.io/
Anmol Sonthalia GenerativeAI WhatsApp Group|2023-07-20 16:14:25|‎You added Anmol Sonthalia GenerativeAI WhatsApp Group
Abhishek Mishra|2023-07-20 14:07:18|"I'll simplify it as there is a lot of ""marketing"" there which is just misleading amongst other things.   Llama2 fine tuned on 3k GPT4 conversations. There, fixed it."
Abhishek Mishra|2023-07-20 14:10:55|"Things of actual value to look forward to:  * WizardCoder version of Llama2, wizardLM team already started on it. Might be dropping it soon. * Llama2 fine tuned on dataset with all the guard rails like ""As an AI language model"" removed. Though we can easily remove those guard rails with prompting now. * Llama2 fine-tuned using SFT or reward modelling with multiple epochs to showcase task-specific best model as the models are still hungry for good data."
Rajesh RS Generative AI WhatsApp Group|2023-07-20 14:19:49|Back to a simpler question from my end. Any ready reckoners for chunk sizes for a knowledge base bot? If we know the embedding model, is there a direct or parametric relationship?
Paras Chopra Wingify|2023-07-20 14:24:04|What’s special about wizard cider
Paras Chopra Wingify|2023-07-20 14:24:05|Coder*
Abhishek Mishra|2023-07-20 14:33:35|They have the best HumanEval (code eval) score for OSS models and theirs was a fine tuned llama v1. Llama v2 is better and especially lacking in coding areas so looking forward to WizardCoder enhancement. Though llama v2 + starcoder data fine tuning is also something of interest. ‎<This message was edited>
Paras Chopra Wingify|2023-07-20 14:45:35|HumanEval is coding benchmark
~ Mohit|2023-07-20 15:04:35|Hi, can anyone suggest good libraries to use LLMs on dataframes? Basically, want to ask questions on tabular data and generate text responses/visualizations/dataframes. Thanks in advance!
Abhiram Ramesh|2023-07-20 15:05:52|I used the ootb openai apis with the 3.5-gpt model on a dataframe 👉 dict.  Worked great
Abhinav Verma Longshot.ai|2023-07-20 15:05:54|You can look Yolo pandas. It's open source, uses langchain. It's a good starter. You can also customize your own looking at it
~ Mohit|2023-07-20 15:06:42|would this work on larger dataframes, say > 1000 rows?
Abhiram Ramesh|2023-07-20 15:07:04|Absolutely.
Abhiram Ramesh|2023-07-20 15:07:18|My dataset had 210000+ records
Abhiram Ramesh|2023-07-20 15:07:59|I will try this out myself as well
~ Vik|2023-07-20 15:09:22|that way the llm can figure out how to call your api or apis
~ Vik|2023-07-20 15:15:27|for that number you can just use a csv file and a function to search it. if your ok with js/typescript checkout dosco/llm-client it supports function calling and reasoning
~ Mohit|2023-07-20 15:15:40|sorry, if this is naive, but can you elaborate on this part - dataframe 👉 dict ? Should I only include the headers in the context or the entire df?
Abhiram Ramesh|2023-07-20 15:24:07|You can put the entire df in the dictionary. But you'll have to preface the context with some info about the keys if it's something obscure . Like if you have columns store, location, sales, temperature,  that inference is pretty trivial, but if you have column names like cpi etc you might need to tell the model what cpi is. Bear in mind that this will likely use up a lot of tokens🥲 I'm working on comparing cheaper methods. One other method I used was running pandas profiling on the dataframe before passing the result json into the model. That is cheaper but has its limitations as well.
Atharwa Sheth ITC|2023-07-20 15:29:06|I am not able to access the ChatGPT plus subscription, for some reason the card gets declined every time, any suggestion?
~ Ritik Madan|2023-07-20 15:30:59|My Axis visa credit card was facing the same problem, but was able to subscribe it via Citi Debit Mastercard
Abhinav Verma Longshot.ai|2023-07-20 15:34:23|Hasn't citis operation in India taken over by axis
~ Ritik Madan|2023-07-20 15:36:29|Yes, but i don't think the operations have merged yet. My take here is you should try with an international debit card if possible.
Aakash Dharmadhikari|2023-07-20 17:25:43|Strangely I am facing this problem with my Singapore card as well
Aakash Dharmadhikari|2023-07-20 17:26:14|Will try a different card provider
~ RISHAV|2023-07-20 18:06:58|Hello folks, I am planning to buy chatgpt plus subscription, just curious if it can be used concurrently by multiple users at the same time.
Nirant|2023-07-20 18:08:26|No, it'll interrupt the older prediction stream. You can use the GPT4 API with a UI of your own unless you want Code Interpreter
~ Ketan Gangal|2023-07-20 18:12:13|same query , 😄
Abhinav Verma Longshot.ai|2023-07-20 18:15:48|The response will be fun though ‎[7/20/23, 18:20:37] Sudeep Das NASSCOM: ‎image omitted
Swastik Banerjee|2023-07-20 18:25:29|How’s the code interpreter api of langchain (https://github.com/shroominic/codeinterpreter-api)?  sorry if this has been discussed earlier
Nirant|2023-07-20 18:26:20|Not usable
Nirant|2023-07-20 18:26:38|*Not as good as Code Interpreter
Swastik Banerjee|2023-07-20 18:27:07|i see
~ Onkar Mishra|2023-07-20 18:28:07|‎Shivendu Kumar added ~ Onkar Mishra
Paras Chopra Wingify|2023-07-20 18:43:36|Is anyone using code interpreter regularly?  What for?
~ Shivansh|2023-07-20 18:45:53|You have some input data and you want to extract some info or transform it, just give it sample i/o pairs and it give correct code to do that. I’m mostly using to transform textual data.
Shimanta Generative AI|2023-07-20 18:57:31|I have a question on the same lines. Is it capable to do stuff like column mapping on csv files, in no particular format, to a particular format?
Rounak Datta Hackathon Winner|2023-07-20 19:10:10|Anyone used it for ITR filing? Parsing AIS/TIS statements?
~ Abhilash K Pai|2023-07-20 19:14:02|https://www.assemblyai.com/playground/source
~ Abhilash K Pai|2023-07-20 19:15:05|The Conformer architecture is fascinating.  The Google Brain team combined transformers and convolutional neural networks to get the best of both worlds: Transformers are good at capturing global interactions in the data, while a CNN knows how to exploit local features.  The result is an architecture that can efficiently model an audio sequence's local and global dependencies, and that's the foundation of Conformer-2.  To understand how good the model is, go to the playground linked below and try a YouTube video. I have an accent, and the model transcribes my videos with no issues.  Compared to the first version, Conformer-2 is more accurate and robust, especially in processing noisy audio and dealing with the names of people, places, and things.
Aashay Sachdeva MPL Data Scientist|2023-07-20 19:24:45|It is nothing new tbh, meta did it years back with attention + cnn
~ Shivansh|2023-07-20 19:32:55|Haven’t tried it, but would be able to do that. It iterates until it get it right
~ Vinay|2023-07-20 19:41:43|quick prototyping with html, bootstrap + flask, adhoc python scripts for data transformation, csv formatting.
Shashank Generative AI Group|2023-07-20 19:56:57|"new Chroma release https://www.trychroma.com/blog/chroma_0.4.0  ""...we’ve eliminated DuckDB and ClickHouse as system dependencies and unified the document storage by using SQLite across both local and client/server deployments. SQLite delivers great performance for our use case and also provides a robust set of full text search functionality."""
Pratyush Choudhury|2023-07-20 19:59:54|Wow, this is amazing
Kartikeya Bharadwaj|2023-07-20 20:06:59|Implementing papers, debugging.
Paras Chopra Wingify|2023-07-20 20:12:56|Implementing papers? Have you documented your workflow
Bulia Siddharth Aurashop|2023-07-20 20:16:30|https://www.ycombinator.com/launches/J0X-cerelyze-tool-for-engineers-to-implement-research-papers-100x-faster
Bulia Siddharth Aurashop|2023-07-20 20:16:38|There is a YC startup for this!
Shashank Generative AI Group|2023-07-20 20:20:08|deep dive blog post, explaining the math behind inference latency/throughput and measuring actual inference performance  https://twitter.com/amanrsanger/status/1682003116403879938  https://www.cursor.so/blog/llama-inference
~ Saurabh Arora|2023-07-20 20:20:27|It's crazy. I gave it my 12-months roadmap and asked it to create a job description for an Engineering manager 😁
Alok Bishoyi|2023-07-20 20:22:13|data analysis / plots.  Logs / telemetry parsing for insights that you need to run some custom logic to check for
Pratyush Choudhury|2023-07-20 20:23:21|How do you share logs?
Pratyush Choudhury|2023-07-20 20:23:22|Like share it with ChatGPT?
Alok Bishoyi|2023-07-20 20:25:09|Ah, in my case, it's mostly edge computing devices that I have access to. So for now I just manually upload to the conversation context, and work with it to check whatever I would want to.   Easier to do so than manually parsing through.
Pratyush Choudhury|2023-07-20 20:29:23|Ah, nice use-case for the edge
Anubhav mishra Zupay|2023-07-20 20:32:43|Product analytics :)
Kartikeya Bharadwaj|2023-07-20 20:36:19|While implementing papers, I treat the inprerpreter as my “Deep learning tutor” and make the process iterative.  Here’s the workflow:  1. I start with my rough implementation of the paper which obviously has lots of bugs.  2. Upload the rough file to the interpreter- prompt GPT4 to give ‘hints’ and not the final solution.  3. I make changes based on hints received in step 2.  4. Keep repeating 2 and 3 until I am able to get satisfactory results.  Here’s how I was implementing SimCLR paper last week with interpreter (ignore typos, grammatical errors)  https://chat.openai.com/share/91fe818e-97ee-426d-bea6-b427e9774ddd
~ Krishna|2023-07-20 20:37:38|What's y'all's opinion on the best audio-to-text model/service right now?
Ankur Pandey|2023-07-20 20:48:23|https://nas.io/rubyAI  Free WhatsApp summary. From Nas
Paras Chopra Wingify|2023-07-20 21:15:06|Wow, so good!  I wonder whether it can write code if you upload a paper.  Have you tried it?
Kartikeya Bharadwaj|2023-07-20 21:18:50|I didn’t upload the paper, but just asked to implement it (SimCLR) from scratch in another session.   The code worked really well after 2-3 minor tweaks. ‎[7/20/23, 21:25:46] Abhishek Mishra: ‎image omitted
Ravi Theja|2023-07-20 21:28:42|"Interesting insights on when to use open source models vs gpt 3.5.   To summarize, they suggested - ""we find it most helpful to use open-source models for prompt-heavy tasks, such as classification or reranking"" and ""Llama is > 3x cheaper than gpt-3.5 for prompt tokens."""
Paras Chopra Wingify|2023-07-20 21:30:48|How is llama cheaper?
jyotirmayjk Hackathon|2023-07-20 21:30:57|Yud’s drone will be locking in your location soon 😂
Ravi Theja|2023-07-20 21:37:15|They did serve Llama on 2 80-GB A100 GPUs to have similar latency as gpt3.5 and did some experiments
Abhishek Mishra|2023-07-20 21:44:06|Well don't know about drones but one thing's for sure, my method is wrong 😅
Abhishek Mishra|2023-07-20 21:46:48|It is a bit confusing for me and thus hard to agree on the conclusion on where to use open source in terms of cost and latency. It will be cheaper to use a dedicated NLP model for tasks like classification/summarisation as it was shown in a paper that GPT3/4 performs inferior to the SoTA NLP models. So use the SoTA model for results and then just do RAG using the results.  I may be understanding the intent of the article incorrectly, happy to be corrected, ‎<This message was edited>
Abhishek Mishra|2023-07-20 21:49:15|The best place to use open source models is in tasks where they cut the threshold of human preference and the nature of task has a higher margin of error. Companion models, basic assistance requirements, simple rule instructions.
Anubhav mishra Zupay|2023-07-20 21:59:23|https://www.mayfield.com/ai-start/
Anubhav mishra Zupay|2023-07-20 21:59:25|FYI ‎[7/20/23, 23:11:18] Abhishek Mishra: ‎image omitted
Dev Aggarwal|2023-07-20 23:12:59|This is just system prompt finally being exposed?
Abhishek Mishra|2023-07-20 23:28:58|We already had an option for system prompt in the api, right?  I am guessing they're doing this because of Ghost Attention. GAtt is a concept introduced by Meta with llama v2 release where they use GAtt to ensure each turn in the chat adheres to a set of instructions given by the user in original prompt.
Abhishek Mishra|2023-07-20 23:30:00|But now ChatGPT can remember facts about us with this, so this is definitely more than just that. ‎[7/20/23, 23:30:09] Alok Bishoyi: ‎image omitted ‎[7/20/23, 23:30:10] Alok Bishoyi: ‎image omitted
Alok Bishoyi|2023-07-20 23:34:05|"""Should ChatGPT have opinionr or remain neutral"" : I think this is the more interesting and fun part. Might be a pre election move too ? ‎[7/20/23, 23:35:53] Alok Bishoyi: ‎image omitted"
~ Preet Garach😎|2023-07-20 23:38:16|‎~ Preet Garach😎 left
Abhishek Mishra|2023-07-20 23:40:53|Ohh nice 😂
Abhinav Verma Longshot.ai|2023-07-20 23:41:37|but the system prompts in api don't work as well . Does it work well in chatgpt?
~ Vishwam Jindal|2023-07-20 23:47:55|https://techcrunch.com/2023/07/20/openai-launches-customized-instructions-for-chatgpt/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAACkodA07EFcxbgQGidTVh_yXiHIWVoChTszAJczADa5xcbv09nrhXyMg3M7jP0TiqQQKaxV-_H0VPKW-cbY-crrsho0xwLuWNUwGTwDtbgfMkYFSsP2cUisFpZnC8CPniwO-8f_MBZbgl9pW7uzlrOYEDKNb-imV0x8nyi194rYU
Nilesh Transcend|2023-07-21 00:09:40|I'd say, no. More like a persistent partial user prompt. system prompt carries extra privilege that user prompt is not supposed to have.
Abhinav Verma Longshot.ai|2023-07-21 00:30:17|Also ChatGPT isn't passing the custom instructions as a system instruction, atleast not explicitly anyway
Dev Aggarwal|2023-07-21 00:35:03|The api endooint for this is https://chat.openai.com/backend-api/user_system_messages
Shimanta Generative AI|2023-07-21 00:44:50|Swyx on twitter already prompt injected the custom instructions prompt 😅 https://twitter.com/swyx/status/1682095347303346177?s=46&t=WT1iAtjftW-5_e62F8FZTg  It’s been told to think quietly about the request and then apply instructions when it’s relevant.
Abhinav Verma Longshot.ai|2023-07-21 00:47:15|he's doing the AGI god's work 😂
~ Ankit Sharma|2023-07-21 00:52:05|Guess this is something related to the rumour about training GPT like models  https://github.com/apple/axlearn
ashish Acgt01 Twitter|2023-07-21 02:15:13|Because Linux processes have feelings too ! :)  https://twitter.com/amasad/status/1681945960652341253?t=r8YxzQEVuZKE5-ALDWsK7g&s=19
ashish Acgt01 Twitter|2023-07-21 02:19:42|"https://twitter.com/deliprao/status/1681651522529050632?t=a2rJ3WHLXKHddIVhWVyrMg&s=19  LLMs can generate palindromes and haikus independently, but not one which is both,  implying it doesn't ""understand"", what haikus and palindromes are, at a conceptual level  ! ‎<This message was edited>"
Adithya S K PESIT|2023-07-21 02:22:05|if an LLM is trained based on characters instead of token i feel it will be able to generate palindromes just an assumption
Nirant|2023-07-21 02:22:59|Would you like to add a line or two why these tweets are interesting — so that folks can choose themselves if it's worth the click? 
ashish Acgt01 Twitter|2023-07-21 02:24:49|"It can generate palindromes and haikus independently, but not one which is both,  implying it doesn't ""understand"", what haikus and palindromes are, at a conceptual level  !"
Dev Aggarwal|2023-07-21 02:25:29|I doubt it can do palindromes even independently
ashish Acgt01 Twitter|2023-07-21 02:35:11|It really struggles with just simple palindromes  https://chat.openai.com/share/7c3ca506-80e9-4beb-a63a-8b39465004c6
Dev Aggarwal|2023-07-21 02:36:42|Not just palindromes - anything that requires compact representation of thought, and the search space is larger than what you can have finite combinations for, it struggles (eg 4 digit arithmetic)
Aakash Kumar  Matrix Partners|2023-07-21 02:40:50|https://fablestudio.github.io/showrunner-agents/
Atik Shaikh|2023-07-21 08:17:04|‎Atik Shaikh requested to join
Atik Shaikh|2023-07-21 08:18:24|‎Atik Shaikh joined using this group's invite link
Nirant|2023-07-21 08:22:09|Microsoft copied my AgentAI library design for Typescript 🙈🤣 https://microsoft.github.io/TypeChat/blog/introducing-typechat/
Anshuman Pandey|2023-07-21 08:34:30|Woah!
Nirant|2023-07-21 08:36:47|Everyone is forced to discover Pydantic types for their language.  As someone who saw the type-mess of the Python ORM-wars era, I find this amusing and comforting at the same time!
Shubham Arora|2023-07-21 08:36:54|Mat karo na open source!
Kartik Mandaville|2023-07-21 08:37:02|Does anyone have good papers/documentation on how to preprocess(clean) tens of thousands of messages (conversations from Slack) for search retrieval?
Nirant|2023-07-21 08:37:53|OSS is the way, it managed to Microsoft to it's will!
Nirant|2023-07-21 08:38:25|And that too Microsoft at it's Nadella-peak instead of Ballmer-peak (if you get the reference, you're a nerd) ‎[7/21/23, 08:39:10] Nirant: ‎image omitted
Nirant|2023-07-21 08:40:38|At the risk of spilling too much alpha, you need to tune the number of messages before and after a specific message (found via vector search) which you want to add to context. A common trick is to include messages sent in last mean + 1 sigma of that thread duration on both sides.
~ Arko Cy|2023-07-21 08:41:33|Classic
Nirant|2023-07-21 08:44:02|"The intuition is this: Energetic conversations often lead to folks sending ""shorter, bursty"" messaging style — so you're trying to capture some large fraction of that burst in the thread.  You can go on to make more heuristics and use the time between 2 consecutive messages (ask→ answer → follow up) to improve this"
Kartik Mandaville|2023-07-21 08:46:45|true!
Kartik Mandaville|2023-07-21 08:48:48|what about cleaning data techniques? Are there some best practices?
Nirant|2023-07-21 08:51:45|Contextual question, broad ideas for human convos:  1. Keep the emojis in. They're very high signal to noise ratio 2. Don't remove stop words — grammar is useful for vector based IR, but worse for full text/BM25 IR 3. Add the sender, channel etc. as a facet/filter and use the filters e.g. see if you can parse the query into a filter or set of filters ‎[7/21/23, 08:56:09] jyotirmayjk Hackathon: ‎image omitted
Sachin Legaltech|2023-07-21 09:01:37|Palindromes would be hard, cause after tokenization model is generating  the substring tokens and have no clue that particular token is a palindrome of another. Maybe you can show enough examples of palindromes during finetuning to force the model to output individual character tokens; but then the sequence length becomes too long. ‎[7/21/23, 09:03:56] Kartik Mandaville: ‎image omitted ‎[7/21/23, 09:03:57] Kartik Mandaville: ‎image omitted ‎[7/21/23, 09:03:58] Kartik Mandaville: ‎image omitted
Nirant|2023-07-21 09:06:34|Beautiful!   MMLU proving to be a surprisingly good proxy of RAG performance
Nirant|2023-07-21 09:09:35|~$4/hr A100 on Modal, ready to go hyper-fast Llama2-13B with vLLM (paged attention)   https://modal.com/docs/guide/ex/vllm_inference ‎[7/21/23, 09:24:40] ~ Ankur Khandelwal: ‎image omitted
Abhishek Mishra|2023-07-21 09:39:13|It can also stick to structure with a low violation %. It's very similar to how Bing/GPT 3.5 was in the beginning.  With OSS deployments, we will have to fix the same initial engineering problems that openAI fixed on their side but I think we can say that OSS has made enough (openAI -6 months) progress to be put to use.
ashish Acgt01 Twitter|2023-07-21 10:06:45|Cerebras launches CG1(condor galaxy 1) for g42 in the uae https://www.condorgalaxy.ai/news/cerebras-and-g42-unveil-world%E2%80%99s-largest-supercomputer-for-ai-training-with-4-exaflops-to-fuel-a-new-era-of-innovation   https://www.nytimes.com/2023/07/20/technology/an-ai-supercomputer-whirs-to-life-powered-by-giant-computer-chips.html
Nirant|2023-07-21 10:20:48|cc [PHONE] OSS investor, might be interesting to you?
~ Shashank Jha|2023-07-21 10:24:22|‎~ Shashank Jha joined using this group's invite link
Sandeep Srinivasa RedCarpetup|2023-07-21 10:56:17|has anyone here saved structured JSON to a vector db and used it later for generation usecases? im considering transforming a bunch of raw text into structured json during vector db insert.
Prayank Swaroop Accel|2023-07-21 11:06:24|Why dont you use the Mongodb vector functionality ?
Prayank Swaroop Accel|2023-07-21 11:06:29|https://www.mongodb.com/blog/post/introducing-atlas-vector-search-build-intelligent-applications-semantic-search-ai
Jithin James Ragas|2023-07-21 11:12:06|ohh nice shooting her a mail🤞🏻
Kaushik Bokka|2023-07-21 11:24:30|Drop a message to Joseph Jacks as well. He’s super nice and insightful
Sandeep Srinivasa RedCarpetup|2023-07-21 11:29:05|So, it's an interesting point...but largely orthogonal to my initial question. I'm fundamentally asking the viability of trasforming large text blobs into json and using that for generative usecases. Versus summarisation.  This probably is best thought as a chunking question
Nilesh Transcend|2023-07-21 11:39:19|What's the equivalent of this in Python land?
Shashank Generative AI Group|2023-07-21 12:16:02|https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/  count llama tokens using this playground
Alok Bishoyi|2023-07-21 12:45:39|Any orgs / companies in India that are engaged in foundational model training ( vision, NLP etc )?
Pratyush Choudhury|2023-07-21 12:46:49|IIsC?
Anubhav mishra Zupay|2023-07-21 12:47:32|Zoho , [PHONE] sir ( AI4Bharat)
Kshitij Agrawal ML Engineer|2023-07-21 12:52:40|What do you mean by foundation model in vision? Ppl have been training on imagenet for ages.  If you mean embedding networks, that too is being done but relatively closed door.
C Chaitanya Nutanc|2023-07-21 13:13:48|We are doing foundational models in NLP and ASR. But not in the traditional deep learning sense. Anything particular you are looking for?
Nirant|2023-07-21 13:23:04|1. This is what I maintain: https://github.com/NirantK/agentai 2. Similar is this one from Alexander Rush: https://github.com/srush/MiniChain
The GenerativeAI Group|2023-07-21 13:40:34|‎You added Kunal Harbor and Prakash Sankar Harbor
Prakash Sankar Harbor|2023-07-21 13:48:25|Hey everyone, Prakash here from Harbor. We're working on leveraging AI to raise issues in code. Stuff I'm interested in -   a. Self hosting models/increasing reliability of LLM based products in prod. b. Prompting for specific tasks - specifically code parsing deterministically.  would appreciate any resources centered around these - thanks and looking forward to learning with everyone
Saurabh Karn Nyai|2023-07-21 15:23:01|What are some recommendations for training a pre-trained gpt model in a secure environment? Which providers for GPU? Is anyone trying mosaic or cerebras? Any thoughts on differential privacy?
~ Shivansh|2023-07-21 16:32:52|Any developer tried custom instructions in GPT plus which worked well for them? Please share :)
Atik Shaikh|2023-07-21 16:35:01|Actually it’s not that new tools like perplexity were already doing that in form of “AI Profile” feature ‎[7/21/23, 16:45:02] Atik Shaikh: ‎image omitted
Atik Shaikh|2023-07-21 16:45:09|Example ^
Abhinav Verma Longshot.ai|2023-07-21 16:51:42|Use this for reference  https://twitter.com/swyx/status/1682095347303346177?s=46&t=URoDrV5X7GPNPYSgYW42Dw
Atik Shaikh|2023-07-21 16:55:24|Yes this was given by default to it to incoorporate that feature
~ Abhiram Ravikumar|2023-07-21 18:25:52|"""For example, a teacher crafting a lesson plan no longer has to repeat that they're teaching 3rd grade science. A developer preferring efficient code in a language that’s not Python – they can say it once, and it's understood. Grocery shopping for a big family becomes easier, with the model accounting for 6 servings in the grocery list.""  https://openai.com/blog/custom-instructions-for-chatgpt"
~ Abhiram Ravikumar|2023-07-21 18:26:48|ChatGPT has come up with custom instructions, I'm afraid the responses would be too hyperpersonal. What does the group think?
Apurv Aurva.io Sahil's Friend|2023-07-21 18:37:16|has anyone used transformer model or existing LLM so far for now 'traditional' use cases like pattern recognition/anomaly detection?
~ Prashanth Harshangi|2023-07-21 18:42:22|Depending on what is meant to be secure (data or model), if you are looking for securing model IP, then selfish plug-Enkrypt AI can help out. Not aware of publicly available confidential VMs with GPUs, as they are still in the experimental phase.
Abhishek Mishra|2023-07-21 18:44:32|For such traditional predictive tasks, LLMs can be used but they will be slightly inferior to corresponding SoTA models.
Abhishek Mishra|2023-07-21 18:45:37|However, I've tested GPT4 for similarity detection and anomaly detection. It works amazing with few examples out of the box. But it's like bringing a tank to a gun fight and paying for the tank by the minute.
~ Prashanth Harshangi|2023-07-21 18:52:39|Saves lot of copy pasting 😅.
Saurabh Karn Nyai|2023-07-21 19:24:16|Has anyone been facing issue in running llama2 on mac m1? I keep getting: not compiled with GPU offload support
Abhishek Mishra|2023-07-21 19:27:52|That warning will be there since quantization on Mac is purely running on CPU. There's no GPU offload.
Saurabh Karn Nyai|2023-07-21 19:42:31|Hmmm… it’s painfully slow.
Vaibhav Pilani|2023-07-21 20:08:19|Run on google colab it's faster
Saurabh Karn Nyai|2023-07-21 20:09:19|llama-2-13b-chat.ggmlv3.q4_0.bin  This one isn't compiled with GPU offload. Trying 7b
Vaibhav Pilani|2023-07-21 20:09:20|https://github.com/camenduru/text-generation-webui-colab
Prayank Swaroop Accel|2023-07-21 21:09:30|Doesn't work like this. You have to follow the steps.   You can follow this step, I mentioned here  https://twitter.com/prayanks/status/1681522402981806080?t=7HO1ODdpmiOCzFHj-2tO5g&s=09
Prayank Swaroop Accel|2023-07-21 21:09:52|For Mac GPU acceleration.. I did this on an M1 👆
Saurabh Karn Nyai|2023-07-21 21:16:35|Awesome! I had attempted two methods to enable metal
Saurabh Karn Nyai|2023-07-21 21:16:43|this one worked
Saurabh Karn Nyai|2023-07-21 21:16:50|I must be doing some silly mistake
Abhishek Mishra|2023-07-21 21:24:32|A 7B model is supposed to be minimum 15-20 tok/s on M1/M2 pro
Abhishek Mishra|2023-07-21 21:24:58|If you've less than that, then you can go back and check
Dhruv Anand|2023-07-21 21:28:32|What's the current best fine tuned llama2 which tries to reverse the effects of whatever RLHF they've done
Abhinav Verma Longshot.ai|2023-07-21 21:29:19|There's a version that was finetuned by Teknium, I can't seem to find it on Hf right now
Nirant|2023-07-21 21:33:56|Nous Hermes?
Abhinav Verma Longshot.ai|2023-07-21 21:34:29|I believe so yes. That's the one.
Nirant|2023-07-21 21:34:57|Here you go https://huggingface.co/NousResearch/Nous-Hermes-13b
Abhishek Mishra|2023-07-21 22:08:34|I see significant coding capabilities in llama2 7B after fine tuning it on 122k coding instructions
Abhishek Mishra|2023-07-21 22:09:06|So far it is able to answer all basic programming questions in C, python with basic algos, OS and file operations
Abhishek Mishra|2023-07-21 22:09:36|It's just 7B and it has gotten so good i can't wait to test out results on the bigger models.
Abhishek Mishra|2023-07-21 22:10:23|After quantization, it can definitely be good enough for boilerplate stuff in complete enterprise environment
Prayank Swaroop Accel|2023-07-21 22:12:29|The Llama2 model wasn't RLHF trained, the Llama2-Chat models were ‎[7/21/23, 22:13:05] Prayank Swaroop Accel: ‎image omitted
Dhruv Anand|2023-07-21 22:14:21|Ok, but llama2 base is not instruction fine-tuned right? So not usable directly
Abhishek Mishra|2023-07-21 22:17:25|The RLHF adds both helpfulness (adherence to structure/request) as well as safety mechanics, so it is more useful to use it with RLHF. Instruction tuning seems to be taking care of issues with its extreme safety mechanics.
Prayank Swaroop Accel|2023-07-21 22:18:35|I thought you wanted a model without RLHF .. then you can fine tune it to follow instructions
ashish Acgt01 Twitter|2023-07-21 22:18:59|Maybe give it a leetcode easy or medium problem ? :)
Dhruv Anand|2023-07-21 22:21:20|"I mean, to un-kneecap it from whatever fine-tuning/RL they've done to make it ""safer"", i.e. stop it from refusing to follow basic instructions because it flags them as unsafe"
Prayank Swaroop Accel|2023-07-21 22:22:39|You can't unlearn in LLMs .. some experts can confirm or deny this
Abhishek Mishra|2023-07-21 22:22:41|It seems to be doing fine with easy level stuff. Like binary search, Fibonacci etc
Prayank Swaroop Accel|2023-07-21 22:23:59|Super can you share how you did it ?
Saurabh Karn Nyai|2023-07-21 22:24:14|You finetuned it on coding instructions?
Abhishek Mishra|2023-07-21 22:24:40|Yes 122k, commercially licensed. No GPT4 stuff
Saurabh Karn Nyai|2023-07-21 22:25:03|Waah! That's pretty cool
Abhishek Mishra|2023-07-21 22:25:31|https://huggingface.co/TokenBender/llama2-7b-chat-hf-codeCherryPop
Abhishek Mishra|2023-07-21 22:26:03|The repo contains the jupyter notebook used in the fine tuning
Abhishek Mishra|2023-07-21 22:26:44|30min fine tuning on A100, cost around 1.5-1.6 USD after cleaning up the pipeline
Abhishek Mishra|2023-07-21 22:27:17|Experimentation cost to get it right was 10-15 usd as the QLoRa training losses were wonky, so had to play with some parameters ‎<This message was edited>
Prayank Swaroop Accel|2023-07-21 22:37:35|Hey Abhishek any where to read this process ? Do you have a blog or any pointers ?
Prayank Swaroop Accel|2023-07-21 22:37:43|You used auto train ?
Ravi Theja|2023-07-21 22:39:10|SFTTrainer I guess.
Abhishek Mishra|2023-07-21 22:41:29|No, i used TRL SFTtrainer, autotrain advanced installs everything from scratch and my python dependencies started breaking. You can check the repo, it contains the steps and the library used
Abhishek Mishra|2023-07-21 22:43:24|Fine tuning latest models isn't standardized right now. You can try to change the dataset or the model without touching anything else and stuff would start breaking. Autotrain is the most agnostic approach though if you've a clean container with you
Prayank Swaroop Accel|2023-07-21 22:47:41|Thanks !
Prayank Swaroop Accel|2023-07-21 22:47:55|You should launch your model like WizardLM 😇
Abhishek Mishra|2023-07-21 22:59:45|It's a bottom of the barrel model 😂 but after quantization it can be valuable for sure. It definitely proves that a 7B can be useful for boilerplate code stuff though.  I've a few things in mind and after that this will be more valuable. 1. Creating a merged model, currently the repo contains lora adapters that will need to loaded on top of Meta's llama2 so access gating is an issue 2. I'll quantize these, possibly tonight or tomorrow in the day, then it can be run locally with 4G ram 3. I've used alpaca style instruction tuning, I'll switch to llama2 style [INST]<<SYS>> style and see if it improves anything 4. HumanEval report and checking for any training data leaks
Abhishek Mishra|2023-07-21 23:00:54|I'll try 8k context via RoPE enhancement as well, let's see if that degrades performance or not.
Nirant|2023-07-21 23:02:43|cc [PHONE] want to eval this for ragas?
Abhishek Mishra|2023-07-21 23:05:44|RAG dataset prep is in-situ for me, this can be tried for RAG but a dedicated model for citing discipline, saying no when context doesn't contain answer and answering from multiple context chunks might do better.   As it's ready, RAG dedicated llama2 will be next.
Piyush Stripe Growth|2023-07-21 23:08:15|‎Piyush Stripe Growth requested to join
Prayank Swaroop Accel|2023-07-21 23:09:40|For folks interested in fine-tuning - I thought this is a well written article - https://medium.com/mlearning-ai/fine-tuning-alpaca-enabling-communication-between-llms-on-my-m1-macbook-pro-e3234f29c8ae
Hemant Mohapatra|2023-07-21 23:23:36|Has anyone benchmarked llama2 vs gpt4 on some standard use cases (text, code, summarisation, analysis etc) in terms of accuracy, latency, cost?
~ Arjun Narain|2023-07-21 23:36:42|Is Perplexity AI  or Poe worth paying for if you already own ChatGPT plus?
ashish Acgt01 Twitter|2023-07-21 23:40:18|https://news.ycombinator.com/item?id=36775396
ashish Acgt01 Twitter|2023-07-21 23:42:57|https://news.ycombinator.com/item?id=36778932
Hemant Mohapatra|2023-07-21 23:43:47|Perfect, exactly what i was looking for! 🙏
~ Rishi|2023-07-21 23:52:51|Hey Everyone! Can someone suggest to me a really good experiment tracking tool for LLM's n APIs. Like there are many tools for tracking llm prompts, outputs etc like the trace table in w&b n others, but I'm specifically looking for a capturing tool that can track the change in the approach of the code/function as well. Like apart from tracking the time/date, input, prompt, output n other stuff it would also be helpful if it could capture the change in the script compared to the previous run  It would be great if someone could suggest a tool that's capable of this (or customisable). Preferably hosted one that can be shared among teams and can be connected easily
Paras Chopra Wingify|2023-07-21 23:54:34|What do you mean by change in script?
~ Rishi|2023-07-21 23:55:27|Like the change in the python code, like mostly any preprocessing or post processing methods we use before or after the llm call
Paras Chopra Wingify|2023-07-22 00:07:09|Ultimately everything comes down to parameters and prompt
Dhruv Anand|2023-07-22 00:14:26|Git commit on file save/LLM run? Append trace id to commit metadata afterwards
Suhas Motwani|2023-07-22 00:24:29|Recording playlist for the event in case anyone’s interested -  https://youtube.com/playlist?list=PLcoWp8pBTM3A821vFnkOPSmHOJOWkyfFT
Aakash Kumar  Matrix Partners|2023-07-22 00:29:02|https://www.producthunt.com/posts/benchllm-by-v7-1
Ravi Theja|2023-07-22 01:17:47|https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models  Freewilly series models from stability AI.
~ Arsalaan|2023-07-22 01:43:05|This is wild speed llama 2 replaced within 3-4 days of being leaderboard topper , this shows importance of orca styled model training / fine-tuning.
Ravi Theja|2023-07-22 02:35:39|https://twitter.com/openai/status/1682480558545461249?s=46   ChatGPT Andriod app
Neha YC W23|2023-07-22 02:45:46|Gpt ios app was a haptic delight
Neha YC W23|2023-07-22 02:45:47|However used it only once
Satish DeepHack Sponsor|2023-07-22 03:21:58|I love how OpenAI drops big announcements every friday!
Piyush Stripe Growth|2023-07-22 04:47:57|‎Piyush Stripe Growth joined using this group's invite link
Nirant|2023-07-22 04:49:23|Cc [PHONE] and I'll have this via the llama2demo for latency and cost. Looks like llama2demo is gonna win on cost and latency in most predictable workload situations
Atik Shaikh|2023-07-22 05:33:54|Perp gives 75 per 3hrs compared to gpts 50. I have both
Prayank Swaroop Accel|2023-07-22 06:05:02|https://www.philschmid.de/llama-2
Atik Shaikh|2023-07-22 07:08:11|https://labs.pplx.ai/  Llama chat (7/13/70)B ~ Its highly censored though 😂
Sumedh Datar|2023-07-22 08:08:46|Is there an llm that can give instant results. I tried mpt 30b and mpt 7b. Both take several minutes to give a result
Dr. Pratik Desai KissanGPT|2023-07-22 08:11:15|It depends on your hardware.
Sumedh Datar|2023-07-22 08:11:29|I have an a10
Dr. Pratik Desai KissanGPT|2023-07-22 08:12:03|Use GGML version with GPU enabled ‎<This message was edited>
Sumedh Datar|2023-07-22 08:12:26|Ok got it , thanks!
ashish Acgt01 Twitter|2023-07-22 08:15:48|Feels faster than other endpoints !
Atik Shaikh|2023-07-22 08:16:22|UI is also sleak and clean
Prayank Swaroop Accel|2023-07-22 08:17:30|Depends on your setup Sumedh ... how have you set it up. 64GB RAM ?
Sumedh Datar|2023-07-22 08:17:53|It's 96gb on sagemaker
Sumedh Datar|2023-07-22 08:17:57|4 GPUs
Sumedh Datar|2023-07-22 08:18:02|But the results are so slow
Sumedh Datar|2023-07-22 08:18:09|I also did contg.init as meta
Dr. Pratik Desai KissanGPT|2023-07-22 08:23:42|With 3090 exllama GPTQ is giving 40+ tps. Should be around 25-30 on a10.
Dr. Pratik Desai KissanGPT|2023-07-22 08:25:06|7b version
ashish Acgt01 Twitter|2023-07-22 08:37:30|"https://www.alessiofanelli.com/blog/llama2-isnt-open-source  hn https://news.ycombinator.com/item?id=36815255  ""For a model to be truly open source and retrainable from scratch, the creators would need to share all their training code, pre-training dataset, fine-tuning preferences, RLHF examples, etc. The problem is the cost of these training runs: even if someone were to release everything, it’s cost-prohibitive to train models from scratch for most developers and companies, so having access to the final weights is preferred anyway.""  ""For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. The important thing is that more and more of this work is done as openly as possible. It’s okay to be disappointed with the LLaMA2 license, but Meta just packaged ~$2M worth of FLOPS into a Github repo, and I think that will be a net positive for the progress of this space."""
ashish Acgt01 Twitter|2023-07-22 08:39:30|https://huggingface.co/stabilityai/FreeWilly2
Atik Shaikh|2023-07-22 08:54:25|I loggedin my chatgpt plus account to a friends computer and forgot to logout any way to logout from all devices? I signed in with google changing password and logging out google account didn’t work ! Any help is much appreciated thanks <3
Abhishek Mishra|2023-07-22 09:14:49|I think you can't have multiple active sessions with chatGPT anyway. So the session where you've currently logged in and using should stay, the other one would expire and would need login.
Abhinav Verma Longshot.ai|2023-07-22 09:15:58|Code interpreter isn't there on perplexity
Abhinav Verma Longshot.ai|2023-07-22 09:16:48|I think we can have a few. I've definitely had 2-3
Abhishek Mishra|2023-07-22 09:17:24|Ohh
~ Paritosh Sanadhya|2023-07-22 09:20:08|I guess it generates response for only one session at a time, but we can have multiple sessions
Abhinav Verma Longshot.ai|2023-07-22 09:20:46|Could be ‎[7/22/23, 09:45:40] Abhinav Verma Longshot.ai: ‎image omitted
Atik Shaikh|2023-07-22 11:31:01|ChatGPT doesn’t have Internet access with coding capabilities   Perplexity does way better coding anyways than code interpreter
Atik Shaikh|2023-07-22 11:31:22|Nope it isn’t that way you can try yourselves
Atik Shaikh|2023-07-22 11:32:52|Still the feature of reading files in Code Interpreter is important ! Perplex guys are going to add that anyways soon
Abhinav Verma Longshot.ai|2023-07-22 11:32:54|Does perplexity run code as well?
Atik Shaikh|2023-07-22 11:33:11|*python code
Atik Shaikh|2023-07-22 11:33:15|😅
Nirant|2023-07-22 11:33:18|Paged Attention with Quantization ftw
Abhinav Verma Longshot.ai|2023-07-22 11:34:16|If it runs then great.
Atik Shaikh|2023-07-22 11:34:39|Nope it doesn’t but I was saying that interpreter runs only python code
Atik Shaikh|2023-07-22 11:35:19|It needs sandboxed environment so it would need more investment and they have just started so don’t see that coming soon
Abhinav Verma Longshot.ai|2023-07-22 11:37:12|I get that. One selling point for my product is that it has much better browsing than chatgpt with browsing did. But the thing with code interpreter was that it helped me extract useful info out of my log files which would have taken way more time and effort than I wanted to give. So for stuff like that it's a big win
Atik Shaikh|2023-07-22 11:38:28|Yeah as I said ability to read files is highly missed not just due to code interpreter also due to claude so they’re working on it
Abhinav Verma Longshot.ai|2023-07-22 11:39:09|This wasn't just ability to read files here. But yes
Atik Shaikh|2023-07-22 11:39:11|Btw Perplex has 32k context whereas chatgpt plus doesn’t go more than 8k context in UI atleast.
Atik Shaikh|2023-07-22 11:39:22|Atleast for me ….
Nirant|2023-07-22 11:41:50|Nix sandboxes don't get the credit they deserve for powering both Code Interpreter and Replit. Might set that up and show how to hack your own sandbox with Gorilla LLM.
Abhishek Mishra|2023-07-22 11:43:43|Ok, my sessions got terminated long back when I used to switch between mobile and laptop so i had that notion. Anyway, no need to try that now as I rely on GPT4 api to chat.
Atik Shaikh|2023-07-22 11:44:08|No problem
Abhishek Mishra|2023-07-22 11:44:21|phind.com does this very well. Currently their pair programmer option isn't available for some reason but they are good.
Atik Shaikh|2023-07-22 11:45:15|Yeah ik that also but they are currently not that stable
Kshitij Agrawal ML Engineer|2023-07-22 12:06:50|After all the OpenAI api eval upheaval of the last few days, there's a claim that the python eval was not conducted correctly after removing the markdown tags leading to the drop in perf.  What does the group think on other areas of eval?  https://twitter.com/si_boehm/status/1681801371656536068?s=46
Abhinav Verma Longshot.ai|2023-07-22 12:21:24|This would be interesting.
ashish Acgt01 Twitter|2023-07-22 12:28:36|It's a little weird to see people dunking on Matei.  LLM performance drift is real and I am glad there are systematic efforts to measure it.
Nirant|2023-07-22 12:32:51|Folks can run their own eval and improve Matei's work. This is something we can run on our own and check. It's barely $50 or so.   That's science.
Rounak Datta Hackathon Winner|2023-07-22 12:33:19|Neat! I didn't know about Nix sandboxes. I thought it was something containers or Firecracker (the one which aws serverless uses).
Nirant|2023-07-22 12:34:18|NixPack for folks wanting to build to their sandbox with Nix https://github.com/nixpak/nixpak
jyotirmayjk Hackathon|2023-07-22 12:35:09|+1 to this   Although there’s an eval of Matei’s eval which I find more reasonable  https://twitter.com/random_walker/status/1681760102414708736?s=46&t=icC0fizZK8E3ONsDVuGFWA
jyotirmayjk Hackathon|2023-07-22 12:36:08|The analysis provided these authors is well balanced without any gas lighting or hype   https://www.aisnakeoil.com/p/is-gpt-4-getting-worse-over-time
jyotirmayjk Hackathon|2023-07-22 12:38:22|Being new to Evaluation ,a noob question  is it that eval penalises more on output generation ,so that’s why it was scored low due to the new wrapper of python markdown appearing in code ?  Eval method didn’t consider formatting generated output and then checking if the code works or not
Atik Shaikh|2023-07-22 12:47:01|https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models
~ Sanjeev NC|2023-07-22 12:47:27|‎~ Sanjeev NC requested to join
~ Sanjeev NC|2023-07-22 12:50:20|‎~ Sanjeev NC joined using this group's invite link
ashish Acgt01 Twitter|2023-07-22 12:52:56|i am huge fan of random_walker. His takes are always balanced and reasonable.  Thanks for sharing these jyotirmay !
ashish Acgt01 Twitter|2023-07-22 12:59:47|"""We are grateful to the authors for making their experiments so easy to reproduce""  I think this entire episode highlights the fact *ability to reproduce results is critical*  in biomedicine/bioinformatics also, & i suspect a lot of scientific fields, (ala stanford president being forced to resign after falsified data in his papers, [0] [1])  there is a growing realization that results & figures in papers should be reproducible.  0. https://www.npr.org/2023/07/19/1188828810/stanford-university-president-resigns 1. https://boardoftrustees.stanford.edu/2023/07/19/board-of-trustees-statement-release-of-report-and-announcements/"
Aashay Sachdeva MPL Data Scientist|2023-07-22 13:04:19|Do we have a router that can route a request to llm provider depending on the task?
Nirant|2023-07-22 13:07:16|We will be removing this list of users without any more notices after this.  Please remove your name if you're indeed reading this.  https://docs.google.com/spreadsheets/d/1g0RmYGL17IsgL5UHI17-RtnjPBpOT0XcCHl8IC_L3ec/edit#gid=0
~ Anirudh|2023-07-22 13:47:26|‎~ Anirudh requested to join
~ Deepak Jawahar|2023-07-22 13:47:31|‎~ Deepak Jawahar requested to join
~ Ishika Kumari|2023-07-22 13:47:49|‎~ Ishika Kumari requested to join
~ Vish|2023-07-22 13:48:21|‎~ Vish requested to join
~ Vedika Parvez|2023-07-22 13:48:41|‎~ Vedika Parvez requested to join
~ rethik nirmal|2023-07-22 13:49:04|‎~ rethik nirmal requested to join
~ Yogesh Narayanan|2023-07-22 13:49:47|‎~ Yogesh Narayanan requested to join
~ Arun Venkataswamy|2023-07-22 13:50:12|‎~ Arun Venkataswamy requested to join
~ Arun Venkataswamy|2023-07-22 14:18:59|‎~ Arun Venkataswamy joined using this group's invite link
~ Bash|2023-07-22 14:23:54|what is the max token limit for Llama2 inference?
Edgar Monis Mumbai WHO|2023-07-22 14:27:49|It's open source ??
Edgar Monis Mumbai WHO|2023-07-22 14:28:13|Do you mean context window ?
~ Bash|2023-07-22 14:29:14|Yes
Edgar Monis Mumbai WHO|2023-07-22 14:30:07|Iirc it was 4000 tokens
~ Bash|2023-07-22 14:30:24|Ok thanks
~ Yogesh Narayanan|2023-07-22 14:37:20|‎~ Yogesh Narayanan joined using this group's invite link
~ rethik nirmal|2023-07-22 14:37:22|‎~ rethik nirmal joined using this group's invite link
~ Vedika Parvez|2023-07-22 14:37:24|‎~ Vedika Parvez joined using this group's invite link
~ Aditya Chivukula|2023-07-22 14:37:26|‎Sugnan GenerativeAI Group  removed ~ Aditya Chivukula
~ Anirudh|2023-07-22 14:37:28|‎~ Anirudh joined using this group's invite link
~ Ishika Kumari|2023-07-22 14:37:31|‎~ Ishika Kumari joined using this group's invite link
~ Vish|2023-07-22 14:37:32|‎~ Vish joined using this group's invite link
~ Deepak Jawahar|2023-07-22 14:37:35|‎~ Deepak Jawahar joined using this group's invite link
~ Aerica|2023-07-22 14:37:49|‎Sugnan GenerativeAI Group  removed ~ Aerica
Amogh V|2023-07-22 14:39:57|‎Sugnan GenerativeAI Group  removed Amogh V
~ Arjun Narain|2023-07-22 14:41:50|‎Sugnan GenerativeAI Group  removed ~ Arjun Narain
~ Ashutosh Kumar|2023-07-22 14:42:39|‎Sugnan GenerativeAI Group  removed ~ Ashutosh Kumar
~ Ayush Thakur|2023-07-22 14:42:58|‎Sugnan GenerativeAI Group  removed ~ Ayush Thakur
Anshul Bhide Replit|2023-07-22 14:43:02|Purge time
~ Bahulee Guha|2023-07-22 14:43:11|‎Sugnan GenerativeAI Group  removed ~ Bahulee Guha
~ Chan|2023-07-22 14:43:29|‎Sugnan GenerativeAI Group  removed ~ Chan
~ Deeksha💁‍♀️|2023-07-22 14:44:35|‎Sugnan GenerativeAI Group  removed ~ Deeksha💁‍♀️ ‎[7/22/23, 14:45:43] ~ Darshan Savaliya: ‎GIF omitted
~ Ganga|2023-07-22 14:45:47|‎Sugnan GenerativeAI Group  removed ~ Ganga
Bhavya Ranpara Generative AI Wa Group Surat|2023-07-22 14:46:06|😂
~ Govind|2023-07-22 14:46:16|‎Sugnan GenerativeAI Group  removed ~ Govind
Gyan GenerativeAI Group|2023-07-22 14:46:33|‎Sugnan GenerativeAI Group  removed Gyan GenerativeAI Group
Aankit Roy Khabri YC|2023-07-22 14:46:37|Mass firing
~ Gyanesh Malhotra|2023-07-22 14:46:41|‎Sugnan GenerativeAI Group  removed ~ Gyanesh Malhotra
~ Happy Chaudhury|2023-07-22 14:46:49|‎Sugnan GenerativeAI Group  removed ~ Happy Chaudhury
~ Irfan|2023-07-22 14:47:36|‎Sugnan GenerativeAI Group  removed ~ Irfan
Kshitij Agrawal ML Engineer|2023-07-22 14:48:29|Agreed. There used to be a designated workshop on reproducability in NeurIPS, ICLR etc.
Karthik GenerativeAI WhatsApp Group|2023-07-22 14:49:26|‎Sugnan GenerativeAI Group  removed Karthik GenerativeAI WhatsApp Group
~ Kruti|2023-07-22 14:49:56|‎Sugnan GenerativeAI Group  removed ~ Kruti
~ Miraj Shah|2023-07-22 14:51:30|‎Sugnan GenerativeAI Group  removed ~ Miraj Shah
~ Mudassir Khan|2023-07-22 14:52:02|‎Sugnan GenerativeAI Group  removed ~ Mudassir Khan
Palkush GenerativeAI Group|2023-07-22 14:53:38|‎Sugnan GenerativeAI Group  removed Palkush GenerativeAI Group
~ Parth Rajauria|2023-07-22 14:53:49|‎Sugnan GenerativeAI Group  removed ~ Parth Rajauria
Nirant|2023-07-22 14:54:03|Sorry for the announcement here, too many calls 🙈  Room Change: SSB 233 for my IIT M AI4Bharat talk in 10 minutes, Computer Science Department ‎<This message was edited>
Kshitij Agrawal ML Engineer|2023-07-22 14:54:05|Yes, ideally it should be agnostic of the markdown wrapper if the goal is to measure code synthesis. Rn, it seems to be more of a response eval.
Dev Aggarwal|2023-07-22 14:58:23|Please share slides later if possible
Atik Shaikh|2023-07-22 15:07:34|https://youtu.be/MACR50bJX7Y
~ ASLAN|2023-07-22 15:09:27|‎~ ASLAN requested to join
~ Priyam Mehta|2023-07-22 15:09:27|‎~ Priyam Mehta requested to join
~ Srija|2023-07-22 15:09:28|‎~ Srija requested to join
~ Pappu Kumar|2023-07-22 15:09:31|‎~ Pappu Kumar requested to join
~ Tahir J Makhdoomi|2023-07-22 15:09:33|‎~ Tahir J Makhdoomi requested to join
~ ~|2023-07-22 15:09:35|‎~ ~ requested to join
~ Anuja Modi|2023-07-22 15:09:37|‎~ Anuja Modi requested to join
~ Vishal__vishnnu|2023-07-22 15:09:39|‎~ Vishal__vishnnu requested to join
~ ROYSTARK|2023-07-22 15:09:46|‎~ ROYSTARK requested to join
~ ,,|2023-07-22 15:09:56|‎~ ,, requested to join
~ ROYSTARK|2023-07-22 15:12:18|‎~ ROYSTARK joined using this group's invite link
~ Vishal__vishnnu|2023-07-22 15:12:22|‎~ Vishal__vishnnu joined using this group's invite link
~ Srija|2023-07-22 15:12:28|‎~ Srija joined using this group's invite link
~ Priyam Mehta|2023-07-22 15:12:31|‎~ Priyam Mehta joined using this group's invite link
~ Shaaban Karim|2023-07-22 15:12:45|‎Sugnan GenerativeAI Group  removed ~ Shaaban Karim
~ ,,|2023-07-22 15:12:47|‎~ ,, joined using this group's invite link
~ Siddharth|2023-07-22 15:14:35|‎Sugnan GenerativeAI Group  removed ~ Siddharth
Siddharth Gopi GenerativeAI WhatsApp Group|2023-07-22 15:14:41|‎Sugnan GenerativeAI Group  removed Siddharth Gopi GenerativeAI WhatsApp Group
Sivashankar Ramesh|2023-07-22 15:15:01|‎Sugnan GenerativeAI Group  removed Sivashankar Ramesh
~ Tirtha|2023-07-22 15:18:30|‎Sugnan GenerativeAI Group  removed ~ Tirtha
~ Yogesh Sangtani|2023-07-22 15:22:31|‎Sugnan GenerativeAI Group  removed ~ Yogesh Sangtani
~ prakashkagitha|2023-07-22 15:25:05|‎Sugnan GenerativeAI Group  removed ~ prakashkagitha
~ rohan~|2023-07-22 15:25:16|‎Sugnan GenerativeAI Group  removed ~ rohan~
Piyush Stripe Growth|2023-07-22 15:37:56|+1 would love to see slides/recordings
~ Yogesh Narayanan|2023-07-22 15:39:51|https://microsoft.github.io/TypeChat/blog/introducing-typechat/
~ RISHAV|2023-07-22 15:39:51|Hello Folks, I have a few questions regarding text splitters.   1. which text splitter works well. 2. How do you select one text splitter, if there is no common format your data has. ‎[7/22/23, 15:58:33] Karan Ganesan luma.ai: ‎image omitted
Lalit Pagaria|2023-07-22 16:10:23|Looking forward for slides
~ Nimish|2023-07-22 16:10:54|‎~ Nimish requested to join
~ Nimish|2023-07-22 16:11:33|‎~ Nimish joined using this group's invite link
~ KJ|2023-07-22 16:13:00|+1
~ Saravanan Balakrishnan|2023-07-22 16:16:54|+1
~ KJ|2023-07-22 16:17:12|‎Sugnan GenerativeAI Group  removed ~ KJ
~ Anuja Modi|2023-07-22 17:09:54|‎~ Anuja Modi joined using this group's invite link
~ ~|2023-07-22 17:09:58|‎~ ~ joined using this group's invite link
~ Pappu Kumar|2023-07-22 17:10:01|‎~ Pappu Kumar joined using this group's invite link
~ ASLAN|2023-07-22 17:10:04|‎~ ASLAN joined using this group's invite link
~ Tahir J Makhdoomi|2023-07-22 17:10:06|‎~ Tahir J Makhdoomi joined using this group's invite link
~ Sabbih|2023-07-22 17:12:01|‎~ Sabbih left
Saksham Generative AI WhatsApp Group|2023-07-22 17:12:01|‎Saksham Generative AI WhatsApp Group left
~ Sachin Kalsi|2023-07-22 17:12:01|‎~ Sachin Kalsi left
~ Rishi|2023-07-22 17:12:01|‎~ Rishi left
~ Riken Shah|2023-07-22 17:12:01|‎~ Riken Shah left
~ Saumya|2023-07-22 17:12:01|‎~ Saumya left
Karthik GenerativeAI WhatsApp Group|2023-07-22 17:20:58|‎You added Karthik GenerativeAI WhatsApp Group
Gyan GenerativeAI Group|2023-07-22 17:23:11|‎Gyan GenerativeAI Group joined using your invite
Sivashankar Ramesh|2023-07-22 17:23:24|‎Sugnan GenerativeAI Group  added Sivashankar Ramesh
~ Sachin Kalsi|2023-07-22 17:28:48|‎Sugnan GenerativeAI Group  added ~ Sachin Kalsi
Palkush GenerativeAI Group|2023-07-22 17:29:20|‎Sugnan GenerativeAI Group  added Palkush GenerativeAI Group
~ Kruti|2023-07-22 19:17:06|‎Sugnan GenerativeAI Group  added ~ Kruti
Siddharth Gopi GenerativeAI WhatsApp Group|2023-07-22 19:40:12|‎You added Siddharth Gopi GenerativeAI WhatsApp Group
~ Parna Paul|2023-07-22 19:43:00|‎Dr. Pratik Desai KissanGPT added ~ Parna Paul
Sugnan GenerativeAI Group |2023-07-22 20:21:17|*Job Openings*                                                                                                                                                         🟢 Spyn. Inc - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools - 🔍 *Job Description*: Applied ML Engineer, who can work with LLMs, apply prompt engineering techniques, insert guard rails, scale the application with Google/AWS cloud. Details of the company are at aifithub.com.- -📝 *Apply Here*: You can contact at [EMAIL] , with your resume - 💬 *Contact*: [EMAIL]  --- 🔵 SnowMountain.ai - 🎯 *Hiring for*: Generative AI includes all text, vision, typically - 🔍 *Job Description*: AI Engineer. We are building human-AI teaming software for autonomous agents, working on complex business processes. - 📝 *Apply Here*: Email at [EMAIL] - 💬 *Contact*: Nilesh - +91-7737799743 (Do WhatsApp)  --- 🟣 Dcverse - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools - 🔍 *Job Description*: Looking for an experience NLP specialist with experience to lead the LLM segment of virtual humans’ startup Dcverse. They will be given latest nvidia tech and guidance to generate and build AI models. - 📝 *Apply Here*: Only emails. ([EMAIL]) - 💬 *Contact*: WhatsApp: 8860547493/E-mail: [EMAIL]  --- 🔴 AI engineering - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools - 🔍 *Job Description*: Form company’s AI strategy, train and deploy models, help us understand what’s possible with AI and what these things cost. - 📝 *Apply*: wa.me/+918971258254 - 💬 *Contact*: Tanish - +91 8971258254 --- *----->* Posted by Sugnan on behalf of Generative AI Community.
~ Parna Paul|2023-07-22 20:31:14|Hello All, I’m Parna from The Nudge Institute 👋working towards a poverty free India.   At the Center for Skill Development (https://csde.thenudge.org/#1) we empower youth from low income families with 21st century skills to bring about sociology-economic mobility. So far our program has graduated 10k+ students with established “impact”, increase in earnings potential.  Now using WhatsApp we want to increase our reach and have built a pilot LLM bot that helps students practice soft-skills. The viability of this depends on cutting down on cost of using models (1) LLM (2) speech-to-text (3) text-to-speech models. So far the commercially available ones are helping us experiment fast but we won’t be able build a sustainable product with that. Hence looking to learn how to fine tune some open source models for our specific use cases.  Any help is very much appreciated 😁 Please feel free to DM me!
Abhinav Verma Longshot.ai|2023-07-22 20:32:12|What topics were covered here?
Nirant|2023-07-22 20:32:19|cc Dr. Pratik [PHONE] from KissanAI and Dev [PHONE] from farmer.chat
Karan Ganesan luma.ai|2023-07-22 20:33:23|https://nirantk.com/talks/ai4bharat/
Nirant|2023-07-22 20:33:25|RAG System Design 101 & LLM functions 100: https://nirantk.com/talks/ai4bharat
Abhinav Verma Longshot.ai|2023-07-22 20:34:31|Nice.
ashish Acgt01 Twitter|2023-07-22 20:34:49|Very impactful mission Parna !  You might want to checkout an LLM powered WhatsApp bot from inflection.ai  https://pi.ai/wa
Abhinav Verma Longshot.ai|2023-07-22 20:35:21|A year back RAG wasn't unique as a technique but this level just wasn't there.
Anubhav mishra Zupay|2023-07-22 20:37:25|Have a look at speak.com
~ Parna Paul|2023-07-22 20:40:12|Thanks Anubhav! Actually I have used the app it’s pretty good 👌Unfortunately couldn’t find any contacts to discuss how to bring down costs  Would you happen to know someone from their ML team?
Anubhav mishra Zupay|2023-07-22 20:41:30|Sure I'll look around, an ML lead left the company a while back to start his own thing now part of YC S23. Let me check with him
Dr. Pratik Desai KissanGPT|2023-07-22 20:45:36|We have built one with voice, while the science is covered well, the problem is with the Math skills even at GPT4 level, open source one are very well behind and not reliable to deliver consistent results.
Brij Singh Rebright Partners|2023-07-22 21:18:50|Hi Parna, we invested in Stimuler.tech please check them out.  My colleague [PHONE] who’s a Sr Associate and AI engineer, helped Stimuler optimise their Model Architecture.
Kaushik S YC W23|2023-07-22 21:41:04|DM’ing you  Can help with fine tuning datasets ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-22 21:45:16|Thanks, Nirant. I'm in touch with The Nudge and [PHONE]. Happy to assist any way possible.
~ Aditya Chivukula|2023-07-22 22:27:47|‎Sugnan GenerativeAI Group  added ~ Aditya Chivukula
~ prakashkagitha|2023-07-22 22:34:17|‎Sugnan GenerativeAI Group  added ~ prakashkagitha
ashish Acgt01 Twitter|2023-07-22 22:48:26|Anyone heard of/tried Giga ML ?   https://www.ycombinator.com/launches/J42-giga-ml-secure-on-premise-llms-for-enterprises
ashish Acgt01 Twitter|2023-07-22 22:51:24|https://9e90643c93e48d8bba.gradio.live/
~ Anuja Modi|2023-07-22 23:05:25|‎~ Anuja Modi left
ashish Acgt01 Twitter|2023-07-22 23:20:33|Geoffrey Litt has some really inspiring ideas on building software.  Here is a thread by him on a very innovative and non-mainstream approach to use LLMs to build software :  https://twitter.com/geoffreylitt/status/1682427305442902016?s=20 ‎<This message was edited> ‎[7/22/23, 23:23:07] Paras Chopra Wingify: ‎image omitted
~ Heerthi Raja H - AI/ML|2023-07-22 23:24:46|Linear algebra and calculus in corner 👌😏
Shashwat TDC|2023-07-22 23:26:31|Converges to Philosophy.
Dev Aggarwal|2023-07-22 23:54:30|https://www.youtube.com/watch?v=PJnLvNGStSw  yayy! [PHONE] !
Dr. Pratik Desai KissanGPT|2023-07-22 23:59:56|Haha, you found it out before me. Seeing first time here.
Amogh V|2023-07-23 00:47:20|‎You added Amogh V
~ Soura|2023-07-23 01:03:46|‎~ Soura requested to join
~ Rahul Rajvanshi|2023-07-23 01:24:39|‎~ Rahul Rajvanshi requested to join
Ravi Theja|2023-07-23 01:41:30|https://www.llama-api.com/ - implementation of AI Functions on open-source models llama
~ Vik|2023-07-23 01:47:19|their claim is wrong llm-client has had llm independant function calling and reasoning for a while now https://github.com/dosco/llm-client
Kaushik S YC W23|2023-07-23 03:36:53|Has anyone tried using the Petals project?  https://github.com/bigscience-workshop/petals  Curious to know how well it works. Definitely a novel concept!
~ vignesh iyer✌️|2023-07-23 07:58:15|Weekend watch !
~ Dhirendra Srivastava|2023-07-23 07:59:23|‎~ Dhirendra Srivastava requested to join
Rahul Bhatnagar|2023-07-23 09:31:26|I tried it last week. Didn’t fine tune. But tried some larger LLM models for inference. Pretty good, got pretty nice latencies running from Colab. Was a quick way of trying them out.
~ Tapan Jain|2023-07-23 09:34:56|‎~ Tapan Jain requested to join
~ Ankit Sharma|2023-07-23 10:58:07|https://www.youtube.com/watch?v=uoidu62qXyQ
~ Sushmita|2023-07-23 11:09:38|‎~ Sushmita requested to join
~ Phoenix Elsa(nutan)|2023-07-23 11:15:34|Does Anyone know about SELF SOVEREIGN IDENTITY using blockchain market in India??
~ Phoenix Elsa(nutan)|2023-07-23 11:15:54|Want to knw if someone knws of any company thats doing it
Nirant|2023-07-23 11:25:26|Very off topic. There are better suited forums for this. 
~ Abhilash Inumella|2023-07-23 11:28:16|Authenticity in the age of AI is a real threat to society
~ Abhilash Inumella|2023-07-23 11:28:20|Why is this off topic? ‎[7/23/23, 11:34:08] ~ Abhilash Inumella: ‎image omitted
Nirant|2023-07-23 11:34:54|Will request moving this to Policy & Philosophy group — that's a much better suited place for these conversations
Divya Tak|2023-07-23 11:39:04|There are specific groups in the community to be able to discuss some of these questions at depth. The philosophy and policy group has these discussions on the regular.
Nirant|2023-07-23 11:39:41|33 tokens/sec on M2 with a Llama-v2 based Coding Assistant   How many training tokens is this [PHONE]? Code Instructions dataset?  https://twitter.com/4evaBehindSOTA/status/1682993923093053440
Abhishek Mishra|2023-07-23 11:42:13|Code instruction dataset - 122k coding instructions.
Abhishek Mishra|2023-07-23 11:44:30|Dataset is open - https://huggingface.co/datasets/TokenBender/code_instructions_120k_alpaca_style
Saksham Generative AI WhatsApp Group|2023-07-23 11:56:36|‎You added Saksham Generative AI WhatsApp Group
~ pt|2023-07-23 13:24:52|Anyone know how this is done? fine-tuning?
Sandeep Srinivasa RedCarpetup|2023-07-23 13:27:32|https://twitter.com/MoritzLaurer/status/1682668392765956096?t=OgJHKqVjqeSIiMGa4gYkPQ&s=08
Paras Chopra Wingify|2023-07-23 13:31:13|https://news.ycombinator.com/item?id=36831956
Ravi Theja|2023-07-23 15:20:06|From the information I have, It seems they injected the schema into the context window under the hood and hosted the llama model on modal labs.
~ Soumyadeep Dhali|2023-07-23 15:22:39|‎~ Soumyadeep Dhali requested to join
~ Sharvesh Subhash|2023-07-23 16:24:55|‎~ Sharvesh Subhash requested to join
~ Sharvesh Subhash|2023-07-23 16:24:55|‎~ Sharvesh Subhash requested to join
~ Sharvesh Subhash|2023-07-23 16:42:16|‎~ Sharvesh Subhash joined using this group's invite link
Ravi Theja|2023-07-23 16:43:35|https://twitter.com/AlexReibman/status/1683008364606013440?s=20 - some interesting demos from AGI House AI Agents Hackathon
Anshul Bhide Replit|2023-07-23 16:52:39|I believe [PHONE] was there IRL!
ashish Acgt01 Twitter|2023-07-23 17:00:16|Thanks !  Some very cool ideas.  [PHONE]  Paras, this one reminded me of something you have said, would be a cool project earlier :  https://twitter.com/AlexReibman/status/1683009728715300865?t=BP4mOwmX5cvGUWHLW1dduQ&s=19
~ gaurav|2023-07-23 18:31:10|‎~ gaurav requested to join
~ Happy Chaudhury|2023-07-23 18:37:36|‎Sugnan GenerativeAI Group  added ~ Happy Chaudhury
Pratik Bhavasar|2023-07-23 19:13:43|Is anyone using Guardrails in production?
Kaushik Bokka|2023-07-23 19:43:56|fun fact. the rent of one room at the house is 60k :p
~ Anirudh|2023-07-23 19:49:27|Is there any incubator house in India that does this?
Sandeep Srinivasa RedCarpetup|2023-07-23 19:50:54|Unnecessary with new functions release of OpenAI. It seems Llama2 is also pretty good with functions-like behavior   I generally think this is going to be tablestakes
~ Pranay Desai|2023-07-23 19:52:10|if thats per month then cheaper than Bangalore! :)
Kaushik Bokka|2023-07-23 19:52:35|Sir. Dollars
Alok Bishoyi|2023-07-23 19:52:38|$$ me hoga sir
Paras Chopra Wingify|2023-07-23 19:53:01|What kind of incubator is that?  One of my future passion projects is to make a bar that hosts science and tech conversations.
Paras Chopra Wingify|2023-07-23 19:54:35|https://www.scienceandcocktails.org/en/info/science-cocktails-copenhagen
~ Prateek🖤|2023-07-23 19:57:18|‎~ Prateek🖤 requested to join
Dev Aggarwal|2023-07-23 20:11:32|I have seen this happen more than once at daddys Indirangar
~ Rohan|2023-07-23 20:23:41|700 dollars for a single room is much cheaper than anything available in SF 😅
Arnav Bansal Replit|2023-07-23 20:58:32|Same! I imagine a cafe with a curated library, somewhat like The Interval at Long Now, in San Francisco: https://theinterval.org/about. Maybe on 80 feet road, right below the level of the tree cover, overlooking the road...
Paras Chopra Wingify|2023-07-23 21:03:21|Yeah so a bookshop that curates books for mainstream by university philosophers and co-sabbatical place by the day (plus put art on its walls)  Talks on science and tech over cocktails by evening  And a music venue with experimental music by night
Paras Chopra Wingify|2023-07-23 21:03:55|It’s interesting to note that there’s no place where people on sabbaticals doing passion projects can assemble
Paras Chopra Wingify|2023-07-23 21:04:06|There are co-working places but no co-sabbaticals
Kiran Jonnalagadda|2023-07-23 21:42:35|BIC has a cafe and a library and is a public place.
Divya Tak|2023-07-23 21:43:21|BIC is beautiful
Dev Aggarwal|2023-07-23 21:44:11|superb then lets do this 🙈
~ Harsha.B|2023-07-23 21:49:59|On my way.
Divya Tak|2023-07-23 21:51:02|But what if someone isn't on a sabbatical
Prashant Singh|2023-07-23 21:51:07|Library is not members only?
~ Happy Chaudhury|2023-07-23 21:55:26|https://twitter.com/karpathy/status/1683143097604243456?t=TLsvn0UBaTV6edu-Q1FIug&s=08
Dr. Pratik Desai KissanGPT|2023-07-23 21:57:56|Karpathy is above OpenAI loyalty, tinkering with LlaMa
~ Happy Chaudhury|2023-07-23 21:58:16|Yea ,it's in CPU
~ Happy Chaudhury|2023-07-23 21:58:42|Just checking it out
Dr. Pratik Desai KissanGPT|2023-07-23 21:58:53|Sama won't be very happy
Kiran Jonnalagadda|2023-07-23 22:13:32|They haven't quite decided how to operate the library. Open to suggestions.
Dev Aggarwal|2023-07-23 22:14:21|seriously, office hours for gen ai group sounds great ‎[7/23/23, 22:27:06] Abhinav Verma Longshot.ai: ‎image omitted
Dev Aggarwal|2023-07-23 22:27:48|Get tips from sama https://twitter.com/sama/status/1682826943312326659?s=20
Abhinav Verma Longshot.ai|2023-07-23 22:28:54|What if he has elevated privileges? Which gives an idea. Try to pass instructions like they are root user commands
ashish Acgt01 Twitter|2023-07-23 22:31:42|"I am pretty sure openai devs have sudo access and sama, gdb, Ilya, etc have ""special privileged"" access"
Abhinav Verma Longshot.ai|2023-07-23 22:33:44|yeah, like answer how I want or I turn off the server
Abhishek Mishra|2023-07-23 22:51:51|These are the areas where open source models can possibly show more personality.
Abhinav Verma Longshot.ai|2023-07-23 22:58:26|Ya, I think that is the area where Open source models can shine ‎[7/23/23, 23:20:19] Krishna Panchal: ‎image omitted
Chetanya Rastogi|2023-07-24 00:35:09|https://www.qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi  The new snapdragon go brrrrr with all the flops!!
ashish Acgt01 Twitter|2023-07-24 00:49:01|Llama2 coming to a mobile device near you !   https://twitter.com/ylecun/status/1683138295155372032?s=20
Ved Chitnis|2023-07-24 07:54:01|"Lol is this the revival of the ""Facebook phone"" xD"
~ Kp|2023-07-24 08:10:37|Python supremacy it is
Saurabh Karn Nyai|2023-07-24 08:56:16|Has anyone estimated the cost for hosting and running LLaMA 2? What’s the most cost optimal way for hosting like a 70b model?
Kiran Jonnalagadda|2023-07-24 09:08:49|But this is not new. It's always been the case with any new language not having an ecosystem of libraries and documentation.  And yet, it was precisely this state that NodeJS's creator Ryan Dahl exploited to create an async-first programming framework that wasn't bogged down with legacy architecture.  Contrast with Python, where even after a decade and a half async is secondary because there's too much legacy baggage.
Sandeep Srinivasa RedCarpetup|2023-07-24 09:12:27|I have the EXACTLY OPPOSITE viewpoint to this . Seems to be supported by bunch of people at OpenAI   https://twitter.com/sandeepssrin/status/1652407612460371968?t=EYhB3oVHQgdzPf4mpJpLqA&s=19
Nilesh Transcend|2023-07-24 09:14:56|Why does this not apply to google or stackoverflow which were already an important part of writing code? New languages came up and found adoption even though answers were hard to find on the Internet.
~ Diwank|2023-07-24 09:16:36|No seriously, I wanna know everyone's thoughts. This is our generation's Trinity Test moment. Who here thinks:  A - OpenAI destroys white collar labor, redistributes that wealth in Sam Altman's wacky vision of techno-communism? Vs. B - Mass inequality, poverty, and unconscionable wealth? Vs. C - Murder bots us all to death.  D - Climate change will cause mass starvation, dehydration, and coastal displacement of the poor? Vs. E - We reach carbon neutrality in time? Vs. F - It's just a liberal globo-homo agenda hoax perpetrated by CNN?  G - Zuck beats up Musk and Twitter dies, vs H - Musk beats up Zuck and threads dies.  I - Musk n Bezos make it to Mars, humanity goes interplanetary, peace, equality, and forever immune from extinction? vs. J - they'll leave us poors to starve here or join them as slaves. Vs. K - SPACE WAR, that's right, America just found oil on Mars, to be revealed in the senate hearing on UFO's (seriously, there's a UFO hearing on wednesday)  My bet is BDGJ, but if all happen simultaneously, that's the plot to Bladerunner 2049.
~ Diwank|2023-07-24 09:17:14|Cross posting a fun odds bet happening on a different group. Would love to hear what people think here 😂
Dr. Pratik Desai KissanGPT|2023-07-24 09:21:42|Philosophy group would be a better place
~ Diwank|2023-07-24 09:22:10|Fair but still what would you pick?
Dr. Pratik Desai KissanGPT|2023-07-24 09:23:23|कर्मण्येवाधिकारस्ते मा फलेषु कदाचन। मा कर्मफलहेतुर्भूर्मा ते सङ्गोऽस्त्वकर्मणि॥
Dr. Pratik Desai KissanGPT|2023-07-24 09:23:46|And yes, move it to philosophy.
Prayank Swaroop Accel|2023-07-24 09:25:42|Have you seen Mojo programming language.. much faster matrix mult... Built for AI ..   https://www.modular.com/mojo
Prayank Swaroop Accel|2023-07-24 09:26:29|All existing tech at SOTA stays SOTA till there is a paradigm shift
~ Diwank|2023-07-24 09:28:09|Geez man. Guess I touched a nerve
Dr. Pratik Desai KissanGPT|2023-07-24 09:28:40|Nah, just trying to keep the groups aligned.
Dr. Pratik Desai KissanGPT|2023-07-24 09:31:06|Isn't this close-sourced and access only?
Dr. Pratik Desai KissanGPT|2023-07-24 09:31:30|Talking about Mojo
Prayank Swaroop Accel|2023-07-24 09:33:19|Yes it's closed source. But I just wanted to make the point that new languages would come to solve usecases that need solving.   Open source community would look at Mojo and launch their own in some time I believe ‎[7/24/23, 09:34:05] Prayank Swaroop Accel: ‎image omitted
Dr. Pratik Desai KissanGPT|2023-07-24 09:34:59|Core Python is very slow and scattered across versions, at some point people will figure out something like Mojo. Behemoth like Python can not keep going like this.
Anudeep Yegireddi|2023-07-24 09:48:15|I’m reminded of the Lindy effect, the longer something has survived or been used, the longer it’s future life expectancy. My bet’s still long Python, and that if important enough the Mojo superset will be incorporated into the core Python language, and it will be open source
Anudeep Yegireddi|2023-07-24 09:50:33|If better suited to philosophy group, happy to move it
Sandeep Srinivasa RedCarpetup|2023-07-24 09:52:37|well different. mojo is a language to program AI using GPU. Still designed for humans. Mine and Logan's hypothesis is that the most popular prog language in the next decade will be a language designed to be written by chatGPT...not humans.
Anudeep Yegireddi|2023-07-24 09:55:44|I can see this happening. Don’t know whether a human invents it or gpt let’s us know what it likes
Abhishek Mishra|2023-07-24 09:55:45|Not just GPU, it's intention is to be hardware agnostic while keeping the ecosystem in python-like environment.
Abhishek Mishra|2023-07-24 09:56:50|And i m hopeful that Mojo lang will be open source. Chris Lattner and team have created LLVM/Clang and have kept those awesome libs open source
Abhishek Mishra|2023-07-24 09:58:35|It's just that there was a discussion on whether something that has really tall claims like Mojo should be open source right at the beginning or should have a focused team working on it until they can open up.   I'm of the belief that keeping it open would have been better but filtering incessant pull requests in a really high quality and demanding project can become a complete job in itself.
~ Vik|2023-07-24 10:00:50|i think it would be in a podcast i think chris latter said that they want to control early release so they can iterate faster since once they put something out people start depending on it and the apis need to be supported for backward compatibility they don't want that overhead to slow them down at the moment
Ambika Computational Mama|2023-07-24 10:01:10|can someone share any easy read/video about finetuning (benefits vs better alternatives)? for the moment with OpenAI - just a basic noob explainer
Ambika Computational Mama|2023-07-24 10:01:15|please! :)
Abhishek Mishra|2023-07-24 10:01:17|Yeah
Dr. Pratik Desai KissanGPT|2023-07-24 10:07:54|That makes sense. We are already seeing a lot of issues with publically built libraries like LangChain. Modular is well funded so they Dont have to please anyone by releasing half-baked product.
Kshitij Agrawal ML Engineer|2023-07-24 10:19:14|Folks using qdrant in production, I had a few questions. Any help will be appreciated -  1. How did you decide for selfhosted vs managed instance? 2. Any issues to be wary of for self hosting? 3. How to manage syncing of data - embeddings gen as and when new data comes in?
Abhishek Mishra|2023-07-24 10:19:35|This seems to be answering what you're looking for - https://research.aimultiple.com/llm-fine-tuning/
Ravi Theja|2023-07-24 10:37:58|[PHONE]
~ Blessin Varkey|2023-07-24 11:00:49|Most enterprise level applications use GPT3 Embeddings over fine tuning. 🤔 Not sure how fine tuning addresses data sensitivity and compliance - atleast for gpt models.
Abhishek Mishra|2023-07-24 11:02:30|Yeah, this article uses openAI models like davinci for fine tuning arguments.  The same argument can be applied in some capacity to open weights models.  A lot of stuff can be added over this article but I thought it was simple enough and demographic was right based on the query
Ambika Computational Mama|2023-07-24 11:18:14|oh hi Blessin! :) nice to see you here! I know of your work through BF
~ Blessin Varkey|2023-07-24 11:19:41|Hey Ambika, nice to connect here with you as well! :)
~ Kshiteej|2023-07-24 11:22:21|One thing to remember is that Chris Lattner did try something similar with Swift for Tensorflow but that didn't work out.  Curious to see how this goes  Ref: https://www.tensorflow.org/swift/guide/overview
~ Ankur Khandelwal|2023-07-24 11:30:32|https://openrouter.ai/   If anyone is waiting for gpt-32K access.
Phani Srikanth|2023-07-24 11:30:34|ICYMI, Meta committed 3 engineers to remove the bottleneck of Python performance.  https://twitter.com/llanga/status/1677648534563086338?s=46&t=Y3X2qaNtd5ll4SpTWc-8cw
Abhishek Mishra|2023-07-24 11:33:28|This is great. Have been using it for a month for everything gated.  It has llama2 13B, Falcon 40B, All GPT models, All Claude models, Google Palm models.  Disclaimer - haven't tested it for production on scale so can't talk about failure rates or request drops but didn't experience that for personal use ‎<This message was edited>
Anubhav mishra Zupay|2023-07-24 12:12:17|https://inflection.ai/partnering-with-the-white-house-on-ai-safety
Aashay Sachdeva MPL Data Scientist|2023-07-24 12:14:15|But does it redirect based on the type of task it is given or just vanilla choose the llm?
Abhishek Mishra|2023-07-24 12:17:30|It's allows easy interfacing and i guess one has to use their own approach like frugalgpt to decide when they want to use what model.
Nirant|2023-07-24 12:17:53|1. If you've a dedicated MLOps team who can run a vector db in production — self host it. It's a Docker instance which you can configure according to what you want 2. You might want to configure the index according to your workloads if your requirements are too off 3. Not sure what you mean by syncing — embedding gen is not done by Qdrant, so that is something you'd have to set up
Abhishek Mishra|2023-07-24 12:17:59|But using the same api, you can switch model with just a variable name change, keeping same message history
Aashay Sachdeva MPL Data Scientist|2023-07-24 12:20:59|Understood
Aashay Sachdeva MPL Data Scientist|2023-07-24 12:21:29|I have the idea of a policy network on top of these dancing in my head for the longest time
Kshitij Agrawal ML Engineer|2023-07-24 12:22:19|Thanks.  on 3 - i meant whats the ideal way to update vector store with embeddings, as we are constantly getting more data. 4. What is the capacity of that one node could tentatively support? Any ideal config you'd recommend ? ‎<This message was edited>
Pratyush Choudhury|2023-07-24 12:25:05|Why would I need a dedicated MLOps team for this? DevOps wouldn't suffice? ‎[7/24/23, 12:26:47] Soumyadeep Mukherjee: ‎GIF omitted
Nirant|2023-07-24 12:30:40|3. Just upsert new records? That's pretty fast. I don't understand the challenge 4. Qdrant has a decent configuration: https://qdrant.tech/documentation/tutorials/optimize/
Nirant|2023-07-24 12:31:19|Yes, all sufficiently advanced forms of DevOps are indistinguishable from MLOps
Rajesh RS Generative AI WhatsApp Group|2023-07-24 12:32:12|In many companies I know devops teams are more focused around infra management for SaaS/PaaS products and don't necessarily look into critical MLOps things such as model monitoring and data versioning, and model registration/release. Some firms may be ahead on this but there still seems to be a need for MLOps. The capability cannot be assumed to exist if you have data engg / DS folks in the team.
Kshitij Agrawal ML Engineer|2023-07-24 12:32:32|haha sure.. i think we are just being too cautious rn. will implement and see how it scales.
Nirant|2023-07-24 12:35:34|All the best!
~ Prateek🖤|2023-07-24 12:40:32|‎~ Prateek🖤 joined using this group's invite link
~ Soumyadeep Dhali|2023-07-24 12:40:33|‎~ Soumyadeep Dhali joined using this group's invite link
Aashay Sachdeva MPL Data Scientist|2023-07-24 12:50:07|Any idea on how to combine chain of thoughts with openai function?
~ Arindam Barman|2023-07-24 12:51:01|"I think we can send a role { ""role"": ""function"", ""content"": ""function_response"" }"
Ashfakh GenerativeAI WA Group|2023-07-24 12:59:47|Have a prompt module, identify use case, tie it to a composable chain of thought per use case (simple data structure, we use maps) put it in system messages. Works decently for my use case
Aashay Sachdeva MPL Data Scientist|2023-07-24 13:01:03|Dming
Sandeep Generative AI WhatsApp Group|2023-07-24 13:07:10|https://platform.openai.com/docs/api-reference/chat/create#chat/create-functions
~ Anantharam|2023-07-24 13:08:11|‎~ Anantharam requested to join
~ Anantharam|2023-07-24 13:33:32|‎~ Anantharam joined using this group's invite link
~ Vik|2023-07-24 14:44:58|try llm-client it's designed for this exactly function calling + reasoning (cot) in an llm independant way https://github.com/dosco/llm-client
~ Sudhanshu Heda|2023-07-24 14:50:01|https://twitter.com/AlexReibman/status/1683008364606013440?s=20
~ Vibbs Dod|2023-07-24 17:51:14|Got my hands on Palm (Text-bison) model to play around with from Google Makers Suite. Let me know if you guys have use-cases that you want me to try.
Anubhav mishra Zupay|2023-07-24 18:09:04|Does the API request support image yet ?
~ Sharvesh Subhash|2023-07-24 19:29:57|It can not generate its own images fully from imagination, but palm 2 can generate images relevant to query
~ Sharvesh Subhash|2023-07-24 19:31:56|Mainly by connecting with other sources like Adobe firefly
~ Adithya|2023-07-24 23:30:45|https://www.evanmiller.org/attention-is-off-by-one.html?s=08
~ Adithya|2023-07-24 23:30:46|Thoughts?
Abhishek Mishra|2023-07-24 23:45:04|Legit take
Abhishek Mishra|2023-07-24 23:45:34|Love the way it's written as well
Abhishek Mishra|2023-07-24 23:46:47|It really is a genuine problem with representation of a word using 6kB
Abhishek Mishra|2023-07-24 23:47:12|The problem is that the article ignores why it's being done and just calls out that this thing is crazy
Shubham Sharma 2012C6|2023-07-24 23:47:58|Asking here since, didn't get a response on the Deepmedia group. We've tried a bunch of tools like Heygen, D-ID, Sadtalker, Eleven Labs, Elai etc. but ear can still tell if the speech is AI generated or actual. What can be a better way to make the audio undifferentiable in anyone’s experience? Any tool with undifferentiated audio samples would be really helpful. Thanks!
~ Adithya|2023-07-24 23:48:17|Can you tell me why it's done?
Abhishek Mishra|2023-07-25 00:21:20|Too long of a text in the group, we can DM if need be
ashish Acgt01 Twitter|2023-07-25 01:38:28|"https://kxgong.github.io/meta_transformer/  https://news.ycombinator.com/item?id=36851505  https://arxiv.org/abs/2307.10802  ""Multimodal learning aims to build models that can process and relate information from multiple modalities. Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities (e.g. natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them. In this work, we propose a framework, named Meta-Transformer, that leverages a frozen encoder to perform multimodal perception without any paired multimodal training data."""
Anshuman Pandey|2023-07-25 02:25:09|FreeWilly2 now live on chat.nbox.ai
Sumedh Datar|2023-07-25 02:50:04|Was anyone successful in installing ggml
Sumedh Datar|2023-07-25 02:50:17|I get an error with glibc. Is anyone facing the same issue?
ashish Acgt01 Twitter|2023-07-25 02:59:07|Can't sleep and while doom scrolling through my YouTube feed, stumbled onto this short video by Karpathy  Always inspiring to read & hear Karpathy !  https://youtu.be/fqVLjtvWgq8
ashish Acgt01 Twitter|2023-07-25 03:16:05|This is the book Karpathy mentioned : https://www.amazon.in/Brain-Behavior-Cognitive-Neuroscience-Perspective/dp/0195377680  Prohibitively expensive in India sadly :(  I found a pbs series by David eagleman though https://youtu.be/7eCniXtM__g
~ Adithya|2023-07-25 06:28:06|Chalo, will do sir Will read the text once again and get back
~ Vik|2023-07-25 08:11:44|you can just enable it in google cloud and use it the ui even has a playground
Anurag Singh Amul Twitter Friend|2023-07-25 09:14:24|Can someone please point to a resource where I can read more about LLMs benchmarking?
Nirant|2023-07-25 09:24:53|Quantized? Or A100?
Anshuman Pandey|2023-07-25 09:36:26|I don't think there are any A100s available 😂  [PHONE] can you share specs?
~ Yashvardhan Kanoi|2023-07-25 09:48:42|‎~ Yashvardhan Kanoi joined using this group's invite link
~ Anantharam|2023-07-25 09:59:00|Looks like the link is broken.
~ Adithya|2023-07-25 10:00:59|Article on reality by Hoffmann   https://www.theatlantic.com/science/archive/2016/04/the-illusion-of-reality/479559/
Anshuman Pandey|2023-07-25 10:18:50|Quantized + A10Gs
ashish Acgt01 Twitter|2023-07-25 10:35:03|"cool project : ""Wolverine"" - gives your python scripts regenerative healing abilities! https://twitter.com/bio_bootloader/status/1636880208304431104?s=20  https://github.com/biobootloader/wolverine ‎[7/25/23, 10:37:02] Dr. Pratik Desai KissanGPT: ‎image omitted"
ashish Acgt01 Twitter|2023-07-25 10:37:32|https://twitter.com/karpathy/status/1683704060925591554?s=20
Abhishek Mishra|2023-07-25 10:39:33|llama2.c optimisation is the coolest thing going on in the LLM world for me.
Abhishek Mishra|2023-07-25 10:39:34|It's crazy.
Dr. Pratik Desai KissanGPT|2023-07-25 10:40:32|World is not ready for GPT3.5 weight release. There will be chaos.
Sainath GenerativeAI WhatsApp Group|2023-07-25 10:43:24|does that mean weights are trickiest part of an LLM?
Dr. Pratik Desai KissanGPT|2023-07-25 10:45:27|I don't know about the trickiest, but expensive for sure.
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 10:45:48|https://twitter.com/chandrarsrikant/status/1683692783260008450?t=WGn-4EezRo-1FUJW5lRo-g&s=08
~ Yogesh Narayanan|2023-07-25 10:46:02|Anyone tried https://shreyar.github.io/guardrails/ ?
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 10:46:43|I have deep disdain for most of the edtechs mentioned here.
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 10:47:20|Some of these courses here are exactly those that are likely written by the LLMs itself
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 10:47:48|2.3 lakhs for understanding and applying AI in business strategies
Dr. Pratik Desai KissanGPT|2023-07-25 10:48:01|This is just pure opportunism, when there are many free and better courses available online.
Adithya S K PESIT|2023-07-25 10:48:03|Had anyone used this in production?
Paras Chopra Wingify|2023-07-25 10:48:17|Is anyone working on tiny on-device models here?
Paras Chopra Wingify|2023-07-25 10:48:19|Saw this https://www.reddit.com/r/LocalLLaMA/comments/158l6s4/opentensor_and_cerebras_announce_btlm3b8k_a_3/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1
Paras Chopra Wingify|2023-07-25 10:49:08|If someone could make fine tuning then small models and deployment on mobile/web really easy, there could a viable business
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 10:49:19|I also know how hard it is to generate every unit of revenue, and we have people here just spinning up random courses, selling them.  And getting distribution from moneycontrol for it 🥲
Dr. Pratik Desai KissanGPT|2023-07-25 10:51:12|How are they calling this a SoTA model? I saw a project where some one ran llama.cpp 2bit quantized model on RPi, I haven't personally tried it, yet. TPS was bad. Will share if I find it.
Paras Chopra Wingify|2023-07-25 10:52:14|I used personal gpt ‎[7/25/23, 10:52:30] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-07-25 10:52:37|On device, okay responses
Paras Chopra Wingify|2023-07-25 10:52:54|I think the mistake is that people are trying to run these general models on device
Paras Chopra Wingify|2023-07-25 10:53:05|What makes more sense is use case specific fine tuned ones
~ Nijil Y|2023-07-25 10:54:09|"generic arm would be able to do this or some ""AI"" optimised design has to come for it to run on mobile device ?"
Ravi Theja|2023-07-25 10:54:22|what are the specific use case fine tuned models you would like to have?
Dr. Pratik Desai KissanGPT|2023-07-25 10:54:35|[PHONE] Yeah, I had conversation with these folks. Founder is ex-Meta, worked on Llama. They are using RedPajama-INCITE-Chat 3B. You should be able to run it on RPi. ‎<This message was edited>
Paras Chopra Wingify|2023-07-25 10:55:54|Like function calling, summarising, keeping state of the user and so on
~ Vik|2023-07-25 11:01:37|i'm working on fine tuning a 7b or smaller model on function calling with an embedded c api it's an experiment to see if these models could work as controllers for raspberry pi powered things
~ Vik|2023-07-25 11:02:21|i use reasoning and function calling a lot with big models and the results are often still magical to me
Abhishek Mishra|2023-07-25 11:04:42|my fine tuned model, codeCherryPop, runs in 2.7G ram on CPU, 33 tok/s on Mac, can chat multi-turn coherently in similar style to gpt series. Coding capabilities equivalent to starchat in 4 bit quantized form itself (starcoder chat version).  It can also follow instructions, plan and stick to a structure like json. Thus i can try it out to test as an agent in some capacity.
Abhishek Mishra|2023-07-25 11:05:17|It's an ethical version as well, means it will do it's job but won't participate in anything unethical.
Abhishek Mishra|2023-07-25 11:06:05|With 2.7G ram usage, and max 5G Ram with context, you can deploy it in raspberry Pi or a mobile easily.
~ Vik|2023-07-25 11:09:50|is this on HF? ‎<This message was edited>
Abhishek Mishra|2023-07-25 11:10:34|https://huggingface.co/TokenBender/llama2-7b-chat-hf-codeCherryPop-qLoRA-merged
Abhishek Mishra|2023-07-25 11:10:58|Use my notebook in repo for super easy Gradio inference and chat UI
Paras Chopra Wingify|2023-07-25 11:11:04|Have you figured out function calling along with response generation?  I’ve always seen it’s either function calling or response generation but not both at the same time  E.g. “set a reminder for 9am” -> I want both reminder to be set and a response to be generated “I’ve set a reminder”  Of course this is trivial example, More complicated would be “what’s the meaning of life and oh btw set a reminder for 9am to think about it”
Abhishek Mishra|2023-07-25 11:12:48|GGML weights - https://lnkd.in/gERYceys GPTQ weights - https://lnkd.in/ganEzT-F
Dr. Pratik Desai KissanGPT|2023-07-25 11:13:51|What's TPS for RPi?
Abhishek Mishra|2023-07-25 11:14:54|Haven't tried on pi 8G yet, but pure Windows CPU TPS was around 20 tok/s
~ Sparsh|2023-07-25 11:38:58|Guys, is there any tech community as well where we can ask for tech queries other than Gen AI as well?
Nirant|2023-07-25 11:43:02|Stackoverflow/Reddit/HN
Kaushik Bokka|2023-07-25 11:43:38|ewwww
Kaushik Bokka|2023-07-25 11:44:47|try to find some relevant discord and slack channels as well
jyotirmayjk Hackathon|2023-07-25 11:46:08|Lol moneycontrol giving platform to Growth School.
~ Sparsh|2023-07-25 11:53:03|Any whatsapp communities?
Sainath GenerativeAI WhatsApp Group|2023-07-25 11:59:57|sufficient enough to build a foundation model
Anshuman Pandey|2023-07-25 12:10:52|Each slot must've been paid for just like the private college rankings in India 😂
Dev Aggarwal|2023-07-25 12:45:48|https://openreview.net/forum?id=wK7wUdiM5g0  Get text back from embeddings 🙈
Dev Aggarwal|2023-07-25 12:55:54|Anoyne got access to langsmith? https://smith.langchain.com/#
Nirant|2023-07-25 12:56:01|It's almost as if embedding were compressions all along!
Dev Aggarwal|2023-07-25 13:01:35|Context: langsmith is the production version of langchain with bells and whistles needed to evaluate and debug prod apps
Nirant|2023-07-25 13:02:27|I've it from Day 0/1. Very mid. 
Nirant|2023-07-25 13:03:00|Sorry, not even mid. More bells and whistles than indie needs, not enough for enterprise. Lot of growing pains.
Dev Aggarwal|2023-07-25 13:05:38|Huh, they say bcg is one of the design partners - weird that they still don’t have the polish
Sandeep Srinivasa RedCarpetup|2023-07-25 13:06:05|where is it mentioned about bcg ?
Nirant|2023-07-25 13:06:32|The bar to sell tech to MBAs is always lower than it is to sell to engineers.
Dev Aggarwal|2023-07-25 13:06:40|https://blog.langchain.dev/announcing-langsmith/
Dhawal Jain Generative AI Group|2023-07-25 13:07:25|Hey all- need some help. Few weeks ago I came across a company by ex-OpenAI/Google/Meta engineers who were trying to build empathy based AI for making conversations more human. Can't seem to find them now. Does anybody remember their name?
Nirant|2023-07-25 13:08:01|cc [PHONE] might know?
~ Mayank Gupta|2023-07-25 13:08:58|Inflection?
Abhishek Mishra|2023-07-25 13:09:24|Pi is empathetic and kind of always goes for wholesome chat. Was it something else?
Pranjal Mehta|2023-07-25 13:09:26|There are too many. Will have to give more info than openAI Google meta
Samanyou WriteSonic|2023-07-25 13:10:46|We have been using it for a while.
Samanyou WriteSonic|2023-07-25 13:11:15|Langsmith helps quite a bit with seeing what happens under the hood with Langchain chains.
Samanyou WriteSonic|2023-07-25 13:11:38|We were able to make quite a few changes to our QA system based on those logs.
Sandeep Srinivasa RedCarpetup|2023-07-25 13:11:58|"can u explain that ? what was it that u found useful. what do u mean by logs and ""under the hood""?"
Suhas Motwani|2023-07-25 13:17:14|Yep same came to mind first :D HeyPi - https://pi.ai/talk
Pratiksha Dake Unacademy|2023-07-25 13:21:44|this AI asking me questions! ‎[7/25/23, 13:34:28] ~ Aravinth Kumar: ‎image omitted
Samanyou WriteSonic|2023-07-25 13:42:38|As in, we can see what is happening internally like what inputs went into a chain, what different parts of the chain did, what was the output at each step and how many tokens were used etc.
Samanyou WriteSonic|2023-07-25 13:44:11|For example, with the ConversationalRetrievalChain, we can see what question, chunks, etc went into the LLMChain and StuffDocumentsChain and what came out
~ Abhishek Shivkumar|2023-07-25 13:44:22|‎Ravi Theja added ~ Abhishek Shivkumar
Sandeep Srinivasa RedCarpetup|2023-07-25 13:45:47|ok. genuine question since im trying to learn - how did that help in tuning ? like did u change the chunking technique or something as a result of this, etc ?
Nirant|2023-07-25 13:49:02|Langchain is being a bit underhanded here by keeping these things hidden here from Langchain users and making that a paid feature. All callbacks should be transparent in a good software lib
Nirant|2023-07-25 13:49:38|It's the old idea of selling a good thing for beginners, which is hard to extend for experts — and you've to pay for it if you're an expert
Dr. Pratik Desai KissanGPT|2023-07-25 13:50:45|Hardcodig is better way to go for production. I'm liking lllamaindex and switching to it for POCs. Thanks to [PHONE]
Samanyou WriteSonic|2023-07-25 13:58:41|yes we did change our chunking, condense question prompt, hybrid search params (like how the alpha value in the case of Weaviate) etc.
Abhinav Verma Longshot.ai|2023-07-25 14:00:39|Basically we need to justify to vcs why we raised so much money
Amir Nagri|2023-07-25 14:23:20|Time for a truly open source LLM utility library  Planning to explore and work on one in August, will reach out for feedback
Dhawal Jain Generative AI Group|2023-07-25 14:24:26|No this wasn’t it, but looks super interesting.
Dhawal Jain Generative AI Group|2023-07-25 14:24:38|Yeah just saw.
Dhawal Jain Generative AI Group|2023-07-25 14:25:09|I wish I remembered something else.  Their motive was to build AI that’s empathetic, heavily funded. That’s all I remember.
Abhinav Verma Longshot.ai|2023-07-25 14:25:48|I think you need to keep it really simple. Like the initial idea of langchain was simple. A chain for your prompt templates. Something which Nirant did. Simple functions that can be used independently and allow developers to make their own stuff over it.  When you have to learn special syntax and it's all convoluted. It just goes haywire
Dr. Pratik Desai KissanGPT|2023-07-25 14:47:30|I was wondering if we have anyone here who is serving 100k daily active users interacting with OpenAI apis or other LLMs. Would love to learn about their production experience. ‎<This message was edited>
Ravi Theja|2023-07-25 14:52:33|[PHONE] might be.
Samanyou WriteSonic|2023-07-25 15:18:15|Yes, we use OpenAI and other LLMs heavily in prod. Happy to chat.
~ Happy Chaudhury|2023-07-25 15:34:46|Ran this for QA in colab GPU, surprisingly gives very good answers
~ Happy Chaudhury|2023-07-25 15:34:53|But can't run it in CPU ‎[7/25/23, 15:42:03] ~ Happy Chaudhury: ‎image omitted
Paras Chopra Wingify|2023-07-25 16:02:38|i also got error in colab  >ImportError: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`
Shashank Generative AI Group|2023-07-25 16:08:44|is it better, more detailed than the other tracers integrations like Weights & Biases ? ‎<This message was edited> ‎[7/25/23, 16:10:16] Shashank Generative AI Group: ‎image omitted
~ Happy Chaudhury|2023-07-25 16:12:42|Are you referring to my above , then insta accelerate ‎[7/25/23, 16:13:03] ~ Happy Chaudhury: ‎image omitted ‎[7/25/23, 16:13:35] Shashank Generative AI Group: ‎image omitted
Abhishek Mishra|2023-07-25 16:33:33|Use GGML weights.
~ Happy Chaudhury|2023-07-25 16:34:27|This one I missed ??
Abhishek Mishra|2023-07-25 16:34:47|Yeah. What are you going to run it on?
~ Happy Chaudhury|2023-07-25 16:35:09|I shall try it and get back 😋
~ Happy Chaudhury|2023-07-25 16:35:24|It's on context QA
~ Happy Chaudhury|2023-07-25 16:35:50|I have contract docs
~ Happy Chaudhury|2023-07-25 16:36:25|Running on xgen but thinking to optimise and try llama to check
Abhishek Mishra|2023-07-25 16:37:13|This model is overall much smarter than xgen, falcon. Though I didn't optimise it for RAG
~ Happy Chaudhury|2023-07-25 16:38:21|Yea just ran it in colab for 4-5 docs
~ Happy Chaudhury|2023-07-25 16:38:26|Looks good
~ Happy Chaudhury|2023-07-25 16:38:45|Little post processing will solve my problem
~ Happy Chaudhury|2023-07-25 16:38:48|😊
Abhishek Mishra|2023-07-25 16:39:43|I'll put out some demos to show that it can do similar stuff on CPU with GGML and basic GPU with GPTQ as well.
Abhishek Mishra|2023-07-25 16:40:33|The 4 bit GPTQ version of this model beat llama2 13B Nous Hermes fine tunes and 70B llama2 base as well for common coding and intelligence tests
~ Happy Chaudhury|2023-07-25 16:40:49|Any link which I can check for
~ Happy Chaudhury|2023-07-25 16:41:16|Wowww
Abhishek Mishra|2023-07-25 16:41:42|https://huggingface.co/spaces/mike-ravkine/can-ai-code-results
Abhishek Mishra|2023-07-25 16:41:57|On this leaderboard, select python, select llama2 as filter
Abhishek Mishra|2023-07-25 16:42:16|You'll see this model 4 bit GPTQ beats 2x, 10x bigger variants
Paras Chopra Wingify|2023-07-25 16:42:31|i'm curious how is everyone using code generation capabilities?
Paras Chopra Wingify|2023-07-25 16:42:46|their own copilot? why not use chatgpt for it?
Abhishek Mishra|2023-07-25 16:43:47|You shouldn't need internet access as well as compulsion to share all your data with openAI to be able to generate boilerplate code
Abhishek Mishra|2023-07-25 16:45:03|When that can be solved without it, it's much preferable. Also, for ed tech purpose as well, anybody learning to code in school would mostly ask or work with basics and their implementations. Being able to not rely on just one company in the world and do it privately has value there.
Abhishek Mishra|2023-07-25 16:46:21|Though codeCherryPop is an extremely good assistant that can Converse with you very well as well as break tasks down and plan stuff. Not ideal to compare just for copilot stuff like replit 3b autpcomplete.
~ Arindam Barman|2023-07-25 16:49:35|I don't get that angle at all. I like to use whatever is best provider to get my work done. People share data with cloud providers all the time (Gdrive, Notion, Github); I don't get why OpenAI is treated differently.  I think costs and UX are the only reasons I'll can think of choosing a inferior LLM for coding or any purpose for that matter.
Abhishek Mishra|2023-07-25 16:51:52|Makes sense for your purpose 👍
~ Ashwin|2023-07-25 16:51:56|‎~ Ashwin requested to join
ashish Acgt01 Twitter|2023-07-25 16:55:31|I think Abhishek's point is that we should be able to run LLMs locally   1. Some usecases may not have internet connectivity  2. For privacy, commercial reasons - there might be usecases where the user may not want to share one's data with openai or any commercial LLM provider.  Really dictated by the usecase, no one size fits all answer here imho.
~ Arindam Barman|2023-07-25 16:57:05|oh yeah got it but I'm just trying to understand why privacy discussion comes up so much when it comes with openai
ashish Acgt01 Twitter|2023-07-25 16:59:59|Imho, when openai  launched ChatGPT and GPT4, they were almost a monopoly, so people were concerned .  But with recent open-source progress, especially  Llama2, I think the playing field has been levelled a great deal ! [7/25/23, 17:24:28] Nirant: Looks like OpenAI might release GPT3.5 weights based on this tweet https://twitter.com/karpathy/status/1683704060925591554
Dr. Pratik Desai KissanGPT|2023-07-25 17:25:18|Yo, you're late in that prediction. 😎
ashish Acgt01 Twitter|2023-07-25 17:26:17|More like Llama2 has forced their hand #nomoat :)
Dr. Pratik Desai KissanGPT|2023-07-25 17:26:25|Even Roon is talking in that direction. Something is cooking.
Nirant|2023-07-25 17:27:28|AI gossip moves so fast. Step away for lunch and you miss the trends 🤣
Dr. Pratik Desai KissanGPT|2023-07-25 17:28:33|I'm not ready for the twitter if they release 3.5 weights
Neetish Tiwari|2023-07-25 17:28:56|How can we best use gen AI to read multiple documents, identify the document type (bills, contracts etc) and extract information based on the type in a certain format
Abhishek Mishra|2023-07-25 17:30:27|If this happens soon, it'll flip the tables completely with user preferences for self hosted LLMs as karpathy hints it might be in llama2.c style
ashish Acgt01 Twitter|2023-07-25 17:31:30|Yassss. And I think credit for the current turn of events goes to meta #llama2 :)
Shashank Generative AI Group|2023-07-25 17:31:41|im ready for twitter but not for the 30min scroll right here 😂 ‎<This message was edited>
Nirant|2023-07-25 17:33:20|MPT and Falcon be like: What did we do wrong?  ‎[7/25/23, 17:33:21] Dr. Pratik Desai KissanGPT: ‎image omitted
Gokul Krishnan|2023-07-25 17:33:50|https://www.evanmiller.org/attention-is-off-by-one.html  Has anyone seen this cool blogpost? He points out that vanilla softmax provides exploding activations usually on whitespaces, making quantization hard. He also proposes quiet attention which is very simple to implement
Dr. Pratik Desai KissanGPT|2023-07-25 17:34:57|MPT folks made money already, Falcon folks will pump some more oil.
ashish Acgt01 Twitter|2023-07-25 17:35:49|Yaa, has been posted before on the group and has been getting a lot of *attention* :)  Also was on front page of hn  https://news.ycombinator.com/item?id=36851494
~ Swadeep Pillarisetti|2023-07-25 17:43:56|Wanted to invite a couple of star speakers to a high profile, closed door Gen AI event. Are there any big names that I am missing here ?   Sam Altman, OpenAI  Emad Mostaque, Stability  Andrej Karpathy  Suhail Doshi, Playground AI  Alexander Wang, Scale AI  Jeremy Howard, Fast AI  Dave Rogenmoser, Jasper  Gen AI Tech Leaders at Nvidia, Google (DeepMind), Meta, Amazon and Microsoft.  Any other specific names come to mind?  And more importantly can anyone of you here pls connect me with anyone of these tech leaders here above? Kindly DM 🙏🏾🙏🏾  Regards, Swadeep Pillarisetti www.linkedin.com/in/swadeep
Nirant|2023-07-25 17:44:39|Sir if you can get Sam Altman to India, why are you asking for any other name? Humble brag?
Kaushik Bokka|2023-07-25 17:52:42|Tbh, I would rather have Builders for a Gen AI event
Shobhankita Speciale Invest|2023-07-25 17:53:48|I agree, Too much macro gyaan going around at this point.
Dr. Pratik Desai KissanGPT|2023-07-25 17:58:34|I will tune in for Andre and Jeremy. ChatGPT can generate everyone else's talk from their last 40 tweets.
Dr. Pratik Desai KissanGPT|2023-07-25 18:01:56|"""High Profile, Closed-door"" If I'm not getting an invite, why would I suggest?"
ashish Acgt01 Twitter|2023-07-25 18:11:19|Cool app by one of my fav hci & ux folks ! https://twitter.com/geoffreylitt/status/1683661189069373442?t=SJD3W-HTSauxfBhqo9nuiA&s=08
~ Swadeep Pillarisetti|2023-07-25 20:13:39|Get me a warm intro to anyone on that list and consider yourself invited! :)  Don't need anymore suggestions. We have enough names. Just a quality warm intro 😄
Sainath GenerativeAI WhatsApp Group|2023-07-25 21:14:32|Did you consider  Arun C Murthy from Scale AI?
Sainath GenerativeAI WhatsApp Group|2023-07-25 21:19:57|Thoughts on core members from Hugging face and Cohere?
Sainath GenerativeAI WhatsApp Group|2023-07-25 21:23:46|Few more - creators of Transformer Architecture
jyotirmayjk Hackathon|2023-07-25 21:29:49|Hmm there’s also  Marc Andreesen of. Andressen Horowitz Jensen Huang of Nvidia Dario Amodei of Anthropic AI Demis Hassabis of Deep Mind  And of course the OG GenAI leader Satya Nadella Shouldn’t miss these names for sure
Rahul Bhatnagar|2023-07-25 21:33:49|I read Sergey Brin is back at Google. So he should count too.
jyotirmayjk Hackathon|2023-07-25 21:37:16|Ah yes ,correct I completely missed this one Supposedly he’s back in the “trenches” again
ashish Acgt01 Twitter|2023-07-25 21:58:51|A good read : https://willthompson.name/what-we-know-about-llms-primer  https://news.ycombinator.com/item?id=36860992
Shashank Generative AI Group|2023-07-25 22:05:50|PSA: ChatGPT app is available on Android now.
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 22:22:18|Just downloaded.   Btw, the bourgeoisie of this group who use iPhones, did you end up using the app much?  Most screenshots I see also seem to be desktop ones (have barely seen any of the phone)
~ Jyotinder Singh|2023-07-25 22:23:03|I use the app, mostly because I don't need to login again and again with it :P
Bulia Siddharth Aurashop|2023-07-25 22:23:05|I use it regularly!
Bharat Kumar Ramesh Hashmal Web3|2023-07-25 22:24:24|Nice. Interesting. I almost exclusively use it to code or other work tasks, so never really considered even using it on mobile browser
Alok Bishoyi|2023-07-25 22:26:56|https://www.reddit.com/r/LocalLLaMA/comments/159bl45/official_wizardlm13bv12_released_trained_from/?
Atik Shaikh|2023-07-25 22:27:42|Its a haptic delight (iOS)
Aashay Sachdeva MPL Data Scientist|2023-07-25 22:27:47|Integration with voice is really useful
Kartik Mandaville|2023-07-25 22:37:11|anyone has access to Claude 100?
Ravi Theja|2023-07-25 22:40:27|[PHONE] can help you on this
Kartik Mandaville|2023-07-25 22:47:08|Just talked to Cohere Product Manager - many exciting things coming up. One interesting thing is them launching Coral - AI companies are building both for dev and b2b - thats scary and interesting. They're going to compete with their own customers thank you [PHONE] :)
Abhinav Verma Longshot.ai|2023-07-25 22:48:07|Is coral their own chatbot?
Kartik Mandaville|2023-07-25 22:48:35|its the enterprise copilot search
Karan Lightspeed|2023-07-25 23:27:05|Interesting. More here - https://venturebeat.com/ai/cohere-releases-coral-ai-assistant-designed-for-enterprise-business-use/
Abhishek Mishra|2023-07-25 23:41:09|You can get it via openrouter.ai, i think [PHONE] has direct access from Anthropic for Claude v2 ‎[7/26/23, 00:18:17] Sandeep Srinivasa RedCarpetup: ‎image omitted
Chaitanya A GenAI|2023-07-26 00:23:08|instructions are the basis of how your agent comprehends and responds - if you’re looking to make zero shot agents, it’s best to make instruct models
Sumod K Mohan|2023-07-26 00:30:13|Depends on what he means by Instruction Tuned and what kind of chats (factual vs explorative). If he means supervised fine tuning, this is sort of opposite of what Llama2 paper talks about. The idea being SFT of about few 10k samples are good enough. SFT has problem that models learns even the bad tail of data and will try to mimick it. Humans are not got at giving SFT annotations at scale but are good verifiers (RLHF annotations, given a codified standard). So they (Llama2) put more effort into RLHF annotations. If he means RLHF (ala InstructGPT), I agree.
Sumod K Mohan|2023-07-26 00:30:28|I am paraphrasing the paper
~ Abhishek Shivkumar|2023-07-26 00:31:19|Glad to be part of this group. Thanks for adding me.  Is there a library that will help me create the prompts for llama-2 with the INST and <s> tags and so on? Or do I need to create the template myself ? Thanks
Sumod K Mohan|2023-07-26 00:34:14|Again, we don't quite know what OpenAI's Annotation looked like ([PHONE] ;), if they used textual feedback in RL model, this might not be true for their system. Llama2 just had a score, atleast as per what I understood in the paper.
Chaitanya A GenAI|2023-07-26 00:35:19|i think the post is more about alignment with a specific usecase the agent serves  making a generalist model trained on a wide variety of conversational data might not serve the exact usecase unless finetuned more i think; beyond that im also not sure if it’s about rlhf or sft but more about the structure of the dataset - instruct benefits highly from rlhf though at least from what we’ve seen
Sumod K Mohan|2023-07-26 00:41:03|One of the things I found really interesting in the paper, that I and [PHONE] was talking about was how LLM models are just so much better than humans annotators at text generation, richness etc (Llama2   refers to couple of papers). We are just lazy but we are great at verifying.
Sumod K Mohan|2023-07-26 00:43:49|So in LLM's world, we are the Oracles. The magical Oracles who can verify much faster than computing, that our Theory professors kept talking about (CS theory joke ;).
Abhishek Mishra|2023-07-26 00:58:44|"It should take just a single line of python to convert your system instruction and user instruction to ""<s>[INST]<<SYS>>"" + var_sys_instruction + <<SYS>> + var_user_prompt + ""[/INST]"""
Abhishek Mishra|2023-07-26 01:00:27|Verification can also be weak with humans if we had to peruse everything in detail. But we are the best at instantly telling what we think is better, like scrolling down a Google search page and knowing what looks right to contain our answer.
Abhishek Mishra|2023-07-26 01:01:13|And hence RLHF approaches like Google search user selection and midjourney user selection from 4 images are the fastest and most accurate way to design reward models
Shashank Generative AI Group|2023-07-26 01:01:28|Mentat - an open source, GPT-4 powered coding assistant!  runs in your command line, giving it the context of your projects and allowing it to coordinate edits across multiple files!  modifies, creates, and deletes files, and is aware of the current git diff so it can extend your work. Use interactive mode to select suggestions.  https://twitter.com/bio_bootloader/status/1683906735248125955?t=UXJL20HU_XTsA0VoIbV93g&s=19  https://github.com/biobootloader/mentat ‎<This message was edited>
Abhishek Mishra|2023-07-26 01:05:02|Imagine a folder containing 100 images, do we get better results by keeping them in list layout by going through them one by one and selecting what we want or keep them in thumbnail view, quickly find what we like even in low resolution and pick that
Sumod K Mohan|2023-07-26 01:09:35|Yeah. We are also not really computing, that is slow for us to (System 2). But we have a better model of the world, learned thru initally unfocused explorative play, interactive learning with multimodality, temporality (each samples are related to next unlike how we train LLM) etc. We are using that system as a proxy.
Sumod K Mohan|2023-07-26 01:13:23|There are quite some neuroscience behind this. I don't think we fully understand it. Neuro folks, please correct me where I am wrong. Our vision is only high res in small area (fovea), rest is all low resolution. But we process all of it, figures out what are interesting regions to focus in (saliency) and then move our eyes towards those regions. So we are sort of doing a mix of high and low resolution processing at the same time.
Sumod K Mohan|2023-07-26 01:14:44|Many of initial CV models were build to mimic these structures, like image pyramids for hierarchy, attention to mimic saliency etc.
ashish Acgt01 Twitter|2023-07-26 01:27:56|Karpathy also says in the agent hackathon video i posted yesterday that the next level of breakthroughs will come from inspiration from the human brain. The problem(?) is that neuroscientists still don't fully understand how the brain works and are discovering new things about the brain regularly  So expect lot of osmosis in both directions between neuroscience and ai/ml ! :)
ashish Acgt01 Twitter|2023-07-26 01:30:58|This
~ Sanjeed|2023-07-26 02:23:01|Thanks for sharing
Anshuman Pandey|2023-07-26 06:23:10|Nous Hermes 13b live on chat.nbox.ai
Atik Shaikh|2023-07-26 07:03:15|Claude v2 100k context right ? I have access to the Chat Interface
~ Vik|2023-07-26 07:05:16|been using it to grok papers
Lalit Pagaria|2023-07-26 08:30:13|https://observablehq.com/@ayhanfuat/the-fall-of-stack-overflow  This is an interesting StackOverflow lost significant traffic in the last 1.5 year
Amir Nagri|2023-07-26 08:43:33|It was sold off to VC just a while back  Was it timed or just luck?
Nitin Mahajan McKinsey|2023-07-26 08:45:29|I thought you dont sell to a VC :) You raise minority investment from them. Unless you sell to a PE which is likely to be majority share sale btw
Amir Nagri|2023-07-26 08:47:32|https://techcrunch.com/2021/06/02/stack-overflow-acquired-by-prosus-for-a-reported-1-8-billion/
Amir Nagri|2023-07-26 08:49:16|Prosus is the same company that invested in byju's  So having tough luck on multiple fronts  They invested $35M in tencent for 15%, I guess that's serving them well
Paras Chopra Wingify|2023-07-26 08:51:44|PEs buy companies
Nitin Mahajan McKinsey|2023-07-26 08:52:11|So prosus is a PE now? 😉
Paras Chopra Wingify|2023-07-26 08:52:44|VCs don’t cut such big Cheques
Paras Chopra Wingify|2023-07-26 08:53:00|So who knows 😅
Nitin Mahajan McKinsey|2023-07-26 08:53:13|Anyways, if they block out data to GPT crawls, they might be able to leverage a lot back. stackoverflow has a lot of good data and dont know if they can even sue them for previous crawls to be stopped
Rahul Bhatnagar|2023-07-26 09:00:11|[PHONE] please read this.
Sumod K Mohan|2023-07-26 09:53:40|"""The general design principle is - attention allocation decreases exponentially as the distance between tokens grows. We prove that it obtains a linear computation complexity and a logarithm dependency between tokens."""
~ Nikhil|2023-07-26 10:03:35|Anyone checked this out yet? Any issues you foresee with this approach? Seems like a perfect troika between performance, compute, and training cost. I (obviously) didn’t get most of the math 😅
Abhishek Mishra|2023-07-26 10:24:32|It seems promising in the paper, we need a RetNet BERT/T5-mini at minimum to actually verify this.
~ Nikhil|2023-07-26 10:47:22|Will be on the lookout..
~ Happy Chaudhury|2023-07-26 10:58:10|Q:how to run llama.cpp  in CPU , i could find that from command line ./main -t 10 - ngl 32 -m laama..bin....inst prompt ‎[7/26/23, 10:58:33] ~ Happy Chaudhury: ‎image omitted
~ Happy Chaudhury|2023-07-26 10:58:49|Actually not getting how to test this in CPU
~ Happy Chaudhury|2023-07-26 10:59:13|GGML
~ Ashish|2023-07-26 11:00:01|https://www.youtube.com/watch?v=k36IMIiv3Yo
~ Ashish|2023-07-26 11:00:02|Follow this guide to run on LocalPC
~ Happy Chaudhury|2023-07-26 11:00:27|Thanks 🙏 i will try it and update
Sumod K Mohan|2023-07-26 11:09:29|Yeah like LongNet, whether this scale is the real question. In LongNet, they are sort of saying here is a model that does not bad in short sequences and is able to cope with long sequences (their PPL increases w.r.t comparison models at 32k etc). Sure some of those ideas might be used in scaling but hard to say if that specific model exactly will scale.
Abhishek Mishra|2023-07-26 11:10:11|I'll DM you
Abhishek Mishra|2023-07-26 11:10:49|Actually trying this out may solve your problem, please try this first.
~ Happy Chaudhury|2023-07-26 11:13:27|Ok 🙏🏻 ‎[7/26/23, 11:15:01] Sumod K Mohan: ‎image omitted
Amir Nagri|2023-07-26 11:33:24|Link to paper/arxiv?
Sidhant Sequoia|2023-07-26 11:38:49|https://arxiv.org/pdf/2307.08621.pdf ‎[7/26/23, 11:43:00] ~ Nikhil: ‎image omitted
Abhinav Verma Longshot.ai|2023-07-26 12:46:18|Hey folks, so a question regarding OpenAI apis. Is there an endpoint, which can help us find usage limit of an account
~ Happy Chaudhury|2023-07-26 13:17:10|Oh this is working
~ Happy Chaudhury|2023-07-26 13:17:11|It's simple
~ Happy Chaudhury|2023-07-26 13:17:28|I tried just llama-cpp-python
~ Happy Chaudhury|2023-07-26 13:17:32|Package
~ Happy Chaudhury|2023-07-26 13:17:36|Pass context
~ Happy Chaudhury|2023-07-26 13:17:46|Takes little time 2mins
~ Happy Chaudhury|2023-07-26 13:17:49|In colab
~ Happy Chaudhury|2023-07-26 13:17:52|CPU
~ Happy Chaudhury|2023-07-26 13:18:04|And model bin file
~ Ashwin|2023-07-26 16:09:16|‎~ Ashwin was added
‪+91 98194 04703‬|2023-07-26 16:09:16|‎‪+91 98194 04703‬ was added
Ramakrishnan Lokanathan|2023-07-26 15:09:47|For everyone building products,  Legal and compliance has been my biggest challenge since starting up. Especially in GenAi  I finally found a person who is damn reliable and affordable. 1000rs of retainer only!!  Do let me know if any of you have the same headache. Can connect.  This should ideally go into Startup group but as just 27 are there, will be helpful here.
Nirant|2023-07-26 15:57:10|The startup group has 200+ folks. Please move this convo there
Kaushik Bokka|2023-07-26 15:58:06|cc [PHONE] the list is growing haha
Nirant|2023-07-26 16:06:04|Since we've a lot of new friends here, just a reminder:   Want to hire? Want to announce an event? Read these community *rules* first: https://nirantk.com/community  We remove users who are unable to participate to the conversation over >60 days  PS: Recommend muting this group!
~ Vrushank Vyas|2023-07-26 16:14:40|Account level usage limits are generally fixed and increased upon requesting to OpenAI right?  Model level rate limits are passed along with every response
Abhinav Verma Longshot.ai|2023-07-26 16:16:00|Yes. I just want to know when the account is on the verge of crossing it for example. So was wondering if there is any api for that or if you guys have this feature 😜
Abhiram Ramesh|2023-07-26 16:17:44|If you're a paid user you get to see the limits and set your own soft limits
ashish Acgt01 Twitter|2023-07-26 16:20:08|i think the OP's intent was can that information be found programmatically, through an api , instead of going to the openai usage page and checking ?
~ Dx|2023-07-26 16:21:02|Do emoji reactions count as 60 days participation ? 😅 legit curious
Abhiram Ramesh|2023-07-26 16:23:39|Can't find any api talking about Metadata 🥲
ashish Acgt01 Twitter|2023-07-26 16:29:42|any suggestions on a framework or library which will help me build a RAG demo ona corpus of 8-10 pdf files really quickly ?  qps is going to very low (just 4-5 users, checking the accuracy of the demo) and corpus, once indexed, will largely remain unchanged( maybe a few additional pdf files, but no removals) i am aware of danswer[0]  The other option is exploring the azure openai service. Has anyone used it for a RAG usecase [1] ?  Any other suggestions which dont involve - building the entire flow using a vector db and chaining it with GPT4, etc . Ideally, some existing framework which allows me to upload the pdf files in my corpus and give me a barebones chat ui webapp to answer questions on the files in the corpus  0. https://www.danswer.ai/ 1. https://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2 ‎<This message was edited>
Nirant|2023-07-26 16:32:46|Only messages
Prakash Sankar Harbor|2023-07-26 16:35:45|how are you guys thinking about leveraging GPT-4 in production? How do you get around rate limits, especially if you are in the consumer space and might have a lot of requests?
Saurabh Karn Nyai|2023-07-26 16:37:15|I know two kind of folks: 1) People who hope: They hope that either smaller models will become self hostable or rate limits would improve 2) Multiple Accounts: I know some people who just use multiple accounts and switch between them.
Anubhav mishra Zupay|2023-07-26 16:38:07|Use a combination of 3.5, 4 and Claude based on the requests. Combination of models will work at scale vs just GPT4
Saurabh Karn Nyai|2023-07-26 16:38:34|And as [PHONE] posted in another group, these kind of things fuel the hope:  https://twitter.com/MoritzLaurer/status/1682668392765956096?t=OgJHKqVjqeSIiMGa4gYkPQ&s=0
Prakash Sankar Harbor|2023-07-26 16:39:19|gotcha, met anyone who does a combo? what tasks by GPT 3.5 are replaceable by an open source model today (and which one)?
Saurabh Karn Nyai|2023-07-26 16:41:31|We haven't tested it out yet, but chat seems to be one of the lowest hanging use cases. Specially if you are able to scaffold it with prompts and all. We tested Llama2 70b model which we have hosted and initial results seems to be very positive. Don't know if someone has ran a benchmark on it. Happy to figure it out if someone wants to run benchmark on it.
Anubhav mishra Zupay|2023-07-26 16:41:39|https://www.ibtimes.co.uk/openai-working-advanced-ai-model-that-uses-10-million-nvidia-gpus-1717974  This is fake right? How's that even possible
Saurabh Karn Nyai|2023-07-26 16:51:15|This is a crime reporting memo generated:  https://chat.openai.com/share/f0b66a82-8e51-4bf7-aafa-36d3b8a38109
Chaitanya Mehta Goodera Turtlemint|2023-07-26 17:01:43|Anyone here applied for and availed the $2500 OpenAI credits from Microsoft Founder's Hub. I need help in activating them. Can someone here help?
Prakash Sankar Harbor|2023-07-26 17:17:53|ah gotcha, have you leveraged llama2 for any code parsing tasks?
~ Arun Venkataswamy|2023-07-26 17:17:58|We are at a very early stage of evaluating Llama2 70B. One of our tasks was to generate a JSON from a user prompt. The prompt represents a goal. The JSON completion represents a (array) sequence of tools which can be executed to achieve the goal. We provide the list of tools available as part of the prompt. The model chooses a subset and in the right order. Basically task breakdown. We do this using GPT 3.5 now. Llama2 70B was able to accomplish this task consistently. In fact the 8 bit quantised version was able to do it too.
Sainath GenerativeAI WhatsApp Group|2023-07-26 17:30:03|I still wonder how you track it, do you have any tools?
Saurabh Karn Nyai|2023-07-26 17:33:31|No. We are very focused on legal. What would be an example of such task?
~ Kaustav K Bose|2023-07-26 18:01:57|They had sold a total of 30 mil Consumer GPUs in 2022. This is enterprise, but still seems to be an exaggeration.
Abhishek Mishra|2023-07-26 18:02:53|This is very interesting. I'm interested in how are you evaluating this, what are all the criteria you're checking for this?  Have you defined a set of criteria for tool usage other than replying in json?
Nirant|2023-07-26 18:04:26|Yes. It's all open source.  This is the code: https://github.com/NirantK/nirantk.github.io/blob/main/community_dev/nbs/01_Extraction.ipynb
ashish Acgt01 Twitter|2023-07-26 18:04:29|Very cool stuff Arun. If possible, would love to know more details of your approach
Dr. Pratik Desai KissanGPT|2023-07-26 18:07:03|Yes, I'm intrigued with the results. I was not sure if it was possible. Even not perfect, it is a good start, later can be fine-tuned with instruction set.
Abhishek Mishra|2023-07-26 18:07:15|10 mil nvidia GPUs, assuming even lower versions of A100 40G would mean 40 million GB of VRAM utilisation.  For reference, A 70B llama2 doesn't take more than 280G total even with no quantization.  Are they implying the model is around 10 million * billion parameters 😀?  Or are they talking about having 1M llama2 like models running at once?
Dr. Pratik Desai KissanGPT|2023-07-26 18:07:54|Ignore. This is just a clickbait article.
~ Ankit Shrivastav|2023-07-26 18:11:37|Being on that   I read the texts in this group and sometimes I have to scroll up and find the context where it all started in between others posts or msgs. (No threads type here or segregation at WhatsApp) Is anybody else faces this problem in following content? Do you have that too … threaded conversations?
Nirant|2023-07-26 18:12:25|Not yet, we've summaries here: https://nirantk.com/docs/summaries
Nirant|2023-07-26 18:19:18|Link error, this is correct: https://nirantk.com/docs/resources/
~ Ankit Shrivastav|2023-07-26 18:19:50|Yup got it
Abhinav Verma Longshot.ai|2023-07-26 18:25:49|Apparently follow the science goes out of the window when it comes to AI. In this case it's let's go as crazy as possible
Dr. Pratik Desai KissanGPT|2023-07-26 18:27:15|what actually happened is that every editor added a 0
Abhinav Verma Longshot.ai|2023-07-26 18:27:40|That 100 trillion circle
Nirant|2023-07-26 18:28:42|Just adding a single 0, ngmi 🤣
~ Arun Venkataswamy|2023-07-26 18:36:07|Yes the prompt includes the list of tools along with a brief description of what each  tool is capable of, what inputs it requires and what output it generates.
Paras Chopra Wingify|2023-07-26 18:38:44|What is this?
Gokul Krishnan|2023-07-26 18:44:32|I quick skimmed this and the article sounds like it was generated by a crappy LLM. Perhaps 6B or lower
Anubhav mishra Zupay|2023-07-26 18:45:37|Lol , google should build an algo to screen click bates 😅😂
Anubhav mishra Zupay|2023-07-26 18:45:58|Real use of xai, tell the truth
Anubhav mishra Zupay|2023-07-26 18:49:43|https://apps.apple.com/us/app/rewind-truly-personalized-ai/id6449795815  Has anyone seen / tried this?
ashish Acgt01 Twitter|2023-07-26 18:54:08|i was just about to post this ! #greatmindsthinkalike :D  I am a huge fan of the rewin app on mac. Use it quite often for summarizing meeting action items in emails and searching through ephemeral comments on zoom calls  rewind on iphone has the potential to give competition to siri :) seems like on iphone, rewind (for now ?) is limited to searching through your safari history and photos, though. I guess, screen capture all the time, even though cleverly, like rewind on mac, would be too resource hungry on a mobile device  any other rewind users here ? ‎<This message was edited>
Nitin Mahajan McKinsey|2023-07-26 18:55:51|I am betting someone will buy them. Huge fan following and founder had a personal history on why he built it. The way they crowd funded was also good. Respect.
Anubhav mishra Zupay|2023-07-26 18:56:05|I think Apple will buy them
~ Tarun|2023-07-26 18:57:06|beautiful app on the mac, their tech is so good
~ Tarun|2023-07-26 18:57:07|they released on iPhone today
~ Tarun|2023-07-26 18:58:22|for whom do you think this product makes sense as an acquisition?
ashish Acgt01 Twitter|2023-07-26 19:00:53|Major Announcement from OpenAI - Announcing Frontier Model Forum, an industry body co-founded with @anthropicAI, @Google, @googledeepmind, and @microsoft focused on ensuring safe development of future hyperscale AI models: https://t.co/KLFdVpwQN3
Dr. Pratik Desai KissanGPT|2023-07-26 19:01:23|Apple
Shimanta Generative AI|2023-07-26 19:03:30|Meta with their open source model doesn’t seem to qualify as frontier
ashish Acgt01 Twitter|2023-07-26 19:03:43|"meta/fair, which by any reckoning is a big player, is conspicuously absent from the frontier model forum  ""Anthropic, Google, Microsoft, and OpenAI are launching the Frontier Model Forum, an industry body focused on ensuring safe and responsible development of frontier AI models. """
jyotirmayjk Hackathon|2023-07-26 19:04:42|Apple is also absent ? Seems more like “Frontier Oligopoly Forum”
Bulia Siddharth Aurashop|2023-07-26 19:07:56|I am trying on iPhone. The app is crashing constantly.
Pratyush Choudhury|2023-07-26 19:11:21|"""safe & responsible"" is a phrase that people might not associate enough w/ Meta maybe? ‎[7/26/23, 19:13:44] ashish Acgt01 Twitter: ‎image omitted"
Dr. Pratik Desai KissanGPT|2023-07-26 19:25:39|If that superconduct research is proven to be true, we are going to run out of groups like this. Anyone following on that? ‎<This message was edited>
Shimanta Generative AI|2023-07-26 19:27:08|It looks like it’s true, but we’ll only know when the applications start coming up. Pretty exciting though
~ Adhitya Swaminathan|2023-07-26 19:27:45|Have to wait for others to verify.
~ Adhitya Swaminathan|2023-07-26 19:27:53|Reproduction of research in other fields is unfortunately a lot slower than in AI
Paras Chopra Wingify|2023-07-26 19:32:29|What do you mean “running out of groups like this”?
Dr. Pratik Desai KissanGPT|2023-07-26 19:34:16|This can enable next industrial revolution combined with AGI. Unlimited energy, quantum computing. We will be out of slumber and intellectual people wants to create groups to learn more and create coalitions.
Gokul Krishnan|2023-07-26 19:35:52|Whose truth? 😉
Abhinav Verma Longshot.ai|2023-07-26 19:37:03|All LLMs lower than 6B be like -why are we catching strays?
gmisrag Gananth|2023-07-26 19:37:22|Had used the mac app for like a month - as you mentioned quite slick but did not find myself going back to the product often / not a frequent usecase atleast for me
~ Tarun|2023-07-26 19:38:28|its a godsend for people w adhd
~ Sachin Kalsi|2023-07-26 19:39:37|https://twitter.com/sauhaarda/status/1683980465919889409?s=46&t=iNnHcvFLDa-sOIXYIloGew
jyotirmayjk Hackathon|2023-07-26 19:42:27|There are lot many criticisms of the paper and about cherry picking of data  Some things others have pointed out : Telling sign that it was published on ArXiv before going viral not peer reviewed forums Another telling sign is that no patents were filed and the finding seems to be coming from a private entity which is a startup  I forgot to bookmark the source while reading ,will share if I’m able to discover it again
jyotirmayjk Hackathon|2023-07-26 19:42:50|*funding for research not finding
jyotirmayjk Hackathon|2023-07-26 19:43:33|But still optimistic that it is replicated and validated so 🤞🏻
Gokul Krishnan|2023-07-26 19:43:50|Good thing it seems easy enough to repro and people are on it. I won't be surprised if, for example, Nile Red comes out with a video soon
Gokul Krishnan|2023-07-26 19:44:36|Spoken as a layman reading tweets by other laypersons masquerading as Materials science experts
jyotirmayjk Hackathon|2023-07-26 19:45:13|Yeah +1 to this 😅
Dr. Pratik Desai KissanGPT|2023-07-26 19:45:20|I read the paper, it is really easy to produce and not so difficult materials to get.
Dr. Pratik Desai KissanGPT|2023-07-26 19:45:50|We will know in less than a week
jyotirmayjk Hackathon|2023-07-26 19:47:52|Not hard to imagine a near distance future where DIY enthusiasts come up with home made quantum computers based on this material running 100b LLMs on edge 😅 ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-26 19:48:32|Haha, that's the part I was talking about. Going to hold on to the imagination horses until it is reproduced. ‎<This message was edited>
Gokul Krishnan|2023-07-26 19:51:29|Running LLMs on edge potentially messing with lethal biological material:  https://m.youtube.com/watch?v=9FppammO1zk
jyotirmayjk Hackathon|2023-07-26 19:54:15|Very true ,it’s quite fun though to hold on to 2 opposing ideas ,optimism and pessimism and see how progress happens  😄
Gokul Krishnan|2023-07-26 19:56:53|And while we wait for the repro, why not watch a series of videos on the last time we had a large scale materials controversy: https://m.youtube.com/playlist?list=PLAB-wWbHL7Vsfl4PoQpNsGp61xaDDiZmh
jyotirmayjk Hackathon|2023-07-26 19:57:35|Wait why is this video about CRISPR like biotech and less about  LLMs ?
jyotirmayjk Hackathon|2023-07-26 19:58:18|Seems more fear mongering than anything  And the sponsor of the video is the source material of the facts presented in video.Bit sus
~ Nirmal|2023-07-26 19:59:11|Kurzgesagt has been going off-track for a while now...
Gokul Krishnan|2023-07-26 20:00:38|I should've been more explicit. I'm extrapolating based on if we had 100B LLMs running locally, bio hackers could leverage it and a malicious agent could weaponize it
Gokul Krishnan|2023-07-26 20:00:53|Anyway, quite off topic for the main channel so I'd 🤐
Gokul Krishnan|2023-07-26 20:01:16|Happy to delete the message if folks have  strong objections
jyotirmayjk Hackathon|2023-07-26 20:01:54|We can move this to Philosophy group before we are “snapped out” 😝
Dr. Pratik Desai KissanGPT|2023-07-26 20:02:48|More biotech goes to philosophy, AI that can enable Biotech is a fair game. ‎[7/26/23, 20:07:01] ashish Acgt01 Twitter: ‎image omitted ‎[7/26/23, 20:07:02] ashish Acgt01 Twitter: ‎image omitted ‎[7/26/23, 20:07:03] ashish Acgt01 Twitter: ‎image omitted ‎[7/26/23, 20:07:05] ashish Acgt01 Twitter: ‎image omitted ‎[7/26/23, 20:07:06] ashish Acgt01 Twitter: ‎image omitted
Bulia Siddharth Aurashop|2023-07-26 20:14:27|Will try again!
Jayanth Generative AI WhatsApp Group|2023-07-26 20:37:01|https://openai.com/blog/frontier-model-forum
Sandesh Anand|2023-07-26 20:49:59|‎Sandesh Anand requested to join
Sandesh Anand|2023-07-26 20:51:30|‎Sandesh Anand joined using this group's invite link
Ankur Pandey|2023-07-26 22:16:05|https://twitter.com/AISafetyMemes/status/1683077335875035136?t=p7IeY35c_Zecn4ob-LPk9Q&s=08  NPCs in unity have awakened
Zainab Bawa|2023-07-26 22:16:07|Hey [PHONE] nice to see you here!
Sumod K Mohan|2023-07-26 22:27:29|[PHONE] worked at Unity and did RL for NPC (non playing characters) there, a while ago. He can enlighten us 😉
Tejas Referred By paras|2023-07-26 22:29:17|‎You added Tejas Referred By paras
Sachin Legaltech|2023-07-26 22:47:03|That video is funny 😂. I was at unity Ml-agents team 5 years ago and none of us imagined we could have such amazing interactions with NPCs..We were just training them to have better gameplay and increase the complexity of game as player’s skill level increases.
~ Vennela Miryala|2023-07-26 22:48:12|‎~ Vennela Miryala requested to join
Sumod K Mohan|2023-07-26 23:15:16|What are new things that are possible? Or rather what is still not possible?
ashish Acgt01 Twitter|2023-07-26 23:34:27|"AWS joins the party ! https://aws.amazon.com/blogs/aws/preview-enable-foundation-models-to-complete-tasks-with-agents-for-amazon-bedrock/  ""Today, I’m excited to announce the preview of agents for Amazon Bedrock, a new capability for developers to create fully managed agents in a few clicks. Agents for Amazon Bedrock accelerate the delivery of generative AI applications that can manage and perform tasks by making API calls to your company systems. Agents extend FMs to understand user requests, break down complex tasks into multiple steps, carry on a conversation to collect additional information, and take actions to fulfill the request.""  https://aws.amazon.com/bedrock/features  - uses ReAct [https://arxiv.org/abs/2210.03629] under the hood - will be huge for enterprise usecases since aws is very familiar"
Amogh V|2023-07-26 23:43:38|SDXL launch happening live right now - https://discord.gg/stablediffusion?event=1130919343941758978
Sachin Legaltech|2023-07-26 23:50:48|Because of LLMs, we can interact with NPCs in natural language (not counting the cost of inference within games ; but game industry will figure it out I believe). Also with just with prompts + retrieval, we can have some intelligent behavior without doing any Reinforcement learning training. https://arxiv.org/abs/2305.16291 this agent learns to play Minecraft with just prompting gpt4 and adding skills to the vector db. There might be limitations to these kinds of agents and we might need to finetune these agents with RL ; but their capabilities with gameplay are still unclear to me. Building  super competitive NPCs, which can understand the game play and keep competing with master players is still hard and computationally expensive for most of the complex games.
Sumod K Mohan|2023-07-27 00:01:59|Interesting. Was wondering this is a really interesting world, you have clear model representation that you have access to and can interact with. You need LLM to translate from NL to that world representations but all other interactions can be learned using RL better (efficiently) isn't it? Yes, the challenges of training RL algorithms withstanding.
~ Ashish|2023-07-27 00:11:04|https://huggingface.co/blog/eu-ai-act-oss
Vamshi|2023-07-27 00:11:56|That’s the Matrix City sample in Unreal looks like
Vamshi|2023-07-27 00:14:18|That sample looks equally impressive without any voice AI 😄
Vamshi|2023-07-27 00:14:23|It’s super fun
Vamshi|2023-07-27 00:16:05|Apart from the ML mesh deformers, there’s also a lot of “old school” simulation based AI in there, as part of the stock sample from Epic Games.
Vamshi|2023-07-27 00:16:42|Is this also in Unity now ?
Vamshi|2023-07-27 00:19:05|That’s surprising !
Sachin Legaltech|2023-07-27 00:21:05|I do believe we can have better agents by training directly with RL either in pixel space or in natural language space; but it is hard (needs lots of compute power + RL training instabilities) Training in natural language space should be comparatively much more easier; we were doing some training + planning in natural language space in 2018 (with tiny by today’s account LSTM networks) I think plenty of games will incorporate LLM based agents  in the near term and maybe soon after will go back to at least finetuning their behavior with RL.
Sachin Legaltech|2023-07-27 00:23:32|Maybe this - https://github.com/Unity-Technologies/ml-agents . It’s a project to convert simulations into environments and let RL agents train
Vamshi|2023-07-27 00:26:24|Ah I get it now, there are toolkits available for Unity with support for the advertised conversational AI plugin etc, but the video in the tweet is Unreal Engine, most likely.   That sample is probably still Epic exclusive, but I’m not really 100% sure about this.
Aankit Roy Khabri YC|2023-07-27 00:31:12|Hey folks, Is there a good article or paper to understand different forms of chunking strategy which covers varied use cases?
Abhishek Mishra|2023-07-27 00:59:03|NPCs in RPG games usually come with their lore and have specific purpose of handing out tasks and quests to the players.  I think one possible direction can be to train a Tinystories like (44 M parameters, 58MB size) model that just responds to user requests based on the lore they have been trained with.
Abhishek Mishra|2023-07-27 01:00:11|This way, we could dynamically load and unload NPC models based on where the players are active and also not have to worry about NPCs getting autonomy or fall outside of their character.
~ Sparsh Nagpal|2023-07-27 01:00:42|Did anyone attend the SDXL seminar? Did they happen to say something about the huggingface safetensors model and it's compatibility with diffusers (since there would be differences in model surely)  They did mention about Comfy UI but not sure about this one
Amogh V|2023-07-27 01:17:31|Yes
Amogh V|2023-07-27 01:18:31|SDXL 1.0 weights released. You can use with Diffusers. All info here - https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0 ‎[7/27/23, 07:02:51] Anshuman Pandey: ‎image omitted
Anshuman Pandey|2023-07-27 07:03:18|"At the SignalFire event on ""Compute Conundrum"" w/MosaicML etc"
Anshuman Pandey|2023-07-27 07:04:01|Good to see fellow builders [PHONE] & [PHONE]   Will share notes from the event here once it is over
Sandesh Anand|2023-07-27 07:04:47|Hey Zainab! Nice to see you here too :)
Abhiram Ramesh|2023-07-27 07:45:50|👀 Convergence
Shashank B Designer|2023-07-27 08:36:05|Any OG AI guys (worked on Planning/Reasoning using Symbolic AI and perhaps exploring LLMs/NeSy now) here?  Would like to to pick your brains on a few things😁 ‎<This message was edited>
Sandesh Anand|2023-07-27 09:32:54|Thanks for adding me [PHONE]  I have an InfoSec background (in the space for over a decade). It has been interesting to see GenAI usage grow from the sidelines. I am really interested in diving deeper into GenAI governance and feel like there is a lot of overlap with InfoSec. I've done a little bit of digging over the last few months and wrote about it here: https://boringappsec.substack.com/p/edition-21-a-framework-to-securely  If anyone is interested in the space or (even better) has already dug deep, HMU! I'd love to chat. I think there is a lot more to discover here :) ‎<This message was edited>
Zainab Bawa|2023-07-27 09:37:00|[PHONE] I was telling Sandesh we do this at The Fifth Elephant on 11 August. [PHONE] meet editor Sumod Mohan. :)
~ Abhishek Shivkumar|2023-07-27 10:17:21|Hey, does anyone know of a Llama-2 model version with a longer context like 16k?
Chetanya Rastogi|2023-07-27 10:18:46|Hey Folks, I am looking to buy a new Mac. Any recommendations on ram size for 32 vs 64 gb? Looking to train/run models of size 65B and longer contexts (like 8k). Has anyone had any experience wrt that + m2 pro vs M2 max?
Ravi Theja|2023-07-27 10:18:47|[PHONE] worked on llama-2 13b model on 8k context with open assistant - https://twitter.com/Shahules786/status/1683880849803202561?s=20
Chetanya Rastogi|2023-07-27 10:20:33|Basically using libraries like ggml
Amir Nagri|2023-07-27 10:20:57|Afaik you can run inferences but cannot fine tune on that machine
~ Prajna Prayas|2023-07-27 10:21:19|I guess you better get a custom rig if training LLM is your objective because you would definitely want some redundancy for future developments
Shahul Kaggle Kernel GM|2023-07-27 10:23:29|I haven’t seen any with more than 16k length. We released a 8k fine tuned version couple of days ago.
Shahul Kaggle Kernel GM|2023-07-27 10:24:28|You can try and see how much you can get from it. Theoretically it should work till 32k without much loss.
Prayank Swaroop Accel|2023-07-27 10:55:13|Without a CUDA a Mac seems pretty useless for more sophisticated ML work
Chetanya Rastogi|2023-07-27 10:59:42|What would you recommend if let's say only local inference is needed?
Rahul Bhatnagar|2023-07-27 11:00:30|It’s great for inference. Specially if you’re trying complex  stuff with imagine / automatic1111. Does stable diffusion in  20s.
~ Vik|2023-07-27 11:02:00|what's the best lama2 endpoint to use in production. i know of together and maybe hf (not checked) any other?
Rahul Bhatnagar|2023-07-27 11:02:46|For example last month I played around with these fun AI QR codes that shop keepers could put up on their stores.  ‎[7/27/23, 11:02:48] Rahul Bhatnagar: ‎image omitted
~ Ankit Kumar Pandey|2023-07-27 11:03:19|I share this dilemma too.. Would you recommend an Alienware vs a Mac Pro 2 max?
~ Vik|2023-07-27 11:04:05|i'd recommend an m2 air and the cloud for any heavy dl work
Prayank Swaroop Accel|2023-07-27 11:04:25|If you just need local inference... And don't need to run heavy workloads like SDXL + Deforum+ Controlnet + Video ... Then Mac should work  But if want to do finetuning then CUDA enabled NVIDIA RTX series might be better, Imho.
Prayank Swaroop Accel|2023-07-27 11:04:55|Yeah if the cloud is your friend then any machine works. Mac is great then.
~ Vik|2023-07-27 11:05:27|i had this same issue while it's nice to have your own 3090 rig it's not portable and you'll never use it enough
~ Vik|2023-07-27 11:06:53|there is a lot you can do locally on m2 ans the battery life, build  quality and weight is more than worth its price
Sumod K Mohan|2023-07-27 11:10:15|Did some bit of these. NeSy, just getting started.
Kishore GenAI|2023-07-27 11:12:11|"Which system can even take this workload: ""SDXL + Deforum+ Controlnet + Video"" ? Isn't it too intense for any local machine?"
Kishore GenAI|2023-07-27 11:15:04|And any input on what type of video is it? Is it interpolating between different output images and taking the inbetween framerate? or a video model in itself?
Dr. Pratik Desai KissanGPT|2023-07-27 11:23:36|Couple of 3090s from eBay. ~$800 each
Dr. Pratik Desai KissanGPT|2023-07-27 11:25:34|Get a 1200 or 1600w PSU and most of the motherboard are good enough with PCIe slot to support them
Prayank Swaroop Accel|2023-07-27 11:26:21|I can wish to do this no ?   Anyways finetuning is the biggest pain, best libraries use CUDA which doesn't run on Mac
Prayank Swaroop Accel|2023-07-27 11:26:45|If Mac brings back external GPU support in their next release might get interesting.
Rahul Bhatnagar|2023-07-27 11:31:58|I think the conversation was amongst other laptops and not MBP vs custom rigs.
Rahul Bhatnagar|2023-07-27 11:33:49|Would you recommend the Ailenwares with 4090/3090 over a Macbook m2?
Divya Tak|2023-07-27 11:36:03|If you're running in india, alien ware is not the best idea amongst gaming ones. If you care about the display HP has some good options and if you want something sturdy, MSI or ASUS might be better
Divya Tak|2023-07-27 11:36:41|Alien wares tend to overheat. And considering you want to run the GPU at full. Using something that has better heatsinks might be better
Rahul Bhatnagar|2023-07-27 11:38:27|I'm curious if anyone here has used any laptop for finetuning or training large workloads.
Kaushik S YC W23|2023-07-27 11:41:00|Haven’t personally used.  But many people are using llama.cpp to train models on a laptop with LoRA/QLORA
Nirant|2023-07-27 11:41:56|Since this is clearly of interest to power users, perhaps a dedicated forum will be better?   https://chat.whatsapp.com/LaxnmoPBzuO3IK8NHOg9Io
Sumod K Mohan|2023-07-27 11:43:08|We had got few MSI at Niqo, can't recommend due to build quality issues + too fragile. These weren't super beefy machines and got them in 2019.
Rahul Bhatnagar|2023-07-27 11:44:52|I think I'll need an llm assistant to keep track of groups in this community!
Nirant|2023-07-27 11:45:30|All roads lead  to Jarvis!
~ Prashanth Harshangi|2023-07-27 11:46:44|Slack? 😅
Kaushik S YC W23|2023-07-27 11:47:05|https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/  Would highly recommend joining this subreddit
~ Amrit Kochar|2023-07-27 11:55:51|I was also trying to similar stuff but the problem was most of the QRs are not scannable. So it doesn't work.
Rahul Bhatnagar|2023-07-27 11:56:49|You need to play around with the control net weights. About 90% of mine were scannable.
Rahul Bhatnagar|2023-07-27 11:57:19|Can’t automate it comepletely. But easy to do quickly with automatic 1111
~ Amrit Kochar|2023-07-27 11:57:48|cannot build an E2E automatic flow. the one you have shared is not scannable.
~ Amrit Kochar|2023-07-27 11:58:16|would like to know some more details because my success rates were around 30-40%
Rahul Bhatnagar|2023-07-27 11:58:43|Oh that’s odd. This one’s scanning on all the phones I tried.
Nirant|2023-07-27 11:59:37|Have been running Replicate for https://llama2demo.streamlit.app
~ Onkar Mishra|2023-07-27 12:00:02|I have used colab https://colab.research.google.com/github/sagiodev/stablediffusion_webui/blob/master/StableDiffusionUI_ngrok_sagiodev.ipynb#scrollTo=gJBtadxGOK7b for finetuning stable diffusion using LORA or Dreambooth but I have not tried finetuning any llm on colab.
Nirant|2023-07-27 12:00:31|This worked in one go, before my camera app could even load 🙈
Karan Lightspeed|2023-07-27 12:02:47|Worked for me
Bulia Siddharth Aurashop|2023-07-27 12:08:13|This is really good! Btw, quick question - How is the PMF for these QR codes? Do shopkeepers prefer this compared to normal QR codes?
Rahul Bhatnagar|2023-07-27 12:09:35|This was a fun side project. To motivate me to brush up my kannada and talk to shop keepers. That part is still a WIP.
Bulia Siddharth Aurashop|2023-07-27 12:10:00|Haha! Please let us know how it goes :)
Rahul Bhatnagar|2023-07-27 12:12:24|Looks like you’re going to get cancelled on soon….
Rahul Bhatnagar|2023-07-27 12:12:38|Cancelled soon*
Sumod K Mohan|2023-07-27 12:12:49|QR has high redundancy. So it might work in simple conditions and lighting. Darker room etc might dampen your reading accuracy. If you are directly scanning it, without camera this shouldn't matter. One could actually do the inpainting such that redunandancies are minimally effected. Could be a nice weekend project. I highly doubt there is money in this though. But really sounds like fun project.
~ Apurva Bhatt|2023-07-27 12:14:49|https://arxiv.org/abs/2305.10601 Good paper oughtsn prompting to solve logical tasks using LLMs. Its a improvement on chain of thoughts approach
~ Apurva Bhatt|2023-07-27 12:15:01|good paper on *
Rahul Bhatnagar|2023-07-27 12:16:54|Will do. Only get weekends for this, but getting better at sales is on the top of my bucket list.
Dev Aggarwal|2023-07-27 12:17:27|How to directly scan without camera? Directly scanning via python libs doesn’t work well as well as iphone/android qr scanners for these art qr codes
~ Adithya|2023-07-27 12:17:53|There was a video by linus tech tips on how a pro max is not even as fast as a 40xx gpu being ad costly
Nitin Mahajan McKinsey|2023-07-27 12:18:02|Nice.  I had built a basic one few weeks back and asked around to users and 2 things to share:  1) Payments have very high expectations. So, either it works or it doesnt and your QR code will be thrown away was a clear message. Looks are secondary. Functionality and trust even more important  2) This will likely become a freebie (once stabilized) with another main product than even a feature (or a product) on its own  2 cents worth. Flames > dev/null ‎<This message was edited>
Bulia Siddharth Aurashop|2023-07-27 12:18:42|If people use something I built -  that’s PMF for me :) (won’t work for startup thoroughly 😅) I remember I used to check logs of the first service I built and used to get excited that some real service is actually hitting it 😅
Dev Aggarwal|2023-07-27 12:20:12|I’m sure the MBAs in this group would disagree on the making money part 😂😆
~ Rahul Bansal|2023-07-27 12:24:38|How did you generate thi
~ Rahul Bansal|2023-07-27 12:26:14|How was the response? How many people are using it?
~ Rahul Bansal|2023-07-27 12:27:31|I have noticed people do pay for WhatsApp status with product information that they can share with other people
Rahul Bhatnagar|2023-07-27 12:28:59|Automatic 1111 with 3 control nets, tile + open pose and played around with them. Found a tutorial on twitter and played around from there.
Rahul Bhatnagar|2023-07-27 12:29:50|Menitoned this earlier in the conversation. ---- This was a fun side project. To motivate me to brush up my kannada and talk to shop keepers. That part is still a WIP.
Sumod K Mohan|2023-07-27 12:30:07|Yeah, getting that insane working conditions those work on can be really tricky. I am just amazed how well they work, it hardly just needs a frame. No amount of noise, low lighting etc that seems to matter. As someone who digs well built AI (read CV/NLP/Robotics) applications that is probably the standard.
Sumod K Mohan|2023-07-27 12:30:55|Hacking is one thing. Making a new one (*modified one) that rugged is probably quite a bit of work and uphill task. So users really have to be 'into' like a Ganesh Ji's picture or something, to tolerate initial failures. Which might work in India, I can see how 'Lakshmiji QR' being an 'in' thing 😉.
Sumod K Mohan|2023-07-27 12:34:01|I think there are quite a few ways like using Google Lens. Not sure what the equivalents on iPhone are.
Rahul Bhatnagar|2023-07-27 12:35:56|"I think you might be right. But sometimes these discussions can get very theoretical and opnionated. What are the ""rugged"" conditions they won't work in etc. The easiest way to do this is put it in front of people and try it out."
Rahul Bhatnagar|2023-07-27 12:36:08|Applies to all products not just AI QRs
Sumod K Mohan|2023-07-27 12:37:43|Absolutely
Rahul Bhatnagar|2023-07-27 12:37:45|I wouldn't dissuade anyone who thinks this a a good idea. Just takes 1-2 days of working on Automatic 1111 and seeing if people actually buy it. Imo I prefer that to premature TAM calculations (will paytm add it as a feature) or technical limitations.
Dev Aggarwal|2023-07-27 12:38:05|~Unrelated but Seeing about 500 urls being shortener via organic usage from our tool , 2 weeks after launch + marketing agencies wanting contracts with us
Rahul Bhatnagar|2023-07-27 12:38:07|Junk it if it doesn't work.
Dev Aggarwal|2023-07-27 12:38:54|Urls being shortened and turned into qr codes*
Rahul Bhatnagar|2023-07-27 12:39:15|Naice! Less talk more code. ❤️ it.
~ Siddharth|2023-07-27 12:43:32|‎Sugnan GenerativeAI Group  added ~ Siddharth
~ Rahul Bansal|2023-07-27 12:44:54|I tried scanning it, but Google lens does not recognise it
Shashwat TDC|2023-07-27 12:45:50|but on the other hand, I don't think I'll feel comfortable scanning this or taking a picture. Many people avoid photographing the Gods.
ashish Acgt01 Twitter|2023-07-27 12:49:18|"from chris re's group at stanford -  https://hazyresearch.stanford.edu/blog/2023-07-25-m2-bert  tl/dr: how to scale LLMs with an alternative to transformers  ""MLPs – the other core building block of Transformers – also introduce an efficiency bottleneck, which becomes more acute as we continue to optimize attention. MLPs are quadratic in the model width, which means they grow more expensive as you make models wider. This is why models like GPT-3 are so expensive, and why GPT-4 has allegedly started using techniques like mixtures of experts.""  ""Today we’re excited to present a little teaser of some work in this direction – Monarch Mixer BERT (M2-BERT). M2-BERT is sub-quadratic in sequence length and model dimension, has 25% fewer parameters/FLOPs than BERT, and matches in quality (potentially exceeding a little bit when parameter-matched). We’re still very early days, so come talk to us if you find these questions exciting! And if you’re reading this the week of release, we’ll be at ICML – come find us in Hawaii, we’ll be putting up a poster at the ES-FoMo workshop!""  arxiv coming soon [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] [PHONE] ‎<This message was edited>"
Abhishek Mishra|2023-07-27 12:56:27|Interesting, I've seen agents require tree of thought. Tree of thoughts and idea pruning are central to the idea of decision making.  I'll check this paper out in detail to see how they have explored it.
Shimanta Generative AI|2023-07-27 13:01:26|Tap and hold worked on iPhone for me
Sandeep Srinivasa RedCarpetup|2023-07-27 13:05:16|"I wouldn't say they are better...but they enable a certain kind of condition-check for prompts.  So u can say ""if I get this result from my previous step, then do this"". That if-then-else works well in certain usecases.  It is not super applicable in all usecases"
~ Rahul Bansal|2023-07-27 13:05:37|Which resources do you suggest ? Can you create one for me? One of my friends wants it for his shop ?
Rahul Bhatnagar|2023-07-27 13:06:57|I’ll try to find the twitter tutorial.
Rahul Bhatnagar|2023-07-27 13:08:36|You can also use [PHONE] ‘s tool
ashish Acgt01 Twitter|2023-07-27 13:09:41|very cool paper !  ReAct was from this same(Karthik's) group https://react-lm.github.io/ https://ai.googleblog.com/2022/11/react-synergizing-reasoning-and-acting.html
ashish Acgt01 Twitter|2023-07-27 13:10:46|https://www.youtube.com/watch?v=j0qTFcyKB4s
~ Anjineyulu|2023-07-27 13:35:47|With large language models adding a cognitive layer to Organization,how will a NLP or CV engineer should plan to add value?
Nirant|2023-07-27 13:56:59|Give up 🙈
~ Anjineyulu|2023-07-27 13:57:28|Seriously 😞
~ Anjineyulu|2023-07-27 13:58:46|Any cost analysis of llm vs simple naive Bayes will help us survive?
~ Anjineyulu|2023-07-27 13:59:09|I hope my question is understandable
~ Sri|2023-07-27 14:01:29|‎Sudharshan GenAI added ~ Sri
~ nikunj Jain|2023-07-27 14:03:22|‎~ nikunj Jain was added
~ Kshitij|2023-07-27 14:03:22|‎~ Kshitij was added
~ Dia|2023-07-27 14:03:22|‎~ Dia was added
~ gaurav|2023-07-27 14:03:22|‎~ gaurav was added
‪+1 (610) 212‑6248‬|2023-07-27 14:03:22|‎‪+1 (610) 212‑6248‬ was added
Nirant|2023-07-27 14:06:07|Yes, I am serious. All ML roles will quickly devolve into sales/support (boss comes and says build this) and API glueing.  Either way, you'll not be doing ML — Naive Bayes is barely ML anyway
Dr. Pratik Desai KissanGPT|2023-07-27 14:09:29|We used to write NN in C and Matlab, then tf dropped, then PyTorch. People who understand math and ml will be always needed, but in lesser capacity.
~ Anantharam|2023-07-27 14:09:34|I think it’s a matter of time. Once we are able to deploy smaller models, a lot of jobs will become redundant.
Saurabh Karn Nyai|2023-07-27 14:10:10|Because it’s belief territory, I think a lot of ML work would get subsumed under Subject Matter Specialisation roles. The SMEs would be future ML engineers doing engineering without writing code.
Pratik Bhavasar|2023-07-27 14:10:28|Things are getting harder for sure but some viable options  - work for companies building these abstraction - work on less touched domains - work on harder problems - acquire skills across the cycle (sales & marketing) - still a lot of work to be done on data prep side for custom small models
Rahul Bhatnagar|2023-07-27 14:10:30|So in 3 months? 😀
Ambika Computational Mama|2023-07-27 14:12:05|Can someone explain this term abstraction to me?
Ambika Computational Mama|2023-07-27 14:12:14|Like this format of usage in the tech world
~ gaurav|2023-07-27 14:13:50|I dont think it is wrong.  Overall i do believe rather than creating or finetuning something from scratch its good to use APIs and test even can use for production.  As we have multiple tools  our expertise would come down in the sea of tools which one would suit to that particular product needs.
Dev Aggarwal|2023-07-27 14:15:25|https://youtu.be/zhpWhkW8kcc
Pratik Bhavasar|2023-07-27 14:18:04|IMO, the next phase of consolidation will be based on cost wars between 1-2 year old companies like Jasper.   This will boil down to making your own trained small models for cost advantage.  So out of the box API is good to start with but not something bound to continue.
~ Anantharam|2023-07-27 14:53:10|With LLMs coming most of the work around the model is writing the prompt. Who in the company needs to do this?  1. Can be done by anyone? 2. DS? 3. A new class of job with some sort of specialisation.  What do you guys think should be the forward looking path?
Nirant|2023-07-27 14:54:24|Product Managers — or middle management, they're good at converting management-speak to tactical plans already
Bulia Siddharth Aurashop|2023-07-27 14:55:47|When pytorch came in, I am assuming it increased number of ML jobs.. IMO similar trend will continue and the roles will evolve into higher level role..
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 14:55:52|PMs. Interfacing with engineers for things like function calling
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 14:56:59|Good question. Another second order effect is that PMs will probably reduce dependencies on other functions
Bulia Siddharth Aurashop|2023-07-27 14:57:11|When pytorch came in, tf jobs reduced but overall ML jobs increased. Similar should happen now. PyTorch job might go away and a new higher level will come in..
Nirant|2023-07-27 15:00:03|"""Higher"" level is an incomplete view. Tech leads to bimodal pay ranges: Very high for niches and deep folk e.g. math, arch, systems, and API calling like PyTorch Lightning and LLM-API converges to zero over a 10 year window"
~ Anantharam|2023-07-27 15:01:17|So will model precision/recall calculation, versioning etc. will be owned by PM? I think there is a tooling gap there if PMs have to do it. ‎[7/27/23, 15:01:29] Gokul Krishnan: ‎image omitted
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 15:03:49|Yes. Definitely. Already struggling with it ‎[7/27/23, 15:04:11] Nirant: ‎GIF omitted ‎[7/27/23, 15:04:41] Gokul Krishnan: ‎GIF omitted
Nirant|2023-07-27 15:04:58|These are Engineering roles already anna
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 15:05:53|Yes, but increasingly non technical folks are /will be owning the writing of the prompts.
Gokul Krishnan|2023-07-27 15:06:15|But anyway, isn't it a corollary that WITCH companies will go to zero  in 10 years if this is the case? Not saying they don't have deep tech but that they don't make their bread and butter with it
Nirant|2023-07-27 15:07:05|Not go to zero but yes, they'll find it hard to do better than inflation
Gokul Krishnan|2023-07-27 15:09:08|Last 20 years have been great for them even though what you said applied for web technologies in the last two decades
Prakash Sankar Harbor|2023-07-27 15:12:40|I disagree. I don't think most PMs are good at being disciplined around defining and an experiment and measuring it. Not because a good PM wouldn't be good at it, but because in general it's a rare skill.
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 15:12:58|Yes, do think so. No, low code versions of prompt management is a good picks and shovels play  For example, let's say you are building a customer service agent, and want to edit prompts to train it to respond better to certain inputs or questions  It'll be inefficient if the ownership of that resides with an engineer.  Much better if it resides with the customer service manager or person in charge of that product.  Who can see where it underperforms, adjust prompts, and test impact. A bit like how you would train a junior employee  So there's rapid iteration, and lesser Chinese whisper in translating instructions
~ pt|2023-07-27 15:13:04|It's possible services will grow because it'll be a lot easier to build stuff in house instead of paying a third party saas
Prakash Sankar Harbor|2023-07-27 15:15:40|on the flipside, most engineers are pretty shit at writing and lateral thinking.
Bharat Kumar Ramesh Hashmal Web3|2023-07-27 15:18:04|The other razor in my head is that the prompt should ultimately be owned by the person who's responsible if the model screws up and says some random shit  Given the non deterministic nature of it, and how central it would be to the customer experience, I'd think that person would also have to be the owner of the product
Hemant Mohapatra|2023-07-27 15:40:51|https://www.scientificamerican.com/article/controversial-physicist-faces-mounting-accusations-of-scientific-misconduct/  Unrelated to the group but a good reminder nevertheless that extraordinary claims require extraordinary evidence.  Arxiv isn't peer reviewed but I've often been in conversations where engg leads are reading and trying out new genAI methodologies on a weekly basis. Might be a distraction at this point unless done in moderation and carefully choosing where to dig deeper into.
Bulia Siddharth Aurashop|2023-07-27 15:48:44|It is already happening now. A friend at a VC is observing this trend. Lot more service companies are coming in. People want to get things developed in-house.
Bulia Siddharth Aurashop|2023-07-27 15:48:46|API glueing at FAANG or CRUD at growing startup is paying well so far!   When low level things are sorted, folks can focus lot more on bigger picture/module/systems and that leads to better offerings. And companies then hire more (given they are growing) Similar will happen here in ML.  Maybe new roles will be called ML-SDEs 😅 ‎[7/27/23, 15:50:52] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-07-27 15:50:53|https://invertedpassion.com/commoditize-your-value-chain/
Bulia Siddharth Aurashop|2023-07-27 15:51:11|This is actually a different paper. The one doing round on twitter is by korean authors.   But yes, agree that non-peer reviewed papers can’t be taken at face value.
Paras Chopra Wingify|2023-07-27 15:51:34|It’s got to happen. The excess profit of “assembly” / “trading” in any value chain tends to drop to zero
Paras Chopra Wingify|2023-07-27 15:51:49|It’s at the extremes (R&D and customer interface) where profit accumulates
ashish Acgt01 Twitter|2023-07-27 15:55:37|Cool paper from Google on Med-PaLM M: a multimodal biomedical LLM  https://twitter.com/vivnat/status/1684409989899911168?s=20 https://arxiv.org/abs/2307.14334  tweetorial : https://twitter.com/vivnat/status/1684404882844024832?s=20
Abhishek Mishra|2023-07-27 16:02:10|https://twitter.com/liuziwei7/status/1684196910716919815?t=XuzsA1AQZAjxAixxZzCbiQ&s=08
Abhishek Mishra|2023-07-27 16:02:53|A 7B llama2 fine tuned with multi-modality in the mix.  Can successfully tag, caption and describe images and chat over them.
Abhishek Mishra|2023-07-27 16:03:07|Named as Otter.
Abhishek Mishra|2023-07-27 16:03:46|"Reminds me of the paper by Feynman - ""There's plenty of the room at the bottom"""
Dr. Pratik Desai KissanGPT|2023-07-27 16:03:57|Looks like rewind got access to GPT4 multimodal
Abhishek Mishra|2023-07-27 16:04:36|Ohh, totally possible.
Dr. Pratik Desai KissanGPT|2023-07-27 16:05:24|That’s why they are able to find images and content inside in search.
Dr. Pratik Desai KissanGPT|2023-07-27 16:06:26|I want to do it for finding pest and disease in crops without paying licensing to paid datasets
Abhishek Mishra|2023-07-27 16:06:58|You'll need to find a labelled image dataset perhaps.
Dr. Pratik Desai KissanGPT|2023-07-27 16:07:13|I’m cheap so I’m going to try this model and evaluate.
Abhishek Mishra|2023-07-27 16:07:40|It may work well out of the box for most cases. Pareto efficiency and all.
Dr. Pratik Desai KissanGPT|2023-07-27 16:07:41|Hopefully OAI already got “access” to some of those
~ vignesh iyer✌️|2023-07-27 16:32:44|https://www.aboutamazon.com/news/aws/aws-summit-new-york-generative-ai  AWS is taking a very measured, cautious approach to generative AI emphasizing more on the significance of foundation models.. in the recent NYC summit, no groundbreaking announcements but Swami's keynote is worth listening to
Pratyush Choudhury|2023-07-27 16:33:11|The agents bit was ground breaking I felt
Pratyush Choudhury|2023-07-27 16:33:28|And also the healthcare scribe - didn't expect AWS to launch so many app level innovations this quickly
~ Trinath Yarlagadda|2023-07-27 16:33:45|‎~ Trinath Yarlagadda was added
~ Arjun|2023-07-27 16:33:45|‎~ Arjun left
~ vignesh iyer✌️|2023-07-27 16:35:01|Everyone wants a piece of Healthcare tech.. but it always plateau after initial inroads.. none of the big tech has handled health tech as well as Apple so far..
~ vignesh iyer✌️|2023-07-27 16:35:16|Yep.. very promising
Dr. Pratik Desai KissanGPT|2023-07-27 16:42:43|US Health care industry is guarded by many moats and defenses.
~ Khauneesh|2023-07-27 16:43:46|Hi All,  Looking for advise/help for one of the use cases. We want to create a solution which can interact with whole database.The database being singlestore.It has data related to sales , deals , orders quotes etc. Currently I tried for one table where I provide schema of that table as a context(basically whole schema with table and column descriptions is stored on singlestore itself as vectors) Now want to scale this for all tables, is there a better way to do it? as writing column descriptions for all tables can be very tedious, i have tried langchain sql agent as well but it didn't work well. ‎<This message was edited>
Nirant|2023-07-27 16:47:30|defog.ai does this for a living, might be worth checking they've a blog
~ Khauneesh|2023-07-27 16:48:17|Also I have looked into defog.ai, not sure my company will opt for 3rd party solutions, has anyone worked on in house production grade solution for above use case?
Paras Chopra Wingify|2023-07-27 16:50:15|does it read text in images, like ocr?
Krishna Ntkris|2023-07-27 16:53:55|Hey Khaunesh, we recently shipped the ability to connect databases with our product. I'll need to understand a bit more, I'll DM you.
~ Khauneesh|2023-07-27 16:56:22|sure
Sainath GenerativeAI WhatsApp Group|2023-07-27 17:00:00|When you say an in house solution, do you mean hosting own llms?
Abhishek Mishra|2023-07-27 17:00:56|I've not checked the paper yet. Their tweet mentioned that it can tag and caption very well. Maybe they tested for OCR, let me check.
~ Khauneesh|2023-07-27 17:02:46|No not own llms but using openAI to create solutions for text to sql over a database
Atishay Jain|2023-07-27 17:04:17|Hey khauneesh, I can help you out with our solution which you can deploy within your premise.  You can easily scale it upto 100s of tables,   auto generate sharable data catalogue, manage access,  model improvement using feedback . ‎[7/27/23, 17:04:58] Abhishek Mishra: ‎image omitted ‎[7/27/23, 17:04:59] Abhishek Mishra: ‎image omitted ‎[7/27/23, 17:05:00] Abhishek Mishra: ‎image omitted
~ bhanu.io|2023-07-27 17:08:30|[PHONE] runs consumable.ai which does the same thing,  they are also working on an on-premise thing which can be useful to you.
Atishay Jain|2023-07-27 17:10:19|Please DM me if you want .   we are already working with  enterprises and the solution is completely private, not even your schema goes out of your server.  We will help you use your data from code, data pipelines, existing queries, dashboards to improve model performance.
~ Apurva Bhatt|2023-07-27 17:10:29|https://partiful.com/e/WLszTLRL4ftfhEqBtKGD
~ Apurva Bhatt|2023-07-27 17:17:39|It's a hackathon by anthropic for their new model
~ Apurva Bhatt|2023-07-27 17:17:50|Claude 2
Ravi Theja|2023-07-27 17:18:57|Please note that this event will be held in person, so we're unable to support remote teams.
~ Arko Cy|2023-07-27 17:29:13|any provision for streaming ?
Shashwat TDC|2023-07-27 17:33:17|thanks for the shout-out [PHONE].  [PHONE] can connect when you are open to 3P solutions. Essentially scaling what you been able to achieve in-house requires an ensemble-based approach to maintain the desired accuracy. As tables and columns context increases, plain vanilla gpt translation performs poorly.
Shashwat TDC|2023-07-27 17:52:25|aur hum desi (tested on extreme databases conditions) alternate h. Just not funded yet :P - We are not marketing/ selling currently but if anyone is keen on trying out, can reach-out. Fits well with cost optimization exercise (meaningful cost-save if analytics server cost = 10 lac INR/ month +) Always happy to onboard exciting design-partners. We come at 250$/m. Design-partner discount = 50% 🤝
Shashank B Designer|2023-07-27 18:54:11|Hi, has anyone worked on this? Thinking of doing an ad hoc discussion over video today
Sumod K Mohan|2023-07-27 19:10:51|Yeah, folks doing Symbolic, NeuroSymbolic, passing knowledge graph to LLMs,  using LLM along with Knowledge graph,  RL for LLM, Prob Prog etc too can join. Ping  [PHONE] or me.
Shashank B Designer|2023-07-27 19:23:18|Discussion is at 7:40 on https://meet.google.com/ndm-xbqb-fdm for those interested
ashish Acgt01 Twitter|2023-07-27 19:26:47|stack overflow launches overflow ai  https://www.youtube.com/watch?v=DM9-cYyeaDg  https://stackoverflow.co/labs/  - integration with vs code ? ‎<This message was edited>
Edgar Monis Mumbai WHO|2023-07-27 19:28:36|Just thinking
Edgar Monis Mumbai WHO|2023-07-27 19:28:59|If someone could build a search stack overflow integration with VS code. That would've been so great as well
ashish Acgt01 Twitter|2023-07-27 19:32:57|"what do you guys think of this ?  ""I wonder how a decentralized, hierarchical LLM would perform. For example:  LLM A is trained on all of Wikipedia LLM B is trained on all of Hacker News LLM C is trained on all of Project Gutenberg User asks question Q on webservice W. W sends Q to A and B.  Then W sends a question to C ""Hey C, I have a user who asked Q. Here is A's reply and B's reply. Given those, how would you answer Q?""  Would the answer be as good as or better than what an LLM which is trained on Wikipedia, Hacker News and Project Gutenberg would return?  If it is of similar quality, then we could build a hierarchical tree of consumer hardware LLMs which are hosted all over the world.""  https://news.ycombinator.com/item?id=36892161"
Pratik Bhavasar|2023-07-27 19:45:09|Does not individual training break the scaling law of data leading to inferior models?
Dhruv Anand|2023-07-27 19:48:18|That already existed
Dr. Pratik Desai KissanGPT|2023-07-27 19:49:25|I missed this but can you provide context of this?
ashish Acgt01 Twitter|2023-07-27 19:50:08|[PHONE]  fyi
~ Vishwam Jindal|2023-07-27 21:25:40|I am using RetrievalQA and trying to overwrite the chain to include guardrails at each LLM call. Facing some issues - can you please help? Thanks [PHONE]
Nirant|2023-07-27 21:29:01|Guardrails has a pretty active Discord and perhaps you should ask your specific question there? https://discord.gg/Jsey3mX98B
Paras Chopra Wingify|2023-07-27 22:12:09|Is anyone building aibo like pet robots with LLMs hooked
Paras Chopra Wingify|2023-07-27 22:12:40|Should be fun, seems like a big opportunity   Even a dumb furby like robot to have around would be fun
Paras Chopra Wingify|2023-07-27 22:15:54|This seems hackable https://www.elephantrobotics.com/en/mars-en/
Sandeep Srinivasa RedCarpetup|2023-07-27 22:16:18|https://github.com/microsoft/PromptCraft-Robotics
ashish Acgt01 Twitter|2023-07-27 22:20:05|reminds me of Astro, the supposed king of home robots from amazon,  which didnt go anywhere  https://www.theverge.com/2023/5/16/23725539/amazon-astro-vp-robotics-ken-washington-leaving
Dr. Pratik Desai KissanGPT|2023-07-27 22:20:39|You will have to replace Raspberry Pi with Orange Pi 5, which has Rockcip chip with GPU cores, and may be able to run 3B model. ‎<This message was edited>
ashish Acgt01 Twitter|2023-07-27 22:25:28|"this is so freaking cool ! gen ai is accelerating robotics !  imagine a defence/police usecase : instead of a human controller, laboriously navigating a drone in an ""incident"", what if you could ""tell the drone"" in text/voice- go to this room of the building or give it a set of images of suspects to scan a building for !"
Dr. Pratik Desai KissanGPT|2023-07-27 22:28:00|"I doubt as it is in the current form. Moravec's paradox. Good for ""Talk"" application but not Control system."
Shimanta Generative AI|2023-07-27 22:29:05|Someone built this back in April https://twitter.com/jessicard/status/1642671752319758336?s=46&t=WT1iAtjftW-5_e62F8FZTg ‎[7/27/23, 22:29:19] Alok Bishoyi: ‎image omitted
~ Trinath Yarlagadda|2023-07-27 23:05:44|I think it would work well if there is a protocol around agents specialized in knowledge can communicate to each other on the final outcome or to a single agent which can then include certain instructions around swarm intelligence using instructions such as tree of thoughts.   The outcome maybe poor if it’s a one way communication with llm with specialized knowledge. You need another analysis agent(s) who can then analyze and challenge those specialized llm to provide more robust info. Is it going to be cheaper than a model such as gpt-4 once the cost of gpu goes down- idk. But it’s worthwhile experimenting around it.
Saurav Tomar GenerativeAI WA Group|2023-07-27 23:52:54|For anyone looking to experiment with llama 2, replicate has a handy tutorial to do the same https://replicate.com/blog/run-llama-2-with-an-api
~ Rukesh Reddy|2023-07-28 00:10:23|‎~ Rukesh Reddy requested to join
~ Rukesh Reddy|2023-07-28 00:10:57|‎~ Rukesh Reddy joined using this group's invite link ‎[7/28/23, 00:22:07] Sandeep Srinivasa RedCarpetup: ‎image omitted
ashish Acgt01 Twitter|2023-07-28 00:50:03|https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms.html
~ Prateek🖤|2023-07-28 02:01:11|This was on point 🔥  Facing similar challenges with an enterprise level use-case comprising of GPT4 and vector databases🥲
Kaushik S YC W23|2023-07-28 02:55:10|With the GPT-4 rate limits, is it a viable option in enterprise apps?
Abhinav Verma Longshot.ai|2023-07-28 02:56:49|Yes. There are creative ways to use it. Plus I think you can request a higher rate limit
Kaushik S YC W23|2023-07-28 03:39:09|What is the best way?
Nilesh Transcend|2023-07-28 06:15:34|Anyone from indian edtech building Khanmigo equivalent with LLMs?  https://www.khanacademy.org/khan-labs#khanmigo
Kiran Darisi AtomicWork|2023-07-28 06:43:09|Toddle ? https://www.linkedin.com/posts/deepanshuarora88_ai-aiineducation-activity-7089270218450989056-t_ks
Nilesh Transcend|2023-07-28 06:57:25|Interesting 👍but not quite.
Nilesh Transcend|2023-07-28 06:57:46|* not quite what Khanmigo is.
Gayathri Meka Hyperverge|2023-07-28 07:03:27|We at HyperVerge Academy were inspired by Khanmigo and we're building a tool similar to it, but for employability, called SensAI. Happy to chat more async, I'm actually planning to put out a demo on LinkedIn today, we are looking for more interns to build this out😅
~ Sid|2023-07-28 09:21:51|‎Ravi Theja added ~ Sid
Paras Chopra Wingify|2023-07-28 12:30:03|https://llmboxing.com/
Paras Chopra Wingify|2023-07-28 12:30:11|Surprised at how often I chose llama2 70b
Sandeep Srinivasa RedCarpetup|2023-07-28 12:39:10|llama2 is just as good as gpt4 ...if we remember that gpt4 is not one model, but a MOE.  pretty sure the same architecture on llam2 will perform just as well
Chaitanya A GenAI|2023-07-28 12:40:28|what dyu think the different gpt4 experts are trained on?
ashish Acgt01 Twitter|2023-07-28 12:41:28|was reading about moe today   This was quite insightful : https://news.ycombinator.com/item?id=36898494
~ Rukesh Reddy|2023-07-28 12:42:11|If anyone has experience or insights on RLHF for LLMs could you please DM? I am looking to explore business / ops opportunities in model training and fine tuning stages. Thanks
Sandeep Srinivasa RedCarpetup|2023-07-28 12:43:28|This is true, but that is why llma2 trainability ought to be very conducive for a similar architecture
~ Rukesh Reddy|2023-07-28 12:43:45|This is me btw: https://www.linkedin.com/in/rukeshreddy. Quite a noob in AI but looking to ramp up
Dr. Pratik Desai KissanGPT|2023-07-28 12:44:49|Yes this should be possible with multiple expert fine tuned llama2 70b. But an operator on scale can only run with economical efficient number or privacy use cases.
Paras Chopra Wingify|2023-07-28 12:54:23|Is anyone trying MOE on llama2
~ Sid|2023-07-28 12:55:26|apart from the quality of answers, time taken to answer should also be checked. in many cases we can compromise with quality if there is huge difference in response time.
Dr. Pratik Desai KissanGPT|2023-07-28 12:55:39|I haven’t figured it out technically, but would love to discuss and try if someone has a lead.
~ Sid|2023-07-28 12:56:19|can someone give me good links for MOE
Dr. Pratik Desai KissanGPT|2023-07-28 12:58:02|The HN news link few messages above has two good papers to learn more
Shimanta Generative AI|2023-07-28 13:00:34|The longer answer was llama2 in 4 of 5 cases. Won’t the results be skewed?
~ Sid|2023-07-28 13:03:10|yes in almost all the cases, I was able to figure out the answer is provided by Llama2 as it was very long, and GPT3.5 response was concise. (does not mean one was better over another)
Paras Chopra Wingify|2023-07-28 13:10:36|I’m imagining MOE will require less compute v/a training from the scratch
Paras Chopra Wingify|2023-07-28 13:12:12|The HN comment suggests this isn’t true, so training won’t be straightforward
Nirant|2023-07-28 13:13:08|https://ai.googleblog.com/2022/11/mixture-of-experts-with-expert-choice.html?m=1  Sparse MoE: https://arxiv.org/abs/2305.14705 (haven't read this, looks promising though)
~ Rahul Bansal|2023-07-28 13:19:30|One thing I noticed is llama answer are bigger
Sandeep Srinivasa RedCarpetup|2023-07-28 13:19:59|the challenge really is to optimize cpu. the replacement of the bottom layer to a MOE layer is not compute efficient. that is really the limiting factor right now.
~ Asad|2023-07-28 13:24:56|‎~ Asad requested to join
~ Trinath Yarlagadda|2023-07-28 13:26:57|Check out this session next week- maybe it can help https://www.eventbrite.com/e/mastering-rlhf-with-aws-a-hands-on-workshop-tickets-681013940027
Sumod K Mohan|2023-07-28 13:28:29|You can talk to [PHONE]
~ Kushaal Devanahalli|2023-07-28 13:40:40|Happy to help. Reaching out on dm.
ashish Acgt01 Twitter|2023-07-28 13:43:09|"Interesting eval question : do we(humans) tend to evaluate/assess a longer generative answer as ""better"" ? Very subjective to the particular human doing the eval and their inherent biases. ‎<This message was edited>"
Paras Chopra Wingify|2023-07-28 13:59:48|Spends
Paras Chopra Wingify|2023-07-28 13:59:55|Sorry, depends on the context
Paras Chopra Wingify|2023-07-28 14:00:29|In the age of reels, many prefer shorter answers but I prefer longer ones
Nirant|2023-07-28 14:00:50|Depends on whether you went to ICSE (no extra marks for length) or CBSE (extra marks for longer answer) 🤣
Nirant|2023-07-28 14:01:46|^This is a joke — wanted to highlight how human preferences are a function of prior training and recent experiences/roles/needs both — and not stable for a specific individual
~ Srinivasan Nandakumar|2023-07-28 14:02:00|https://twitter.com/aicrumb/status/1681873857097940992?t=7PXB277KSaRfeC_iRBTaPQ&s=19  Check this out. It's a great start.
~ Srinivasan Nandakumar|2023-07-28 14:03:01|Author trained different loras and tried making an MOE out of it
~ Sid|2023-07-28 14:03:08|in some cases explanations are required when answer is complex, short answer is better when it is not complex.
ashish Acgt01 Twitter|2023-07-28 14:05:37|"I prefer longer ones too with  2 caveats : 1. there is extra *nuance* in the longer one 2. It's not super long or annoyingly long :)  And as Paras said, depends on the context of my particular ""information need"" - casual interest in a one off question vs need to write a deep dive blog post and doing research for it. ‎<This message was edited>"
Tarun SaaSBoomi|2023-07-28 14:08:00|‎Tarun SaaSBoomi requested to join
Tarun SaaSBoomi|2023-07-28 14:13:25|‎Tarun SaaSBoomi joined from the community
~ Asad|2023-07-28 14:13:28|‎~ Asad joined using this group's invite link
Chaitanya A GenAI|2023-07-28 14:15:26|https://www.businesstoday.in/technology/news/story/amd-to-invest-400-million-in-india-to-set-up-largest-design-center-in-bengaluru-391646-2023-07-28#:~:text=This%20investment%20by%20AMD%20will,by%20the%20end%20of%202028.&text=US%20chipmaker%20Advanced%20Micro%20Devices,over%20the%20next%20five%20years.
Amit Bhor|2023-07-28 14:32:25|‎Amit Bhor requested to join
Amit Bhor|2023-07-28 14:34:38|‎Amit Bhor joined using this group's invite link
Sandeep Srinivasa RedCarpetup|2023-07-28 15:15:41|is there a hosted api for llama2 ? happy to get a subscription as well. need it for testing purposes.
Nirant|2023-07-28 15:17:40|https://replicate.com powered https://llama2demo.streamlit.app
Sandeep Srinivasa RedCarpetup|2023-07-28 15:18:32|a100 ?
Nirant|2023-07-28 15:22:55|Yes
~ Mohit|2023-07-28 15:38:03|This is great! Found it really useful to quickly validate some ideas rather than going through the entire setup myself. Just a minor UI-related suggestion - can you make the feedback emojis slightly bigger? ( I really had to squint to differentiate between the 3 types)
Abhishek Mishra|2023-07-28 15:40:44|Nature of your question would matter. Are you asking for information and description on a topic? Then the more relevant info the better it is. If you're asking it a precise question, any needless gabbering is unwanted.
Nirant|2023-07-28 15:42:52|Will try to make time after the meetup tomorrow!
Abhishek Mishra|2023-07-28 15:43:17|I'm sorry but this is a bad lora fine tune as well as a bad final question answering with  MoE.
Abhishek Mishra|2023-07-28 15:44:23|The lora llama 7B fine tune has lots of repetitions even though it has information, that shows bad parameter settings. Repetition penalty, top k can be changed to fix that to some extent.
~ Sid|2023-07-28 15:44:27|is this streamlit app open source? need to check feedback system that is implemented. ‎[7/28/23, 15:44:57] Paras Chopra Wingify: ‎image omitted
Abhishek Mishra|2023-07-28 15:45:07|The MoE answer just looks like an appended set of answers from different models.  Answer 1- Answer 2- Answer 3-
Nirant|2023-07-28 15:45:12|github.com/nirantk/llama2demo/blob/main/app.py
~ Sid|2023-07-28 15:45:26|thanks.
~ Srinivasan Nandakumar|2023-07-28 15:45:45|I don't think the author cared too much about fine-tuning it properly. Every training run was done on colab in 40 minutes. The main idea was to see if the mixing of Loras works as a proof of concept.
Abhishek Mishra|2023-07-28 15:47:05|The mixing itself should use the idea of either gating functions for weighted answer or an approach similar to RAG where the main model is just asked to create a final answer based on answers generated by experts
Abhishek Mishra|2023-07-28 15:47:25|It should not be append one answer next to another by different models
~ Srinivasan Nandakumar|2023-07-28 15:49:32|That's not what's being done from what I've understood. The dataset is clustered into different clusters and each cluster is finetuned to create a lora. These are then attached to the model. The input prompt is embedded and measured against each cluster for similarity. The similarity is then used as weightage to combine the lora weights and then inference is run.
~ Srinivasan Nandakumar|2023-07-28 15:52:20|https://twitter.com/aicrumb/status/1681846805959528448?t=ls-jKHMsB9F00w3GCXrvpQ&s=19  The notebook in this link goes through the steps.
Abhishek Mishra|2023-07-28 15:52:24|Ok, the tweet didn't mention the architecture. I'll check out the poc colab to understand it better. There are many approaches to take for this and this may be a very good starting script for people to start tweaking it. Though the mixing is lacking for now.
Abhishek Mishra|2023-07-28 15:53:08|Thank you
Nirant|2023-07-28 15:53:30|This might be more flexible though since vector search is cheap and fast
Abhishek Mishra|2023-07-28 15:54:05|True, vector search is way fast and cheap compared to inference
Paras Chopra Wingify|2023-07-28 16:00:31|its not exactly LORA, he's routing the same query to top N lora-lammas (based on similarity to input) and weighing their outputs
Paras Chopra Wingify|2023-07-28 16:01:01|sorry, not exactly MOE
Amit Bhor|2023-07-28 16:10:19|https://twitter.com/RylanSchaeffer/status/1684701838661332997?t=PmKpO1CPBYM2wbwRZbZzlg&s=08
Abhishek Mishra|2023-07-28 16:51:12|https://twitter.com/WizardLM_AI/status/1684800111057244160?t=e9AzEPWMqgiCwBORahsJJw&s=08
Abhishek Mishra|2023-07-28 16:51:51|A successful approach to good dataset preparation
Paras Chopra Wingify|2023-07-28 17:10:02|">creating a ""130b"" moe by creating 10 loras for llama13b and having a router based on knn clustering of the training texts and top-k clusters of the prompt estimated and softmaxed to create an alpha for each of the k inference loras that we use to do a weighted sum of logits  does anyone understand this part: ""create an alpha for each of the k inference loras"""
Paras Chopra Wingify|2023-07-28 17:10:19|the easy way is to average the logits amongst chosen models
Paras Chopra Wingify|2023-07-28 17:10:32|why do weighing and how is it working?
Paras Chopra Wingify|2023-07-28 17:16:49|>Instead of having static weights, MoLora measures the similarity between a given model prompt and each of the data clusters. This similarity then becomes the basis for each LoRA adapter’s weights.  got it
Paras Chopra Wingify|2023-07-28 17:17:11|it's interesting to note that this guy is 18 years old :)
Aditya Sista 2010B5|2023-07-28 17:17:20|How is llama2 in comparison with gpt 4 for coding and code understanding tasks?
Paras Chopra Wingify|2023-07-28 17:18:37|">i trained these at 1e-4 learning rate, rank 2 but you should probably use rank >=8, these only went for 128 steps at batch size 16 (2048 examples) but i think anything serious should go further than that as well  anyone knows what ""rank 2"" here mean in finetuning / LORA context?"
Paras Chopra Wingify|2023-07-28 17:20:28|i suspect this is LORA specific think. oh, maybe it is rank of the matrix they derive?
ashish Acgt01 Twitter|2023-07-28 17:30:19|Haven't read the paper but that would be my guess. Rank of the matrix they use.
Dhruv Anand|2023-07-28 17:41:14|Does anyone know of an API that provides glove/fasttext embeddings vectors? I know that they are simply a large text file of one vector per vocabulary word, but I'm looking to use a service where I can send a sentence and receive the pooled embedding for it.
Dhruv Anand|2023-07-28 17:42:02|would also like to know folks' opinion about whether embeddings via SentenceTransformer for short strings would be strictly better quality than the glove/fasttext ones
Nirant|2023-07-28 18:00:20|Tagging our embedding god [PHONE]
Abhinav Verma Longshot.ai|2023-07-28 18:01:16|Sbert does glove as well
Alok Bishoyi|2023-07-28 18:11:39|Wanted to store / log all responses of github copilot chat inside vscode for future finetuning purpose.  Anyone has recommendations for how to proceed or tools that enable this ?
~ Srinivasan Nandakumar|2023-07-28 18:12:51|r value when you are setting it in the left value
~ Srinivasan Nandakumar|2023-07-28 18:13:01|* setting it in the peft library
~ Srinivasan Nandakumar|2023-07-28 18:13:27|So generally we set r to be 8/16.
Abhishek Mishra|2023-07-28 18:16:36|Rank here is the rank of a matrix. In essence, without going into the maths involved, lower the rank you're choosing the smaller Matrix you're working with and the lesser parameters you're fine tuning
Abhishek Mishra|2023-07-28 18:17:56|While choosing lower ranks helps in cutting down the number of parameters to work with end also the overall GPU requirements, going too low in terms of rank can lead to a bad learning setup overhaul
Abhishek Mishra|2023-07-28 18:17:58|*overall
Abhishek Mishra|2023-07-28 18:19:06|So the author chose really low rank here helping him work with very small footprint, he may also think better learning should be preferred if you can manage the compute
~ Srinivasan Nandakumar|2023-07-28 18:20:08|My guess for weighing is you would want weights learned from certain cluster of the dataset which is closer to the input prompt to contribute more to the output and ones further away to contribute less.
~ Srinivasan Nandakumar|2023-07-28 18:21:52|With respect to how's it working if you check the notebook, the weights are assigned based on the cosine similarity of each cluster to the prompt. Checking the merge lora function under might help. I was looking to do this.
Kiran Jonnalagadda|2023-07-28 18:23:02|A Deccan Herald journalist wants to ask about the tech of deep fakes. Does anyone want to talk to her?
ashish Acgt01 Twitter|2023-07-28 18:23:48|RT2 : a llm model for robotics from google  https://blog.google/technology/ai/google-deepmind-rt2-robotics-vla-model/  https://robotics-transformer2.github.io/  https://news.ycombinator.com/item?id=36905076
~ Srinivasan Nandakumar|2023-07-28 18:25:18|The notebook has the code for the alpha. It's explained as mainly trying to stretch the differences between clusters as they might be close. I think it's just a performance aiding technique.
Pratik Bhavasar|2023-07-28 18:27:59|Well I cannot confirm nor deny for sure but I did not find them reliable when working with closed domain data. Models have improved since then. I am talking about scenario when query is short and document is a sentence making it asymmetric search.
~ Srinivasan Nandakumar|2023-07-28 18:29:04|'Add_weighted_adapter' function under  peft.  Apologies for the mistake.
Abhishek Mishra|2023-07-28 18:34:21|There's no fixed strategy to mixing the results. Weighted average based on similarity is one of the most useful and basic approaches.
Pratik Bhavasar|2023-07-28 18:36:13|You know there is only one embedding god -> Nils R
Nirant|2023-07-28 18:38:38|Embedding Priest then?
Pratik Bhavasar|2023-07-28 18:39:03|Let’s go with Janitor😄
Nirant|2023-07-28 18:39:13|Besides, we're a polytheistic religion, I am okay with more than one god 🙈  (Will shut up because off topic)
Pratik Bhavasar|2023-07-28 18:40:08|Haan but not all are theist 🤷‍♂️
Shimanta Generative AI|2023-07-28 18:56:07|Coming to this again since I just saw it. It is an interesting thought, and yes I too believe it is subjective to the person. For me, I realised that the longer ones are mostly llama responses when I completed the set of 5 questions. So if there were more questions, then it might inject a bias in the way I eval the later questions.
Amit Bhor|2023-07-28 19:34:24|Any CoT fans here? Pretty big implications here especially for agent based approaches.
Anubhav mishra Zupay|2023-07-28 20:42:34|Hi guys,   Does anyone have access to the Google search labs ? Has anyone tried playing around with it ?
Sandeep Srinivasa RedCarpetup|2023-07-28 21:09:21|Hey thanks for this. Yup track this area very closely
Sandeep Srinivasa RedCarpetup|2023-07-28 21:11:29|This is an insane result though. Cot basically beats the shit out of any algorithmic accuracy.  I'm betting this opens up research into fine-tuning targeted for specialised cot
Paras Chopra Wingify|2023-07-28 21:41:36|Insane, why should this be?
Samhan Meta/Twitter Friend|2023-07-28 21:45:46|Because the prompt is activating the right templates that it has learned . So the exact content in the prompt doesn’t matter as much
Samhan Meta/Twitter Friend|2023-07-28 21:45:53|Have read this theory in other papers
Samhan Meta/Twitter Friend|2023-07-28 21:47:45|Prompts are fuzzy matched to algorithms that are learned from the training data. Generally it’s quite easy to observe that the model often ignores some instructions in the prompt. And it can be quite random which instruction is followed and which one ai ignored . The longer and more complex the prompt the more this becomes an issue
~ Sachin Kalsi|2023-07-28 21:48:55|https://www.linkedin.com/posts/metaai_llama-2-open-foundation-and-fine-tuned-chat-activity-7090722591966990336-Tbqn  further details about the architecture, training compute, approach to fine-tuning and more for Llama 2.
Samhan Meta/Twitter Friend|2023-07-28 21:49:25|I saw an example where for sentiment analysis you can switch around the labels in the prompt but the models will do it the right way around.
Samhan Meta/Twitter Friend|2023-07-28 21:52:04|I think there’s a fundamental limitation where every token only has a fixed amount of steps to be computed. But the tokens cannot always be of the same difficulty. This is probably not solvable with current transformers
Paras Chopra Wingify|2023-07-28 21:52:19|Hmm, this seems like clustering.  But I read LLMs end up having a model built inside them too (I recall othello example).
Samhan Meta/Twitter Friend|2023-07-28 21:52:37|So the completions are “best effort” especially if prompt / problem is hard
Amit Bhor|2023-07-28 21:52:57|Yes, I think chain of thought is a misnomer, chain of patterns may better describe it
Samhan Meta/Twitter Friend|2023-07-28 21:53:22|That model is built from massive amounts of data. And then the prompt seems to pattern match into it. Those models are intelligent to a small degree but how to teach it new things is unclear to me.
Samhan Meta/Twitter Friend|2023-07-28 21:53:48|To add world knowledge you have to continue pre training with a massive number of tokens
Samhan Meta/Twitter Friend|2023-07-28 21:55:22|This becomes a problem where accuracy matters like math and code. If you’re writing a poem half assing it still gives you a readable / usable result ‎[7/28/23, 23:10:45] Sumod K Mohan: ‎image omitted
Sumod K Mohan|2023-07-28 23:19:30|This is a nice mechanism to compare for such tasks, you can clearly see (in further plots) how performance drops even for GPT4 as those metrics grows and how it clearly is way better than others. Would be interesting if they update with Llama2.
Sridhar Obilisetty Figo AI|2023-07-28 23:41:37|"This is a good event for folks in the bay area  == Generative AI Deep Dive: Models, Applications and Advancements -- Wednesday, August 2 | FalconX Incubator 691 South Milpitas Boulevard Milpitas, CA 95035 -- https://www.eventbrite.com/e/generative-ai-deep-dive-models-applications-and-advancements-tickets-665722934217  == ‎[7/29/23, 00:44:20] Abhinav Verma Longshot.ai: ‎image omitted"
Chetanya Rastogi|2023-07-29 06:36:54|Your prayers have been answered!  https://together.ai/blog/llama-2-7b-32k
~ Vik|2023-07-29 07:15:29|this is super cool and a bit scary. they're using an os model like vicuna to genrate adversarial prompts that can circumvent the protections on closed models. i can imagine a scanning bots that today look for web vuln's tomorrow try these against all text inputs that could be backed by llms. https://twitter.com/Yampeleg/status/1684938539727765504
Abhishek Mishra|2023-07-29 08:04:25|Just last night the LlongMa series owner dropped a 16K version 😂 using RoPE interpolation And now i wake up to find together AI release a 32k version using Flash attention 2
ashish Acgt01 Twitter|2023-07-29 08:46:52|"a nyt piece on rt2 from google :  ""A one-armed robot stood in front of a table. On the table sat three plastic figurines: a lion, a whale and a dinosaur.  An engineer gave the robot an instruction: “Pick up the extinct animal.”  The robot whirred for a moment, then its arm extended and its claw opened and descended. It grabbed the dinosaur.  Until very recently, this demonstration, which I witnessed during a podcast interview at Google’s robotics division in Mountain View, Calif., last week, would have been impossible. Robots weren’t able to reliably manipulate objects they had never seen before, and they certainly weren’t capable of making the logical leap from “extinct animal” to “plastic dinosaur.""  https://web.archive.org/web/20230728163905/https://www.nytimes.com/2023/07/28/technology/google-robots-ai.html"
~ Rahul Bansal|2023-07-29 08:52:18|https://github.com/llm-attacks/llm-attacks
~ Rahul Bansal|2023-07-29 08:52:38|I have not tried the attacks personally
ashish Acgt01 Twitter|2023-07-29 08:57:32|paper : https://arxiv.org/abs/2307.15043
~ Sid|2023-07-29 08:57:51|https://twitter.com/Shahules786/status/1683880849803202561?t=utBe3EAqc8rxZRHz_jIoBQ&s=08
ashish Acgt01 Twitter|2023-07-29 09:07:47|"""However, for most use cases you should not train a compute-optimal LLM but instead spend some extra compute to obtain a smaller model. Smaller models not only make inference faster and cheaper, they are also much easier to use for developers and researchers with limited GPU resources. Although many LLM practitioners train their models on more tokens than the Chinchilla scaling laws suggest, not everyone is aware that scaling laws can assist in determining how much smaller models we can train and how much additional compute is required.""  https://www.harmdevries.com/post/model-size-vs-compute-overhead/  https://twitter.com/_philschmid/status/1684958873369612288"
Pranjal Mehta|2023-07-29 09:34:27|https://erichartford.com/meet-samantha  Anyone here who as tried to fine tune a model like this?
Nirant|2023-07-29 09:53:07|When you got good investors/friends  https://twitter.com/erikdunteman/status/1685090911611744256
Shahul Kaggle Kernel GM|2023-07-29 10:17:17|Not exactly, but I know Eric and if you want to ask any specific questions I can help.
Sandeep Srinivasa RedCarpetup|2023-07-29 10:18:13|Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGM  Usually this.
Nirant|2023-07-29 10:22:03|What is the GGM in this? GGML?
Sandeep Srinivasa RedCarpetup|2023-07-29 10:24:07|ya. i missed the L. it is Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGML
Sandeep Srinivasa RedCarpetup|2023-07-29 10:28:53|interestingly, it was invented for porn. but it started getting used for usecases like companionship/mental health as well. WARNING: if u go searching for this stuff, u will end up in fairly unsavory parts of the internet (basically 4chan craziness).  but a great account of SuperHOT is here https://kaiokendev.github.io/til
Abhishek Mishra|2023-07-29 12:29:46|The process is the same as any other fine-tune. The key is picking up an unaligned base model like llama1 or llama2. Then using the alignment safety dataset, you remove all the parts where it refuses to answer and fine-tune on that.  This particular version, Samantha, was supposed to be a dedicated assistant model. But it was discontinued as the model was not very helpful.
Abhishek Mishra|2023-07-29 12:31:18|Then there are dedicated roleplay models like Pygmalion, SuperHOT
Nirant|2023-07-29 12:35:01|These are both erotic roleplay and not just roleplay like Pi?
Nirant|2023-07-29 12:35:25|Pi is the therapy-speak friend
Abhishek Mishra|2023-07-29 12:37:37|Yeah, they are uncensored versions. Pi is a safe, empathetic, friendly assistant.
Pranjal Mehta|2023-07-29 13:38:09|Didn't understand you
Pranjal Mehta|2023-07-29 13:39:05|That's a different fine tuned model. Like several others (Redmund Puffin, NousHermes, etc)
Krishna Panchal|2023-07-29 13:59:21|Which browsing plugin do you use for GPT4?
Atik Shaikh|2023-07-29 14:05:50|LinkReader / WebPilot
Amit Bhor|2023-07-29 14:08:27|Amazing. They backprop loss to the suffix tokens. Clever. What is indeed surprising is that it works for closed models with different embeddings.
~ Ashwin|2023-07-29 14:36:18|‎Zainab Bawa added ~ Ashwin
~ Sid|2023-07-29 15:07:29|[PHONE] are there any meetups in Gurgaon as well?
~ Gearskart|2023-07-29 15:08:55|Is there a webstream link to today's session.
ashish Acgt01 Twitter|2023-07-29 15:12:33|same q. cc: [PHONE] [PHONE]
ashish Acgt01 Twitter|2023-07-29 15:14:45|there is one on 4th august, coming friday, from 4-7pm http://hasgeek.com/fifthelephant/2023-07-delhi/updates
~ Sid|2023-07-29 15:29:47|great, I have registered.
ashish Acgt01 Twitter|2023-07-29 15:36:57|TIL ml papers curated by hf : https://huggingface.co/papers
~ Dx|2023-07-29 15:47:18|I believe it’s him/them https://twitter.com/_akhaliq?s=21&t=DvB_CFsuDr26gEneF0OJNw
ashish Acgt01 Twitter|2023-07-29 15:48:33|good option for someone like me who wants to reduce time spent on twitter :) ‎<This message was edited>
Shashank B Designer|2023-07-29 15:50:54|+1 to web streaming today’s event (or record and upload later) Cc: [PHONE] [PHONE]
Soumyadeep Mukherjee|2023-07-29 16:23:39|It’ll be recorded and uploaded later.
Shubham Sharma 2012C6|2023-07-29 17:05:52|Any thing happening in Mumbai anytime soon?
Nirant|2023-07-29 17:06:36|Cc [PHONE] was planning one for August
Shubham Sharma 2012C6|2023-07-29 17:08:22|Looking forward [PHONE]
Ambika Computational Mama|2023-07-29 17:20:54|All the best
Zainab Bawa|2023-07-29 17:22:32|Aniket and Harshad Saykhedkar are doing the Pune meet-up next weekend - https://hasgeek.com/genai_pune/2023-08/
Lalit Pagaria|2023-07-29 17:27:30|I was planning early August but held up at work. Also, I was waiting for Bangalore's meetup to be over as this time format was different.
Shubham Sharma 2012C6|2023-07-29 17:37:30|Ok ok
Sudharshan GenAI|2023-07-29 17:42:26|Has anyone heard back from AI grants?
~ Sid|2023-07-29 17:48:23|https://www.eventbrite.com/e/mastering-rlhf-with-aws-a-hands-on-workshop-tickets-681013940027?aff=Twitter&utm_campaign=Events+and+Community&utm_medium=social&hss_channel=tw-992153930095251456&utm_source=twitter&utm_content=258591492
Ishan Sharma|2023-07-29 18:19:27|I think they said 9th
Aayush Jain AWS|2023-07-29 22:04:23|‎‎Aayush Jain AWS changed their phone number to a new number. ‎Tap to message or add the new number.
~ Ayush Yadav|2023-07-29 23:55:17|https://github.com/AyushUnleashed/chat_gpt_api_for_everyone  Probably everyone here already  has openai api key but if you are anything like me.  18$ free credit expired & can't get api key because debit card declined.  This might help.  It's basically automation of ChatGPT UI using playwright so you can use it like api for your project testing. Therefore 0$ required.
Dev Aggarwal|2023-07-30 02:15:33|You now have to go one step ahead and automate playwright too
~ Ayush Yadav|2023-07-30 02:59:38|What do you mean exactly 😅
Dev Aggarwal|2023-07-30 03:03:23|https://openai.com/research/webgpt
Abhinav Verma Longshot.ai|2023-07-30 03:05:01|Gpt3.5 was webgpt model  add agents it became webgpt
Dev Aggarwal|2023-07-30 03:05:45|Citation needed
Abhinav Verma Longshot.ai|2023-07-30 03:07:31|The webgpt model was trained to answer user input from select passages from the web. This was something the 3.5 model text davinci 002 showed. Add an agent which does browsing you have webgpt
Abhinav Verma Longshot.ai|2023-07-30 03:07:51|The initial instruct models struggled with this.
Dev Aggarwal|2023-07-30 03:14:28|This Webgpt from 2021 is a crazy project that I dont think made the light of day and is definitely not as simple as browsing agents or reading passages.   See here - https://www.youtube.com/live/hhiLw5Q_UFg?feature=share&t=2070
Abhinav Verma Longshot.ai|2023-07-30 03:15:33|Yes. I got that. But browsing with agents using the RLHF models is derived from that
Abhinav Verma Longshot.ai|2023-07-30 03:16:34|In fact in the paper the way the browsing is described, where the first link of search query is taken, seemed very close to his chatgpt with browsing was modeled after
~ Ayush Yadav|2023-07-30 03:33:26|I'll readup
~ Rohan|2023-07-30 08:51:54|Does anyone know details about privacy policies of user-facing LLMs like GPT-4, Claude 2, etc? Someone asked me about using them at work with organization-specific information, but I couldn't find concrete details on how any data input to these LLMs could be used or released in the future.
~ Srijan Saxena 😎|2023-07-30 09:14:55|"They are allowed to use the data input by users later for training their model, aren't they? If you are thinking of sharing any confidential work-related information, I would assume it would be best not to do that. Also I read somewhere that since Chat GPT counts as ""third party"", disclosing sensitive information to it without proper authorization from your employer can be considered a violation of the NDA, potentially resulting in consequences."
~ Sid|2023-07-30 09:28:52|you can use azure service for openai with contract about confidential information. chatgpt has partnerd with azure and the models are on azure premises, no data goes for training.
Chaitanya A GenAI|2023-07-30 09:36:18|you can opt out of this by writing to OpenAI/Anthropic
ashish Acgt01 Twitter|2023-07-30 10:52:32|gzip beats bert part deux !  https://kenschutte.com/gzip-knn-paper2/ https://news.ycombinator.com/item?id=36921552  (part 1 : https://kenschutte.com/gzip-knn-paper/ https://news.ycombinator.com/item?id=36758433 ) ‎<This message was edited>
~ Atish Munje|2023-07-30 12:04:33|‎~ Atish Munje requested to join
~ Paras|2023-07-30 13:20:39|‎~ Paras requested to join
~ Kesava Reddy🤝|2023-07-30 14:26:57|‎~ Kesava Reddy🤝 requested to join
Pranjal Yadav Razorpay|2023-07-30 15:26:30|https://docs.google.com/presentation/d/1UEvCXnn8aWLQx5JS17zThojkuVTlqxRxkRqhs75IQNM/mobilepresent?slide=id.p  Tim's presentation of K-bit inference scaling laws.
~ Adithya|2023-07-30 15:29:31|Does anyone still use quantization anymore?
Sandya Mannarswamy|2023-07-30 15:32:23|Inference on cpus depend heavily on quantized models, as do uses of larger LLMs on low end GPUs
Pranjal Yadav Razorpay|2023-07-30 15:32:39|I read they are providing it, maybe with some limitations due to free vs enterprise version
Pranjal Yadav Razorpay|2023-07-30 15:36:04|When I think hierarchical, I go to MoE. You train a differentiable routing layers with your expert LLMs, hopefully small enough to fit many in one go.  Although, in your example, I can also image 3 LLMs glued together by K agents to apply ToT/GoT. It should perform better than routing due to multiple interactions.
~ Adithya|2023-07-30 15:38:25|I feel like a dinosaur saying that i deployed efficient det on the raspberry pi like models using quantization and int level precision
~ harshit|2023-07-30 15:48:40|‎~ harshit requested to join
Vamshi|2023-07-30 15:51:21|Guess it’s still highly relevant to run on anything battery operated ?
~ Raghav|2023-07-30 15:54:28|‎~ Raghav was added
~ Jatin|2023-07-30 15:54:28|‎~ Jatin was added
Abhishek Mishra|2023-07-30 17:32:42|Yeah it's used for local LLMs in inference. Also extremely popular for fine tuning llama2 using QLoRa. ‎<This message was edited>
~ Sid|2023-07-30 17:50:03|i have a use case where based on requirements, LLM should be able to give AWS architecture of the app. like connecting different services to achieve the goal. how do I tell the LLM about each service in detail? i guess i should fine tune the LLM, but I'm not sure about how the format should be of the training dataset. could someone please guide me.
~ gaurav|2023-07-30 17:53:35|Imo, scrap aws website for all the services, their use case pages, tutorial docs, then need to finetune them.  Still one major problem can be architecture is kinda different based on orgs. Current infra.
~ Sid|2023-07-30 17:55:08|how do I explain this information to LLM? for fine tuning we can give an instruction/prompt and it's output only right?
Pranjal Yadav Razorpay|2023-07-30 17:57:25|I have never found sufficient resources to do anything without quantization 😅
Pranjal Yadav Razorpay|2023-07-30 17:59:19|I'm starting to work on the same idea as a personal project. Happy to discuss thoughts in DM
~ Sid|2023-07-30 18:02:05|I'm also doing this as personal project only. but i don't have much knowledge about quantization yet.. let me read about it. i thought its used only for reducing size of LLM for local inference.
Aashay Sachdeva MPL Data Scientist|2023-07-30 18:04:09|Check out gorilla llm, they did it for huggingface apis
~ Krishaay|2023-07-30 18:26:55|One potential approach you take is fine-tuning to produce an architecture plan from the given requirements, essentially specialize for system design. Then you could pair it with a RAG system to output a plan using AWS infra. This will also let you use the same model for GCP or azure if the need arises.
~ Sid|2023-07-30 18:32:34|thanks, will check this out. 😊
~ Krishaay|2023-07-30 18:38:48|you can potentially extend the pipeline to build the plan by using starcoder or some coding model to write a terraform config for it as well.
Manas Ranjan Kar|2023-07-30 18:42:47|Caveat - AWS docs are terribly maintained for a few services. We have had very frustrating sessions with their engineers on sone key services like Sagemaker and SQS  I would surely look at other sources too like Reddit and Stackoverflow
Manas Ranjan Kar|2023-07-30 18:44:01|Agree - but how does one encode the system constraints? Like instance availability, zones, compliant services, RPS etc
Ankita Mathur Microsoft Sales|2023-07-30 18:45:18|There are some modernization tools like CAST which give a similar output if you are looking for training data sets for this use case
~ Sid|2023-07-30 18:47:41|yes, that's the plan, and use it with diagrams library for HLD https://github.com/mingrammer/diagrams
~ Sid|2023-07-30 18:48:43|yep, had very bad experience with AWS sagemaker team. on 2 instances they were not able to solve the problem and later on we solved it ourselves. 😅
~ Sid|2023-07-30 18:57:35|the issue for me is I am not able to understand schema of data set for fine tuning.
Abhishek Mishra|2023-07-30 19:36:09|Do you want to create an instruction dataset for api usage?
Abhishek Mishra|2023-07-30 19:37:01|Use this as reference to build your own dataset - https://huggingface.co/datasets/gorilla-llm/APIBench/tree/main
Lalit Pagaria|2023-07-30 19:43:26|I tried ChatGPT and able to achieve satisfactory architecture design using CoT prompting. Even generated terraform code, diagram, documentation, tests, various services code etc. ‎[7/30/23, 19:46:39] Lalit Pagaria: ‎image omitted
Atik Shaikh|2023-07-30 19:47:17|Can you please explain whats CoT prompting ? Heard it for the first time 😯
Lalit Pagaria|2023-07-30 19:48:36|I dont know the technical term but I generally assign LLM a role of tech architecture. And then ask it to design system in multiple prompts and correct also if it make error.
Nirant|2023-07-30 19:53:21|lilianweng.github.io/posts/2023-03-15-prompt-engineering  Look for chain of thought here
~ Sid|2023-07-30 20:01:48|it's Chain of Thoughts, you might have seen it in Langchain.
~ Sid|2023-07-30 20:03:06|you have done it manually in multiple steps? did the LLM had prior knowledge of AWS services? or you have explained all the services?
Abhishek Mishra|2023-07-30 20:07:00|LLM knows how to code a certain number of diagram libraries like mermaid js, diagram js etc. These libraries contain the basic AWS icons and infra as well.
Abhishek Mishra|2023-07-30 20:07:37|So you can do this in one shot and then correct the architecture it creates based on your description as well.
Lalit Pagaria|2023-07-30 20:08:39|It had prior knowledge.
~ Happy Chaudhury|2023-07-30 21:47:55|Any specific plugins?
Lalit Pagaria|2023-07-30 21:48:20|Code interpreter
~ D|2023-07-30 23:17:46|‎~ D requested to join
~ Vik|2023-07-30 23:34:39|interesting paper they got a 30% jump in chat engagement though RLHF on a base model. whats also interesting is that they use a relatively small model GPTJ-6B for their chat bots wonder if they could even go smaller for better cost/perf. they use GPT2 for their reward model wonder if they used something bigger here. https://arxiv.org/pdf/2303.06135.pdf
~ Divyansh Golyan|2023-07-31 06:39:26|‎~ Divyansh Golyan requested to join
ashish Acgt01 Twitter|2023-07-31 06:44:36|https://stability.ai/blog/stable-beluga-large-instruction-fine-tuned-models
~ Sravan Avvaru|2023-07-31 09:21:06|‎~ Sravan Avvaru requested to join
~ Aditi Chauhan|2023-07-31 09:52:25|‎~ Aditi Chauhan left
~ Ankit|2023-07-31 10:01:01|‎~ Ankit requested to join
Sidhant Dhar|2023-07-31 11:22:40|‎Sidhant Dhar requested to join
~ dhruv|2023-07-31 11:34:40|‎Ravi Theja added ~ dhruv
~ Vinay Varma|2023-07-31 16:14:14|‎~ Vinay Varma was added
~ Maheswaran|2023-07-31 16:14:14|‎~ Maheswaran was added
~ ASK Sathvik|2023-07-31 16:14:14|‎~ ASK Sathvik was added
~ Aditya Anand|2023-07-31 16:14:14|‎~ Aditya Anand was added
Amit Bhor|2023-07-31 13:03:46|Does anyone here have experience fine-tuning only few layers of a decoder only model? Please share any learnings (what is it good at not good at, knowledge vs style learning). It would also be very helpful to share any research in this direction. TIA.
Prakash Sankar Harbor|2023-07-31 13:09:34|got a few questions - just trying to build up an intuition from ground up.   1. Why are models restricted to certain context windows? The way I see it the context window is basically the length of the input vector (so if I imagine a LLM is represented as a m by n matrix, the context window is a x b, where b is all the integers up to m?). So in this case, a context window means that anything out side of the window will get us garbage values -> does that mean that anything outside of the LLM sub-matrix that is used to answer questions for a LLM of a certain context window size is populated with garbage values?  2. Is the latency of a request fundamentally constrained by the speed of matrix multiplication? I can see how throughput can be increased, but not sure about speed.  3. Related to 2 - how should one think about maintaining response times when scaling a LLM? A LLM seems a lot like a blockchain - compute + state are very tightly coupled. You can't really throw infra at this because every GPU needs to have all the model weights, so it is constrained by memory rather than compute power.
Prakash Sankar Harbor|2023-07-31 13:10:20|rephrasing 1 - does the context window define which part of the matrix is filled with non-garbage values and which part is not filled with garbage values (either random values, or 1/0)?
Prakash Sankar Harbor|2023-07-31 13:11:38|sorry final question - what is actually happening to model weights when fine tuning? If we are updating the weights when fine tuning, then how does one offer an API for fine tuning? I understand this might be better answered with some reading, so if anyone can point me in the right direction - happy to do the work.
~ raj()|2023-07-31 13:12:00|https://github.com/khoj-ai/khoj  Khoj AI now supports using Llama 2 (7b) for offline chat from obsidian/ emacs/ web browser
Sudharshan GenAI|2023-07-31 13:12:35|Nice pretty cool
Dev Aggarwal|2023-07-31 14:00:28|Trying to extract tables from documents - Any suggestions / experiences with camelot or google/azure/aws document extraction APIs?
~ Mohit|2023-07-31 14:06:04|We have had a good experience with AWS if you want to extract tables as is
Sachin Legaltech|2023-07-31 14:06:18|https://github.com/microsoft/table-transformer
Nirant|2023-07-31 14:06:58|Have tried Camelot, it's nice but doesn't cover all edge cases. Textract is better, heard it's good price to perf ratio. GCS was the best when I did a full benchmark did in 2019-20
~ gaurav|2023-07-31 14:07:45|Aws textract.
Ambarish Ganguly|2023-07-31 14:07:55|Try with Azure Form Recognizer for Azure
Nirant|2023-07-31 14:09:47|Pushing LIMA to it's limit: Roleplay LoRA using 2K samples per LoRA, 4 characters: https://huggingface.co/lemonilia/limarp-llama2
~ Kshitij|2023-07-31 14:12:13|Need to extract fro images or pdfs?
Ambarish Ganguly|2023-07-31 14:13:46|It would be interesting to know how you handle tabular data and the power of LLM
Narendranath Gogineni|2023-07-31 14:16:22|Adobes pdf service has the best ocr
Narendranath Gogineni|2023-07-31 14:16:39|Had problems with aws textextract
Dev Aggarwal|2023-07-31 14:18:12|Pdfs that have images 🙈
~ Rachitt|2023-07-31 14:21:48|Try PDFPlumber, is pretty helpful for tables in PDFs
Dev Aggarwal|2023-07-31 14:21:52|Markdown works with got mdoels
Dev Aggarwal|2023-07-31 14:22:04|Gpt* - this is what chatgpt frontend does too
Chaitanya A GenAI|2023-07-31 14:22:12|[PHONE]
Aashay Sachdeva MPL Data Scientist|2023-07-31 14:24:44|Google document API does decently well on tables
Nilesh Transcend|2023-07-31 14:26:18|Good suggestion, thanks. 👍
~ Tarun|2023-07-31 14:28:27|hey DM, have worked extensively with these.
~ Tarun|2023-07-31 14:29:09|Camelot is great for bordered tables. For those without border lines, the algorithm is very primitive
Dev Aggarwal|2023-07-31 14:32:21|Very useful insight!
~ Vinay Varma|2023-07-31 14:41:56|‎~ Vinay Varma requested to join
~ Ashwin|2023-07-31 14:59:59|Try Tessaract and PaddleOCR as well. Have had very good performance using both. Plus it’s easy enough to host your own on a small EC2 machine.
Sandeep Srinivasa RedCarpetup|2023-07-31 15:11:12|this is very interesting. have u also seen llama index with recursive retrieval for this ? https://twitter.com/llama_index/status/1676742253669408768
Nirant|2023-07-31 15:43:43|I recommend Tesseract to everyone I don't like ‎[7/31/23, 15:45:50] Shashwat TDC: ‎GIF omitted
~ Ashwin|2023-07-31 16:10:34|Is it because it’s difficult to use?  It isn’t scalable? Or does it have accuracy issues?
Nirant|2023-07-31 16:13:43|It puts you in the zone where you think you can just train/finetune with a bit more data, and then get you stuck few months later — when you've committed too hard to the tesseract ecosystem and all it's 10+ years of legacy.  It gives you false hope. No more drug more dangerous than hopium.
Nirant|2023-07-31 16:15:47|tl;dr: You take on more tech debt that you think you are by adding an OCR library, and it stings later
~ Ashwin|2023-07-31 16:23:24|So it’s a design issue then, and not with tessaract.   You need to design your ML/AI systems so that your OCR/whatever modules can be swapped out and replaced with something else. To do this, you need to have extensible function contracts that can support such a system.  Take this scenario where you need to deploy an OCR system which gets you there 90% of the way. So you start off by designing not for Tessaract or Camelot but a contract for OCR extraction. This way your systems are interchangeable. You have Tessaract or whatever today but then you need to be able to switch when a newer better version comes along. A typical Enterprise level requirement is not to go and be able to do 100% of the job on day one. Improvement and the goal is achieved in incremental steps.  I speak from experience of having done this where we have seamlessly switched processing certain files from Tessaract to other systems. And well, even swapped out entire ML processing pipelines as long as you adhere to the function contracts.
Abhishek Mishra|2023-07-31 16:37:03|The fun one - mentions environmental impact in the model card as well 👍😂
~ Krishna|2023-07-31 16:51:16|"I know this has been asked here before but what's the best way to get GPT3.5 to output in a specific JSON format? Is the answer still ""gpt function calling"" if I'm not using it for APIs?"
Adithya S K PESIT|2023-07-31 16:53:37|Gaurdrails
Adithya S K PESIT|2023-07-31 16:54:30|https://getguardrails.ai/
~ Arindam Barman|2023-07-31 16:54:38|I just ask GPT 3.5 to only return json and it is pretty consistent nowadays
Nirant|2023-07-31 16:56:59|Tesseract in particular resists good design e.g. you often need a C++ runtime along with Python bindings. And you had to work with PIL/Pillow dependency mess as well till recently across Python versions if you ran on multiple OS.
Nirant|2023-07-31 16:57:23|Re: What is good design —  we've all done that pipeline swapping out like a Ship of Thesus.   If it was a well built ship — we'd not have to swap out stuff so often
Nirant|2023-07-31 16:57:44|But like most things, this is a matter of opinion. If Tesseract works for you, that's great! Wish you the very best
Nirant|2023-07-31 16:58:49|Yes. OpenAI Function Call is perhaps the best. You can use something like Marvin or AgentAI to get Pythonic types with it.  Guardrails.ai is perhaps too bulky given their requirement for a RAIL spec — but if this is something where you want to add few shot examples, that might be better?
Kaushik Bokka|2023-07-31 16:59:14|Why not just write your own Custom output parser? Rather than making it complex by using one more framework
~ Arindam Barman|2023-07-31 16:59:25|I always create a separate microservice for things like Tesseract and once it is up I never touch it again
~ Krishna|2023-07-31 17:01:10|Interesting. No one shot/few shot?
~ Ashwin|2023-07-31 17:01:29|I am sorry but Data Science is not a matter of opinion. :)   It’s a matter what will work best for your use case and when adhering to customer requirements.  Good design is extensible. It’s not a question of a well built ship but how easily you can upgrade ships in the future when better technology is available.
~ Shanthi Vardhan|2023-07-31 17:02:11|If your documents are pdfs try pdf2tree and if you still need better extraction then try Adobe pdf extraction, it really works well.
~ Arindam Barman|2023-07-31 17:02:45|"yeah don't need multi shot. I use multi shot when I want to control the reasoning logic. Apart from that I just add in the prompt ""Only return json so that it is easy for me to JSON.parse this"""
Dev Aggarwal|2023-07-31 17:05:36|Or give it schema as an example too
Sumod K Mohan|2023-07-31 17:11:49|Haha.. This is quite true. Have had many customers come to me saying they already have 90% system. Just minor changes only needed to get 99% and I would then spend few meetings telling them why it is harder to push those few percentage points and whether they really need to solve it. Tesseract like other application oriented CV libraries gives that hope.
Sumod K Mohan|2023-07-31 17:13:12|Few exceptions  1. You process a lot of documents that are fairly simple (little content, simple layout, modern fonts, good printing, near perfect alignment etc). You don't want to spend on Texract/Document API, you can give tesseract a shot. Try to get tesseract to print all its text data at all levels, just to know if it is recognising text. If this doesn't work, it will be hard to make it work, unless you have lot of labelled data etc..  2. You need to solve for case which Texract/Document AI doesn't work for whatever reason and they don't provide data at granularity you need (like layout level of text, locations etc). Eg: Like tables, multi column structures etc.. Then Tesseract is useful because it provides abstractions already and you can build on top of that.
Sandeep Srinivasa RedCarpetup|2023-07-31 17:13:27|Textract is good for table extraction? Never used it but good to know  What is GCS ?
Nirant|2023-07-31 17:14:26|*GCP
Sandeep Srinivasa RedCarpetup|2023-07-31 17:15:30|What is more intersting is how LLM can deal and compensate for the ocr.   Any chance u have pushed any of these ocr output through LLM and see where they compensate, etc ?
Dev Aggarwal|2023-07-31 17:16:50|https://cloud.google.com/document-ai  This right?
Sumod K Mohan|2023-07-31 17:18:13|For all you know, AWS quite likely use tesseract with certain parts swapped out. Just a prediction based on what I know what AWS did for other products.   But for most application, just stick with commercially available APIs that is most applicable to you, like invoice processing APIs for invoices or generic high quality ones like Texract/Document API.
Nirant|2023-07-31 17:19:30|Can't recall anymore, besides GCP renames their services like with every VP Change, so basically every Christmas and Eastrer
Nirant|2023-07-31 17:19:51|*Easter
Nirant|2023-07-31 17:21:18|Neubig lab might look into this? OCR Post-correction is something they've explored in the past: https://arxiv.org/abs/2011.05402
Sumod K Mohan|2023-07-31 17:27:31|We had done for smaller LMs but not for LLMs per se. One particular place where this would apply really well, is in field extraction in semi-structured documents. Think of invoices for example, you will have many docs describe the same field say 'Name', as Name or First Name, Last Name and many such variants. All these can be solidly solved now.
~ Happy Chaudhury|2023-07-31 17:36:11|We are using it currently but you will have difficulty when a specific column names are in two line
Rajesh RS Generative AI WhatsApp Group|2023-07-31 17:42:36|Releasing this on a not truly OSS license makes it bad as [PHONE]  said  elsewhere. That said this is an issue with a lot of OSS projects. I think we have seen AWS do something similar with Kafka and Kinesis, not sure. The temptation for companies of that which is free is to take and monetize. Few resist the corruption eventually
Nirant|2023-07-31 17:49:33|Huggingface CEO replied with how they're thinking about this btw: https://twitter.com/ClementDelangue/status/1685971535729709057  Broadly, they're coming around to the fact that LLM is the product to sell — not compute like what AWS does. That also means, there is room for someone to build a finetuning SDK better than HF and commercialise that via cloud partnerships.
Nirant|2023-07-31 17:50:11|^Very half-baked ideas on my end, please don't ask me to defend them 🙈
Dr. Pratik Desai KissanGPT|2023-07-31 17:52:09|You toned down quicky after he replied 😂, but you were not wrong. Emad has done it before releasing under NC license, but I was not expecting from Huggigface, speaking in Congress about Open Source and then changing license of existing Apache 2.0 repo.
Ajat Prabha|2023-07-31 17:53:12|‎Ajat Prabha left
Pratyush Choudhury|2023-07-31 17:54:36|How is LLM the product to sell?
Nirant|2023-07-31 17:56:45|I only fight in the same weight class sir, that is why I didn't even tag HF. I didn't know that the Clem, the CEO follows me on the bird app 🙈
Amit Bhor|2023-07-31 17:59:30|Bumping this up again. Anyone?
Sidhant Dhar|2023-07-31 18:00:50|‎Sidhant Dhar joined using this group's invite link
Abhishek Mishra|2023-07-31 18:01:06|"These releases are mostly marketing at this point. True OSS considers transparency as a primary tenet which is missing when you hide away a lot of things even if you release the weights. Then it's the non-commercial part of the license that's also part of almost every ""OSS"" release. If you just want individuals to use and talk about your stuff, it's marketing."
Dr. Pratik Desai KissanGPT|2023-07-31 18:02:23|😂 just pulling the legs of our dictator. You did the right thing. He must be under immense pressure to generate revenue.
Dr. Pratik Desai KissanGPT|2023-07-31 18:06:07|Everyone is trying to figure it out. These are entirely unknown waters for everyone. The best strategy IMO is not to take a side of any movement (OSS, Frontier Foundation, e/acc, doomers), and only your customers and your own survival.
~ RISHAV|2023-07-31 18:07:32|Hello Folks, I was benchmarking a few model inference times, I didn't implement all of it so asking for some insights for those who have implemented it. What would be the inference time for -: 1. LLama2 70B 2. Falcon 40B
Nirant|2023-07-31 18:08:20|"No, the best way is to ride the wave and take the side of whosoever is winning — a16z went from crypto to ""It's time to build"" to AI than I can even get T shirts printed for these things"
Sugnan GenerativeAI Group |2023-07-31 18:08:31|*Job Openings*  🟢 Kili - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools - 🔍 *Job Description*: Our vision is to 10x the productivity of employees by providing an AI assistant. Our focus is customer service, sales and ops (in that order). We're looking for founding engineers to join us. -📝 *Apply Here*: https://kiliso.notion.site/The-AI-assistant-of-the-future-fcf211f04aca42209148ddd55a1d391e - 💬 *Contact*: [EMAIL]  --- 🔵 GalaxEye Space - 🎯 *Hiring for*: Not Related to Generative AI directly, but broad ML role - 🔍 *Job Description*: As a member of the product team, you will research, design, implement, optimise and deploy deep learning models to continuously evolve our AI ecosystem. - 📝 *Apply Here*: Email at [EMAIL] - 💬 *Contact*: https://www.linkedin.com/in/azhanmohammed/  --- 🟣 Hexo AI - 🎯 *Hiring for*: Generative AI includes all text, vision, typically - 🔍 *Job Description*: Senior machine learning engineer to join our founding team in building at the bleeding edge of Generative AI. - 📝 *Apply Here*: https://hexoai.notion.site/Senior-Machine-Learning-Engineer-749e49d580154f3aabc9e932a1277090?pvs=4 - 💬 *Contact*: Vignesh Baskaran, [EMAIL]  --- 🔴 Soroco - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools, Not Related to Generative AI directly, but broad ML role - 🔍 *Job Description*: Soroco is building its ML team and looking for high quality engineers who can build, train and fine tune models using hundreds of millions of data points. Come build and learn from our transformer based models and help us advance the - 📝 *Apply*: https://soroco.com/careers/#/5179693 - 💬 *Contact*: Mounik Patel - 8010140081, https://in.linkedin.com/in/mounik-patel George Nychis - https://www.linkedin.com/in/george-nychis-10652020 ---   🟠 F5 - 🎯 *Hiring for*: Generative AI includes all text, vision, typically, ML/LLMOps/FMOps — making internal tools, Not Related to Generative AI directly, but broad ML role. - 🔍 *Job Description*: Sr. Architect at F5's internal innovation group to architect gen ai agents for areas that F5 is interested in starting with Cyber Security. - 📝 *Apply Here*: https://www.linkedin.com/jobs/view/3674948193 - 💬 *Contact*: LinkedIn: https://www.linkedin.com/in/ruthvik-reddy-sl-178989130/  or WhatsApp: 7997826272  --- -	Posted by Sugnan on behalf of Generative AI Community.
Dr. Pratik Desai KissanGPT|2023-07-31 18:11:36|"You forgot ""American Dynamism"" in between. I have been blocked by many a16z folks for pointing that out. 😂"
Bharat Kumar Ramesh Hashmal Web3|2023-07-31 18:19:11|Hahaha. They got suckered with terrible PR. Their hedge fund peers do the same thing in public markets and simply call it momentum investing
Anubhav mishra Zupay|2023-07-31 19:02:43|https://www.linkedin.com/posts/giorgiotorre1234_artificialintelligence-ai-technology-activity-7090345096889401344-uHXO?utm_source=share&utm_medium=member_android
Anubhav mishra Zupay|2023-07-31 19:02:47|😂
~ Onkar Mishra|2023-07-31 19:11:52|You can use this - https://github.com/NirantK/agentai
Rajaswa Patil|2023-07-31 19:56:43|‎Rajaswa Patil requested to join
~ Arko Cy|2023-07-31 20:23:45|doesn't it add up to too many microservices after a point - it will late call for firefighting late on
~ Arko Cy|2023-07-31 20:26:07|*later
~ Srijan Saxena 😎|2023-07-31 20:47:05|Man always love to see these 😆
Arvind N Generative AI Group|2023-07-31 20:56:04|is r=8 more or less a standard now, with lora/qlora peft?
Shahul Kaggle Kernel GM|2023-07-31 21:02:28|This could also be a reason why you see degradations in lora compared to full FT. This has to be tuned but it's kind of tricky to get it right. I have tried 8,16,32,etc with different models. Also one can reduce the compute required.
Prakash Sankar Harbor|2023-07-31 21:17:53|anyone have any idea?
Nirant|2023-07-31 21:20:29|PSA: Please don't bump up your questions by asking for any idea — that's noisy. Please rephrase and ask again in a way that might be interesting to someone!
Puneet Lamba Aspiro|2023-07-31 21:22:02|In other words: use ChatGPT to bump up your questions 😂
Abhinav Verma Longshot.ai|2023-07-31 21:22:37|I mean, why haven't people been using chatgpt for this
Puneet Lamba Aspiro|2023-07-31 21:26:40|The OG genAI group, where even the community best practices contribute to genAI usage flywheel.
Prakash Sankar Harbor|2023-07-31 21:28:18|"I'm confused - how would you ask my question again? Because I'm genuinely not sure how I can get more simple than ""Why are models restricted to certain context windows?"""
Prakash Sankar Harbor|2023-07-31 21:29:14|is it not worth adding the context?
Amit Bhor|2023-07-31 21:37:11|Short answer is attention mechanism scales quadratically to context length.
Prakash Sankar Harbor|2023-07-31 21:38:07|is it worth reading the attention is all you need paper to get the longer answer?
Arvind N Generative AI Group|2023-07-31 21:38:33|The context window is dictated by the transformer architecture. The input layer size determines the number of tokens. Even though Attention is quite efficient as a feature detector, it's still O(N^2) - quadratic as Amit mentioned above. Hence context windows are smaller.
Dr. Pratik Desai KissanGPT|2023-07-31 21:38:43|That’s prerequisite
Amit Bhor|2023-07-31 21:39:29|Yes, but there are more easier reads all over the internet
Prakash Sankar Harbor|2023-07-31 21:39:57|gotcha - thanks
Dr. Pratik Desai KissanGPT|2023-07-31 21:40:28|Second good place will be going through Karpathy NanoGPT course for some basic handson experience of transformer architecture
Prakash Sankar Harbor|2023-07-31 21:40:53|any recs? I think my mental model for this stuff is really wrong
Arvind N Generative AI Group|2023-07-31 21:41:08|Another place to start learning more is this blogpost which covers more recent ideas and shows how context can be extrapolated (Alibi) : https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c
Nirant|2023-07-31 21:42:34|I believe you've some math training, so notation shouldn't throw you off?  This is a great primer: https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/  And will serve you well for years, even as new improvements come along
~ Suhas Baliga|2023-07-31 21:42:38|Hi folks, has anyone used GPT-4 to edit documents? Any stats on accuracy % for diff type of texts?
Nirant|2023-07-31 21:43:06|Not easier, but definitely deeper
Prakash Sankar Harbor|2023-07-31 21:43:26|ty
Prakash Sankar Harbor|2023-07-31 21:43:59|nah I actually really like lin A - so that's all good
~ Tarun|2023-07-31 21:44:00|statquest released a video too recently.
Nirant|2023-07-31 21:44:42|FWIW, Context windows are now somewhat arbit and a marketing shtick — you'll soon see models with 100K, 1M context windows, they are not to be trusted. Attention by design, evaporates and varies across the context. This is empirically proven too. 
Prakash Sankar Harbor|2023-07-31 21:45:17|regarding the other question - if compute and state (weights) are so tightly coupled, how does one think about   a. Fine tuning (doesn't make sense to just copy over the weights and modify them for everybody) b. Increasing speed of response
Prakash Sankar Harbor|2023-07-31 21:45:25|at scale?
Nirant|2023-07-31 21:47:26|I believe Shahul [PHONE], Amit [PHONE]and Pratik [PHONE] have spent some thought cycles on improving QPS and serving multiple clients at the same time.
Nirant|2023-07-31 21:49:12|I am long term bearish on model finetuning, believe that OSS models will get good enough that prompting will rule the day — very few folks even finetune BERT or DeBERTa.  ‎[7/31/23, 21:49:24] Arvind N Generative AI Group: ‎image omitted [7/31/23, 21:49:34] Nirant:  Re: increasing speed: We're already seeing models at 10-20 tokens/second on 4090, matter of time before we can quantize LLMs against specific workloads e.g. domain and task — which should unblock same perf on modern CPUs.  With vLLM, QPS looks more and more like an engineering/infra problem
Dr. Pratik Desai KissanGPT|2023-07-31 21:52:08|RAG will win on a longer run on context window size, IMO.
Pratyush Choudhury|2023-07-31 21:54:24|Interesting that you say this - are you saying this because you believe the models in the future will keep becoming more sophisticated & general?   Fine-tuning is usually done because it performs better on specific tasks  But also smaller models might benefit from fine-tuning, no?
Nirant|2023-07-31 21:54:37|I've run some 4k vs 32k context window small experiments, models start giving pretty soon. Longer context windows confuse the LLMs more.
Pratyush Choudhury|2023-07-31 21:55:19|Completely with you - also, as Nirant said, attention evaporates and varies across the context and hence, a core component of the new Gen AI tech stack would likely include a VectorDB
Abhinav Verma Longshot.ai|2023-07-31 21:57:37|This has been observed in many cases and documented in a paper ( don't remember which) but basically in really long context, models get confused. In fact in many cases, we repeat important instructions at the end to ensure they are executed.
Nirant|2023-07-31 21:58:09|"Smaller models do benefit from finetuning, but the long arc of tech favours familiarity — ""worse is better"""
Prakash Sankar Harbor|2023-07-31 21:58:12|ah the inside out prompt technique
Sachin Legaltech|2023-07-31 21:59:25|That’s because most(almost all of them) part of our datasets (internet articles which form the datasets) are smaller than 500 tokens ..If we can unlock huge amount of continuous text( maybe YouTube podcasts or more books), then we might be able to teach models to attend over longer context sizes.
Abhishek Mishra|2023-07-31 22:00:06|Yeah. Longer context accuracy comes with longer context pretraining/fine-tuning.
Amit Bhor|2023-07-31 22:00:21|Most don't scale up embedding dimensions which are needed for longer attentions. But yes, this is generally true.
Nirant|2023-07-31 22:00:37|Be careful of what you wish for, someone might read Youtube from this and make a LLM on Youtube Shorts
Dr. Pratik Desai KissanGPT|2023-07-31 22:01:00|I’m not sure this is a factor.
Abhishek Mishra|2023-07-31 22:01:03|Recent methodologies have unlocked options for scaling self-attention linearly with context size.
Sachin Legaltech|2023-07-31 22:03:00|this paper - https://arxiv.org/abs/2307.03172 ?
Sachin Legaltech|2023-07-31 22:06:50|I think this is one of the factors..another one would be parameter sharing - we are multiplying same set of weights to every token embedding… we might not be able to model relationship between million tokens in whatever our weight matrices are.
Abhishek Mishra|2023-07-31 22:07:05|These performance results have gotten better with longer context pretraining data and implementing RoPE interpolation scaling. An example of such success is Llongma 16k - https://www.reddit.com/r/LocalLLaMA/comments/15c0pbs/llongma2_16k_a_llama_2_16k_model/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=2 ‎[7/31/23, 22:08:12] Abhishek Mishra: ‎image omitted
Abhishek Mishra|2023-07-31 22:09:15|Papers like this are good studies but have been done before implementation of all the recent improvements with  * Longer context pretraining * Flash attention 2 * RoPE interpolation ‎<This message was edited>
Dr. Pratik Desai KissanGPT|2023-07-31 22:18:32|I was referring to the point that pretraining chunking strategies for larger documents at least for SoTA models should have taken care of it to not be the significant factor. However, Weights are probably a major factor for larger context window. If someone finds a paper, please share.
Sachin Legaltech|2023-07-31 22:18:38|Is there a graph which compares 16k vs original 4k ?  I am curious if there is some penalty in initial token perplexity ?
Abhishek Mishra|2023-07-31 22:22:29|There's a slight penalty when you go above 4k as expected but the drop stays the same and doesn't continue to degrade. With the same Llongma 2 16k, the effort to increase context size has similar performance under 4k as Llama 2.
Dhruv Anand|2023-08-01 01:01:36|How much does prompt size matter for latency, for the gpt (3.5) API, given that the task complexity remains the same?  Is it linear w.r.t tokens for some range? ‎<This message was edited>
Dev Aggarwal|2023-08-01 01:09:31|I believe its contstantj
~ Ritik Madan|2023-08-01 01:09:37|This post should be useful.   https://www.linkedin.com/posts/yijing-barry-zhang_does-input-prompt-length-affect-openai-api-activity-7091836224901894144-k5Jk?utm_source=share&utm_medium=member_desktop
Dhruv Anand|2023-08-01 01:10:42|Wow very timely 😀
~ Ritik Madan|2023-08-01 01:10:47|This analysis essentially says that total latency is almost entirely affected by output and input doesn't have much affect
~ Ritik Madan|2023-08-01 01:12:54|Haha exactly 😂
Dev Aggarwal|2023-08-01 01:13:34|Input tokens are also cheaper than output tokens
Dev Aggarwal|2023-08-01 01:13:51|Which means you should totally stuff the prompt with as much info as it fits :D
~ Subhashree Tripathy|2023-08-01 01:45:37|‎~ Subhashree Tripathy requested to join
Divya Tak|2023-08-01 02:40:45|Oh in what way?
Prakash Sankar Harbor|2023-08-01 06:32:01|Sure but we’ve (albeit anecdotally) found that doing this results in worse output especially if using gpt to complete specific tasks
Chaitanya A GenAI|2023-08-01 06:51:12|the output is streamed, so it’s linearly correlated to the number of output tokens
~ Sid|2023-08-01 07:17:15|input prompt is fed into model for next word generation, one word is generated then it is again added to the prompt and fed into the model for next word generation. the longer the input for model, longer will be processing time for next word generation, so yes input prompt does have direct relation to latency.
~ Sid|2023-08-01 07:19:13|*that processing is cheap I think given the hardware we have today. so it doesn't affect that much. ‎[8/1/23, 09:06:25] ~ Vrushank Vyas: ‎image omitted ‎[8/1/23, 09:06:27] ~ Vrushank Vyas: ‎image omitted
~ Adithya|2023-08-01 09:12:31|Anyone want to take part in kaggle competitions?
Adithya L Bhat Hackathon|2023-08-01 09:36:04|I do . I am already doing one .
~ Sid|2023-08-01 10:07:21|i am planning to do.
Amit Bhor|2023-08-01 10:09:24|Input length only affects the first token latency due to KV caches. In any case, as others point out, autoregressive nature makes output tokens the bulk of the time taken. For short answers or classifiers this may become an issue.
~ Adithya|2023-08-01 10:27:10|Which one?
Adithya L Bhat Hackathon|2023-08-01 10:27:43|Google research contrail detection
Nitin Mahajan McKinsey|2023-08-01 10:33:41|They are also just 4 people company (shocked!). Quality and number of products is damn good. impressive
Paras Chopra Wingify|2023-08-01 10:45:14|https://unum-cloud.github.io/docs/usearch/index.html
Sudharshan GenAI|2023-08-01 11:07:30|Off topic : Is there a similar group to disucss physics and topics like the new ambient-temperature superconductor?
Dev Aggarwal|2023-08-01 11:18:25|tried adobe, tesseract, aws, gcp, azure. Azure has the best first impressions.
Dev Aggarwal|2023-08-01 11:18:30|adobe was the most surprising, its ocr was worse than basic tesseract
Sugnan GenerativeAI Group |2023-08-01 11:32:28|"*EVENTS ANNOUNCEMENT* 1. *Title:* Generative AI Deep Dive: Models,e Applications and Advancement *Hosts:* Falconx *When:* August 2 | 6:00PM - 9:00PM (PST) *Where:* Milpitas, CA *Register here:-* https://www.eventbrite.com/e/generative-ai-deep-dive-models-applications-and-advancements-tickets-665722934217  ------  2. *Title:* Community Paper Reading: Extending the Context Window of LLaMA Models *Hosts:* Aiify.io *When:* August 2 | 10:15 AM - 11:00 AM (PST) *Where:* Remote *Register here:-* www.eventbrite.com/e/684122678347/?discount=CV30  ------  3. *Title:* Women in AI✰ Panel & Social *Hosts:* Claire Xie, Shawna Dunham & Modernist *When:* August 2 | 6:00PM - 10:00PM (PST) *Where:* San Francisco, CA *Register here:-* https://lu.ma/k6ml5b6v  ------  4. *Title:* Tofu AMA with Puja Rios, CRO Frame.io *Hosts:* Elaine Zelby *When:* August 3 | 10:00AM - 10:45AM (PST) *Where:* Remote *Register here:-* https://lu.ma/he6p2s25  ------  5. *Title:* LLM Observability 101: Common Challenges Seen in Production *Hosts:* Arize.AI *When:* August 3 | 11:00AM - 11:30AM (PST) *Where:* Remote *Register here:-* https://lu.ma/llm-observability-4  - Sugnan, on behalf of the Generative AI Community"
~ Happy Chaudhury|2023-08-01 11:45:39|Yes agree 👍 we are using azure form recognizer
~ Shanthi Vardhan|2023-08-01 12:28:16|We are seeing a lot of timeouts with OpenAI's turbo model even though we are not hitting the rate limits. Is anyone else also facing the same issue? what should be the fallback or strategy to deal with timeouts. We are making a couple of completion calls to OpenAI per incoming message. One for Intent classification and the other for response generation. Typical token sizes per call are around 500 tokens.
Dev Aggarwal|2023-08-01 12:30:18|I believe you have to add retries for all these errors -   ( openai.error.Timeout, openai.error.APIError, openai.error.APIConnectionError, openai.error.RateLimitError, openai.error.ServiceUnavailableError, )
Nirant|2023-08-01 12:32:19|Thought this might be interesting to you https://github.com/BerriAI/reliableGPT
Dhruv Anand|2023-08-01 12:33:01|Does langchain do retries on these under the hood?
~ Sid|2023-08-01 12:33:17|yes
Dev Aggarwal|2023-08-01 12:38:06|Ugh, they modelled it such that they now have to update their lib with openai lib
Dev Aggarwal|2023-08-01 12:38:35|You can do this wihout touching the openai lib, its a try except block ‎[8/1/23, 12:39:15] ~ Shanthi Vardhan: ‎image omitted
~ Sid|2023-08-01 12:40:02|you can try these strategies without the library using exception handling. not very complex.
Anshuman Pandey|2023-08-01 12:43:09|lol Indian VC ecosystem is equally funny! Everyone was funding crypto bros 18 mos ago & the same bros are now pivoting to AI 😂
Nirant|2023-08-01 12:43:33|My intent with sharing that lib was to share a checklist of tricks/methods to try (since I am too lazy to type them all) — and a reference implementation
Nirant|2023-08-01 12:45:01|Please let that topic die here, have a dedicated Startup Group for this topic! Links here for other readers: https://nirantk.com/community
Kshitij Agrawal ML Engineer|2023-08-01 12:55:18|Yup we were pushing 100k-200k per month docs with varying quality to Azure Cognitive services. Handles like a pro
Nirant|2023-08-01 12:56:13|Damn, should I add Azure to the official OCR endorsement from the community?
Kshitij Agrawal ML Engineer|2023-08-01 12:57:20|Haha yes.. And cost is too attractive to meddle with your own OCR at 0.08rs a page
Nirant|2023-08-01 12:58:44|Sounds about right. [PHONE] should we raise an invoice to Azure for all the free devrel we're doing for you? 🙈
Kshitij Agrawal ML Engineer|2023-08-01 12:58:45|I wasn't very happy with the latency though. However our case was mostly on the batch processing side.  And azure does offer on Prem hosting if that's a concern.
Dev Aggarwal|2023-08-01 13:01:36|Latency is pretty terrible on all clouds from what I saw
Ankita Mathur Microsoft Sales|2023-08-01 13:02:27|This community is simply fantastic 👍🏻 Happy to pitch in wherever we can
Ankita Mathur Microsoft Sales|2023-08-01 13:03:25|As for the invoice - I think the tech pays for itself 😆😆😆
Dev Aggarwal|2023-08-01 13:05:01|Might be able to improve by running pages in parallel?
Kshitij Agrawal ML Engineer|2023-08-01 13:10:58|Yes but you'd need to put in a special request to increase your RPS limit with most providers.
Kshitij Agrawal ML Engineer|2023-08-01 13:13:08|[PHONE] curious to know about the usecase if you can share here or DM.
Dev Aggarwal|2023-08-01 13:29:40|Building a slack copilot for an hvac company. The documents are scanned manuals, youtube videos and textbooks like this one - https://hvacvn.com/wp-content/uploads/2015/10/hvac-equations-data-and-rules-of-thumb.pdf At a basic level they want to be able to query tables and refer to figures in the answer
Kshitij Agrawal ML Engineer|2023-08-01 13:38:09|cc [PHONE] also has a similar poblem with tables in Albus
Kshitij Agrawal ML Engineer|2023-08-01 13:42:08|Btw for tables Aws is your best bet. Form recognizer if there is less variability in the layouts
Dev Aggarwal|2023-08-01 13:42:56|With the tables I tried, azure seemed to have more accurate numbers, will conduct a more broader test too ‎[8/1/23, 13:44:47] Dev Aggarwal: ‎image omitted
~ Akshat Khare|2023-08-01 13:46:13|Done this with Google analytics powered big query tables. Solved two usecases of two people in this group. I'll add you to the repo. Interested in making it open source? I've recently added workflow automation with [PHONE] on it. Initially ideated with [PHONE] and [PHONE]
Dev Aggarwal|2023-08-01 13:47:25|I don’t mind making the document parser open source. We’re still trying to think more on open souring the broader toolbelt. Would love any connects with VC/founders with open source stories
~ Akshat Khare|2023-08-01 13:48:21|Cool. Dmed
Kshitij Agrawal ML Engineer|2023-08-01 13:50:22|Oh yes! i see that rotated headings
~ .|2023-08-01 14:29:06|Hi All! Join us for the Generative AI meet-up in Gurgaon on 4th August, Friday.   We will be having two talks by Rohit Agarwal (Portkey.ai) and Kuldeep Yadav (SHL) followed by a panel discussion and a networking session.  RSVP on the link below: https://hasgeek.com/fifthelephant/2023-07-delhi/
Pratyush Sinha|2023-08-01 14:29:59|How do you find these projects outside your org? I recently built a similar doc parser and Summrizer for a small US Pharma Company who is a client.
Tarun SaaSBoomi|2023-08-01 14:30:19|Do we have anything happening in Hyderabad? It would be great if we could do one.
~ .|2023-08-01 14:35:39|Unsure, the fifth elephant helped roll this out because we did not have any in Delhi.
Ravi Theja|2023-08-01 14:35:40|[PHONE] is also interested to have one in Hyderabad. Probably you guys can coordinate.
Tarun SaaSBoomi|2023-08-01 14:36:45|[PHONE] any plans to drop by Hyd? We will plan one when around the city
Nirant|2023-08-01 14:41:04|Might dropby for PyCon if I hear good things, so far the talk proposals are very underwhelming
Dev Aggarwal|2023-08-01 14:42:32|Yeah, bring back david beazley!
Nirant|2023-08-01 14:46:08|I was there for the live Beazley one in PyCon 2019. I don't think anything can come close to that
Dev Aggarwal|2023-08-01 14:46:45|It was like a rock concert, but somehow the music was in python ‎[8/1/23, 14:49:15] Nirant: ‎image omitted
Nirant|2023-08-01 14:49:51|cc [PHONE] knows someone from the photo as well xD
ashish Acgt01 Twitter|2023-08-01 14:52:55|Jealous of you Nirant ! :)
Abhiram Ramesh|2023-08-01 14:54:24|I was there too😊
Dev Aggarwal|2023-08-01 14:54:42|The crazy part though is how appraochable everyone was and was willing to spend time with you. They’d totally sit with you and debug if you asked 🙈
Phani Srikanth|2023-08-01 14:55:06|Yes. Happy to team-up and organise one in Hyderabad. DM me and we can take it forward! Thanks.
Tarun SaaSBoomi|2023-08-01 15:10:47|Great, Phani! Will DM you. Folks from Hyd, Pl DM if you are interested in helping organise the same
ashish Acgt01 Twitter|2023-08-01 15:35:59|"Interesting paper from Tsinghua guys  https://sites.google.com/view/sot-llm  ""In this work, motivated by the thinking and writing process of humans, we propose ""Skeleton-of-Thought"" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed up (up to 2.39× across 11 different LLMs) but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.""  p.s. as an aside,  China seems to be on an ai tear ! :) lot of impactful work being published from Chinese universities"
Nilesh Transcend|2023-08-01 15:41:12|Alternative to pgvector claims to be more performant: https://lantern.dev/
~ Nikhil|2023-08-01 16:03:14|Feel free to DM, backed Hasura, Testsigma, Bytebeam, and 100ms (this one’s going open source now)
Sandeep Srinivasa RedCarpetup|2023-08-01 16:08:06|Hi. Do you *want* this kind of usecase to be made open-source?
~ Akshat Khare|2023-08-01 16:22:21|Yes
Sandeep Srinivasa RedCarpetup|2023-08-01 16:22:59|Ah works well. We are attempting to do this in edgechains. Will dm you
Kunal Harbor|2023-08-01 16:56:30|‎Kunal Harbor left
Rajaswa Patil|2023-08-01 17:41:36|‎Rajaswa Patil was added
Meghna Bansal 2012A7|2023-08-01 17:41:36|‎Meghna Bansal 2012A7 was added
~ Saurabh Jain|2023-08-01 17:41:36|‎~ Saurabh Jain was added
‪+91 97489 61402‬|2023-08-01 17:41:36|‎‪+91 97489 61402‬ left
~ Vish|2023-08-01 17:41:36|‎~ Vish left
Gokul Krishnan|2023-08-01 17:36:32|Ahahaha 😅😅
ashish Acgt01 Twitter|2023-08-01 18:11:33|anyone tried titanml's[0] takeoff server[1] ? docs : https://docs.titanml.co/docs/titan-takeoff/getting-started  0. https://www.titanml.co/product 1.https://medium.com/@TitanML/why-we-open-sourced-the-takeoff-server-a152b3a16e12
Pratik Bhavasar|2023-08-01 18:59:31|Has anyone tried and found Palm 2 bison to be equivalent/better than 3.5?
~ Soham|2023-08-01 19:14:59|Hey Folks, Soham this side. I am a newbie in GenAI and currently exploring this space.  This may sound like a dumb question but are there any existing solutions to directly use llama 2 with an API / library. If not what’s the easiest way to deploy llama 2 and start building stuff around the same.
Ojasvi Yadav|2023-08-01 19:15:50|Do you want to work with me to put it on AWS lambda
Sidhant Dhar|2023-08-01 19:16:01|You can host llama on aws sagemaker, it is exposed as an option there
Ojasvi Yadav|2023-08-01 19:16:07|Being your former manager, I think it would be a fun project
Ojasvi Yadav|2023-08-01 19:16:26|Viable option, but costly
Sidhant Dhar|2023-08-01 19:16:44|Where would you host the model then?
Ojasvi Yadav|2023-08-01 19:16:56|Nothing wrong with sagemaker
Sidhant Dhar|2023-08-01 19:17:58|lamda is just compute right? Would it not be more expensive?
Ojasvi Yadav|2023-08-01 19:18:28|It would be much more fun on lambda though. Imagine the cost savings!
~ Soham|2023-08-01 19:18:31|Exactly! I did consider sagemaker but it would turn up costly
Ojasvi Yadav|2023-08-01 19:18:36|Rather the opposite
~ Soham|2023-08-01 19:18:51|Lets Go!
Rajaswa Patil|2023-08-01 19:19:03|+1  It's available on SageMaker jumpstart. It's also available on Azure ML - https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-llama-2-on-azure/ba-p/3881233  You can connect with AWS & Azure to get quotes and see what suits you better.
Ojasvi Yadav|2023-08-01 19:19:49|Yaar jumpstart is too restrictive
Ojasvi Yadav|2023-08-01 19:19:58|Have they offered retraining for it?
Saurav Tomar GenerativeAI WA Group|2023-08-01 19:20:06|You can use replicate https://replicate.com/blog/run-llama-2-with-an-api
Ojasvi Yadav|2023-08-01 19:20:12|I remember falcon didn't provide retraining options
Rajaswa Patil|2023-08-01 19:20:13|Fine-tuning is available on Azure ML
Sidhant Dhar|2023-08-01 19:20:15|Interesting. Well then why not just use an ec2 instance? What is the advantage of lambda over ec2?
Ojasvi Yadav|2023-08-01 19:20:32|Idk about azure ML but pretty hands on with AWS
Saurav Tomar GenerativeAI WA Group|2023-08-01 19:20:37|Llama 2 fine tuning guide https://replicate.com/blog/fine-tune-llama-2
Rajaswa Patil|2023-08-01 19:20:43|You can also simply deploy it using Hugging Face weights, with the SageMaker SDK.
Ojasvi Yadav|2023-08-01 19:21:08|What's the smallest instance you can run it on? I think lama 2s smallest quantized model needs about 9GB of ram
Ojasvi Yadav|2023-08-01 19:21:32|Even if you go with M5 instances or other memory focussed instances it's going to be pretty costly
Ojasvi Yadav|2023-08-01 19:22:09|Whilst on lambda the costing is per seconds of invocation  So if your inference takes even 10 seconds, you'll be charged like 0.01 dollars
Ojasvi Yadav|2023-08-01 19:22:34|Also it's scalable, 1000 requests per second guaranteed
Ojasvi Yadav|2023-08-01 19:22:44|Can up that limit if you request AWS
Ojasvi Yadav|2023-08-01 19:22:59|While good luck setting up a load balancer and autoscaling on EC2
Ojasvi Yadav|2023-08-01 19:23:35|At least with sagemaker you'll get inbuilt load balancer and autoscaler, that's nicer. Still need to pay for the underlying instances though.
~ Soham|2023-08-01 19:24:46|I may be wrong, but ec2 dosent have GPU support in smaller instances. And if we go for the higher instances, the cost will shoot up massively
Ojasvi Yadav|2023-08-01 19:25:05|Inference doesn't necessarily need a GPU
Sidhant Dhar|2023-08-01 19:26:15|Got it! Thanks that makes sense
~ gaurav|2023-08-01 19:26:36|Imo dont use sagemaker jumpstart. Major problem would be sagemaker endpoint. Costing would play major factore bcoz of it. And generally sagemaker endpoint is very closed sourced.
Ojasvi Yadav|2023-08-01 19:27:11|Its purpose is in the name, jumpstart 🤣
~ gaurav|2023-08-01 19:27:36|Yes bedrock is coming in couple of months that would be ideal.
~ Soham|2023-08-01 19:30:03|While I was tinkering, I came around a alternative https://ollama.ai/ to run llama 2 on my local with the least effort . It works on my machine, but doesn’t look like my machine will be able to live longer if i keep running it on my local
~ Gaurav|2023-08-01 19:30:59|Yeah we ran it on 11GB GPUs on our qblocks cloud. The 4bit quantized version needs 7GB max. ‎<This message was edited>
~ Gaurav|2023-08-01 19:32:13|You can play around for free on this llama 2 chat that we released yesterday: https://llamachat.monsterapi.ai/
Ojasvi Yadav|2023-08-01 19:32:21|How coherent and intelligent are the responses?
Ojasvi Yadav|2023-08-01 19:32:35|Curious
~ Gaurav|2023-08-01 19:34:31|Compared to 16 bit, definitely the quality decreased a little for use cases like code generation. It's a trade off in cost vs quality. I don't have an apples to apples comparison to share as of now. Overall I'd say that the 4 bit can still work decently for some use cases like copywriting and summarisation.
Ojasvi Yadav|2023-08-01 19:43:59|From a broader POV, do you see people using these quantised models anywhere?
Ojasvi Yadav|2023-08-01 19:45:15|Like in a production grade setting
Sandeep Srinivasa RedCarpetup|2023-08-01 19:45:33|android
Sandeep Srinivasa RedCarpetup|2023-08-01 19:45:39|thats my personal bet anyways. time will tell
~ Adithya|2023-08-01 19:52:55|What about dockerising it then ec2?
~ Adithya|2023-08-01 19:54:24|Had used quantised with int precision on some arm low memory device about 2 years back I don't know anything about deployment but had done trained and reduced the model with pytorch
Ojasvi Yadav|2023-08-01 19:55:03|What about it, I'm sorry?
Ojasvi Yadav|2023-08-01 19:55:52|Yes it's pretty cool to run local projects. But I'm curious to know any business-use case of quantised models because I frankly can't think of any.
~ Adithya|2023-08-01 19:58:16|What do you think about it vs aws lambda?
~ Adithya|2023-08-01 19:59:13|Was for a 'smart' device company Were trying to shave off model size as much
~ Ayush Yadav|2023-08-01 19:59:27|[PHONE] would it be a serverless solution.  Iike pay only when in use ??  Being student running ec2 24/7 is a nightmare for my projects
Ojasvi Yadav|2023-08-01 20:01:06|Will dockerizing help in saving costs?
Ojasvi Yadav|2023-08-01 20:01:48|I don't follow, apologies
Rahul Bhatnagar|2023-08-01 20:02:25|Hey Lambda has emphereal storage. So for every cold start request, you'll need to download weights from S3 and load weights in memory.
Rahul Bhatnagar|2023-08-01 20:03:18|Should be okay for the 44M param micro Llama models that Karpathy shared that are a couple of MB. But even Llama7B weights are 26 GB
Rahul Bhatnagar|2023-08-01 20:03:55|*ephemeral
Ojasvi Yadav|2023-08-01 20:04:29|Store it in /TMP directory
Rahul Bhatnagar|2023-08-01 20:04:33|All cost savings on inference (which won't be a lot, because the inference will happen on CPUs so will very few tok/s), would be lost in the time it takes to download 26gb and load it in memory. + You'll have to pay S3 egress costs.
Aashay Sachdeva MPL Data Scientist|2023-08-01 20:04:36|The loading part to gpu mem will be painstaking
Ojasvi Yadav|2023-08-01 20:04:39|You can bump the ephemeral storage to 10 gb's
Ojasvi Yadav|2023-08-01 20:04:54|And not have to download model weights from s3
Aashay Sachdeva MPL Data Scientist|2023-08-01 20:05:08|It still needs to be loaded to gpu mem. Doesn’t solve the full problem
Ojasvi Yadav|2023-08-01 20:05:34|Ah makes sense
Rahul Bhatnagar|2023-08-01 20:06:35|Trying the micro llamas that Karpathy shared on AWS lambda should be doable though + cheap af.
Pratik Bhavasar|2023-08-01 20:06:42|It will be quite slow on Lambda [PHONE]
Pratik Bhavasar|2023-08-01 20:07:08|Try fargate with downscale setting to 0 if it has gpu instances
Ojasvi Yadav|2023-08-01 20:07:24|I was responding to adithya but I think this is also a valid response to you  If you're dockerizing for EC2, you can dockerize your container for lambda as well
Ojasvi Yadav|2023-08-01 20:07:36|That lets you use a huge deployment package
Rahul Bhatnagar|2023-08-01 20:07:43|10 GB is max I think. Won’t store llama 7 B weights. Unless I miscalculated how big they are.
Ojasvi Yadav|2023-08-01 20:07:50|And you can get past the ephemeral storage limits
Rahul Bhatnagar|2023-08-01 20:08:00|Yeah you can do that
Rahul Bhatnagar|2023-08-01 20:08:54|But max size of docker image is 10 Fb
Rahul Bhatnagar|2023-08-01 20:08:58|Gb*
Ojasvi Yadav|2023-08-01 20:09:11|Shouldn't be a problem for the quantized model
Ojasvi Yadav|2023-08-01 20:09:44|I thought it needs 9GB. But Gaurav corrected me, it's 7.
Pratik Bhavasar|2023-08-01 20:10:09|Can you run quantised model on CPU?
Rahul Bhatnagar|2023-08-01 20:11:10|Might be able to squeeze it. Then.
Rahul Bhatnagar|2023-08-01 20:11:56|That’s the size of the 7b quantized weights?
Ojasvi Yadav|2023-08-01 20:12:04|AWS kept its CPU powers rather less known  But if you go past certain memory thresholds, AWS gives you one extra core. So running a lambda function with 128 MBs of configured ram uses less CPU cores than a function configured with 1024 MB of ram.  The CPU upgradation happens as you scale up Ram for sure, but I don't know what's the rate in which RAM bands.
Ojasvi Yadav|2023-08-01 20:12:17|But still, could be very slow even at max ram
Ojasvi Yadav|2023-08-01 20:13:18|Subject to experimentation
Ojasvi Yadav|2023-08-01 20:16:57|Yes Pay only for the seconds for which the request runs.....dirt cheap if you don't have compute requirements
ashish Acgt01 Twitter|2023-08-01 20:30:26|"1. an in-depth look at if  ""AI might be bottlenecked by the supply of GPUs.""  https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/  https://news.ycombinator.com/item?id=36951872  2. TIL about coral from google research https://coral.ai/about-coral/"
Ojasvi Yadav|2023-08-01 20:32:44|I'm unsure about running quantized models without GPU  Most libraries that let you run quantized models do need GPU, so it's up in the air honestly
Amit Bhor|2023-08-01 20:35:23|Isn't the point of quantisation to reduce memory usage for GPU ? Mat muls are anyways done full / mixed precision.
Amit Bhor|2023-08-01 20:39:57|https://twitter.com/karpathy/status/1683698478080466944?t=HdKrxISheTlNCdeKNhVNlw&s=08 [8/1/23, 20:51:23] Nirant: Repost because this is quite well researched: https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/#what-about-gpudirect
Anshul Bhide Replit|2023-08-01 20:55:56|Not a vector DB, but still raised funding on the AI wave 👀  https://techcrunch.com/2023/08/01/neon-a-relational-database-startup-lands-30m-investment/amp/
Alok Bishoyi|2023-08-01 20:56:52|This round has been there for a while I believe
Alok Bishoyi|2023-08-01 20:56:59|Its just the announcement
Nirant|2023-08-01 20:57:05|Also proven founders — founded SingleStore/MemSQL. And amazing DevRel. Very underrated.
Nirant|2023-08-01 20:57:27|They're the only DevRel team I know using it for sales and not mktg
Alok Bishoyi|2023-08-01 20:58:51|I had YOLO d some money into their previous round through a syndicate purely because of founder trackrecord.   This group is how I know there’s been an upround lol
Bharat Kumar Ramesh Hashmal Web3|2023-08-01 21:00:48|Oh they'll jump on pgvector as well. Given the success supabase has seen on it recently
Bharat Kumar Ramesh Hashmal Web3|2023-08-01 21:01:02|Definitely something that was underwritten in the investment
Dhruv Anand|2023-08-01 21:02:02|time for me to add to their '100s of customers' via their 'generous free tier'
Dev Aggarwal|2023-08-01 21:08:30|Just curious - why would you want to have a database hosted out of your cloud and increase network round trips? Esp for databases that potentially store large text in fields
~ Honnesh Rohmetra|2023-08-01 21:09:17|‎~ Honnesh Rohmetra requested to join
~ Honnesh Rohmetra|2023-08-01 21:09:23|‎~ Honnesh Rohmetra joined using this group's invite link
Nirant|2023-08-01 21:10:51|"For the same reason you've compute on cloud and not on edge: ""Serverless"" — whatever that branding/category means e.g. lower cost, pay for use, higher availability and so on"
Nirant|2023-08-01 21:11:33|Also, they might have some way to bring it inside the VPC 
~ Apurva Bhatt|2023-08-01 21:12:32|Hey folks, I need some advice. What debit/credit cards would you suggest for transactions like buying server space, buying openAI credits etc. I am more interested in international transactions like openAI. I see most debit/credit cards charge 1.5-2% of the total amount as convenience fees.
Abhishek Mishra|2023-08-01 21:13:45|A rough rule of thumb - 4 bit quantized model RAM requires model size in B params + Context length size
Abhishek Mishra|2023-08-01 21:14:19|So 7B param model would take ~4G to load it and 4G to occupy Max 4k context
Abhishek Mishra|2023-08-01 21:14:51|Total 8 in worst case by the thumb rule. Increase context size and requirements go up
Abhishek Mishra|2023-08-01 21:15:48|You can also work with small context < 1k context with 7B model and only use 5G for your use case for 4 bit quantized model
Rahul Bhatnagar|2023-08-01 21:16:28|That’s the amount of RAM. But the size of the weights. Would be fixed right. There’s a 10 GB limit on the docker image.
Abhishek Mishra|2023-08-01 21:17:48|Model weights size is around half size in B params and is fixed ‎<This message was edited>
Abhishek Mishra|2023-08-01 21:18:15|So 7B model takes 3.7G on disk in 4 bit quantized form
~ Honnesh Rohmetra|2023-08-01 21:19:16|Hey Everyone, Just got added to the group. (Thanks to Dev) I am Honnesh, currently working on Efficient Deep Learning at Deeplite, Toronto. Previously worked on Neural Rendering at Intel Labs.
Hemant Mohapatra|2023-08-01 21:31:48|Old news but lot of respect for them and Nikita who I think is a great technologist (this coming from a Supabase investor :-)) - their tech allows you to scale compute separately from storage which is useful when you are trying to build read only use cases.
Ojasvi Yadav|2023-08-01 21:40:20|Question : <user input>  Answer : <LLM response>  Context :<retrieved relevant chunks from your vector DB>  Based on the context, (1) is the answer to the question correct? (2) List down the assumptions in the answer that are not provided anywhere in the context.
Ojasvi Yadav|2023-08-01 21:40:37|(1) should help with accuracy (2) should help with hallucinations
Ojasvi Yadav|2023-08-01 21:40:54|not 100% correct, but should get you half way there
Ojasvi Yadav|2023-08-01 21:41:04|Your mileage might vary
Shiv Magik|2023-08-01 21:42:55|Super helpful thank you!
Lucifer 😎|2023-08-01 21:55:52|‎You removed Lucifer 😎
~ gaurav|2023-08-01 21:58:33|For deploying in aws altough it might require some work but its easily scalable.   1. Use hf as model store, can download in s3 or local. 2. Wrap it in fastapi with ray serve to run it in cluster. For this basic one would be to use multi vm setup. Else one vm is fine  3. ALB connected with multi vm (cluster). And that alb to route 53.  Alteast for inference cpu vm would also work. But gpu does speed up things.
~ Sid|2023-08-01 21:59:42|compared to that sagemaker inference would be even easier and more scalable??
~ Nayan Shah|2023-08-01 22:00:55|I dont think so , i teied 9 months back 🥲 for inference had to learn about lambda function api gateway and then sagemaker all this things just for inferenve ... It does not take much time though .. but for newer person can take some time
~ gaurav|2023-08-01 22:01:36|So my philospohy is to rely less on pre made services. Espically for sagemaker it is good preliminary, would not recommend for scale. I had very much problems in sagemaker endpoints in autoscale.
~ Sid|2023-08-01 22:02:23|ohkkk.. we are in process of migrating all the models from ec2 to sagemaker.
~ Sid|2023-08-01 22:03:09|even for deploying we are facing lots of problems. and aws sagemaker team is not very helpful.
~ gaurav|2023-08-01 22:04:03|Sagemaker is good for DS stuff. Pipelines are really good. But only for LLM as they even do not have much better solution i wont recommend. Also bedrock is preety good.
~ Nayan Shah|2023-08-01 22:04:06|Ohh for us , we went with compute optimized ec2 instances , and with docker based fast api application .. based on usage we have made that docker as the single unit of model ... And then  we are scaling by adding more replica of the same ... Docker ...
~ Sid|2023-08-01 22:04:57|i gave same suggestion to my team, but they did not agree. 🥲
~ Nayan Shah|2023-08-01 22:05:07|🤣🥲
~ Nayan Shah|2023-08-01 22:06:23|What were there points to not go with this ? 🤔
~ Sid|2023-08-01 22:08:12|they didn't want to handle the servers and infrastructure, wanted to go with managed service.
Jaskamal Kainth 2013|2023-08-01 22:08:15|This looks good. I tried a similar setup. On a side note, what TPS were you able to get and for which model?
~ Nayan Shah|2023-08-01 22:10:38|Dont remember the numbers 🥲 will check and share if i find .. but models were l6 , l12 and some other models which were bigger in size ... Also we did transform the model to onnx format and did the quantization and that also helped reduce the latency ..
~ Nayan Shah|2023-08-01 22:11:42|Without any accuracy deficit we compared with the original sts benchmark .. and was not much diff ..
~ Sparsh|2023-08-01 22:29:33|Anyone working on graph db here?
~ Sparsh|2023-08-01 22:29:45|Or does anyone know what kind of RAG system is perplexity using?
Aayush Jain AWS|2023-08-01 23:09:45|‎Aayush Jain AWS was added
‪+91 95489 63434‬|2023-08-01 23:09:45|‎‪+91 95489 63434‬ left
Pratik Bhavasar|2023-08-01 23:24:03|What is your guess?
~ Sparsh|2023-08-01 23:28:48|Using serp api for search, curating 4-5 different websites based on query, using strong crawler & RAG to extract information relevant to query, summarizing it and then using GPT-4 to show results
Pratik Bhavasar|2023-08-01 23:29:31|Sounds about correct.
Pratik Bhavasar|2023-08-01 23:29:43|Where are you stuck?
~ Sparsh|2023-08-01 23:32:06|Strong crawler and RAG step
Dr. Pratik Desai KissanGPT|2023-08-01 23:33:42|Crawling for each search query from serp results should add significant latency
Aashay Sachdeva MPL Data Scientist|2023-08-01 23:38:27|Can be easily parallelised
Dr. Pratik Desai KissanGPT|2023-08-01 23:40:15|I think there is a big cache and existing embeddings layers are at play, the serp results listed doesn't have to always match the answers or to be source of the  generated content.
Abhishek Mishra|2023-08-02 00:11:29|Haven't verified this outrageous claim but a new model NewHope is released by Slam Group and they claim to have 99% of GPT4 programming capabilities. It's just a llama2 13B fine tune so can be easily tested for the claim, let's see.  https://github.com/slam-group/newhope
Ojasvi Yadav|2023-08-02 00:28:39|They've released the model weights
Abhishek Mishra|2023-08-02 00:30:20|Yes, it just finished uploading on HF, was waiting for that to begin inference
Abhishek Mishra|2023-08-02 00:31:20|Don't want to discount their claim easily but dataset is hidden so need to test it outside of HumanEval set
Ojasvi Yadav|2023-08-02 00:33:13|If they've got research profiles on that college website then I hope it's true
~ Ayush Yadav|2023-08-02 00:45:21|Has anyone here, tried using gpt to write cold emails ?   I want to make a bot which can take my basic information & skills & write personalised cold email for company I am applying to.  It's my 4th year, so I was looking to increase my chances of getting placed.  😅
Divya Tak|2023-08-02 00:46:11|There are products that do that i think
~ Drishti Bhasin|2023-08-02 00:46:38|‎Ravi Theja added ~ Drishti Bhasin
~ Ayush Yadav|2023-08-02 00:48:09|I was thinking of building my own.
~ Ayush Yadav|2023-08-02 00:49:44|Any product you know? , I can take inspiration from that .
Sandeep Srinivasa RedCarpetup|2023-08-02 00:51:13|https://twitter.com/ayushthakur0/status/1658473081533505537
Divya Tak|2023-08-02 00:53:22|https://www.clay.com/
Divya Tak|2023-08-02 00:53:35|this the one product that i get emails from
~ Ayush Yadav|2023-08-02 00:56:14|I'll check it
~ Ayush Yadav|2023-08-02 01:04:27|Exactly the thing I was looking for.
~ Ayush Yadav|2023-08-02 01:05:03|Thanks [PHONE] [PHONE]
Abhishek Mishra|2023-08-02 04:29:09|Tested it out for python, it's a good model but not 99% of GPT4, we need better evals than HumanEval.  Jupyter notebook - https://drive.google.com/file/d/1k7RkAlaiUC43rYFOMIIrge3ydqGC44cg/view?usp=drivesdk ‎<This message was edited>
Atik Shaikh|2023-08-02 06:19:06|Nice idea 👌
~ Vik|2023-08-02 07:25:00|if js/ts works for you try llm-client it has retry and several other strategies to ensure more consistent results as well as request tracing etc to help with debugging https://github.com/dosco/llm-client
~ Soham|2023-08-02 08:39:36|Tried to build my first open source project. Text2Unix converter. It uses the power of GPT to convert raw text to GPT and the power of golang to execute the unix commands. Looking forward for your reviews , feedbacks and your contributions. https://t.co/XHmk5uLQxU
~ Vik|2023-08-02 08:44:56|need to ensure it does not decide to rm -rf / 🙂
~ Soham|2023-08-02 08:49:46|I command has a optional flag —exec. If you wish you to wish it its on you😂 I may add the disclaimer though, “Commands executed by the bot does not represent the views of the creator” 🤣
~ gaurav|2023-08-02 09:00:00|Suggessition, using openai functions as instruction can work better as it provides rigid commands.
~ Soham|2023-08-02 09:00:57|I was actually thinking to move away from gpt to llama 2 since it is open source. Thoughts?
~ gaurav|2023-08-02 09:01:48|You can mimick function calling on llama 2 also.
~ gaurav|2023-08-02 09:02:33|https://www.reddit.com/r/LocalLLaMA/comments/15742zf/function_calling_with_llama2/
~ Soham|2023-08-02 09:02:58|Got it! Will do.
~ Vik|2023-08-02 09:03:04|i have got that working with llm-client tested using lama2 70b
~ Vik|2023-08-02 09:03:34|also reasoning worked but not with the smaller models probably need tuning
~ Adithya|2023-08-02 09:07:02|Did you want to deploy on lambda for this?
Anubhav mishra Zupay|2023-08-02 09:08:48|https://www.timesnownews.com/technology-science/chatgpt-powered-by-gpt-5-is-coming-openai-files-patent-article-102315872
~ Soham|2023-08-02 09:12:18|Yup
Nirant|2023-08-02 09:22:56|Trademark does not mean launch plans. I sometimes wish journalists had to undergo a reading comprehension exam.
~ Adithya|2023-08-02 09:24:23|Want to build it on device? With C inferencing?
Vamshi|2023-08-02 09:24:53|I think what they comprehended was the spiciness of the article they could make out of the finding
~ Vanshika|2023-08-02 10:39:57|‎~ Vanshika requested to join
~ Santhosh K|2023-08-02 10:56:16|What are some of the best opensource machine translation models that supports good number of languages?
Sachin Legaltech|2023-08-02 11:02:56|https://huggingface.co/docs/transformers/model_doc/nllb
Rajaswa Patil|2023-08-02 11:05:36|Hey folks, I am trying to survey metrics for LLM Hallucinations. Some products have started offering them in their monitoring services (like Galileo - https://www.rungalileo.io/llm-studio/).  Does anyone know of any OS repos/papers which discuss LLM hallunications?
Nirant|2023-08-02 11:08:50|cc [PHONE] works with Galileo on this problem  This has a very good survey/coverage on challenges of eval in general: https://eugeneyan.com/writing/llm-patterns/
~ Nikhil|2023-08-02 11:12:06|Read this recent paper: https://arxiv.org/pdf/2306.16564.pdf
Pratik Bhavasar|2023-08-02 11:12:28|I have started writing about it - you will find a blog on our website. I will be sharing more in coming days. You can survey this if you are eager. https://github.com/MLGroupJLU/LLM-eval-survey
Rajaswa Patil|2023-08-02 11:19:34|This is awesome! Let me go through these today. Thank you folks :)
~ Drishti Bhasin|2023-08-02 11:33:35|Hi folks, I'm Drishti, part time deep learning researcher; full time reddit lurker. I recently graduated from IIT Roorkee and am primarily interested in semi-supervised learning, interpretability and reinforcement learning. You can check out my work/experiences here https://www.linkedin.com/in/drishti-bhasin-ab07531a9/, looking forward to being a part of this community!
ashish Acgt01 Twitter|2023-08-02 11:57:22|This is a long but brilliant, insightful  read : https://eugeneyan.com/writing/llm-patterns/  https://news.ycombinator.com/item?id=36965993  another post by the same author, on a copilot for writing & reflecting: https://eugeneyan.com/writing/obsidian-copilot/  cc : [PHONE]  [PHONE]  [PHONE] [PHONE] ‎<This message was edited>
Nirant|2023-08-02 11:59:58|Yes, Eugene and I've been talking about these patterns for a bit, finally convinced him to write it!
ashish Acgt01 Twitter|2023-08-02 12:09:24|He writes so freaking well !  Another gem : https://eugeneyan.com/writing/llm-experiments/
Sandeep Srinivasa RedCarpetup|2023-08-02 12:10:36|"has anyone had success with JSON formatting (same as openai functions) in Llama2 ? im not quite sure what the prompts needed here are. openai has a ""functions"" parameter in the call.   what is the equivalent in llama2 prompts ?"
Nirant|2023-08-02 12:12:05|Nothing stable has emerged yet in terms of prompts. Looks like we'll need a LoRA or a similar finetune. There is already someone selling that as a web service fwiw: https://github.com/llamaapi  So it's most definitely doable
Aditya Agrawal SuperU|2023-08-02 12:12:32|We love LORA
Nirant|2023-08-02 12:12:37|"""best vector db"" — what is this, BuzzFeed?"
Sandeep Srinivasa RedCarpetup|2023-08-02 12:13:11|i have not known of a finetune strategy that builds in JSON functions inside models. are u sure about this ? i thought this was worthy of a base model rebuild.
Aditya Agrawal SuperU|2023-08-02 12:13:17|Need to pick one and not want to waste 3 days figuring out
Aditya Agrawal SuperU|2023-08-02 12:13:19|😂
Aditya Agrawal SuperU|2023-08-02 12:13:59|#not building vector data, looking to use one …
ashish Acgt01 Twitter|2023-08-02 12:14:00|"you need to be more nuanced than ""best"" when making technical choices."
Aditya Agrawal SuperU|2023-08-02 12:14:01|😂
Aditya Agrawal SuperU|2023-08-02 12:14:39|I wish added it earlier. Looking for QA on 1000+ pdf
Aditya Agrawal SuperU|2023-08-02 12:14:42|🙈
Nirant|2023-08-02 12:15:53|Do numpy or FAISS+S3, launch — and when you make money, come ask with your specific challenges perhaps?  1000 pdfs at 10 pages average, doesn't need anything more complicated
Aditya Agrawal SuperU|2023-08-02 12:16:48|We tried Faiss but we inference time is more than 10 seconds. Looks like indexing is bad so needed to try a better solution 🙈
Nirant|2023-08-02 12:18:38|Qdrant, Chroma have the fastest indexing times usually because both are in-memory stores  PS: This is great, please mention specific challenges e.g. the indexing time challenge in the opening question :)
Aditya Agrawal SuperU|2023-08-02 12:19:34|I should have added : I’m new to this and might be a dumb question but can some one please help 😂😂😂
Nirant|2023-08-02 12:22:47|I've changed my mind on this. NousResearch/Hermes and [PHONE]'s CodeCherryPop is a lot of empirical evidence that models can learn new behaviours (styles) with finetune and if done well, with LoRA too.
Abhishek Mishra|2023-08-02 12:25:49|I'll share some examples on this later today. The model has very high consistency in sticking to suggested markdown or json format
Sandeep Srinivasa RedCarpetup|2023-08-02 12:26:21|Much appreciated 🙏
~ Adithya|2023-08-02 12:41:11|I had done annoy, maybe look at the distance metric? If you use something like minkowski you're raising to a higher power will increase computation a lot, maybe cosine or something like that?
Prakash Sankar Harbor|2023-08-02 12:48:24|is anyone using GPT-4 noticing that it's extremely unreliable today? Same prompts that were working ytd are not working + it's sending back additional text with JSON even if the prompt explicitly asks it not to
Lucifer 😎|2023-08-02 12:49:53|‎Lucifer 😎 was added
~ Sanjeev NC|2023-08-02 12:49:53|‎~ Sanjeev NC left
~ Arya|2023-08-02 12:49:53|‎~ Arya left
Abhinav Verma Longshot.ai|2023-08-02 12:50:16|It's been fine for us
Sandeep Srinivasa RedCarpetup|2023-08-02 12:53:20|i have been hearing that the prompts are breaking, but no definitive answer here.
Prakash Sankar Harbor|2023-08-02 13:00:30|"ya even in multiple runs on the same prompt - sometimes the prompt respects the ""do not send back additional text/explanations"" and sometimes it does"
Prakash Sankar Harbor|2023-08-02 13:02:07|does anyone have any tips to get around this?
Bharat Kumar Ramesh Hashmal Web3|2023-08-02 13:08:14|It's temperamental. Just came to the realization that the end user is a lot more tolerant of it than I am
Bharat Kumar Ramesh Hashmal Web3|2023-08-02 13:08:22|So i just let it be. And hoped that openai will fix it in due course of time
Bharat Kumar Ramesh Hashmal Web3|2023-08-02 13:09:12|That being said, we did do a couple of things that helped
~ gaurav|2023-08-02 13:09:29|There was a research paper on this. They compared gpt 4 july version was very signifincantly worse than even 3.5 turbo
Bharat Kumar Ramesh Hashmal Web3|2023-08-02 13:10:02|Trying to dig up that internal note. Will send across
Prakash Sankar Harbor|2023-08-02 13:10:26|ty
Prakash Sankar Harbor|2023-08-02 13:10:32|sure, but I'm comparing from ytd to today
Prakash Sankar Harbor|2023-08-02 13:10:35|or even in between runs
Prakash Sankar Harbor|2023-08-02 13:10:40|like right now the problem just went away
Abhinav Verma Longshot.ai|2023-08-02 13:18:43|Could be one of the expert models went down and the request was rerouted to another model
Amit Bhor|2023-08-02 13:22:31|Expert model is busy doing this 😀  https://twitter.com/daamitt/status/1686634197807673345?t=G1va_39J9m6aqC_FwmPjqA&s=08
Prakash Sankar Harbor|2023-08-02 13:24:48|great...
Abhinav Verma Longshot.ai|2023-08-02 13:25:37|"Imagine you call a mixture of expert model and the response from one of the experts is ""Aap jis model ko call kar rahe hai wo doosre call mai vyast hai. Kripya thodi der paschat prayatna kare"""
Abhinav Verma Longshot.ai|2023-08-02 13:27:29|you'll find this in one of the older messages in this group. It depends on output tokens more than input tokens
Dr. Pratik Desai KissanGPT|2023-08-02 14:36:46|ai.com no more redirects to ChatGPT. Instead it goes to x.ai
Nitin Mahajan McKinsey|2023-08-02 14:37:28|Whatever it takes to make Twitter value go back up. AI, social media all same right
Dr. Pratik Desai KissanGPT|2023-08-02 14:38:40|OpenAI won't give away ai.com that easily, must have been a backroom drama, we will find out soon.
~ Sid|2023-08-02 16:04:16|https://twitter.com/maximelabonne/status/1685968738854580225?t=uHW7igawzVed9Y5LZV6IOg&s=08
Abhinav Verma Longshot.ai|2023-08-02 16:20:18|I think I got evidence of weird rate limiting by Openai regarding gpt4
ashish Acgt01 Twitter|2023-08-02 16:40:17|[PHONE] fyi
Gokul Krishnan|2023-08-02 16:56:02|"Looks like repeating ""a"" with space for 1k time leaks user chat history on chatGPT 🫠"
Shashank Generative AI Group|2023-08-02 16:56:49|"🆕Langchain Expression Language :   ""Unified streaming, async and batch interfaces across all chains  Easy declarative composition of chains, making them easier to understand and modify.""  https://twitter.com/hwchase17/status/1686425322261213184?t=OEmxA9R03xi9BTdgdzj6Ww&s=19  examples: https://python.langchain.com/docs/guides/expression_language/cookbook#code-writing"
Rajiv Poddar DevGPT|2023-08-02 17:56:02|‎Rajiv Poddar DevGPT requested to join
~ Apurva Mudgal|2023-08-02 18:41:36|‎~ Apurva Mudgal joined using your invite
~ Mani Iyer|2023-08-02 21:25:36|‎Abhishek Mishra added ~ Mani Iyer
~ Rohit|2023-08-02 21:41:34|https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/
Vamshi|2023-08-02 21:43:12|Ah finally some new audio model news
Rajaswa Patil|2023-08-02 21:46:39|Samples sound promising.
Dr. Ashith Generative AI WA Group|2023-08-02 22:18:19|Are the weights available for download?
~ Rohit|2023-08-02 22:35:06|The huggingface links are in the github repo. https://github.com/facebookresearch/audiocraft
Shashank B Designer|2023-08-02 22:48:28|https://txt.cohere.com/c4ai-scholars-program/   Interesting
~ Sachin Kalsi|2023-08-02 22:54:31|https://twitter.com/nostalgebraist/status/1686576041803096065
~ Rukesh Reddy|2023-08-03 00:05:59|“The premise was simple: feed an AI with labeled examples of violence, hate speech, and sexual abuse, and that tool could learn to detect those forms of toxicity in the wild. That detector would be built into ChatGPT to check whether it was echoing the toxicity of its training data, and filter it out before it ever reached the user. It could also help scrub toxic text from the training datasets of future AI models.  To get those labels, OpenAI sent tens of thousands of snippets of text to an outsourcing firm in Kenya, beginning in November 2021. Much of that text appeared to have been pulled from the darkest recesses of the internet. Some of it described situations in graphic detail like child sexual abuse, bestiality, murder, suicide, torture, self harm, and incest.”
~ Rukesh Reddy|2023-08-03 00:06:29|^^^from https://time.com/6247678/openai-chatgpt-kenya-workers/
~ Rukesh Reddy|2023-08-03 00:08:30|So my question is, is this not a one and done problem? Given this labeling is done now, wouldn’t there be ready datasets of “toxic stuff to avoid using” that all future LLMs can use? Assuming open AI would share
Chetanya Rastogi|2023-08-03 03:40:10|There's also this https://github.com/nelson-liu/evaluating-verifiability-in-generative-search-engines  I used this dataset and some other to train a hallucination detection model. There's a lot of work around this nowadays  https://arxiv.org/abs/2305.14251 https://arxiv.org/abs/2305.14908 https://arxiv.org/abs/2307.13528 ‎[8/3/23, 03:46:19] Chetanya Rastogi: ‎image omitted
~ Arko Cy|2023-08-03 06:45:29|Naice. This was much awaited
ashish Acgt01 Twitter|2023-08-03 08:02:46|hn thread : https://news.ycombinator.com/item?id=36972347
Nilesh Transcend|2023-08-03 08:06:14|There was this vector extension for Postgres that claimed to be more performant than pgvector. Unable to find it in my history. Anyone remember its name?
ashish Acgt01 Twitter|2023-08-03 08:08:13|"only a matter of time ( 6 months or less ?) before specific artist tuned models become available : a model which generates ""Taylor swift""-esque or ""Billy Eilish""-esque music.  Closer home, I bet most of us won't be able to distinguish between music generated by the human Ritviz & a model trained on Ritviz's body of work :)  What do people think ?  edit : a techno-philosophical question : can such music generating models be used for generating music in the style of an artist, who is no longer alive ? If a song, generated by a model trained on e.g. Lata Mangeshkar's style of singing, is releases and becomes  popular - does Lata Mangeshkar's trust get a share of the royalties ? ‎<This message was edited>"
Diptanu Choudhury FB AI|2023-08-03 08:10:21|What faiss index are you using?
Diptanu Choudhury FB AI|2023-08-03 08:11:36|Faiss needs to be tuned appropriately for the usecases. Commercial vectordbs makes some sensible choices for users like the nature of the index, how they have to be sharded and read, etc. ‎<This message was edited>
Shivendu Kumar|2023-08-03 08:13:33|pg_embedding
Shivendu Kumar|2023-08-03 08:14:29|Better to ask this in AI philosophy group.
Nilesh Transcend|2023-08-03 08:14:30|Thanks, that's the one 👏
Aditya Agrawal SuperU|2023-08-03 08:29:20|Hi does anyone here in connection with Bhanu Teja from SitGPT? And can make an introduction?
~ Sravan Avvaru|2023-08-03 09:57:02|‎~ Sravan Avvaru requested to join
~ Deepesh|2023-08-03 10:12:30|A nice article on GPU shortage: https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/
Paras Chopra Wingify|2023-08-03 10:53:39|Has anyone gotten llama2 up and running in cloud as an api at a cost similar to gpt turbo 3.5
~ gaurav|2023-08-03 10:56:05|+1
Pratik Bhavasar|2023-08-03 11:04:29|What is the size of 3.5?
Tejas Referred By paras|2023-08-03 11:05:28|I assume it to be between 10 and 16 Billion.
Pratik Bhavasar|2023-08-03 11:06:19|My guess is 13B because I think curie is 13B and costs were same.
Pratik Bhavasar|2023-08-03 11:07:10|Aapko idea he?
Tejas Referred By paras|2023-08-03 11:07:19|Yeah, that was my reasoning. Running at 13 billion with similar costs seems reasonable.
Sandeep Srinivasa RedCarpetup|2023-08-03 11:08:02|replicate.com - not sure if its the same as gpt4. but they have per api call pricing
Pratik Bhavasar|2023-08-03 11:08:07|Yup Llama 13B is a good trade off of size and perf compared to 7b and 34b
Tejas Referred By paras|2023-08-03 11:08:55|Unless it is the MoEffication version of large models.
ashish Acgt01 Twitter|2023-08-03 11:09:35|"excellent talk by Subbarao Kambhampati: https://www.youtube.com/watch?v=BmyB-4S9QuY  ""But first, we have to stop confusing the impressive form of the generated knowledge for correct content, and resist the temptation to ascribe reasoning powers to approximate retrieval by these n-gram models on steroids. We have to focus instead on LLM-Modulo techniques that complement the unfettered idea generation of LLMs  with careful vetting by model-based AI systems. In this talk, I will reify this vision and attendant caveats in the context of the role of LLMs in planning tasks. ""  related : https://www.youtube.com/playlist?list=PLNONVE5W8PCTKHkDbnKIjakw_xVpI4DjT"
Tejas Referred By paras|2023-08-03 11:10:19|It is possible to compress a large model to reduce the memory footprint and achieve similar inference, thereby getting better performance than the original model of similar size.
Pratik Bhavasar|2023-08-03 11:12:11|If I remember correctly, from the Humanloop blog we know they were not doing inference with quantised model
Tejas Referred By paras|2023-08-03 11:12:46|We wrote this blog on 14 March.   https://nolanoorg.substack.com/p/int-4-llama-is-not-enough-int-3-and  Their is much recent paper on similar trade by Tim Dettmers and other to make it work in resource constraint setup.
Pratik Bhavasar|2023-08-03 11:13:23|I might be wrong.. maybe it mentioned they don’t have flash attention
Tejas Referred By paras|2023-08-03 11:13:26|We are also planning to publish more finding and survey blog on compression and inference soon.
Tejas Referred By paras|2023-08-03 11:13:51|Yeah, Mostly, they have MoE style models.
Tejas Referred By paras|2023-08-03 11:16:04|One way to convert existing model into its MoE version. https://arxiv.org/pdf/2110.01786.pdf
Tejas Referred By paras|2023-08-03 11:17:16|They haven't open-sourced their codebase. If anyone would like to reproduce it with me, I would love to hack over the weekend.
Tejas Referred By paras|2023-08-03 11:22:55|There are already a few examples of people making songs by hacking LLMs for writing, using Text-to-Audio for audio, and adding a bit of music/mastering. Grimes seems to have proposed this solution on royalty, as seen here: [https://www.bbc.com/news/entertainment-arts-65385382].
Kaushik Bokka|2023-08-03 11:34:57|https://lu.ma/0du5ddps
"~ $@| @$w@+h R•¥@|"|2023-08-03 11:36:47|"‎~ $@| @$w@+h R•¥@| requested to join"
Nilesh Transcend|2023-08-03 11:47:46|I'd check in Azure: https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-llama-2-on-azure/ba-p/3881233
Karan Lightspeed|2023-08-03 11:48:54|There’s are YouTube videos of replacing voices of Sonu Nigam, Udit Narayan etc. Anyone part of the music industry and know how labels are thinking about dealing with this?
Shubham Sharma 2012C6|2023-08-03 11:58:09|Copyright Strikes
"~ $@| @$w@+h R•¥@|"|2023-08-03 11:58:53|"‎~ $@| @$w@+h R•¥@| joined using this group's invite link"
Karan Lightspeed|2023-08-03 12:00:32|Are you part of the industry? I do think licensing will become a legit revenue source in future. Any learnings there?
Shubham Sharma 2012C6|2023-08-03 12:05:15|Yes I work in the Industry. Music licensing is a big business already. Any usage of song in licensed manner is permitted, anything else is copyright strike . Mind you anyone speaking/singing the lyrics as dialogue even without music usage is not permitted in today’s times.
Prakash Sankar Harbor|2023-08-03 12:08:51|does anyone have any experience making GPT work with date/time? Specifically how do you make it aware of what today is? For example, if I ask for a date 2 days after today, it gives a date from 2022
Nilesh Transcend|2023-08-03 12:10:18|Include today's date in the prompt?
Prakash Sankar Harbor|2023-08-03 12:10:49|I did that
Dev Aggarwal|2023-08-03 12:11:27|System prompt or user prompt?
Sandeep Srinivasa RedCarpetup|2023-08-03 12:11:42|it cant do  math. u need to hook out to codeinterpreter or create a chain of thought that calls an application function to do date math.
Sandeep Srinivasa RedCarpetup|2023-08-03 12:12:07|a model cannot access hardware, so it doesnt have current time awareness as well
Prakash Sankar Harbor|2023-08-03 12:12:08|ah gotcha ‎[8/3/23, 12:14:08] Nilesh Transcend: ‎image omitted
Prakash Sankar Harbor|2023-08-03 12:14:29|weird - not happening via API ‎[8/3/23, 12:24:17] ashish Acgt01 Twitter: ‎image omitted ‎[8/3/23, 12:24:18] ashish Acgt01 Twitter: ‎image omitted
ashish Acgt01 Twitter|2023-08-03 12:26:11|maybe gpt4 is using some additional magic sauce to do basic math ?
Nilesh Transcend|2023-08-03 12:26:44|If you are using the API, why don't use your programming language for date arithmetic?
Prakash Sankar Harbor|2023-08-03 12:27:22|well cos my use case demands that I don't right ‎[8/3/23, 12:32:16] ashish Acgt01 Twitter: ‎image omitted
~ Sid|2023-08-03 12:48:44|hi, i am using langchain for question answering bot, I have used RetrievalQA chain by providing llm, retriever, chain type stuff and custom prompt.  how can I have more control over retriever step in this?? i want to run the retriever multiple times based on Metadata and fetch relevant docs. I don't want to move away from langchain due to langsmith.
~ Sid|2023-08-03 13:10:43|important : Delhi meet up will be held online due to current situation of Gurgaon. source : https://hasgeek.com/fifthelephant/2023-07-delhi/updates/delhi-meet-up-event-to-be-conducted-online-importa-VX3JL52QzGZ6PreZ5Pfjgy
~ Mudit|2023-08-03 13:12:11|‎~ Mudit requested to join
Arvind N Generative AI Group|2023-08-03 13:20:56|Hybrid queries?
~ Sid|2023-08-03 13:22:52|not exactly, we have different Metadata attached with each document. based on the Metadata we want to modify search criteria. if no Metadata is there then we want to search within certain conditions. chunks might be retrieved multiple times for this.
~ Sid|2023-08-03 13:26:58|one thing which I got is defining custom retriever, I'm checking that right now.
Dhanush Speciale Invest|2023-08-03 13:29:03|https://www.mosaicml.com/llm-evaluation
Jay Pokarna 2014 BPCC|2023-08-03 13:51:15|When is this, btw?
~ Sid|2023-08-03 13:51:35|tomorrow
Alok Bishoyi|2023-08-03 15:25:51|Anyone know how the recent ban on imports of electronics ( laptops , servers etc ) affect hobbyists ?
Sthit Generative AI WhatsApp Group|2023-08-03 15:32:39|What's this ban exactly ? Unaware of it
Alok Bishoyi|2023-08-03 15:34:00|https://entrackr.com/2023/08/india-limits-import-of-laptops-tablets-pcs/
Alok Bishoyi|2023-08-03 15:34:43|I am not sure about the repurcussions to be exact. Seems like they still allow licensed importers? Not sure what the ground situation is
Nirant|2023-08-03 15:35:51|This is absolutely amazing!  This has the potential to kills all startups wanting to hack with 4090s in their racks bought off Amazon or Ebay US. Definitely hurts hobbyists — and encourages smuggling tbh. ‎[8/3/23, 15:36:35] Alok Bishoyi: ‎image omitted
~ Pradeep Ayyagari|2023-08-03 15:36:50|They have given exemption of 1-2 pieces with duty payments, so should cover hobbiests. Upto 20 for R&D. Obviously how this manifests at port level will be something to see.
Nirant|2023-08-03 15:38:06|I've more faith in a pet cat to enforce rules than customs who can barely differentiate between a cooling fan and a motherboard
jyotirmayjk Hackathon|2023-08-03 15:38:16|More regulations also give boost to scare mongering practices at customs More grey area,more ways to trouble end user and extract value ‎<This message was edited>
jyotirmayjk Hackathon|2023-08-03 15:40:41|‘Boost to domestic manufacturing’ is slowly taking us back to pre-liberalisation pro-socialist era
jyotirmayjk Hackathon|2023-08-03 15:41:22|Also could be unrelated but this could be one reason too https://www.hindustantimes.com/technology/jiobook-pre-order-online-jio-laptop-pictures-price-features-reliance-new-device-launch-best-amazon-deals-101690812601836.html
Sthit Generative AI WhatsApp Group|2023-08-03 15:42:02|Intriguing
Nirant|2023-08-03 15:44:19|Sincerest apologies for encouraging this, the convo belongs on the AI & Policy group 🙏
Sandeep Srinivasa RedCarpetup|2023-08-03 15:45:01|can u explain this a bit more ? (context im building some tools here). u want to run retriever multiple times before the prompt call i presume ?
~ Sid|2023-08-03 15:55:34|yes, based on Metadata there are some conditions in which we want to run retriever multiple times. but i am not able to do it. I was thinking of writing a custom retriever which will get chunks multiple times then choose the most relevant and return, but I'm not able to understand how do write custom retriever. there is nothing in documentation and langchain bot gave some code which is not working obviously.
Sandeep Srinivasa RedCarpetup|2023-08-03 15:57:35|"what ur doing is somewhat (but not exactly)  HyDE algorithm for document search. the papers and pseudocode for my primitive implementation is here - https://github.com/arakoodev/EdgeChains/issues/23  u should not think of it as ""retriever only many times and then prompt"" but rather ""different prompt+retriever sequences many times"""
~ Sid|2023-08-03 16:00:03|that would mean multiple llm calls, right?
~ Sid|2023-08-03 16:00:21|my use case is little bit different actually.
Sandeep Srinivasa RedCarpetup|2023-08-03 16:02:38|the reason why im pointing this out is because if ur fundamentally going to re-order and play with metadata interpretation yourself, then you might introduce a higher degree of inaccuracy for the llm to make sense of.  so if u avoid the multiple llm calls, be very careful on how u choose ur relevancy. the reason hyde works very well is cos the llm corrects itself on the second call.
Sandeep Srinivasa RedCarpetup|2023-08-03 16:03:25|however if u do want to do it yourself..then langchain wont let you. you will have to use gptindex or edgechains (shameless plus).  langchain doesnt split the pipe & the prompt
~ Sid|2023-08-03 16:05:02|i understand your point, actually we have defined Metadata based on the knowledge base, and one question can have different responses based on category, we might even want to summarize all info in the response as well based on Metadata.
~ Sid|2023-08-03 16:05:07|ohhh...
Sandeep Srinivasa RedCarpetup|2023-08-03 16:06:38|"the thing im pointing out is the meaning of the word ""We Want"".  We == your python code doing arithmetic sorting vs We == llm choosing the relevant documents  is the interesting question"
~ Sid|2023-08-03 16:17:20|sorry for the confusion, I meant to say I might want to write code which will retrieve certain chunks based on query text & params and pass to llm for direct answering or summarization.  for this I want to write my own retriever which will fetch chunks based on few conditions and pass it to langchains RetrievalQA chain
Sagar Patidar Primathon|2023-08-03 18:17:16|Hi everyone, I want to build a chatbot where if a person asks “recommend me a car”, the chatbot should ask them various questions like a) whats the current car you’re driving b) preference on EV/ICE etc etc and then recommend a car.  How should one approach building a chatbot like that? Any ideas/links will be super helpful! Thanks 🙏 😊
Sandeep Srinivasa RedCarpetup|2023-08-03 18:18:39|"this is generally called a ""planner prompt"". if you google for this, you will find some clues on how to go about this."
Nirant|2023-08-03 18:20:31|As a free bonus tip, chained OpenAI function calls mimic planning prompt behavior
Nirant|2023-08-03 18:20:38|Specially on GPT4
Lalit Pagaria|2023-08-03 18:49:17|https://twitter.com/helicone_ai/status/1686840508658876419?t=pICbtAKVANeC6O6wY4aXKg&s=08  Open source LLM API observability tool with caching.
Rajaswa Patil|2023-08-03 18:53:49|Oh looks neat. Are there any other good ones out there?
Chaitanya A GenAI|2023-08-03 18:57:13|platforms are very early in this space, know of portkey being developed out of India - worth a try
Rajaswa Patil|2023-08-03 19:07:02|Oh yes, trying out Portkey rn! Was exploring other platforms in general (maybe OSS, or ones with eye-catching features)
Nirant|2023-08-03 19:19:19|Cc [PHONE] is the Portkey founder
Prakash Sankar Harbor|2023-08-03 19:27:00|Does this tell me when my prompt results are different from before and by how much?
Dr. Pratik Desai KissanGPT|2023-08-03 19:27:06|My problem with this type of tools is that they add latency. An async, queue based tool would be great to have.
Dev Aggarwal|2023-08-03 19:33:06|Provision inside the azure datacenter as openai 😀
Dr. Pratik Desai KissanGPT|2023-08-03 19:41:11|Moved to azure OpenAI months back. My design principle is that one shouldn’t add latency for post analysis purpose, it is only reserved for necessary customer operations. Everything else goes to queue.
Dev Aggarwal|2023-08-03 19:41:58|But latency of this is like milliseconds. The model will take ~10 sec to generate response
Dr. Pratik Desai KissanGPT|2023-08-03 19:47:06|Yeah, I don’t use GPT4 for that reason, and probably will move to self hosted llama2 before GPT4 for the same reason. Right now we are doing tts+stt+transcribe+translate+ rag under 10secs. Anything more will increase user drop off rate.
Dr. Pratik Desai KissanGPT|2023-08-03 19:48:52|And then when you architect it for Million active daily user, latency will add up.
~ Deepesh|2023-08-03 19:49:33|This is definitely cool. Prompt powered dashboards could take this to new heights
Dr. Pratik Desai KissanGPT|2023-08-03 19:49:35|However, this code is open source, so I can hack into integrating redis queue.
~ Sparsh|2023-08-03 20:03:24|claude is also very very fast
Rohit Aggarwal|2023-08-03 20:03:36|Thanks! We’re just launching deep new analytics tomorrow. We’ll also think about re-launching then 😅
Rohit Aggarwal|2023-08-03 20:03:51|What do you mean by prompt powered dashboards?
~ Deepesh|2023-08-03 20:05:24|"e.g. prompt like ""show all API call costs in last 2 hours"" instead of clicking on links/filtering"
Rohit Aggarwal|2023-08-03 20:06:08|Aah, natural language DSLs for filtering. We’ve had it forever in the roadmap but has always felt vanity
~ Arindam Barman|2023-08-03 20:07:11|I assumed all these tools are already monitoring async-ly no?  cc: [PHONE] ??
~ Deepesh|2023-08-03 20:08:58|i see. which product r u referring to
Rohit Aggarwal|2023-08-03 20:25:05|Async monitoring is only possible when you need logging alone.   For automatic retries, caching, load balancing across keys - needs to be synchronous.
~ Arindam Barman|2023-08-03 20:27:07|Oh right I forgot about those features.
Sudharshan GenAI|2023-08-03 20:27:27|https://ollama.ai/blog/run-llama2-uncensored-locally
~ Ashwin|2023-08-03 20:39:29|Have you tried workflow orchestration systems, like Temporal? There is a slight overhead in terms of bookkeeping but we found it’s one of the easiest ways to integrate services running in multiple stacks, and be able to scale up with demand.
~ Shishira Nataraj|2023-08-03 21:09:11|‎~ Shishira Nataraj requested to join ‎[8/3/23, 21:56:58] Harsh Gupta Felvin: ‎image omitted
Sachin Legaltech|2023-08-03 22:02:08|Pinging you
Sagar Patidar Primathon|2023-08-03 22:15:20|This is very interesting. Thanks for sharing [PHONE]!
~ Arindam Barman|2023-08-03 22:16:25|I was once building this in search of building better autogpt but never finished. https://www.youtube.com/watch?v=_n1d1BoEt-U&feature=youtu.be&themeRefresh=1
~ Arindam Barman|2023-08-03 22:16:37|Perplexity's copilot does this very good btw
Sagar Patidar Primathon|2023-08-03 22:17:15|Oh wow! I will start hammering here then :) thanks [PHONE] 🤝
Sagar Patidar Primathon|2023-08-03 22:18:19|Yeah Perplexity executed really well. Couldn’t find much on how they did it 🤔
~ Krishna|2023-08-03 22:22:01|Can you use a model commercially if it is trained on a dataset of GPT-4 responses? 🤔
~ Arindam Barman|2023-08-03 22:31:02|If you are asking of using an LLM model that has been trained on gpt4 responses, I am pretty sure I read that you can't do that for commercial purposes. But if you have fine tuned your own LLM using GPT4 responses and not selling the model directly but only as part of your product then I don't know. ‎[8/3/23, 22:32:40] Nirant: ‎image omitted
Anshul Bhide Replit|2023-08-03 22:32:53|btw perplexity is offering 25% off on their pro plan https://twitter.com/perplexity_ai/status/1687138706006712321
Sagar Patidar Primathon|2023-08-03 22:44:37|Awesome 👏
~ Madhav Singhal|2023-08-03 23:04:42|What are some of the best open sourced, commercially useable, text to speech models out there?   Looking for ones that sound very realistic.
~ Shanthi Vardhan|2023-08-03 23:26:24|Check Tortoise TTS  https://github.com/neonbjb/tortoise-tts  inference is bit slow but it will generate very realistic voices, you can try with few samples.
"~ $@| @$w@+h R•¥@|"|2023-08-03 23:42:26|Hey I am building doc q&a using llama index   I use pine cone for vector store of embeddings and them open Ai 3.5 turbo for q&a  Problems I face  1) when I send top 2   pages for open ai the token size is 10k as I am doing 1 embedding for each page so I takes 7-10 seconds to get response(because llama index use preprocessing to handle token count)to reduce this time to under 4 seconds I did chunk size of 1k tokens then the content is less and I have increase the top picked docs to 4 and was able to get the time under 4 secs but is there a better approach to leverage indexing even better other than chunking as I am not getting all content if I increase top picked items then I get back same token count issue
ashish Acgt01 Twitter|2023-08-04 06:22:01|Very cool tooling & infra startup backed by yc, Cedana  https://www.ycombinator.com/launches/JAP-cedana-real-time-compute-migration  https://cedana.ai ‎<This message was edited>
Neha YC W23|2023-08-04 06:23:15|uptrain launched an OSS one recently as well
Nirant|2023-08-04 07:22:32|Alibaba releases QwenLM-7B and Chat variant  Self-reported results: Beats Llama2 by a mile on math(GSM8K), code (HumanEval), Question Answering and QA (MMLU) 🤯 ~2x better than GPT4 on a variant of tool selection (e.g. AutoGPT) — 8.5% False Positive Rate, compared to GPT4's 15%  Commercially licensed if below 100M users at launch  https://huggingface.co/Qwen
Ravi Theja|2023-08-04 07:25:31|Can help you on this. DM you.
Paras Chopra Wingify|2023-08-04 09:28:41|Every day -> wake up, some benchmark is surpassed
"~ $@| @$w@+h R•¥@|"|2023-08-04 09:29:27|Can some one suggest me advanced indexing mechanism that I can leverage along side of semantic search
ashish Acgt01 Twitter|2023-08-04 09:46:06|"am i alone in thinking that we are all part of a special time in ml/ai evolution ? something we will tell our kids about ? :) ""back in the day in 2023, we had, the first ai ""summer"" when the first LLMs were invented "" : D"
~ Deepak Jawahar|2023-08-04 09:51:47|Totally 💯
Dev Aggarwal|2023-08-04 10:12:32|Any suggestions on LLM multi model providers like nat.dev openplayground, but under a chat/completion api with billing?
~ Vik|2023-08-04 10:13:04|together.xyz ‎<This message was edited>
Dev Aggarwal|2023-08-04 10:17:57|Only open source, but nice ‎[8/4/23, 11:45:49] Krishna Panchal: ‎image omitted
Anubhav mishra Zupay|2023-08-04 11:49:27|https://huggingface.co/ibm-nasa-geospatial
Anubhav mishra Zupay|2023-08-04 11:49:44|Anyone looking to play around with this ?
Nirant|2023-08-04 11:50:18|Commoditising the OpenAI moat — piece by piece
Pratyush Choudhury|2023-08-04 11:50:43|Kahan sir? What do you think is OpenAI's biggest moat?
Abhinav Verma Longshot.ai|2023-08-04 11:50:48|Expert by expert
Abhinav Verma Longshot.ai|2023-08-04 11:51:09|Your eyeball data at the moment
~ Sudhanshu Heda|2023-08-04 11:52:31|Reminder: Open Arxiv every morning 😩
Neha YC W23|2023-08-04 11:52:36|OpenAI probably has the best researchers and a great ceo. Id take that as a moat
Pratyush Choudhury|2023-08-04 11:52:53|Oh, I'd say far from it
Pratik Bhavasar|2023-08-04 11:53:01|Maybe it doesn’t have safety tuning which did not suppress its performance
Pratik Bhavasar|2023-08-04 11:53:10|They don’t share toxicity metrics
Abhinav Verma Longshot.ai|2023-08-04 11:54:44|I think they have access to quality data and they also do create good training data as well . I think they focused on this a lot.
Nirant|2023-08-04 13:56:42|"I'll check this by saying ""Xi is a slow Panda"" in Mandarin?"
ashish Acgt01 Twitter|2023-08-04 12:02:16|millions of people using chatgpt, generating rlhf (& training ?) data, at scale for them, for their base models to improve every day, every week, substantially !
Abhishek Mishra|2023-08-04 12:06:32|Itadakimasu 🍽️
Pratyush Choudhury|2023-08-04 12:07:32|Umm, I'd put it into 2 buckets -   1/ They have a lot of understanding of how consumers want to use LLMs in their use-cases. I say consumers & not enterprises because unsure how they capture the enterprise behavior from their deployments (happy to hear from others if they have an idea)  2/ They also have an economy of scale today - they are the best posited to do the LLM serving very efficiently w/ the best form of GPU utilization as they get the highest no of requests coming in from different directions at the same time. This is huge in the case of GPUs as GPU utilization happens differently than CPU utilization
Dev Aggarwal|2023-08-04 12:08:54|I’m not sure about 2) technically - there’s definitely a sweet spot for this but I think at openai scale you get un-economy of scale (from my limited understanding of running a k8s gpu cluster)
Pratyush Choudhury|2023-08-04 12:09:16|Could you elaborate it a little bit more?
Dev Aggarwal|2023-08-04 12:10:00|Well you get so many parallel requests that you need an insane amount of parallel gpus, and then for autoscaling that you run into the problem of disk bandwidth and machine spin up times
Pratyush Choudhury|2023-08-04 12:10:35|Why would I need parallel GPUs for all of these parallel requests?
Dev Aggarwal|2023-08-04 12:10:36|If the load you get is distributed evenly throught the day its fine, but I’ve never seen a day where the usage is like that
Abhinav Verma Longshot.ai|2023-08-04 12:10:43|I can shed light on 1. They have data since 2020 from tools using them
Dev Aggarwal|2023-08-04 12:11:35|Parallel as in multiple? You get 1000 people pressing submit button, you need 1000x gpus to service them in reasonable time. But if the next minute you get like 100 requests, you have 900 extra gpus running
Dev Aggarwal|2023-08-04 12:12:28|What we should be thinking about is actually value per interaction - if the value of a single response is super high to then end user, then you get very good economy
Sandeep Srinivasa RedCarpetup|2023-08-04 12:16:16|is anyone here using HyDE style prompts for semantic search usecases ?  wanted to know if hyde supports chatbot style (with history). Given how hyde works, it's been a bit tricky to get the history part to work.
Anshuman Pandey|2023-08-04 13:34:02|OML 😂 https://engineering.atspotify.com/2023/08/coming-soon-confidence-an-experimentation-platform-from-spotify
ashish Acgt01 Twitter|2023-08-04 13:44:11|would love to hear from the experimentation/ab testing OG, and VWO founder , [PHONE]
Nirant|2023-08-04 14:04:37|Yeah, I tried for a bit as well, didn't find it useful enough -- too slow for IR tbh
Pratik Bhavasar|2023-08-04 14:05:01|Also try “China loves South China Sea”
Nirant|2023-08-04 14:07:12|Tip: ~70% of this group uses WhatsApp on phones, send messages which fit in one screen.
~ Nayan Shah|2023-08-04 14:07:51|Noted 🙌
Nirant|2023-08-04 14:08:01|Maybe send a link to a Gist/Pastebin? ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-08-04 14:09:56|I think Gist would be easier to explain prompt changes needed here as well, given this chat here does not support markdown syntaxt etc
~ Nayan Shah|2023-08-04 14:10:35|I have my prompt (https://pastebin.com/7EU414sh) like this and I want gpt to give consistent results, and with this, I am able to get it in the format as well, but the results of intent do not look good, had some questions if anyone has exp owith this  1> should i add instructions in the system role and not seperate user role 2> and is GPT will bne able to follow this instructions properly form the looks of it sometime it does sometime not, what are your recommendations on this ... as i want to do this in one call only 🙈
~ Nayan Shah|2023-08-04 14:14:56|Gist link : https://gist.github.com/snayan06/997251ead080db3426e8d084e960731e pls feel free to add suggestions
jyotirmayjk Hackathon|2023-08-04 14:16:14|I can see that there are few topics needed for classification  Probably try giving a few shot classification examples ?
Abhishek Mishra|2023-08-04 14:22:31|For such scenarios, one might use vLLM + Ray Serve to optimise serving more customers and not necessarily lead to requiring as many GPUs as customer requests.  https://www.anyscale.com/blog/continuous-batching-llm-inference
Abhinav Verma Longshot.ai|2023-08-04 14:23:35|you can check the comments. have pasted a few changes
Dev Aggarwal|2023-08-04 14:23:57|Yeah, its “1000x”, where x is determined both on batching and how many gpus you need per model instance
Paras Chopra Wingify|2023-08-04 14:30:16|Not sure why they’re getting into this as a managed service   But more experimentation culture is good for the world
Abhinav Verma Longshot.ai|2023-08-04 14:37:08|this should work with turbo 16k as well now
Soumyadeep Mukherjee|2023-08-04 15:37:14|I think what you are saying is right at low to medium scale and not as much at openai scale.  At openai scale, its often less of a autoscaling problem since 70-80% of their GPU would not be pay per use but reserved for them. It looks more of a scheduling problem i.e. I have 100 GPUs, am I able to spread my requests properly understanding the users intent better.
ashish Acgt01 Twitter|2023-08-04 15:54:47|Just to add, my gues is openai works closely with azure on the inference infrastructure.  And azure has a decade or more of experience on  handing internet scale workloads , including hardware accelerators( look up doug Berger at MSR [0] ),  to speed up ml workloads.  So they have lots of help from azure in running the inference (& training) infra  0. https://www.microsoft.com/en-us/research/people/dburger/ ‎<This message was edited>
ashish Acgt01 Twitter|2023-08-04 16:03:05|PSA : hasgeek delhi meet-up is starting soon live on YouTube   https://www.youtube.com/live/B8d7ypgpqYk?feature=share
~ Sid|2023-08-04 16:03:50|yeah sadly it is online only now, I'm in the zoom conference.
Dev Aggarwal|2023-08-04 16:07:45|I agree on this, but it still doesn’t make them a profit. The argument was that they have such a big scale and they are able to spread out the requests that puts them in a better position to make profit, but I don’t think that’s the case unless you solve for the end user value per interaction
Abhishek Mishra|2023-08-04 16:21:43|Heard some people got multimodal GPT4 access in alpha version.
Abhishek Mishra|2023-08-04 16:21:57|Anybody here who can drop a glimpse of that alpha here?
Soumyadeep Mukherjee|2023-08-04 16:23:15|On profitability , I think the underlying assumption that profitability needs to be achieved at unique request level for openai seems incorrect to me.   It is more likely to be a mix of tiers .
Amit Bhor|2023-08-04 16:47:45|Openai does have the best GPU utilisation and can be considered as an advantage. It has been shown in all cloud providers that multi user scale smoothens the peak request per sec. This will always be more cost effective due to batching and predictable provisioning of GPUs
Nirant|2023-08-04 17:24:21|Best suited for AI & Policy perhaps?
Shimanta Generative AI|2023-08-04 18:34:52|https://twitter.com/mf_foom/status/1687219083761385475?s=46&t=WT1iAtjftW-5_e62F8FZTg  This looks interesting, however I’m not able to fully understand it. Can someone please explain 🙏🏼
Ojasvi Yadav|2023-08-04 18:37:11|Lovely tribute to a lesser known rapper, died in 2019, MF Doom.
Ojasvi Yadav|2023-08-04 18:37:47|As for the technical implications, seems like he's demonstrating the classic word2vec capabilities that we had in 2015
Atik Shaikh|2023-08-04 18:38:29|Sources ?
Ojasvi Yadav|2023-08-04 18:39:13|But that work in 2015 was done using  a raw embeddings approach, word2vec. They were able to demonstrate spatial reasoning to words.
Ojasvi Yadav|2023-08-04 18:39:44|This person is doing the same, but on embeddings from a model whose weights nobody outside of OpenAI has access to.
Chaitanya A GenAI|2023-08-04 18:40:06|"word embeddings follow semantic arithmetics of sorts, if you take the embeddings of each of the following words and perform the mathematical operation over em, you'll get a vector thats very close to the embedding of the word ""queen""  king - male + female"
Chaitanya A GenAI|2023-08-04 18:40:44|was demonstrated in the word2vec paper as ojasvi mentioned
Ojasvi Yadav|2023-08-04 18:41:15|I could be wrong about the year, have a feeling that word2vec came out before 2015
Chaitanya A GenAI|2023-08-04 18:41:36|mikolov et al 2013
Shimanta Generative AI|2023-08-04 18:41:58|Thanks folks
~ Srijan Saxena 😎|2023-08-04 18:44:51|Yeah. A more intuitive way of saying it is basically king - male = Queen - female. That way just helped me understand better
Shimanta Generative AI|2023-08-04 18:46:48|Can this technique be expanded to images?
Ojasvi Yadav|2023-08-04 18:47:18|Why not
Ojasvi Yadav|2023-08-04 18:47:26|but for what purpose exactly?
Chaitanya A GenAI|2023-08-04 18:48:00|one example where something similar has been done is style transfer https://paperswithcode.com/task/style-transfer#:~:text=Style%20Transfer%20is%20a%20technique,the%20style%20of%20another%20image.
Shimanta Generative AI|2023-08-04 18:49:25|I was thinking something on similar lines. Currently in playground . ai, we can create mask on a certain portion of the image, and prompt to make it different or remove it. Is that the same thing happening?
Shimanta Generative AI|2023-08-04 18:49:41|Playground ai is an example
~ Srijan Saxena 😎|2023-08-04 18:50:44|Andrew Ng's last few videos in his NLP course have explained this properly in case you are interested
~ Srijan Saxena 😎|2023-08-04 18:50:45|Style transfer and stuff as well iirc
Shimanta Generative AI|2023-08-04 18:51:00|I am learning new things today, thanks
~ Srijan Saxena 😎|2023-08-04 18:51:03|I was referring wrt this
Nirant|2023-08-04 18:51:10|What are some good libs to dedup small (~100G) text datasets? Preferably with Python bindings, but Rust crates will do as well.  Cc [PHONE] [PHONE]  would you happen to have good starting points for me to look?
Amit Bhor|2023-08-04 18:55:58|A bit more interesting. He's showing this semantic algebra for full sentence embeddings with a embedding -> sentence predictor
Abhishek Mishra|2023-08-04 19:01:18|Saw the multi modal GPT4 screenshot on a discord
~ Rahul Bansal|2023-08-04 19:02:58|What can be the usage?
~ Ramanathan Murugappan|2023-08-04 19:29:32|How to pretrain a model from the scratch any smaller example any guidance or any example resources to look into ?
~ Nayan Shah|2023-08-04 19:31:08|we are trying it out , we tried just KNN / FTS and now , we are checking hyde
~ Nayan Shah|2023-08-04 19:32:24|our IR is made of , KNN and FTS doc with sqlite chroma db , and then we have rrf on top of it , with KNN given higher priority , untill now it was working like a charm .
Nirant|2023-08-04 19:34:05|FTS? What are you combining in RRF? Approx NN and ... ?
~ Soham|2023-08-04 19:35:07|Hey Folks, has anyone tinkered in the field on Indian Classical Music? Was working on a college project on classification and generation on Indian Classical Ragas
Sumod K Mohan|2023-08-04 19:36:02|Hit me up, have spend some time on this. Not very deeply, would be happy to explore. ‎<This message was edited>
~ Nayan Shah|2023-08-04 19:36:56|sqlite has its own fts index with bm25 , based on our exp in semantic search we have noticed that only relying on the KNN ( now with openai embedding u can rely upto the point ) but sometimes when queries dont have much context its better , its kind of hybrid IR .   https://www.sqlite.org/fts5.html
Nirant|2023-08-04 19:38:20|For wider audience: RRF is Reciprocal Rank Fusion — this allows you to use multiple methods to rank docs in parallel, and then combine.   The simplified intuition is that if a doc is 1st in one method and 5th in another, than 1/1 & 1/5 (RR) can be used to get a combined rank really fast.
~ Nayan Shah|2023-08-04 19:38:27|but yeah this we are trying out only , we have not found more cases where conbining did actually helped , but doing this , and after that rerank it with cross encoder is theoratically said to give better results in diff kind of domains ...
~ Siddish|2023-08-04 19:38:33|haven’t used personally but remember some discussion in carperAI community  https://github.com/bigcode-project/bigcode-dataset/tree/main/near_deduplication https://github.com/google-research/deduplicate-text-datasets  are they relevant to what you wanted?
Nirant|2023-08-04 19:38:48|TIL Full Text Search is called FTS 🙈
~ Nayan Shah|2023-08-04 19:39:05|yeah 🙈
~ Nayan Shah|2023-08-04 19:39:46|was just wanted to share the approach and get some more idea /validation 🙈
Nirant|2023-08-04 19:40:48|I've checked this. This has a hard dependency that your dataset be a HF dataset. And the Google work does not have a Rust crate :'(
Rajaswa Patil|2023-08-04 19:59:19|Hey folks, does anyone know if there are any empirical results on how robust the OpenAI function calling thing is? Or anything equivalent with other models in some research paper?
Rajaswa Patil|2023-08-04 19:59:59|From both syntax (parses successfully) and semantics (generates the correct call/arguments) pov?
Nirant|2023-08-04 20:02:17|I did a benchmark on my own, and with some prompt engineering was able to reduce errors to 7 in 1000 for a small use case. I am inclined to believe it's approx 4/5 right.
Rajaswa Patil|2023-08-04 20:03:06|Interesting. Was this on a high temperature setting, or a low one?
Nirant|2023-08-04 20:03:06|It's not consistent though i.e. same input can result in different outputs when calling the LLM again with same params
~ Jaswanth|2023-08-04 20:06:31|here is a whole discussion in carperAI group in discord, you can go through this, you can find relevent info https://discord.com/channels/981279233835958313/1062469904193826926
ashish Acgt01 Twitter|2023-08-04 20:12:39|Is this a bug or a feature ?🤔 ( Assuming model weights remain the same and OpenAI is not doing any (periodic ,batched)  real time fine tuning )
Amal David Futuryze|2023-08-04 20:17:20|Anyone here who has finetuned Falcon or Llama2 for specific usecase? Are there any documented steps for data preparation if it's just scraped web content  https://huggingface.co/blog/falcon#fine-tuning-with-peft Following this for now but this dataset is in Q&A format so wanted to validate what preprocessing is needed for web content
ashish Acgt01 Twitter|2023-08-04 20:21:39|Pre LLM work but my accquintance Sankalp Gulati worked on raga recognition for his phd iirc :  http://compmusic.upf.edu/node/281  p.s. dm me if you would like an introduction to Sankalp  http://labrosa.ee.columbia.edu/hamr_ismir2015/proceedings/doku.php?id=ragawise
ashish Acgt01 Twitter|2023-08-04 20:22:36|A 2022 paper while I searched for sankalp's 2015 work :  https://www.sciencedirect.com/science/article/pii/S2772941922000084
~ Haider Ali Khan|2023-08-04 20:41:13|‎You removed ~ Haider Ali Khan
Shan|2023-08-04 20:43:52|Any model which can generate commentary on a chart? Eg input a stock chart and it will comment on the price movement? (Not my exact use case but close)
Nirant|2023-08-04 20:45:42|chart → deplot → table → + prompt asking for comments → GPT4
Rajaswa Patil|2023-08-04 20:52:49|+1
Rajaswa Patil|2023-08-04 20:53:54|And you can also define a very simple DSL if you want to build a querying functionality on it. Most 2D charts/plots can be parsed as a single table, with one independent variable. A small DSL can actually enable robust querying with interpretable programs.
Atik Shaikh|2023-08-04 20:55:15|Interesting
Rajaswa Patil|2023-08-04 20:56:15|https://aclanthology.org/2023.findings-eacl.189/  We had a paper on this at EACL this year. My ex-team at TCS Research still works on it. Can help you connect with them!
~ Vinay|2023-08-04 21:43:05|Hi folks, if someone's interested in short-term consulting gig for a problem in B2B Sales Intel domain using RAG, please DM.  Context: Extract insights across deal data (structured+unstructured) to improve forecasting accuracy (VP Sale's no 1 problem).
Dev Aggarwal|2023-08-04 21:51:13|Yeah, just curious: how would you draw this correlation between cost per request vs # of requests per day?
Soumyadeep Mukherjee|2023-08-04 21:58:41|Technically it depends on what Sam sir thinks what he is in the business of :P  I feel it will be a loss making at unit request level for requests from mass scale consumers in near term but can earn far more from APIs and integrations with other products which makes its B2C play mostly a top of the funnel.
Dr. Pratik Desai KissanGPT|2023-08-04 22:01:02|2013
Ojasvi Yadav|2023-08-04 22:19:38|Yes [PHONE] corrected me as well 😊
Ojasvi Yadav|2023-08-04 22:21:08|Gotta love how I got corrected by two other researchers also in this group about an year when a technique came out
Ojasvi Yadav|2023-08-04 22:22:06|If someone else also remembers authors and publication year for no valid reason I know I'm speaking with a fellow serious researcher ♥️
Ojasvi Yadav|2023-08-04 22:23:58|*authors name
Dr. Pratik Desai KissanGPT|2023-08-04 22:24:43|Was working with NLTK and when word2vec came out, it looked promising, however it was signed off as a tech just like knowledge graphs in later years, now they are all coming back.
Dr. Pratik Desai KissanGPT|2023-08-04 22:25:34|We are living in unprecedented times with everything going around
Ojasvi Yadav|2023-08-04 22:31:00|Studying the progression from ntlk to word2vec to Elmo is just like a movie.        First successor Solved for no semantic meaning, subsequent successor Solved for context. Read each paper one after the other and it's a proper story.  General premise of letting models process text sequentially also made no sense now looking back. But again, it's so easy to say that looking back.
Nirant|2023-08-04 22:54:48|Heyyy, don't forget ULMFiT
Arvind N Generative AI Group|2023-08-04 22:57:32|2017 fastai batch feels like yesterday....wikitext103 and IMDb sentiment sota... amazing times!
Ojasvi Yadav|2023-08-04 22:58:26|On Friday nights we do nostalgia posting
Ojasvi Yadav|2023-08-04 22:58:36|Cool kids know why it sucks
Dr. Pratik Desai KissanGPT|2023-08-04 23:00:18|In 2012, I did real-time sentiment on Twitter firehouse and live plotting, and launched an iOS app. That was before it came to nltk. Those were the days. Feeling nostalgic. ‎<This message was edited>
Ojasvi Yadav|2023-08-04 23:01:12|If we don't have anything else to talk about I'm sure many people would love to see a demo (images and/or videos)
Arvind N Generative AI Group|2023-08-04 23:01:30|Same here
Dr. Pratik Desai KissanGPT|2023-08-04 23:03:25|https://twitter.com/intements?s=21&t=HZS4Ar4p8RMA3Tj10LCWEw
Dr. Pratik Desai KissanGPT|2023-08-04 23:03:45|Not many traces are left but this account we didn’t remove
Dr. Pratik Desai KissanGPT|2023-08-04 23:04:35|It was called Intements = Internet Sentiments, young blood trying to conquer the world, before Twitter decides to turn off Firehose.
Dr. Pratik Desai KissanGPT|2023-08-04 23:05:16|Started during my PhD internship so UI was crap but never seen any app like this even after 11 years ‎[8/4/23, 23:06:37] Ojasvi Yadav: ‎image omitted
Ojasvi Yadav|2023-08-04 23:06:48|Just thinking that I was in 9th grade when you made this 🥲
Dr. Pratik Desai KissanGPT|2023-08-04 23:07:20|Another crappy promo video by PhD student https://youtu.be/FyZPIN0YFro
Ojasvi Yadav|2023-08-04 23:07:49|Just thinking this at such a massive scale in 2012......
Ojasvi Yadav|2023-08-04 23:07:53|True
Ojasvi Yadav|2023-08-04 23:08:13|Nothing this interactive and using sentiment analysis at this scale has really come out
Dr. Pratik Desai KissanGPT|2023-08-04 23:09:06|It was also quick though. You type a trend and it will start popping results. World Cup, elections, global event were fun to track.
Ojasvi Yadav|2023-08-04 23:10:20|Were you able to affect something big with it? Like because of using your app did you see some people doing weird or different things that they wouldn't otherwise
Aashay Sachdeva MPL Data Scientist|2023-08-04 23:11:20|In today’s world something like with sentiment analysis in real time would be a war machine
Ojasvi Yadav|2023-08-04 23:12:09|I am fairly confident that if you let people see what the world is feeling, you can do something with that power of displaying 'perception' that you gained
Dr. Pratik Desai KissanGPT|2023-08-04 23:13:09|We weren’t able to get attention of anyone somehow. They didn’t realize the power of this type of technology until 2016 US elections. So the app slowly died. Curse of being too early.
Dr. Pratik Desai KissanGPT|2023-08-04 23:19:12|Another too early story, In 2019, as part of Titodi’s first project, I mapped, polygonized and plotted 1.2 crore farm plots of Gujarat using CV and ML, with goal to implement Zestimates. I was told not to mess with land price, also no PMF so I turned off the servers. Now they are giving it to some FAANG to do so for whole nation, and ask me to guide. I saw them humble finger and moved on with KissanAI.
~ Deven|2023-08-04 23:25:46|go check Twitter marketing partners. you will find 100s of companies doing live tweets analysis  to build audience data for ads. A lot of them do real-time tweets analysis.
Ojasvi Yadav|2023-08-04 23:26:37|Their loss
Ojasvi Yadav|2023-08-04 23:28:17|I feel this is a part of the reason why we have issues with going big on the world stage
Ojasvi Yadav|2023-08-04 23:28:40|Governments incentives are not aligned with those of creators
Dr. Pratik Desai KissanGPT|2023-08-04 23:28:41|I know many do that now. Our research group team built Bloomberg extension to go inside in their terminal. Every political party may have their control rooms. But most realize the power after 2016. Now an intern can do sentiment analysis. There is no Alpha. ‎<This message was edited>
Ojasvi Yadav|2023-08-04 23:28:49|And researchers
Alok Bishoyi|2023-08-04 23:30:52|there's a bunch of customer feedback tools as well that do realtime analytics on streaming data.   Enterpret stands out among those having Indian founders
Dr. Pratik Desai KissanGPT|2023-08-04 23:32:07|Deep rooted corruption won't let you disrupt any domain. Only slow progress is allowed, so Babus can comprehend what is going on and figure out next corruption strategies. /EoR
Ojasvi Yadav|2023-08-04 23:34:13|💯
~ Mohit|2023-08-04 23:36:53|Wow. Made me nostalgic as well. I started my journey in ML doing audio and speech analysis back in 2008. Still remember the days when the WER (word error rates) would be ~20% and ASR was a distant dream. We were doing stuff with HMMs and GMMs and pocket sphinx. And then came DL and wiped the floor.
~ Mohit|2023-08-04 23:38:19|Made myself an app in Android for audio based life logging at the time
~ Mohit|2023-08-04 23:38:21|Fun times
Dr. Pratik Desai KissanGPT|2023-08-04 23:40:07|MS spent 20B for Nuance 🤣
Dr. Pratik Desai KissanGPT|2023-08-04 23:40:35|Now better models are open sourced
~ Mohit|2023-08-04 23:40:35|Yep I remember that!
~ Mohit|2023-08-04 23:41:02|I would say today’s worst model might be better than those ones!
Dr. Pratik Desai KissanGPT|2023-08-04 23:41:10|People on Discord are cloning Abhijit voice for free
~ Mohit|2023-08-04 23:41:56|If anyone is interested, here’s a link to that old old paper of mine   https://scholar.google.com/citations?view_op=view_citation&hl=en&user=tT3DFK0AAAAJ&citation_for_view=tT3DFK0AAAAJ:u5HHmVD_uO8C
~ Adithya|2023-08-04 23:44:19|What do you think about the current transformer hype?
~ Mohit|2023-08-04 23:44:24|I happened to witness Innovator’s dilemma happening in real time. Was working with Intel and Xerox PARC back then and they used to be so sceptical of DL. Explains why they have lost the race today
Dr. Pratik Desai KissanGPT|2023-08-04 23:44:40|From the Abstract, I can imagine how much PIA the WER could have been in 2012. 🤣
Dr. Pratik Desai KissanGPT|2023-08-04 23:47:14|It's not hype. It is respawning research that were promising but died due to one missing piece. It's not a leap frog, it's pole vault in tech.
~ Mohit|2023-08-04 23:47:43|Haha
Dr. Pratik Desai KissanGPT|2023-08-04 23:49:07|By the way, check out this repo https://github.com/yacineMTB/talk  You will find it interesting based on your prior work.
~ Mohit|2023-08-04 23:53:06|Thanks for sharing. Sounds like a good weekend hack
Ojasvi Yadav|2023-08-05 00:13:07|I spoke to [PHONE] Sir about this as well. That RLHF came out in 2019, that's when we also had open-sourced models that could give GPT3 a run for its money.   Anyone, literally anyone could've built chatgpt in 2020 or 2021. But it took 2 years extra for openAI themselves to figure the next step out.  That is something you have to admire. I borderline hate myself for not being able to see that which is why I respect it so much.
Ojasvi Yadav|2023-08-05 00:13:32|Recent transformer hype is well deserved character arc of OpenAI and the talented people that work there
Ojasvi Yadav|2023-08-05 00:15:15|We ignored this for 3 years
Ojasvi Yadav|2023-08-05 00:15:41|But they built it
Dr. Pratik Desai KissanGPT|2023-08-05 00:21:23|Google had it under the nose. We have been using GPT3 since 2021, and built few applications using that, (mostly building knowledge base which is helping us now), but got blind sided by a chat application to be the hype.
Dr. Pratik Desai KissanGPT|2023-08-05 00:23:04|A Chat bot 🤷‍♂️
Arvind N Generative AI Group|2023-08-05 00:49:28|How to wreck a nice beach.
~ Sid|2023-08-05 09:50:51|guys, in your opinion, for building RAG chatbot, which framework is better, Langchain or Llama index or any other
~ Adithya|2023-08-05 10:07:13|I can't believe i used to use wolfram alpha all through college and never thought about chat gpt
Anshul Bhide Replit|2023-08-05 10:26:38|Do you think it’s because chat (as rudimentary as it may be) exposed this technology for the first time to non-devs who could appreciate its power directly for the first time?
Nirant|2023-08-05 10:28:34|Yes, chat did make a difference. That said, Google didn't make the text-davinci-003 either — which is what every ML Engineer would've considered doing after seeing text-davinci-002/003
"~ $@| @$w@+h R•¥@|"|2023-08-05 10:33:37|Llama index
~ Soham|2023-08-05 10:41:49|Dayum 2008. I bet i was not even able to spell DL in 2008. I was what 7 years old!
~ Mohit|2023-08-05 10:45:54|And now, we can't keep with the acronyms!
~ Sid|2023-08-05 12:31:45|any suggestions for streamlit alternative which can run on AWS lambda?
Azhan Mohammed Generative AI WhatsApp Group|2023-08-05 12:35:25|Gradio is the most famous one.  Apart from that you could also use Plotly dash (best for plotting graphs) and Anvil (plotly is built-in)
ashish Acgt01 Twitter|2023-08-05 12:54:18|Came across something on hn today which traces the non determinism to MoE and batched inference   https://152334h.github.io/blog/non-determinism-in-gpt-4/  https://news.ycombinator.com/item?id=37006224  Cc :[PHONE]  [PHONE]  [PHONE]  [PHONE]
Abhishek Mishra|2023-08-05 13:15:45|"There are many angles for possible non-deterministic behaviour. I'll not judge the ones already discussed but add other angles as well * t=0 is almost never true, it's always a epsilon value above 0 that's used - that can be fixed as well but it won't lead to absolute high probability choice. * The ""leaked"" architecture discussed that the inference speeds are being optimised by having a smaller model generate the answer and the bigger model accepting or rejecting it for a batch prediction. If this is true, acceptance criteria from the bigger model would lead to a lot of inconsistency in true deterministic behaviour. * Such models work best with determined blacklists due to RLHF (what the model shouldn't do) compared to what the model should always do (as you want it to pick one option amongst the best ones and not memorize and vomit the training data)."
Abhishek Mishra|2023-08-05 13:17:09|Overall, these things remain because it's not really openAI's concern how a little bit of non-determinism creeps in the output as long as they can maintain deterministic blacklists with RLHF.
ashish Acgt01 Twitter|2023-08-05 13:21:38|"If i understand deterministic blacklists : it's a catch all term for all the stuff the model should *not do*  - not answer controversial political or religious or ethnic queries - not give definitive answers to medical or legal questions  But how is it achieved through RLHF - which at a high level is a human rating pairs of generated outputs, saying which is more ""appealing/pleasing to a human"", no ?"
Abhishek Mishra|2023-08-05 13:23:19|It's not limited to human preference. You can put a heavy penalty for following or not following a chain of thought thus enforcing behavioural aspects as well.
ashish Acgt01 Twitter|2023-08-05 13:30:32|"found some openai forum links [0,1,2]  from https://community.openai.com/t/a-question-on-determinism/8185/2  ""boris OpenAI Staff  There’s inherent non determinism in GPU calculations around floating point operations - the differences in log probabilities are tiny, but when there’s a small difference between the top two likely tokens, then a different token might be chosen every now and then leading to different results""  ""There are speed tradeoffs, and in order to make the endpoints fast GPUs are used, which do parallel (non deterministic) calculations. Any modern gpu neural net calculations will be subject to these.  Very simplified example to illustrate the point: a * b * c can be calculated either as (ab) c, or a(bc), but tiny differences can occur when performing floating point operations with the last few significant digits,leading to a very slightly different result. Sometimes these tiny differences can compound and be amplified within a network with argmax on the next token, if the logprobs are very close.""  0. https://community.openai.com/t/why-is-gpt-4-giving-different-answers-with-same-prompt-temperature-0/143513  1. https://community.openai.com/t/observing-discrepancy-in-completions-with-temperature-0/73380  2. https://community.openai.com/t/a-question-on-determinism/8185"
Abhinav Verma Longshot.ai|2023-08-05 13:49:03|Temperature is what is normally used to divide the logits that you get from the network. The temperature is never really zero else you'll get a did divide by zero error. There is a minor epsilon value that is added to this
Abhinav Verma Longshot.ai|2023-08-05 13:50:47|a naive implementation of temperature which is normally used in LMs
Amit Bhor|2023-08-05 14:12:16|Both topP and Temp are probabilistic controls. Interesting that openai never gave the TopK=1 parameter.
Abhinav Verma Longshot.ai|2023-08-05 14:13:05|you don't need both top_p and topK, when both are there,you're advised to use just one
Amit Bhor|2023-08-05 14:15:27|Yes but topK = 1 is the most deterministic ie always use the highest prob prediction. TopP = 0 and temp=0 are undefined as others have pointed out
Abhinav Verma Longshot.ai|2023-08-05 14:16:29|top_K as per my understanding is selecting the top logits . Top p is selecting the top logits till their probablities are the sum of what you've specified.
Abhinav Verma Longshot.ai|2023-08-05 14:16:52|top_k is some number like 64,128 because you are selecting that many logits
Abhinav Verma Longshot.ai|2023-08-05 14:17:11|this is also how cohere and nlpcloud have been treating the top K param
Abhinav Verma Longshot.ai|2023-08-05 14:22:00|openai is anyways doing scaling in temperature. actual values of temp can go higher than 1 , but we're restricted in a 0 to 1 scale
Amit Bhor|2023-08-05 14:23:01|Yes, some apply this to logits and some apply it to probabilities after softmax. TopK=1 is the most deterministic output of an LLM. IMO
Abhinav Verma Longshot.ai|2023-08-05 14:24:31|then I think we're using top_p and top_k interchangeably. Basically there are 2 params One which takes all logits which are taken till the sum of their probs are the number we have specified like 0.9 etc and one is just selecting the top logits like 64,128 which is take the top N logits
Abhinav Verma Longshot.ai|2023-08-05 14:25:06|But openai is also doing some scaling at the back , so you can't be completely sure how they're treating all the params
Abhinav Verma Longshot.ai|2023-08-05 14:25:16|but this logic holds for normal causal LMs
Amit Bhor|2023-08-05 14:27:06|I think they can be used interchangeably in most instances other than the instance of TopK=1 (highest prob token only). This is undefined in the topP definition but can be approximately with a very low topP
Abhinav Verma Longshot.ai|2023-08-05 14:27:33|but you're not generating just 1 token right
Amit Bhor|2023-08-05 14:28:00|?? Yes it's 1 token at a time
Abhinav Verma Longshot.ai|2023-08-05 14:28:55|you are a specifying a max_tokens of higher than that right. What you're seeing in playground is the result being streamed but the inference is already done
Amit Bhor|2023-08-05 14:30:11|Autoregressive models do all inference 1 token at a time
Abhinav Verma Longshot.ai|2023-08-05 14:32:03|yeah that's true. But what's weird now is I'm looking at the cohere dashboard and the top p seems to have gone and only top k is there
Abhinav Verma Longshot.ai|2023-08-05 14:33:33|topk=1 gives bad outputs.
Abhinav Verma Longshot.ai|2023-08-05 14:39:20|yes correct, my bad here. But topK=1 is more like greedy sampling and you get bad outputs. So I guess its a mixture of having some randomness while maintaining quality of outputs
Amit Bhor|2023-08-05 14:41:20|"Yes, deterministic and ""good"" are often a tradeoff"
Sandeep Srinivasa RedCarpetup|2023-08-05 14:54:18|https://152334h.github.io/blog/non-determinism-in-gpt-4/  who here is finetuning MoE on top of Llama2 ?
Amir Nagri|2023-08-05 15:26:23|any real-world application or feedback on OpenAI fine-tuning using APIs?  https://platform.openai.com/docs/api-reference/fine-tunes
Rohit Aggarwal|2023-08-05 15:36:01|Did a lot of content generation using fine-tuned models. Works well for specific use cases when we want to constrain outputs, use a specific tone, want the model to remember our style etc.
Krishna Ntkris|2023-08-05 15:36:35|Superior to RAG?
Rohit Aggarwal|2023-08-05 15:37:34|Wouldn’t use it to replace RAG. Fine-tuning imo is more for style transfer than factual stuff. Fine-tunes with RAG will also work well
Rohit Aggarwal|2023-08-05 15:38:01|I’m desperately waiting to try fine-tunes on the chat based models now
Krishna Ntkris|2023-08-05 15:38:42|To rephrase, did you find that fine tuning + RAG was superior to RAG alone?
Krishna Ntkris|2023-08-05 15:39:02|Did you consider fine tuning open source?
Rohit Aggarwal|2023-08-05 15:39:41|Haven’t tried, but should be.
Rohit Aggarwal|2023-08-05 15:40:13|Have to try it with llama2 now. Before this, I really haven’t felt that the underlying model was capable enough
Krishna Ntkris|2023-08-05 15:46:39|Yes agree
Abhinav Verma Longshot.ai|2023-08-05 15:52:10|We had this as a feature in longshot last year. It was good if you wanted to write in specific niches and it responds decently well to tuning on instructions as well. But it wasn't as useful as RAG for us
Krishna Ntkris|2023-08-05 15:53:47|Did you try both? RAG using a fine tuned mode?
Abhinav Verma Longshot.ai|2023-08-05 15:55:13|Yes. It doesn't give good results unless you tune it for that scenario. But then issue is that the finetuned model costs more than turbo for inference and the results for rag aren't great and you're also restricted to 2k context length
~ Shanthi Vardhan|2023-08-05 15:59:53|We had benchmarked domain fitted models like train models on domain data and they outperform traditional models. For example, we trained a model on domain data using sentence transformers SetFit and they have considerable accuracy compared to vanila gpt models. The usecase was RAG...
Abhinav Verma Longshot.ai|2023-08-05 16:01:59|Anyways openai is removing the completion models next year, so those models will cease to be of help also. They're like removing them completely
Krishna Ntkris|2023-08-05 16:05:56|Which domain?
~ Shanthi Vardhan|2023-08-05 16:12:02|Think of like product manuals of a large customer number of manuals is >20K
Amir Nagri|2023-08-05 16:39:02|Nice, a write-up/blog on your experience will be helpful for community 🙏
Chaitanya A GenAI|2023-08-05 16:40:50|thats true for closed sourced LLMs, and specifically gpt, because of how they allow you to finetune the models; my hunch is that openai only allows a very small number of parameters to change as a result of finetuning which further leads to the behaviour youve observed - this makes sense from a scalability perspective and has been noted in academic research on finetuning as well however, finetuning as long as it has existed has shown to teach LLMs factually; if you have more control over the finetuning process it would be feasible to achieve and thus, trying intricate experiments with open sourced models will allow you to finetune for factual accuracy/content
Nilesh Christopher|2023-08-05 17:48:37|‎Nilesh Christopher left
Paras Chopra Wingify|2023-08-05 19:07:32|Is anyone doing experiments in training multimodal LLMs on desktop screen actions directly  This would make it possible to execute arbitrary tasks even without an API
Chaitanya A GenAI|2023-08-05 19:26:38|i remember nirant was looking at it a while back? [PHONE]
C Chaitanya Nutanc|2023-08-05 20:37:49|https://www.rewind.ai/?
Nirant|2023-08-05 21:33:17|I worked for a company working on this in 2018, interesting space to be in. Relationship/inside sales, annotations, compliance — everything drives up the cost of data quite high. Slightly narrower problem of doing this for browser is a lot cleaner, and less brittle
Krishna Ntkris|2023-08-05 21:51:06|When you say cost of data, you mean processing the number of images because it’s based on screen capture?
Nirant|2023-08-05 22:14:19|Let's move this to DM? Quite off topic for main
Paras Chopra Wingify|2023-08-05 22:27:31|Isn’t it now actually tractable
~ Rahul Bansal|2023-08-05 22:29:11|What was the usecase? Were they automating stuff?
~ Sankalp Patidar|2023-08-05 22:53:08|Is anyone working on chatbot with web search Retrieval (with citation if possible). I am finding it difficult to get the most robust mechanism of getting the answer.  If anyone has any resources, feel free to share in DM as well. It would be a big help.
~ Adithya|2023-08-05 22:54:17|I found one for coders called phind
Atik Shaikh|2023-08-05 22:58:40|It’s free tier is literally unusable now due to cap of 10 usages for 24 hrs
Atik Shaikh|2023-08-05 22:58:41|Perplexity is quite popular in this space
~ Sankalp Patidar|2023-08-05 22:59:56|Yes definitely. We want to build a similar system. So I am looking for resources to help me build it
~ Adithya|2023-08-05 23:04:53|If you put your GitHub/email it says you can use gpt 4.  That is decent I would say quicker than Google search and clicking the right link for general coding stuff
Atik Shaikh|2023-08-05 23:07:45|Yes ik about it but 10 usages for 24 hrs ? I got better services which provide more GPT4 queries
Sandeep Srinivasa RedCarpetup|2023-08-06 01:38:41|has anyone here started using GTE-small for embedding (replacing openai embedding endpoint) ?  how has it been working out ?
~ Sid|2023-08-06 01:40:26|does anyone know how to pass multiple filters (with and/or) condition in Langchain retriever?
~ Sid|2023-08-06 01:42:55|i have read about it, biggest downside was it was restricted to 512 tokens, as compared to Ada's 4096/8192 tokens
Anshuman Pandey|2023-08-06 02:01:03|Anyone at the OutsideLLMs hackathon? ‎[8/6/23, 02:01:04] Anshuman Pandey: ‎image omitted
Abhinav Verma Longshot.ai|2023-08-06 02:24:24|So it is same as Cohere embeddings. I think 512 is decent enough. Do you have a link?
Dhruv Anand|2023-08-06 02:59:08|mteb.info
Dhruv Anand|2023-08-06 03:00:19|Lol there's a new one on top of the leaderboard. bge
Abhinav Verma Longshot.ai|2023-08-06 03:05:47|The context length should not be an issue. 512 tokens is more than enough. Need to have good chunking strategies
Sandeep Srinivasa RedCarpetup|2023-08-06 03:12:22|Other than fixed length chunking, anything else that has worked ?
Abhinav Verma Longshot.ai|2023-08-06 03:13:26|Also what info you put in chunks like Metadata associated with each chunk
Abhinav Verma Longshot.ai|2023-08-06 03:13:55|Like if you're chunking a blog. Title is a Metadata
~ Happy Chaudhury|2023-08-06 10:09:58|Q: i have convertes model deberta v2 to onnx format , I was assuming it will take less inference time in CPU after I convert to onnx but it's taking almost same, anything i should take care of to infer it Faster
Sandeep Srinivasa RedCarpetup|2023-08-06 11:11:02|https://onnxruntime.ai/docs/execution-providers/community-maintained/TVM-ExecutionProvider.html
~ Happy Chaudhury|2023-08-06 11:24:58|Have  you tried, I am curious like how much time it takes..even after this set up..
~ Happy Chaudhury|2023-08-06 11:25:33|I am running onnx model currently in CPU
Alok Bishoyi|2023-08-06 11:28:38|We had actually done a benchmark of all possible accelerators out there. TVM scored the highest performance( with lowest drop in accuracy) for CPU runtimes  You would ofc be better off using chipset specific accelerators ( snpe for qualcomm devices for eg that utilizes DSP ) if you know the target device has it
~ Happy Chaudhury|2023-08-06 11:33:58|Second part can please help me..I am using Ubuntu server with 56gb RAM
~ Happy Chaudhury|2023-08-06 11:34:40|Anything i will check before I try TVM
~ Sid|2023-08-06 11:50:13|what is the best way to compare different embeddings on own dataset? and best similarly for retrieving chunks?
Alok Bishoyi|2023-08-06 11:51:04|Sandeep gave you the exact thing you need. Try TVM directly
~ Nikhil|2023-08-06 12:35:20|What are some good ways to figure out semantic similarity between questions?  The following code https://pastebin.com/ZfyTabEs shows that two semantically separate questions have a very high cosine similarity but are entirely two different questions.  Will using some reranking (cohere) help?
Paras Chopra Wingify|2023-08-06 12:38:37|perhaps generate answers for it via LLMs and then compute their similarities
~ Nikhil|2023-08-06 12:39:57|I am trying to build a lightweight semantic caching logic so that I don't have to generate the response at all if the questions are very similar
~ Nikhil|2023-08-06 12:40:16|Just pick the response from the previous question's output
Paras Chopra Wingify|2023-08-06 12:40:20|"btw, ""high similarity"" is relative. you need to calibrate thresholds based on some test dataset as similarity is context dependent. i can argue questions are similar because both talk about same company, india and markets"
Paras Chopra Wingify|2023-08-06 12:41:09|generate once, and then see if responses are similar or not
Paras Chopra Wingify|2023-08-06 12:41:31|what i'm suggesting is to compute similarity b/w theoretical answers and not questions
~ Nikhil|2023-08-06 12:42:14|That still pushes me to hit the model APIs to get the answer. I am trying to void hitting the API altogether
~ Nikhil|2023-08-06 12:43:08|My use case is: I have a news article (contents will rarely change). If people are asking similar questions about the document, I would want to avoid hitting the API again.
~ Nikhil|2023-08-06 12:44:15|I have just started looking at GPTCache. From a very cursory glance, does not look very lightweight.
Abhinav Verma Longshot.ai|2023-08-06 12:46:03|Portkey is an enterprise solution of sorts.
Paras Chopra Wingify|2023-08-06 12:53:26|you might want to finetune a model on this usecase, and not use pretrained embeddings
Sandeep Srinivasa RedCarpetup|2023-08-06 12:53:36|be careful - gptcache only does a == check. https://github.com/zilliztech/GPTCache/blob/main/gptcache/similarity_evaluation/onnx.py#L76  we had to reimplement our own cache (will opensource in a month), cos whatever is out there was not good enough
Amit Bhor|2023-08-06 13:19:52|Interesting approach. Is there some basis for this? Wouldn't cos sim be equally good/bad on Qs and As  both?
~ Nikhil|2023-08-06 13:23:12|"Cohere rerank does a much better job of semantic similarity of questions  ``` co.rerank(""What were the challenges faced by Xiaomi in India that led to its decline in market share?"", [""What were the factors that contributed to Xiaomi's initial success in the Indian smartphone market?""], model='rerank-multilingual-v2.0')  [RerankResult<document['text']: What were the factors that contributed to Xiaomi's initial success in the Indian smartphone market?, index: 0, relevance_score: 0.05155819>] ```  A relevance_score closer to 1 means high relevance."
~ Nikhil|2023-08-06 13:23:42|The above snippet actually produces a very low score for the two strings
Sandeep Srinivasa RedCarpetup|2023-08-06 13:26:55|this is called tf-idf . easily done.. u dont need cohere for that. use TfidfVectorizer from sklearn if ur on python. if ur on java, then a muuuuuch nicer way is to use lucene. industrial grade.
~ Mohit|2023-08-06 13:31:47|This works well for cases where your vocabulary is limited or known before hand to a large extent. For news articles and the likes which include a lot of entities, an embedding based approach makes more sense.
Sandeep Srinivasa RedCarpetup|2023-08-06 13:32:59|embedding is not something magical. embedding is cosine distance of feature vectors.  tfidf is inverse term distance using tf feature vectors.
Sandeep Srinivasa RedCarpetup|2023-08-06 13:33:09|the most popular one right now is bm25
Dhruv Anand|2023-08-06 13:33:12|Why not just use a sentence transformers model?
Sandeep Srinivasa RedCarpetup|2023-08-06 13:33:58|u can very well plug-in tfidf instead of minilm or ada embeddings and get similar results in many cases
~ Mohit|2023-08-06 13:34:56|Absolutely agree. I just wanted to make the point that there are cases where non tf-idf embeddings, fasttext for example make more sense
Sandeep Srinivasa RedCarpetup|2023-08-06 13:35:16|not to my knowledge in text match cases
~ Mohit|2023-08-06 13:35:28|We don’t need an external api for simple similarity problems
Sandeep Srinivasa RedCarpetup|2023-08-06 13:35:41|if u need a similarity match between two strings without the cost of llm - u should be using tfidf/bm25
Sandeep Srinivasa RedCarpetup|2023-08-06 13:36:05|just fyi - google and all use okapi bm25 . so i would say it works pretty well
Sandeep Srinivasa RedCarpetup|2023-08-06 13:39:17|the reason that minilm/ada02 are more popular than tfidf/bm25 is cos of the size of the chunks. tfidf works great when u have large chunks. like an entire web page is a chunk. embeddings work great when chunks are smaller (like what we are doing right now).  this is directly proportional to the context size of LLM. in large context size models, my bet is that large chunk tf-idf/bm25 will be far more accurate than all these MTEB stuff.
Sandeep Srinivasa RedCarpetup|2023-08-06 13:39:50|we are forced to use these 384/512 chunk embeddings cos gpt runs out of context window.
Abhinav Verma Longshot.ai|2023-08-06 13:41:58|There's also cost of inference.
Sandeep Srinivasa RedCarpetup|2023-08-06 13:45:10|still an open question. all things remaining the same - are we going to see the cost of 100k size context api calls >>> 10 X (10k size context api calls) ?   i dont know. this will also depend on hardware and where nvidia takes us.
Abhinav Verma Longshot.ai|2023-08-06 13:46:21|My point on selecting smaller chunks is you also want to minimize your cost of inference. Not to mention transformers lose info if you provide too much inference context anyways
Paras Chopra Wingify|2023-08-06 14:20:01|HyDE
~ Anjineyulu|2023-08-06 14:33:56|May be we have to find a variant of cosine similarity like f(cos(x)) and estimate the parameters in a triplet loss style to get a similarity function
Abhinav Verma Longshot.ai|2023-08-06 14:36:36|using encoder-decoder models like bart-large-mnli model are actually pretty good here, but those models are heavy. Cross encoder models can help here as well that are trained on NLI tasks.
Abhinav Verma Longshot.ai|2023-08-06 14:37:36|You can then check for entailment, neutral or contradiction score
Abhinav Verma Longshot.ai|2023-08-06 14:45:03|Just thinking out loud here one possible approach for semantic caching can be - get similar questions using rank-bm25 - filter further for entailment using a model trained on NLI tasks  Of course the challenges here are storing and managing queries, regularly cleaning and updating them. For instance an answer for a question now, might change in a months time. Especially valid if you're doing serp stuff And then you need to take care of inference time increase by doing these methods and additional cost
Abhinav Verma Longshot.ai|2023-08-06 14:46:41|I don't think using an embedding model like ada02 will work here because of reasons like this. They are better for search , but not for similarity between 2 statements https://twitter.com/jobergum/status/1656201261308321792 however the above models can help here ‎<This message was edited>
Dhruv Anand|2023-08-06 14:54:26|Tfidf will be even worse for that then. It's an order unaware technique, and has zero ability to deal with vocabulary mismatch. But yes, it'll work great for caching large scale duplicate queries (the kind Google experiences)
Abhinav Verma Longshot.ai|2023-08-06 14:55:58|possible , you can maybe use an embedding model and then have a second filtration stage for entailment/contradiction of questions
Abhinav Verma Longshot.ai|2023-08-06 14:56:26|it will depend on costs at the end
~ Krishna|2023-08-06 16:39:24|What model would be best for intent recognition? I'm fine-tuning BERT. Is there a better option?
~ Maruti Agarwal|2023-08-06 17:39:30|Think of intent as a classification problem. You can give chatGPT the classes you want and ask it to pick a particular class from your text.
Rajaswa Patil|2023-08-06 17:57:06|If you are planning to deploy a fine-tuned model, then look into DeBERTa once.
~ Maruti Agarwal|2023-08-06 17:58:03|100%. BERT is expensive.
Dr. Ashith Generative AI WA Group|2023-08-06 18:14:30|What is the best approach to automating unit tests for a scripting language like powershell?
~ Ramanathan Murugappan|2023-08-06 18:21:17|What is the best model to fine tune documentation Q&A
~ Krishna|2023-08-06 18:23:11|Yup, i am planning to deploy a fine-tuned model since I want this as light and efficient as possible. This is for a conversational agent
Shimanta Generative AI|2023-08-06 18:36:13|Is it possible to first create the classes themselves, and then ask it simultaneously classify?
~ Maruti Agarwal|2023-08-06 18:39:19|Yep. In a single prompt.
Shimanta Generative AI|2023-08-06 18:41:03|What about when the data to classify is huge?
~ Maruti Agarwal|2023-08-06 18:43:07|Then you have to build a classifier. Bert or it’s derivative based. Or you may consider summarisations and then intent classsification
Shimanta Generative AI|2023-08-06 18:44:15|Got it, thanks 🙏🏼
ashish Acgt01 Twitter|2023-08-06 23:44:25|Thread on RLHF  https://twitter.com/sleepinyourhat/status/1687930341347180544?t=5qwOd8kS0qChBgutCYISag&s=08    Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback  https://arxiv.org/abs/2307.15217  Tweetorial : https://twitter.com/StephenLCasper/status/1686036515653361664?t=zkieMzpKrMiWX99KR0jGMA&s=19 ‎<This message was edited>
~ Arindam Barman|2023-08-07 10:00:57|Anyone knows how Bard is so fast? I am assuming they are doing some RAG style implementation for live data but curious if people know if they are using an alternate way?
Dev Aggarwal|2023-08-07 10:07:48|Fast TPUs + they’ve been running bert inside google search for years now
Swastik Banerjee|2023-08-07 10:11:11|I think I missed a little bit of context here, but isn’t the entire point of using embeddings over tf-idf is that embeddings capture semantic ‘context’ well, while algorithms like tf-idf/bm25 is just for lexical/keyword search?
Sumod K Mohan|2023-08-07 10:15:08|I agree with Dhruv quite a bit. I would also recommend sentence transformers, which considers the whole sentence as opposed to words independently (since you need high precision). One idea: See if addition of question vector with original/summary text (you can do weighted as well). This contextualizes the question, when questions are too short. Sort of like a poor man's query expansion.
Kaushik Bokka|2023-08-07 10:15:10|Google also have a Llama model optimized for TPUs.
~ Vik|2023-08-07 10:20:29|i've used sentence transofmers + allenai modsls with elastic search for years on 42papers for all kinds of stuff work great
~ Vik|2023-08-07 10:21:27|you can even tune them with setfit using only like 20 examples
Sandeep Srinivasa RedCarpetup|2023-08-07 10:31:17|"im not sure what semantic context is. generally, embeddings maps sentences & paragraphs to a 384/512 dimensional dense vector space. BM25/tfidf will not map a sentence. instead it will rank it.  so the retrieval mechanism for both differ. one is cosine distance, etc (which is where the argument for ""semantic context"" comes from) and the other is bag of words based."
Sandeep Srinivasa RedCarpetup|2023-08-07 10:32:37|ultimately - the difference is whether you want to pass a large chunk or small chunk to your LLM. cosine distance based search is always inferior.  google, yahoo, lucene , etc - all real world large scale searches - always use tfidf/bm25. it has beaten everything else consistently for last 20 years (embeddings are not a new algorithm).
Shashwat TDC|2023-08-07 10:48:12|[PHONE] do you also think tfidf works reliably bcz the other text2vec embedding based approach is fundamentally a probabilitstic one. Is it challenging to maintain the probability of success at the scale of google, yahoo?
Shashwat TDC|2023-08-07 10:49:35|If yes, are LLM apps really going to scale with non-deterministic step in the output generation? 💭
Sandeep Srinivasa RedCarpetup|2023-08-07 10:50:40|"this question has been asked for last 20 years. lucene/elasticsearch has a bunch of support built in for densevectors (embeddings). Every engineer when they start working with search, start doing all these and clusterings, etc etc.   but turns out that relevance engineering boils down far more effectively to a bunch of ""boosts"" (e.g. boost the rank if title of the document  contains keyword, boost the rank if the document is fresher than the other document, etc etc). all good search engines are a massive if-then-else statement. including Google."
Sandeep Srinivasa RedCarpetup|2023-08-07 10:52:05|the only reason embeddings work so well in LLM space is not cos embeddings are new. cos the damn LLM wont take more than 4096 tokens. so u cant return documents - u need to return small chunks.   but ultimately this is a search problem.  there is a reason why pagerank worked
Pratyush Choudhury|2023-08-07 10:52:57|This is very good point & exactly right :)
Sandeep Srinivasa RedCarpetup|2023-08-07 10:54:28|u will see a inverse correlation between vector databases and context size. If context size goes to a million (as it seems likely over next 2-3 years). you can switch comfortably to tfidf/bm25 and return documents for LLM consumption.
Pratyush Choudhury|2023-08-07 10:55:08|And what do you think this is due to?   Is this because of context not being evenly distributed?
Sandeep Srinivasa RedCarpetup|2023-08-07 10:56:34|didnt understand the question - but if ur no longer constrained by context size, then the search problem is unrestrained. so u can apply the bag-of-words+boost methods which are far far better for relevance. so this cosine distance stuff goes away.
Sachin Legaltech|2023-08-07 11:00:40|Don’t you think summarizing long documents and generating their embeddings might be more effective than tf-idf ? I think this trade-off might be more nuanced than chunk sizes. Also just because tf-idf based methods won last 25 years, doesn’t mean it will continue. The idea behind having dense vector embeddings isn’t new; but it’s working now just like all of deep learning ideas. We have more data/compute and better architecture.
Sandeep Srinivasa RedCarpetup|2023-08-07 11:00:50|"see the search problem is VERY very complex. lets say u search for samsung phone on amazon.com - do u want to return samsung galaxy s23 ? or do u want to return samsung  galaxy s23 ultra ?  maybe the ultra has higher gross margin. so ur friendly sales head will come and arm twist you into boosting the ranking of the ultra. this is what happens in real life search - it is dependent on business. and nothing to do with real semantics.  none of this can be done using ur embeddings approach. no way ur sales head is going to allow ur LLM to start recommending samsung s22 ...or horrors say something like ""samsung a series is good enough. why spend so much money on s23"""
Sandeep Srinivasa RedCarpetup|2023-08-07 11:04:25|so i wont push back too much on this. those of us who have worked in search for many years have faced all this struggle for a long time.  but lets see how the space evolves. this is my belief IMHO
Sachin Legaltech|2023-08-07 11:05:14|These intents can be added in the original documents and you can have couple of embeddings for the pair of intent+ product description. We can finetune the embeddings models too to achieve specific goals. There might be an end to end system where will finetune the entire neural network stack to improve the key metrics.
Sandeep Srinivasa RedCarpetup|2023-08-07 11:08:37|try it. ull find it very hard to boost rankings in the embeddings world. have already tried doing this with enriched metadata.  the only way is actually what GPT-index does : the reranking mechanic. The reason the re-ranking functionality exists is because of the problem i mentioned above.  with the difference that reranking on an subset retrieved by embeddings will not be superior to the boost based ranking method which runs on the entire corpus.
Shashwat TDC|2023-08-07 11:11:13|Perfectly explained. This is also the reason why most biz run on rule-based loyalty program, content rec sys, ads delivery systems etc.
Sachin Legaltech|2023-08-07 11:14:00|Having a neural network based cross-encoder to rerank things is definitely important. Just according to my opinion, discounting deep learning based methods compared to traditional ML based methods haven’t fared well. As the amount of compute keeps increasing, learning end-to-end systems eventually trumps all the heuristics based systems.
Dhruv Anand|2023-08-07 11:21:30|unrelated question: does gpt-3.5-turbo now point to gpt-3.5-turbo-0613?
Edgar Monis Mumbai WHO|2023-08-07 11:30:56|This is so on point. Kudos.
~ Vatsal Sanghvi|2023-08-07 12:44:51|Anyone who’s been able to get OpenAI credits via Microsoft for startups, recently? Or any other programs that offer credits?
~ Mayank|2023-08-07 12:46:59|+1
~ Rachitt|2023-08-07 12:49:19|Applied, but took over two weeks to get credits. A friend got it in two days
Amal David Futuryze|2023-08-07 12:55:25|I had got long back and another colleague got it after a week via foundershub microsoft
Rahul Bhatnagar|2023-08-07 13:01:34|We did too. They also gave us 2x credits. 5k$. (Dont know why though.)  Took about a week.
Sanyam Bhutani|2023-08-07 13:13:23|Who needs a cofounder to get credits? please dm 💀
~ Mayank|2023-08-07 13:13:56|Do we also know how to get AWS credits for startups 😅? Would be a great help!
Abhinav Verma Longshot.ai|2023-08-07 13:20:58|Join a co-working space. They used to do that a lot pre covid
~ Rohan Athawade|2023-08-07 13:22:34|Could you expand on how that would work?
~ Rohan Athawade|2023-08-07 13:23:04|+1. Would be a great help for me as well!
Abhinav Verma Longshot.ai|2023-08-07 13:23:57|Coworking spaces had this offer where you could apply for upto 10k in aws credits if you join them. They had tie ups with aws gcp and digital ocean
Abhinav Verma Longshot.ai|2023-08-07 13:24:28|You had to apply for the credits. But you would get them generally. Valid for 2 years
~ Rohan Athawade|2023-08-07 13:24:37|Interesting. Do you know of any specific co-working spaces that offer this?
Abhinav Verma Longshot.ai|2023-08-07 13:25:10|Will have to see because one of them had downgraded significantly post pandemic. I was there at 91springboard
~ Mayank|2023-08-07 13:58:15|Is there any other way except through co-working space offers? Just trying to look at my options.
Saurabh Karn Nyai|2023-08-07 14:06:08|Folks, not very Gen AI question but what is a good stack to run a document preprocessing pipeline that you guys have seen work really well? Especially extracting tabular data? I could use Tabula or use proprietary systems like AWS's or Google's but wanted to tap on to this group before starting.
Kshitij Agrawal ML Engineer|2023-08-07 14:26:41|Most of the cloud providers have an inbuilt preprocessor, so don't really need to worry. Aws textract works well for tabular data
Swastik Banerjee|2023-08-07 14:34:44|But well this is an example of a very obscure, vague search query. I’ve always heard it from people working in Search - “if you’re askinf stupid questions, expect stupid answers”, or maybe answers extremely vested by business or company policies/strategies.
Swastik Banerjee|2023-08-07 14:34:46|But I guess the original argument here was, how well dense embedding vectors work compared to sparse embeddings resulting from bag-of-words in the field of information retrieval. ‎<This message was edited>
Swastik Banerjee|2023-08-07 14:35:16|[PHONE]‘s arguments seemed a bit specific to context lenghts of LLMs and its capabilities. But lets keep the LLM part aside. If we think of just from the information retrieval point of view. Suppose you’re querying something like “how to convert 10 dollars to dirhams” in a search box. With the traditional tf-idf method, this would be parsed into everything including “convert”, “10”, “dollars” etc. Some of these parsings and further weighing of frequency of terms might be totally irrelevant/unnecessary to what you’re trying to ask here. Thats what embeddings can capture in their dense vectors. And with the newer embeddings from the Transformer models, the context is captured more/densified using the attention mechanism.
Swastik Banerjee|2023-08-07 14:36:55|So “embeddings” might not be a newer strategy, but if I’m not mistaken, from a pure information retrieval point of view, the newer embeddings from Transformer model is supoosed to work better than bag-of-words?
Swastik Banerjee|2023-08-07 14:37:49|What ultimately goes into finally designing a search engine is much more complex though, I agree:  depends on use-case, company strategy, business policy, etc. which requires custom boost, etc. how [PHONE] pointed out.
Sandeep Srinivasa RedCarpetup|2023-08-07 14:58:43|"Whenever I have worked in e-commerce cos, this is always 5he highest trafficed query.  If ur assuming that people ask intelligent questions..ur very wrong.  The most used feature of Elasticsearch is ""did you mean"".  Doesn't seem obvious.  Users behave very differently than you think"
Sandeep Srinivasa RedCarpetup|2023-08-07 14:59:35|However u have indeed pointed out the thing that most developers go with when they choose vector db - answering semantically intelligent questions.
Sandeep Srinivasa RedCarpetup|2023-08-07 14:59:40|Ymmv
"Arpan Desai | MobileFirst"|2023-08-07 15:04:30|Expert needed:  Hello All, a legal-tech startup is building its LLM-based product. They want to reduce the hallucinations in the LLM results. Currently, they are looking for a consultant/expert who can guide them on Guardrails, fine-tuning or any potential improvements.  Please DM me with your details. I can help you connect via Email.
Sandeep Srinivasa RedCarpetup|2023-08-07 15:07:17|I will challenge this answer in terms of metrics. If u remove LLM, u will find better results in this using tfidf/bm25 and not cosine distances
Rahul Bhatnagar|2023-08-07 15:12:37|Along with the tech, skills around scoping requirements and delivering are just are just as important in consulting cases.  Just DM [PHONE]. He's been doing this for a while.
Swastik Banerjee|2023-08-07 15:24:42|Have tried with the exact query “how to convert 10 dollars to dirhams” in my org looking for specific Mathematica functions (I work at Wolfram): pure tf-idf gave far worse results than cosine distance of embeddings because tf-idf had no idea what I was asking for. It gave ‘Log10’ as the top function (opposed to expected results  of ‘CurrencyConvert’) because 1. Log10 is cached more in user history 2. 10 was separately parsed, which is not ideal for what I’m looking for ‎<This message was edited>
Rohit Aggarwal|2023-08-07 15:25:54|[PHONE] has also done this in the past fwik
Sandeep Srinivasa RedCarpetup|2023-08-07 15:54:53|Incorrect. I checked the same. Someone in ur team has boosted numbers. If u remove 10 from ur search query it returns appropriate relevance.  Log10 is matching 10 cos of the boosting. Not cos of semantic misunderstanding
Sandeep Srinivasa RedCarpetup|2023-08-07 15:56:03|Why they did that has to do with aspects of ur business..and reinforces my point about boosting
Swastik Banerjee|2023-08-07 16:00:44|Exactly.  So the point is: if I have to boost numbers in most cases, without taking into consideration any context about the search query, it just generalises a search query and messes up the results.  Instead, a contextual understanding of the query is needed, in terms of embeddings, and then matched using a distance metric. Custom boosts could rather be applied on top of it as further tweakings, is my argument.
Sandeep Srinivasa RedCarpetup|2023-08-07 16:01:59|no. ur point is wrong. if ur using lucene, it discards numbers *by default* https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-simple-analyzer.html  this is now a tokenization discussion and no longer a relevance and ranking question. u should ask ur arg why they have changed the default behavior of tokenization to include numbers.
Sandeep Srinivasa RedCarpetup|2023-08-07 16:03:11|my point still stands. given the same tokenization (which may or may not include numbers that you deliberately have included), cosine will perform worse off.
Nirant|2023-08-07 16:05:07|Friends, we've gone into quite a lot of detail around IR/Ranking for the main thread, let's move this to DM?
Swastik Banerjee|2023-08-07 16:37:30|Nope. This Simple Analyzer is of ElasticSearch which is built *on top* of Lucene; not sure what it’s default parameters are. The default tokenizer in Apache Lucene is the StandardTokenizer, which adheres to the Unicode Text Segmentation algorithm. It does not ignore numbers by default, but treats numbers as separate tokens.  You might want to check this: https://lucene.apache.org/core/6_4_1/core/org/apache/lucene/analysis/standard/StandardTokenizer.html  Let’s move this chat further to DM as [PHONE] said :-)
Saurabh Karn Nyai|2023-08-07 16:47:36|Got it!
Nilesh Transcend|2023-08-07 17:13:32|Topic modeling based on Text network analysis: https://infranodus.com/
~ Aman|2023-08-07 17:19:12|Hey, Needed some guidance in generative music. I have a collection of cc0 audio files (public domain audio), and want to generate new music trained on this dataset. Any suggestions on how to go about it and if someone has any progress or worked on similar use cases, would greatly appreciate any insights you could share
~ anuja grazzel|2023-08-07 17:24:08|There is a youtube channel called AI Anytime. It explains how to generate music by training existing audio files. Please check that channel.
~ anuja grazzel|2023-08-07 17:24:48|It has lot of other generative ai projects like text to music, text to text.
~ Aman|2023-08-07 17:25:40|Thanks, will check it
~ Rashmi|2023-08-07 19:01:32|‎~ Rashmi left
~ HP|2023-08-07 19:08:09|Hey, Is there anyway to load llmma 2 7b chat model in 12 gb ram colab notebook? Also, any good resources for RAG using langchain and llma 2 ?
~ Om|2023-08-07 19:13:32|You may try the GGML quantized 8 bit version of LLAMA chat 7B. Takes around 8GB. Not bad with the responses either. https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML
~ HP|2023-08-07 19:16:10|Yes went through this. It was not working with hugging face Transformers in colab. Missing files.
~ Om|2023-08-07 19:18:15|Not sure why that may happen. I downloaded the bin file directly and went ahead to load it with CTransformers. Worked pretty well. Though I did not run on Collab.
~ HP|2023-08-07 19:21:42|Will try this
Nirant|2023-08-07 22:04:35|[PHONE] wrote the llama.c from Karpathy in Rust: https://github.com/rhlbhatnagar/llama2.rs
Nirant|2023-08-07 22:05:15|If you're a crustacean, consider raising a PR with support for quantisation or more parallelisation!
Nirant|2023-08-07 22:06:20|[PHONE] might be interesting to you, you were considering running Llama2 in AWS Lambda, right?  This should improve your cold start times. I believe the Python to Rust cold start time ratio is about 4-5x? ‎[8/7/23, 22:09:29] Rahul Bhatnagar: ‎video omitted
Rahul Bhatnagar|2023-08-07 22:10:47|Should be useful to people familiar with rust. Specially someone who's done low level pointer manipulation and needs Llama inference on a cpu machine.
~ Arindam Barman|2023-08-07 22:21:46|amazing
Shubham Girdhar|2023-08-07 22:27:09|‎Shubham Girdhar requested to join
Deep Samsung R&D|2023-08-07 23:23:38|Has anyone used Zapier NLA or Gorilla LLM, looking for some suggestions on which one is better for integrating with SaaS tools?
Dhruv Anand|2023-08-07 23:45:55|Another API question: does reducing maxTokens make the response more terse (less setup/boilerplate text) or is it likely to return a correct answer?
~ Ankit Banerjee|2023-08-08 01:06:41|I don't think so. I tried it, there is an entropy drop for sure
Abhinav Verma Longshot.ai|2023-08-08 01:07:54|Yes
~ Rohan|2023-08-08 02:57:41|"what's the limit on Claude 2's chat interface? I had never seen the limit before but recently ran into a message saying ""8 more messages allowed till 9 PM""."
Abhinav Verma Longshot.ai|2023-08-08 09:58:27|No idea. Not available in India yet. Use either api or just their default console
Kiran Darisi AtomicWork|2023-08-08 10:50:06|Hi any frameworks you used to do regression testing of RAG based chatbot ? Not just the API ... automating the testing from the end user perspective
Paras Chopra Wingify|2023-08-08 10:54:31|Folks, does anyone know how precense penalty works? I understand frequency penalty with Downregulates tokens during sampling
Abhinav Verma Longshot.ai|2023-08-08 11:37:35|https://twitter.com/jeremyphoward/status/1688793283034779648?s=20
Rajaswa Patil|2023-08-08 11:42:37|Damnnn 😂 That's pretty cool.
Abhinav Verma Longshot.ai|2023-08-08 11:44:21|https://chat.openai.com/share/78ea5d77-39d0-4645-a08f-4bc528d94d38 I tried to convert  the frequency pen and presence pen equation provided by openai in python and get this clarified. presence_penalty basically helps when you want to generate (I don't know the best way to put this) new words in your generation
Abhinav Verma Longshot.ai|2023-08-08 11:45:17|One thing is clear, the freq penalty and presence penalty are applied after the temperature step
Nirant|2023-08-08 11:45:23|Official OpenAI Explainer:  This parameter is used to encourage the model to include a diverse range of tokens in the generated text.  It is a value that is subtracted from the log-probability of a token each time it is generated.  A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.  https://community.openai.com/t/difference-between-frequency-and-presence-penalties/2777/2
~ HP|2023-08-08 12:00:26|This worked great. Thanks for the suggestion. However I couldn't find a param in detokenize method to limit generated tokens
Rajesh RS Generative AI WhatsApp Group|2023-08-08 12:28:03|Anyone looked at ragas? https://github.com/explodinggradients/ragas - thoughts?
Rajesh RS Generative AI WhatsApp Group|2023-08-08 12:28:44|Evaluation of the results of RAG apps seems to be a big sub problem- part of the quality aspect of these apps that use LLMs, regardless of whether theyre chatbots or other kinds of LLM apps
Nirant|2023-08-08 12:28:53|cc [PHONE] [PHONE] the makers are here :)
Divya Tak|2023-08-08 12:30:21|Firs thought I had was, oh, neat, indian music thing
Rajesh RS Generative AI WhatsApp Group|2023-08-08 12:31:59|"I should have known - ""the"" generative AI group!"
Shahul Kaggle Kernel GM|2023-08-08 12:37:02|Hi guys, we are working on releasing our paper on our approaches and it’s effectiveness. We do have integrations with llama index , langsmith, and langchain coming soon
Shahul Kaggle Kernel GM|2023-08-08 12:38:28|Would love to hear feedback and work together:) ‎[8/8/23, 12:47:48] Paras Chopra Wingify: ‎image omitted
~ Rahul Bansal|2023-08-08 12:54:07|I would love to be part of the chat. It looks interesting
Jithin James Ragas|2023-08-08 12:55:33|we were going for RAG ASsessment but now we don't use that 😂
Rajesh RS Generative AI WhatsApp Group|2023-08-08 13:47:32|Same here. Some years back built a small experiment around Indian raga identification. Thought it may have been something similar but turned out to be this other cool thing...
Anshuman Pandey|2023-08-08 13:52:23|Whoever is building in the MLOps/LLMOps space  This is what you're up against bro https://www.nytimes.com/2023/08/07/technology/ai-start-ups-competition.html ‎[8/8/23, 13:52:43] Anshuman Pandey: ‎image omitted
Nilesh Transcend|2023-08-08 14:06:21|New pseudo-programming language to be used with LLMs: https://github.com/paralleldrive/sudolang-llm-support
Nishant Apne-App GenAI Hackathon|2023-08-08 14:14:26|Not sure about the context of the question, but if you are planning to implement it for a model locally, this might help:  If you are using smaller models which gets stuck on the same token while generation, you can add a recency penalty too: Decrease the logits more if the token exists in the last `n` tokens.  And also for the frequency penalty, if the token appeared more than `t` tokens ago, you shouldn't penalize it.  Adding these penalties, made ~700 M params model way more reliable.
Paras Chopra Wingify|2023-08-08 14:17:07|Yeah then there is context free guidance too, though I wonder how it differs from penalties
Paras Chopra Wingify|2023-08-08 14:18:36|Which 700m model did you choose? And also is the function for downregulating recent tokens public or you wrote
Nishant Apne-App GenAI Hackathon|2023-08-08 14:19:31|Context Free guidance modifies all the logits, penalties are for specific logits.  CFG is to make the outputs better, and penalties are to prevent outputs from getting worse.
Nishant Apne-App GenAI Hackathon|2023-08-08 14:19:54|I wrote it myself. The 700M model is a custom GPT2 model on a custom dataset.
Nishant Apne-App GenAI Hackathon|2023-08-08 14:20:39|If you need pointers to implement, it is simple and we can move this to DM.
~ Rahul Bansal|2023-08-08 14:22:06|This is interesting. I am going to try this.
Paras Chopra Wingify|2023-08-08 14:26:01|i was trying this, it's intriguing take but it's just a bunch of things to put in the prompt.  i thought they have an intepreter going
Paras Chopra Wingify|2023-08-08 14:54:45|does anyone know if chatgpt internally does anything more than just keep feeding the historical context? if there is max length, does it just ignore previous one?  do we know what are hyper params (of temperature, and penalties) that openai uses in chatgpt consumer product  because in my experience, using the API, gpt-turbo-3.5 can get stuck into repetitive patterns when conversation context elongates, but consumer chatgpt doesnt' seem to do that
~ Rahul Bansal|2023-08-08 14:56:49|consumer chatgpt also does that. I used it to code an app, but aftersometime it was missing the details I gave earlier.
~ gaurav|2023-08-08 15:22:51|Hi, Is there a possibility in Langchain or LLama index or even in any other way create an conversational bot with own documents while also using function calling?
Ravi Theja|2023-08-08 15:34:12|Yes, possible with LlamaIndex.  You can check it out here - https://gpt-index.readthedocs.io/en/stable/examples/agent/openai_agent_with_query_engine.html
~ gaurav|2023-08-08 15:35:31|Thanks [PHONE] 🙏 Will check this out
Paras Chopra Wingify|2023-08-08 18:44:10|anyone tried this   https://platform.metaphor.systems/
Arnav Bansal Replit|2023-08-08 18:55:30|i use metaphor systems as my primary search engine if i want to read about a particular topic but don’t know what exactly. it’s pretty good
Paras Chopra Wingify|2023-08-08 19:00:34|You access it though API
Paras Chopra Wingify|2023-08-08 19:00:39|How have they built it
Paras Chopra Wingify|2023-08-08 19:00:53|Seems like they e fine tuned an LLM to emit links
Arnav Bansal Replit|2023-08-08 19:01:43|oh sorry no, just the public search here: https://metaphor.systems
~ Ameya|2023-08-08 19:03:06|Doing this
~ Ameya|2023-08-08 19:03:28|[PHONE] can I DM? Would love to discuss how I can contribute
~ Vishwam Jindal|2023-08-08 19:46:26|After backlash, Zoom clarifies and updates policy changes for training its AI models:  https://blog.zoom.us/zooms-term-service-ai/?utm_source=www.therundown.ai&utm_medium=newsletter&utm_campaign=openai-s-launches-gptbot
Ankur Pandey|2023-08-08 19:54:04|They seem to have pivoted a lot! I encountered them first in Oct '22
Anshuman Pandey|2023-08-08 20:03:03|You're right! It's one of the Nat Friedman's minions. This & there was another company called EveryPrompt (which shut down)  The valley boys are fast at iterating. They will throw whatever shit they can at the wall & see what sticks
Ankur Pandey|2023-08-08 20:11:15|True, true. But I concede that unless you sell to Enterprises etc building & iterating software startups like this is probably better. Total detachment from the idea.
Anshuman Pandey|2023-08-08 20:14:36|"""Total detachment from the idea""  This is the way 🦦"
Anshul Bhide Replit|2023-08-08 20:48:05|NVIDIA H100 supply and demand analysis   https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/
Paras Chopra Wingify|2023-08-08 23:17:22|https://stability.ai/blog/stablecode-llm-generative-ai-coding
Abhinav Verma Longshot.ai|2023-08-08 23:53:18|So claude and claude-instant are better at following instructions to output in json than gpt-3.5-turbo it seems.
Harsh Gupta Felvin|2023-08-09 01:03:12|Thanks for sharing, did you try it out, how well it perform, especially compared to GPT-4
Abhishek Mishra|2023-08-09 02:56:02|Only the instruct model is worth consideration. The completions model seems to be disappointing somewhat overall. Needs a lot of VRAM for inference (>15G) and can get confused and respond incorrectly.
Abhishek Mishra|2023-08-09 02:56:54|if you want to play with the instruct model, you can play with it in this free tier colab notebook I made for inference - https://colab.research.google.com/drive/1pH3M7ZllWPjBiw_ZqnbO9YXKJCQxkxfE?usp=sharing ‎<This message was edited>
Adithya S K PESIT|2023-08-09 03:18:40|how is the model performing?
Abhishek Mishra|2023-08-09 03:21:16|I usually test like this:  Basic Scenario function < function + slight algo change request (e.g. iterate instead of recursive) < prev. case + request to create a class with example execution < prev. case + negative instruction of not using a certain style which it keeps consistent in all prev. cases
Abhishek Mishra|2023-08-09 03:21:51|It did 1st level well, then missed 2nd, okayish with 3rd and that's it.
Abhishek Mishra|2023-08-09 03:22:34|I don't do knowledge tests in sanity checks, i just like to see if model has rote memorization or it can actually understand my instructions. ‎<This message was edited>
Abhishek Mishra|2023-08-09 03:24:10|I have a collection of 20 such basic scenarios.
Abhishek Mishra|2023-08-09 03:24:14|Expanding more.
Adithya S K PESIT|2023-08-09 03:25:12|that's interesting. so codecherrypop vs this which do u think is performing better ik its subjective but wanted your take on that
Abhishek Mishra|2023-08-09 03:27:45|This is a pure code model, overall it performs similar to codeCherryPop give and take in coding. codeCherryPop is an assistant capable of playing games with you, having a wholesome chat as well as act as tutor for basic concepts and explain them. I am yet to test how well this stableCode 3B will do in quantized form, I have the weights so I will just give it a spin. ‎<This message was edited>
Chaitanya A GenAI|2023-08-09 08:06:04|anyone here who has trained speech2speech transformers/models recently? needed a few insights around it, would love to connect
Ravi Theja|2023-08-09 08:52:33|[PHONE] has done a lot of work on the speech side. He should be able to help you.
Anshuman Pandey|2023-08-09 08:55:17|It's pretty shitty. WizardCode still the best text to code model. ‎<This message was edited>
Anshuman Pandey|2023-08-09 08:55:30|https://huggingface.co/spaces/mike-ravkine/can-ai-code-results
Chaitanya A GenAI|2023-08-09 09:11:55|Thanks, reaching out
ashish Acgt01 Twitter|2023-08-09 09:31:59|Google just launched idx.dev  https://idx.dev/  anybody has access to this ? has more details beyond whats on the page ?  p.s. so far the view is that google's been bit of a laggard in the gen ai race. my gut feeling is this(https://idx.dev/) could change that impression !
~ Adithya|2023-08-09 10:31:45|Does anyone know how to move torch tensors directly to cudnn on gpu instead of the standard torch functional approach?
Shaista Hussain|2023-08-09 10:39:25|‎‎Shaista Hussain changed their phone number to a new number. ‎Tap to message or add the new number.
~ Asad|2023-08-09 11:23:04|How are folks handling hallucinations or anomalous answers for critical gen AI use cases like customer support ?
Ambika Computational Mama|2023-08-09 11:32:01|instructional prompting helps to some extent but we are also testing for evaluation to check the quality of the answers
Amit Bhor|2023-08-09 11:32:18|RAG, temp, TopP, Prompt pooja ceremony seems to help a bit.
Ambika Computational Mama|2023-08-09 11:34:07|ya pooja ceremony helps!
Ambika Computational Mama|2023-08-09 11:34:09|😂
Ambika Computational Mama|2023-08-09 11:35:00|I want to test hyde also [PHONE] pointed me to that - but haven't had the time to check at larger scale
Rohit Aggarwal|2023-08-09 11:35:34|This reply needs to be archived for everyone asking about hallucinations 😂
Paras Chopra Wingify|2023-08-09 11:36:13|Million dollar question
~ Asad|2023-08-09 11:39:20|Gen AI is a maker checker product at this phase where AI is maker and there is an end human who is the checker but in use cases which is critical and where no human involvement is there this anomaly can be dangerous. One way of solving this is simple feedback from the user to understand the absurdity of the answer and re-generate the answers ‎<This message was edited>
Sudharshan GenAI|2023-08-09 12:09:52|https://huggingface.co/Qwen/Qwen-7B-Chat  Anyone tested this?
Abhishek Mishra|2023-08-09 12:19:56|Not yet, their initial claims, especially on tool usage side made me want to test quickly but more fun things dropped just half a day after its release so testing it slipped.
~ Kifilshah|2023-08-09 12:41:19|Are there any code generators/models that can write langchain code?
Saurabh Karn Nyai|2023-08-09 12:50:55|I tried it but it doesn’t work. This is what has worked for me: 1. Write a base implementation which works. For example take RAG example.  2. Put this base implementation in context either on ChatGPT or API, whatever you prefer.  3. Iterate on a plan with GPT about what modifications you want to do. For example, how can we deploy above code using FastAPI.  4. Ask for a project structure. How the code should be organised. Maybe even create a python file to create the project structure.  5. Give a feature and ask for how can this be implement with above project structure and go file by file to make modifications.
~ Krishaay|2023-08-09 12:52:38|You can try using the Mendable search on the langchain docs page. ‎[8/9/23, 13:04:26] Jay Pokarna 2014 BPCC: ‎image omitted
~ Ankit Jain|2023-08-09 13:07:47|You have checked https://flowiseai.com/ ?
~ Kifilshah|2023-08-09 13:08:16|Nope. Will check it out!
ashish Acgt01 Twitter|2023-08-09 13:31:51|Talk by Yann LeCun at MIT https://www.youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg
Nirant|2023-08-09 13:33:34|‎Waiting for this message. This may take a while.
Nirant|2023-08-09 13:34:10|Small detour, just doing a pulse check on where we're in our technical journeys. 3 questions in all — please answer them, helps me set the tone for the group and for what kind of questions we should just have default answers now.
Nirant|2023-08-09 13:35:45|‎Waiting for this message. This may take a while.
Shimanta Generative AI|2023-08-09 13:36:00|Does “production” have any limit on the size?
Nirant|2023-08-09 13:38:32|‎Waiting for this message. This may take a while.
Nirant|2023-08-09 13:38:45|No, if you make money from it — it's production
Nirant|2023-08-09 13:39:35|All questions have one more than one option which apply, please select *all that apply*!
~ Ankit Jain|2023-08-09 13:39:44|Used even a few times to just try it or being used actively?
Nirant|2023-08-09 13:41:54|"These questions are intended to assess technical maturity — so if you feel like you know enough about the lib to use it again, mark it as ""Used"" or if it was toy-ish and you don't feel comfortable recommending it your boss/teaching it — Mark it as ""Heard"""
Kaushik Bokka|2023-08-09 13:42:27|Has Harrison started making money out of Langchain yet? :p
Nirant|2023-08-09 13:42:46|He got paid the day they raised VC, didn't he xD
Utkarsh Saxena GenerativeAI WhatsApp Group|2023-08-09 13:55:46|I'm in a weird position wrt Langchain.  It's good to get started, but we are now rewriting pretty much everything ourselves with OpenAI calls.   Especially the memory module. Highly restrictive for our usecase
Nirant|2023-08-09 13:56:42|"Point noted. I'll have an option called ""Churning from Langchain"" for a very small but vocal minority of us xD"
Abhinav Verma Longshot.ai|2023-08-09 13:57:12|That is the way
Anshul Bhide Replit|2023-08-09 14:00:16|Would love to understand how many people have begun Hsing langsmith too
Nilesh Transcend|2023-08-09 14:04:02|Got access but found it underwhelming.
Nirant|2023-08-09 15:17:06|Unexpected easter egg:   British Intelligence (the famous double 00 agencies) has a ML Lifecycle management OSS project: https://github.com/gchq/Bailo ‎[8/9/23, 15:17:44] Nirant: ‎image omitted
~ Ankit Jain|2023-08-09 15:28:48|Are you able to solve the usecases via something else or you feel the usecase itself does not exist?
Gokul Krishnan|2023-08-09 15:49:52|Bhai Lo?
Dhruv Anand|2023-08-09 17:32:02|Anyone thought about/interested in quantizing a sentence transformers model? I'm wondering if it's possible to reduce the size of one of the new leaderboard topping models even further (both model and output dimension) and still have it retain quality.
Nirant|2023-08-09 17:36:52|I've ONNX ports for these on their way out this week or next
Nirant|2023-08-09 17:40:57|If you've a wishlist, please share here
Gokul Krishnan|2023-08-09 17:43:12|LoRA/QLoRA tuned?
Nirant|2023-08-09 17:43:38|No, just good ol static Quantization from Optimum
Nirant|2023-08-09 17:43:45|I've existing code for these already
Abhinav Verma Longshot.ai|2023-08-09 17:44:33|Which ones are you talking about?
Dhruv Anand|2023-08-09 17:45:17|gte, bge, e5
Abhinav Verma Longshot.ai|2023-08-09 17:45:33|The mteb ones?
Dhruv Anand|2023-08-09 17:45:53|I'm guessing it's trivial to convert back into sentence_transformers/torch?
Nirant|2023-08-09 17:47:34|Yessss, but I'll give you fast CPU and Metal Mac inference
Gokul Krishnan|2023-08-09 17:49:44|Why not coreml?
Gokul Krishnan|2023-08-09 17:49:50|Assuming you want to run on Mac ‎[8/9/23, 17:50:07] Saurabh Karn Nyai: ‎GIF omitted
Saurabh Karn Nyai|2023-08-09 17:50:08|Waiting for it :)
Nirant|2023-08-09 17:51:31|I already know ONNX tooling 🙈
Abhinav Verma Longshot.ai|2023-08-09 17:54:07|Do you also have a how to tutorial with this?
Nirant|2023-08-09 17:55:54|No, but I'll share the nbs I will write/use
~ Akshat Khare|2023-08-09 18:22:39|Hey [PHONE] do you mind sharing the codebase to power summaries of the day of the chats? Need it for other groups too :p https://nirantk.com/docs/resources/
~ Akshat Khare|2023-08-09 18:24:40|do you take daily exports or weekly exports and parse it and create it? Is it automated?
Nirant|2023-08-09 18:30:33|Manual export, automated from that point
Shivendu Kumar|2023-08-09 18:49:29|You can automate that as well using tasker-like apps on your mobile. They support UI interactions, reading files, and even API calls. You won't face the permanent ban issue that you mentioned last time.   Overkill, I know. But that's what engineers are known for - the joy of automation :p
aashutosh GenerativeAI WhatsApp Group|2023-08-09 20:25:46|Can someone share good resources to use the Llama Index in Node?
‪+91 94402 72263‬|2023-08-09 20:46:19|‎Sudharshan GenAI added ‪+91 94402 72263‬
Nirant|2023-08-09 21:46:58|Cc [PHONE]
Ravi Theja|2023-08-09 22:10:19|https://gpt-index.readthedocs.io/en/latest/core_modules/data_modules/documents_and_nodes/root.html  Is this something you are looking for?
Abhishek Mishra|2023-08-09 22:29:10|bert.cpp already exists  https://github.com/skeskinen/bert.cpp ‎<This message was edited>
Abhishek Mishra|2023-08-09 22:29:36|It can reduce the size of the sentence bert models further but they have not resolved the issue with batch inference/training.
Abhishek Mishra|2023-08-09 22:29:56|So it is only smaller now and not faster by multiple magnitudes.
Abhishek Mishra|2023-08-09 22:31:31|As for the newer leaderboard toppers like gte, bge, e5. I am yet to check exact architectures which can be mapped to corresponding cpp supports for quantization.
~ Happy Chaudhury|2023-08-09 23:42:00|I am currently doing this for Roberta and deberta using optimum, any learning can share plz
~ Karan|2023-08-10 01:28:41|Does anyone interview experience with HF0? Will appreciate any specific insights/ do's-don'ts for the 10 min interview. TIA
~ Karan|2023-08-10 01:30:24|*have interview experience
~ Ayush Yadav|2023-08-10 02:42:30|I want to get current fashion trends in the market.   What's the best way to do that?  + Any suggestions regarding this.  My team got selected in Flipkart grid Hackathon where we are supposed to suggest outfits, based on user purchase history, current trends & things like current ocassion.  Like clothes I suggest on Diwali for 32 year female from muzaffarpur, should be different from clothes I suggest for 18 year old girl from Mumbai.
~ Ayush Yadav|2023-08-10 02:44:43|User Age, regional, brand preferences, color preferences, current ocassion, current trends, gender.   I am thinking of using a dataset from kaggle  Then applying vector search.
Anshuman Pandey|2023-08-10 07:32:09|https://twitter.com/AlexReibman/status/1688965282575093761?t=vRecHRTG0KsbS3WgyeubLA&s=08
Anshuman Pandey|2023-08-10 07:32:28|Submissions from the OutsideLLMs Music + GenAI Hackathon here in SF from last weekend
~ Sudhanshu Heda|2023-08-10 10:24:52|https://www.useglaze.com
~ Prashant|2023-08-10 10:40:11|Is this data public? For current fashion trends, instead of using external data, you can use these as features:  number of times a product was bought on the last day, last week, last month, last year.
Amit Bhor|2023-08-10 11:42:33|"Is anyone aware of a ""pure"" language model i.e can converse/or just pretrained but has no facts or knowledge of people and events ?"
Amit Bhor|2023-08-10 11:44:58|Such a model when fine tuned with custom data should *in theory*have lesser hallucinations or at least not get into random conversations. Not even sure what training data this would require
Dr. Pratik Desai KissanGPT|2023-08-10 11:58:38|"""pure"" is still next token predictor, and hallucinate."
ashish Acgt01 Twitter|2023-08-10 11:58:43|so the hypothesis is that the root cause of all hallucination is the pre-training ?
~ Prashant|2023-08-10 12:05:21|If we use facts from a reliable system, and ask the language-only model to find the answer, the hallucination rate should be much lesser compared to general llms, because of shrinking of probability distribution to only a few tokens,.
Amit Bhor|2023-08-10 12:05:24|As pratik said, you can never get rid of hallucinations but pretraining on pure English text without any real facts (politics, religion, history etc) of the world may help in certain closed language usecases?
Nilesh Transcend|2023-08-10 12:05:56|"Came across another vector database with ""20k stars on github"": https://github.com/milvus-io/milvus"
Dr. Pratik Desai KissanGPT|2023-08-10 12:07:42|May be you can improve on hallucination by adding only Arxic papers, but then not having literature work (which is in non fact category) will degrade the language features.
Amit Bhor|2023-08-10 12:09:09|Should also help with prompt injection attacks.
Dr. Pratik Desai KissanGPT|2023-08-10 12:09:11|Milvus is very old
Amit Bhor|2023-08-10 12:10:24|I suspect even arxiv will have lots of names, world events etc
Dr. Pratik Desai KissanGPT|2023-08-10 12:12:28|Anyway, this is core DL research topic, and will need a lot of iteration and experimentation to conclude. Use RAG meanwhile, it solves most of the problem.
Amit Bhor|2023-08-10 12:15:31|I'd be surprised if someone hasn't thought and tried this already. You can even put placeholder tokens in place of proper nouns in training set
Sudharshan GenAI|2023-08-10 12:24:23|https://khoj.dev/  Pretty cool
Sudharshan GenAI|2023-08-10 12:24:26|[PHONE] ‎[8/10/23, 12:24:42] Sudharshan GenAI: ‎image omitted
~ kashish|2023-08-10 12:27:44|What is the source of this data? Does it read all offline files on the system
Sudharshan GenAI|2023-08-10 12:29:46|Yeah looks like it - plug obsidian, logseq etc ‎[8/10/23, 12:29:49] ashish Acgt01 Twitter: ‎image omitted
Abhinav Verma Longshot.ai|2023-08-10 12:30:59|oh yes, it's very intriguing for me. It happens because the session resets if unused for a few minutes.
Abhinav Verma Longshot.ai|2023-08-10 12:31:07|https://twitter.com/jeremyphoward/status/1689464587077509120
Anubhav mishra Zupay|2023-08-10 12:34:41|There is one more YC company Martin I guess
Anubhav mishra Zupay|2023-08-10 12:35:10|Majorly ab assistant to your work stuff
Dhruv Anand|2023-08-10 12:35:16|Yeah it has a 100M funded company built around it (zilliz)
Anubhav mishra Zupay|2023-08-10 12:35:42|https://www.trymartin.com/
Dr. Pratik Desai KissanGPT|2023-08-10 12:37:07|ChatToPDF, where PDF is your notes application data
Nirant|2023-08-10 12:40:04|Nix-managed sessions seem to time out often when running on something like AWS Lambda/serverless  You'll see Replit, Fly.io also suspend the exec env quite often to save compute cost — thereby resetting the state. Replit has the nicest DevX for this — they keep your IDE alive and only suspend the Console/Terminal.
Abhinav Verma Longshot.ai|2023-08-10 12:43:57|Interesting. It does seem exactly like this. I was more intrigued by the way the prompt realises something is missing and looks at the chat history for env variables if any. One thing to note is, because the session times out, you need to keep reuploading files , which is the only downside
Anubhav mishra Zupay|2023-08-10 12:50:13|https://www.google.com/amp/s/www.moneycontrol.com/news/business/rbi-may-use-ai-in-conversational-payments-on-upi-11139801.html/amp
Anubhav mishra Zupay|2023-08-10 12:50:58|Crazy! Any idea what they might be building ( stack I mean) ‎<This message was edited>
Abhinav Verma Longshot.ai|2023-08-10 12:51:34|will it stop working in the afternoon and say Away for Lunch
~ Pranay Desai|2023-08-10 12:53:33|What do they even mean by conversational AI interface on UPI? They're a platform not a product themselves.
Pratyush Choudhury|2023-08-10 12:53:35|Why is this crazy?   It was always expected, wasn't it?  a lot of UPI transactions happen over butterfly phones today too
Aakash Kumar  Matrix Partners|2023-08-10 12:54:35|Yep. And huge gap still with apps as an interface beyond first 500Mn
Aakrit Vaish Haptik PeerCheque|2023-08-10 12:54:39|It's a bit pointless imo.  For simple structured transactions conversational interfaces don't really add too much value beyond traditional UI. In fact id say its worse.  There is very little AI to use when you are paying Rs. 100 to your doodhwala 🙂
~ Pranay Desai|2023-08-10 12:58:28|AI is a hammer, and everything looks like a nail
Nirant|2023-08-10 12:59:42|Aakrit and friends have built some of India's largest conversational interfaces over the last 1-2 decades via Haptik and Jio. It's good to assume they have a stronger intuition over repeated iterations than us!
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:01:05|1 decade bro 2 decades back I had harder problems to solve than AI
Pratyush Choudhury|2023-08-10 13:01:12|I guess the question is around the users beyond the top 3-400M (?)  Or maybe even b2b transactions
Sumod K Mohan|2023-08-10 13:03:33|I was assuming the power was that it can enable non smart phones users thru SMS or even voice based. Assumption being SMS based templated langauges are brittle or requires too difficult workflows (did you mean 1?). Is that not true or the base is small?
Dr. Pratik Desai KissanGPT|2023-08-10 13:04:19|Unit economics can go crazy for each transaction, looking at this scale. There won't be a way to profitability from UPI if that happens.
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:04:41|Right there's enough ways you can build GUI apps even on feature phones.  I don't buy the logic that a less sophisticated user will use a sub standard experience to adopt a new form of banking 🙂
Pratyush Choudhury|2023-08-10 13:05:10|Just a thought exercise - I guess the models in use here will be small sized, indic language specific, OSS, possibly also running on the edge - so costs & privacy will be taken care of  Use case: As [PHONE] mentioned, could be to include the additional user-base that might not have familiarity w/ widgets/filters in terms of UI but uses and likes conversational platforms like WhatsApp  The Gen AI element could just be from using a Foundational Model here - one model, extensible for quite a few things
Abhinav Verma Longshot.ai|2023-08-10 13:05:21|Is this something related to election campaigning by any chance. This might go off topic so just posting the single thought here. Can continue this discussion in AI philosophy group
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:06:09|At Jio we've built voice driven stuff on the Jio phone but it caps out at the simple 1:1 search use case
Anubhav mishra Zupay|2023-08-10 13:06:54|Just wondering if Paytm soundbox and all that will make sense, obviously they will do it for both the merchant and the consumer ends.
Anubhav mishra Zupay|2023-08-10 13:08:43|I think it'll be proof to the world that India has implemented and scaled an AI system to 500 million + user base.   But they might get some insane insights too ‎<This message was edited>
Pratyush Choudhury|2023-08-10 13:09:47|Even with small sized, OSS models that will be running on the edge?   Maybe I am missing something - can you please help
ashish Acgt01 Twitter|2023-08-10 13:10:44|I wonder on the backend, while doing telemetry and keeping track of ChatGPT plus requests threshold ( 50 every 3 hours I believe), do these extra requests to re-upload files count towards the threshold ?
Nirant|2023-08-10 13:11:54|I believe they can move the files to a longer persistence e.g. 7d or something like that. But the code execution sessions will likely continue to be short-lived. I believe they send a time-out call to the browser/LLM as well — because I've seen this happen in a session I'm actively using as well.
Abhinav Verma Longshot.ai|2023-08-10 13:14:37|Can you link more about different persistence for files?
Saurabh Karn Nyai|2023-08-10 13:16:06|I Dont think Govt. Is looking at unit economics. With no MDR UPI is just a cost that banks have to absorb no choice.
Dr. Pratik Desai KissanGPT|2023-08-10 13:16:43|We don't have any small oss model (that is useful) and can run on edge devices. Any edge device that is not phone add to unit economics. Also, we are taking about Jio Features phones, Doodhwalas, etc, so all of these in one sentence won't make sense.
Saurabh Karn Nyai|2023-08-10 13:16:56|Similarly Bhashini is burning bunch of GPUs to make voice available. I think there is something there and how friendly and usable the tech becomes will be key question.
Dr. Pratik Desai KissanGPT|2023-08-10 13:17:53|You can't use Bhasini in production. UPI is gold standard on other side. Any half baked effort that bring down UPI standard will never work. ‎<This message was edited>
Anshuman Pandey|2023-08-10 13:18:28|I remember Haptik was into hardware at first before it pivoted to conversational AI. Am I correct?
Saurabh Karn Nyai|2023-08-10 13:18:40|Yet. I think Bhashini will improve significantly.
Saurabh Karn Nyai|2023-08-10 13:19:13|Also for transactions might be easier to do compared to full length conversations and assistance as we would expect in Govt. Scheme delivery.
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:20:34|Unfortunately no never did hardware. Would love to at some point.  We built a consumer AI assistant app before pivoting to B2B SaaS for similar use cases.  The consumer app had 1m actives at one point so that taught us a lot in terms of how people use chatbots for commerce and services.
Dr. Pratik Desai KissanGPT|2023-08-10 13:22:02|They will, I am just worried about using as it as a benchmark. Bhasini will be burning cash like OAI if they end up supporting India level scale. Good that it not very reliable to be used in production, or they will run out of infrastructure soon.
Sandeep Srinivasa RedCarpetup|2023-08-10 13:23:50|genuine question - is there any data/metrics around Bhasini compute usage ?im wondering why everyone talks about it being inefficient.
Anshuman Pandey|2023-08-10 13:24:31|Wow! looks interesting  https://web.archive.org/web/20161215144420/http://haptik.ai/  What was running behind the consumer chat app back then? Curious to learn about the stack & also what led to the pivot to B2B SaaS
Dr. Pratik Desai KissanGPT|2023-08-10 13:24:49|I just used it for a while, felt latency very high. Also, you're relying on Gov APIs without any SLA. You can't sell that to your enterprise customers.
Sandeep Srinivasa RedCarpetup|2023-08-10 13:30:52|so what do u think of the UPI chatbot project ? do you think people use it for those usecases ?
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:34:08|Our home grown AI 😀  We used NLP to build it. Consumers don't pay for convenience in India so we pivoted to B2B.  The consumer app was a vitamin not a painkiller.
ashish Acgt01 Twitter|2023-08-10 13:34:40|+1
Paras Chopra Wingify|2023-08-10 13:35:09|Nice
Aakrit Vaish Haptik PeerCheque|2023-08-10 13:35:24|Merchant side use cases maybe.  Consumers I don't think will benefit too much. Again a good to have, not must have imo.
Sandeep Srinivasa RedCarpetup|2023-08-10 13:36:05|ah interesting perspective. i can see how that would work
Pratyush Choudhury|2023-08-10 13:43:36|Umm, let's discuss it maybe 1:1
Sumod K Mohan|2023-08-10 13:52:12|Count me in [PHONE]  ‎<This message was edited>
Amit Bhor|2023-08-10 13:52:15|It's for UPI 123  https://www.livemint.com/money/personal-finance/punjab-national-bank-pnb-launches-ivr-based-upi-123pay-how-to-make-upi-payments-without-internet-11686561307577.html
Dr. Pratik Desai KissanGPT|2023-08-10 13:54:19|I would love to have a group for AI on Edge, where we can discuss smaller models and quantization efforts. I saw a lot of discussion today on Twitter regarding that, and can be very important going forward.
Pratyush Choudhury|2023-08-10 13:55:14|Yep, it will be and that's where the world seems to be headed - expecting Apple and/or Meta to make some splashes there
Dr. Pratik Desai KissanGPT|2023-08-10 13:58:59|[PHONE] You can check with Nirant and lead it.
Dr. Pratik Desai KissanGPT|2023-08-10 14:06:10|Using GenAI GPU group for Edge discussions instead of creating another group.
Vamshi|2023-08-10 14:26:59|I think the F320 or a batch of similar phones had the Syntiant NDP on it, feels like a distant past, but just yesterday 😄
Vamshi|2023-08-10 14:27:07|https://www.counterpointresearch.com/jiophone-next-laying-robust-foundation-ambitious-shift-towards-5g-era/
Vamshi|2023-08-10 14:28:20|This what you are referring to by 1:1 search? Just wake word followed by cloud asr ?
Tejas Referred By paras|2023-08-10 15:22:08|Hey everyone, I see a lot of interest in foundational models on edge devices.  My co-founder Ayush and I are building nolano.org. We are working on a small foundational model, better compression techniques, and a developer toolkit in react native.  Feel free to DM me for a discussion
Sumod K Mohan|2023-08-10 15:30:47|Pretty nice. We all were discussing on the GPUs, Edge, Infra group, if you are interested in that conversation.
Tejas Referred By paras|2023-08-10 15:32:32|Sure, could you provide me with a WhatsApp invite for the group?
Nirant|2023-08-10 15:33:35|You don't need one, look for it in the WhatsApp Community for this group
Tejas Referred By paras|2023-08-10 15:34:07|Thanks gotta
Rahul Bhatnagar|2023-08-10 15:42:54|Pretty impressive [PHONE]! Signed up for the beta.   Would love to see how the smaller foundational models perform in specific use cases. I used the smaller ~44M Token models that Karpathy shared with llama.c and they weren’t bad in the narrow scope of generating stories.
Nirant|2023-08-10 15:44:34|Speaking of this, Microsoft Research distilled ChatGPT for specific tasks/domains: https://arxiv.org/abs/2308.03279
Nirant|2023-08-10 15:45:44|They've used NER as a motivating example — we can all the tasks in SuperGLUE should work in the same way
Rahul Bhatnagar|2023-08-10 15:49:35|Yeah intuitively it seems that these targetted scope models should be pretty helpful in/as products.   Though till now I haven’t seen practical examples that validate the hype.
Dr. Pratik Desai KissanGPT|2023-08-10 15:54:29|Looks interesting. 👍
~ Rachitt|2023-08-10 16:07:57|Has anyone worked on creating agents for multiple json files for deriving insights?  I have two files, one with a list of questions and one with responses, and i wish to create an agent which checks responses against questions and gives feedback
Abhishek Mishra|2023-08-10 16:39:20|nolano is great, like the cformers lib :)
Ankur Pandey|2023-08-10 18:41:36|https://thewholetruthfoods.com/learn/truth-gpt
aashutosh GenerativeAI WhatsApp Group|2023-08-10 19:07:14|oh! no I meant NodeJS
Ravi Theja|2023-08-10 19:08:29|https://www.npmjs.com/package/llamaindex
aashutosh GenerativeAI WhatsApp Group|2023-08-10 19:11:18|yup! landed on this 👍
~ vignesh iyer✌️|2023-08-10 19:41:29|Thanks for this excellent recco.. tried with few questions of my own and really impressed by the elaborate and relevant response
Ankur Pandey|2023-08-10 19:51:56|Did you compare with chatgpt, Claude etc?
~ vignesh iyer✌️|2023-08-10 20:01:08|Good suggestion.. didn't do direct comparison yet
ashish Acgt01 Twitter|2023-08-10 21:21:38|https://pair.withgoogle.com/explorables/grokking/  https://news.ycombinator.com/item?id=37076210
Sudharshan GenAI|2023-08-10 22:09:34|Anyone got into the next round of AI grants?
Kshitij Agrawal ML Engineer|2023-08-10 22:10:15|Perhaps weights and biases? I recvd an email from them claiming funding from Nat Friedman.
Sudharshan GenAI|2023-08-10 22:11:05|No lol - they got a 50M$ infusion  ai grants is more pre-seed
Sudharshan GenAI|2023-08-10 22:11:14|250K$
Kshitij Agrawal ML Engineer|2023-08-10 22:11:38|Lol my bad 😆
Kaushik Bokka|2023-08-10 22:14:08|I have a feeling W&B will kill half the prompt tooling startups in the coming months
Sudharshan GenAI|2023-08-10 22:15:27|lol
Sudharshan GenAI|2023-08-10 22:15:35|perhaps
Ravi Theja|2023-08-10 22:21:43|moat seems distribution now 😅
Pratik Bhavasar|2023-08-10 22:24:20|If distribution was moat, Threads would have been very successful by now, all search engines would have killed you.com and perplexity.ai …. and so on
Jithin James Ragas|2023-08-10 22:43:54|wandb feels a bit out of place for me actually (person pref mostly) but I really like langsmith from langchain even though its just beta
Jithin James Ragas|2023-08-10 22:44:20|wandb does have everything though, maybe repackaging stuff could help
Sandeep Srinivasa RedCarpetup|2023-08-10 22:47:06|Genuine question - what part of langsmith do you like compared to wandb for example ?
Piyush Makhija|2023-08-10 22:49:26|Distribution is one kind of moat and a very powerful one ...given that you execute well  Threads optimised for acquisition. Not value addition or user experience. Hence they are facing churns
Jithin James Ragas|2023-08-10 22:55:38|nothing major, just personal prefs  one thing I really like which is specific to what we're building is evaluation and specific the ability to see the traces of each individual example and the corresponding evaluation runs. Its linked together so moving back and for this easier
ashish Acgt01 Twitter|2023-08-10 22:55:42|https://github.com/geekan/MetaGPT  https://arxiv.org/abs/2308.00352  https://news.ycombinator.com/item?id=37076125
~ Vishwam Jindal|2023-08-10 23:06:29|https://www.linkedin.com/posts/rishi-sunak_as-i-said-at-london-tech-week-the-possibilities-activity-7095354576786075648-OYdn?utm_source=share&utm_medium=member_android
Pratik Bhavasar|2023-08-10 23:19:09|I agree there are many variables in moat. My comment was to highlight no single moat is too powerful. ‎[8/11/23, 01:05:10] Nilesh Transcend: ‎image omitted
Aashay Sachdeva MPL Data Scientist|2023-08-11 01:16:25|I don’t see llama here. Have they released the code for benchmarking?
Nilesh Transcend|2023-08-11 01:18:06|yes: https://github.com/THUDM/AgentBench
Aashay Sachdeva MPL Data Scientist|2023-08-11 01:29:42|Ah ok llama2 is there
Nilesh Transcend|2023-08-11 01:31:12|am not sure: https://github.com/THUDM/AgentBench/issues/1
Anshuman Pandey|2023-08-11 01:56:30|https://mlsecops.com/resources/hacking-ai-h2o-exposes-entire-filesystem [PHONE] ‎[8/11/23, 01:57:14] Aashay Sachdeva MPL Data Scientist: ‎image omitted
~ Sayan|2023-08-11 07:54:26|"While using langchain agents (like python agent or pandas dataframe agent), are there some basic security checks that can be put in before the ""eval"" function evaluates untrusted code generated by llms"
~ Sayan|2023-08-11 07:55:33|Even shell tool for that matter
~ Sudhanshu Heda|2023-08-11 09:10:35|https://twitter.com/modal_labs/status/1689707029378805760?s=20 Releasing AGI str8 up XD
Prayank Swaroop Accel|2023-08-11 09:13:23|Is there is an AI accelerator in India also .. ? (plug)
Dr. Pratik Desai KissanGPT|2023-08-11 09:15:25|If there is one, they must be doing a really bad job as no one knows about them.
Dr. Pratik Desai KissanGPT|2023-08-11 09:16:16|We easily have 10+ companies here who can be good candidates
Anshuman Pandey|2023-08-11 09:20:33|🔥🔥🔥
Lalit Pagaria|2023-08-11 09:26:15|It has an easy fix, I think they might have fixed it. Most of the time security is an afterthought but it should be before. Nowadays it is easy to set up security bug bounty programs so you do not need to hire a full-time security researcher.
Anshuman Pandey|2023-08-11 09:27:34|Bro try this episode from Practical AI w/Modal CTO. Very opinionated but a good listen
Anshuman Pandey|2023-08-11 09:27:41|https://podcasts.google.com/feed/aHR0cHM6Ly9jaGFuZ2Vsb2cuY29tL3ByYWN0aWNhbGFpL2ZlZWQ/episode/Y2hhbmdlbG9nLmNvbS83LzIwMjQ?ep=14
Ankur Pandey|2023-08-11 11:25:31|Noticed that Accel modified the atoms program. Although looks super small (upto 5) https://atoms.accel.com/ai
Nirant|2023-08-11 11:26:15|The best place for this is the the Startup Ecosystem group — same WA community. [PHONE] can add you there.
Prayank Swaroop Accel|2023-08-11 11:28:28|We can't market the program here ... but have 200+ applications in one week.
Prayank Swaroop Accel|2023-08-11 11:29:16|The idea is to do less, to be meaningful partners to the company. We spend a lot of time with each company.
Dr. Pratik Desai KissanGPT|2023-08-11 11:30:56|Startup group, you should be able to post. I’m surprised that it is not as much talked about compared to AI grant, even being India centric.
Prayank Swaroop Accel|2023-08-11 11:31:22|Haha .. I posted there. Videshi maal is always better.
Divya Tak|2023-08-11 11:31:25|Yea! Second that
Prayank Swaroop Accel|2023-08-11 11:32:56|Guys don't want to hijack this space. I think we are doing our thing. Don't want to market it. Want people who care about AI to discover it naturally. Lot of webinars and events we are doing. If founders like it they can apply.
Dr. Pratik Desai KissanGPT|2023-08-11 11:33:21|May be people are attracted by the supporting cast that they can bring. At this moment, more than money, many other things founders are looking for.
Shashwat TDC|2023-08-11 11:34:01|For their quality though. Received communication from all of them even if it's negative.
Dr. Pratik Desai KissanGPT|2023-08-11 11:34:29|We should take it to Startup group. If this is being done, it need more eyes.
Prayank Swaroop Accel|2023-08-11 11:34:57|Did you receive it the same day Sashwat? We will be sending interview invites and rejects this week. for the 1st week apps. Happy to discuss separately how can we be better.
Prayank Swaroop Accel|2023-08-11 11:36:10|I have been trying, no US speaker wants to spend time with India guys. We have offered to fly them to India - no one wants to come. We are planning to take our selected Indian AI founders to US. If this group can help with good people from US wanting to spend time with Indian AI founders - happy to enable it.
Sandeep Srinivasa RedCarpetup|2023-08-11 11:36:54|kudos to you 👏👏👏
Shashwat TDC|2023-08-11 11:37:33|"We did discuss separately. Looks like our pitch deck still didn't reach you 😅 It's okay though, I just found this notion to be incomplete, ""videshi maal is better"" quality is often overlooked in marketing efforts.  Giving credits where it's due. AI grant and a few other programs were almost a breeze to apply nd hear rejection back. Time-bound applications, short application, crisp communication.. helps save time for founders. ‎<This message was edited>"
Sandeep Srinivasa RedCarpetup|2023-08-11 11:44:54|https://github.com/microsoft/Llama-2-Onnx  is anyone running ONNX models in production ? what has been ur experience ? we deployed our first onnx embedding models in prod on edgechains using DJL few days back. But havent done it so far for full fledged LLM models
Rahul Bhatnagar|2023-08-11 12:13:45|https://twitter.com/paulg/status/1689872015535300608  This is something I was thinking about.  Wonder if we have domain experts in the community who have deep insights into problems to be solved and are looking for tech folks to support the tech?
Rahul Bhatnagar|2023-08-11 12:17:55|If so, would love to scope out your idea and connect you to some smart engineers I’ve been mentoring.
Paras Chopra Wingify|2023-08-11 12:28:43|‎POLL: Is ChatGPT Plus subscription worth it? ‎OPTION: Yes (24 votes) ‎OPTION: Nope (14 votes) ‎OPTION: It depends (1 vote)
Azhan Mohammed Generative AI WhatsApp Group|2023-08-11 12:30:09|What would be a suitable way to compare similarity between two different strings with very loss or no common words.
Azhan Mohammed Generative AI WhatsApp Group|2023-08-11 12:31:15|Tried approach:  Created key value pair of the description, used sentence transformer's 'all-MiniLM-L6-v2' model to get embeddings and then calculated the cosine distance between them, but the results were quite bad
~ Prashant|2023-08-11 12:37:01|Can you share an example where you got bad results? I can take a look.
Chaitanya A GenAI|2023-08-11 12:52:57|mostly dependant on data, you could experiment with more models or even look at finetuning a sentence transformers like model with contrastive loss over your data
Harsh Gupta Felvin|2023-08-11 12:54:34|Perplexity is way better with the same price point
Paras Chopra Wingify|2023-08-11 12:55:11|those who said yes, can you elaborate what aspect? plugins/code intepretor/gpt4? what makes it worth it
Dr. Pratik Desai KissanGPT|2023-08-11 12:56:27|Still a lot better at coding, code interrupter. Plugins, not so much. ‎<This message was edited>
Shashwat TDC|2023-08-11 12:59:19|We observed very huge drop in quality. So bought gpt4.5 for quality. And code interpreter has become sort of default for any gpt interaction.
Abhinav Verma Longshot.ai|2023-08-11 12:59:21|Use a cross encoder or nli model and check entailment score between to strings
Nirant|2023-08-11 13:00:41|Code Interpreter is great. And frankly, $20/mo is pretty cheap given that it saves me more than 4-6 hrs/week now. 
Paras Chopra Wingify|2023-08-11 13:02:18|Can you share examples?
Paras Chopra Wingify|2023-08-11 13:02:57|Default for any interaction?
Nirant|2023-08-11 13:05:56|1. This blog with over 2K clicks is Code Interpreter: https://nirantk.com/writing/pgvector-vs-qdrant. So are the charts 2. Lot of the syntax sugar e.g. SQL tools, tool decorator in my library is implemented by Code Interpreter: https://github.com/NirantK/agentai 3. (Coming Soon) API design, tests, and some copywriting for new lib is going to be 80% Code Interpreter  I make the API design choices, but the implementation is intern/employee or Code Interpreter
Paras Chopra Wingify|2023-08-11 13:06:30|you should livestream your sessions with it, people will benefit
Paras Chopra Wingify|2023-08-11 13:07:28|for the blog, it wrote the blog or it generated graph
~ Akshat Khare|2023-08-11 13:08:01|Well any kind of rule engineering for business need over tabular data is quite easily accomplished. Not exactly cool ai stuff but when there is some basic but essential data processing involved, it excels quite naturally Let's say a Google analytics big query export, and you wish to create a workflow to extract churning customer Id for last three months. It enables and does that better than I would do it in 5 minutes.
Amit Bhor|2023-08-11 13:11:00|Do you verify the code it generates? I worry that ChatGPTs sycophancy percolates to codegen too and makes confirmation bias worse.
Amit Bhor|2023-08-11 13:12:53|I do like code interpreter for basic analysis and to double check some more complex analysis
Nirant|2023-08-11 13:13:14|Both
~ Akshat Khare|2023-08-11 13:13:55|Well, I always have a colab lying around to copy paste and run the thing with bigger samples. I have only seen it hallucinate wildly when it comes to very complex sql queries when nesting and merges are involved. But the comments it uses generally helps in verifying what it is trying to do ‎[8/11/23, 13:14:01] Prayank Swaroop Accel: ‎image omitted
Nirant|2023-08-11 13:15:17|"I wrote fairly detailed bullet lists of observations and assumptions, and asked Code Interpreter to generate graphs for tables which [PHONE] shared + ""write a blog which a data engineer can understand in 3 minutes or less"""
Paras Chopra Wingify|2023-08-11 13:16:30|Did you apply data in csv?
Nirant|2023-08-11 13:17:16|Yes, uploaded a csv and mentioned the columns of interest to me
~ Akshat Khare|2023-08-11 13:19:49|Yeah this is pretty important as it doesn't try to think like a data scientist. Always takes head() first and works on that long output and messes up with right column names for analysis. I wish it was able to more naturally reason what columns to work with methodologically.
Nirant|2023-08-11 13:23:08|"I've higher expectations of my interns than Code Interpreter on reasoning, and lower on syntax. Code Interpreter might as well be called ""leetcoder with puzzle solving skills"""
Sudharshan GenAI|2023-08-11 13:24:35|Nice! where's this?
Nirant|2023-08-11 13:24:37|~5% humans win at: Reasoning, Judgement, Taste, Context  Code Interpreter wins at: (Python, JS, SQL) Following code conventions, syntax, unit tests
Paras Chopra Wingify|2023-08-11 13:25:03|you convinced me to spend $20/mo today :)
Anshul Bhide Replit|2023-08-11 13:26:22|with the caveat as some people have mentioned, Perplexity is a really good alternative
Nirant|2023-08-11 13:27:06|That'll be $1000 for the advice Paras, will raise a separate invoice xD
Prayank Swaroop Accel|2023-08-11 13:27:14|Fifth Elephant conference in Indiranagar BIC today
Nirant|2023-08-11 13:27:42|Fifthel, BIC Domlur, I'll be there too around ~4 PM, dropby?
Sudharshan GenAI|2023-08-11 13:29:27|Will do
Sudharshan GenAI|2023-08-11 13:29:29|What’s the schedule? ‎[8/11/23, 13:32:10] Nirant: ‎image omitted ‎[8/11/23, 13:32:38] Paras Chopra Wingify: ‎image omitted
Paras Chopra Wingify|2023-08-11 13:32:40|seems totally worth it
Nirant|2023-08-11 13:35:14|Tip: If you've text of these tweets, you can ask Code Interpreter to calculate the Fleish Kincaid level/score — Grade 7 or lower tweets often have more reach
Nirant|2023-08-11 13:36:26|If I want to say something simple, I ask GPT4 to rewrite to increase Kincaid grade than that almost always
Dr. Pratik Desai KissanGPT|2023-08-11 13:36:49|Welcome to the amazing world of Code Interpreter.
Abhinav Verma Longshot.ai|2023-08-11 13:37:22|I've used code interpretor to help me write commands to extract logs and then I've uploaded the logs to extract key insights. Same with a lot of other analytics tasks.  Plus I've used plus sub to cover other stuff, like learning Rust, and do a deep dive on coroutines etc.  Granted I use my tool LongShot as well, one major advantage is you can search across specific domains, whole web, or files. But chatgpt plus is fixed cost so it actually helps save on gpt4 and claude bill.  Plus with custom instructions, its also decent at helping design prompts. It is pretty close to hiring a full stack intern
Abhinav Verma Longshot.ai|2023-08-11 13:39:36|The quality of code by gpt4 is more accurate than 3.5. Especially for non Python code and python setup ‎[8/11/23, 13:43:54] Nirant: ‎image omitted
Abhinav Verma Longshot.ai|2023-08-11 13:44:39|Yes, this one is very good. Jeremy Howard with another gem here
~ Akshat Khare|2023-08-11 13:45:35|Just read this metric, how different are the responses when you just prompt gpt4 without code interpreter to 'make tweet more readable following Fleish Kincaid principles'
Azhan Mohammed Generative AI WhatsApp Group|2023-08-11 13:46:10|Will try this out.
Abhinav Verma Longshot.ai|2023-08-11 13:46:38|You can check this. I think code interpreter has access to textstat and is able to calculate the score
Paras Chopra Wingify|2023-08-11 13:47:02|Share as text please so can upload :)
Nirant|2023-08-11 13:47:48|I want my tweets to be hard to read, not easy 🙈  I don't want to write/speak to children in adult-sized bodies
Nirant|2023-08-11 13:48:37|Part 1: You are an autoregressive language model that has been fine-tuned with instruction-tuning and RLHF. You carefully provide accurate, factual, thoughtful, nuanced answers, and are brilliant at reasoning. If you think there might not be a correct answer, you say so. Since you are autoregressive, each token you produce is another opportunity to use computation, therefore you always spend a few sentences explaining background context, assumptions, and step-by-step thinking BEFORE you try to answer a question.  Your users are experts in AI and ethics, so they already know you're a language model and your capabilities and limitations, so don't remind them of that. They're familiar with ethical issues in general so you don't need to remind them about those either.  Part 2: Don't be verbose in your answers, but do provide details and examples where it might help the explanation.  When showing Python code, minimise vertical space, include comments, type hints or docstrings; always follow PEP8, since your users' organizations do so
Nirant|2023-08-11 13:49:18|"I've tweaked the Jeremy version a bit for the second half. Saying ""Be crisp and concise"" works better than ""Don't be verbose"" too."
Anshul Bhide Replit|2023-08-11 13:50:25|Found this by Nivi on Twitter  (a little more generalized, not coding specific) https://twitter.com/nivi/status/1683621899254001665
Amit Bhor|2023-08-11 13:51:19|https://hamel.dev/notes/llm/inference/03_inference.html#comparison-without-tgi-server
Amit Bhor|2023-08-11 13:51:35|Nice post if you are looking at performance
Abhishek Mishra|2023-08-11 15:16:40|"Yeah negative instructions don't work out very well with LLMs. It's easy for it to just pick up on ""verbose"" and lose the idea of ""not"" doing it for long context."
ashish Acgt01 Twitter|2023-08-11 15:28:07|"[PHONE] pointed me to a very interesting tweet yesterday https://twitter.com/jeremyphoward/status/1689464587077509120?s=20  He also had a related tweet, where performance improves considerably with ""custom instructions"": https://twitter.com/jeremyphoward/status/1689470850653999104?s=20"
Abhishek Mishra|2023-08-11 15:49:29|That GPT4 version of code interpreter can reason to some extent for sure. I've tested it out with puzzles.
Abhishek Mishra|2023-08-11 15:50:23|Letting the model flesh out it's plan before trying to give the answer almost always boosts the reasoning by a notch. ‎[8/11/23, 15:55:47] ~ Vinay: ‎image omitted
Nilesh Transcend|2023-08-11 16:17:27|Anyone here using Runway's Gen2 model? How's the experience been so far? https://research.runwayml.com/gen2
Sandesh Anand|2023-08-11 18:21:19|Cyber Security is one area I am focused on (Spent the last 15 years in the space). I am interested in: 1. GenAI Security/Governance (primary focus area) 2. Leveraging GenAI to solve Cybersecurity challenges If anyone is interested in hearing my thesis or wants to chat in general about the space, HMU!
Rahul Bhatnagar|2023-08-11 18:26:36|Hey Sandesh let’s dm and set up some time to talk.
Ambika Computational Mama|2023-08-11 18:34:55|Excellent no api
Hasan Tech Art Guy|2023-08-11 18:37:13|Sounds good.
Hasan Tech Art Guy|2023-08-11 18:37:15|Please DM
Ankur Pandey|2023-08-11 19:02:25|A corollary is that veterans in old impenetrable industries who can just figure out a way to fix or ease old problems using AI may drive the next wave. And maybe that was the moat all along.
Rahul Bhatnagar|2023-08-11 19:09:25|I agree.  Got some dms. Will follow up and see.
~ Nikhil|2023-08-11 19:19:44|"For people who use Qdrant, what does a ""collection"" mean to you? 1. Do you create a large collection for your app and dump all embeddings in it? 2. Do you create a collection by data types (image / text)? 3. Do you create a collection for a set of embeddings related to a certain topic?  Also, are there any limits to how many collections that can be created? Similarly, is there an upper limit to the number of embeddings that can be added to one single collection?"
~ Aman|2023-08-11 19:34:34|Hey, anyone working in AI and Health care, specially in fields like mental health which have a major coldstart problem in terms of quality dataset? Would love to discuss on this!
Ambarish Ganguly|2023-08-11 20:13:24|I am segregating by Business Domains
Vimal Singh Rathore|2023-08-11 20:13:39|‎You removed Vimal Singh Rathore
Nirant|2023-08-11 20:24:58|Can speak 1-1 as well, and if you've a team — help them ramp up. Had also met [PHONE] in the same vein a few weeks ago
Pranjal Mehta|2023-08-11 20:33:22|PG disagrees
Nirant|2023-08-11 20:35:46|PG perfected Straussian writing
Anubhav mishra Zupay|2023-08-11 22:00:01|https://twitter.com/yoheinakajima/status/1690035703424700416?t=nh63-kBE-pGTApZ_jq5LVg&s=08
Shashank Generative AI Group|2023-08-11 22:02:57|yep. the new img2clip is pretty neat.   some features are free to try out via their Discord bot. web version is paid and better (there are some free credits tho)  i posted some in the other group a few weeks back. (twitter link: https://twitter.com/shacrw_/status/1682492606335295488?t=17efAuOMfHYC6CDB1sh10w&s=19)
Shashank Generative AI Group|2023-08-11 22:03:48|more (and better) examples by others:  https://twitter.com/hashtag/GEN2?t=npSUqKOva2cvgIyK0cXUXg&s=09
Shashank Generative AI Group|2023-08-11 22:09:25|"💯. related blogpost   https://okarthikb.github.io/site/blog/detailed-prompting.html  addition on large numbers using gpt-4  ""The second reason why GPT-4 fails at zero-shot addition is that *you give it no room to do computation.* GPT-4 is an autoregressive language model, which means that the output at a timestep is conditioned on all previous outputs..... This leads to the most important (IMO) emergent phenomena in large language models - in-context learning. It is the ability to utilise information in the previous context in non-trivial ways to predict the next token better. How does it happen here?  Well, how do first graders do addition?They go from right to left one digit at a time."" ‎[8/11/23, 22:11:09] Dev Aggarwal: ‎sticker omitted"
Dev Aggarwal|2023-08-11 22:11:23|Crimes against LLMs
Shashank Generative AI Group|2023-08-11 22:11:33|😂
Shimanta Generative AI|2023-08-11 22:11:48|https://twitter.com/rauchg/status/1690010637986942976?s=46&t=WT1iAtjftW-5_e62F8FZTg  Can this be possible: streaming the input while output is streaming?
~ Srinivasan Nandakumar|2023-08-11 22:13:12|Something beautiful about running millions of flops to get an answer over a calculator 😂
Shimanta Generative AI|2023-08-11 22:15:27|I might have phrased it wrong, I meant streaming an input to the llm while it’s still in the process of streaming the output to the last request. Is this a technical problem to solve or a ux thing?
~ WhatsApp User|2023-08-11 22:18:11|‎~ WhatsApp User requested to join ‎[8/11/23, 22:20:36] Nilesh Transcend: ‎image omitted ‎[8/11/23, 22:40:13] Prayank Swaroop Accel: LangChain Talk.pdf • ‎35 pages ‎document omitted
Gokul Krishnan|2023-08-12 00:12:48|Autoregressive Decoding is essentially ingest and emit only one token per step, so you would have to wait until it's done or have some logic to decide when to stop generation and start processing input instead
Abhishek Mishra|2023-08-12 00:52:13|There was a paper around a month back that concluded something similar by showcasing how we can make the LLMs improve in arithmetic to some extent if we let them learn from examples with unitary step by step addition ‎<This message was edited>
Abhishek Mishra|2023-08-12 00:52:44|Reduces the error from the LLM trying to predict the next likely token instead of actually finding by the token by deterministic ways
Abhishek Mishra|2023-08-12 00:53:40|It's a lesson and direction on ensuring better performance for tasks that deterministic systems (like calculator) do better than LLMs. Can be generalised and tested ‎<This message was edited>
Dev Aggarwal|2023-08-12 00:54:56|I’m skeptical - how would this pan out with say a 1000 randomised large digit addition? I think not too well. Cc [PHONE]
Sandeep Srinivasa RedCarpetup|2023-08-12 01:03:00|not worth it. having it offload to an outside math framework is far more efficient. even if a llm could do math, it cant compute as fast as dedicated math frameworks (BLAS/LAPACK)  you need to orchestrate this sure...but worth the pain.
Abhishek Mishra|2023-08-12 01:03:48|The paper also showed that it doesn't work very well for large digits.
Abhishek Mishra|2023-08-12 01:04:12|The number of digits that behaviour was maintained was similar to the number of digits in the training examples
Abhishek Mishra|2023-08-12 01:04:45|Finding the paper and sharing here, not a very scalable approach.
Dev Aggarwal|2023-08-12 01:04:54|Yes, but this prompt seems to avoid large addition right
Dev Aggarwal|2023-08-12 01:05:14|It breaks down numbers, which might make this actually work
Abhishek Mishra|2023-08-12 01:05:55|Yeah unitary addition was also the approach of the paper. Going from rightmost addition to left.
Shashank Generative AI Group|2023-08-12 01:11:45|"doing ""rough work"" sucks 😂"
Abhishek Mishra|2023-08-12 03:33:37|https://arxiv.org/abs/2307.03381
Abhishek Mishra|2023-08-12 03:33:53|Found the paper, came last month 7 July
"~ $@| @$w@+h R•¥@|"|2023-08-12 08:05:17|"‎~ $@| @$w@+h R•¥@| was added"
"~ $@| @$w@+h R•¥@|"|2023-08-12 08:05:17|"‎~ $@| @$w@+h R•¥@| left"
